{"url": "https://towardsdatascience.com/the-basics-of-data-prep-7bb5f3af77ac", "time": 1683007101.871711, "path": "towardsdatascience.com/the-basics-of-data-prep-7bb5f3af77ac/", "webpage": {"metadata": {"title": "How to Prepare your Data. Structuring, cleaning, and enriching\u2026 | by Diego Lopez Yse | Towards Data Science", "h1": "How to Prepare your Data", "description": "It is rare that you get data in exactly the right form you need it. Often you\u2019ll need to create some new variables, rename existing ones, reorder the observations, or just drop registers in order to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.analyticsindiamag.com/industry-view-what-are-the-popular-tools-and-techniques-used-by-analytics-practitioners/", "anchor_text": "data-wrangling piece is a prerequisite to the math/modelling", "paragraph_index": 2}, {"url": "https://thenextweb.com/podium/2019/06/19/data-science-automation-ai-custom-data-science/", "anchor_text": "data won\u2019t be ready", "paragraph_index": 3}, {"url": "https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html", "anchor_text": "You may transform categorical variables to a format which will better work for classification and regression models, or use logarithmic transformations to transform non-linear models into linear models and work with skewed data.", "paragraph_index": 23}, {"url": "https://towardsdatascience.com/python-pandas-dataframe-join-merge-and-concatenate-84985c29ef78", "anchor_text": "link", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14", "anchor_text": "Decision Tree", "paragraph_index": 37}, {"url": "https://www.datacamp.com/community/tutorials/categorical-data", "anchor_text": "here", "paragraph_index": 54}, {"url": "https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction", "anchor_text": "here", "paragraph_index": 58}, {"url": "https://www.linkedin.com/in/lopezyse/", "anchor_text": "Linkedin", "paragraph_index": 61}, {"url": "https://twitter.com/lopezyse", "anchor_text": "Twitter", "paragraph_index": 61}], "all_paragraphs": ["It is rare that you get data in exactly the right form you need it. Often you\u2019ll need to create some new variables, rename existing ones, reorder the observations, or just drop registers in order to make data a little easier to work with.", "This is called data wrangling (or preparation), and it is a key part of Data Science. Most of the time data you have can\u2019t be used straight away for your analysis: it will usually require some manipulation and adaptation, especially if you need to aggregate other sources of data to the analysis.", "In essence, raw data is messy (usually unusable at the start), and you\u2019ll need to roll up your sleeves to get to the right place. For this reason, all the activity you take to make it \u201cneat\u201d enough is as important as the algorithms you choose to work with. In almost all cases, the data-wrangling piece is a prerequisite to the math/modelling and a majority of the time is spent on cleaning the data in a real-world scenario.", "Let\u2019s face it: data won\u2019t be ready or able to be consumed by any algorithm without extra effort.", "So, let\u2019s discuss some concepts that will help you face this sometimes seemingly titanic task. In practical terms, datasets can be considered as tables composed of variables (columns), and observations (rows):", "Columns or variables should be all of the same type (e.g. numeric, date, character, etc), while rows or observations (also referred to as \u201cvectors\u201d) can be a mixture of all types of data.", "So, to begin discussing data preparation we need to distinguish between data wrangling for one, and more than one datasets.", "The main tasks to deal with single datasets are:", "One of the most basic functions of data wrangling is to order rows by the value or characters of a variable, or a selection of them. This can be in alphabetical order, from the smallest to highest number, or others.", "In most cases, you\u2019ll need to sort one single variable, but sorting can be done with multiple criteria, by defining one main parameter and then the subsequent ones.", "Selection is the activity of choosing columns in a dataset based on a defined criteria. This can be as simple as picking a column based on its name or position, or using different statements on a range of columns. It\u2019s possible to make partial matching on columns by using statements like \u201cstarts with\u201d, ends with\u201d, or \u201ccontains\u201d in the selection statement, or even exclude a specific column (or a chunk of columns) from the selection.", "You can use conditional selections to show columns that meet certain criteria, like showing only columns that contain numeric data, or character data for example. The other way around, you can select the negation of these conditions, and select only data that doesn\u2019t meet one or more conditions(e.g. show only data that\u2019s not date formatted).", "Additionally, you can use logical expressions on numeric data like selecting values that are above a certain threshold or contain an average value below a certain parameter.", "When you don\u2019t want to include all rows of a dataset in your analysis, you can use a filter function to return rows that match 1 or more conditions. This is a sub-setting procedure that allows you to pick specific values by column/s, a range of values, or even approximations with ranges of tolerance. With characters, you can filter to include or exclude results based on exact or partial character matches, and also find registers that begin with, end up or contain certain terms.", "Filters with multiple conditions can be combined with AND, OR, and NOT conditions, and you can even specify to return values when only one condition out of two is met, but not doing it when both are met.", "Similar to selection functions, filters can be applied to all columns with no discrimination, or used with conditions to return just the registers that meet them. Filter functions are especially useful to filter out NA or missing values rows. You can also filter the top highest or lowest values and show only those registers, without the need to show the whole dataset rows.", "Filtering is the right method for getting the unique or distinct values in a data frame, or just counting the number of them.", "Data aggregation is the process of gathering information and expressing it in a summary form, with the objective of performing statistical analysis (summarizing) or creating particular groups based on specific variables (grouping by).", "Summarized operations use a single numerical value to condense a large number of values, for example, the mean/average or the median. Other examples of summary statistics include the sum, the smallest (minimum) value, the largest (maximum) value, and the standard deviation: these are all summaries of a large number of values. This way, a single number gives insights into the nature of a potentially large dataset, just by computing aggregations.", "Summarizing can be conditional, where you state the arguments prior to performing the operation. For example, if you consider calculating the mean of all variables, you can define a condition to do so only for variables that are numeric, since categorical variables will produce an error (they have no mean).", "In most cases, we don\u2019t just want to summarize the whole data table, but we want to get summaries by groups, which gives better information on the distribution of the data. To do this, you first need to specify by which variable(s) you want to divide the data, and then summarize those categories.", "Group by is a classic aggregation function, that becomes powerful when combined with a summarize function. You can group by multiple variables, and then summarize multiple variables at the same time, which is quite useful when you want to brake down variables by categories. This approach is also known as the \u201cSplit-Apply-Combine Principle\u201d, in which you break up a big problem into small manageable pieces (Split), operate on each piece independently (Apply), and then put all the pieces back together (Combine).", "Transforming data involves the creation of new record fields through existing values in the dataset, and is one of the most important aspects of data preparation . It\u2019s not easy to identify when (and if) data transformations are required, and it\u2019s even more complex to define the type of transformation required.", "But why would you bother transforming a variable? You may transform categorical variables to a format which will better work for classification and regression models, or use logarithmic transformations to transform non-linear models into linear models and work with skewed data.", "You can perform all types of transformations (e.g. standardization, normalization, or binarization), and apply the same transformation to multiple variables. You can concatenate variables to create new ones, or perform basic arithmetic operations to create them.", "This is what you use when you want to convert specific characters to something else. You can convert numerical characters to data & time formats, or re-code variables to fit models. This technique is typically used to replace missing values, although we\u2019ll deep dive in that matter later.", "The main differences between Transformation and Replacement is that you\u2019re not creating additional variables or registers (you\u2019re modifying existing ones), and you can change the nature of the variable (e.g. change a character variable to a numerical code), without creating new record fields. You can perform replacements on all variables, set conditions for them, or do it just on specific registers.", "The true power of Data Science comes with data volume. In reality, data are hosted on different servers and exist in many different files. When the data you need come from multiple sources, it\u2019s essential to know how to combine them. Let\u2019s explore some techniques generally used to exploit this matter:", "In general, you can add information by adding more rows or by adding more columns to your dataset. When you have datasets that have the same set of columns (variables) or have the same set of rows (observations), you can concatenate or bind them vertically or horizontally, respectively.", "If you\u2019re going to add more rows, datasets must have the same set of variables (columns), but observations don\u2019t have to be in the same order.", "If you\u2019re going to add more columns, you should check that the quantity and the order of the observations are the same.", "It\u2019s important to note that if you have the same observation across multiple datasets and you concatenate them vertically, you'll end up with duplicate observations in your table.", "Joins are the standard way to merge datasets into a single table. A Join is used to combine rows from two or more datasets, based on a related column between them. There are many types of joins, being the main ones:", "You can find examples in Python in this link", "Often encoded as NaNs or blanks, missing data (or missing values) is defined as the data value that is not stored for a variable in the observation of interest. The problem of missing data is relatively common in almost all research and can have a significant effect on the conclusions that can be drawn from the data. Missing values can be categorized into:", "There are many strategies for dealing with missing data, and none of them are applicable universally. Resolving this issue require both experience and domain based, and it starts by understanding the nature of the missing value.", "Some commonly used methods for dealing with this problem include:", "You can also develop your own strategy, like dropping any instances with more than 2 missing values and use the mean attribute value imputation those which remain. Or what\u2019s even more complex, build a Decision Tree to fill those missing values.", "An outlier is an observation that lies at an abnormal distance from other values, diverging from otherwise well-structured data. They are data points that don\u2019t belong to a certain population.", "In order to identify them it\u2019s essential to perform Exploratory Data Analysis (EDA), examining the data to detect unusual observations, since they can impact the results of our analysis and statistical modeling in a drastic way. Look at the following example:", "Do you see how these outliers modify the slope of the regression on the left? Which of the 2 regression lines better represent the dataset?", "All right, so you find an outlier, remove it, and move on with your analysis. NO! Simply removing outliers from your data without considering how they\u2019ll impact the results is a recipe for disaster.", "Outliers aren\u2019t necessarily a bad thing", "This is where your judgment comes to play. Outliers can drastically bias/change the fit estimate and prediction of your model, but they need to be trated carefully. Detecting outliers is one of the core problems in disciplines like Data Science, and the way you deal with them will affect your analysis and model performance. Some common ways to detect outliers are:", "Outliers can be of two types: Univariate and Multivariate. Univariate outliers can be found when we look at distribution of a single variable, while multi-variate outliers are outliers in an n-dimensional space: in order to find them, you have to look at distributions in multi-dimensions.", "Similarly to missing values, outliers can be imputed (e.g. with mean / median / mode), capped (replacing those outside certain limits), or replaced by missing values and predicted.", "The range of the variables in your dataset may differ significantly. Some features may be expressed in kilograms while others in grams, another might be liters, and so on. Using the original scale may put more weights on variables with a large range, and that can be a problem. Feature scaling is a method to unify self-variables or feature ranges in data.", "Some distanced-based algorithms like K-Nearest-Neighbours, SVMs or Neural Networks can be affected when the range of the features is very different (features with large range will have a high influence in computing the distance). On the other hand, if an algorithm is not distance-based (e.g. Naive Bayes or Decision Trees), feature scaling won\u2019t have an impact.", "So, how to do you scale?", "The choice of using normalization or standardization will depend on the problem and the machine learning algorithm. There is no universal rule to use one or the other, so you can always start by fitting your model to raw, normalized and standardized data and compare the performance for best results.", "Feature scaling can improve the performance of some machine learning algorithms significantly but have no effect on others.", "Many machine learning algorithms can support categorical values without further manipulation but there are many more algorithms that do not. Categorical variables can only take on a limited, and usually fixed, number of possible values. Some examples include color (\u201cRed\u201d, \u201cYellow\u201d, \u201cBlue\u201d), size (\u201cSmall\u201d, \u201cMedium\u201d, \u201cLarge\u201d) or geographic designations (State or Country).", "Again, there is no single answer on how to approach this problem, but let\u2019s present some of the main strategies:", "Besides these strategies, there are multiple other approaches to encoding variables, so it\u2019s important to understand the various options and how to implement them on your own data sets.", "You can find a complete tutorial for encoding in Python here.", "As data volume increases, this can have a significant impact on the time of implementation of certain algorithms, make visualization extremely challenging, and even make some machine learning models useless. Statistically, the more variables we have, the more number of samples we will need to have all combinations of feature values well represented in our sample.", "Dimensionality reduction is the process of reducing the total number of variables in our data set in order to avoid these pitfalls. The concept behind this is that high-dimensional data are dominated \u201csuperficially\u201d by a small number of simple variables. This way, we can find a subset of the variables to represent the same level of information in the data or transform the variables to a new set of variables without losing much information.", "Probably the 2 main common approaches to deal with high-dimensional data are:", "You can find a full implementation of both methods in Python here.", "In real world, data comes split across multiple datasets and across many different formats. Whether you like it or not, you\u2019ll need to face some of the problems we described, and the better you prepare, the less you\u2019ll suffer.", "The important thing to remember is that there\u2019s no free lunch. To solve a problem you need to make a decision, and that decision will bring consequences. When you drop missing values or remove outliers with percentiles, you\u2019re changing the dataset. Even when you change the smallest thing (which you\u2019ll need to do), you\u2019re changing your raw data. That\u2019s fine, no need to worry, but keep in mind that your actions (big or small) carry out consequences.", "Interested in these topics? Follow me on Linkedin or Twitter", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7bb5f3af77ac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lopezyse.medium.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": ""}, {"url": "https://lopezyse.medium.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Diego Lopez Yse"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F806fa785a6af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&user=Diego+Lopez+Yse&userId=806fa785a6af&source=post_page-806fa785a6af----7bb5f3af77ac---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@anchorlee?utm_source=medium&utm_medium=referral", "anchor_text": "Anchor Lee"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.analyticsindiamag.com/industry-view-what-are-the-popular-tools-and-techniques-used-by-analytics-practitioners/", "anchor_text": "data-wrangling piece is a prerequisite to the math/modelling"}, {"url": "https://thenextweb.com/podium/2019/06/19/data-science-automation-ai-custom-data-science/", "anchor_text": "data won\u2019t be ready"}, {"url": "https://medium.com/analytics-vidhya/split-apply-combine-strategy-for-data-mining-4fd6e2a0cc99", "anchor_text": "Analytics Vidhya"}, {"url": "https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html", "anchor_text": "You may transform categorical variables to a format which will better work for classification and regression models, or use logarithmic transformations to transform non-linear models into linear models and work with skewed data."}, {"url": "http://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/", "anchor_text": "Data Science Made Simple"}, {"url": "https://towardsdatascience.com/python-pandas-dataframe-join-merge-and-concatenate-84985c29ef78", "anchor_text": "link"}, {"url": "https://towardsdatascience.com/the-complete-guide-to-decision-trees-28a4e3c7be14", "anchor_text": "Decision Tree"}, {"url": "https://www.analyticsvidhya.com/blog/2019/02/outlier-detection-python-pyod/?utm_source=Twitter&utm_medium=social-media&utm_campaign=beginner-articles", "anchor_text": "Analytics Vidhya"}, {"url": "https://www.purplemath.com/modules/boxwhisk3.htm", "anchor_text": "measure of statistical dispersion"}, {"url": "https://donernesto.github.io/blog/outlier-detection-with-dbscan/", "anchor_text": "grows clusters based on a distance measure"}, {"url": "https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/", "anchor_text": "Analytics Vidhya"}, {"url": "https://www.datacamp.com/community/tutorials/categorical-data", "anchor_text": "here"}, {"url": "https://setosa.io/ev/principal-component-analysis/", "anchor_text": "Setosa visual explanations"}, {"url": "https://www.kaggle.com/arthurtok/interactive-intro-to-dimensionality-reduction", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/lopezyse/", "anchor_text": "Linkedin"}, {"url": "https://twitter.com/lopezyse", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7bb5f3af77ac---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7bb5f3af77ac---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----7bb5f3af77ac---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----7bb5f3af77ac---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/data?source=post_page-----7bb5f3af77ac---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&user=Diego+Lopez+Yse&userId=806fa785a6af&source=-----7bb5f3af77ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&user=Diego+Lopez+Yse&userId=806fa785a6af&source=-----7bb5f3af77ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7bb5f3af77ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7bb5f3af77ac---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7bb5f3af77ac--------------------------------", "anchor_text": ""}, {"url": "https://lopezyse.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lopezyse.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Diego Lopez Yse"}, {"url": "https://lopezyse.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "944 Followers"}, {"url": "https://www.linkedin.com/in/lopezyse/", "anchor_text": "https://www.linkedin.com/in/lopezyse/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F806fa785a6af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&user=Diego+Lopez+Yse&userId=806fa785a6af&source=post_page-806fa785a6af--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe1178cb759ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-of-data-prep-7bb5f3af77ac&newsletterV3=806fa785a6af&newsletterV3Id=e1178cb759ee&user=Diego+Lopez+Yse&userId=806fa785a6af&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}