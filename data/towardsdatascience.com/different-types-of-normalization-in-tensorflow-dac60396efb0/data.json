{"url": "https://towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0", "time": 1683009087.0724008, "path": "towardsdatascience.com/different-types-of-normalization-in-tensorflow-dac60396efb0/", "webpage": {"metadata": {"title": "Different Types of Normalization in Tensorflow | by Vardan Agarwal | Towards Data Science", "h1": "Different Types of Normalization in Tensorflow", "description": "Learn about the batch, group, instance, layer, and weight normalization in Tensorflow with explanation and implementation."}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1602.07868", "anchor_text": "papers abstract", "paragraph_index": 8}, {"url": "http://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/", "anchor_text": "article", "paragraph_index": 16}], "all_paragraphs": ["When normalization was introduced in deep learning, it was the next big thing and improved performances considerably. Getting it right can be a crucial factor for your model. Ever had those questions whatever the hell is batch normalization and how does it improve performances. Also are there any substitutes for it? If you like me had these questions but never bothered and just used it for the sake of it in your models this article will clear it up.", "The most widely used technique providing wonders to performance. What does it do? Well, Batch normalization is a normalization method that normalizes activations in a network across the mini-batch. It computes the mean and variance for each feature in a mini-batch. It then subtracts the mean and divides the feature by its mini-batch standard deviation. It also has two additional learnable parameters, the mean and magnitude of the activations. These are used to avoid the problems associated with having zero mean and unit standard deviation.", "All this seems simple enough but why did have such a big impact on the community and how does it do this? The answer is not figured out completely. Some say it improves the internal covariate shift while some disagree. But we do know that it makes the loss surface smoother and the activations of one layer can be controlled independently from other layers and prevent weights from flying all over the place.", "So it is so great why do we need others? When the batch size is small the mean/variance of the mini-batch can be far away from the global mean/variance. This introduces a lot of noise. If the batch size is 1 then batch normalization cannot be applied and it does not work in RNNs.", "It computes the mean and standard deviation over groups of channels for each training example. So it is essentially batch size independent. Group normalization matched the performance of batch normalization with a batch size of 32 on the ImageNet dataset and outperformed it on smaller batch sizes. When the image resolution is high and a big batch size can\u2019t be used because of memory constraints group normalization is a very effective technique.", "Instance normalization and layer normalization (which we will discuss later) are both inferior to batch normalization for image recognition tasks, but not group normalization. Layer normalization considers all the channels while instance normalization considers only a single channel which leads to their downfall. All channels are not equally important, as the center of the image to its edges, while not being completely independent of each other. So technically group normalization combines the best of both worlds and leaves out their drawbacks.", "As discussed earlier it computes the mean/variance across each channel of each training image. It is used in style transfer applications and has also been suggested as a replacement to batch normalization in GANs.", "While batch normalization normalizes the inputs across the batch dimensions, layer normalization normalizes the inputs across the feature maps. Again like the group and instance normalization it works on a single image at a time, i.e. its mean/variance is calculated independent of other examples. Experimental results show that it performs well on RNNs.", "I think the best way to describe it would be to quote its papers abstract.", "By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time.", "What\u2019s the use of understanding the theory if we can\u2019t implement it? So let\u2019s see how to implement them in Tensorflow. Only batch normalization can be implemented using stable Tensorflow. For others, we need to install Tensorflow add-ons.", "Let\u2019s create a model and add these different normalization layers.", "When assigning the number of groups in group normalization make sure its value is a perfect divisor of the number of feature maps present at that time. In the above code that is 32 so its divisors can be used to denote the number of groups to divide into.", "Now we know how to use them why not try it out. We will use the MNIST dataset with a simple network architecture.", "I tried all the normalizations with 5 different batch sizes namely 128, 64, 32, 16, and 8. The results are shown below.", "I won\u2019t go into deep with the results because of discrepancies like dataset bias and luck! Train it again and we will see different results.", "If you want to read about these in more detail or discover more normalization techniques you can refer to this article which was a great help to me in writing this. If you would like to further improve your network then you can read this:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdac60396efb0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dac60396efb0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@vardanagarwal16?source=post_page-----dac60396efb0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Vardan Agarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b122513e3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&user=Vardan+Agarwal&userId=e0b122513e3b&source=post_page-e0b122513e3b----dac60396efb0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1803.08494.pdf", "anchor_text": "Source"}, {"url": "https://unsplash.com/@upmanis?utm_source=medium&utm_medium=referral", "anchor_text": "Kaspars Upmanis"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@hudsonhintze?utm_source=medium&utm_medium=referral", "anchor_text": "Hudson Hintze"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@ericjamesward?utm_source=medium&utm_medium=referral", "anchor_text": "Eric Ward"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@freetousesoundscom?utm_source=medium&utm_medium=referral", "anchor_text": "Free To Use Sounds"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@kellysikkema?utm_source=medium&utm_medium=referral", "anchor_text": "Kelly Sikkema"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/abs/1602.07868", "anchor_text": "papers abstract"}, {"url": "http://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/", "anchor_text": "article"}, {"url": "https://towardsdatascience.com/beyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d", "anchor_text": "Beyond the Standard CNN in Tensorflow 2Generate deeper models with complex architectures and learn about different layers which makes the model better.towardsdatascience.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----dac60396efb0---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----dac60396efb0---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dac60396efb0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----dac60396efb0---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dac60396efb0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&user=Vardan+Agarwal&userId=e0b122513e3b&source=-----dac60396efb0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&user=Vardan+Agarwal&userId=e0b122513e3b&source=-----dac60396efb0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdac60396efb0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dac60396efb0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dac60396efb0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dac60396efb0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dac60396efb0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dac60396efb0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dac60396efb0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vardan Agarwal"}, {"url": "https://medium.com/@vardanagarwal16/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "399 Followers"}, {"url": "https://www.linkedin.com/in/vardan-agarwal-6bb123168/", "anchor_text": "https://www.linkedin.com/in/vardan-agarwal-6bb123168/"}, {"url": "https://www.buymeacoffee.com/vardan", "anchor_text": "https://www.buymeacoffee.com/vardan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b122513e3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&user=Vardan+Agarwal&userId=e0b122513e3b&source=post_page-e0b122513e3b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4ce0157411b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&newsletterV3=e0b122513e3b&newsletterV3Id=4ce0157411b4&user=Vardan+Agarwal&userId=e0b122513e3b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}