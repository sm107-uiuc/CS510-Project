{"url": "https://towardsdatascience.com/word-vectors-and-semantics-2863e7e55417", "time": 1683007386.3579469, "path": "towardsdatascience.com/word-vectors-and-semantics-2863e7e55417/", "webpage": {"metadata": {"title": "Word-Vectors and Semantics. Opinion mining or emotion AI | by Aditya Beri | Towards Data Science", "h1": "Word-Vectors and Semantics", "description": "Word2vec is a two-layer neural net that processes text. Its input is a text corpus and output is a set of vectors which are essentially feature vectors for words in that corpus. The purpose and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm", "anchor_text": "Euclidian (L2) norm", "paragraph_index": 13}, {"url": "https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Magic/Nargle", "anchor_text": "nargle", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 20}], "all_paragraphs": ["Word2vec is a two-layer neural net that processes text. Its input is a text corpus and output is a set of vectors which are essentially feature vectors for words in that corpus. The purpose and usefulness of Word2vec is to group the vectors of similar words in vectors space. It detects similarities mathematically. It creates vectors that are distributed numerical representations of word features, features such as the context of individual words and it does so without human intervention.", "Given enough data, usage and contexts, Word2vec can make highly accurate guesses about a word\u2019s meaning based on its past appearances. Those guesses than can be used to establish a word\u2019s association with other words like man is to boy what woman is to girl.", "Word2vec trains words against other words that neighbor them in the input corpus. It does so in two ways, either using context to predict a target word, or using a word to predict a target context, which is called skip-gram.", "The CBOW approach we have several input words and then our projection is essentially trying to predict what is the highest probability word to show up given the context of those surrounding words. On the other hand the Skip-gram methods take a little longer to train and develop because it\u2019s essentially doing the opposite. Given an input of single word using autoencoder neural network projection trying to output the weighted probabilities of other words that are going to show up around the context of this input word", "We also have to keep in mind that every word is represented by a vector. This means we can use Cosine similarity to measure how similar word vectors are to each other", "So what does a word vector look like? Since spaCy employs 300 dimensions, word vectors are stored as 300-item arrays.", "Note that we would see the same set of values with en_core_web_md and en_core_web_lg,", "This returns a large array. (See the output in GitHub link)", "The best way to expose vector relationships is through the .similarity() method of Doc tokens.", "We know that lion and cat\u2019s have a bit of similarity as they are same part of a bigger family. Also, there is a relationship between cat and pet as cat is mostly kept as a pet in various parts of the world", "We see that we got some correct and understandable results.", "Words that have opposite meaning, but that often appear in the same context may have similar vectors.", "Here we can think that like, love and hate have entirely different meaning but if we use them together in a sentence it makes sense and the model recognizes it.", "It\u2019s sometimes helpful to aggregate 300 dimensions into a Euclidian (L2) norm, computed as the square root of the sum-of-squared-vectors. This is accessible as the .vector_norm token attribute. Other helpful attributes include .has_vector and is_oov or out of vocabulary.", "For example, our 685k vector library may not have the word \u201cnargle\u201d. To test this:", "Indeed we see that \u201cnargle\u201d does not have a vector, so the vector_norm value is zero, and it identifies as out of vocabulary.", "Believe it or not, we can actually calculate new vectors by adding & subtracting related vectors. A famous example suggests", "You can have a look at the entire code in my Github repository provided below.", "In this blog we learnt how to take machine learning even further, and try to extract intended meanings from complex phrases. Some simple examples include:", "However, things get harder with phrases like:", "The way this is done is through complex machine learning algorithms like word2vec. The aim was to create numerical arrays or word embeddings for every word in a large corpus. Each word was assigned its own vector in such a way that words that frequently appear together in the same context are given vectors that are close together. The result is a model that may not know that a \u201clion\u201d is an animal, but does know that \u201clion\u201d is closer in context to \u201ccat\u201d than \u201cdandelion\u201d.", "It is important to note that building useful models takes a long time \u2014 hours or days to train a large corpus \u2014 and that for our purposes it is best to import an existing model rather than take the time to train our own.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2863e7e55417&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2863e7e55417--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@beriaditya20?source=post_page-----2863e7e55417--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@beriaditya20?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Aditya Beri"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6540e5cfbfa9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&user=Aditya+Beri&userId=6540e5cfbfa9&source=post_page-6540e5cfbfa9----2863e7e55417---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm", "anchor_text": "Euclidian (L2) norm"}, {"url": "https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Magic/Nargle", "anchor_text": "nargle"}, {"url": "https://github.com/aditya-beri/Word-Vectors-and-Semantics.git", "anchor_text": "aditya-beri/Word-Vectors-and-SemanticsContribute to aditya-beri/Word-Vectors-and-Semantics development by creating an account on GitHub.github.com"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2863e7e55417---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2863e7e55417---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----2863e7e55417---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/python?source=post_page-----2863e7e55417---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&user=Aditya+Beri&userId=6540e5cfbfa9&source=-----2863e7e55417---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&user=Aditya+Beri&userId=6540e5cfbfa9&source=-----2863e7e55417---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2863e7e55417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2863e7e55417---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2863e7e55417--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2863e7e55417--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2863e7e55417--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2863e7e55417--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2863e7e55417--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@beriaditya20?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@beriaditya20?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aditya Beri"}, {"url": "https://medium.com/@beriaditya20/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "70 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6540e5cfbfa9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&user=Aditya+Beri&userId=6540e5cfbfa9&source=post_page-6540e5cfbfa9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2d44ae701abc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-vectors-and-semantics-2863e7e55417&newsletterV3=6540e5cfbfa9&newsletterV3Id=2d44ae701abc&user=Aditya+Beri&userId=6540e5cfbfa9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}