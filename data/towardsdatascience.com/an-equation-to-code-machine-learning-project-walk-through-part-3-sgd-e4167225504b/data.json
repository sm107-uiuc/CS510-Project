{"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b", "time": 1682996699.601238, "path": "towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b/", "webpage": {"metadata": {"title": "An \u201cEquation-to-Code\u201d Machine Learning Project Walk-Through \u2014 Part 3 SGD | by Xu LIANG | Towards Data Science", "h1": "An \u201cEquation-to-Code\u201d Machine Learning Project Walk-Through \u2014 Part 3 SGD", "description": "In the previous articles, we talk about in linear separable problem in part 1, and non-linear separable problem in part 2. This time we will implement stochastic gradient descent (SGD) based on the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-1-linear-separable-fd0e19ed2d7", "anchor_text": "part 1", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac?source=your_stories_page---------------------------", "anchor_text": "part 2", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2", "paragraph_index": 2}, {"url": "https://gist.github.com/BrambleXu/52b0aaf10987015a078d36c97729dace", "anchor_text": "data", "paragraph_index": 3}, {"url": "https://gist.github.com/BrambleXu/0e00bbd2f11ad7b3fa264c4ea27ea03b", "anchor_text": "code", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2", "paragraph_index": 5}, {"url": "https://gist.github.com/BrambleXu/a64df128d6c0c26143f82f7b6e889983", "anchor_text": "non_linear_data.csv", "paragraph_index": 10}, {"url": "https://www.wikiwand.com/en/Likelihood_function#/Log-likelihood", "anchor_text": "log likelihood", "paragraph_index": 13}, {"url": "https://www.youtube.com/watch?v=SB2vz57eKgc", "anchor_text": "video", "paragraph_index": 13}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2", "paragraph_index": 17}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium", "paragraph_index": 32}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view", "paragraph_index": 32}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu", "paragraph_index": 32}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang", "paragraph_index": 32}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu", "paragraph_index": 32}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/", "paragraph_index": 34}], "all_paragraphs": ["Hi, everyone! This is \u201cEquation-to-Code\u201d walk-through part 3.", "In the previous articles, we talk about in linear separable problem in part 1, and non-linear separable problem in part 2. This time we will implement stochastic gradient descent (SGD) based on the equation.", "Part 3 is self-contained. But I won\u2019t give too much explanation for the duplicate content in part 2. If you find something difficult to understand, I recommend reading part 2 first.", "Here are the data and code.", "The content is structured as follows. * means you can skip this step if you already part 2.", "You can skip this step if you already read part 2", "First, we look at what we have done in part 2.", "After plotting the data, we found a straight line cannot separate X and O. This kind of problem is called the non-linear separable problem, where data is not linearly separable.", "So we introduce polynomial logistic regression, which adds a polynomial term in the linear function.", "We use \u03b8 to represent the parameter. The \u03b8 mark in the left part means the function f(x) has the parameter theta. \u03b8 in the right part means there are two parameters. The last term is the polynomial term, which makes the model generalize for non-linear separable data.", "Notice that we have x1 and x2 two features in the non_linear_data.csv. We pick up x1 to as the polynomial term. So the function should become below form.", "As for the prediction model, we use the sigmoid function. Below is the vector representation.", "We use the z to represent the linear function and pass it to sigmoid function. The sigmoid function will give a probability for each data sample. We have two class in our data, one is 1 and another is 0.", "Alright, we prepared our data, model (sigmoid), and what else do we need? Yes, a goal function. A goal function can guide us on how to update the parameter in the right way. As for the sigmoid (logistic regression), we usually use log likelihood as the goal function. More specifically, we need to calculate the derivative of the log-likelihood function. Here I will directly give the final update equation. (If you are interested in how to get this equation, this video should be helpful)", "A Numpy array-like version might be easy to understand.", "We plot the model line and accuracy line.", "Below is the whole code we left after part 2.", "If you find something difficult to understand, you could read part 2 for a detailed explanation.", "The main reason we use SGD is to avoid local minima.", "The basic idea is updating the parameter by randomly selecting one data in each updating. So the parameter is easier to get out of local minimum.", "This is the gradient descent form. We can see in order to update \u03b8j, we use the whole training data (the \u03a3 part). The code is below.", "But in SGD, we only use one data a time.", "Here k means the data that we randomly selected.", "You can think SGD as this way. In each epoch, both gradient descent and SGD using the whole data set to update the parameter. Gradient descent update parameter with whole ordered data. But the SGD update parameter with one randomly selected data, which can is easier to get out of local minimum.", "The accuracy line. We can see the convergence is faster than gradient descent.", "SGD is good but the computation is not efficient due to updating parameter by one data in each time.", "Using whole data will cause local minima problem (gradient descent), and using one data each time is inefficient. That\u2019s why we use mini-batch gradient descent.", "Unlike SGD, we could update the parameter with several data samples. Here K is an index set which contains m randomly selected data samples.", "We have 20 data samples, and we set the batch sizem as 5.", "Notice that we have to shuffle data in each epoch. The calculate is the same as gradient descent by matrix multiplication. If you are interested, you can find detail explanation see part 1 or part 2.", "The convergence speed is the same with gradient descent. But computation is more efficient.", "In part 3, we talked about how to implement SGD and Mini-Batch Gradient Descent. You can find the whole code below. Leave comments to let me know whether my article is easy to understand. Stay tuned for the final article in this \u201cEquation-to-Code\u201d series about the regularization.", "Check out my other posts on Medium with a categorized view!GitHub: BrambleXuLinkedIn: Xu LiangBlog: BrambleXu", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m an engineer focusing on NLP and Data Science. I write stuff to repay the engineer community. You can find me on linkedin.com/in/xu-liang-99356891/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe4167225504b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4167225504b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bramblexu?source=post_page-----e4167225504b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4----e4167225504b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-1-linear-separable-fd0e19ed2d7", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac?source=your_stories_page---------------------------", "anchor_text": "part 2"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2"}, {"url": "https://gist.github.com/BrambleXu/52b0aaf10987015a078d36c97729dace", "anchor_text": "data"}, {"url": "https://gist.github.com/BrambleXu/0e00bbd2f11ad7b3fa264c4ea27ea03b", "anchor_text": "code"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2"}, {"url": "https://gist.github.com/BrambleXu/a64df128d6c0c26143f82f7b6e889983", "anchor_text": "non_linear_data.csv"}, {"url": "https://gist.github.com/BrambleXu/a64df128d6c0c26143f82f7b6e889983", "anchor_text": "non_linear_data.csv"}, {"url": "https://www.wikiwand.com/en/Likelihood_function#/Log-likelihood", "anchor_text": "log likelihood"}, {"url": "https://www.youtube.com/watch?v=SB2vz57eKgc", "anchor_text": "video"}, {"url": "https://towardsdatascience.com/an-equation-to-code-machine-learning-project-walk-through-in-python-part-2-non-linear-d193c3c23bac", "anchor_text": "part 2"}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium"}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view"}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu"}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang"}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e4167225504b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----e4167225504b---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e4167225504b---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----e4167225504b---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/python-programming?source=post_page-----e4167225504b---------------python_programming-----------------", "anchor_text": "Python Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&user=Xu+LIANG&userId=ee86e6752cb4&source=-----e4167225504b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&user=Xu+LIANG&userId=ee86e6752cb4&source=-----e4167225504b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e4167225504b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe4167225504b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e4167225504b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e4167225504b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e4167225504b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e4167225504b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e4167225504b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e4167225504b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/@bramblexu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd5c245665a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-equation-to-code-machine-learning-project-walk-through-part-3-sgd-e4167225504b&newsletterV3=ee86e6752cb4&newsletterV3Id=d5c245665a2&user=Xu+LIANG&userId=ee86e6752cb4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}