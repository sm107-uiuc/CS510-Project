{"url": "https://towardsdatascience.com/building-a-bot-that-plays-videos-for-my-toddler-597330d0005e", "time": 1682993167.261909, "path": "towardsdatascience.com/building-a-bot-that-plays-videos-for-my-toddler-597330d0005e/", "webpage": {"metadata": {"title": "Building a Bot That Plays Videos for My Toddler | by Agustinus Nalwan | Towards Data Science", "h1": "Building a Bot That Plays Videos for My Toddler", "description": "My wife and I have a super curious 21-month-old boy name Dexie. Although he does not fully speak yet, he really loves pointing at things asking us to tell him what they are. It can be a picture of an\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "SSDLiteMobileNetV2", "paragraph_index": 8}, {"url": "https://github.com/tensorflow/models/tree/master/research/object_detection", "anchor_text": "object detection", "paragraph_index": 8}, {"url": "https://aws.amazon.com/rekognition/", "anchor_text": "Amazon Rekognition", "paragraph_index": 9}, {"url": "https://github.com/Ericsson/eva", "anchor_text": "EVA", "paragraph_index": 11}, {"url": "https://aws.amazon.com/machine-learning/amis", "anchor_text": "AWS EC2 Deep Learning AMI", "paragraph_index": 12}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "Object Detection blog", "paragraph_index": 12}, {"url": "https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit", "anchor_text": "here", "paragraph_index": 13}, {"url": "https://github.com/msubzero2000/Qrio-public/blob/master/misc/objectDetectionOnJetsonNano.py", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://cseweb.ucsd.edu/classes/sp16/cse169-a/readings/2-Skeleton.html", "anchor_text": "blog", "paragraph_index": 20}, {"url": "https://www.tutorialspoint.com/computer_graphics/computer_animation.htm", "anchor_text": "keyframe animation", "paragraph_index": 22}, {"url": "https://pypi.org/project/pyttsx3/", "anchor_text": "pyttsx3", "paragraph_index": 25}, {"url": "https://aws.amazon.com/polly/", "anchor_text": "Amazon Polly", "paragraph_index": 26}, {"url": "https://pypi.org/project/selenium/", "anchor_text": "python binding", "paragraph_index": 30}, {"url": "https://github.com/msubzero2000/Qrio-public/blob/master/misc/browserServiceJetson.py", "anchor_text": "here", "paragraph_index": 31}, {"url": "https://nvidianews.nvidia.com/news/nvidia-announces-jetson-xavier-nx-worlds-smallest-supercomputer-for-ai-at-the-edge", "anchor_text": "NVIDIA Jetson NX", "paragraph_index": 47}, {"url": "https://github.com/msubzero2000/Qrio-public/tree/master/qrio", "anchor_text": "here", "paragraph_index": 49}, {"url": "https://www.linkedin.com/in/agustinus-nalwan", "anchor_text": "https://www.linkedin.com/in/agustinus-nalwan", "paragraph_index": 51}], "all_paragraphs": ["My wife and I have a super curious 21-month-old boy name Dexie. Although he does not fully speak yet, he really loves pointing at things asking us to tell him what they are. It can be a picture of an animal in his favourite book, a picture of a car on his flash card or just a toy. I enjoy doing this activity with him, and recently I have been showing him videos that depict tigers, dolphins, trains and other interesting things. He really loves seeing how an actual tiger walks, roars and socialises, which I think is good for his cognitive development.", "One day, I came up with the idea of building him a bot that can play this pointing game with him. Don\u2019t get me wrong, the aim wasn\u2019t to replace us but to complement us and to expose him to technology as early as possible.", "After a bit of a brainstorming session \u2026 with myself, I knew exactly what I wanted to build. It was to be a chat bot with the appearance of a dog, which is Dexie\u2019s favourite animal. Her name was to be Qrio, a blend of the two words question and curiosity. In my one and a half years of buying toys for him and observing which ones he keeps playing with and which ones he doesn\u2019t, I found out that the more closely the toy is able to mimic a living thing (a dog in this case) with which he can bond, the higher the chance for it to be successful.", "With the aim of maximising the bonding factor, Qrio is modelled after our late dog Pepsi, with whom Dexie had built a relationship in his first year.", "Qrio will be able to see Dexie walking by and say to him, \u2018Hi, Dexie! Do you want to come and show me your toy?\u2019 Next, when Dexie picks up and shows her an airplane toy, she will continue with \u2018Hey, that is an airplane. Let me play you a video about an airplane,\u2019 and then look for an airplane video for him to play.", "In order to achieve the above, Qrio needs to have the following modules:", "After some serious research, I came up with a list of the hardware required to run the system.", "With a solid plan in hand, I began to fulfil my mission.", "First, an object detection component needed to be developed and trained to identify specific human faces and toys. Bear in mind that the NVIDIA Jetson Nano\u2019s GPU is way less powerful than a desktop class GPU card like 1080Ti, so choosing an object detection model architecture which has a good balance between accuracy and performance is crucial. First, I decided the minimum rate of frames per second (FPS) I can live with. I then worked backwards and searched for the model that can deliver such FPS on a Jetson Nano. I chose 8 FPS which, in practice, will go down to about 5 FPS when it has video processing, text to speech, virtual puppetry rendering and so forth running simultaneously. Having less than 5 detections per second would significantly decrease the chance of achieving a good quality capture in which Dexie\u2019s face and his toy are clearly visible. The winning model architecture was SSDLiteMobileNetV2, which runs on TensorFlow 1.8 object detection API.", "I trained the model using just four classes: a human face and three of Dexie\u2019s toys (airplane, train and panda). All the training set images (150 images per class) had been generated from video files recorded using the same Sony IMX219 camera. In order to maximise detection accuracy and make sure that the lighting and the background were consistent, they were taken in the same living room where I will run the system. The three toys were manually and painstakingly labelled from the videos. However, to save my sanity, I used Amazon Rekognition, an off-the-shelf object detection cloud service to automatically label all faces.", "The video recording was done using GStreamer, which is easily done by executing the command below. Recording with a low FPS causes a significant motion blur in the final video and yields a low-quality training set. Hence, I set the recording frame rate to be 120 FPS and down sampled them later using a video editing tool. The recording dimension was set to 720x540, which was more than enough as our object detection model only runs on 300x300 pixels with any larger image to be automatically resized to 300x300 pixels during training and inference.", "I used EVA, a great and free object detection labelling tool which you can install locally and can import a video file as an image source.", "The training was completed in five hours, using AWS EC2 Deep Learning AMI running on P3.2XLarge (Pascal V100) which achieves mAP=0.8. Mean Average Precision (mAP) is a metric used to evaluate the performance of an object detection by calculating an area under the curve of precision/recall which are averaged over various iOU threshold. It takes an entire blog posting to explain this properly, so I will simply refer you to mAP for Object Detection blog to read. Otherwise, you\u2019ll just have to trust me that an mAP of 0.8 is very good, and it can still be further improved by aggregating detection from several frames.", "Deploying and running this model on NVIDIA Jetson Nano is pretty straightforward once you have flashed the device (follow the steps here), as it is running a fully functional Ubuntu 18.04. What I mean is you can install Tensorflow, Object Detection API and all the Python dependencies just as you would on your laptop or PC. I used Tensorflow 1.8 because at the time this blog was written, object detection API was not supported in Tensorflow 2.0 due to missing a contrib dependency.", "GStreamer and OpenCV framework were used to connect to and obtain the video feed from the camera. From there, we simply needed to pass the captured image directly to our Object Detection model. See the self-explanatory code sample here.", "I managed to get the object detection running at 10 FPS, which was more than my minimum requirement of 8 FPS \u2014 and with a pretty good detection accuracy!", "It is critical to get the visual presence component right. Qrio must be attractive and, more importantly, look enough like a real, living dog for Dexie to want to play with her. Her eyes need to be able to look directly at Dexie\u2019s face, wherever he is. And like a normal dog, she needs fidget by wagging her tail, moving her head around and looking in random directions when she is not interacting with Dexie. I feel so grateful that I learned such valuable skills in my good five years as a 3D animation programmer working at a movie special effects company that specialised in facial animation and virtual puppetry. All I needed now was a game engine!", "A few hours of digging led me to this awesome Python framework called arcade which had everything I needed. Well\u2026 almost, I will get to this later. It supports a game animation loop and is able to render/display a sprite (PNG image with transparency) with rotation and scaling. Since this framework is based on OpenGL, the speed performance on NVIDIA Jetson Nano should be excellent as it will be GPU accelerated.", "In order for individual parts of Qrio\u2019s body (ears, eyeballs, eyebrows, head and tail) to move both independently and as a group, separate sprites needed to be assembled (e.g. moving the head will also move the ears, eyebrows and eyeballs). I needed to build a skeletal animation system (SAS) which allows you to join several objects together in a hierarchical relationship (e.g. the head is a child to the body while the ears, eyes and eyebrows are children to the head). Thus, when you apply a transformation (rotation, translation or scale) to an object, it will also affect all of its children.", "Most game characters, humans, animals, monsters like the one in the animation below are built using an SAS.", "Most game engines support SAS natively; however, Arcade does not. Since I couldn\u2019t find an alternative framework, I decided to implement the SAS capability from scratch, which is actually not that hard. The first thing I needed to do was to build a tree data structure which stores all the sprites (ear, head, eyebrows, etc.) and connects their joints according to their relationships. Next was to build an SAS hierarchical transformation function. This involved a little bit of trigonometry and matrices. If you are keen to know the mathematical details, you can read them in this blog.", "Qrio\u2019s SAS is demonstrated in the image below. The first image shows how sprites are used to define each of the body parts, which are assembled hierarchically as shown in the next image. Each body part will also have a joint defined to be the centre of rotation. The rightmost image shows transformation (rotation) being applied to the right ear around its joint, and no other body parts are affected since the right ear does not have any children. The bottom image depicts rotation being applied to the head around its joint, and it affects the eyebrows, eyeballs and ears. Note the marking showing that the right ear is also rotated accordingly around the head joint.", "In order to complete the visual presence module, the next thing I needed to build was a fidget animation system which is based on a simple keyframe animation. A keyframe animation lets you animate an object such as a head by supplying its initial and final transform (position, scale and rotation) and the duration of the animation. The system interpolates the transform from the initial to the final value. Next, I defined a few fidget animations such as the up-and-down movement of the ears, rotation of the head and tail, and movement of the eyeballs and eyebrows. Each fidget animates the respective objects from one transform to the next with its value (rotation/translation), duration and frequency picked randomly so as to look more natural.", "I spent a couple of hours tweaking the fidget animation parameters to finally get the result I wanted.", "Lastly, I added a way to overwrite the eyeballs and eyebrows\u2019 position on demand by manually supplying their position which is needed for the head tracking logic to follow where Dexie\u2019s face is at a later stage.", "With her sight and her visual presence module completed, what she needed next was speech capability. The best free offline text to speech application I could find with a good couple of hours research was pyttsx3. The engine supports a few drivers but the only one available on Ubuntu is espeak and it has the most horrendous voice quality. It sounds like the late Stephen Hawking\u2019s wheelchair (with no intent to disrespect). Dexie is currently at the stage where he repeats every single thing we say, and the last thing I want is for him to learn to speak like that. Check out the below and be your own judge.", "After giving up on an offline offering, I started to look for an online counterpart. I landed on Amazon Polly. After a few minutes of playing with it I was totally sold. The voice quality is 100 times better and there is no noticeable delay, even though it needs to make an API call via the internet to generate and download the resulting audio file from the cloud. This was initially was my main concern. It only takes 200ms to generate seven seconds of audio file. I know this is not a free solution. However, it can be heavily cached given that Qrio will only need to utter 50 different sentences at most, and we will only ever need to pay for 50 Amazon Polly calls (0.08 cents). Yay!!!", "Building the Video Search and Play", "As we discussed previously, Qrio needs to be able to search for and play a specific video on YouTube. The best way to do this is by using an automation test suite, which can control a web browser to perform a search in YouTube and to play the video from the search result. Here Selenium automation framework comes to the rescue!", "It is a tool which is normally used by a QA to test a website. It allows you to write scripts that automate things such as typing into a text field, pressing a button, etc. As you can guess, I will be using it to navigate to a YouTube site, entering a search term like panda and then automatically clicking on the first video in the search result and pressing the full screen button to play it full screen. First, you need to install a chromium-chromedriver for Selenium to be able to control the Chromium web browser (the native browser that comes with Ubuntu 18.04) by executing the apt-get install command below.", "You can then programmatically execute the Selenium script from your Python code using python binding for Selenium.In order to make sure that the video played is kid safe, I use YouTubeKids.com instead of the normal YouTube. This introduces a slight complication, as it does have a series of steps you have to go through to prove that you are a parent every time Selenium starts. However, I managed to write a Selenium script which automatically completes these steps and it just needs to be executed once.", "You can see the code here.", "This module serves as a coordinator which glues all other modules together. One critical part of the coordinator is a state machine which keeps track of the current state of the game. Why do we need a state machine? So that we can make different decisions upon receiving the same event, depending on which state we are in at the moment. For example, seeing an airplane toy by itself should not trigger a call to play the YouTube video if previously Qrio has not yet seen Dexie, as it may be a situation where the toy plane was just there on the couch. Seeing an airplane toy after playing an airplane video should make Qrio say \u2018Hey, we have played with an airplane before. Why don\u2019t you bring me something else?\u2019 That way, we avoid having Qrio play the same video again and again if Dexie continues to hold the plane after it was previously recognised and video playback had been triggered.", "There are four major states \u2014 Idle, Engaged, ObectRecognised and PlayingVideo \u2014 as you can see in the state diagram below. When the system is in any state except PlayingVideo, it periodically calls Fidget Animation System to animate Qrio fidgeting and checks with the sight module to get the location of all recognisable objects. The system starts from an Idle state and if Dexie is detected for at least 0.5 seconds (to minimise false detection), it will call the speech module to say something like \u2018Hi Dexie, do you want to come and play?\u2019 and set the game state to an Engaged state.", "Furthermore, if a panda toy is visible while we are in Engaged mode, Qrio will say \u2018Hi Dexie. I think that is a panda,\u2019 and will enter ObjectRecognised mode. If the panda toy still remains visible for another two seconds, Qrio will switch into PlayingVideo state, will say \u2018Let me play you a video about a panda,\u2019 and will call the Video Search and Play module to search for a panda video and play it. However, if we have just recently played a video about a panda, instead it will say \u2018Hey, we have played with a panda before. Why don\u2019t you bring me something else? The video will only play full screen for 45 seconds while the sight and fidget animation system are paused to focus the CPU resources on playing a smooth video. When the video playback is completed, the browser window is hidden, and the sight and fidget animation systems are resumed. When Dexie is not visible for 10 seconds while in engaged mode, Coordinator will reset the state to Idle.", "You can also see that there is a call to the Head Tracking module in any state except PlayingVideo when a face is visible in order to make Qrio\u2019s eyeballs follow the centre point of the face bounding box.", "With everything ready to go, I set up the system in the living room for a final calibration and testing.", "At initialisation, the system goes through and passes the YouTubeKids parent authorisation without any issue. I saw Qrio\u2019s eyes following my face swiftly wherever it goes, a sign that the object detection and the head tracking logic work very well. I noticed NVIDIA Jetson Nano has been pushed to the limit, with the RAM running super low and the device becoming very hot. It is totally understandable given that it is running a heavy-duty AI model on the fly and still needs to render the game engine in real-time, controlling the Selenium browser and decoding videos. However, the whole system seemed to function pretty well with the game engine showing the benchmark of 5 FPS.", "All I need now is to find the right time to show Qrio to Dexie!", "It was a priceless moment watching Dexie when he saw Qrio for the first time. He rushed towards her curiously while Qrio was calling him and he stood still, just staring at her for a few seconds in disbelief. Suddenly, he burst into giggles and laughs\u2026 I just knew that I had passed the first test with flying colours \u2014 a successful bonding between boy and bot!", "In the interest of making make him more familiar and comfortable, I let him do whatever he wanted without any guidance. He walked towards her, watched her fidgeting, touched the TV (thinking that he is actually touching her) and even called her \u2018Doggie\u2019.", "Then came the moment of truth \u2014 to test the actual game play. As an example, I let him watch me show Qrio his airplane toy which she flawlessly recognised it and said, \u2018Hey, I think it is an airplane. Let me play you a video about an airplane\u2019. Dexie was super excited when he saw the airplane video start playing!", "Once the video playback is finished, I passed a panda toy to Dexie. Copying me, he showed the panda toy to Qrio, and she again searched for and played an appropriate video! You can watch that whole experience on the video below.", "The system is not perfect yet. Although it manages to recognise toys and to play the right video about 80% of the time, it still fails from time to time \u2014 which is fine. The most important thing is that I have learned a lot about what works and what doesn\u2019t work for the next time a similar project comes around.", "Most of the failures happens when Dexie is standing too close to the TV, which is outside the camera visibility range. As seen in the photo below, the camera has a 77-degree FOV and is positioned to cover a medium-to-close distance from the TV \u2014 but not very close (area marked in red circle). The same problem happens with the vertical coverage where the camera cannot see a toy he is holding very low while sitting on the floor. Lowering the focus of the camera would solve this but would introduce the opposite problem of not being able to see his face when he is standing and close to the camera.", "The solution to this may be to get a new camera with a wider (120-degree) FOV so that it can cover more areas. However, the accuracy of the detection around the edge of the FOV might drop due to lens distortion.", "So far Qrio sight module has only been trained with three toys and always plays the same video for the same toy. This is only enough to entertain Dexie for five minutes until he gets bored. Hence, it has a low replayability factor. I plan to add support for more toys in the future \u2014 if I can muster the courage to manually label thousands of additional images. A randomisation could also be added to pick randomly from the top five videos found, rather than always picking the first one.", "Another area for improvement is the game\u2019s FPS. The game runs at around 5 FPS with occasional short freezes and longer ones when the Video Search and Play module executes Selenium scripts to control the chromium browser. You have probably already spotted this in the demo video above. A frozen game engine means Qrio stops moving, which is not that pleasant to watch. An idea would be to move the object detection into a separate thread so that it can run concurrently and not block the game engine. The same treatment might also be applied to the video search and play module. However, we need to test whether OpenCV and Selenium are happy to run on a separate thread. Aside from that, I would also like to test a more powerful device such as NVIDIA Jetson NX which would probably be more appropriate for a project of this scale.", "That\u2019s it, folks! I hope you have enjoyed reading about my exciting weekend project as much as I have enjoyed sharing it with you.", "The full source code is available here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "The AI guy Connect with me on https://www.linkedin.com/in/agustinus-nalwan"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F597330d0005e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://agustinus-nalwan.medium.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": ""}, {"url": "https://agustinus-nalwan.medium.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Agustinus Nalwan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b7ab157b0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&user=Agustinus+Nalwan&userId=8b7ab157b0a4&source=post_page-8b7ab157b0a4----597330d0005e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "SSDLiteMobileNetV2"}, {"url": "https://github.com/tensorflow/models/tree/master/research/object_detection", "anchor_text": "object detection"}, {"url": "https://aws.amazon.com/rekognition/", "anchor_text": "Amazon Rekognition"}, {"url": "https://github.com/Ericsson/eva", "anchor_text": "EVA"}, {"url": "https://aws.amazon.com/machine-learning/amis", "anchor_text": "AWS EC2 Deep Learning AMI"}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "Object Detection blog"}, {"url": "https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit", "anchor_text": "here"}, {"url": "https://github.com/msubzero2000/Qrio-public/blob/master/misc/objectDetectionOnJetsonNano.py", "anchor_text": "here"}, {"url": "https://cseweb.ucsd.edu/classes/sp16/cse169-a/readings/2-Skeleton.html", "anchor_text": "blog"}, {"url": "https://www.tutorialspoint.com/computer_graphics/computer_animation.htm", "anchor_text": "keyframe animation"}, {"url": "https://pypi.org/project/pyttsx3/", "anchor_text": "pyttsx3"}, {"url": "https://aws.amazon.com/polly/", "anchor_text": "Amazon Polly"}, {"url": "https://pypi.org/project/selenium/", "anchor_text": "python binding"}, {"url": "https://github.com/msubzero2000/Qrio-public/blob/master/misc/browserServiceJetson.py", "anchor_text": "here"}, {"url": "https://nvidianews.nvidia.com/news/nvidia-announces-jetson-xavier-nx-worlds-smallest-supercomputer-for-ai-at-the-edge", "anchor_text": "NVIDIA Jetson NX"}, {"url": "https://github.com/msubzero2000/Qrio-public/tree/master/qrio", "anchor_text": "here"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----597330d0005e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/object-detection?source=post_page-----597330d0005e---------------object_detection-----------------", "anchor_text": "Object Detection"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----597330d0005e---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/iot?source=post_page-----597330d0005e---------------iot-----------------", "anchor_text": "IoT"}, {"url": "https://medium.com/tag/chatbots?source=post_page-----597330d0005e---------------chatbots-----------------", "anchor_text": "Chatbots"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&user=Agustinus+Nalwan&userId=8b7ab157b0a4&source=-----597330d0005e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&user=Agustinus+Nalwan&userId=8b7ab157b0a4&source=-----597330d0005e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F597330d0005e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----597330d0005e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----597330d0005e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----597330d0005e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----597330d0005e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----597330d0005e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----597330d0005e--------------------------------", "anchor_text": ""}, {"url": "https://agustinus-nalwan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://agustinus-nalwan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Agustinus Nalwan"}, {"url": "https://agustinus-nalwan.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "298 Followers"}, {"url": "https://www.linkedin.com/in/agustinus-nalwan", "anchor_text": "https://www.linkedin.com/in/agustinus-nalwan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8b7ab157b0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&user=Agustinus+Nalwan&userId=8b7ab157b0a4&source=post_page-8b7ab157b0a4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe9a25b6d319d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-bot-that-plays-videos-for-my-toddler-597330d0005e&newsletterV3=8b7ab157b0a4&newsletterV3Id=e9a25b6d319d&user=Agustinus+Nalwan&userId=8b7ab157b0a4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}