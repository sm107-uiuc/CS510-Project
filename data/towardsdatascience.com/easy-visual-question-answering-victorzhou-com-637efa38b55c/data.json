{"url": "https://towardsdatascience.com/easy-visual-question-answering-victorzhou-com-637efa38b55c", "time": 1683003751.4218209, "path": "towardsdatascience.com/easy-visual-question-answering-victorzhou-com-637efa38b55c/", "webpage": {"metadata": {"title": "Easy Visual Question Answering. A gentle introduction to Visual\u2026 | by Victor Zhou | Towards Data Science", "h1": "Easy Visual Question Answering", "description": "Now imagine you\u2019re a computer. You\u2019re given that same image and the text \u201c what sport is depicted in this image? \u201c and asked to produce the answer. Not so easy anymore, is it? This problem is known\u2026"}, "outgoing_paragraph_urls": [{"url": "https://easy-vqa-demo.victorzhou.com", "anchor_text": "demo", "paragraph_index": 4}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "introduction to CNNs", "paragraph_index": 5}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 6}, {"url": "https://victorzhou.com/blog/keras-neural-network-tutorial/", "anchor_text": "introduction to Neural Networks with Keras", "paragraph_index": 6}, {"url": "https://victorzhou.com/blog/easy-vqa/#8-the-results", "anchor_text": "The Results", "paragraph_index": 8}, {"url": "https://victorzhou.com/blog/easy-vqa/", "anchor_text": "victorzhou.com", "paragraph_index": 9}, {"url": "https://visualqa.org", "anchor_text": "visualqa.org", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1505.00468.pdf", "anchor_text": "VQA paper", "paragraph_index": 10}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA", "paragraph_index": 11}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA", "paragraph_index": 16}, {"url": "https://victorzhou.com/tag/computer-vision/", "anchor_text": "Computer Vision", "paragraph_index": 17}, {"url": "https://victorzhou.com/tag/natural-language-processing/", "anchor_text": "Natural Language Processing", "paragraph_index": 17}, {"url": "https://github.com/vzhou842/easy-VQA-keras", "anchor_text": "easy-VQA-keras", "paragraph_index": 20}, {"url": "https://pypi.org/project/tensorflow/", "anchor_text": "tensorflow", "paragraph_index": 22}, {"url": "https://pypi.org/project/Pillow/", "anchor_text": "Pillow", "paragraph_index": 22}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-vqa", "paragraph_index": 22}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "Convolutional Neural Network", "paragraph_index": 23}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 23}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/", "anchor_text": "a guide on using Keras to implement CNNs", "paragraph_index": 23}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "intro to CNNs", "paragraph_index": 25}, {"url": "https://keras.io/models/model/", "anchor_text": "Model", "paragraph_index": 26}, {"url": "https://keras.io/models/sequential/", "anchor_text": "Sequential", "paragraph_index": 26}, {"url": "https://victorzhou.com/blog/intro-to-rnns/", "anchor_text": "Recurrent Neural Network", "paragraph_index": 27}, {"url": "https://victorzhou.com/blog/bag-of-words/", "anchor_text": "short, beginner-friendly introduction to Bag-of-Words models", "paragraph_index": 30}, {"url": "https://keras.io/preprocessing/text/#tokenizer", "anchor_text": "Tokenizer", "paragraph_index": 31}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-vqa documentation", "paragraph_index": 32}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/", "anchor_text": "intro to Neural Networks", "paragraph_index": 34}, {"url": "https://keras.io/layers/merge/#multiply", "anchor_text": "Multiply merge layer", "paragraph_index": 37}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/#4-training-a-neural-network-part-2", "anchor_text": "propagating gradients through its layers", "paragraph_index": 41}, {"url": "https://keras.io/layers/merge/", "anchor_text": "Merge Layers", "paragraph_index": 42}, {"url": "https://victorzhou.com/blog/softmax", "anchor_text": "Softmax", "paragraph_index": 44}, {"url": "https://victorzhou.com/blog/softmax", "anchor_text": "explanation of Softmax", "paragraph_index": 44}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/#52-cross-entropy-loss", "anchor_text": "Cross-Entropy Loss", "paragraph_index": 47}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA", "paragraph_index": 48}, {"url": "https://keras.io/utils/#to_categorical", "anchor_text": "to_categorical", "paragraph_index": 52}, {"url": "https://en.wikipedia.org/wiki/One-hot", "anchor_text": "one-hot", "paragraph_index": 52}, {"url": "https://keras.io/callbacks/#modelcheckpoint", "anchor_text": "ModelCheckpoint", "paragraph_index": 53}, {"url": "https://github.com/vzhou842/easy-VQA-keras", "anchor_text": "find it here on Github", "paragraph_index": 54}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/#8-extensions", "anchor_text": "Extensions", "paragraph_index": 57}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/", "anchor_text": "introduction to CNNs with Keras", "paragraph_index": 57}, {"url": "https://easy-vqa-demo.victorzhou.com/", "anchor_text": "easy-VQA demo", "paragraph_index": 57}, {"url": "https://phillipkwang.com/", "anchor_text": "Phillip Wang", "paragraph_index": 59}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com", "paragraph_index": 61}], "all_paragraphs": ["Quick \u2014 what sport is depicted in this image?", "You probably immediately knew the answer: baseball. Easy, right?", "Now imagine you\u2019re a computer. You\u2019re given that same image and the text \u201c what sport is depicted in this image? \u201c and asked to produce the answer. Not so easy anymore, is it?", "This problem is known as Visual Question Answering (VQA): answering open-ended questions about images. VQA is interesting because it requires combining visual and language understanding. A model that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image.", "This might seem like a pretty unapproachable problem at first, but in reality it\u2019s probably more accessible than you think. In this post, we\u2019ll explore basic methods for performing VQA and build our own simple implementation in Python. Here\u2019s a demo of the final product of this post:", "Caveat: this post assumes a basic knowledge of Convolutional Neural Networks (CNNs). My introduction to CNNs covers everything you need to know, so start there if necessary.", "We\u2019ll also be using Keras, a deep learning library for Python, to power our model, so I recommend reviewing my introduction to Neural Networks with Keras if you\u2019ve never seen Keras code before.", "Enough of this preface. Let\u2019s get started!", "Just looking for the source code / results? Skip to The Results.", "This post is best viewed on victorzhou.com", "The best known dataset for VQA can be found at visualqa.org and contains 200k+ images and over a million questions (with answers) about those images. Here are a few examples from the original VQA paper:", "Impressive, right? Unfortunately, this level of VQA is outside of the scope of this blog post. We\u2019ll instead be using a custom dataset created just for this blog post: easy-VQA.", "The images in the easy-VQA dataset are much simpler:", "The questions are also much simpler:", "In total, easy-VQA contains 5k images and ~50k questions, split into training (80%) and testing (20%) sets. The questions have 13 possible answers:", "The standard approach to performing VQA looks something like this:", "Notice that we\u2019re working with a fixed answer set where exactly one of the possible answers is guaranteed to be correct. This makes our lives a lot easier because we don\u2019t have to generate the correct answer, we just have to answer what is effectively a multiple-choice question. Most cutting-edge VQA systems out there have 1000 possible answers, but for this post we\u2019ll only allow the 13 possible answers included in easy-VQA.", "Steps 1 and 2 generally use methods from Computer Vision and Natural Language Processing, respectively, to turn raw image / text inputs into processed data vectors. These two output representations can then be used analyzed together to ultimately pick the most likely answer.", "Here\u2019s a very simple example of how a VQA system might answer the question \u201cwhat color is the triangle?\u201d about the image in the visualization above:", "In the following sections, we\u2019ll walk through the specifics of implementing each of these 4 steps for our easy-VQA dataset.", "If you want to follow along with this post without starting from scratch, clone the easy-VQA-keras repo:", "Otherwise, if you do want to setup from scratch, make sure you\u2019re using Python 3 and install a few packages:", "We need tensorflow to power Keras, and we\u2019ll use Pillow for image processing. We\u2019ll also be using the easy-vqa Python package, which makes it simple to access the easy-VQA dataset. More on that later \u2014 for now, let\u2019s get started.", "First up: our image model. As we\u2019ve previously mentioned, we\u2019ll build a Convolutional Neural Network (CNN) to extract information from the image input. To do this, we\u2019ll use Keras, a beginner-friendly but powerful deep learning library for Python. I\u2019ve already written a guide on using Keras to implement CNNs \u2014 it might help to open it in a new tab or skim it before continuing.", "Our image dataset is not very complex, so we can tackle it with a relatively simple CNN:", "Confused? All of the concepts above are covered in my intro to CNNs.", "This code uses Keras\u2019s Model (functional) API. We\u2019re not using Keras\u2019s Sequential model API because we\u2019ll need to combine our image model and our question model later (you\u2019ll see, keep reading).", "Next up: our question model. Most VQA models would use some kind of Recurrent Neural Network (RNN) to process the question input, but that\u2019s a little overkill for our use case. The questions in the easy-VQA dataset are short, simple, and come from a fixed set of question templates, so they\u2019re much more approachable compared to those you might see in the real world.", "Instead of a complicated RNN architecture, we\u2019ll take a simpler approach:", "Don\u2019t worry if you don\u2019t entirely understand what that meant. We\u2019ll go through both of those steps below.", "A BOW representation turns any text string into a fixed-length vector by counting how many times each word appears in the text. I\u2019ve written a short, beginner-friendly introduction to Bag-of-Words models \u2014 I\u2019d recommend reading that now if you\u2019re unfamiliar with them! From here on, I\u2019m assuming you have a basic understanding of BOW models.", "We\u2019ll take advantage of Keras\u2019s Tokenizer class to implement BOW:", "Notice that we read question data from the easy-vqa package. If you want to see the details on those APIs, refer to the easy-vqa documentation.", "As discussed before, our question dataset is relatively simple, so we don\u2019t need anything too fancy for our question model. We\u2019ll just pass our BOW vector representation into 2 fully-connected (FC) neural network layers:", "Reminder: fully-connected layers have every node connected to every output from the previous layer. We used fully-connected layers in my intro to Neural Networks if you need a refresher.", "Here\u2019s our implementation, which also uses Keras\u2019s Model (functional) API:", "The vocab_size variable is the length of our BOW vector representations, which are the inputs to our question model.", "We\u2019ll use a very simple method to merge our image and question vectors: element-wise multiplication. Implementing this is a one-liner with Keras\u2019s Multiply merge layer:", "The out vector now contains information derived from both the image and the question.", "To illustrate how this might be useful, consider this (somewhat contrived) example:", "Then the first element in the out vector will only be high when both the image and the question are related to the color blue. This result would be very useful in answering a question like \"Is there a blue shape in the image?\"", "In reality, it\u2019s unlikely that our model learns exactly this kind of behavior. Remember that the model learns by propagating gradients through its layers, and that\u2019s unlikely to produce a result so simple. Instead, focus on the intuition that:", "Practically, we could\u2019ve used any differentiable method of merging the two vectors. Other merge methods listed under Keras\u2019s Merge Layers section include Add, Subtract, Concatenate, and Average, all of which do what you think they do. Most of these would probably work just as well as Multiply for our simple dataset - feel free to try them out on your own!", "Finally, it\u2019s time for our VQA system to produce an answer. Recall that we\u2019re working with a fixed answer set: we know all possible answers and exactly one is guaranteed to be correct.", "For this step, we\u2019ll use Softmax to turn our output values into probabilities so we can quantify how sure we are about each possible answer. If you\u2019re unfamiliar with Softmax, I highly recommend reading my explanation of Softmax before continuing.", "First, we\u2019ll throw in one fully-connected layer for good measure, then use Keras\u2019s built-in Softmax implementation:", "That\u2019s it! All that\u2019s left is to build and compile the model:", "If you need a refresher, I explained Cross-Entropy Loss in my CNNs series.", "Now that we\u2019ve got our model figured out, we just need a bit more code to get all our data ready. For this section, I recommend opening the easy-VQA documentation in a separate tab for reference. I\u2019ll leave out explanations of methods we use from easy-vqa for brevity.", "First, we\u2019ll just pull some data from easy-vqa:", "Next, we\u2019ll read and pre-process our images:", "Then, we\u2019ll create the actual inputs and expected outputs we\u2019ll use to train our model:", "Keras\u2019s to_categorical is a handy method to make one-hot vectors out of indices. We need one-hot vectors to match the dimensions of our output Softmax layer.", "As an optional step, we\u2019ll setup a Keras ModelCheckpoint to save our best models after every epoch:", "I won\u2019t include the full code in this post itself to save space, but you can find it here on Github. Copy and paste these lines into your terminal to train the model yourself:", "Running the code gives us results like this:", "Not bad at all for 8 epochs on such a simple model:", "If you want, you can experiment on your own with the code to achieve even better results. The Extensions section of my introduction to CNNs with Keras is a good starting point. Given the relative simplicity of this problem, you should be able to pass 99% validation accuracy pretty easily. For reference: the official easy-VQA demo uses a model that achieved 99.5% validation accuracy with only slightly different parameters.", "You\u2019ve now implemented a working VQA model! This post was just a gentle introduction, though. There\u2019s much more you can do:", "Note: this post used first person (\u201cI\u201d, \u201cmy\u201d) to read like it\u2019s me (Victor Zhou) talking. However, as indicated at the very top, this post was co-authored by my good friend Phillip Wang, a recent CS grad from CMU who\u2019s done his fair share of ML. Thanks Phillip!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CS @ Princeton University. I write about web development, machine learning, and more at https://victorzhou.com."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F637efa38b55c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://victorczhou.medium.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab----637efa38b55c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://easy-vqa-demo.victorzhou.com", "anchor_text": "demo"}, {"url": "https://easy-vqa-demo.victorzhou.com", "anchor_text": "easy-VQA DemoA Javascript demo of a Visual Question Answering model trained on the easy-VQA dataset.easy-vqa-demo.victorzhou.com"}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "introduction to CNNs"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://victorzhou.com/blog/keras-neural-network-tutorial/", "anchor_text": "introduction to Neural Networks with Keras"}, {"url": "https://victorzhou.com/blog/easy-vqa/#8-the-results", "anchor_text": "The Results"}, {"url": "https://victorzhou.com/blog/easy-vqa/", "anchor_text": "victorzhou.com"}, {"url": "https://visualqa.org", "anchor_text": "visualqa.org"}, {"url": "https://arxiv.org/pdf/1505.00468.pdf", "anchor_text": "VQA paper"}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA"}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA"}, {"url": "https://victorzhou.com/tag/computer-vision/", "anchor_text": "Computer Vision"}, {"url": "https://victorzhou.com/tag/natural-language-processing/", "anchor_text": "Natural Language Processing"}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "CNN"}, {"url": "https://victorzhou.com/blog/softmax", "anchor_text": "Softmax"}, {"url": "https://github.com/vzhou842/easy-VQA-keras", "anchor_text": "easy-VQA-keras"}, {"url": "https://github.com/vzhou842/easy-VQA-keras.git", "anchor_text": "https://github.com/vzhou842/easy-VQA-keras.git"}, {"url": "https://pypi.org/project/tensorflow/", "anchor_text": "tensorflow"}, {"url": "https://pypi.org/project/Pillow/", "anchor_text": "Pillow"}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-vqa"}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "Convolutional Neural Network"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/", "anchor_text": "a guide on using Keras to implement CNNs"}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/", "anchor_text": "intro to CNNs"}, {"url": "https://keras.io/models/model/", "anchor_text": "Model"}, {"url": "https://keras.io/models/sequential/", "anchor_text": "Sequential"}, {"url": "https://victorzhou.com/blog/intro-to-rnns/", "anchor_text": "Recurrent Neural Network"}, {"url": "https://victorzhou.com/blog/bag-of-words/", "anchor_text": "Bag of Words"}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/", "anchor_text": "standard (feedforward) neural network"}, {"url": "https://victorzhou.com/blog/bag-of-words/", "anchor_text": "short, beginner-friendly introduction to Bag-of-Words models"}, {"url": "https://keras.io/preprocessing/text/#tokenizer", "anchor_text": "Tokenizer"}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-vqa documentation"}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/", "anchor_text": "intro to Neural Networks"}, {"url": "https://keras.io/layers/merge/#multiply", "anchor_text": "Multiply merge layer"}, {"url": "https://victorzhou.com/blog/intro-to-neural-networks/#4-training-a-neural-network-part-2", "anchor_text": "propagating gradients through its layers"}, {"url": "https://keras.io/layers/merge/", "anchor_text": "Merge Layers"}, {"url": "https://victorzhou.com/blog/softmax", "anchor_text": "Softmax"}, {"url": "https://victorzhou.com/blog/softmax", "anchor_text": "explanation of Softmax"}, {"url": "https://victorzhou.com/blog/intro-to-cnns-part-1/#52-cross-entropy-loss", "anchor_text": "Cross-Entropy Loss"}, {"url": "https://github.com/vzhou842/easy-VQA", "anchor_text": "easy-VQA"}, {"url": "https://keras.io/utils/#to_categorical", "anchor_text": "to_categorical"}, {"url": "https://en.wikipedia.org/wiki/One-hot", "anchor_text": "one-hot"}, {"url": "https://keras.io/callbacks/#modelcheckpoint", "anchor_text": "ModelCheckpoint"}, {"url": "https://github.com/vzhou842/easy-VQA-keras", "anchor_text": "find it here on Github"}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/#8-extensions", "anchor_text": "Extensions"}, {"url": "https://victorzhou.com/blog/keras-cnn-tutorial/", "anchor_text": "introduction to CNNs with Keras"}, {"url": "https://easy-vqa-demo.victorzhou.com/", "anchor_text": "easy-VQA demo"}, {"url": "https://victorzhou.com/blog/intro-to-rnns/", "anchor_text": "Recurrent Neural Networks"}, {"url": "https://visualqa.org/", "anchor_text": "VQA"}, {"url": "https://arxiv.org/pdf/1607.05910.pdf", "anchor_text": "survey of VQA"}, {"url": "https://vqa.cloudcv.org/", "anchor_text": "CloudCV VQA demo"}, {"url": "https://phillipkwang.com/", "anchor_text": "Phillip Wang"}, {"url": "https://victorzhou.com/blog/easy-vqa/", "anchor_text": "https://victorzhou.com"}, {"url": "https://medium.com/tag/visual-question-answering?source=post_page-----637efa38b55c---------------visual_question_answering-----------------", "anchor_text": "Visual Question Answering"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----637efa38b55c---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----637efa38b55c---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----637efa38b55c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----637efa38b55c---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&user=Victor+Zhou&userId=dd190d205cab&source=-----637efa38b55c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&user=Victor+Zhou&userId=dd190d205cab&source=-----637efa38b55c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F637efa38b55c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----637efa38b55c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----637efa38b55c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----637efa38b55c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----637efa38b55c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----637efa38b55c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----637efa38b55c--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://victorczhou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "925 Followers"}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8d9c8575861&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feasy-visual-question-answering-victorzhou-com-637efa38b55c&newsletterV3=dd190d205cab&newsletterV3Id=b8d9c8575861&user=Victor+Zhou&userId=dd190d205cab&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}