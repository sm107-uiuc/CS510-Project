{"url": "https://towardsdatascience.com/building-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2", "time": 1682994854.564846, "path": "towardsdatascience.com/building-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2/", "webpage": {"metadata": {"title": "Building a Better Profanity Detection Library with scikit-learn | by Victor Zhou | Towards Data Science", "h1": "Building a Better Profanity Detection Library with scikit-learn", "description": "Of course, before I did that, I looked in the Python Package Index (PyPI) for any existing libraries that could do this for me. The only half decent results for the search query \u201cprofanity\u201d were\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/vzhou842/profanity-check", "anchor_text": "profanity-check", "paragraph_index": 1}, {"url": "https://pypi.org/", "anchor_text": "Python Package Index", "paragraph_index": 2}, {"url": "https://github.com/ben174/profanity/blob/master/profanity/data/wordlist.txt", "anchor_text": "wordlist.txt", "paragraph_index": 4}, {"url": "https://www.figure-eight.com/", "anchor_text": "Figure Eight", "paragraph_index": 13}, {"url": "https://github.com/vzhou842/profanity-check/blob/master/profanity_check/data/clean_data.csv", "anchor_text": "download here", "paragraph_index": 17}, {"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "this", "paragraph_index": 18}, {"url": "https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908", "anchor_text": "this", "paragraph_index": 18}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "CountVectorizer", "paragraph_index": 20}, {"url": "https://victorzhou.com/blog/bag-of-words/", "anchor_text": "Bag of Words", "paragraph_index": 20}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html", "anchor_text": "LinearSVC", "paragraph_index": 23}, {"url": "https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72", "anchor_text": "This", "paragraph_index": 23}, {"url": "https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/", "anchor_text": "this", "paragraph_index": 23}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html", "anchor_text": "CalibratedClassifierCV", "paragraph_index": 24}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com", "paragraph_index": 31}], "all_paragraphs": ["A few months ago, I needed a way to detect profanity in user-submitted text strings:", "I ended up building and releasing my own library for this purpose called profanity-check:", "Of course, before I did that, I looked in the Python Package Index (PyPI) for any existing libraries that could do this for me. The only half decent results for the search query \u201cprofanity\u201d were:", "Third-party libraries can sometimes be sketchy, though, so I did my due diligence on these 4 results.", "After a quick dig through the profanity repository, I found a file named wordlist.txt:", "The entire profanity library is just a wrapper over this list of 32 words! profanity detects profanity simply by looking for one of these words.", "To my dismay, better-profanity and profanityfilter both took the same approach:", "This is bad because profanity detection libraries based on wordlists are extremely subjective. For example, better-profanity's wordlist includes the word \u201csuck.\u201d Are you willing to say that any sentence containing the word \u201csuck\u201d is profane? Furthermore, any hard-coded list of bad words will inevitably be incomplete \u2014 do you think profanity's 32 bad words are the only ones out there?", "Having already ruled out 3 libraries, I put my hopes on the 4th and final one: profanity-filter.", "Turns out, it\u2019s really slow. Here\u2019s a benchmark I ran in December 2018 comparing (1) profanity-filter, (2) my library profanity-check, and (3) profanity (the one with the list of 32 words):", "I needed to be able to perform many predictions in real time, and profanity-filter was not even close to being fast enough. But hey, maybe this is a classic tradeoff of accuracy for speed, right?", "None of the libraries I\u2019d found on PyPI met my needs, so I built my own.", "I knew that I wanted profanity-check to base its classifications on data to avoid being subjective (read: to be able to say I used Machine Learning). I put together a combined dataset from two publicly-available sources:", "Each of these datasets contains text samples hand-labeled by humans through crowdsourcing sites like Figure Eight.", "Here\u2019s what my dataset ended up looking like:", "The Twitter dataset has a column named class that\u2019s 0 if the tweet contains hate speech, 1 if it contains offensive language, and 2 if it contains neither. I classified any tweet with a class of 2 as \u201cNot Offensive\u201d and all other tweets as \u201cOffensive.\u201d", "The Wikipedia dataset has several binary columns (e.g. toxic or threat) that represent whether or not that text contains that type of toxicity. I classified any text that contained any of the types of toxicity as \u201cOffensive\u201d and all other texts as \u201cNot Offensive.\u201d", "Now armed with a cleaned, combined dataset (which you can download here), I was ready to train the model!", "I\u2019m skipping over how I cleaned the dataset because, honestly, it\u2019s pretty boring\u2014 if you\u2019re interested in learning more about preprocessing text datasets check out this or this.", "Two major steps are happening here: (1) vectorization and (2) training.", "I used scikit-learn's CountVectorizer class, which basically turns any text string into a vector by counting how many times each given word appears. This is known as a Bag of Words (BOW) representation. For example, if the only words in the English language were the, cat, sat, and hat, a possible vectorization of the sentence the cat sat in the hat might be:", "The ??? represents any unknown word, which for this sentence is in. Any sentence can be represented in this way as counts of the, cat, sat, hat, and ???!", "Of course, there are far more words in the English language, so in the code above I use the fit_transform() method, which does 2 things:", "The model I decided to use was a Linear Support Vector Machine (SVM), which is implemented by scikit-learn's LinearSVC class. This and this are good introductions if you don\u2019t know what SVMs are.", "The CalibratedClassifierCV in the code above exists as a wrapper to give me the predict_proba() method, which returns a probability for each class instead of just a classification. You can pretty much just ignore it if that last sentence made no sense to you, though.", "Here\u2019s one (simplified) way you could think about why the Linear SVM works: during the training process, the model learns which words are \u201cbad\u201d and how \u201cbad\u201d they are because those words appear more often in offensive texts. It\u2019s as if the training process is picking out the \u201cbad\u201d words for me, which is much better than using a wordlist I write myself!", "A Linear SVM combines the best aspects of the other profanity detection libraries I found: it\u2019s fast enough to run in real-time yet robust enough to handle many different kinds of profanity.", "That being said, profanity-check is far from perfect. Let me be clear: take predictions from profanity-check with a grain of salt because it makes mistakes. For example, its not good at picking up less common variants of profanities like \u201cf4ck you\u201d or \u201cyou b1tch\u201d because they don\u2019t appear often enough in the training data. You\u2019ll never be able to detect all profanity (people will come up with new ways to evade filters), but profanity-check does a good job at finding most.", "profanity-check is open source and available on PyPI! To use it, simply", "How could profanity-check be even better? Feel free to reach out or comment with any thoughts or suggestions!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CS @ Princeton University. I write about web development, machine learning, and more at https://victorzhou.com."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3638b2f2c4c2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://victorczhou.medium.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab----3638b2f2c4c2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/vzhou842/profanity-check", "anchor_text": "profanity-check"}, {"url": "https://github.com/vzhou842/profanity-check", "anchor_text": "vzhou842/profanity-checkA fast, robust Python library to check for offensive language in strings. - vzhou842/profanity-checkgithub.com"}, {"url": "https://pypi.org/", "anchor_text": "Python Package Index"}, {"url": "https://pypi.org/project/profanity/", "anchor_text": "profanity"}, {"url": "https://pypi.org/project/better-profanity/", "anchor_text": "better-profanity"}, {"url": "https://github.com/ben174/profanity", "anchor_text": "profanity"}, {"url": "https://github.com/ben174", "anchor_text": "Ben Friedland"}, {"url": "https://pypi.org/project/profanityfilter/", "anchor_text": "profanityfilter"}, {"url": "https://pypi.org/project/profanity-filter/", "anchor_text": "profanity-filter"}, {"url": "https://github.com/ben174/profanity/blob/master/profanity/data/wordlist.txt", "anchor_text": "wordlist.txt"}, {"url": "https://github.com/snguyenthanh/better_profanity/blob/master/better_profanity/profanity_wordlist.txt", "anchor_text": "a 140-word wordlist"}, {"url": "https://github.com/areebbeigh/profanityfilter/blob/master/profanityfilter/data/badwords.txt", "anchor_text": "a 418-word wordlist"}, {"url": "https://xkcd.com/290/", "anchor_text": "xkcd"}, {"url": "https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data", "anchor_text": "t-davidson/hate-speech-and-offensive-language"}, {"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge", "anchor_text": "this Kaggle competition"}, {"url": "https://conversationai.github.io/", "anchor_text": "Conversation AI"}, {"url": "https://www.figure-eight.com/", "anchor_text": "Figure Eight"}, {"url": "https://github.com/vzhou842/profanity-check/blob/master/profanity_check/data/clean_data.csv", "anchor_text": "download here"}, {"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "this"}, {"url": "https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908", "anchor_text": "this"}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "CountVectorizer"}, {"url": "https://victorzhou.com/blog/bag-of-words/", "anchor_text": "Bag of Words"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html", "anchor_text": "LinearSVC"}, {"url": "https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72", "anchor_text": "This"}, {"url": "https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/", "anchor_text": "this"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html", "anchor_text": "CalibratedClassifierCV"}, {"url": "https://github.com/vzhou842/profanity-check", "anchor_text": "vzhou842/profanity-checkA fast, robust Python library to check for offensive language in strings. - vzhou842/profanity-checkgithub.com"}, {"url": "https://victorzhou.com/blog/better-profanity-detection-with-scikit-learn/", "anchor_text": "victorzhou.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3638b2f2c4c2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----3638b2f2c4c2---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----3638b2f2c4c2---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/tag/support-vector-machine?source=post_page-----3638b2f2c4c2---------------support_vector_machine-----------------", "anchor_text": "Support Vector Machine"}, {"url": "https://medium.com/tag/nlp?source=post_page-----3638b2f2c4c2---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&user=Victor+Zhou&userId=dd190d205cab&source=-----3638b2f2c4c2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&user=Victor+Zhou&userId=dd190d205cab&source=-----3638b2f2c4c2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3638b2f2c4c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3638b2f2c4c2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3638b2f2c4c2--------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://victorczhou.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Victor Zhou"}, {"url": "https://victorczhou.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "925 Followers"}, {"url": "https://victorzhou.com", "anchor_text": "https://victorzhou.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd190d205cab&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&user=Victor+Zhou&userId=dd190d205cab&source=post_page-dd190d205cab--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8d9c8575861&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-better-profanity-detection-library-with-scikit-learn-3638b2f2c4c2&newsletterV3=dd190d205cab&newsletterV3Id=b8d9c8575861&user=Victor+Zhou&userId=dd190d205cab&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}