{"url": "https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868", "time": 1682997262.720178, "path": "towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868/", "webpage": {"metadata": {"title": "How to tune hyperparameters of tSNE | by Nikolay Oskolkov | Towards Data Science", "h1": "How to tune hyperparameters of tSNE", "description": "This is the second post of the column Mathematical Statistics and Machine Learning for Life Sciences. In the first post we discussed whether and where in Life Sciences we have Big Data suitable for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/do-we-have-big-data-in-life-sciences-c6c4e9f8645c", "anchor_text": "first post", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Single_cell_sequencing", "anchor_text": "Single Cell", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-distributed stochastic neighbor embedding (tSNE)", "paragraph_index": 0}, {"url": "https://www.scilifelab.se/events/single-cell-rna-sequencing-data-analysis-2/", "anchor_text": "single cell RNA sequencing (scRNAseq) course", "paragraph_index": 2}, {"url": "https://distill.pub/2016/misread-tsne/", "anchor_text": "this fantastic post", "paragraph_index": 2}, {"url": "https://www.rdocumentation.org/packages/Rtsne/versions/0.15/topics/Rtsne", "anchor_text": "Rtsne", "paragraph_index": 4}, {"url": "https://github.com/lvdmaaten/bhtsne/", "anchor_text": "Barnes-Hut", "paragraph_index": 4}, {"url": "http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf", "anchor_text": "original tSNE algorithm", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/deep-learning-for-single-cell-biology-935d45064438", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://www.nature.com/articles/s41467-018-07582-3", "anchor_text": "Cancer Associated Fibroblasts (CAFs)", "paragraph_index": 6}, {"url": "https://lvdmaaten.github.io/tsne/", "anchor_text": "FAQ", "paragraph_index": 9}, {"url": "https://hemberg-lab.github.io/scRNA.seq.datasets/", "anchor_text": "here", "paragraph_index": 11}, {"url": "http://www.nxn.se/", "anchor_text": "Valentine Svensson", "paragraph_index": 11}, {"url": "http://www.nxn.se/single-cell-studies", "anchor_text": "list", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "K - Nearest Neighbors (KNN) algorithm", "paragraph_index": 13}, {"url": "https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm", "anchor_text": "here", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler (KL) divergence", "paragraph_index": 14}, {"url": "https://www.nature.com/articles/nbt.4314", "anchor_text": "UMAP", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/u/8570b484f56c", "anchor_text": "Nikolay Oskolkov,", "paragraph_index": 19}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186", "anchor_text": "Linkedin", "paragraph_index": 19}], "all_paragraphs": ["This is the second post of the column Mathematical Statistics and Machine Learning for Life Sciences. In the first post we discussed whether and where in Life Sciences we have Big Data suitable for Machine / Deep Learning, and emphasized that Single Cell is one of the most promising Big Data resources. t-distributed stochastic neighbor embedding (tSNE) is a Machine Learning non-linear dimensionality reduction technique which is absolutely central for Single Cell data analysis. However, the choice of hyperparameters for the tSNE might be confusing for beginners.", "In this post, I will share my recommendations on selecting optimal values of hyperparameters such as perplexity, number of principal components to keep, and number of iterations for running tSNE.", "When teaching single cell RNA sequencing (scRNAseq) course I keep getting questions about sensitivity of tSNE with respect to hyperparameters such as perplexity. The questions are usually inspired by this fantastic post about challenges with interpreting tSNE plots.", "Despite my great respect for the main message of the post, I think scRNAseq community should not worry too much about perplexity and other tSNE hyperparameters based on what they learn from that post because: a) many examples in the post come from abstract mathematical topologies which do not really resemble scRNAseq data, b) the post concentrates on extreme tSNE hyperparameters which are rarely used in the real world scRNAseq analysis.", "If you do scRNAseq analysis you will not avoid the popular Rtsne function and R package which is based on Barnes-Hut C++ implementation of the original tSNE algorithm. The Rtsne function has three main hyperparameters:", "Here, we will go through these hyperparameters and explain what they mean. Obviously, their default values might not work well for arbitrary data. Here, I am going to explain how to select optimal tSNE hyperparameters for your particular data set if you are not sure where to start.", "scRNAseq is a high-dimensional data (~20 000 dimensions / genes) while tSNE has difficulty dealing with high dimensions. Therefore, typically you want to reduce initial number of dimensions linearly with e.g. PCA or non-linearly with e.g. Autoencoder (see e.g. here) down to 30 - 50 latent variables (initial_dims) and use this as a new data set for feeding into tSNE. Here for simplicity we will use PCA for the pre-dimensionality reduction since PCA is great at separating signal from noise. Let us plot the percentage of variance explained by Principal Components (PCs) using scRNAseq data from Cancer Associated Fibroblasts (CAFs):", "Looks familiar, doesn\u2019t it? However, how many Principal Components (PCs) should we keep for inputting into tSNE, i.e. what value initial_dims should take: 20, 30, 50 or maybe more? Here we have a dilemma: 1) if we select too many PCs, we will include \u201cnoisy\u201d PCs from the tail of the plot, however 2) if we select too few PCs we might loose the signal from the data. To make this decision we recall that randomization is a friend of a Data Scientist and will compare the observed variance explained by PCs with permuted variance. For this purpose, we shuffle the elements of the expression matrix, perform PCA and check what would the above plot look like for the permuted matrix:", "The red curve on the first plot is the mean of the permuted variance explained by PCs, this can be treated as a \u201cnoise zone\u201d. In other words, the point where the observed variance (green curve) hits the permuted variance (red curve) determines how many informative PCs we have in our data. Moreover, since we have a vector of permuted variances, it is possible to calculate the p-value of how the observed variance is different from the permuted variance for each PC. For the case of CAFs we conclude that 30 PCs should be kept for the tSNE and the rest should be ignored as their values fall into the \u201cnoise zone\u201d.", "Perplexity is perhaps the most confusing hyperparameter of tSNE. The author of tSNE, Laurens van der Maaten, mentions in the FAQ: Typical values for the perplexity range between 5 and 50. One obvious questions that comes immediately to my mind: \u201cFor how many data points? What if I have 10 000 cells, should I still use perplexity in the range between 5 and 50?\u201d. In the next sentence of the FAQ Laurens van der Maaten adds:", "Loosely speaking, one could say that a larger / denser data set requires a larger perplexity", "This sounds reasonable but what should be the functional form of perplexity vs. number of cells in order to capture both local and global data structures? To answer this question, one year ago I collected 43 scRNAseq data sets which were publicly available at that time, many of them were downloaded from here. Valentine Svensson has another comprehensive and much more updated list of 500 scRNAseq data sets. For each of the 43 data sets I made a few tSNE plots with perplexities varying from 3 to N/3 (default max perplexity in Rtsne function), N is the number of cells. For the CAFs data set this looked like this:", "Next, I went through the plots in order to select a range of perplexities where clustering looked most transparent to me, and plotted the mean value of this range of perplexities vs. number of cells for each data set. The curves for the normal (above) and the log-scale (below) looked as follows:", "The dependence on the log-scale looks linear, fitting linear model I obtained log(Perp) = -0.179 + 0.51*log(N). Please note the coefficient 1/2 in front of log(N), this implies that the perplexity grows as Perp ~ N^(1/2). Later I realized that this power law is very similar to the rule of thumb for selecting optimal K in the K - Nearest Neighbors (KNN) algorithm. Indeed, in the KNN Machine Learning it is widely accepted (see for example here) that optimal K~N^(1/2). Since the intuition behind perplexity is how many neighbors each data point can \u201csense\u201d, this confirms the power law obtained above.", "Now let us try to analytically derive this power law. Since tSNE is based on minimization of the Kullback-Leibler (KL) divergence, so maybe the optimal perplexity can be found from the minimum of KL? However, if we plot KL as a function of perplexity at other parameters fixed, it decreases monotonically.", "So there is no minimum of KL with respect to perplexity, and KL will always prefer higher perplexities despite we know that too large perplexities will lead to one big clump of points without any clustering. Therefore we need to build another Score function that includes the KL and an additional contribution that penalizes KL for too large perplexities. Assuming that the KL behaves as 1/Perplexity, a simple function which always has a minimum would be Score ~ 1/Perplexity + Perplexity. However, Perplexity is usually a large number, therefore the Score function will be dominated by the second term. A simple trick to make both contributions to be on the same order of magnitude is to normalize the second term by the number of cells N. Finally, in order to find the minimum of Score we calculate its derivative with respect to Perplexity and equate it to zero. Solving this equation leads to Perplexity ~ N^(1/2).", "Despite the empirical way of deriving the power law, Perplexity ~ N^(1/2), can not be considered as a proper research, it helps developing an intuition about the concept of perplexity and its relation to the number of cells. On the other hand, many things about tSNE are based on pure intuition and rules of thumb as tSNE does not have a solid mathematical background in contrast to UMAP. Therefore if you are not sure what perplexity to use for your particular data set, try N^(1/2) and you will not be too off.", "When it comes to the number of iterations needed for tSNE to converge, the simplest recommendation can be the more iterations the better. However, practically this is not feasible for big data sets as one might have to wait for days to reach e.g. 10 000 iterations. In contrast, if you use too few iterations the clusters might not be visible and you typically discover a huge clump of data points in the center of your tSNE plot. What to do in this case? Well, if you look carefully at the tSNE plots available in literature, you notice that the largest distance between data points is on the order of ~100. This simple rule of thumb indicates that the algorithm reached convergence and further increasing the number of iterations will only marginally change the plot. For the CAFs data set, we can observe how the scale spans only a few units at the beginning of the training and grows up to ~60 units for larger numbers of iterations such as max_iter = 1000, this also leads to more distinct clustering.", "In this post we have learnt that despite tSNE can be sensitive with respect to its hyperparameters, there are simple rules for obtaining good looking tSNE plots for scRNAseq data. The optimal number of PCs for inputting into tSNE can be found through randomization of the expression matrix. The optimal perplexity can be calculated from the number of cells according to the simple power law Perplexity ~ N^(1/2). Finally, the optimal number of iterations should provide the largest distance between the data points of ~100 units.", "In the comments below let me know which analyses in Life Sciences seem especially mysterious to you and I will try to address them in this column. Follow me at Medium Nikolay Oskolkov, in Twitter @NikolayOskolkov and connect in Linkedin. I plan to write the next post about Doing clustering without specifying the number of clusters, stay tuned.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7c0596a18868&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c----7c0596a18868---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences"}, {"url": "https://satijalab.org/seurat/v1.4/pbmc3k_tutorial.html", "anchor_text": "Image source"}, {"url": "https://towardsdatascience.com/do-we-have-big-data-in-life-sciences-c6c4e9f8645c", "anchor_text": "first post"}, {"url": "https://en.wikipedia.org/wiki/Single_cell_sequencing", "anchor_text": "Single Cell"}, {"url": "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding", "anchor_text": "t-distributed stochastic neighbor embedding (tSNE)"}, {"url": "https://www.scilifelab.se/events/single-cell-rna-sequencing-data-analysis-2/", "anchor_text": "single cell RNA sequencing (scRNAseq) course"}, {"url": "https://distill.pub/2016/misread-tsne/", "anchor_text": "this fantastic post"}, {"url": "https://distill.pub/2016/misread-tsne/", "anchor_text": "tutorial"}, {"url": "https://www.rdocumentation.org/packages/Rtsne/versions/0.15/topics/Rtsne", "anchor_text": "Rtsne"}, {"url": "https://github.com/lvdmaaten/bhtsne/", "anchor_text": "Barnes-Hut"}, {"url": "http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf", "anchor_text": "original tSNE algorithm"}, {"url": "https://towardsdatascience.com/deep-learning-for-single-cell-biology-935d45064438", "anchor_text": "here"}, {"url": "https://www.nature.com/articles/s41467-018-07582-3", "anchor_text": "Cancer Associated Fibroblasts (CAFs)"}, {"url": "https://lvdmaaten.github.io/tsne/", "anchor_text": "FAQ"}, {"url": "https://hemberg-lab.github.io/scRNA.seq.datasets/", "anchor_text": "here"}, {"url": "http://www.nxn.se/", "anchor_text": "Valentine Svensson"}, {"url": "http://www.nxn.se/single-cell-studies", "anchor_text": "list"}, {"url": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm", "anchor_text": "K - Nearest Neighbors (KNN) algorithm"}, {"url": "https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler (KL) divergence"}, {"url": "https://www.nobelprize.org/prizes/physics/1991/9905-what-do-they-look-like/", "anchor_text": "scaling"}, {"url": "https://www.nature.com/articles/nbt.4314", "anchor_text": "UMAP"}, {"url": "https://towardsdatascience.com/u/8570b484f56c", "anchor_text": "Nikolay Oskolkov,"}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7c0596a18868---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----7c0596a18868---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/stats-ml-life-sciences?source=post_page-----7c0596a18868---------------stats_ml_life_sciences-----------------", "anchor_text": "Stats Ml Life Sciences"}, {"url": "https://medium.com/tag/bioinformatics?source=post_page-----7c0596a18868---------------bioinformatics-----------------", "anchor_text": "Bioinformatics"}, {"url": "https://medium.com/tag/life-sciences?source=post_page-----7c0596a18868---------------life_sciences-----------------", "anchor_text": "Life Sciences"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----7c0596a18868---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----7c0596a18868---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7c0596a18868&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7c0596a18868---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7c0596a18868--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7c0596a18868--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7c0596a18868--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7c0596a18868--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7c0596a18868--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://nikolay-oskolkov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff4a74ad409c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-tune-hyperparameters-of-tsne-7c0596a18868&newsletterV3=8570b484f56c&newsletterV3Id=f4a74ad409c6&user=Nikolay+Oskolkov&userId=8570b484f56c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}