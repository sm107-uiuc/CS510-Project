{"url": "https://towardsdatascience.com/data-versioning-all-you-need-to-know-7077aa5ed6d1", "time": 1683017468.1179461, "path": "towardsdatascience.com/data-versioning-all-you-need-to-know-7077aa5ed6d1/", "webpage": {"metadata": {"title": "Data Versioning with lakeFS: All You Need to Know | Towards Data Science", "h1": "Data Versioning: All You Need to Know", "description": "Introduction to Data Versioning with LakeFS command line. lakeFS introduces git-level manageability of your data and introduces CLI and UI interfaces to work with"}, "outgoing_paragraph_urls": [{"url": "https://stackoverflow.com/questions/29393447/why-cant-git-handle-large-files-and-large-repos", "anchor_text": "this", "paragraph_index": 4}, {"url": "https://lakefs.io/how-to-manage-your-data-the-way-you-manage-your-code/", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://dvc.org/", "anchor_text": "DVC", "paragraph_index": 6}, {"url": "https://mlflow.org/", "anchor_text": "MLflow", "paragraph_index": 6}, {"url": "https://lakefs.io/", "anchor_text": "lakeFS", "paragraph_index": 8}, {"url": "https://lakefs.io/object-storage/", "anchor_text": "object storage", "paragraph_index": 10}, {"url": "https://lakefs.io/blog/", "anchor_text": "blog", "paragraph_index": 10}, {"url": "https://docs.lakefs.io/", "anchor_text": "documentation", "paragraph_index": 10}, {"url": "https://docs.lakefs.io/using/", "anchor_text": "this", "paragraph_index": 11}, {"url": "https://docs.docker.com/docker-for-mac/install/", "anchor_text": "macOS", "paragraph_index": 13}, {"url": "https://docs.docker.com/docker-for-windows/install/", "anchor_text": "Windows", "paragraph_index": 13}, {"url": "https://docs.docker.com/engine/install/centos/", "anchor_text": "Linux Distros", "paragraph_index": 13}, {"url": "http://127.0.0.1:8000/setup", "anchor_text": "http://127.0.0.1:8000/setup", "paragraph_index": 22}, {"url": "http://127.0.0.1:8000/login", "anchor_text": "http://127.0.0.1:8000/login", "paragraph_index": 24}, {"url": "https://docs.lakefs.io/quickstart/lakefs_cli.html", "anchor_text": "lakeFS CLI", "paragraph_index": 27}, {"url": "https://github.com/treeverse/lakeFS/releases", "anchor_text": "this", "paragraph_index": 27}, {"url": "http://127.0.0.1:8000/api/v1", "anchor_text": "http://127.0.0.1:8000/api/v1", "paragraph_index": 35}, {"url": "https://docs.lakefs.io/reference/commands.html", "anchor_text": "CLI reference", "paragraph_index": 43}, {"url": "https://docs.lakefs.io/", "anchor_text": "official website", "paragraph_index": 61}, {"url": "https://docs.lakefs.io/reference/commands.html", "anchor_text": "CLI reference", "paragraph_index": 70}, {"url": "https://www.linkedin.com/in/bextuychiev/", "anchor_text": "https://www.linkedin.com/in/bextuychiev/", "paragraph_index": 72}], "all_paragraphs": ["There is a need for a better system for versioning massive amounts of data. It has been around for years.", "While Git does an excellent job of managing codebases, it sucks at versioning binary files. Even the creator of Git, Linus Torvalds, admits this:", "And yes, then there\u2019s the \u201cbig file\u201d issues. I really don\u2019t know what to do about huge files. We suck at them, I know.", "Once you upload a large binary file to a repository, it is there for everyone to download. Anyone who clones or forks the repo will have a copy of the file. It gets saved on the disk, not to mention all the duplication for many branches.", "This topic has been discussed at length by many; you can find discussions on this StackOverflow thread and from here.", "These problems are challenging in many areas of data. For example, machine learning engineers work with massive datasets through ML pipelines, and introducing reproducibility to their workflow in an easy manner is hard.", "Specialists try to use technologies such as DVC or MLflow to solve their versioning issues but these tools do not provide enough stability to implement them at an enterprise level. So, what is the solution?", "Get the best and latest ML and AI papers chosen and summarized by a powerful AI \u2014 Alpha Signal:", "lakeFS provides all the solutions for data versioning problems. It prides itself in introducing git-level manageability of data with no duplication.", "The lakeFS ecosystem introduces solutions for many challenging issues such as managing data access for multiple users, providing safe data ingestion and experimentation environments for both data consumers and engineers, running ML pipelines with any complexity level, and many more.", "It also works seamlessly with many cloud-based object storage systems such as Amazon S3 and GCP. I especially like how lakeFS provides both UI and CLI interfaces to work with which is a combination not yet available in its competitors. You can learn the many more benefits of the tool from the official blog and the documentation.", "Today, we will talk about the basics of lakeFS to give you an idea of how it works by interacting with local repositories with lakeFS Command Line Interface. If you want to try it out using data stored on the cloud, refer to this page of the docs.", "From personal experience, installing lakeFS to run local instances, Docker Compose is the best solution.", "First of all, ensure that you have Docker installed with compose version 1.25.04 or higher. If you don\u2019t have Docker installed, here are links for installation guides: macOS, Windows, Linux Distros.", "You can verify that you have correctly installed Docker by running docker version on the shell:", "Next, start lakeFS instance with a single command:", "If your output is anything like this, you are on the right track:", "You can also see the image running on your Docker Desktop Console:", "Next, start the lakeFS instance with a single command:", "curl https://compose.lakefs.io | docker-compose -f - up", "If your output is anything like this, you are on the right track:", "You can also see the image running on your Docker Desktop Console:", "When you run the docker-compose command for the first time, you should set up a user admin by opening http://127.0.0.1:8000/setup on your browser. It will open up this page:", "Enter a username of your choice, and it will give you one-time-only credentials. You should store them securely in a file somewhere because we will need it later.", "Next, proceed to http://127.0.0.1:8000/login, where you will be able to log in using your credentials. As soon as you log in, you will land on your repositories page. Think of it like your GitHub account but with lakeFS:", "This page is your UI for interacting with all of your repos and your user account.", "However, for peeps who love the shell, lakeFS provides an even more powerful Command Line Interface, which we will cover in the next sections.", "lakeFS CLI is installed using its CLI binary. First, go to this GitHub releases page of lakeFS. Click on the latest release and scroll to the bottom. You will find download options depending on your OS:", "Download yours and place it somewhere in your PATH. If you want to run the CLI for a single project, you can extract it directly into the root directory of your project:", "Before running the CLI commands, check that you are still running the lakeFS image from your Docker Console. Then, run this to check if the CLI is working:", "If the shell displays a help page, congratulations, you are running the CLI on your local machine!", "Before we move on, it is important that you know the lakeFS namespace. Different operations all reference components of lakeFS repositories through the lakefs:// keyword. Here is a reference list of patterns for referring to different components:", "Important note for later sections: When you work with file and directory paths, make sure to end them with a forward slash / for the commands to work as expected.", "To start interacting with repositories under your account, you should first authorize your session (done every time you start a new one). Start by running lakectl config which should show this output:", "Copy and paste your Access Key ID you saved from the earlier section. Do the same for your secret key:", "It does not ask twice for each field; it is just displayed like that. The Server Endpoint URL you see is http://127.0.0.1:8000/api/v1. After you enter these values into the fields, you will be authorized and will be able to control pretty much everything related to lakeFS.", "You can check if you are authorized by running this command:", "It should give you an empty table since we did not create any repos. So, shall we?", "To create a repository, we will use the `lakectl repo` command, which gives access to all commands to control repositories:", "The above command will create a repo named example in the local storage since we are using local:// keyword. The storage word is arbitrary:", "From now on, this repository can be referenced only with lakefs://exampleURI (Uniform Resource Identifier). If we run lakectl repo list, we should be able to see it now:", "Just like Git, each repo has a default master branch when created.", "You can delete repositories with delete keyword:", "For full repository commands, check out the CLI reference of lakeFS.", "At this point, we start to interact with our data. Remember our main aim of using lakeFS. We want to manage data with any magnitude just like we do our code. So, what you will find useful is to integrate lakeFS with git itself.", "The idea is that we control any-data related changes through lakeFS and manage our code with git. To achieve this, you should put all the file extensions in .gitignore file which won't be tracked by git afterward.", "Now, say we want to upload some audio files to our lakeFS repo which are stored inside data directory:", "Since they have .wma extension, make sure you add *.wma as a new line to .gitignore.", "Let\u2019s upload all the files in data. Just like lakectl repo command, lakectl fs gives access to manipulate files and objects. We will use the upload command which has this pattern:", "The above command works for uploading both single or many files from a given directory. You should provide the path after --source flag. For the destination, you must include the repository name followed by a branch. It is also very important to end both source and destination paths with a / otherwise, the command fails.", "Here is the sample command to upload the 4 audio files:", "lakectl fs upload is an equivalent to git add. To list the contents of a directory, we can run:", "The above command is equivalent to the shell\u2019s ls command. When you give the pathname, just like the others it should start with lakefs:// followed by repository name, branch name, and path.", "We just uploaded new files to our repository. Notice we did not write any code so we do not need to make a commit through git. However, to save the changes to our lakeFS repo, we should make one through lakectl.", "lakectl commit commands generally follow this pattern:", "But before committing, it is usually helpful to see the changes we have made since the last commit. Just like git diff, there exists similar command for lakectl and follows this pattern:", "The diff command shows all the uncommitted changes made to the lakeFS repository on the branch you specify.", "Now, after making sure everything is good, we can commit our changes:", "We will get a success message once the changes are committed. It also gives some details such as commit ID and timestamp.", "You can see the list of commits on your repo with this command:", "The real power of lakeFS can be seen in the instance of branches. Creating branches in git allows you to duplicate your codebase and work with it in an isolation to try out experiments and features. However, doing this for repositories with an enormous amount of data is not feasible both storage-wise and time-wise.", "lakeFS solves this problem elegantly. If you create a branch for your lakeFS repository, the task is performed instantaneously and without. Creating a branch at a particular point of your repo's commit history will create a snapshot of the repo's state at that particular commit, again without duplication. The official website says that it is all about metadata management under the hood.", "Before we get to creating branches, I will upload some more data and make a few commits for example purposes.", "Next, we will create a new branch at the head, meaning from the latest commit. First, get yourself acquainted with the command to create branches:", "When you create a branch you should specify both the new branch\u2019s name and the one it should branch out from. This means that you can create branches from existing ones, it does not have to be the master.", "This will create a branch named new and you can list out existing ones with this command:", "Now, suppose you did some experimentation with your data and tested out new features. Once satisfied, you may want to merge this newly-created branch back to master.", "First of all, make sure that you commit any unsaved changes to your new branch:", "Before merging, you may want to see what is getting modified when you merge two branches. In this scenario, you can use diff command again. The below usage of the command will yield the difference between two branches:", "Note that any uncommitted changes will be committed when two branches merge.", "One final point for working with branches: If you are unsatisfied with the changes in any branch, you can always revert them with lakectl. The CLI provides 4 options depending on the situation. I won't list them out here but you can always learn about them from the CLI reference.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "BEXGBoost | DataCamp Instructor |\ud83e\udd47Top 10 AI/ML Writer on Medium | Kaggle Master | https://www.linkedin.com/in/bextuychiev/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7077aa5ed6d1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ibexorigin.medium.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Bex T."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39db050c2ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&user=Bex+T.&userId=39db050c2ac2&source=post_page-39db050c2ac2----7077aa5ed6d1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@tannerboriack?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Tanner Boriack"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://stackoverflow.com/questions/29393447/why-cant-git-handle-large-files-and-large-repos", "anchor_text": "this"}, {"url": "https://lakefs.io/how-to-manage-your-data-the-way-you-manage-your-code/", "anchor_text": "here"}, {"url": "https://dvc.org/", "anchor_text": "DVC"}, {"url": "https://mlflow.org/", "anchor_text": "MLflow"}, {"url": "https://ibexorigin.medium.com/membership", "anchor_text": "Join Medium with my referral link - BEXGBoostGet exclusive access to all my \u26a1premium\u26a1 content and all over Medium without limits. Support my work by buying me a\u2026ibexorigin.medium.com"}, {"url": "https://alphasignal.ai/?referrer=Bex", "anchor_text": "Alpha Signal | The Best of Machine Learning. Summarized by AI.Stay in the loop without spending countless hours browsing for the next breakthrough; our algorithm identifies the\u2026alphasignal.ai"}, {"url": "https://lakefs.io/", "anchor_text": "lakeFS"}, {"url": "https://lakefs.io/object-storage/", "anchor_text": "object storage"}, {"url": "https://lakefs.io/blog/", "anchor_text": "blog"}, {"url": "https://docs.lakefs.io/", "anchor_text": "documentation"}, {"url": "https://docs.lakefs.io/using/", "anchor_text": "this"}, {"url": "https://docs.docker.com/docker-for-mac/install/", "anchor_text": "macOS"}, {"url": "https://docs.docker.com/docker-for-windows/install/", "anchor_text": "Windows"}, {"url": "https://docs.docker.com/engine/install/centos/", "anchor_text": "Linux Distros"}, {"url": "http://127.0.0.1:8000/setup", "anchor_text": "http://127.0.0.1:8000/setup"}, {"url": "http://127.0.0.1:8000/login", "anchor_text": "http://127.0.0.1:8000/login"}, {"url": "https://docs.lakefs.io/quickstart/lakefs_cli.html", "anchor_text": "lakeFS CLI"}, {"url": "https://github.com/treeverse/lakeFS/releases", "anchor_text": "this"}, {"url": "http://127.0.0.1:8000/api/v1", "anchor_text": "http://127.0.0.1:8000/api/v1"}, {"url": "https://docs.lakefs.io/reference/commands.html", "anchor_text": "CLI reference"}, {"url": "https://docs.lakefs.io/", "anchor_text": "official website"}, {"url": "https://docs.lakefs.io/reference/commands.html", "anchor_text": "CLI reference"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----7077aa5ed6d1---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7077aa5ed6d1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7077aa5ed6d1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7077aa5ed6d1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----7077aa5ed6d1---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&user=Bex+T.&userId=39db050c2ac2&source=-----7077aa5ed6d1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&user=Bex+T.&userId=39db050c2ac2&source=-----7077aa5ed6d1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7077aa5ed6d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7077aa5ed6d1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7077aa5ed6d1--------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ibexorigin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bex T."}, {"url": "https://ibexorigin.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "16.4K Followers"}, {"url": "https://www.linkedin.com/in/bextuychiev/", "anchor_text": "https://www.linkedin.com/in/bextuychiev/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39db050c2ac2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&user=Bex+T.&userId=39db050c2ac2&source=post_page-39db050c2ac2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F22cea38b90f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-versioning-all-you-need-to-know-7077aa5ed6d1&newsletterV3=39db050c2ac2&newsletterV3Id=22cea38b90f3&user=Bex+T.&userId=39db050c2ac2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}