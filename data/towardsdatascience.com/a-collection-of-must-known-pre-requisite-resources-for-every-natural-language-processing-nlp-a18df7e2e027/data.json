{"url": "https://towardsdatascience.com/a-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027", "time": 1683001764.455507, "path": "towardsdatascience.com/a-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027/", "webpage": {"metadata": {"title": "A collection of must known resources for every Natural Language Processing (NLP) practitioner | by Nikhil Jaiswal | Towards Data Science", "h1": "A collection of must known resources for every Natural Language Processing (NLP) practitioner", "description": "After thorough readings from multiple sources since last one year, here are my compiled versions of the best sources of learnings which can help anyone to start their journey into the fascinating\u2026"}, "outgoing_paragraph_urls": [{"url": "https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html", "anchor_text": "https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html", "paragraph_index": 40}], "all_paragraphs": ["Hey, are you a fresher wondering to dive into the world of NLP or a regular NLP practitioner who is confused with the vast amount of information available on the web and don\u2019t know where to start from? Relax, I was the same until I decided to spend a good amount of time gathering all the required resources at one single place.", "After thorough readings from multiple sources since last one year, here are my compiled versions of the best sources of learnings which can help anyone to start their journey into the fascinating world of NLP. There are a variety of tasks which comes under the broader area of NLP such as Machine Translation, Question Answering, Text Summarization, Dialogue Systems, Speech Recognition, etc. However to work in any of these fields, the underlying must known pre-requisite knowledge is the same which I am going to discuss briefly in this blog. (Note: If any of the links have expired, please do let me know in the comments section.)", "Just a quick disclaimer about the contents:1. The contents which I am going to discuss mostly belongs to modern NLP and not that of the classical NLP techniques.2. It\u2019s impossible for anyone to go through all the available resources. I have applied my uttermost effort in whatever way I could do. 3. I assume that the reader is comfortable with at least a decent amount of knowledge regarding Machine Learning (ML) and Deep Learning(DL) algorithms.4. For all the topics that I am going to cover, I have mainly cited the best resources in terms of blogs or videos. Readers can easily find the research papers for each individual topics. I feel the mentioned blogs are more than sufficient for anyone to fully understand the respective topics.", "Here is my roadmap to the NLP world:1. Word Embeddings \u2014 Word2Vec, GloVe, FastText2. Language Models & RNN3. Contextual Word Embeddings \u2014 ELMo4. Transfer Learning in NLP \u2014 ULMFiT5. Sentence Embeddings 6. Seq2Seq & Attention Mechanism7. Transformers 8. OpenAI GPT & BERT9. GPT-2, XLNet 10. Summary", "Let\u2019s briefly summarize the above 10 topics:", "Well the first point that comes into mind when we start studying NLP is that how can we represent the words into numbers so that any ML or DL algorithm can be applied to it. That\u2019s where the word vectors/embeddings come into play. As the name suggests, the aim here is to take as input any given word and outputs a meaningful vector representation that characterizes this word.There exist different approaches to obtain this representation based on the underlying techniques such as Word2Vec, GloVe, FastText", "To begin with this topic, I would suggest the reader watch lecture 1 & 2 of Stanford CS224N: NLP with Deep Learning | Winter 2019 freely available on YouTube.", "These two lectures form a solid background regarding semantic word representation. Apart from that, you also get to know the detailed mathematics involved in the working of both Word2Vec and GloVe model. Once you are comfortable with this, I would like to refer you to some of the blogs that I found most useful on this topic. In these blogs, you can find some of the examples and visualization that helps you gain a better understanding.", "I hope these readings are more than sufficient to give you a solid understanding of Word2Vec. Let\u2019s move ahead.", "GloVe was much better explained in lecture 3 of Stanford Natural Language Processing with Deep Learning (Winter 2017)", "Apart from this, the following blogs help you obtain a clear picture of the topic and the mathematics behind this.", "I hope you must have till now understood how GloVe takes advantage of the global statistics information unlike Word2Vec and optimizes a completely different objective.", "FastText is a library created by Facebook Research Team for efficient learning of word representations and sentence classification. It supports training CBOW or Skip Gram models similar to that of Word2Vec but it operates on n-gram representation of a word. By doing so, it helps in finding vector representation of the rare words by making use of character-level information.", "Kindly refer following links for a better understanding:", "If you are done with the above-mentioned pointers, you must be now at least having a deeper understanding of the word embeddings approach. It\u2019s time to move into the backbone of NLP \u2014 Language Models.", "Language models are what we use on a daily basis. One such scenario occurs while texting a message be it on your cellphone or Gmail or LinkedIn. LM provides you with the most probable suggestions that you would like to type further. In simple words, LM is a task of predicting what word comes next. And my argument about LM being the backbone of NLP is because all the current state of the art transfer learning models depends on LM as the underlying task. You will get to know further about these in your upcoming journey. But before that, let\u2019s look at the resources to understand LM.", "As usual, my first go-to suggestion over here is to go through some of the wonderful lectures from Stanford on this particular topic.Lecture 6 of CS224N covers this topic beautifully. It gives you a glimpse of how LM was developed prior to neural networks and what advantages does neural networks basically RNN brings to this. Also, if you would like to re brush your knowledge regarding RNNs, kindly refer lecture 7 for the same.", "Also, if you feel less knowledgeable about the inner working of RNNs, you can go for a wonderful course that I studied on Udemy-", "This is one of the best courses that I found useful in the vast collection of online courses available on the web. In this course, you can understand the working of RNNs by unrolling them, turning them to bidirectional etc. Also, you can learn to code these models in Keras \u2014 one of the simplest deep learning framework to get started with.", "Guess what word embeddings are back !! Wait for a second, there is a term \u2018contextual\u2019 which makes it different from our previous studied approaches. OK, then why did not we study this topic together with the first topic. Hmmm, only because we need the knowledge of LM to understand this topic. And yeah, as I had mentioned earlier, we have come across the first application of LM in our ongoing journey. Trust me by the end, you will agree with me with awarding LM as the backbone of NLP. Enough said, let\u2019s jump into our current topic \u2014 Contextual Word Embeddings", "Embeddings from Language Models (ELMo) uses LM to obtain embeddings of individual words. Until now we were having a single embedding of any input word, for example, say a bank. Now suppose I have 2 different sentences \u2014 I went to withdraw money from the bank and I was standing near the bank of a river. In both these sentences, the meaning of the word bank are completely different and therefore they must be having different vector representation. This is what contextual embeddings aim at. ELMo is one such approach based on the multi-layer bidirectional LSTM models for obtaining contextual word embeddings. Please go through following blogs to learn about them.", "I hope that the above two resources are sufficient enough to help you get a better understanding of ELMo. It\u2019s time to move ahead \u2026", "Transfer Learning has completely revolutionized NLP domain in the last one year. Most of the current state of the art algorithms that are being developed makes use of this technique. After making a significant contribution to the field of Computer Vision, Transfer Learning has finally rejoiced NLP practitioners. Universal Language Model Fine-tuning for Text Classification (ULMFiT) is one such approach that should be credited for this wonderful change.ULMFiT introduced methods to effectively utilize a lot of what the model learns during pre-training \u2014 more than just embeddings and more thancontextualized embeddings. ULMFiT introduced a language model and a process to effectively fine-tune that language model for various tasks.Finally, pre-training and fine-tuning concepts started showing its magic power in the NLP field. ULMFiT paper also introduced different techniques such as Discriminative Fine Tuning and Slanted Triangular Learning rates that helped in improving the way the transfer learning approach could be utilized.", "Ready to explore these exciting terms, then keep calm and refer the following blogs:", "Well by now, you must be quite familiar with ULMFiT. Next in our journey comes the Sentence Embedding.", "Learnt enough about the word embeddings. What about the sentence? Can we obtain some representation of a sentence similar to that of a word? One very naive but a strong baseline approach would be to average the sentence\u2019s word vectors (so-called Bag-of-Word approach). Apart from this, there can be different approaches based on unsupervised, supervised and multi-task learning set up.", "Unsupervised schemes learn sentence embeddings as a byproduct of learning to predict a coherent succession of sentences. The main advantage over here is that you can get plenty of unsupervised data since the internet is full of text kinds of stuff. Skip Thought Vectors and Quick Thought Vectors are two such successful approaches which have been developed in the unsupervised setting.On the other hand, supervised learning requires a labelled dataset annotated for a given task. Accomplishing this task lets you learn a good sentence embedding. InferSent is one such interesting approach by Facebook Research Team. Now to resolve the conflict between unsupervised and supervised embeddings, multi-task learning set up comes into the picture. Several proposals for multi-task learning were published such as MILA/MSR\u2019s General Purpose Sentence Representation, Google\u2019s Universal Sentence Encoder etc.", "Excited to enter this world. Explore & explore the mentioned links:", "Having learnt the variants of RNN Models as well as having a good understanding of word and sentence embeddings, it\u2019s time to move ahead to an exciting NLP architecture known as Sequence 2 Sequence models(Seq2Seq). This architecture is used in a variety of NLP tasks such as Neural Machine Translation, Text Summarization, Conversational Systems, Image Captioning, etc. A sequence-to-sequence model is a model that takes a sequence of items (words, letters, features of an image \u2026etc) and outputs another sequence of items. The best way to understand these models is with the help of visualization, and this is where I would like to refer you to one of my most loved NLP author\u2019s blog. He is none other than Jay Alammar. Believe me, you would love to go through each of his blogs. The efforts he uses to explain these terms are outstanding. Click below link to enter into this beautiful world.", "I think I do need to explain you further regarding Seq2Seq, as by now you must be well conversed with it.However, now I would like to refer you again to the Stanford lectures to learn more about Statistical and Neural Machine Translation. Having knowledge of Seq2Seq would help you move fluently with these lectures. Also, Attention which is one of the most important topics is discussed in detail there. Together with that, you will also get to know about the Beam Search Decoding & BLEU metric used for evaluating NMT models.", "It\u2019s time for the beast \u2014 Transformers. While LSTM models were revolutionizing the NLP industry, it was Transformers that was developed out of the box as an improved replacement of the RNN models. The Transformer is a model that uses attention to boost the speed with which these models can be trained.The Transformer lends itself to parallelization. The Transformer was proposed in the paper Attention is All You Need. Due to the parallelization nature, it frees us from the recurrence connections involved in the RNN models. Not only it helps in reducing the training time, but also in improving the accuracy by a great margin on various NLP tasks. It is similar to Seq2Seq architecture but it depends only on the attention mechanism along with their variants. Again, the best blog to understand this topic is by Jay Alammar. In fact, as mentioned earlier you can follow all his blogs to learn about these advanced NLP techniques.", "Apart from this if you want to understand this paper in terms of implementation point of view, then please refer this awesome annotated blog by Harvard NLP group.", "If you have successfully understood the above two blogs, then give yourself a big thumbs up!! Believe me, it was not an easy task.Let\u2019s explore now regarding how researchers have utilized this newer architecture to build State of the Art models like BERT, GPT-2, etc.", "Transfer learning is back but now of course with Transformers. It\u2019s as simple as follows: utilize Transformer decoder\u2019s stack to build a newer model called GPT or utilize the encoder part of the Transformer to build an amazing model named BERT.Believe me, even if you are very new to NLP field and have been just listening to NLP buzzwords in the last one year then BERT and GPT are the toppers in this list.", "Generative Pre-Training(GPT) goal is similar to that of ULMFit i.e. to apply transfer learning in NLP. But there is a major difference. Yeah, you got it right \u2014 using Transformer instead of LSTM. Apart from that, there are also some of the difference in the training objective which you can learn about after going through the below-mentioned blogs. To summarize, the overall idea of GPT is to train the transformer decoder for language modelling task also known as pre-training. Once it is pre-trained, we can start to use it for downstream tasks. There can be a number of input transformations to handle a variety of such tasks.", "Here comes the most buzzing word of NLP \u2014 BERT.", "The main objective was to build a transformer-based model whose language model was conditioned on both left as well as right context. This was the limitation of GPT since GPT only trains a forward language model. Now to achieve the objective of bidirectional conditioning, BERT made use of encoder part of the Transformer. And in order to not see the future words while calculating attention scores, it uses a special technique called masking. According to the authors of this paper, this masking technique was the greatest contribution of this paper. Apart from the masking objective to handle relationships between multiple sentences, the pre-training process includes an additional task: Given two sentences (A and B), is B likely to be the sentence that follows A, or not?", "Well, if you are feeling burdened by some of the above terms and want a piece of deeper knowledge about them, just be relaxed. All these terms are beautifully explained in the following blogs:", "GPT-2 was nothing but a successor to GPT with more than 10X the parameters and trained on more than 10X the amount of data. Due to the concerns about malicious applications of the technology, the authors initially did not release the larger trained model which became a debatable topic.XLNet is a generalized autoregressive model. It outperforms BERT on 20 tasks, often by a large margin. It is the new go-to technique for transfer learning in NLP. For a broader understanding of GPT-2 and XLNet, please refer the below blogs.", "Finally, you have covered the entire journey of learning NLP pre-requisite as per our proposed plan. Kudos to you !!! Models keep on involving due to a large number of researchers working actively in this field. And so, within almost every month, you come across a new paper which beats the previous state of the art. So, the only way to move ahead with this fast-changing world is to remain updated with the latest knowledge by going through the research papers and these informative blogs on a regular basis.", "If you want to recollect the entire journey, go through the following mentioned blog once. https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html", "Here, I am also listing below some of the best blogs which I find most useful while learning about new topics in the field of NLP:", "I hope my resources were helpful to the reader. As said earlier, it\u2019s impossible for anyone to cover the entire topics. Suggestions are always welcome citing some of the better blogs or the important topics which I have missed. I hope anyone who is thorough with these pre-requisites can work in any of the NLP tasks. Till then, cheers, enjoy !!!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa18df7e2e027&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Nikhil Jaiswal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dd29ea0662e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=post_page-3dd29ea0662e----a18df7e2e027---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa18df7e2e027&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----a18df7e2e027---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa18df7e2e027&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=-----a18df7e2e027---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=1", "anchor_text": "https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=1"}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"}, {"url": "http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/", "anchor_text": "http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/"}, {"url": "http://jalammar.github.io/illustrated-word2vec/", "anchor_text": "http://jalammar.github.io/illustrated-word2vec/"}, {"url": "https://www.youtube.com/watch?v=ASn7ExxLZws", "anchor_text": "https://www.youtube.com/watch?v=ASn7ExxLZws"}, {"url": "https://www.slideshare.net/NikhilJaiswal3/paper-dissected-glove-global-vectors-for-word-representation-explained-machine-learning-explained", "anchor_text": "[slideshare id=229369562&doc=paperdissectedgloveglobalvectorsforwordrepresentationexplainedmachinelearningexplained-200228052056&type=d]"}, {"url": "https://www.slideshare.net/NikhilJaiswal3/emnlp-what-is-glo-ve-part-i-towards-data-science", "anchor_text": "[slideshare id=229369559&doc=emnlpwhatisgloveparti-towardsdatascience-200228052054&type=d]"}, {"url": "https://www.slideshare.net/NikhilJaiswal3/emnlp-what-is-glo-ve-part-ii-towards-data-science", "anchor_text": "[slideshare id=229369555&doc=emnlpwhatisglovepartii-towardsdatascience-200228052050&type=d]"}, {"url": "https://www.slideshare.net/NikhilJaiswal3/emnlp-what-is-glo-ve-part-iii-towards-data-science", "anchor_text": "[slideshare id=229369551&doc=emnlpwhatisglovepartiii-towardsdatascience-200228052047&type=d]"}, {"url": "https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3", "anchor_text": "https://towardsdatascience.com/fasttext-under-the-hood-11efc57b2b3"}, {"url": "https://arxiv.org/pdf/1607.04606v1.pdf", "anchor_text": "https://arxiv.org/pdf/1607.04606v1.pdf"}, {"url": "https://arxiv.org/pdf/1607.01759.pdf", "anchor_text": "https://arxiv.org/pdf/1607.01759.pdf"}, {"url": "https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6", "anchor_text": "https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6"}, {"url": "https://www.youtube.com/watch?v=QEw0qEa0E50&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=7", "anchor_text": "https://www.youtube.com/watch?v=QEw0qEa0E50&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=7"}, {"url": "https://www.udemy.com/course/deep-learning-advanced-nlp/", "anchor_text": "https://www.udemy.com/course/deep-learning-advanced-nlp/"}, {"url": "https://mlexplained.com/2018/06/15/paper-dissected-deep-contextualizedword-representations-explained/", "anchor_text": "https://mlexplained.com/2018/06/15/paper-dissected-deep-contextualizedword-representations-explained/"}, {"url": "https://www.slideshare.net/shuntaroy/a-review-of-deep-contextualized-word-representations-peters-2018", "anchor_text": "https://www.slideshare.net/shuntaroy/a-review-of-deep-contextualized-word-representations-peters-2018"}, {"url": "http://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html", "anchor_text": "http://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html"}, {"url": "https://ahmedhanibrahim.wordpress.com/2019/07/01/a-study-on-cove-context2vec-elmo-ulmfit-and-bert/", "anchor_text": "https://ahmedhanibrahim.wordpress.com/2019/07/01/a-study-on-cove-context2vec-elmo-ulmfit-and-bert/"}, {"url": "https://yashuseth.blog/2018/09/12/awd-lstm-explanation-understanding-language-model/", "anchor_text": "https://yashuseth.blog/2018/09/12/awd-lstm-explanation-understanding-language-model/"}, {"url": "https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a", "anchor_text": "https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a"}, {"url": "https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html", "anchor_text": "https://ai.googleblog.com/2018/05/advances-in-semantic-textual-similarity.html"}, {"url": "https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9", "anchor_text": "https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9"}, {"url": "http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/", "anchor_text": "http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"}, {"url": "https://www.youtube.com/watch?v=XXtpJxZBa2c&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=8", "anchor_text": "https://www.youtube.com/watch?v=XXtpJxZBa2c&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=8"}, {"url": "http://jalammar.github.io/illustrated-transformer/", "anchor_text": "http://jalammar.github.io/illustrated-transformer/"}, {"url": "https://nlp.seas.harvard.edu/2018/04/03/attention.html", "anchor_text": "https://nlp.seas.harvard.edu/2018/04/03/attention.html"}, {"url": "http://jalammar.github.io/illustrated-bert/", "anchor_text": "http://jalammar.github.io/illustrated-bert/"}, {"url": "http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/", "anchor_text": "http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"}, {"url": "https://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/", "anchor_text": "https://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/"}, {"url": "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/", "anchor_text": "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"}, {"url": "https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a", "anchor_text": "https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a"}, {"url": "http://jalammar.github.io/illustrated-gpt2/", "anchor_text": "http://jalammar.github.io/illustrated-gpt2/"}, {"url": "https://openai.com/blog/better-language-models/", "anchor_text": "https://openai.com/blog/better-language-models/"}, {"url": "https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8", "anchor_text": "https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8"}, {"url": "https://towardsdatascience.com/what-is-xlnet-and-why-it-outperformsbert-8d8fce710335", "anchor_text": "https://towardsdatascience.com/what-is-xlnet-and-why-it-outperformsbert-8d8fce710335"}, {"url": "https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html", "anchor_text": "https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html"}, {"url": "https://medium.com/huggingface", "anchor_text": "https://medium.com/huggingface"}, {"url": "http://jalammar.github.io/", "anchor_text": "http://jalammar.github.io/"}, {"url": "https://ruder.io/", "anchor_text": "https://ruder.io/"}, {"url": "https://mlexplained.com/", "anchor_text": "https://mlexplained.com/"}, {"url": "https://mccormickml.com/", "anchor_text": "https://mccormickml.com/"}, {"url": "https://medium.com/tag/natural-language-processi?source=post_page-----a18df7e2e027---------------natural_language_processi-----------------", "anchor_text": "Natural Language Processi"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a18df7e2e027---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a18df7e2e027---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a18df7e2e027---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----a18df7e2e027---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa18df7e2e027&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----a18df7e2e027---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa18df7e2e027&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----a18df7e2e027---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa18df7e2e027&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dd29ea0662e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=post_page-3dd29ea0662e----a18df7e2e027---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F3dd29ea0662e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----a18df7e2e027---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Written by Nikhil Jaiswal"}, {"url": "https://medium.com/@nikhiljaiswal_9475/followers?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "84 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dd29ea0662e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=post_page-3dd29ea0662e----a18df7e2e027---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F3dd29ea0662e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-collection-of-must-known-pre-requisite-resources-for-every-natural-language-processing-nlp-a18df7e2e027&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----a18df7e2e027---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/sequencematcher-in-python-6b1e6f3915fc?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Nikhil Jaiswal"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/sequencematcher-in-python-6b1e6f3915fc?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "SequenceMatcher in PythonA human-friendly longest contiguous & junk-free sequence comparator"}, {"url": "https://towardsdatascience.com/sequencematcher-in-python-6b1e6f3915fc?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "\u00b76 min read\u00b7Apr 15, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6b1e6f3915fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequencematcher-in-python-6b1e6f3915fc&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----6b1e6f3915fc----0-----------------clap_footer----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/sequencematcher-in-python-6b1e6f3915fc?source=author_recirc-----a18df7e2e027----0---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6b1e6f3915fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequencematcher-in-python-6b1e6f3915fc&source=-----a18df7e2e027----0-----------------bookmark_preview----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----a18df7e2e027----1---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----a18df7e2e027----1-----------------bookmark_preview----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----a18df7e2e027----2---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----a18df7e2e027----2-----------------bookmark_preview----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/covid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Nikhil Jaiswal"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/covid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "COVID-19 : How data scientists can contribute to the medical community?Let\u2019s discuss COVID-19 !!"}, {"url": "https://towardsdatascience.com/covid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": "\u00b716 min read\u00b7Apr 8, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fad03b19d34f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcovid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0&user=Nikhil+Jaiswal&userId=3dd29ea0662e&source=-----ad03b19d34f0----3-----------------clap_footer----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/covid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0?source=author_recirc-----a18df7e2e027----3---------------------f239078d_22ab_4498_bfa6_f21b3290a36b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad03b19d34f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcovid-19-how-data-scientists-can-contribute-to-the-medical-community-ad03b19d34f0&source=-----a18df7e2e027----3-----------------bookmark_preview----f239078d_22ab_4498_bfa6_f21b3290a36b-------", "anchor_text": ""}, {"url": "https://medium.com/@nikhiljaiswal_9475?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "See all from Nikhil Jaiswal"}, {"url": "https://towardsdatascience.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----a18df7e2e027----0-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----a18df7e2e027----1-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Eric Kleppen"}, {"url": "https://python.plainenglish.io/?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Python in Plain English"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Topic Modeling For Beginners Using BERTopic and PythonHow to make sense of your text data by reducing it to topics"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b711 min read\u00b7Feb 12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----aaf1b421afeb----0-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----a18df7e2e027----0---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&source=-----a18df7e2e027----0-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----a18df7e2e027----1---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----a18df7e2e027----1-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "LucianoSphere"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Build ChatGPT-like Chatbots With Customized Knowledge for Your Websites, Using Simple ProgrammingLike ChatGPT but in a form that you can plug into your website and expand with any kind of tailored information by combining basic\u2026"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b711 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&user=LucianoSphere&userId=d28939b5ab78&source=-----f393206c6626----2-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----a18df7e2e027----2---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&source=-----a18df7e2e027----2-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Angel Das"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "Generating Word Embeddings from Text Data using Skip-Gram Algorithm and Deep Learning in PythonIntroduction to embeddings in natural language processing using Artificial Neural Network and Gensim"}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": "\u00b713 min read\u00b7Nov 9, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8873b225ab6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6&user=Angel+Das&userId=8418ab50405a&source=-----a8873b225ab6----3-----------------clap_footer----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6?source=read_next_recirc-----a18df7e2e027----3---------------------0c323d63_3c59_46f6_9d79_ce94de6ba64e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8873b225ab6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-word-embeddings-from-text-data-using-skip-gram-algorithm-and-deep-learning-in-python-a8873b225ab6&source=-----a18df7e2e027----3-----------------bookmark_preview----0c323d63_3c59_46f6_9d79_ce94de6ba64e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----a18df7e2e027--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}