{"url": "https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6", "time": 1683003070.649716, "path": "towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6/", "webpage": {"metadata": {"title": "A small timing experiment on the new Tokenizers library \u2014 a write-up | by Steven van de Graaf | Towards Data Science", "h1": "A small timing experiment on the new Tokenizers library \u2014 a write-up", "description": "A little over a week ago, the lovely people at Hugging Face released their new Tokenizers library to the public. Written in the Rust programming language (known for its performance a.o. when compared\u2026"}, "outgoing_paragraph_urls": [{"url": "https://huggingface.co/", "anchor_text": "Hugging Face", "paragraph_index": 0}, {"url": "https://github.com/huggingface/tokenizers", "anchor_text": "Tokenizers library", "paragraph_index": 0}, {"url": "https://www.rust-lang.org/", "anchor_text": "Rust", "paragraph_index": 0}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT", "paragraph_index": 1}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformers library", "paragraph_index": 2}, {"url": "https://docs.python.org/3.7/library/concurrent.futures.html", "anchor_text": "concurrent.futures", "paragraph_index": 4}], "all_paragraphs": ["A little over a week ago, the lovely people at Hugging Face released their new Tokenizers library to the public. Written in the Rust programming language (known for its performance a.o. when compared to Python), Tokenizers provides \u201can implementation of today\u2019s most used tokenizers, with a focus on performance and versatility\u201d.", "As such, this write-up presents the results of some small timing experiments, which contrast and compare the different implementations of the WordPiece tokenizer, as introduced by Wu et al. (2016) and popularized with the release and publication of BERT by Devlin et al. (2018). All of the code relating to these timing experiments can be found in the Jupyter Notebook below:", "In this first timing experiment, I compared the performance (in terms of execution time) of the Bert WordPiece tokenizer as implemented in the popular Transformers library (also by Hugging Face) to that of the new Tokenizers library. For both, I tokenized (encoded) 1 million English-language sentences over 5 independent runs, the results of which can be found below:", "As you can see, with a mean execution time of just 45.6 seconds, the Tokenizers library implementation presents an almost 9x speed-up as compared directly to the Transformers library implementation (with a mean execution time of 6 minutes and 42 seconds).", "Tokenizers also provides a method to encode multiple sentences at once (in batches), which can significantly improve performance, due to its multithreaded implementation (in Rust). Python also supports multithreading, however, for example using concurrent.futures.", "As such, similarly to the first timing experiment, here I compared the performance of the Bert WordPiece tokenizer using concurrent.futures.ThreadPoolExecutor with submit and map, as well as Tokenizers\u2019 native encode_batch, the results of which can be found below:", "As you can see, surprisingly both submit and map have (equal) worse performance when compared to non-multithreaded tokenization. What is even more interesting (and impressive) however, is that the multithreaded encode_batch that is native to the Tokenizers library takes only 10.6 seconds to tokenize 1 million sentences!", "As advertised, the new Tokenizers library by Hugging Face provides a significantly (almost 9x) faster BERT WordPiece tokenizer implementation than that in the Transformers library. When tokenizing sentences in batches, however, the performance is even more impressive, as it takes only 10.6 seconds to tokenize 1 million sentences. As such, I think I can safely conclude that it\u2019s blazingly fast \ud83d\udd25!", "While the new Tokenizers library provides more benefits than just its impressive performance (e.g. the ability to train a tokenizer on a new vocabulary), it should be said that this significant increase in performance does not only allow for ever larger data sets to be tokenized (on the fly), but it also allows for the better democratization of these methods and techniques (e.g. deployment on cheaper hardware, such as mobile phones and SoCs), allowing aspiring NLP enthusiasts from all backgrounds to get started with the latest and greatest in NLP research. \ud83e\udd17", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Graduate student in Artificial Intelligence @UvA_Amsterdam with multiple years of experience in Python and VBA development."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7caab6f80ea6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sgraaf?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgraaf?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Steven van de Graaf"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2853d5aeff85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&user=Steven+van+de+Graaf&userId=2853d5aeff85&source=post_page-2853d5aeff85----7caab6f80ea6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/huggingface/tokenizers", "anchor_text": "Tokenizers library on GitHub"}, {"url": "https://huggingface.co/", "anchor_text": "Hugging Face"}, {"url": "https://github.com/huggingface/tokenizers", "anchor_text": "Tokenizers library"}, {"url": "https://www.rust-lang.org/", "anchor_text": "Rust"}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "Transformers library"}, {"url": "https://docs.python.org/3.7/library/concurrent.futures.html", "anchor_text": "concurrent.futures"}, {"url": "https://arxiv.org/abs/1609.08144", "anchor_text": "Google\u2019s neural machine translation system: Bridging the gap between human and machine translation"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "Bert: Pre-training of deep bidirectional transformers for language understanding"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7caab6f80ea6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----7caab6f80ea6---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/transformers?source=post_page-----7caab6f80ea6---------------transformers-----------------", "anchor_text": "Transformers"}, {"url": "https://medium.com/tag/tokenization?source=post_page-----7caab6f80ea6---------------tokenization-----------------", "anchor_text": "Tokenization"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7caab6f80ea6---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&user=Steven+van+de+Graaf&userId=2853d5aeff85&source=-----7caab6f80ea6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&user=Steven+van+de+Graaf&userId=2853d5aeff85&source=-----7caab6f80ea6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7caab6f80ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7caab6f80ea6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7caab6f80ea6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgraaf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgraaf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Steven van de Graaf"}, {"url": "https://medium.com/@sgraaf/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "41 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2853d5aeff85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&user=Steven+van+de+Graaf&userId=2853d5aeff85&source=post_page-2853d5aeff85--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F27561262aa3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6&newsletterV3=2853d5aeff85&newsletterV3Id=27561262aa3f&user=Steven+van+de+Graaf&userId=2853d5aeff85&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}