{"url": "https://towardsdatascience.com/human-rights-first-a-data-science-approach-57724b249f32", "time": 1683015604.9131362, "path": "towardsdatascience.com/human-rights-first-a-data-science-approach-57724b249f32/", "webpage": {"metadata": {"title": "Human Rights First: A Data Science Approach | by Daniel Benson | Towards Data Science", "h1": "Human Rights First: A Data Science Approach", "description": "Human Rights First is an independent organization pushing for total human rights and equality within the United States through political brainstorming, creative policy development, various campaigns\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.humanrightsfirst.org/about", "anchor_text": "Human Rights First", "paragraph_index": 0}, {"url": "https://www.linkedin.com/in/daniel-benson-dsaopls/", "anchor_text": "LinkedIn", "paragraph_index": 18}, {"url": "https://twitter.com/DanielbensonPoe", "anchor_text": "Twitter", "paragraph_index": 18}, {"url": "https://github.com/Daniel-Benson-Poe", "anchor_text": "GitHub", "paragraph_index": 18}, {"url": "https://github.com/Lambda-School-Labs/Labs27-C-HRF-DS", "anchor_text": "repository", "paragraph_index": 18}, {"url": "https://main.d17v0exvwwwzgz.amplifyapp.com/", "anchor_text": "deployed landing page", "paragraph_index": 18}, {"url": "https://www.humanrightsfirst.org", "anchor_text": "Human Rights First", "paragraph_index": 18}], "all_paragraphs": ["Human Rights First is an independent organization pushing for total human rights and equality within the United States through political brainstorming, creative policy development, various campaigns, data gathering and research, and mass education. These human rights issues are especially important in today\u2019s world where the frequency of inequality and injustices continue to run rampant. You can find more information and ways to help the Human Rights First organization at their website Human Rights First.", "In a team consisting of one team project lead, five web developers, and three data scientists we worked on a heavily specific subdomain of the Human Rights First organization, police brutality. Our team project lead met weekly with a stakeholder of the organization to gain insight into expectations of the project. Questions were asked such as, \u201cWhat is the user expected to see upon when loading up the landing page\u201d, \u201cWhat interactivity is the user expected to be given\u201d, \u201cWhat kind of data is expected and is precision more important or the number of instances?\u201d The problem was laid out before us: create a website that a user can visit and be met with an interactive choropleth map of the United States allowing visual insights into which states and cities contained incidents of police brutality as well as textual insights through linked articles, videos, etc. with a heavy focus on data precision.", "Each of the teams inherited a GitHub repository for their respective field created by a previous team working on the same project. The Data Science team recieved a repo that included ipython notebooks, app directories and files, a preprocessed baseline predictive model, and .csv files containing pre-collected data. Our approach began by determining the usefulness of this repository\u2019s contents and planning what our own contributions would be.", "Our team began the planning process immediately, spending a week meeting as a full team at least once a day and within our specific field teams several times a day. In our brainstorming sessions we came up with a list of tasks deemed important to the final product. This was followed up by the creation of user stories allowing us valuable insight into the workings of our visualized final product through a user\u2019s eyes. Using a Trello board and an aggregation of creative yet logical thought we settled on a final list of user stories and a sublist of tasks for each. We tackled problems such as, \u201cAs a user, I can see immediately on the landing page, a map of the US with informational data on how many police brutality incidents occur in different states\u201d and \u201cAs a user, I can zoom in to the map enough to view individual incident data\u201d with tasks labeled and sorted by which team/s would need to contribute.", "During the team\u2019s planning stage we worked through a number of brainstorming sessions to hash out sub-lists for each task outlining the technical possibilities for completing them. This included models, libraries, methods, and potential programming canvases we felt that we might need as tools. We implemented these lists into a full-product flowchart, combining each field (DS, Backend, Frontend) through anticipated connections.", "While first approaching the development phase of this project I anticipated two major challenges. The first was in using Natural Language Processing as part of our modeling process as none of us had worked with NLP libraries for several months. This risk was handled accordingly through exploration, research, and inheritance of the previous team\u2019s use of this same method. This allowed us to explore what we did have and modify as needed to fit our own model needs.", "Below is a snippet of code used to tokenize our data.", "The second challenge involved the Data Science team as a whole. We needed to ensure that we were collaborating frequently and effectively to ensure that we were all on the same page regarding the modeling research and development process, time-management of the data collection process, and cleaning the data properly and usefully; the importance of this lay in the fact that each of these tasks is strongly dependent on the success of the previous task. To that end we worked closely five days a week for upwards of eight hours a day ensuring accurate communication. Whenever coding was being done we would meet as a team and pair program, switching out who was driving and who was navigating round-robin style. In this way, we were able to avoid any possible pitfalls that could occur through a lack of teamwork and communication.", "The Data Science side of the project included a number of time consuming features. We began by exploring the notebooks we inherited from the previous team and recreating and modifying their work for a thorough understanding. We asked questions such as, \u201cHow did they go about cleaning up the data?\u201d, \u201cWhat features did they feel were important?\u201d, \u201cWhy these features?\u201d, \u201cWhat parameters did they use to create their model?\u201d, \u201cHow accurate is their model?\u201d. Using these questions as a layout to our exploration, we created new google colab notebooks and recreated the inherited notebooks one by one, putting together tests and making modifications as needed to ensure our thorough understanding. This process included using the Reddit API wrapper PRAW to pull news articles and reddit posts from \u201cnews\u201d subreddits as well as pre-collected data from reddit, twitter, internet sources, and various news sites as well as cleaning up the data and performing some feature engineering as needed.", "Below is the code we used to access the reddit API and pull the top 1000 hottest submissions from the \u201cnews\u201d subreddit; these were then appended to a list called \u201cdata\u201d and used to create a new dataframe:", "Next, we decided to recycle the previous team\u2019s data collection, cleaning and feature engineering but modifying their Natural Language Processing model to include a number of tags that the previous team had left out. We followed this up by putting together our baseline predictive model using TfidVectorizer and a RandomForestClassifier with a RandomizedSearchCV for early parameter tuning. Using these methods we were able to create a csv file we felt comfortable sending over to the web team for use in their baseline choropleth map. The code used to build our model can be found in the embedding below.", "On top of my contributions in the exploration, cleaning, and modeling phases I took the lead in working with the Data Science API. Our project used FastAPI to get the Data Science app created and working and Docker to hold an image of our app for deployment to AWS Elastic Beanstalk. Within my local environment I included the previously mentioned csv file along with a file containing data cleaning and feature engineering methods put together by myself, a fellow team member, and the previous Data Science team. Using this I was able to create two new csv files, one containing the raw final data and the other containing the final data cleaned up and pre-processed for jsonification. This data was converted to a json object before being added to a get endpoint for access by the web team\u2019s back end. The router that was set up to achieve this task can be found in the following embedding:", "One of the major challenges we faced was during the deployment stage of the project. I was able to get the data set up and deployed onto AWS Elastic Beanstalk but several times there was a problem with the jsonification of the data making it unusable for the web team. First, the data was returning with several out-of-place forward slashes \u201c\\\u201d and backslashes \u201c/\u201d. Secondly some of the data features, specifically \u201csrc\u201d and \u201ctags\u201d were being returned as strings instead of arrays. The DS team sat down together in chat to research and brainstorm how to fix this issue. After a number of trial and errors in our deployment we found the preprocessing steps we needed to ensure the data being sent was formatted correctly. The embedded code for this process can be found below:", "As of now our contributions to the product has reached its end. The Data Science team was able to collect, clean, feature engineer, and ship a useable dataset to the web team, including 1177 instances of police brutality across the United States over the last seven months. Each instance sent to the back end included the following features: \u201csrc\u201d \u2014 an array of urls linking to the source videos, articles, and/or posts, this was cleaned up using newspaper3k to extract the correct text \u2014 \u201cstate\u201d \u2014 the state in which the incident occurred, this was engineered using spaCy to extract the state name from the text \u2014 \u201ccity\u201d \u2014 the city in which the incident occurred, this was engineered using spaCy to extract the city name from the text\u2014 \u201cdesc\u201d \u2014 text description of the incident \u2014 \u201ctags\u201d \u2014 the tags used to identify whether the story was a case of police brutality or not, this was engineered using Natural Language Processing \u2014 \u201ctitle\u201d \u2014 a descriptive title of the incident \u2014 \u201cdate\u201d \u2014 the date that the incident occurred \u2014 \u201cid\u201d \u2014 a unique string identifier for each instance \u2014 \u201clat\u201d \u2014 the latitude code to map the location of the incident, this was engineered using the state and city name and a separate csv file listing city, state, and geolocation codes (lat and lon) \u2014 and \u201clong\u201d \u2014 the longitude code to map the location of the incident, this was engineered using the state and city name and a seperate csv file listing city, state, and geolocation codes (lat and lon). Our team was also able to ship a useable API that allowed connection to backend and through them connection to the frontend visualizations. A sample selection of the data being sent to the backend team can be found below:", "The web team was able to use this data and put together a functioning interactive choropleth map of the United States on the landing page. This map shows the user a number of clickable pins that, upon being interacted with, shows the user an information box that includes the title of the incident, the city and state location of the incident, a text description of the incident, and the http sources linking to where the data was collected, where the incident was reported, and any accompanying video and news sources of that incident.", "Upon product completion, there are a number of possible future modifications and feature additions. The Data Science team\u2019s baseline model, while working and deployed, had a tendency to output too many false positives not making it dependable enough for use in an automatic data gathering architect. Future teams can work to improve the model significantly and use and modify the update skeleton that collects new data every 24 hours and uses the model to predict instances of police brutality. For the web side some possible future additions could include an updated and more visually pleasing map, access to more visualizations and data \u2014 this would also involve extra data and possibly seaborn or plotly visualizations shipped by future Data Science teams \u2014 and ability for user to sort the data by dates, locations, etc.", "Throughout this journey I was exposed to a plethora of new and rewarding experiences. I learned the importance of prioritizing planning early on and how to go about this process productively and efficiently both as a team and individually. I learned the banes and boons of pair programming; this project had us pair programming five days a week for four weeks, a span long enough to gain plenty of insights and frustrations. This led me directly to my next and arguably most important learning opportunity: team development and communication; when working on a multidisciplinary project that requires many tasks from many different people, most of which are heavily dependent on the completion of a number of different tasks, working closely as a team to build trust, understanding, and a strong communication system is of the utmost importance. Beyond this I also learned the ins and outs of a number of technical libraries and methods including FastAPI, AWS Elastic Beanstalk, and newspaper3k, and obtained more experience in libraries and methods such as NLP, spaCy, tokenization, RandomForestClassification, RandomSearchCV, APIs such as PRAW and TWEEPY, amongst a number of many others.", "This product and experience is something I will be able to carry with me into the future for the purposes of leaning on to glean insight into future approaches to NLP or Data Engineering problems, invaluable teamwork experience, a reference for my resume, applications, and job interviews, and so much more beyond my current scope of conscious thought.", "My name is Daniel Benson. I am a Data Scientist and aspiring Machine Learning Engineer trained through Lambda School\u2019s Data Science program. I currently hold an Associate\u2019s Degree from Weber State University and am working on finishing up a Bachelor\u2019s Degree in Biology and Neuroscience. If you wish to read more of my work I make an effort to complete at least one blog post a week here on Medium outlining a project that I worked on or am working on. If you wish to contact me I can be found at LinkedIn or Twitter, and for a closer look into my project methods you can also visit my GitHub where I store all of my technical projects. Finally, if you would like to follow the development of this police brutality product you can consult the repository, the deployed landing page, or the Human Rights First website itself. Thank you for following me on this journey, brave reader, and keep an eye out for the next post. Rep it up and happy coding.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a Data Scientist and writer prone to excitement and passion. I look forward to a future I am able to focus those characteristics into work I love."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F57724b249f32&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://danielbensonpoe.medium.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": ""}, {"url": "https://danielbensonpoe.medium.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Daniel Benson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4381b405c4d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&user=Daniel+Benson&userId=4381b405c4d7&source=post_page-4381b405c4d7----57724b249f32---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.humanrightsfirst.org/about", "anchor_text": "Human Rights First"}, {"url": "https://main.d17v0exvwwwzgz.amplifyapp.com", "anchor_text": "Human Rights ConsideredWeb site created using create-react-appmain.d17v0exvwwwzgz.amplifyapp.com"}, {"url": "https://www.linkedin.com/in/daniel-benson-dsaopls/", "anchor_text": "LinkedIn"}, {"url": "https://twitter.com/DanielbensonPoe", "anchor_text": "Twitter"}, {"url": "https://github.com/Daniel-Benson-Poe", "anchor_text": "GitHub"}, {"url": "https://github.com/Lambda-School-Labs/Labs27-C-HRF-DS", "anchor_text": "repository"}, {"url": "https://main.d17v0exvwwwzgz.amplifyapp.com/", "anchor_text": "deployed landing page"}, {"url": "https://www.humanrightsfirst.org", "anchor_text": "Human Rights First"}, {"url": "https://medium.com/tag/data-science?source=post_page-----57724b249f32---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/lambda-school?source=post_page-----57724b249f32---------------lambda_school-----------------", "anchor_text": "Lambda School"}, {"url": "https://medium.com/tag/human-rights?source=post_page-----57724b249f32---------------human_rights-----------------", "anchor_text": "Human Rights"}, {"url": "https://medium.com/tag/the-journey?source=post_page-----57724b249f32---------------the_journey-----------------", "anchor_text": "The Journey"}, {"url": "https://medium.com/tag/police-brutality?source=post_page-----57724b249f32---------------police_brutality-----------------", "anchor_text": "Police Brutality"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&user=Daniel+Benson&userId=4381b405c4d7&source=-----57724b249f32---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&user=Daniel+Benson&userId=4381b405c4d7&source=-----57724b249f32---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F57724b249f32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----57724b249f32---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----57724b249f32--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----57724b249f32--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----57724b249f32--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----57724b249f32--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----57724b249f32--------------------------------", "anchor_text": ""}, {"url": "https://danielbensonpoe.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://danielbensonpoe.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Benson"}, {"url": "https://danielbensonpoe.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "38 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4381b405c4d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&user=Daniel+Benson&userId=4381b405c4d7&source=post_page-4381b405c4d7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F4381b405c4d7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-rights-first-a-data-science-approach-57724b249f32&user=Daniel+Benson&userId=4381b405c4d7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}