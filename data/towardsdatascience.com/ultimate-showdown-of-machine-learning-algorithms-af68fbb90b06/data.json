{"url": "https://towardsdatascience.com/ultimate-showdown-of-machine-learning-algorithms-af68fbb90b06", "time": 1683010631.4485528, "path": "towardsdatascience.com/ultimate-showdown-of-machine-learning-algorithms-af68fbb90b06/", "webpage": {"metadata": {"title": "Final Showdown of Machine Learning Algorithms | by Shubh Patni | Towards Data Science", "h1": "Final Showdown of Machine Learning Algorithms", "description": "It all started with my young cousin, who was lost in his own world, doodling in his drawing book. I asked him what is he doing. He replied he is making a cat; it didn\u2019t look like a cat at all. He\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/quickdraw-doodle-recognition", "anchor_text": "Kaggle competition", "paragraph_index": 1}, {"url": "https://medium.com/u/840a3210fbe7?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Tony Yiu", "paragraph_index": 7}, {"url": "https://medium.com/u/31b07253bc35?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Renu Khandelwal", "paragraph_index": 9}, {"url": "https://medium.com/u/4f5e144c000d?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Jorge Leonel", "paragraph_index": 11}, {"url": "https://medium.com/u/61966d0f938f?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Nagesh Singh Chauhan", "paragraph_index": 13}, {"url": "https://medium.com/u/aff72a0c1243?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Sik-Ho Tsang", "paragraph_index": 15}, {"url": "https://www.kaggle.com/c/quickdraw-doodle-recognition", "anchor_text": "the Kaggle quickdraw dataset", "paragraph_index": 17}, {"url": "https://medium.com/u/75bc9075b8c4?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Shashwat Tiwari 16MCA0068", "paragraph_index": 18}, {"url": "https://medium.com/u/1ac480820908?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Shervin Minaee", "paragraph_index": 19}, {"url": "https://www.youtube.com/watch?v=HD9FnjVwU8g", "anchor_text": "Mobile net Research Paper Walkthrough (YouTube)", "paragraph_index": 48}, {"url": "https://y.at/\ud83d\udcbb\ud83c\udfa5\u270d\ufe0f\u2615", "anchor_text": "https://y.at/\ud83d\udcbb\ud83c\udfa5\u270d\ufe0f\u2615", "paragraph_index": 50}], "all_paragraphs": ["It all started with my young cousin, who was lost in his own world, doodling in his drawing book. I asked him what is he doing. He replied he is making a cat; it didn\u2019t look like a cat at all. He asked me to play a game with him in which I would recognize what he is drawing. It was fun for some time, but soon, I got bored. I didn\u2019t want to hurt his feelings by not playing with him, so I used my computer vision and python skills to make a doodle classifier. Now the question was how will I implement it; There are hundreds of methods to classify a doodle, and I had to pick the most accurate one, which takes the least amount of time to train, occupies less memory, requires less processing power, and doesn\u2019t require TB\u2019s of data to give meaningful results.", "After some web surfing, I found the top 5 algorithms that can complete this task in the best way possible, but each website I visited told a different story. Some were saying CNN is the best, while others said mobile-net is best. I thought \u2014 well, let\u2019s test out all of them. I found a great dataset containing lots of doodles with their labels in a Kaggle competition available for free to download.", "Image classification is a vast topic as there are tons of algorithms available to use for various applications. Image classification is so vast and ever-changing that every day new algorithms are being created and new applications of it are emerging. Thus, it was difficult for me to handpick a few algorithms given that even they have hundreds of variations. So, this post will investigate which algorithm performs best for doodle classification specifically.", "I will also test how reliable these algorithms are in other situations such as handwritten character classification, number plate recognition, etc.", "There are thousands of algorithms for doodle classification, here I have shortlisted a few famous ones which I will explore -", "We can use the random forest algorithm for both classification and regression. It is like decision trees, except it uses hundreds of decision trees to come up to a conclusion. A decision tree separates data into various classes based on similar features. For each data point, it checks if it has a certain feature, most common data falls under the same class. In the random forest algorithm, we take many decision trees and randomly give them fewer features to check from, ex if we have 100 features, we might give 10 random features to each tree. Some trees will assign incorrect classes, but many will be right! We take the majority and create our classification model.", "Research paper on random forest algorithm:", "A great article on random forest algorithm by Tony Yiu:", "K-nearest neighbors (KNN) can be used both as a classification and a regression algorithm. In KNN, data points are separated into several classes to predict the classification of a new sample point. To achieve this task, it uses distance formula to calculate distances between various data points, based on this distance, it then defines region boundaries for each class. Any new data point will fall into one of these regions and will be assigned that class.", "A great article on KNN by Renu Khandelwal:", "Multi-layer perception (MLP) is a form of feed-forward artificial neural network. MLP has many layers, but only a logistic function in its hidden layers and a softmax function at the output layer. The algorithm takes in a single big vector as input and performs matrix operations on the input layer and hidden layers, then the result goes through a logistic function, and its output goes through another hidden layer. This process is repeated until the network reaches the output layer, where a single output is produced using the softmax function.", "A great article on MLP by Jorge Leonel:", "Convolution neural networks (CNN) is one of the easiest to implement deep learning computer vision algorithm. First, it takes an input image of a given size and creates multiple filters/feature detectors (which is initially a randomly generated matrix of the given size) for it, a filter aims to recognize certain patterns in an image, the filter is moved across the image and matrix multiplication is done between the matrix and the image. This filter slides throughout the image to gather more features, we then use an activation function mostly a rectified linear unit function to increase non-linearity or preserve only important features, then we use max-pooling function to add up all the values in a given matrix size (ex- if we choose a matrix of 4 then it will add all the 4 values to create 1 value), thus reducing the size of our output to make it faster. The last step is to flatten the final matrix which is passed as input to a basic ANN (artificial neural network) and get class predictions.", "A great article on CNN by Nagesh Singh Chauhan:", "Mobile-Net architecture uses depth-wise separable convolution, which comprises a depth-wise convolution and a point-wise convolution. Depth wise convolution is a channel-wise Dk * Dk spatial convolution, suppose we have 3 channels (R, G, B) in an image then we will have 3*Dk*Dk spatial convolution. In point-wise convolution we have kernel size of 1*1*M, where M is the number of channels in depth wise convolution, in this case, it\u2019s 3. Therefore, we have one kernel of size 1*1*3; we iterate this one kernel through our 3*Dk*Dk output to get Dk*Dk*1 output. We can create N 1*1*3 kernels that output a Dk*Dk*1 image each, to get a final image of shape Dk*Dk*N. The final step is to add depth wise convolution to pointwise convolution. This type of architecture reduces training time as we have lesser parameters to tune while having a minor effect on accuracy.", "A great article on Mobile-net by Sik-Ho Tsang:", "Above are the samples of doodles used for this research.", "I trained my machine learning models on the Kaggle quickdraw dataset that comprises 50 million images of different types of doodles. I divided this huge dataset into two parts: 35000 images for training, and 15000 for testing. I then calculated the training time for each algorithm on randomly chosen 5 different types of doodles. On the test set, I calculated mean average precision, accuracy, and recall for each algorithm.", "More on Evaluation Metrics by Shashwat Tiwari 16MCA0068", "Also, a good post by Shervin Minaee", "max_features \u2014 Features to be considered while splitting [\u2018auto\u2019,\u2019sqrt\u2019]", "n_jobs \u2014 number of processes running in parallel, usually set as -1 to do maximum processes at a time.", "criterion \u2014 it is a way to calculate loss and thus update the model to make the loss lesser and lesser. [\u2018entropy\u2019,\u2019cross_validation\u2019]", "I used \u2018auto\u2019 as the max_feature; 8 as the max_depth; -1 as n_jobs and \u2018entropy\u2019 as my criterion because they usually give the best results.", "However, to find out the optimal number of trees, I used GridSearchCV. It tries all the given parameter combinations and creates a table to show results. As can be seen from the figure, there is no significant increase in the test score after 80 trees. Thus, I decided to train my classifier on 80 trees.", "n_neighbors \u2014 number of nearest data points to compare [2,5,8]", "n_jobs \u2014 number of processes running in parallel, usually set as -1 to do maximum processes at a time", "I did not change any default parameters for this model because they would give the best result.", "However, to find the optimum number of n_neighbors, I have used GridSearchCV, and this is the graph I got:", "According to the graph, the test score declines after 5 n_neighbors, which means 5 is the optimum number of neighbors.", "activation \u2014 A function which provides value to important characteristics in an image and deletes the irrelevant information. [\u2018relu\u2019,\u2019tanh\u2019,\u2019logistic\u2019].", "solver \u2014 Also known as the optimizer, this parameter tells the network which technique to use for training the weights in a network. [\u2018sgd\u2019,\u2019adam\u2019].", "I have chosen activation as \u2018relu\u2019 and solver as \u2018adam\u2019 because these parameters give the best result.", "However, to choose the number of hidden layers and alpha, I have used GridSearchCV.", "As can be seen in the table the best result is received when alpha is 0.001, and hidden_layer_size is (784,784). Therefore, I decided to use those parameters.", "activation \u2014 A function which provides value to important characteristics in an image and deletes the irrelevant information. [\u2018relu\u2019,\u2019tanh\u2019,\u2019logistic\u2019].", "solver \u2014 Also known as the optimizer, this parameter tells the network which technique to use for training the weights in a network. [\u2018sgd\u2019,\u2019adam\u2019].", "Epochs \u2014 Number of times the program should run or how many times the model should be trained. [10,20,200]", "I have chosen activation function as \u2018relu\u2019 and solver as \u2018adam\u2019 because these parameters usually give the best results. In the network, I have added 3 convolution layers, 2 maxpool layers, 3 dropout layers, and at the end one softmax activation function. I did not use GridSearchCV here because there can be a lot of possible combinations that can be tried out, but there won\u2019t be much difference in the results.", "activation \u2014 A function which provides value to important characteristics in an image and deletes the irrelevant information. [\u2018relu\u2019,\u2019tanh\u2019,\u2019logistic\u2019].", "optimizer \u2014 Also known as the solver, this parameter tells the network which technique to use for training the weights in a network. [\u2018sgd\u2019,\u2019adam\u2019].", "batch_size \u2014 It is the number of images to be processed at once. [200,100,200]. Epochs \u2014 Number of times the program should run or how many times the model should be trained. [10,20,200]", "loss- It tells the network which method to use to calculate the loss i.e. the difference between the predicted and actual value. [\u2018categorical_crossentropy\u2019, \u2018RMSE\u2019]", "First, I resized the 28*28 images to 140*140 images, as the mobile net requires a minimum of 32*32 images, so the final input_shape value I used was (140,140,1), where 1 is the image channel (in this case, black and white). I set alpha to 1 because it usually gives the best results. The activation function was set to default, which is \u2018relu\u2019. I have used \u2018Adadelta\u2019 optimizer as it gave the best results. batch_size was set to 128 to train the model faster. I have used 20 epochs for better accuracy. Classes were set to 5 as we have 5 classes to classify.", "Above is the performance of all the machine learning techniques used. Metrics include accuracy, recall, precision, and training time. It shocked me to see the training time of Mobile Net to be 46 minutes, as it is considered as a light model. I am not sure why that is the case, if you know why please let me know.", "Results suggest that mobile-net achieved the highest accuracy, precision, and recall therefore it is the best algorithm in terms of these three parameters. However, the training time for mobile-net is also the highest. If we compare it with CNN, we can see that CNN took much lesser time to train, giving similar accuracy, precision, and recall. Therefore, according to this research, I would conclude that CNN is the best algorithm.", "After doing this research, I conclude that algorithms like mobile-net and CNN can be used for hard-written character recognition, number-plate detection and in banks around the world. Algorithms, such as mobile-net and CNN, achieved an accuracy of over 97% which is better than average human performance of 95%. Thus, these algorithms can be used in real life, making harder or time- consuming processes automated.", "You can find the code here:", "Mobile net Research Paper Walkthrough (YouTube)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Programmer | Youtuber | Writer and Student at Northeastern University. Socials- https://y.at/\ud83d\udcbb\ud83c\udfa5\u270d\ufe0f\u2615"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faf68fbb90b06&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://shubhpatni.medium.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": ""}, {"url": "https://shubhpatni.medium.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Shubh Patni"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3762dfaaa71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&user=Shubh+Patni&userId=a3762dfaaa71&source=post_page-a3762dfaaa71----af68fbb90b06---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jaimespaniol?utm_source=medium&utm_medium=referral", "anchor_text": "Jaime Spaniol"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://giphy.com/gifs/entourage-true-story-ari-gold-FotjY3LFxjFrW", "anchor_text": "Giphy"}, {"url": "https://www.kaggle.com/c/quickdraw-doodle-recognition", "anchor_text": "Kaggle competition"}, {"url": "https://giphy.com/search/machine-learning", "anchor_text": "Giphy"}, {"url": "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf", "anchor_text": "Leo Breiman"}, {"url": "https://medium.com/u/840a3210fbe7?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2", "anchor_text": "Understanding Random ForestHow the Algorithm Works and Why it Is So Effectivetowardsdatascience.com"}, {"url": "https://www.researchgate.net/profile/Gongde_Guo", "anchor_text": "Gongde Guo"}, {"url": "https://medium.com/u/31b07253bc35?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Renu Khandelwal"}, {"url": "https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7", "anchor_text": "K-Nearest Neighbors(KNN)In this article we will understand what is K-nearest neighbors, how does this algorithm work, what are the pros and\u2026medium.com"}, {"url": "https://www.researchgate.net/profile/Popescu_Marius", "anchor_text": "Popescu Marius"}, {"url": "https://medium.com/u/4f5e144c000d?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Jorge Leonel"}, {"url": "https://medium.com/@jorgesleonel/multilayer-perceptron-6c5db6a8dfa3", "anchor_text": "Multilayer PerceptronWe've seen here that the Perceptron, that neural network whose name evokes how the future looked from the perspective\u2026medium.com"}, {"url": "https://www.researchgate.net/profile/Keiron_Oshea", "anchor_text": "Keiron Teilo O\u2019Shea"}, {"url": "https://medium.com/u/61966d0f938f?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Nagesh Singh Chauhan"}, {"url": "https://levelup.gitconnected.com/introduction-to-convolutional-neural-networks-cnn-1ee504bc20c3", "anchor_text": "Introduction to Convolutional Neural Networks(CNN)The article focus on all the concepts related to CNN and its implementation using Keras python library.levelup.gitconnected.com"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Howard%2C+A+G", "anchor_text": "Andrew G. Howard"}, {"url": "https://medium.com/u/aff72a0c1243?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Sik-Ho Tsang"}, {"url": "https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69", "anchor_text": "Review: MobileNetV1 \u2014 Depthwise Separable Convolution (Light Weight Model)In this story, MobileNetV1 from Google is reviewed. Depthwise Separable Convolution is used to reduce the model size\u2026towardsdatascience.com"}, {"url": "https://www.kaggle.com/c/quickdraw-doodle-recognition", "anchor_text": "the Kaggle quickdraw dataset"}, {"url": "https://medium.com/u/75bc9075b8c4?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Shashwat Tiwari 16MCA0068"}, {"url": "https://medium.com/analytics-vidhya/complete-guide-to-machine-learning-evaluation-metrics-615c2864d916", "anchor_text": "Complete Guide to Machine Learning Evaluation MetricsDive in to Explore!medium.com"}, {"url": "https://medium.com/u/1ac480820908?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Shervin Minaee"}, {"url": "https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce", "anchor_text": "20 Popular Machine Learning Metrics. Part 1: Classification & Regression Evaluation MetricsAn introduction to the most important metrics for evaluating classification, regression, ranking, vision, NLP, and deep\u2026towardsdatascience.com"}, {"url": "https://giphy.com/gifs/doctor-strange-WPtzThAErhBG5oXLeS", "anchor_text": "Giphy"}, {"url": "https://giphy.com/gifs/nervous-spongebob-sqaurepants-biting-nails-DUuyU3KyYGLNS", "anchor_text": "Giphy"}, {"url": "https://colab.research.google.com/drive/1aefccgDjDIPW6RVImtFG5fAlaI91ysbg?usp=sharing", "anchor_text": "Google ColaboratoryEdit descriptioncolab.research.google.com"}, {"url": "https://www.youtube.com/watch?v=HD9FnjVwU8g", "anchor_text": "Mobile net Research Paper Walkthrough (YouTube)"}, {"url": "https://www.youtube.com/watch?v=T7o3xvJLuHk", "anchor_text": "Depthwise Seperable Convolution"}, {"url": "https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce", "anchor_text": "20 Popular Machine Learning Metrics. Part 1: Classification & Regression Evaluation MetricsAn introduction to the most important metrics for evaluating classification, regression, ranking, vision, NLP, and deep\u2026towardsdatascience.com"}, {"url": "https://levelup.gitconnected.com/introduction-to-convolutional-neural-networks-cnn-1ee504bc20c3", "anchor_text": "Introduction to Convolutional Neural Networks(CNN)The article focus on all the concepts related to CNN and its implementation using Keras python library.levelup.gitconnected.com"}, {"url": "https://towardsdatascience.com/doodling-with-deep-learning-1b0e11b858aa", "anchor_text": "Doodling with Deep Learning!Our Journey with Sketch recognitiontowardsdatascience.com"}, {"url": "https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7", "anchor_text": "K-Nearest Neighbors(KNN)In this article we will understand what is K-nearest neighbors, how does this algorithm work, what are the pros and\u2026medium.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----af68fbb90b06---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----af68fbb90b06---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----af68fbb90b06---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----af68fbb90b06---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/software-development?source=post_page-----af68fbb90b06---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&user=Shubh+Patni&userId=a3762dfaaa71&source=-----af68fbb90b06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&user=Shubh+Patni&userId=a3762dfaaa71&source=-----af68fbb90b06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faf68fbb90b06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----af68fbb90b06---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----af68fbb90b06--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----af68fbb90b06--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----af68fbb90b06--------------------------------", "anchor_text": ""}, {"url": "https://shubhpatni.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://shubhpatni.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shubh Patni"}, {"url": "https://shubhpatni.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "437 Followers"}, {"url": "https://y.at/\ud83d\udcbb\ud83c\udfa5\u270d\ufe0f\u2615", "anchor_text": "https://y.at/\ud83d\udcbb\ud83c\udfa5\u270d\ufe0f\u2615"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3762dfaaa71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&user=Shubh+Patni&userId=a3762dfaaa71&source=post_page-a3762dfaaa71--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8c93b7847863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-showdown-of-machine-learning-algorithms-af68fbb90b06&newsletterV3=a3762dfaaa71&newsletterV3Id=8c93b7847863&user=Shubh+Patni&userId=a3762dfaaa71&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}