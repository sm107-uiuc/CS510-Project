{"url": "https://towardsdatascience.com/the-complete-guide-to-auc-and-average-precision-cf1d4647efc3", "time": 1683010910.952959, "path": "towardsdatascience.com/the-complete-guide-to-auc-and-average-precision-cf1d4647efc3/", "webpage": {"metadata": {"title": "The Complete Guide to AUC and Average Precision | by Rachel Draelos, MD, PhD | Towards Data Science", "h1": "The Complete Guide to AUC and Average Precision", "description": "This post offers the clearest explanation on the web for how the popular metrics AUC (AUROC) and average precision can be used to understand how a classifier performs on balanced data, with the next\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/rachellea/glassboxmedicine/tree/master/2020-07-14-AUROC-AP", "anchor_text": "GitHub", "paragraph_index": 0}, {"url": "https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/", "anchor_text": "this post", "paragraph_index": 3}, {"url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "anchor_text": "this post", "paragraph_index": 5}, {"url": "https://glassboxmedicine.com/2019/02/17/measuring-performance-the-confusion-matrix/", "anchor_text": "this post", "paragraph_index": 8}, {"url": "https://github.com/rachellea/glassboxmedicine/tree/master/2020-07-14-AUROC-AP", "anchor_text": "GitHub", "paragraph_index": 10}], "all_paragraphs": ["This post offers the clearest explanation on the web for how the popular metrics AUC (AUROC) and average precision can be used to understand how a classifier performs on balanced data, with the next post focusing on imbalanced data. This post includes numerous simulations and AUROC/average precision plots for classifiers with different properties. All code to replicate the plots and simulations is provided on GitHub.", "First, here is a brief intro to AUROC and average precision:", "The AUROC indicates whether your model can correctly rank examples. The AUROC is the probability that a randomly selected positive example has a higher predicted probability of being positive than a randomly selected negative example. The AUROC is calculated as the area underneath a curve that measures the trade off between true positive rate (TPR) and false positive rate (FPR) at different decision thresholds d:", "A random classifier (e.g. a coin toss) has an AUROC of 0.5, while a perfect classifier has an AUROC of 1.0. For more details about the AUROC, see this post.", "Average precision indicates whether your model can correctly identify all the positive examples without accidentally marking too many negative examples as positive. Thus, average precision is high when your model can correctly handle positives. Average precision is calculated as the area under a curve that measures the trade off between precision and recall at different decision thresholds:", "A random classifier (e.g. a coin toss) has an average precision equal to the percentage of positives in the class, e.g. 0.12 if there are 12% positive examples in the class. A perfect classifier has an average precision of 1.0. For more details about average precision, see this post.", "In the simulations, I generate a ground truth vector indicating the true label for a series of examples (e.g. [0,0,1] for three examples that are [negative, negative, positive]) and a prediction vector indicating a hypothetical model\u2019s predictions on that series of examples (e.g. [0.1,0.25,0.99]).", "I generate the ground truth and predictions so that there are differing numbers of true positive, false positives, true negatives, and false negatives:", "For a more detailed review of confusion matrices, see this post.", "The simulated model results in this post were created relative to an assumed decision threshold of 0.5. For example, to create true positives from an assumed decision threshold of 0.5, I uniformly sampled prediction values between 0.5001 and 1.0, and marked the ground truth as 1 for each sampled value. Note that a decision threshold of 0.5 was used only for simulating the ground truth and prediction vectors. The AUROC and average precision are calculated with a sliding decision threshold, following their definitions.", "All code to replicate the results and figures in this post can be found on GitHub.", "Let\u2019s look at plots of the AUROC and average precision on a balanced data set, i.e. a data set for which the number of actual positives and the number of actual negatives is equal.", "In the figure above for \u201cModelBalanced\u201d the left plot (red) shows the receiver operating characteristic (ROC), with the title reporting the area under the ROC, or AUROC, in this case, 0.48.", "The right plot (blue) shows the precision-recall curve, with the title reporting the area under the precision recall curve (AUPRC) calculated using the average precision method.", "Here, the AUROC is ~0.5, the baseline, and the average precision is also ~0.5, the baseline since the fraction of positives is 0.50. The values are not exactly 0.500 because of the random uniform sampling involved in the simulation. \u201cModelBalanced\u201d means that the model isn\u2019t skewed towards making positive or negative predictions, and also isn\u2019t skewed towards making correct predictions. In other words, this is a random, useless model equivalent to a coin toss.", "Additionally, I show the points on the curves where the decision threshold is equal to 0.9, 0.5, and 0.1. These points are labeled d = 0.9, d = 0.5, and d = 0.1. We can see that the decision threshold goes from 1 to 0 as we sweep from left to right. The curves themselves are relatively smooth because they were created using numerous decision thresholds; only 3 decision thresholds are explicitly shown as dots to emphasize properties of the curves.", "In \u201cModelPredBad\u201d the model is skewed towards making bad predictions, i.e. it tends to get the wrong answer and has high false negatives and high false positives. Notice that here, the AUROC and average precision are both below the baseline. This illustrates an interesting fact about classifiers \u2014 in practice if you have a model that is \u201cexpertly bad\u201d then you can just flip the classification decision and get a model that is good. If we flipped all of the classification decisions here, we could get a model with 1.0\u20130.11 = 0.89 AUROC. That is why the baseline for AUROC is always 0.5; if we have a classifier with AUROC below 0.5 we flip its decisions and get a better classifier with an AUROC between 0.5 and 1.0.", "The \u201celbow\u201d in the AUROC and average precision plots at d = 0.5 is due to the way the simulated results were created relative to a decision threshold of d = 0.5.", "In \u201cModelPredGood\u201d we have a good model that produces a lot of true positives and true negatives. We can see that the AUROC and average precision are both high.", "In \u201cModelPredNeg(HighTN,HighFN)\u201d we have balanced data and a model that is biased towards predicting negatives. Although it predicts more negatives in total, it predicts the same number of true negatives as false negatives. Because tp == fp and tn == fn, the AUROC and average precision are once again around their baseline values of 0.5, meaning that this is a useless model.", "We can confirm this by considering the formulas for TPR (true positive rate, recall), FPR (false positive rate), and precision. Since we have tp == fp, we can call this value a, i.e. tp == fp == a. Since we have tn == fn, we can call this value b, i.e. tn == fn == b. Then we can write:", "For AUROC: TPR = tp/(tp+fn) = a/(a+b), and FPR = fp/(fp+tn) = a/(a+b). Thus, TPR and FPR are always equal to each other, meaning that the ROC is a straight line at y = x, meaning that the AUROC is 0.5.", "For average precision: precision = tp/(tp+fp) = a/(a+a) = 1/2, and from before, TPR = recall = tp/(tp+fn) = a/(a+b). Thus, regardless of what the value of the recall is, the precision is always about 1/2, and so we get an area under the PR curve of 0.5.", "In \u201cModelPredPos(HighTP,HighFP)\u201d we can see the same effect as we saw in \u201cModelPredNeg(HighTN,HighFN)\u201d. This model is biased towards predicting positives, but although it predicts a larger number of positives in total, it predicts the same number of true positives as false positives, and so it is a useless model with AUROC and average precision at their baseline values.", "It is also interesting to look at the points on the curves corresponding to d = 0.9, 0.5, and 0.1. Here, when the model tends to predict positives, the points for d=0.5 and d=0.1 are squished closer together. Immediately above, in \u201cDataBalanced/ModelPredNeg\u201d we instead have d=0.5 squished closer to d=0.9.", "In \u201cModelPredGoodTN(HighTN)\u201d the model is particularly good at identifying true negatives. This produces better-than-random AUROC and better-than-random average precision.", "In the ROC plot (red), we see that the decision thresholds d = 0.9 to d = 0.5 span a small interval of FPR = fp/(fp+tn). This is because for these high decision thresholds, the fps are especially low and the tns are especially high, which produces a small FPR.", "Note that the average precision is not explicitly improved by the number of true negatives, because true negatives aren\u2019t used in the calculation of average precision. The average precision is improved by the decrease in false positives that occurs because some examples were shifted from being false positives to true negatives, which was required in order to keep the assumption that the dataset is balanced. Precision = tp/(tp+fp), so when we make the fp smaller, we increase the precision. Also, precision tends to be highest when the decision threshold is highest (the left side of the plot) because the higher the decision threshold, the more stringent the requirement for being marked positive, which in general increases tps and lowers fps.", "In \u201cModelPredBadFP(HighFP)\u201d the model produces a lot of false positives. Once again because this model is \u201cstrategically bad\u201d we could get a good model out of it by flipping its classification decisions. If we flipped its classification decisions, then the FPs would become TNs, and we would have a model biased towards predicting TNs \u2014 the exact model shown above in \u201cModelPredGoodTN(HighTN)\u201d.", "This is our second-to-last figure. In \u201cModelPredGoodTP(HighTP)\u201d the model produces a lot of true positives. This leads to a better-than-random AUROC and a better-than-random average precision.", "Notice how this ROC is peaked more towards the top, whereas in \u201cModelPredGoodTN(HighTN)\u201d the ROC curve is peaked more towards the bottom. The ROC here is peaked more towards the top because a small range of TPR=tp/(tp+fn) is covered by the lower decision thresholds d = 0.5 to d = 0.1. That is because when the decision thresholds are low, in this tp-biased model we end up with a lot of tps and few fns, creating high recall across these various lower decision thresholds. The \u201celbow\u201d being present at d = 0.5 is because of the way the synthetic results were generated relative to a decision threshold of 0.5.", "This is the final plot. \u201cModelPredBadFN(HighFN)\u201d shows plots for a model that produces a particularly large number of false negatives. If we flipped this bad model\u2019s classification decisions, all of the FNs would become TPs, and we would get the good model shown above as \u201cModelPredGoodTP(HighTP)\u201d.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a physician with a PhD in Computer Science. My research focuses on machine learning methods development for medical data. I am the CEO of Cydoc."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcf1d4647efc3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----cf1d4647efc3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/rachellea/glassboxmedicine/tree/master/2020-07-14-AUROC-AP", "anchor_text": "GitHub"}, {"url": "https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/", "anchor_text": "this post"}, {"url": "https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/", "anchor_text": "this post"}, {"url": "https://glassboxmedicine.com/2019/02/17/measuring-performance-the-confusion-matrix/", "anchor_text": "this post"}, {"url": "https://github.com/rachellea/glassboxmedicine/tree/master/2020-07-14-AUROC-AP", "anchor_text": "GitHub"}, {"url": "https://glassboxmedicine.com/2020/07/14/the-complete-guide-to-auc-and-average-precision-simulations-and-visualizations/", "anchor_text": "http://glassboxmedicine.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----cf1d4647efc3---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cf1d4647efc3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----cf1d4647efc3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----cf1d4647efc3---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----cf1d4647efc3---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----cf1d4647efc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----cf1d4647efc3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcf1d4647efc3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cf1d4647efc3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cf1d4647efc3--------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://rachel-draelos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rachel Draelos, MD, PhD"}, {"url": "https://rachel-draelos.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "576 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa0377bd1bf3d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-auc-and-average-precision-cf1d4647efc3&newsletterV3=209c0f742bcf&newsletterV3Id=a0377bd1bf3d&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}