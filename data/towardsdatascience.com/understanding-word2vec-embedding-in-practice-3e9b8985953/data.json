{"url": "https://towardsdatascience.com/understanding-word2vec-embedding-in-practice-3e9b8985953", "time": 1683001758.265462, "path": "towardsdatascience.com/understanding-word2vec-embedding-in-practice-3e9b8985953/", "webpage": {"metadata": {"title": "Understanding Word2vec Embedding in Practice | by Susan Li | Towards Data Science", "h1": "Understanding Word2vec Embedding in Practice", "description": "This post aims to explain the concept of Word2vec and the mathematics behind the concept in an intuitive way while implementing Word2vec embedding using Gensim in Python. The basic idea of Word2vec\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2vec", "paragraph_index": 0}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "Gensim", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "countvectorizer", "paragraph_index": 1}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html", "anchor_text": "tfidfvectorizer", "paragraph_index": 1}, {"url": "https://www.tensorflow.org/tutorials/text/word_embeddings", "anchor_text": "Tensorflow / Keras", "paragraph_index": 8}, {"url": "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html", "anchor_text": "Pytorch", "paragraph_index": 8}, {"url": "https://raw.githubusercontent.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/master/bbc-text.csv", "anchor_text": "BBC news data set", "paragraph_index": 9}, {"url": "https://github.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/blob/master/Word2vec%20BBC%20news.ipynb", "anchor_text": "Jupyter notebook", "paragraph_index": 11}, {"url": "https://github.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/blob/master/Word2vec%20BBC%20news.ipynb", "anchor_text": "Github", "paragraph_index": 11}, {"url": "https://www.linkedin.com/in/susanli/", "anchor_text": "https://www.linkedin.com/in/susanli/", "paragraph_index": 13}], "all_paragraphs": ["This post aims to explain the concept of Word2vec and the mathematics behind the concept in an intuitive way while implementing Word2vec embedding using Gensim in Python.", "The basic idea of Word2vec is that instead of representing words as one-hot encoding (countvectorizer / tfidfvectorizer) in high dimensional space, we represent words in dense low dimensional space in a way that similar words get similar word vectors, so they are mapped to nearby points.", "Word2vec is not deep neural network, it turns text into a numeric form that deep neural network can process as input.", "For example, we can use \u201cartificial\u201d to predict \u201cintelligence\u201d.", "However, the prediction itself is not our goal. It is a proxy to learn vector representations so that we can use it for other tasks.", "This is one of word2vec models architectures. It is just a simple one hidden layer and one output layer.", "The following is the math behind word2vec embedding. The input layer is the one-hot encoded vectors, so it gets \u201c1\u201d in that word index, \u201c0\u201d everywhere else. When we multiply this input vector by weight matrix, we are actually pulling out one row that is corresponding to that word index. The objective here is to pull out the important row(s), then, we toss the rest.", "This is the main mechanics on how word2vec works.", "When we use Tensorflow / Keras or Pytorch to do this, they have a special layer for this process called \u201cEmbedding layer\u201d. So, we are not going to do math by ourselves, we only need to pass one-hot encoded vectors, the \u201cEmbedding layer\u201d does all the dirty works.", "Now we are going to implement word2vec embedding for a BBC news data set.", "Please note, the above results could change if we change min_count. For example, if we set min_count=100, we will have more words to work with, some of them may be more similar to the target words than the above results; If we set min_count=300, some of the above results may disappear.", "The Jupyter notebook can be found on Github. Enjoy the rest of the week.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Changing the world, one post at a time. Sr Data Scientist, Toronto Canada. https://www.linkedin.com/in/susanli/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3e9b8985953&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://actsusanli.medium.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Susan Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F731d8566944a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&user=Susan+Li&userId=731d8566944a&source=post_page-731d8566944a----3e9b8985953---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "Word2vec"}, {"url": "https://radimrehurek.com/gensim/models/word2vec.html", "anchor_text": "Gensim"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "countvectorizer"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html", "anchor_text": "tfidfvectorizer"}, {"url": "https://www.infoq.com/presentations/nlp-practitioners/?itm_source=presentations_about_Natural-Language-Processing&itm_medium=link&itm_campaign=Natural-Language-Processing", "anchor_text": "https://www.infoq.com/presentations/nlp-practitioners/?itm_source=presentations_about_Natural-Language-Processing&itm_medium=link&itm_campaign=Natural-Language-Processing"}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"}, {"url": "https://www.tensorflow.org/tutorials/text/word_embeddings", "anchor_text": "Tensorflow / Keras"}, {"url": "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html", "anchor_text": "Pytorch"}, {"url": "https://raw.githubusercontent.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/master/bbc-text.csv", "anchor_text": "BBC news data set"}, {"url": "https://github.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/blob/master/Word2vec%20BBC%20news.ipynb", "anchor_text": "Jupyter notebook"}, {"url": "https://github.com/susanli2016/PyCon-Canada-2019-NLP-Tutorial/blob/master/Word2vec%20BBC%20news.ipynb", "anchor_text": "Github"}, {"url": "https://learning.oreilly.com/videos/oreilly-strata-data/9781492050681/9781492050681-video327451?autoplay=false", "anchor_text": "https://learning.oreilly.com/videos/oreilly-strata-data/9781492050681/9781492050681-video327451?autoplay=false"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3e9b8985953---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----3e9b8985953---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/word2vec?source=post_page-----3e9b8985953---------------word2vec-----------------", "anchor_text": "Word2vec"}, {"url": "https://medium.com/tag/nlp-tutorial?source=post_page-----3e9b8985953---------------nlp_tutorial-----------------", "anchor_text": "Nlp Tutorial"}, {"url": "https://medium.com/tag/vector-space-model?source=post_page-----3e9b8985953---------------vector_space_model-----------------", "anchor_text": "Vector Space Model"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&user=Susan+Li&userId=731d8566944a&source=-----3e9b8985953---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&user=Susan+Li&userId=731d8566944a&source=-----3e9b8985953---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3e9b8985953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3e9b8985953---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3e9b8985953--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3e9b8985953--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3e9b8985953--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3e9b8985953--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3e9b8985953--------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://actsusanli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Susan Li"}, {"url": "https://actsusanli.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "27K Followers"}, {"url": "https://www.linkedin.com/in/susanli/", "anchor_text": "https://www.linkedin.com/in/susanli/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F731d8566944a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&user=Susan+Li&userId=731d8566944a&source=post_page-731d8566944a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f2b19329694&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word2vec-embedding-in-practice-3e9b8985953&newsletterV3=731d8566944a&newsletterV3Id=1f2b19329694&user=Susan+Li&userId=731d8566944a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}