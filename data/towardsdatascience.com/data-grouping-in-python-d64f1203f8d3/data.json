{"url": "https://towardsdatascience.com/data-grouping-in-python-d64f1203f8d3", "time": 1683016345.153219, "path": "towardsdatascience.com/data-grouping-in-python-d64f1203f8d3/", "webpage": {"metadata": {"title": "Data Grouping in Python. Pandas has groupby function to be able\u2026 | by Jerry Zhang | Towards Data Science", "h1": "Data Grouping in Python", "description": "Grouping records by column(s) is a common need for data analyses. Such scenarios include counting employees in each department of a company, calculating the average salary of male and female\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/analytics-vidhya/how-python-handles-big-files-fc60ff90b819", "anchor_text": "How Python Handles Big Files", "paragraph_index": 79}, {"url": "https://www.linkedin.com/in/witness998", "anchor_text": "https://www.linkedin.com/in/witness998", "paragraph_index": 82}], "all_paragraphs": ["Grouping records by column(s) is a common need for data analyses. Such scenarios include counting employees in each department of a company, calculating the average salary of male and female employees respectively in each department, and calculating the average salary of employees of different ages. Pandas has groupby function to be able to handle most of the grouping tasks conveniently. But there are certain tasks that the function finds it hard to manage. Here let\u2019s examine these \u201cdifficult\u201d tasks and try to give alternative solutions.", "groupby is one of the most important Pandas functions. It is used to group and summarize records according to the split-apply-combine strategy. The following diagram shows the workflow:", "You group records by a certain field and then perform aggregate over each group.", "This is the simplest use of the above strategy. To count employees in each department based on employee information, for instance:", "Problem analysis: Use department as the key, group records by it and count the records in each group.", "Below is part of the employee information:", "Explanation: groupby(\u2018DEPT\u2019)groups records by department, and count() calculates the number of employees in each group.", "You group records by multiple fields and then perform aggregate over each group.", "We handle it in a similar way. To calculate the average salary for both male and female employees in each department based on the same employee information in the previous instance.", "Problem analysis: There are two grouping keys, department and gender. We treat thea composite key as a whole to perform grouping and aggregate.", "Explanation: The expression groupby([\u2018DEPT\u2019,\u2018GENDER\u2019])takes the two grouping fields as parameters in the form of a list. The expression as_index specifies whether to use the grouping fields as the index using True or False (Here False means not using them as the index). The mean() function calculates the average salary.", "The grouping key is not explicit data and needs to be calculated according to the existing data. Such a key is called computed column. To calculate the average salary for employees of different years, for instance:", "Problem analysis: There isn\u2019t a years column in the employee information. We need to calculate it according to the employees\u2019birthdays, group records by the calculated column, and calculate the average salary.", "Explanation: Since the years values don\u2019t exist in the original data, Python uses np.floor((employee[\u2018BIRTHDAY\u2019].dt.year-1900)/10) to calculate the years column, groups the records by the new column and calculate the average salary.", "You perform one type of aggregate operation over each of multiple columns or several types of aggregates over one or more columns.", "1. One aggregate on each of multiple columns", "You perform one type of aggregate on each of multiple columns. To count the employees and calculate the average salary in every department, for example:", "Problem analysis: The count aggregate is on EID column, and the average aggregate is over the salary column. Each column has its own one aggregate.", "Explanation: Pandas agg() function can be used to handle this type of computing tasks. Relevant columns and the involved aggregate operations are passed into the function in the form of dictionary, where the columns are keys and the aggregates are values, to get the aggregation done.", "2. Multiple aggregates on one column", "You perform more than one type of aggregate on a single column. For the previous task, we can also sum the salary and then calculate the average. This way we perform two aggregates, count and average, on the salary column.", "Explanation: We can combine the aggregate operations as a list and take it as the parameter to pass to the agg() function.", "3. Multiple aggregates over multiple columns", "You summarize multiple columns during which there are multiple aggregates on a single column. The aggregate operation can be user-defined.", "To get the number of employees, the average salary and the largest age in each department, for instance:", "Problem analysis: Counting the number of employees and calculating the average salary are operations on the SALARY column (multiple aggregates on one column). Finding the largest age needs a user-defined operation on BIRTHDAY column.", "Explanation: Columns to be summarized and the aggregate operations are passed through parameters to the function in the form of dictionary. For a column requiring multiple aggregate operations, we need to combine the operations as a list to be used as the dictionary value.", "You extend each of the aggregated results to the length of the corresponding group. This is equivalent to copying an aggregate result to all rows in its group. To add a new column containing the average salary of each department to the employee information, for instance:", "Problem analysis: Group records by department, calculate the average salary in each department, and populate each average value to the corresponding group while maintaining the original order.", "Explanation: Group records by department and calculate average salary in each group. transform() function calculates aggregate on each group, returns the result and populates it to all rows in the order of the original index. That makes sure that the records maintain the original order.", "You perform one or more non-aggregate operations in each group. To sort each group, for example, we are concerned with the order of the records instead of an aggregate. To sort records in each department by hire date in ascending order, for example:", "Problem analysis: Group records by department, and loop through each group to order records by hire date.", "Explanation: To sort records in each group, we can use the combination of apply()function and lambda. The lambda expression loops through groups to sort records in each group using sort_values() function, and returns the sorting result.", "There are more complicated computing goals. To find the difference between salary of the eldest employee and that of the youngest employee in each department, for instance:", "Problem analysis: Group records by department, locate the eldest employee record and the youngest employee record, and calculate their salary difference.", "Explanation: The script uses apply()and a user-defined function to get the target. apply() passes the grouping result to the user-defined function as a parameter. Parameter g in the user-defined function salary_diff()is essentially a data frame of Pandas DataFrame format, which is the grouping result here. The script gets the index of the eldest employee record and that of the youngest employee record over the parameter and then calculate the difference on salary field.", "Mastering Pandas groupby methods are particularly helpful in dealing with data analysis tasks.", "Let\u2019s take a further look at the use of Pandas groupby though real-world problems pulled from Stack Overflow.", "You group records by their positions, that is, using positions as the key, instead of by a certain field. Such a scenario includes putting every three rows to same group, and placing rows at odd positions to a group and those at even positions to the other group. Below is an example:", "Below is part of the source data:", "We want to group and combine data every three rows, and keep the mode in each column in each group. The expected result is as follows:", "Problem analysis: This grouping task has nothing to do with column values but involve positions. We perform integer multiplications by position to get a calculated column and use it as the grouping condition.", "Explanation: The expression np.arange(len(data)) // 3generates a calculated column, whose values are [0 0 0 1 1 1 2 2 2]. The script uses it as the key to group data every three rows. The expression agg(lambda x: x.mode())gets the mode from each column in every group. In the first group the modes in time column is [0,1,2], and the modes in a and b columns are [0.5]and [-2.0]respectively. The script then uses iloc[-1] to get their last modes to use as the final column values.", "You group ordered data according to whether a value in a certain field is changed. That is, a new group will be created each time a new value appears. Here\u2019s an example:", "Below is part of the original data:", "After data is grouped by user, sum duration values whose location values are continuously the same, and perform the next sum on duration when location value changes. Below is the expected result:", "Problem analysis: Order is import for location column. Records with continuously same location values are put into same group, and a record is put into another group once the value is changed. When user is B, location values in row 4 (whose index is 3) are [gym,shop,gym,gym]. Here we shouldn\u2019t just put threesame gyms into one group but should put the first gym in a separate group, becausethe location value after the first gym is shop, which is a different value. Shop should be put another separategroup. And then the other two gyms should be in same group because they are continuously same. So the grouping result for user B should be [[gym],[shop],[gym,gym]]. That\u2019s why we can\u2019t use df.groupby([\u2018user\u2019,\u2018location\u2019]).duration.sum()to get the result. Instead we need a calculated column to be used as the grouping condition.", "Explanation: The calculated column derive gets its values by accumulating location values before each time they are changed. The cumulated values are [1 1 2 2 3 4 4]. Then group the original data by user, location and the calculated array, and perform sum on duration.", "You create a new group whenever the value of a certain field meets the specified condition when grouping ordered data. Below is an example:", "Below is part of the original data:", "We want to get a random row between every two x values in code column.", "The expected result is as follows:", "Problem analysis: To get a row from two x values randomly, we can group the rows according to whether the code value is x or not (that is, create a new group whenever the code value is changed into x), and get a random row from the current group. So we still need a calculated column to be used as the grouping key.", "Explanation: code.eq(x) returns True when code is x and False when code isn\u2019t x. cumsum()accumulates the number of true values and false values to generate a calculated column [1 1 1 1 1 1 1 1 1 2 2\u2026]. Then the script finds the records where code is x, group records by those x values, and get a random record from each group.", "In all the above examples, the original data set is divided into a number of subsets according to a specified condition, and has the following two features:", "2\uff09Each member in the original data set belongs to and only belongs to one subset.", "We call this type of grouping the full division. There is also partial division.", "Alignment grouping has a base set. It compares an attribute (a field or an expression) of members of the to-be-grouped set with members of the base set and puts members matching a member of the base set into same subset. The number of subsets is the same as the number of members in the base set. The alignment grouping has three features:", "1\uff09There may be empty subsets (one or more members of the base set don\u2019t exist in the to-be-grouped set, for instance);", "2\uff09There may be members of the to-be-grouped set that are not put into any group (they are not so important as to be included in the base set, for instance);", "3\uff09Each member in the to-be-grouped set belongs to one subset at most.", "A company wants to know the precise number of employees in each department. If a department doesn\u2019t have male employees or female employees, it records their number as 0.", "Problem analysis: If we group data directly by department and gender, which is groupby([\u2018DEPT\u2019,\u2019GENDER\u2019]), employees in a department that doesn\u2019t have female employees or male employees will all be put into one group and the information of absent gender will be missing. It\u2019s easy to think of an alternative. That solution groups records by department, generates a [male, female] base set to left join with each group, groups each joining result by gender and then count the numbers of male and female employees. This will make sure that each subgroup includes both female employees and male employees.", "The user-defined function align_groupuses merge()function to generate the base set and perform left join over it and the to-be-grouped set, and then group each joining result set by the merged column. After records are grouped by department, the cooperation of apply() function and the lambda expression performs alignment grouping on each group through a user-defined function, and then count on EID column. (Note: You shouldn\u2019t perform count on GENDER because all GENDER members are retained during the merge operation. When there is an empty subset, the result of count on GENDER will be 1 and the rest of columns will be recorded as null when being left-joined. That will result in a zero result for a count on EID).", "2. Members of the to-be-grouped set that are not put into any group", "The task is to group records by the specified departments [\u2018Administration\u2019, \u2018HR\u2019, \u2018Marketing\u2019, \u2018Sales\u2019], count their employees and return result in the specified department order.", "Problem analysis: We can filter away the records not included by the specified set of departments using left join.", "Explanation: Pandas doesn\u2019t directly support the alignment grouping functionality, so it\u2019s roundabout to implement it. Besides, the use of merge function results in low performance.", "An enumeration grouping specifies a set of conditions, computes the conditions by passing each member of the to-be-grouped set as the parameter to them, and puts the record(s) that make a condition true into same subset. The subsets in the result set and the specified condition has a one-to-one relationship. One feature of the enumeration grouping is that a member in the to-be-grouped set can be put into more than one subset.", "The task is to group employees by durations of employment, which are [employment duration<5 years, 5 years<= employment duration<10 years, employment duration>=10 years, employment duration>=15 years], and count female and male employees in each group (List all eligible employee records for each enumerated condition even if they also meet other conditions).", "Problem analysis: The enumerated conditions employment duration>=10 years and employment duration>=15 years have overlapping periods. Employees who have stayed in the company for at least 15 years also meet the other condition. A calculated column doesn\u2019t support putting one record in multiple groups. We need to loop through all conditions, search for eligible records for each of them, and then perform the count.", "Explanation: EMPLOYED is a column of employment durations newly calculated from HIREDATE column. The user-defined function eval_g()converts enumerated conditions into expressions. The enumerated conditions<5, for instance, is equivalent to the eval_g(dd,ss) expression emp_info[\u2018EMPLOYED\u2019]<5. The new calculated column value will then be used to group the records. The script loops through the conditions to divide records into two groups according to the calculated column. get_group(True) gets eligible groups. Finally the script uses concat() function to concatenate all eligible groups.", "Python can handle most of the grouping tasks elegantly. It needs to generate a calculated column that meets the grouping condition when dealing with order-based grouping tasks, such as grouping by changed value/condition. It is a little complicated. It becomes awkward when confronting the alignment grouping an enumeration grouping tasks because it needs to take an extremely roundabout way, such the use of merge operation and multiple grouping. That\u2019s time and effort consuming. Pandas still has its weaknesses in handling grouping tasks", "esProc SPL handles the grouping tasks tactfully. esProc is specialized data computing engine. SPL, the language it is based, provides a wealth of grouping functions to handle grouping computations conveniently with a more consistent code style.", "Two esProc grouping functions groups()and group() are used to achieve aggregation by groups and subset handling. They are able to handle the above six simple grouping problems in a concise way:", "Python is also convenient in handling them but has a different coding style by involving many other functions, including agg, transform, apply, lambda expression and user-defined functions. SPL takes consistent coding styles in the form of groups(x;y) and group(x).(y).", "Python scripts are a little complicated in handling the following three problems by involving calculated columns. The ordered set based SPL is able to maintain an elegant coding style by offering options for handling order-based grouping tasks", "You can choose to use groups or group function to handle a grouping and aggregate task according to whether you need a post-grouping aggregation or you want to further manipulate data in each subset.", "Python is really awkward in managing the last two types groups tasks, the alignment grouping and the enumeration grouping, through the use of merge function and multiple grouping operation. SPL has specialized alignment grouping function, align(), and enumeration grouping function, enum(), to maintain its elegant coding style.", "Python\u2019s fatal weakness is the handling of big data grouping (data can\u2019t fit into the memory). The language requires external storage read/write and hash grouping. It\u2019s almost impossible for a non-professional programmer to get it done in Python. Read How Python Handles Big Files to learn more.", "That article points out Python problems in computing big data (including big data grouping), and introduces esProc SPL\u2019s cursor mechanism. This mechanism supplies group function and groupx() function to handle big data calculations in an elegant way.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Products and resources that simplify hard data processing tasks. If you have any questions, send me a message. https://www.linkedin.com/in/witness998"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd64f1203f8d3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://simplifydataprocessing.medium.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": ""}, {"url": "https://simplifydataprocessing.medium.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Jerry Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a807787661b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&user=Jerry+Zhang&userId=1a807787661b&source=post_page-1a807787661b----d64f1203f8d3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/analytics-vidhya/how-python-handles-big-files-fc60ff90b819", "anchor_text": "How Python Handles Big Files"}, {"url": "https://medium.com/tag/python?source=post_page-----d64f1203f8d3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/group-by?source=post_page-----d64f1203f8d3---------------group_by-----------------", "anchor_text": "Group By"}, {"url": "https://medium.com/tag/pandas?source=post_page-----d64f1203f8d3---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&user=Jerry+Zhang&userId=1a807787661b&source=-----d64f1203f8d3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&user=Jerry+Zhang&userId=1a807787661b&source=-----d64f1203f8d3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd64f1203f8d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d64f1203f8d3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d64f1203f8d3--------------------------------", "anchor_text": ""}, {"url": "https://simplifydataprocessing.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://simplifydataprocessing.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jerry Zhang"}, {"url": "https://simplifydataprocessing.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "236 Followers"}, {"url": "https://www.linkedin.com/in/witness998", "anchor_text": "https://www.linkedin.com/in/witness998"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a807787661b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&user=Jerry+Zhang&userId=1a807787661b&source=post_page-1a807787661b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F38074cfc7c09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-grouping-in-python-d64f1203f8d3&newsletterV3=1a807787661b&newsletterV3Id=38074cfc7c09&user=Jerry+Zhang&userId=1a807787661b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}