{"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-f35cd7349e16", "time": 1682996945.166442, "path": "towardsdatascience.com/deep-dive-into-the-computer-vision-world-f35cd7349e16/", "webpage": {"metadata": {"title": "Deep Dive into the Computer Vision World: Part 1 | by Jiwon Jeong | Towards Data Science", "h1": "Deep Dive into the Computer Vision World: Part 1", "description": "After finishing the basics of neural networks, the next step would be learning some of the \u201cfamous rock star models\u201d in this field. ResNet, Inception Net, Faster R-CNN, YOLO and so on. Studying these\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-artificial-neural-network-6a3f2bc0eecb?source=friends_link&sk=a9021d009dcd1651c16b59c6e48d0533", "anchor_text": "The Most Intuitive and Easiest Guide", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=friends_link&sk=17c6523b385d28525c9e68e2da28b9e8", "anchor_text": "the basic concept of convolutional neural network", "paragraph_index": 2}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "ImageNet Large Scale Visual Recognition Challenge", "paragraph_index": 3}, {"url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf", "anchor_text": "AlexNet", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1311.2901.pdf", "anchor_text": "ZFnet", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "the original paper", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1603.05027.pdf", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1704.04861.pdf", "anchor_text": "the original paper", "paragraph_index": 27}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "LinkedIn", "paragraph_index": 32}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "https://www.linkedin.com/in/jiwon-jeong/", "paragraph_index": 34}], "all_paragraphs": ["After finishing the basics of neural networks, the next step would be learning some of the \u201cfamous rock star models\u201d in this field. ResNet, Inception Net, Faster R-CNN, YOLO and so on. Studying these models can be divided into three parts: The applications, the implementations, and intuition behind these architectures. There are already plenty of resources on how to use pre-trained models and how to build them. But grasping the real intuition behind the model is overlooked sometimes. What\u2019s the researchers\u2019 intention for building a model with such structures? What motivated them to take such an approach? And what can we infer from the outcome?", "This article is the next series to \u201cThe Most Intuitive and Easiest Guide\u201d tutorials and the complete set of the series is as follows:", "This article assumes that you\u2019re already familiar with the basic concept of convolutional neural network. On top of that, we\u2019re going to dive deeper and see various convolutional transformation and modification with VGG, ResNet, Inception Network and MobileNet. Walking through them one by one, we\u2019ll answer the questions mentioned above so that we truly understand the underlying meaning of these architectures.", "ImageNet is a large dataset used for the research in the computer vision field. Since 2010, a competition has been held annually under the name of ImageNet Large Scale Visual Recognition Challenge (ILSVRC). The VGGNet was the winner of the ILSVRC competition in 2014. Although it has a simple architecture compared to the other fancy networks, it is still one of the most popular networks.", "One interesting part of this network is that it used only 3x3 filters even in the first layers. If we compare it to the previous ones, AlexNet, the winner in 2012, used 11x11 and 5x5 filters at the first two layers. And ZFnet, the winner in 2013, used 7x7 filters. Instead of using a relatively large size of a filter in the first convolution layer, the size of the filters VGG network used is 3x3 only.", "So what\u2019s the intention for trying this? The answer is to reduce the number of parameters. Let\u2019s do some calculation here. How many parameters does a single 7x7 convolution layer with the channel size C require? It\u2019s 49C\u00b2. Now, what\u2019s the number with 3 layers of 3x3 convolution layers with the same channel size? (9C\u00b2)x3 = 27C\u00b2. See how many parameters decreases. Reducing the number of weights can handle overfitting by reducing the complexity of the network. Moreover, as we can have an activation layer for each convolution layer, this encourages the model\u2019s learning as well.", "Along with the VGG networks or AlexNet, most of the Convolutional networks followed the basic structure: a series of convolutional layers, a pooling layer and an activation layer with some of the normalization. But going deeper and deeper, people came across some serious problems and started to redesign this approach.", "Intuitively we\u2019d like to expect \u201cdeeper is better.\u201d However, researchers found was it wasn\u2019t the case. As a network gets extremely deeper and deeper, the performance gets worse. One of the reasons is a vanishing/ exploding gradient problem. Although we already have several ways to address this issue such as gradient clipping, there is a degradation problem that isn\u2019t due to overfitting. The birth of ResNet started from here. Why is that?", "Let\u2019s assume that we have a good network with desirable accuracy. Now we\u2019re going to copy this network and add just 1 layer but having no additional function. This is called an identity mapping, which means getting the output exactly the same with the input. Compared to other complex layers with many parameters, this will be a piece of cake to our \u201csmart\u201d model. So there should be no harm to the performance of the network, right?", "Then what will be the outcome if we attach more and more identity layers? As identity layers give no impact to the output, there should be no degradation in the performance. It seems a reasonable guess, but the outcome of this experiment was different from our expectations. The performance of this model was worse than the shallower model without identity layers.", "This outcome indicates \u201cdeeper is better\u201d is not applicable to neural networks even with the identity mapping. Just attaching identity layers directly to a network makes it hard to train. Okay, then what about putting identity layers as an additional layer?", "Now, this is where ResNet comes into play. Let\u2019s say H(x) as the outcome of the network. And if we put an additional path, the original function becomes F(x) + x where F(x) is the function of the main branch as shown above. The identity layer is also called a shortcut connection or a skip connection. This brings the concept of \u201cresidual learning\u201d to the network. Now the main branch is trained to approximate H(x) \u2014 x and make F(x) go closer to zero. This means giving the layers a certain direction for learning, which makes the training easier. Moreover, the network can skip some of the layers through the identity layer. This allows us to have deeper layers but still with high performance.", "You may ask how it\u2019s possible to add F(x) and x when the two layers have different sizes. We can handle this problem by the zero padding or a linear projection at the shortcut connections. So there are two kinds of shortcut connections in ResNet, one without weights and the other with weights.", "The picture above shows the convolutional block of ResNet 50-layers. It has a main branch with 3 convolution layers and a shortcut connection with a 1x1 convolution. Here we may need to ask, why 1x1\u20133x3\u20131x1 convolution?", "To answer this question, it is necessary to understand how the dimension of data changes according to filter size. Please have a look at the picture on the right. If we say the shape of the input is (32, 32, 256), the dimension decreases when it passes the 3x3 filter compared to the previous step. And when it passes the second 1x1 filter, it increases again. This is making a bottleneck. By forcing the data to fit into a smaller dimension, we can get a more efficient feature representation.", "Optimizing the deep neural network easily with much fewer filters, much less computation, and higher accuracy. This simple yet novel reformulation brought such a beautiful achievement is how ResNet blew people\u2019s minds in 2015. With this fundamental intuition on ResNet, I\u2019d like you to explore the network from the original paper. And here is the second part of the research on experimenting the variants of the residual block. Or you can find an easy explanation on ResNet here.", "Going deeper with high performance is good. We need deep neural networks to implement complex and challenging tasks. But there is another factor to consider when we evaluate the networks. Think about when we have to embed a model in a mobile application. It\u2019ll be not desirable to have a \u201ctoo heavy\u201d model for sure. But more than that, there is a computational cost problem that is quite critical in real practice. So now the question becomes, how can we go deeper with higher efficiency?", "One place where the researchers had found inefficient computation occurred was a fully connected architecture. In a convolutional approach, a fully connected architecture indicates that a layer l feeds from a layer l-1 and is connected to the next layer l+1 as shown below on the left. The researchers found any uniform increase in the number of the filters doubles the computation. So they suggest moving from densely connected architectures to sparsely connected architectures.", "Instead of implementing one type of convolutions, the sparse architecture does multiple convolutions with multiple filter sizes as shown above. And the dimension of output from these layers can be matched up with \u2018SAME\u2019 padding.", "There is an important meaning in having several filters with different sizes here. During the training, the scale of features a network detects are small and local at first, and it gets bigger as it goes deeper. For example, let\u2019s say the model detects a cat. The model sees a small scale of features such as the fur pattern of the cat, and then it moves to a bigger scale such as the shape of its ear, and then the number of legs.", "So even with the pictures where the cats are at different scales like above, the model still processes the same scale of feature mapping. This is inefficient and it hurts the performance. Therefore having multiple filters indicates now it knows how to \u201czoom in and out\u201d according to the input image. It enables the model to detect the image in different scales at a time. And by doing so, we can also handle off the work of choosing parameters as well as reducing the inefficient computation. This is the first kick of Inception network.", "So the Inception Module looked like the one on the left of the picture above. But there was a problem. But what about the computation cost? Sparely connected architectures still require the same or more amount of computation anyways! The solution of the researchers to handle this problem was implementing 1x1 convolutions as shown above on the right. The purpose of the 1x1 convolutions here is dimension reduction just as what we discussed with ResNet. See the computation times are reduced given the (N, N, C) shape of the input image. If the size of the image is 32 x 32 with the 129 channels, we can reduce the number of parameters 9 times less!", "The final architecture of GoogleNet is shown above. The modules are concatenated, forming 22 layers in total. This is quite a deep network and it also couldn\u2019t avoid the notorious vanishing gradient problem. So the way the researchers took to handle this issue was making side branches.", "What do we mean by \u201cgradient vanish?\u201d It indicates that the value of the gradient gets smaller and smaller as it goes deeper, which means the gradient has little information to learn. So we can say that the gradient from the early stages carries more information. In other words, we can have additional information by adding helper classifiers in the intermediate layers. Moreover, as we discussed above, the features detected are different along with the layers. Therefore the \u201cintermediate products\u201d are also beneficial for classifying the labels. We add the loss from these branches to the total loss of the network with weighted.", "Inspired by the networks we discussed above, \u201cgoing deeper and more complicated\u201d was the high trend in CNN research. Although those networks brought higher accuracy, they were not efficient or \u2018light\u2019 enough for a real-world application. To be carried out in a computationally limited platform with a timely manner, they need to be smaller and faster.", "One solution the researchers proposed was forming a factorized convolutions. Factorizing convolutions indicates factorizing a standard convolution into a depthwise convolution and a pointwise convolution. This is called depthwise separable convolution.", "In depthwise separable convolution, we first split each channel of the input and the filter, and convolve the input with the corresponding filter, or in a depthwise manner. And then concatenate the output together. This is depthwise convolution. After that, we do pointwise convolution, which is the same as 1x1 convolution. Now see the final outcome. Isn\u2019t it the same with that of a standard 3x3 convolution? If so, what\u2019s the point for doing this?", "The answer is computation. Let\u2019s compare the computational cost of the two. When the shape of input is (N, N, C1) and the output channel is C2 with the filter size F, the total computation of the two should be as shown on the left. So as you can see, the computational cost is reduced with depthwise separable convolution. According to the original paper, MobileNet requires 8 to 9 times less computation with only a small reduction in accuracy compared to the same architecture but with standard convolutions.", "Depthwise separable convolution is also used to Xception, and its paper was released earlier than that of MobileNet. But I found MobileNet paper gives a more straightforward explanation on the concept of depthwise separable convolution.", "Now do the architectures become simpler and tangible to you? Like I said, understanding the thesis behind the structure is essential. So I\u2019d like to go over some kicks of the networks again.", "Firstly, the filter size at the convolution layers has more meanings than just feature mapping. It can change the number of parameters like VGG. We can also create bottlenecks to extract meaningful representations of the data. 1x1 convolution can serve more than a linear transformation. It can serve as a useful trick for giving more non-linearity, changing the dimension, and reducing the computation without impacting the input data significantly.", "To get higher performance, ResNet utilized the residuals by shortcut connection. This layer promoted the optimization better by conveying weights across the layers efficiently. On the other hand, the strategy of Inception Network was using multiple filters by building sparse architectures. It was for dealing with the change in scales during training. Lastly, MobileNet chose to factorize a convolution into two steps. With depthwise separable convolutions, MobileNet could reduce computation and the model size dramatically.", "Did this story resonate with you? Please share your insight with us. I\u2019m always open to talk, so feel free to leave comments below and share your thoughts. I also share interesting and useful resources on LinkedIn so feel free to follow and reach out to me. I\u2019ll be back with another interesting story, next time. As always, stay tuned!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science Researcher / Data geek \ud83e\udd13 Bookworm \ud83d\udcda Travel lover \ud83c\udf0f LinkedIn: https://www.linkedin.com/in/jiwon-jeong/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff35cd7349e16&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Jiwon Jeong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df293b5ca56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&user=Jiwon+Jeong&userId=1df293b5ca56&source=post_page-1df293b5ca56----f35cd7349e16---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-artificial-neural-network-6a3f2bc0eecb?source=friends_link&sk=a9021d009dcd1651c16b59c6e48d0533", "anchor_text": "The Most Intuitive and Easiest Guide"}, {"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-2-7a24efdb1a14?source=friends_link&sk=4fec4dfc9499c930f263c6808b2f369d", "anchor_text": "Regions with CNN, let\u2019s start object detection!"}, {"url": "https://towardsdatascience.com/deep-dive-into-the-computer-vision-world-part-3-abd7fd2c64ef?source=friends_link&sk=876a90f05dcef8f9f0546b42adaec42d", "anchor_text": "YOLO, SSD and RetinaNet, more unified ones"}, {"url": "https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480?source=friends_link&sk=17c6523b385d28525c9e68e2da28b9e8", "anchor_text": "the basic concept of convolutional neural network"}, {"url": "http://www.image-net.org/challenges/LSVRC/", "anchor_text": "ImageNet Large Scale Visual Recognition Challenge"}, {"url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf", "anchor_text": "AlexNet"}, {"url": "https://arxiv.org/pdf/1311.2901.pdf", "anchor_text": "ZFnet"}, {"url": "https://arxiv.org/pdf/1512.03385.pdf", "anchor_text": "The architecture of VGG-19"}, {"url": "https://arxiv.org/pdf/1512.03385.pdf", "anchor_text": "The comparison of a plain network and ResNet"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "the original paper"}, {"url": "https://arxiv.org/pdf/1603.05027.pdf", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035", "anchor_text": "here"}, {"url": "https://knowyourmeme.com/memes/we-need-to-go-deeper", "anchor_text": "Know your meme"}, {"url": "https://arxiv.org/abs/1409.4842", "anchor_text": "The architecture of Inception Network"}, {"url": "https://arxiv.org/pdf/1704.04861.pdf", "anchor_text": "the original paper"}, {"url": "https://arxiv.org/pdf/1704.04861.pdf", "anchor_text": "The applications of MobileNet"}, {"url": "https://arxiv.org/abs/1409.1556", "anchor_text": "Very deep convolutional network for large-scale image recognition"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Deep residual learning for image recognition"}, {"url": "https://arxiv.org/abs/1409.4842", "anchor_text": "Going deeper with convolutions"}, {"url": "https://arxiv.org/pdf/1602.07261.pdf", "anchor_text": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"}, {"url": "https://arxiv.org/pdf/1610.02357.pdf", "anchor_text": "Xception: Deep Learning with Depthwise Separable Convolutions"}, {"url": "https://arxiv.org/pdf/1704.04861.pdf", "anchor_text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f35cd7349e16---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f35cd7349e16---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/image-recognition?source=post_page-----f35cd7349e16---------------image_recognition-----------------", "anchor_text": "Image Recognition"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----f35cd7349e16---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----f35cd7349e16---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----f35cd7349e16---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&user=Jiwon+Jeong&userId=1df293b5ca56&source=-----f35cd7349e16---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff35cd7349e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f35cd7349e16---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f35cd7349e16--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f35cd7349e16--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f35cd7349e16--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jiwon.jeong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jiwon Jeong"}, {"url": "https://medium.com/@jiwon.jeong/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://www.linkedin.com/in/jiwon-jeong/", "anchor_text": "https://www.linkedin.com/in/jiwon-jeong/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1df293b5ca56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&user=Jiwon+Jeong&userId=1df293b5ca56&source=post_page-1df293b5ca56--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd0a222fc96e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-dive-into-the-computer-vision-world-f35cd7349e16&newsletterV3=1df293b5ca56&newsletterV3Id=d0a222fc96e6&user=Jiwon+Jeong&userId=1df293b5ca56&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}