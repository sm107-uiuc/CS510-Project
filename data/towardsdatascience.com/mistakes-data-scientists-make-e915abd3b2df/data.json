{"url": "https://towardsdatascience.com/mistakes-data-scientists-make-e915abd3b2df", "time": 1683000431.002794, "path": "towardsdatascience.com/mistakes-data-scientists-make-e915abd3b2df/", "webpage": {"metadata": {"title": "Twelve Mistakes Data Scientists Make | by Adam Green | Towards Data Science", "h1": "Twelve Mistakes Data Scientists Make", "description": "I've made many mistakes while learning, working and teaching data science. I see those same mistakes repeated by my students when teaching."}, "outgoing_paragraph_urls": [{"url": "https:/www.youtube.com/watch?v=TGGGDpb04Yc", "anchor_text": "Statistical Thinking for Data Science", "paragraph_index": 72}, {"url": "https://medium.com/@adgefficiency", "anchor_text": "Medium", "paragraph_index": 108}, {"url": "https://www.linkedin.com/in/adgefficiency/", "anchor_text": "LinkedIn", "paragraph_index": 108}], "all_paragraphs": ["An expert is a person who has made all the mistakes that can be made in a very narrow field.", "This article is a list of common mistakes I\u2019ve seen myself and others make when learning and practicing data science.", "Patterns exist in the mistakes data scientists make \u2014 here you can learn from them too:", "Prediction is what separates the data scientist from the data analyst. The data analyst analyzes the past \u2014 the data scientist predicts the future.", "Supervised machine learning is commonly used by data scientists to make predictions.The basic process in supervised learning is using features x to predict a target y.", "Understanding the distribution of the target is a natural first step for any supervised learning project. The distribution of the target informs many decisions a data scientist makes, including:", "The target we are predicting can be either a continuous number (regression) or a discrete category (classification).", "In a regression problem, a data scientist wants to know the following about the target:", "A histogram will answer all of these \u2014 making it an excellent choice for visualizing the target in regression problems. The code below generates a toy dataset of four distributions and plots a histogram:", "The histogram shows the two normal and two uniform distributions that generated this dataset.", "In a classification problem, a data scientist wants to know the following about the target:", "We can answer these questions using a bar chart:", "The bar chart shows us we have three classes, and shows that our `dreaming` class is under-represented.", "Dimensionality provides structure for understanding the world.", "Lower dimensional representations are more valuable than high dimensional representations. This is because it is eaiser to make decisions in low dimensional spaces.", "Take for example the decision of whether to walk or take the bus \u2014 a decision that depends on whether it rains or not.", "If you are given a high dimensional representation of the weather (such as pixels in a satellite image), there is still work to be done before you can decide how to travel.", "If instead you have access to a low dimensional representation of the weather (such as a probability of rain), a decision can be made using only a single threshold parameter. Many other decisions in business are low dimensional \u2014 such as go/no-go or a project or hire/no-hire.", "Notice that much of the work of a data scientist is using machine learning to reduce dimensionality:", "Each of the low dimension outputs can be used by a business ways the high dimensional data can\u2019t.", "Unlike their high dimensional raw data inputs, the lower dimensional outputs can be used to make decisions:", "- solar power output can be used to guide energy trader actions,- a high wind turbine breakdown probability can lead to a maintenance team being sent out,- a low customer lifetime estimation can lead to less money budgeting for marketing.", "The above are examples of the interaction between prediction and control. The better you are able to predict the world, the better you can control it.", "This is also a working definition of a data scientist \u2014 making predictions that lead to action \u2014 actions that change how a business is run.", "The difficulty of working in high dimensional spaces is the curse of dimensionality.", "To understand the curse of dimensionality we need to reason about the space and density of data.", "We can imagine a dense dataset \u2014 a large number of diverse samples within a small space. We can also imagine a sparse dataset \u2014 a small number of samples in a large space.", "What happens to the density of a dataset as we add dimensions? It becomes less dense, because the data is now more spread out.", "However, the decrease of data density with increasing dimensionality is not linear \u2014 it\u2019s exponential. The space becomes exponentially harder to understand as we increase dimensions.", "Why is the increase exponential? Because this new dimension needs to be understood not only in terms of the each other dimension (which would be linear) but in terms of the combination of every other dimension with every other dimension.", "This combination with every other combination leads to an exponential increase.", "This is the curse of dimensionality \u2014 the exponential increase of space as we add dimensions. The code below show this effect:", "The larger the size of the space, the more work a machine learning model needs to do to understand it.", "This is why adding features with no signal is painful. Not only does the model need to learn it\u2019s noise \u2014 it needs to do this by considering how this noise interacts with each combination of every other column.", "Getting a theoretical understanding of dimensionality is step one. Next is applying it in the daily practice of data science. Below we will go through a few practical cases where data scientists can not apply the curse of dimensionality to their own workflow.", "Data scientists can waste time doing excessive grid searching \u2014 expensive in both time and compute. The motivation of complex grid searches come from a good place \u2014 the desire for good (or even perfect) hyperparameters.", "Yet we now know that adding just one additional search means an exponential increase in models trained \u2014 because this new search parameter needs to be tested in combination with every other search parameter.", "Another mistake is narrow grid searches \u2014 searching over small ranges of hyperparameters. A logarithmic scale will be more informative than a small linear range:", "Different projects require different amounts of grid searching, over both models and their hyperparameters. I find that I often build two grid searching pipelines:", "- one to compare different models (using the best hyperparameters found so far for each)- one to compare different hyperparameters for a single model", "I\u2019ll start by comparing models in the first pipeline, then doing further tuning on a single model in the second grid search pipeline. Once a model is reasonably tuned, it\u2019s best hyperparameters can be put into the first grid search pipeline.", "The fine tuning on a single model is often searches over a single parameter at a time (two maximum). This keeps the runtime short, and also helps to develop intuition about what effect changing hyperparameters will have on model performance.", "A misconception I had as a junior data scientist was that adding features had no cost. Put them all in and let the model figure it out! We can now easily see the naivety of this \u2014 more features has as exponential cost.", "This misconception came from a fundamental misunderstanding of deep learning.", "Seeing the results in computer vision, where deep neural networks do all the work of feature engineering from raw pixels, I thought that the same would be true of using neural networks on other data. I was making two mistakes here:", "- not appreciating the useful inductive bias of convolutional neural networks- not appreciating the curse of dimensionality", "We know now there is an exponential cost to adding more features. This also should change how you look at one-hot encoding, which dramatically increases the space that a model needs to understand, with low density data.", "In data science projects, performance is judged using metrics such as training or test performance.", "In industry, a data scientist will choose metrics that align with the goals of the business. Different metrics have different trade-offs \u2014 part of a data scientists job is to select metrics that correlate best with the objectives of the business.", "However, it\u2019s common for junior data scientists to report a range of different metrics. For example, on a regression problem they might report three metrics:", "Combine this with reporting a test & train error (or test & train per cross validation fold), the number of metrics becomes too many to glance at and make decisions with.", "Pick one metric that best aligns with your business goal and stick with it. Reduce the dimensionality of your metrics so you can take actions with them.", "Data scientists are lucky to have access to many high quality implementations of models in open source packages such as `scikit-learn`.", "This can become a problem when data scientists repeatedly train a suite of models without a deliberate reason why these models should be looked at in parallel. Linear models are trained over and over, without ever seeing the light outside a notebook.", "Quite often I see a new data scientist train a linear model, an SVM and a random forest. An experienced data scientist will just train a tree based ensemble (a random forest or XGBoost), and focus on using the feature importances to either engineer or drop features.", "Why is are tree based ensembles a good first model? A few reasons:", "If there is one hyperparameter worthy of searching over when training neural networks it is the learning rate.", "Setting the learning rate too high will make training of neural networks unstable. What the learning rate does is quite intuitive \u2014 higher learning rate means faster training.", "The second most important parameter for neural networks is the batch size.", "Batch size is less intuitive \u2014 a smaller batch size will mean high variance gradients, but some of the value of batches is using that variance to break out of local minima.", "In general, batch size should be as large as possible to improve gradient quality \u2014 often it is limited by GPU memory (especially for images).", "Three sources of error in statistics are:", "Even if quantifying the magnitude of these errors is often impossible \u2014 there is still value in thinking qualitatively about the where error in your statistics is coming from.", "Thinking about the difference between the sampling & distribution of your training and test can help improve the generalization of a machine learning model, before it fails to generalize in production.", "Another useful thinking tool for error is the concept of IID \u2014 that data should be independent & identically distributed:", "- independently sampled (no sampling bias),- identically distributed (no sampling or measurement error).", "IID is an assumption made in statistical learning about the quality of the distribution and sampling of data \u2014 and it\u2019s almost always an assumption that is broken.", "The prediction error of a supervised learning model has three components \u2014 bias, variance, and noise:", "The error of a machine learning model is usually due to a combination of all three. Often data scientists will be able to make changes that lead to a trade off between bias & variance.", "Three common levers a data scientist can pull to trade bias for variance (or vice versa) are:", "More data will have no effect on bias.", "More data can even make bias worse, if the sampling of additional is biased.", "Additional data sampled with bias will only give your model the chance to be more precise about being wrong \u2014 see Chris Fonnesbeck\u2019s talk on Statistical Thinking for Data Science for more on the relationship between bias, sampling bias and data quantity.", "Obsessing over the architecture of fully connected neural networks comes with the process of building them. Constructing a neural network requires defining the architecture \u2014 surely it\u2019s important?", "Yet when it comes to fully connected neural nets, the architecture isn\u2019t really that important.", "As long as you give the model enough capacity and sensible hyperparameters, a fully connected neural network will be able to learn the same function with a variety of architectures. Let your gradients work with the capacity you give them.", "Case in point is the 2015 reinforcement learning paper Trust Region Policy Optimization, which uses a simple feed-forward neural network as a policy on locomotion tasks. The locomotion tasks use a flat input vector, with a simple fully connected architecture.", "The correct mindset with a fully connected neural network is a depth of two or three, with the width set between 50 to 100 (or 64 to 128, if you want to fit in with the cool computer science folk). If your model is low bias, consider adding capacity through another layer or additional width.", "One interesting improvement on the simple fully connected architecture is the wide & deep architecture, which mixes wide memorization feature interactions with deep unseen, learned feature combinations.", "Programs must be written for people to read, and only incidentally for machines to execute.", "Abelson & Sussman \u2014 Structure and Interpretation of Computer Programs", "Code style is important. I remember being confused at why more experienced programmers were so particular about code style.", "After programming for five years, I now know where they were coming from.", "Code that is laid out in the expected way requires less effort is required to read & understand code.", "Poor code style places additional burden on the reader to understand your unique code style, before they even think about the actual code itself.", "If you ever get a model with an impossibly low training error, it is likely that your target is a feature.", "This is the advice I\u2019ve given most when debugging machine learning projects. Whenever I see a high loss (higher that say 2 or 3), it\u2019s a clear sign that the target has not been scaled to a reasonable range.", "Scale matters because unscaled targets lead to large prediction errors, which mean large gradients and unstable learning.", "By scaling, I mean either standardization:", "Note that there is a lack of consistency between what these things are called \u2014 normalization is also often called min-max scaling, or even standardization!", "Take the example below, where we are trying to predict how many people attend a talk, from the number of speakers and the start time. Our first pipeline doesn\u2019t scale the features or targets, leading to a large error signal and large gradients:", "Our second pipeline takes the time to properly scale features & target, leading to an error signal with appropriately sized gradients:", "A similar logic holds for features \u2014 unscaled features can dominate and distort how information flows through a neural network.", "A no-brainer when writing code that processes data \u2014 and an expensive mistake in developer time if you run the data processing using your full dataset each time you are fixing a bug.", "You can work on a sample of your data roughly using an integer index:", "pandas allows you only load a subset of the data at a time (avoiding pulling the entire dataset into memory):", "A simple way to control this is a variable \u2014 this is what you would do in a Jupyter Notebook:", "Or more cleanly with a command line argument:", "Which can be controlled when running the script data.py:", "Raw data is holy \u2014 it should never be overwritten. This is true both within a program and on disk.", "This one isn\u2019t a mistake \u2014 but it\u2019s a pattern that has dramatically simplified my life.", "Managing paths in Python can be tricky. There are few things that can change how path finding Python can work:", "- where the user clones source code- where a virtual environment installs that source code- which directory a user runs a script from", "Some of the problems that occur are from these changes:", "- os.path.realpath will change based on where the virtual environment installs your package- os.getcwd will change based on where the user runs Python the interpreter", "Putting data in a fixed, consistent place can avoid these issues \u2014 you don\u2019t ever need to get the directory relative to anything except the users `$HOME` directory.", "The solution is to create a folder in the user\u2019s $HOME directory, and use it to store data:", "This means your work is portable \u2014 both to your colleagues and to remote machines.", "If you enjoyed this post, feel free to follow me on Medium or connect on LinkedIn.", "Make sure to check out some of my other posts:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe915abd3b2df&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@adgefficiency?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adgefficiency?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Adam Green"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe78e947c3373&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&user=Adam+Green&userId=e78e947c3373&source=post_page-e78e947c3373----e915abd3b2df---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https:/www.youtube.com/watch?v=TGGGDpb04Yc", "anchor_text": "Statistical Thinking for Data Science"}, {"url": "https://arxiv.org/abs/1502.05477", "anchor_text": "Schulman et. al (2015) Trust Region Policy Optimization"}, {"url": "https://arxiv.org/abs/1606.07792", "anchor_text": "Cheng et. al (2016) Wide & Deep Learning for Recommender Systems"}, {"url": "https://medium.com/@adgefficiency", "anchor_text": "Medium"}, {"url": "https://www.linkedin.com/in/adgefficiency/", "anchor_text": "LinkedIn"}, {"url": "https://towardsdatascience.com/getting-the-most-out-of-jupyter-lab-9b3198f88f2d", "anchor_text": "Getting the most out of Jupyter LabA guide to the next generation of notebook tooling.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/daniel-c-dennetts-four-competences-779648bdbabc", "anchor_text": "Daniel C. Dennett\u2019s Four CompetencesA useful idea to understand computational control algorithms.towardsdatascience.com"}, {"url": "https://adgefficiency.com/mistakes-data-scientist/", "anchor_text": "https://adgefficiency.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e915abd3b2df---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e915abd3b2df---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----e915abd3b2df---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/programming?source=post_page-----e915abd3b2df---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/education?source=post_page-----e915abd3b2df---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&user=Adam+Green&userId=e78e947c3373&source=-----e915abd3b2df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&user=Adam+Green&userId=e78e947c3373&source=-----e915abd3b2df---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe915abd3b2df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e915abd3b2df---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e915abd3b2df--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e915abd3b2df--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e915abd3b2df--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adgefficiency?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adgefficiency?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Adam Green"}, {"url": "https://medium.com/@adgefficiency/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "226 Followers"}, {"url": "http://datasciencesouth.com", "anchor_text": "datasciencesouth.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe78e947c3373&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&user=Adam+Green&userId=e78e947c3373&source=post_page-e78e947c3373--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3458b9df45ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmistakes-data-scientists-make-e915abd3b2df&newsletterV3=e78e947c3373&newsletterV3Id=3458b9df45ca&user=Adam+Green&userId=e78e947c3373&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}