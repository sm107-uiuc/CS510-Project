{"url": "https://towardsdatascience.com/understanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5", "time": 1683007353.308352, "path": "towardsdatascience.com/understanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5/", "webpage": {"metadata": {"title": "Understanding the Building Blocks of Graph Neural Networks (Intro) | by Giuseppe Futia | Towards Data Science", "h1": "Understanding the Building Blocks of Graph Neural Networks (Intro)", "description": "This post is an introduction to a series of articles on Graph Neural Networks (GNNs). The goal of this series is to provide a detailed description, with intuitions and examples, of the GNNs building\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.dgl.ai/", "anchor_text": "Deep Graph Library (DGL)", "paragraph_index": 1}, {"url": "https://pytorch-geometric.readthedocs.io/en/latest/", "anchor_text": "Pytorch Geometric", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/tagged/grl-series", "anchor_text": "https://towardsdatascience.com/tagged/grl-series", "paragraph_index": 31}, {"url": "https://medium.com/@giuseppefutia/membership", "anchor_text": "https://medium.com/@giuseppefutia/membership", "paragraph_index": 32}], "all_paragraphs": ["This post is an introduction to a series of articles on Graph Neural Networks (GNNs). The goal of this series is to provide a detailed description, with intuitions and examples, of the GNNs building blocks.", "In this series, I will also share running code, using Numpy, Pytorch, and the most prominent libraries adopted in this field, such as Deep Graph Library (DGL) and Pytorch Geometric. At the end of this series, you will be able to combine these building blocks and create a neural architecture to perform analysis and learning tasks on graph data.", "This series will analyze the main components to set up a GNN, including (i) the input layer, (ii) the GNN layer(s), and (iii) the Multilayer Perceptron (MLP) prediction layer(s).", "The framework to analyze and decompose the standard GNN architectures is based on the recent paper entitled \u201cBenchmarking Graph Neural Networks\u201d, whose metadata is available below:", "This post does not cover the fundamentals of graph theory and neural networks. For an introduction to this topic, I suggest the following article:", "The input layer defines the initial representation of graph data, which becomes the input to the GNN layer(s). Basically, the idea is to assign a feature representation to the nodes and edges of the graph.", "The GNN layer encodes the information on the structure of the graph. Then, it exploits this information to update the initial representation of nodes and edges.", "The MLP prediction layer performs a specific learning task, including node classification or link prediction, employing the encoded graph representation obtained as output from the GNN layer(s).", "This post introduces the input layer and the main principles behind a GNN layer. The next articles will describe different types of GNN layers, explaining the related features and showing the main differences between them. In parallel, I will provide an overview of the traditional MLP prediction layers to perform specific tasks on graph data.", "As mentioned before, the goal of the input layer is to define the initial representation of graph data, assigning features to nodes and edges. For the sake of simplicity, I currently consider only the node features.", "The simplest way to represent nodes in the graph is by using one-hot vectors. This representation is usually adopted to distinguish different words in a vocabulary for NLP tasks. In our case, it is exploited to represent different nodes of the graph. The length of the vector representing each node is equal to the number of nodes and, for each vector, an element in a different position is set to 1, while the other elements are set to 0.", "In order to clarify this representation, the following script creates a graph with 5 nodes, represented using one-hot vectors.", "Each row of this matrix represents a node of the graph. To assign initial features to each of these nodes, the input layer applies a linear transformation (also called projection) to the one-hot vectors which encode the node representations. Giving a brief recap of the linear transformation, the definition is the following:", "As reported by Dwivedi et al., the bias value b is not used for the linear transformation in the case of the one-hot vectors. Therefore, the following scripts perform the linear transformation:", "The projection step assigns a d-dimensional vector representation to each node in the graph. In this example, the 5-length one-hot vectors representing the nodes are mapped (or projected) into 3-length dense feature vectors.", "The goal of the input layer is to embed the input features of nodes (and edges) to a d-dimensional vector of hidden features. This new representation is obtained via a simple linear transformation (also known as projection).", "To clarify this aspect, you can analyze the following block:", "The current features have been generated randomly. As a consequence, these features do not actually convey any type of information in regard to the nodes. However, these initial features of the nodes will be updated by means of two different steps:", "At the end of this twofold process, we will be able to obtain an embedding representation of the nodes, which will be characterized by features that convey specific information. In other words, the vector representation of the nodes will express meaningful information that, as human beings, we should be able to recognize observing the graph. In the simplest case, similar embedded features will be assigned to similar nodes in the graph.", "The goal of the GNN layer is to update the d-dimensional representation of the nodes obtained from the input layer. This goal is reached computing, as defined by Dwivedi et. al, a \u201crecursive neighborhood diffusion\u201d, through the so-called \u201cmessage passing framework\u201d. The main idea behind this framework is that each node feature is updated with the features of its neighbors. The neighbor features are passed to the target node as messages through the edges. As a consequence, the new representation of the node encodes and represents the local structure of the graph. To perform this step, we need a structure that describes the relations (edges) between the nodes in the graph. The adjacency matrix, which describes the relations between the nodes in a graph, helps us in this direction.", "Consider the following script, which initializes a random adjacency matrix in a graph of 5 nodes:", "Each row of the adjacency matrix represents the connections, identified by the 1 element, to a node. For instance, the first row indicates that Node 1 is connected to itself, Node 2, Node 3, and Node 5. On the other side, Node 1 is not connected to node 4, because the value in the position (1, 4) is equal to 0.", "Let\u2019s see what happens when we multiply the adjacency matrix with the output of the input layer, which has applied the projection:", "To better understand what is happened to the node representations, consider the following script, which sums the d-dimensional representation of Node 1, to the d-dimensional representation of itself, Node 2, Node 3, and Node 5.", "As you can see, the updated vector representation of Node 1 corresponds to the aggregation (in this case a sum operation) of the features of the neighbors. In other words, this representation encodes the local structure of the graph.", "One of the key ideas of this representation is that stacking L layers in the neural architecture, the resulting target node representation aggregates the features of nodes, whose distance is equal to L from the target node. This behavior is the result of the \u201crecursive neighborhood diffusion\u201d.", "As underlined by Dwivedi et al.:", "\u201cStacking L GNN layers allows the network to build node representations from the L-hop neighborhood of each node.\u201d", "The main differences between different GNN layers consist of the type of aggregation, which is performed by exploiting the local graph structure. In the simplest formulation of the GNN, such as the Vanilla Graph Convolutional Networks (GCNs), the aggregation/update is an isotropic operation. This means that the features of neighbor nodes are considered in the same way. More advanced neural architectures, such as the Graph Attention Network (GAT), introduce anisotropic operations, in which the contribution of each neighbor node in the aggregation is weighted according to its importance.", "In the next article, I will introduce the GCN layer, describing also a specific extension for graphs with labeled edges (Knowledge Graphs), named Relational Graph Convolutional Network (R-GCN).", "For further details on the anisotropic operation computed by the GAT layer, I suggest reading the following article, which provides a detailed explanation \u201cfrom math to NumPy\u201d.", "For further readings on Graph Representation Learning, you can follow my series at the following link: https://towardsdatascience.com/tagged/grl-series.", "If you like my articles, you can support me using this link https://medium.com/@giuseppefutia/membership and becoming a Medium member.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Data Scientist at GraphAware | Ph.D. at Politecnico di Torino. Passionate about Knowledge Graphs, Semantic Modeling, and Graph Neural Networks."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F56627f0719d5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----56627f0719d5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@giuseppefutia?source=post_page-----56627f0719d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giuseppefutia?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Giuseppe Futia"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F26954e99f7a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&user=Giuseppe+Futia&userId=26954e99f7a8&source=post_page-26954e99f7a8----56627f0719d5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/grl-series", "anchor_text": "GRL Series"}, {"url": "https://www.dgl.ai/", "anchor_text": "Deep Graph Library (DGL)"}, {"url": "https://pytorch-geometric.readthedocs.io/en/latest/", "anchor_text": "Pytorch Geometric"}, {"url": "https://arxiv.org/abs/2003.00982", "anchor_text": "https://arxiv.org/abs/2003.00982"}, {"url": "https://towardsdatascience.com/graph-theory-and-deep-learning-know-hows-6556b0e9891b", "anchor_text": "Graph Theory and Deep Learning know-howsGraph Learning and Geometric Deep Learning \u2014 Part 0towardsdatascience.com"}, {"url": "http://snap.stanford.edu/graphsage/", "anchor_text": "home page"}, {"url": "https://towardsdatascience.com/graph-neural-networks-for-multi-relational-data-27968a2ed143", "anchor_text": "Graph Neural Networks for Multi-Relational DataFrom GCNs to R-GCNs: encoding the structure of Knowledge Graphs with neural architectures (examples in NumPy code)towardsdatascience.com"}, {"url": "https://towardsdatascience.com/graph-attention-networks-under-the-hood-3bd70dc7a87", "anchor_text": "Graph Attention Networks Under the HoodA Step-by-step Guide From Math to NumPytowardsdatascience.com"}, {"url": "https://towardsdatascience.com/tagged/grl-series", "anchor_text": "https://towardsdatascience.com/tagged/grl-series"}, {"url": "https://medium.com/@giuseppefutia/membership", "anchor_text": "https://medium.com/@giuseppefutia/membership"}, {"url": "https://medium.com/tag/graph-neural-networks?source=post_page-----56627f0719d5---------------graph_neural_networks-----------------", "anchor_text": "Graph Neural Networks"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----56627f0719d5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----56627f0719d5---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/grl-series?source=post_page-----56627f0719d5---------------grl_series-----------------", "anchor_text": "Grl Series"}, {"url": "https://medium.com/tag/graph?source=post_page-----56627f0719d5---------------graph-----------------", "anchor_text": "Graph"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&user=Giuseppe+Futia&userId=26954e99f7a8&source=-----56627f0719d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&user=Giuseppe+Futia&userId=26954e99f7a8&source=-----56627f0719d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F56627f0719d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----56627f0719d5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----56627f0719d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----56627f0719d5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----56627f0719d5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----56627f0719d5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----56627f0719d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giuseppefutia?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giuseppefutia?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Giuseppe Futia"}, {"url": "https://medium.com/@giuseppefutia/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "732 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F26954e99f7a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&user=Giuseppe+Futia&userId=26954e99f7a8&source=post_page-26954e99f7a8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcf29694085e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5&newsletterV3=26954e99f7a8&newsletterV3Id=cf29694085e2&user=Giuseppe+Futia&userId=26954e99f7a8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}