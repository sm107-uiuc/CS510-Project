{"url": "https://towardsdatascience.com/kubernetesexecutor-for-airflow-e2155e0f909c", "time": 1682994983.710111, "path": "towardsdatascience.com/kubernetesexecutor-for-airflow-e2155e0f909c/", "webpage": {"metadata": {"title": "KubernetesExecutor for Airflow. Scale Airflow natively on Kubernetes | by Brecht De Vlieger | Towards Data Science", "h1": "KubernetesExecutor for Airflow", "description": "In the 1.10 release, Airflow introduced a new executor to run workers at scale: the Kubernetes executor. In this article we\u2019ll look into: Airflow has a new executor that spawns worker pods natively\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm", "anchor_text": "git repository", "paragraph_index": 1}, {"url": "https://airflow.apache.org/", "anchor_text": "Airflow", "paragraph_index": 3}, {"url": "https://luigi.readthedocs.io", "anchor_text": "Luigi", "paragraph_index": 3}, {"url": "http://oozie.apache.org/", "anchor_text": "Oozie", "paragraph_index": 3}, {"url": "https://azkaban.github.io/", "anchor_text": "Azkaban", "paragraph_index": 3}, {"url": "https://github.com/jghoman/awesome-apache-airflow", "anchor_text": "this curation of sources on Github", "paragraph_index": 5}, {"url": "http://www.celeryproject.org/", "anchor_text": "Celery", "paragraph_index": 8}, {"url": "https://github.com/mumoshu/kube-airflow", "anchor_text": "Here", "paragraph_index": 8}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm", "anchor_text": "Helm chart", "paragraph_index": 10}, {"url": "https://github.com/puckel/docker-airflow", "anchor_text": "docker-airflow", "paragraph_index": 13}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm/blob/master/airflow/values.yaml", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://github.com/apache/airflow/tree/master/airflow/example_dags", "anchor_text": "Airflow repository", "paragraph_index": 19}, {"url": "http://localhost:8080", "anchor_text": "http://localhost:8080", "paragraph_index": 25}], "all_paragraphs": ["In the 1.10 release, Airflow introduced a new executor to run workers at scale: the Kubernetes executor. In this article we\u2019ll look into:", "Airflow has a new executor that spawns worker pods natively on Kubernetes. There\u2019s a Helm chart available in this git repository, along with some examples to help you get started with the KubernetesExecutor.", "The data engineering space rapidly evolves to process and store ever-growing volumes of data. Lots of technologies exist today to store and query petabytes of raw data in so-called data lakes or data warehouses. Think of open-source platforms \u2014 Hadoop, Kafka, Druid, Ceph \u2014 or cloud-native solutions \u2014 Amazon Redshift and S3, Google BigQuery and GCS, Azure Data Warehouse and Data Lake. You can use tools such as Spark, Flink, Storm or Beam to process these humongous amounts of data. Or run a query on a data warehouse and store the results in a new table. Data pipelines often consist of many steps and many tools to move data around. So how can we sew these components together into a reliable workflow?", "A workflow scheduler manages dependencies between tasks and orchestrates their execution. Well-known schedulers are Airflow, Luigi, Oozie and Azkaban. Airflow gained a lot of support from the community because of its rich UI, flexible configuration and ability to write custom extensions. Airbnb started the project and open-sourced it as an Apache incubator.", "Imagine we have a pile of data sitting somewhere in Google Cloud Storage (GCS), waiting to be processed. We want to use Spark to clean the data and move it to BigQuery for analysis. The budget is tight, so we don\u2019t have a Hadoop cluster running 24/7. We first want to create a new Dataproc cluster (Dataproc is Hadoop on Google Cloud). Then the Spark job fetches the data from GCS, processes it and dumps it back to GCS. Finally, a BigQuery job loads the data from GCS into a table. At the same time we can close the Dataproc cluster to clean up our resources. Here\u2019s how such an Airflow workflow looks like.", "Airflow natively supports all the steps above and many more. Airflow also takes care of authentication to GCS, Dataproc and BigQuery. This was a simple illustrative example of how Airflow creates workflows between tasks. If you\u2019re new to Airflow, I highly recommend to check out this curation of sources on Github. This article assumes you already understand Airflow\u2019s essentials.", "Airflow can run more than just data pipelines. It can trigger any job with an API. That opens a world of opportunities! Before you know, your Airflow installation becomes crowded with pipelines. It\u2019s time to scale. Kubernetes is one of the leading technologies to scale applications. Individual pieces of an application run as isolated containers in so-called pods. Kubernetes duplicates those pods when the application needs more power.", "Airflow\u2019s architecture fits perfectly in this paradigm. At its core, a scheduler decides which tasks need to run next. The web server enables users to interact with DAGs and tasks. A database keeps track of the state of the current and past jobs. Finally, Airflow has workers that run the tasks. The scheduler, web server and database usually don\u2019t need to scale. It\u2019s the worker nodes that do the heavy duty. Airflow has two popular executors available that deploy workers at scale \u2014 the CeleryExecutor and KubernetesExecutor.", "Celery is a distributed task queue that balances the workload across multiple nodes. Using Celery to schedule jobs on worker nodes is a popular approach to scale Airflow. Here you can find a Helm chart to automate the deployment with the CeleryExecutor. But if using Celery works so well, then why would we need another executor for Kubernetes? Because celery is quite complex. You need to deploy Celery as an extra component in your system. And Celery requires a broker such as RabbitMQ or Redis as back-end. Additionally, you probably want Flower, a web interface, to monitor Celery. Perhaps these many components add too much overhead for the task at hand? Can\u2019t we have something more simple? Yes! Airflow 1.10 introduced a new executor to scale workers: the Kubernetes executor.", "With Celery, you deploy several workers up front. The queue will then schedule tasks across them. In contrast, the KubernetesExecutor runs no workers persistently. Instead, it spawns a new worker pod for every job. Airflow cleans up the resource as soon as the job finished. Now we leverage the full potential of Kubernetes. There\u2019s no more need for additional components. Scaling is only limited to the size of the cluster. As long as you have enough CPU and memory available, Airflow can keep scheduling more tasks. When Airflow has no more jobs to run, only the scheduler, web server and database remain alive. Your cluster can use its resources for other applications.", "Let\u2019s dive into the practical details. The remainder of the post walks through a simple example. We\u2019ll use a Helm chart to set up Airflow on minikube, but you can deploy it on any cloud provider if you want. Our deployment will sync the DAGs regularly from Airflow\u2019s git repository. Let\u2019s start by cloning the git repository.", "Before you continue, make sure that minikube is up and running. You might have to wait a minute after minikube has started to spin up the dashboard.", "First of all, we need a docker image that contains Airflow version 1.10.2 or higher. Make sure that you have Docker installed and that minikube is up and running. Follow these guides to install and set up docker and minikube. The repository contains a script to build the docker image.", "The script builds a new image from docker-airflow with the Kubernetes dependencies. When the script has finished, the image will be available as airflow:latest in the registry of minikube.", "Helm charts allow developers to create reusable Kubernetes deployments. Helm reads a values.yaml file and generates a set of yaml files. These files describe a Kubernetes deployment. We only have to create a new yaml file that overwrites the default settings to create a custom deployment. You can find all the default values and their explanation here. We\u2019ll cover the necessary changes one by one. Start by creating a new values.yaml file.", "Airflow uses a fernet key to encrypt passwords in the database. We don\u2019t want to store them as plain text of course. Here\u2019s how you can generate such a key.", "Paste the generated key in your values.yaml file.", "Next we have to tell which image to use. If you built the image on minikube, then the configuration looks like this:", "The pull_policy does not matter on minikube because it uses its local registry to get the Airflow image.", "We have to tell Airflow were to get the DAGs from and how to store them. Our example fetches the example DAGs from the Airflow repository at regular intervals and copies them to the DAGs folder. The following snippet shows you how to do this:", "Persistence must be disabled to pull DAGs from git. In most cases, the DAGs don\u2019t live in the root git folder. In our case, we have to look for them in the subdirectory ./airflow/example_dags. We\u2019ll pass this directory to subpath parameter. Its default value is dags. You can configure how frequently to pull DAGs from git using the wait field.", "Make sure your values.yaml file looks like the snippet below before continuing to the deployment.", "The remainder of the tutorial is child\u2019s play. With only a few commands, we\u2019ll have Airflow up and running. But first, we need to install Helm on minikube. By the way, we call the part of Helm that runs on Kubernetes Tiller. We\u2019ll also install the required Helm dependencies.", "Use Helm to generate the yaml files and deploy Airflow.", "Within a couple of minutes, Airflow should be up and running. Don\u2019t worry if it takes a little while. Usually, the web server and scheduler try to connect to the Postgres database before it\u2019s ready. The connection needs to time out before the pods fail and restart. To speed up the process, restart the web server and scheduler pods manually as soon as the database is ready.", "When all the pods are ready, you can use this command to port-forward the web UI to http://localhost:8080.", "Now try to run example_bash_operator by unpausing it. The DAG should run twice now. Watch how Airflow starts new pods and cleans up finished ones in the minikube dashboard. You can look at the logs in the graph and tree view. Unfortunately, you cannot view the logs from the task instances panel. That\u2019s still a bug in the KubernetesExecutor.", "Airflow 1.10 introduced a new executor to run Airflow at scale: the KubernetesExecutor. The scheduler interacts directly with Kubernetes to create and delete pods when tasks start and end. As a result, only the scheduler and web server are running when Airflow is idle. That frees up resources for other applications in the cluster. Airflow is now able to scale natively on Kubernetes without the need for additional components such as Celery. The deployment is much simpler and straightforward.", "However, the new executor is still pretty new and sometimes behaves a bit unexpected. Version 1.10.2 resolves most of the issues, so I recommend to use only this version or above. There\u2019s one tricky part remaining though. The volume for the logs needs to allow read and write access from all Airflow pods. Cloud providers don\u2019t natively support ReadWriteMany volumes, so you have to provide a solution yourself. The repository contains an example with an NFS server.", "Nonetheless, the executor works as expected and is stable enough to be put to production. The development team of Airflow did a great job. Kudos! Thank you for sticking to the end, I hope this post can be useful for your next deployment.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I believe data can be an asset to everyone. As a Data Engineer at Crunch Analytics, I search for ways to make data accessible and transparent within companies."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe2155e0f909c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@brechtdevlieger?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@brechtdevlieger?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Brecht De Vlieger"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb40009046e47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&user=Brecht+De+Vlieger&userId=b40009046e47&source=post_page-b40009046e47----e2155e0f909c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm", "anchor_text": "git repository"}, {"url": "https://unsplash.com/photos/nZL80Di-YAg", "anchor_text": "Background image"}, {"url": "https://airflow.apache.org/", "anchor_text": "Airflow"}, {"url": "https://luigi.readthedocs.io", "anchor_text": "Luigi"}, {"url": "http://oozie.apache.org/", "anchor_text": "Oozie"}, {"url": "https://azkaban.github.io/", "anchor_text": "Azkaban"}, {"url": "https://github.com/jghoman/awesome-apache-airflow", "anchor_text": "this curation of sources on Github"}, {"url": "https://unsplash.com/photos/ZpeCkOiiQUo", "anchor_text": "Background image"}, {"url": "http://www.celeryproject.org/", "anchor_text": "Celery"}, {"url": "https://github.com/mumoshu/kube-airflow", "anchor_text": "Here"}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm", "anchor_text": "Helm chart"}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm", "anchor_text": "https://github.com/BrechtDeVlieger/airflow-kube-helm"}, {"url": "https://github.com/puckel/docker-airflow", "anchor_text": "docker-airflow"}, {"url": "https://github.com/BrechtDeVlieger/airflow-kube-helm/blob/master/airflow/values.yaml", "anchor_text": "here"}, {"url": "https://github.com/apache/airflow/tree/master/airflow/example_dags", "anchor_text": "Airflow repository"}, {"url": "https://github.com/apache/airflow", "anchor_text": "https://github.com/apache/airflow"}, {"url": "https://github.com/apache/airflow", "anchor_text": "https://github.com/apache/airflow"}, {"url": "http://localhost:8080", "anchor_text": "http://localhost:8080"}, {"url": "https://medium.com/tag/airflow?source=post_page-----e2155e0f909c---------------airflow-----------------", "anchor_text": "Airflow"}, {"url": "https://medium.com/tag/kubernetes?source=post_page-----e2155e0f909c---------------kubernetes-----------------", "anchor_text": "Kubernetes"}, {"url": "https://medium.com/tag/docker?source=post_page-----e2155e0f909c---------------docker-----------------", "anchor_text": "Docker"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----e2155e0f909c---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/software-engineering?source=post_page-----e2155e0f909c---------------software_engineering-----------------", "anchor_text": "Software Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&user=Brecht+De+Vlieger&userId=b40009046e47&source=-----e2155e0f909c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&user=Brecht+De+Vlieger&userId=b40009046e47&source=-----e2155e0f909c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe2155e0f909c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e2155e0f909c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e2155e0f909c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e2155e0f909c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e2155e0f909c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@brechtdevlieger?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@brechtdevlieger?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Brecht De Vlieger"}, {"url": "https://medium.com/@brechtdevlieger/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "85 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb40009046e47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&user=Brecht+De+Vlieger&userId=b40009046e47&source=post_page-b40009046e47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fb40009046e47%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkubernetesexecutor-for-airflow-e2155e0f909c&user=Brecht+De+Vlieger&userId=b40009046e47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}