{"url": "https://towardsdatascience.com/explaining-machine-learning-classifiers-with-lime-def5adaacfea", "time": 1683008995.732793, "path": "towardsdatascience.com/explaining-machine-learning-classifiers-with-lime-def5adaacfea/", "webpage": {"metadata": {"title": "Explaining Machine Learning Classifiers with LIME | by Teemu Kanstr\u00e9n | Towards Data Science", "h1": "Explaining Machine Learning Classifiers with LIME", "description": "Machine learning algorithms can produce impressive results in classification, prediction, anomaly detection, and many other hard problems. Understanding what the results are based on is often\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "anchor_text": "Explainable AI", "paragraph_index": 0}, {"url": "https://www.darpa.mil/attachments/XAIProgramUpdate.pdf", "anchor_text": "for", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1909.06342", "anchor_text": "many", "paragraph_index": 1}, {"url": "https://ucbrise.github.io/cs294-ai-sys-sp19/assets/lectures/lec26/xai.pdf", "anchor_text": "reasons", "paragraph_index": 1}, {"url": "https://www.h2o.ai/blog/h2o-world-explainable-machine-learning-discussions-recap/", "anchor_text": "including", "paragraph_index": 1}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME", "paragraph_index": 2}, {"url": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/", "anchor_text": "Local Interpretable Model-Agnostic Explanations", "paragraph_index": 2}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "There", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "anchor_text": "are", "paragraph_index": 3}, {"url": "https://medium.com/analytics-vidhya/explain-your-model-with-lime-5a1a5867b423", "anchor_text": "plenty", "paragraph_index": 3}, {"url": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/", "anchor_text": "introductory", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/explainable-machine-learning-for-healthcare-7e408f8e5130", "anchor_text": "articles", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/explain-nlp-models-with-lime-shap-5c5a9f84d59b", "anchor_text": "around", "paragraph_index": 3}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "LIME", "paragraph_index": 3}, {"url": "https://github.com/Microsoft/LightGBM", "anchor_text": "LGBM", "paragraph_index": 9}, {"url": "https://catboost.ai/", "anchor_text": "Catboost", "paragraph_index": 9}, {"url": "https://github.com/dmlc/xgboost", "anchor_text": "XGBoost", "paragraph_index": 9}, {"url": "https://www.kaggle.com/c/titanic", "anchor_text": "Titanic", "paragraph_index": 10}, {"url": "https://github.com/mukatee/ml-experiments/blob/master/lime/Explaining%20models%20with%20LIME.ipynb", "anchor_text": "Github", "paragraph_index": 11}, {"url": "https://www.kaggle.com/donkeys/explaining-models-with-lime-et-al", "anchor_text": "Kaggle notebook", "paragraph_index": 11}, {"url": "https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/", "anchor_text": "articles", "paragraph_index": 12}, {"url": "https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html", "anchor_text": "documentation", "paragraph_index": 12}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "very good criticism", "paragraph_index": 13}, {"url": "https://scikit-learn.org/stable/modules/permutation_importance.html", "anchor_text": "permutation importance", "paragraph_index": 13}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation importance function", "paragraph_index": 15}, {"url": "https://www.kaggle.com/ronitf/heart-disease-uci", "anchor_text": "Cleveland Heart Disease risk", "paragraph_index": 39}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview", "anchor_text": "Ames Housing Dataset", "paragraph_index": 48}, {"url": "https://pythondata.com/local-interpretable-model-agnostic-explanations-lime-python/", "anchor_text": "a Python Data article", "paragraph_index": 49}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "this book chapter", "paragraph_index": 55}, {"url": "https://towardsdatascience.com/explainable-artificial-intelligence-14944563cc79", "anchor_text": "sales", "paragraph_index": 58}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "arguments", "paragraph_index": 58}, {"url": "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability", "anchor_text": "integrated", "paragraph_index": 58}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "Some even say", "paragraph_index": 59}], "all_paragraphs": ["Machine learning algorithms can produce impressive results in classification, prediction, anomaly detection, and many other hard problems. Understanding what the results are based on is often complicated, since many algorithms are black boxes with little visibility into their inner working. Explainable AI is a term referring to techniques for providing human-understandable explanations of ML algorithm outputs.", "Explainable AI is interesting for many reasons, including being able to reason about the algorithms used, the data we have to train them, and to understand better how to test the system using such algorithms.", "LIME, or Local Interpretable Model-Agnostic Explanations is one technique that seems to have gotten attention lately in this area. The idea of LIME is to give it a single datapoint, and the ML algorithm to use, and it will try to build understandable explanation for the output of the ML algorithm for that specific datapoint. Such as \u201cbecause this person was found to be sneezing and coughing (datapoint features), there is a high probability they have a flu (ML output)\u201d.", "There are plenty of introductory articles around for LIME, but I felt I needed something more concrete. So I tried it out on a few classifiers and datasets / datapoints to see. This article discusses the results.", "For the impatient, I can summarize LIME seem interesting and going in the right direction, but I still found the details confusing to interpret. It didn\u2019t really make me very confident on the explanations. There seems to be still ways to go for easy to understand, and high confidence explanations.", "There are three sections to my experiments in this article. First, I try to use LIME to explain the output from three different ML algorithms specifically designed for tabular data. Second, I try explaining the output of a generic neural network architecture. Third, I try a regression problem as opposed to the first two, which examine a classification problem. Each of the three sections uses LIME to explain a few datapoints, each from different datasets for variety.", "As a little experiment, I took a single feature that was ranked as having a high contribution to the explanation for a datapoint by LIME, for each ML algorithm in my experiments, and inverted (or changed) their value. I then re-ran the ML algorithm and LIME on this same datapoint, with the single value changed, and compared the explanation.", "The inverted feature was in most cases a binary categorical feature (in one case categorical with 4 possible values), making the inversion process obvious (e.g, change gender from male to female or the other way around). The point with this was just to see if changing the value of a feature that LIME weights highly results in large changes in the ML algorithm outputs and associated LIME weights variable importances.", "The datasets used in different sections:", "Some of the most popular classifiers I see with tabular data are gradient boosted decision tree based ones; LGBM, Catboost, and XGBoost. Many others exist that I also use at times, such as Naive Bayes, Random Forest, and Logistic Regression. However, LGBM, Catboost, and XGBoost are ones I often try first these days for tabular data. So I try using LIME to explain a few datapoints for each of these ML algorithms in this section. I expect a similar evaluation for other ML algorithms should follow a quite similar process.", "For this section, I use the Titanic dataset. The goal with this dataset is to predict who would survive the shipwreck and who would not. Its features:", "The actual notebook code is available on my Github as well as in a Kaggle notebook.", "Each of the three boosting models (LGBM, Catboost, XGBoost) provides access to their internal statistics as a form of feature weights. For details, check some articles and documentation. These types of model feature weights provide a more holistic view of the model workings, over all datapoints as opposed to the single datapoint that LIME tries to explain. In the following, I will show these feature weights for comparison where available.", "However, there is also some very good criticism on using these types of classifier internal statistics for feature importances, noting it might also be meaningful to compare with other techniques such as permutation importance and drop-column importance. As such, I calculate also permutation importance for each of the three boosters here, as well as later for the Keras NN classifier.", "The following figure illustrates the weights given by the model itself, when I trained it on the Titanic dataset, via the classifier feature_importances_ attribute.", "And the ones illustrated by the following figure are the ones given by the SKLearn\u2019s permutation importance function for the same classifier.", "Comparing the two above - the model statistics based weights, and the permutation based weights, there is quite a difference in what they rank higher. Something interesting to keep in mind for LIME next.", "The following figure illustrates the LIME explanations (figures are from LIME itself) for the first datapoint I picked in the test set for Titanic data:", "The figure shows two versions of the same datapoint. The one on the left is the original data from the dataset. The one on the right has the sex attribute changed to the opposite gender. This is the invertion of the highly ranked LIME feature I mentioned before. As you can see in this figure, LIME ranks it as the highest ranking feature for this datapoint.", "Now, compare these LIME visualizations/explanations for these two datapoint variants, to the global feature importances above (from model internal statistics and permutation score). The top features presented by LIME closely match those given by the global permutation importance as top features. In fact, it is almost an exact match.", "Beyond that, the left side of the figure illustrates one of my main confusions about LIME in general. The prediction of the classifier for this datapoint is:", "I would expect the LIME feature weights to show highest contributions then for the not survived classification. But it shows much higher weights for survived. By far \u201cSex=male\u201d seems to be the heaviest weight for any variable given by LIME here, and it is shown as pointing towards survived. Similarly, the overall LIME feature weights in the left hand figure are", "Funny how the not survived weights sum up the exact prediction value for survived. I might think I am looking at it the wrong way, but further explanations I tried with other datapoints seem to indicate otherwise. Starting with the right part of the above figure.", "The right side of the above figure, with the gender inverted, also shows the sex attribute as the highest contibutor. But now, the title has risen much higher. So perhaps it is telling that a female master has a higher change of survival? I don\u2019t know, but certainly the predictions of the classifier changed to:", "Similarly, passenger class ( Pclass) value has jumped from weighting on survival to weighting on non-survival. The sums of LIME feature weights in the inverted case do not seem too different overall, but the prediction has changed by quite a bit. I would have hoped for simple and easy to understand explanations, but it seems complicated.", "LIME explanation for the second datapoint in the test set:", "For this one, the ML prediction for the left side original datapoint seems to indicate even more strongly that the predicted survival chance is low (not survived is 81%), but the LIME feature weights point even stronger into the opposite direction (LIME weights almost all feature values as contributing to survived).", "On the other hand, the right side of this figure, with the gender value inverted, provides a quite good match with the LIME weights vs the actual prediction. Both weight survival higher, at relatively close ratios for both LIME andthe ML algorithm. But compared to the original datapoint here (gender not inverted, left side), it is not consistent in any way. For the original, LIME weights do not match the prediction, for the changed datapoint it is close.", "Of course, the right side figure here illustrates a bit how silly my changes can be (inverting only gender). I would not expect the combination of female with mr to happen in real data. But regardless of the sanity of some of the value combinations, I would expect the explanation to reflect the prediction equally well. After all, LIME is designed to explain a given prediction with given features, however crazy those features might be.", "An interesting point is also how the gender seems to always weight heavily towards survival in both cases here. Perhaps it is due to the combinatorics of the other feature values, but given how the LIME weights vs predictions seem to vary across datapoints, I wouldn\u2019t be so sure. If the value is indicating high survival in both cases, they why would it have high explanatory power? Given that all (both) values would indicate the same result (while no other value changes)?", "Model feature weights based on model internals:", "In this case, LIME seems to rank males as not surviving, while females as surviving, both with very high weights. Of course, this is for a single datapoint, and so depends on the specific values of the other variables as well. The total weighting of survived vs not-survived is not too far in this case for LIME vs the ML classifier. However, the gender change has little impact on the ML output, while having a large impact on LIME output. Again, does not seem very consistent.", "As opposed to the LGBM case/section above, in this case (for Catboost) the top LIME features actually seem to follow almost exactly the global feature weights from the model internal statistics. For LGBM it was the other way around, they were not following the internal weights but rather the permutation weights. Confusing, although one is datapoint specific and the other is global.", "In this case, LIME is giving very high weights for variables on the side of survived, while the actual classifier is almost fully predicting non-survival. Does not make me feel very confident.", "Model feature weights based on model internal statistics:", "In this case, the left one seems to indicate not-survived on the weights quite heavily, but the actual predictions are quite even on survived and not survived. On the right side the weights vs predictions are more in line with LIME feature weights, seeming to match prediction.", "As for LIME weights vs the global weights from model internals and permutations, in this case they seem to be mixed. Some LIME top features are shared with the top global feature weights for model internals, some are shared with permutations.", "Compared to the previous sections, the LIME weights vs model and permutation weights seem to be all over the place. This might be related some attribute of the different ML algorithms in case of the internal feature weights, and how LIME considers single datapoints vs globally the whole model. However, I would expect LIME to be more consistent with regards to permutation weights, as that algorithm is the same across classifiers.", "Here, the left side LIME figure seems to indicate much more of survival on the weights, and non-survival in actual XGBoost prediction. On the right side, the weights and predictions seem more in line again. Not very consistent.", "This section uses a different dataset of the Cleveland Heart Disease risk. The inverted variable in this case is not gender but the cp variable, since it seemed to be the highest scoring categorical variable for LIME on the datapoints I looked at. This cp variable also has 4 values, not 2, but in any case, I expect changing a high scoring variable to show some impact.", "Keras does not provide feature weights based on model internal statistics, being a generic neural networks framework, as opposed to specific algorithms such as the boosters above. But permutation based feature weighting is always an option:", "Training curves are always nice to look at, so here you go:", "First datapoint explained by LIME for Keras:", "This one is predicting almost fully no risk on both datapoints. Yet the LIME weights seem to be indicating almost fully on the risk of heart side. The change of the cp (chest pain) value from 0 to 1 has dropped the variable completely from the LIME list of top features. However, the LIME weights still indicate heavily on the risk of heart side, while the ML algorithm prediction is almost fully on the side of no risk. Very inconsistent.", "Compared to the global permutation weights, the LIME weights share the same top 1\u20132 features, with some changes in the lower ranked features.", "Second datapoint explained by LIME for Keras:", "In this case, the predictions and LIME weights are more mixed on both sides. The right side seems to have the weights much more on the no risk side than the left side, yet the ML algorithm prediction has shifted more in the opposite direction, towards the risk of heart side.", "In this case, the features are quite different from the first datapoint, and also from the global weights given by permutation importance. This is likely not an issue since LIME aims to explain single datapoints and not the global model. However, I do see an issue in not being able to map the LIME weights to the predictions in any reasonable way. Not consistently at least. Sometimes the LIME weights are consistent with the prediction, often not, and sometimes completely opposite.", "Features in the Ames Housing Dataset used in this section:", "As discussed a Python Data article, LIME results seem more intuitive to reason about for classification than regression. For regression it should show some relative value of how the feature values contribute to the predicted regression value. In this case this would be how the specific features values are predicted to impact the house price.", "However, the meaning of this is a bit unclear. For example, what does it mean for something to be positively weighted? Or negatively? Regards to what? What is the baseline, or what are the weights against? A more thorough evaluation of explaining regression models would be interesting, but at least LIME can be applied. Just as with classification, the results could maybe be a bit more intuitive.", "Just out of interest, here is a description of the data distribution for the features shown above.", "One could perhaps make some analysis of how the feature value distributions are with regards to the LIME weights for those variables, and use those as a means to analyze the LIME results further in relation to the predicted price. Maybe someday someone will.. \ud83d\ude42", "Compared to all the global feature weights given by the model internal statistics, and the permutation based weights, the results I showed in this article are often sharing some of the top features. And comparing explanations for different datapoints using the same algorithm, there appears to be some changes in which features LIME ranks highest per datapoint. Overall, this all makes sense considering what LIME is supposed to be. Explaining individual data points, where the globally important features likely often (and on average should) rank high, but where single points can vary.", "The LIME visualization in general seems like a good way to visualize feature importances for a datapoint. I like how the features are presented as weighting in one direction vs other. The idea of trying values close to a point to come up with an explanation also seems to make sense. However, many of the results I saw in my experiments do not quite seem to make sense. The LIME weights presented often seem to be opposed to the actual predictions from the ML algorithm.", "I tried to look for any insights on this online, and this book chapter hosts some good discussion on the limitations of LIME, and maybe it explains some of this. The book chapters ends up says to use great care in applying LIME, and how the LIME parameters impact the results and explanations given. Which seems in line with what I see above.", "Many of the articles I found (some linked in the beginning) provide a single example, or some graphs from the LIME papers, and simply gloss over the interpretation of the results, providing few insights into how it performs at a larger scale. For me, it seems simple enough to find some examples that fit assumptions and make the technique look good. This is quite common in academia, where you want to show good results for your research. However, this does not necessarily match my expectations if I try to use it for real. In my experiments, I got the results that I showed here, where I cannot really match LIME results with the classifier output confidently in the overall dataset.", "More useful would be maybe to understand the limitations, and not expect LIME (or any other technique) to work perfectly in every case. When the results seem to differ from the presentation (advertising) material, I get the feeling maybe the parts show are cherry-picked. Having worked in research myself, and LIME being the results of research, this is of course how it works. You don\u2019t get papers accepted or funding and tenure granted for not showing great results, or showing issues in your approach. But not discussing them makes it more difficult to figure our the working techniques for practical use.", "Overall, with these results I would not really use LIME for more than some experiments. Mostly because I cannot see myself trusting these types of results very much, no matter what the sales arguments. But overall, it seems like interesting work, and I like the underlying ideas. Perhaps it will help produce other new explainable AI techniques that work better for me. Along these lines, it is also nice to see these types of approaches being integrated as part of ML platform offerings and services.", "There are other interesting methods for similar approaches as well. SHAP is one that seems very popular, and Eli5 is another. Some even say LIME is a subset of SHAP, which should be more complete vs the sampling approach taken by LIME. Perhaps it would be worth the effort to make a comparison some day..", "If you have some ideas on what I missed, or could do better, happy to hear :).", "That\u2019s all for this time. Cheers.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD. Technology research and software engineering. Typically I write too long, because I try to understand something myself."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdef5adaacfea&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://teemukanstren.medium.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": ""}, {"url": "https://teemukanstren.medium.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Teemu Kanstr\u00e9n"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9fc0679190dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&user=Teemu+Kanstr%C3%A9n&userId=9fc0679190dc&source=post_page-9fc0679190dc----def5adaacfea---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "anchor_text": "Explainable AI"}, {"url": "https://www.darpa.mil/attachments/XAIProgramUpdate.pdf", "anchor_text": "for"}, {"url": "https://arxiv.org/abs/1909.06342", "anchor_text": "many"}, {"url": "https://ucbrise.github.io/cs294-ai-sys-sp19/assets/lectures/lec26/xai.pdf", "anchor_text": "reasons"}, {"url": "https://www.h2o.ai/blog/h2o-world-explainable-machine-learning-discussions-recap/", "anchor_text": "including"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME"}, {"url": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/", "anchor_text": "Local Interpretable Model-Agnostic Explanations"}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "There"}, {"url": "https://towardsdatascience.com/understanding-model-predictions-with-lime-a582fdff3a3b", "anchor_text": "are"}, {"url": "https://medium.com/analytics-vidhya/explain-your-model-with-lime-5a1a5867b423", "anchor_text": "plenty"}, {"url": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/", "anchor_text": "introductory"}, {"url": "https://towardsdatascience.com/explainable-machine-learning-for-healthcare-7e408f8e5130", "anchor_text": "articles"}, {"url": "https://towardsdatascience.com/explain-nlp-models-with-lime-shap-5c5a9f84d59b", "anchor_text": "around"}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "LIME"}, {"url": "https://pixabay.com/users/stevepb-282134/", "anchor_text": "Steve Buissinne"}, {"url": "https://pixabay.com/photos/lime-club-soda-drink-cocktail-907124/", "anchor_text": "Pixabay"}, {"url": "https://www.kaggle.com/c/titanic", "anchor_text": "Titanic"}, {"url": "https://www.kaggle.com/ronitf/heart-disease-uci", "anchor_text": "Heart disease UCI"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview", "anchor_text": "Ames housing dataset"}, {"url": "https://github.com/Microsoft/LightGBM", "anchor_text": "LGBM"}, {"url": "https://catboost.ai/", "anchor_text": "Catboost"}, {"url": "https://github.com/dmlc/xgboost", "anchor_text": "XGBoost"}, {"url": "https://www.kaggle.com/c/titanic", "anchor_text": "Titanic"}, {"url": "https://github.com/mukatee/ml-experiments/blob/master/lime/Explaining%20models%20with%20LIME.ipynb", "anchor_text": "Github"}, {"url": "https://www.kaggle.com/donkeys/explaining-models-with-lime-et-al", "anchor_text": "Kaggle notebook"}, {"url": "https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/", "anchor_text": "articles"}, {"url": "https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html", "anchor_text": "documentation"}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "very good criticism"}, {"url": "https://scikit-learn.org/stable/modules/permutation_importance.html", "anchor_text": "permutation importance"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html", "anchor_text": "permutation importance function"}, {"url": "https://www.kaggle.com/ronitf/heart-disease-uci", "anchor_text": "Cleveland Heart Disease risk"}, {"url": "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview", "anchor_text": "Ames Housing Dataset"}, {"url": "https://pythondata.com/local-interpretable-model-agnostic-explanations-lime-python/", "anchor_text": "a Python Data article"}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "this book chapter"}, {"url": "https://towardsdatascience.com/explainable-artificial-intelligence-14944563cc79", "anchor_text": "sales"}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "arguments"}, {"url": "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability", "anchor_text": "integrated"}, {"url": "https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/", "anchor_text": "Some even say"}, {"url": "https://swenotes.wordpress.com/2020/06/10/explaining-machine-learning-classifiers-with-lime/", "anchor_text": "http://swenotes.wordpress.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----def5adaacfea---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----def5adaacfea---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/data-science?source=post_page-----def5adaacfea---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&user=Teemu+Kanstr%C3%A9n&userId=9fc0679190dc&source=-----def5adaacfea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&user=Teemu+Kanstr%C3%A9n&userId=9fc0679190dc&source=-----def5adaacfea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdef5adaacfea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----def5adaacfea---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----def5adaacfea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----def5adaacfea--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----def5adaacfea--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----def5adaacfea--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----def5adaacfea--------------------------------", "anchor_text": ""}, {"url": "https://teemukanstren.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://teemukanstren.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Teemu Kanstr\u00e9n"}, {"url": "https://teemukanstren.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "125 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9fc0679190dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&user=Teemu+Kanstr%C3%A9n&userId=9fc0679190dc&source=post_page-9fc0679190dc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F233b40996863&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-machine-learning-classifiers-with-lime-def5adaacfea&newsletterV3=9fc0679190dc&newsletterV3Id=233b40996863&user=Teemu+Kanstr%C3%A9n&userId=9fc0679190dc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}