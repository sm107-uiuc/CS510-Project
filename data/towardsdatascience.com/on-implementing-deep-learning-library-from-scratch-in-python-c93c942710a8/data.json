{"url": "https://towardsdatascience.com/on-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8", "time": 1683003381.789783, "path": "towardsdatascience.com/on-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8/", "webpage": {"metadata": {"title": "On Implementing Deep Learning Library from Scratch in Python | by Parmeet Bhatia | Towards Data Science", "h1": "On Implementing Deep Learning Library from Scratch in Python", "description": "Deep Learning has evolved from simple neural networks to quite complex architectures in a short span of time. To support this rapid expansion, many different deep learning platforms and libraries are\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/parmeet/dll_numpy", "anchor_text": "https://github.com/parmeet/dll_numpy", "paragraph_index": 0}, {"url": "https://keras.io/initializers/", "anchor_text": "https://keras.io/initializers/", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Automatic_differentiation", "anchor_text": "https://en.wikipedia.org/wiki/Automatic_differentiation", "paragraph_index": 9}, {"url": "https://github.com/BVLC/caffe", "anchor_text": "Caffe", "paragraph_index": 11}, {"url": "https://keras.io/", "anchor_text": "Keras", "paragraph_index": 22}, {"url": "http://cs231n.github.io/neural-networks-case-study/", "anchor_text": "blog-post", "paragraph_index": 25}, {"url": "https://cs.stanford.edu/people/karpathy/", "anchor_text": "Andrej Karapathy", "paragraph_index": 25}], "all_paragraphs": ["Deep Learning has evolved from simple neural networks to quite complex architectures in a short span of time. To support this rapid expansion, many different deep learning platforms and libraries are developed along the way. One of the primary goals for these libraries is to provide easy to use interfaces for building and training deep learning models, that would allow users to focus more on the tasks at hand. To achieve this, it may require to hide core implementation units behind several abstraction layers that make it difficult to understand basic underlying principles on which deep learning libraries are based. Hence the goal of this article is to provide insights on building blocks of deep learning library. We first go through some background on Deep Learning to understand functional requirements and then walk through a simple yet complete library in python using NumPy that is capable of end-to-end training of neural network models (of very simple types). Along the way, we will learn various components of a deep learning framework. The library is just under 100 lines of code and hence should be fairly easy to follow. The complete source code can be found at https://github.com/parmeet/dll_numpy", "Typically a deep learning computation library (like TensorFlow and PyTorch) consists of components shown in the figure below.", "Also used interchangeably with layers, they are the basic building blocks of any neural network. Operators are vector-valued functions that transform the data. Some commonly used operators are layers like linear, convolution, and pooling, and activation functions like ReLU and Sigmoid.", "They are the backbones of any deep learning library. They provide the necessary recipe to update model parameters using their gradients with respect to the optimization objective. Some well-known optimizers are SGD, RMSProp, and Adam.", "They are closed-form and differentiable mathematical expressions that are used as surrogates for the optimization objective of the problem at hand. For example, cross-entropy loss and Hinge loss are commonly used loss functions for the classification tasks.", "They provide the initial values for the model parameters at the start of training. Initialization plays an important role in training deep neural networks, as bad parameter initialization can lead to slow or no convergence. There are many ways one can initialize the network weights like small random weights drawn from the normal distribution. You may have a look at https://keras.io/initializers/ for a comprehensive list.", "They provide the necessary control mechanism to avoid overfitting and promote generalization. One can regulate overfitting either through explicit or implicit measures. Explicit methods impose structural constraints on the weights, for example, minimization of their L1-Norm and L2-Norm that make the weights sparser and uniform respectively. Implicit measures are specialized operators that do the transformation of intermediate representations, either through explicit normalization, for example, BatchNorm, or by changing the network connectivity, for example, DropOut and DropConnect.", "The above-mentioned components basically belong to the front-end part of the library. By front-end, I mean the components that are exposed to the user for them to efficiently design neural network architectures. On the back-end side, these libraries provide support for automatically calculating gradients of the loss function with respect to various parameters in the model. This technique is commonly referred to as Automatic Differentiation (AD).", "Every deep learning library provides a flavor of AD so that a user can focus on defining the model structure (computation graph)and delegate the task of gradients computation to the AD module. Let us go through an example to see how it works. Say we want to calculate partial derivatives of the following function with respect to its input variables X\u2081 and X\u2082:", "The following figure, which I have borrowed from https://en.wikipedia.org/wiki/Automatic_differentiation, shows it\u2019s computation graph and calculation of derivatives via chain-rule.", "What you see in the above figure is a flavor of reverse-mode automatic differentiation (AD). The well known Back-propagation algorithm is a special case of the above algorithm where the function at the top is loss function. AD exploits the fact that every composite function consists of elementary arithmetic operations and elementary functions, and hence the derivatives can be computed by recursively applying the chain-rule to these operations.", "In the previous section, we have gone through all the necessary components to come up with our first deep learning library that can do end-to-end training. To keep things simple, I will mimic the design pattern of the Caffe Library. Here we define two abstract classes: A \u201cFunction\u201d class and an \u201cOptimizer\u201d class. In addition, there is a \u201cTensor\u201d class which is a simple structure containing two NumPy multi-dimensional arrays, one for holding the value of parameters and another for holding their gradients. All the parameters in various layers/operators will be of type \u201cTensor\u201d. Before we dig deeper, the following figure provides a high-level overview of the library.", "At the time of this writing, the library comes with the implementation of the linear layer, ReLU activation, and SoftMaxLoss Layer along with the SGD optimizer. Hence the library can be used to train a classification model comprising of fully connected layers and ReLU non-linearity. Lets now go through some details of the two abstract classes we have.", "The \u201cFunction\u201d abstract class provides an interface for operators and is defined as follows:", "All the operators are implemented by inheriting the \u201cFunction\u201d abstract class. Each operator must provide an implementation of forward(\u2026) and backward(\u2026) methods and optionally implement getParams function to provide access to its parameters (if any). The forward(\u2026) method receives the input and returns its transformation by the operator. It will also do any house-keeping necessary to compute the gradients. The backward(\u2026) method receives partial derivatives of the loss function with respect to the operator\u2019s output and implements the partial derivatives of loss with respect to the operator\u2019s input and parameters (if there are any). Note that backward(\u2026) function essentially provides the capability for our library to perform automatic differentiation.", "To make things concrete let\u2019s look at the implementation of the Linear function as shown in the following code snippet:", "The forward(\u2026) function implements the transformation of the form Y = X*W+b and returns it. It also stores the input X as this is needed to compute the gradients of W in the backward function. The backward(\u2026) function receives partial derivatives dY of loss with respect to the output Y and implements the partial derivatives with respect to input X and parameters W and b. Furthermore, it returns the partial derivatives with respect to the input X, that will be passed on to the previous layer.", "The abstract \u201cOptimizer\u201d class provides an interface for optimizers and is defined as follows:", "All the optimizers are implemented by inheriting the \u201cOptimizer\u201d base class. The concrete optimization class must provide the implementation for the step() function. This method updates the model parameters using their partial derivatives with respect to the loss we are optimizing. The reference to various model parameters is provided in the __init__(\u2026) function. Note that the common functionality of resetting gradients is implemented in the base class itself.", "To make things concrete, let\u2019s look at the implementation of stochastic gradient descent (SGD) with momentum and weight decay.", "To this end, we have all the ingredients to train a (deep) neural network model using our library. To do so, we would need the following:", "The following pseudo-code depicts a typical training cycle:", "Though not a necessary ingredient for a deep learning library, it may be a good idea to encapsulate the above functionality in a class so that we don\u2019t have to repeat ourselves every time we need to train a new model (this is in line with the philosophy of higher-level abstraction frameworks like Keras). To achieve this, let\u2019s define a class \u201cModel\u201d as shown in the following code snippet:", "This class serves the following functionalities:", "Since this class does not serve as a fundamental building block for deep learning, I implemented it in a separate module called utilities.py. Note that the fit(\u2026) function makes use of DataGenerator Class whose implementation is also provided in the utilities.py module. This class is just a wrapper around our training data and generate mini-batches for each training iteration.", "Let\u2019s now go through the final piece of code that trains a neural network model using the proposed library. Inspired by the blog-post of Andrej Karapathy, I am going to train a hidden layer neural network model on spiral data. The code for generating the data and it\u2019s visualization is available in the utilities.py file.", "A three-class spiral data is shown in the above figure. The data is non-linearly separable. So we hope that our one hidden layer neural network can learn the non-linear decision boundary. Bringing it all together, the following code snippet will train our model.", "The following figure shows the same spiral data together with the decision boundaries of the trained model.", "With the ever-increasing complexity of deep learning models, the libraries tend to grow at exponential rates both in terms of functionalities and their underlying implementation. That said, the very core functionalities can still be implemented in a relatively small number of lines of code. Although the library can be used to train end-to-end neural network models (of very simple types), it is still restricted in many ways that make deep learning frameworks usable in various domains including (but not limited to) vision, speech, and text. With that said, I think this is also an opportunity to fork the base implementation and add missing functionalities to get your hands-on experience. Some of the things you can try to implement are:", "I hope this article gives you a glimpse of what happens under the hood when you use any deep learning library to train your models. Thank you for your attention and I look forward to your comments or any questions in the comment section.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc93c942710a8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c93c942710a8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bhatia.parmeet?source=post_page-----c93c942710a8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhatia.parmeet?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Parmeet Bhatia"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F68eb2b2d729b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&user=Parmeet+Bhatia&userId=68eb2b2d729b&source=post_page-68eb2b2d729b----c93c942710a8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/parmeet/dll_numpy", "anchor_text": "https://github.com/parmeet/dll_numpy"}, {"url": "https://keras.io/initializers/", "anchor_text": "https://keras.io/initializers/"}, {"url": "https://en.wikipedia.org/wiki/Automatic_differentiation", "anchor_text": "https://en.wikipedia.org/wiki/Automatic_differentiation"}, {"url": "https://github.com/BVLC/caffe", "anchor_text": "Caffe"}, {"url": "https://keras.io/", "anchor_text": "Keras"}, {"url": "http://cs231n.github.io/neural-networks-case-study/", "anchor_text": "blog-post"}, {"url": "https://cs.stanford.edu/people/karpathy/", "anchor_text": "Andrej Karapathy"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c93c942710a8---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----c93c942710a8---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----c93c942710a8---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/libraries?source=post_page-----c93c942710a8---------------libraries-----------------", "anchor_text": "Libraries"}, {"url": "https://medium.com/tag/software-architecture?source=post_page-----c93c942710a8---------------software_architecture-----------------", "anchor_text": "Software Architecture"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&user=Parmeet+Bhatia&userId=68eb2b2d729b&source=-----c93c942710a8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&user=Parmeet+Bhatia&userId=68eb2b2d729b&source=-----c93c942710a8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc93c942710a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c93c942710a8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c93c942710a8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c93c942710a8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c93c942710a8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c93c942710a8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c93c942710a8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhatia.parmeet?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bhatia.parmeet?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Parmeet Bhatia"}, {"url": "https://medium.com/@bhatia.parmeet/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "72 Followers"}, {"url": "http://www.linkedin.com/in/parmeet-bhatia-616b0923", "anchor_text": "www.linkedin.com/in/parmeet-bhatia-616b0923"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F68eb2b2d729b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&user=Parmeet+Bhatia&userId=68eb2b2d729b&source=post_page-68eb2b2d729b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F68eb2b2d729b%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fon-implementing-deep-learning-library-from-scratch-in-python-c93c942710a8&user=Parmeet+Bhatia&userId=68eb2b2d729b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}