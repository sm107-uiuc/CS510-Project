{"url": "https://towardsdatascience.com/utilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d", "time": 1683016830.134702, "path": "towardsdatascience.com/utilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d/", "webpage": {"metadata": {"title": "Utilization of Twitter\u2019s API with R \u2014 Advanced Techniques. | by Justin Cocco | Towards Data Science", "h1": "Utilization of Twitter\u2019s API with R \u2014 Advanced Techniques.", "description": "Twitter\u2019s API is free-to-use and is overall a very useful resource for data analysis. Extracting tweets for one, or several, users can happen without much additional work other than using an R\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Twitter\u2019s API is free-to-use and is overall a very useful resource for data analysis. Extracting tweets for one, or several, users can happen without much additional work other than using an R package. Yet \u2014 if you are interested in harvesting millions of tweets from tens of thousands of users, you will have to sacrifice additional tears. Here, the general strategy will be outlined for doing just that so that you don\u2019t also lose your collective minds.", "The goal is to outline the progressive steps taken to produce a robust and functioning script to extract millions of timelines from a list of thousands of users.", "The general flow of this write-up will be:", "2 \u2014 Explanation of requirements in code", "4 \u2014 Putting it all together", "There are two main strategies for getting the timeline or tweets from a Twitter user\u2019s timeline. You can either webscrape the data or use Twitter\u2019s API. Twitter has two types of APIs: the free version and the paid version. The paid version is very expensive and not ideal unless you\u2019re Bill Gates.", "The free version can be accessed by anyone with a developer account. Setting up the developer account is easy enough. From there, you grab your keys and head over to R.", "The walk through for this will be focused on the various and sundry ways that twitter\u2019s API can throw you for a loop (ha!) and how to prevent it. There are two main issues at hand: the first is that each request type is monitored on a time-basis. The one that is most utilized here is the get-timeline get request which has a 900 times per 15-minute limit. The second is that, given a list of user names one may want to pull tweets from, some may be protected, or some may only return small fragments of timelines. As such, the program will have to know how to handle those two errors, along with the mysterious error of never-completing user timelines (more on that maddening experience later).", "In doing so, the below script utilizes several techniques: tryCatch() calls, appending dataframes, hard-writing to disk, a dynamic re-start function, automatic shut-down functions, and lastly a manner by which the program can monitor its progress and react accordingly.", "Quick Note: Aside from the outline of the program, my other goal in writing this is to help consolidate a lot of common programming questions asked but are spread far and wide throughout the internet. Here, these questions are answered in a pragmatic and concise manner to help aspiring R programmers (hence the length).", "Thus, we need a code that can do the following things:", "1 \u2014 Able to iterate through a list of users", "2 \u2014 Make the request for a specific users timeline", "3 \u2014 Keep track of the responses already gathered, so as to not get duplicates", "3 \u2014 Keep track of the responses already gathered, so as to not get duplicates", "5 \u2014 Able to export to disk", "6\u2014 Able to handle errors due to rate-limit responses", "7\u2014 Able to handle errors due to unavailable users", "8\u2014 Able to handle never-ending loops of requests", "8\u2014 Shut program down periodically to allow for system reboot", "9 \u2014 Give periodic updates on the status of the program", "10 \u2014 Able to have a dynamic reboot modality", "Overall, this is a simple for command in R which exports to a tryCatch() function housing a get_timeline request for Twitter\u2019s API. It\u2019ll iterate through a per-established list of user names, feeding the users into the get timeline request. There are two possible outcomes from this, an error or a dataframe with the requested information. As such, the request will be wrapped into a tryCatch() handler whose output can then be parsed into either an error response or the requested data.", "If the output is the requested data, then the program will extract the least status_id (each Twitter status has an associated ID) which will serve as the ceiling for the next request. It will update the array signifying that the response was good, as well as update other key components. Then it appends the dataframe with the new information and then proceeds to the next loop.", "If the output of the GET request is an error, it updates the array for the appropriate error that was generated and reacts accordingly. If it is a time-related error, the program saves the data that has been retrieved thus far, exports it, then waits the appropriate amount of time.", "If the output is an unauthorized user response (a user is private or some other excluding issue) then the program saves that user\u2019s user ID in a dataframe, and moves on to the next user.", "There are also instances wherein the response will be minimal: maybe only one or two tweets per response. This will cause you to quickly reach your maximum causing lengthy delays without receiving sufficient return. For instance: if you only receive 2 tweets per request, for 3,200 tweets that is 1,800 requests which would take 30 minutes minimum. Now multiply that by approximately 5% of your database. Thus,if the output is minimal: the program closes that user and proceeds to the next.", "Furthermore \u2014 the program recycles its memory vehicles requiring a dynamic start after either a scheduled shut down or an unexpected loss of function.", "Lastly, throughout all of this the script should update the user on key items, most importantly being the number of users completed and the estimated time of completion.", "Once all of the users have been iterated through, the script will simply export as a csv and be done!", "This tutorial will utilize the following packages:", "Lets look at the steps individually:", "Be sure to establish your developer\u2019s account and have your keys. From there, use rtweet\u2019s function create_token() to create a token for the API calls. Here, my token is simply: token.", "Iterating through a list of users", "Supposing you have some dataframe, say, users.df that have a list of users of whom you want to receive their timelines, then the command is a simple for loop:", "With these users, we want to request the timeline. For this the rtweet package will be used. It houses a function called get_timeline() that will call on Twitter\u2019s API.", "Quick Note: Twitter\u2019s free API has two distinct rate limits. GET requests for a user\u2019s timeline can only be performed 900 times per 15 minutes. GET requests for the remaining amount of GET requests available can occur 150 times per 15 minutes.", "The get_timeline() function from rtweet inherently performs a GET request for available request limits. Setting check = FALSE eliminates this. Otherwise, instead of being able to perform 900 requests before having to wait 15 minutes, you could only perform 150.", "To keep track of a lot of the values required, we will use an array. This array will be called master.array. Thus we can update the get_timeline() function as follows:", "Quick Note : Setting max_id to NA rather than NULL will return an empty dataset that will not be caught in the error-catching mechanisms discussed below.", "Ideally, with this call, a table is returned with approximately 200 entries. Each entry will be a tweeting activity by that user associated with 90 columns of data. These data include items such as \u201cis_retweet\u201d to specify if the activity is a retweet and other markers useful for investigations.", "But the response may also be an error or an empty table. These potentials will have to be addressed. But \u2014 before diving into the errors, let\u2019s look at the desired outcomes:", "Since we want each GET request will solicit a different set a tweets, we have to tell Twitter\u2019s API which tweets we already have obtained. This is done via the (slightly confusing) max_id argument. The max_id will set the ceiling from which the next iteration of tweets will be pulled. The max_id of the next set is the minimum status_id of the previous set.", "So our first function for propagation becomes:", "Quick Note: When storing NULL value in an array, you have to use the list(NULL) command, otherwise you will simply delete the entry. Retrieving this value then is different from other calls: it must be unlisted as we will see below.", "As can be seen, the function can nicely handle if a new user is being called as the new argument will either insert a NULL if it is a new user or will produced the necessary transfers if it is the same user.", "A good time to introduce the master.array creation function:", "Now we can just update our calling function get_timeline() to the following:", "Since each user can only return 3,200 tweets as a response a method for monitoring how many responses have been obtained should be added. Here, a while() loop will be utilized, thus a required function will be the creation and modification of a constant k.", "Where the introduced df will be the dataframe that houses all of the responses obtained thus far from a user.", "The last step before we have the outline of our master function is what to do after each request. Here, the output will be a dataframe that needs to be appended to the pre-existing dataframes. Subsequently, after each user, it is a good idea to append to another dataframe so that the dataframe resulting from the user-specific requests can be deleted and remade thereby reducing memory load.", "The appending is a simple rbind() where the output is appended with a previously made dataframe, say \u2014 rolling.dataframe.", "Quick Note: rbind is considered one of the circles of R-hell. I know this. We all now this. Until I learn how to append the vectorization of a large dataframe onto another this is where we all live now.", "And lastly, since there are going to be quite a lot of updates in the array, so we might as well create a mater-update function:", "Lastly \u2014 it would be prudent to occasionally do two things: shuffle the working memory somewhere else, and export your work.", "To improve working times, every 1,000,000 tweets obtained is transferred to an overflow.dataframe and the user.dataframe is deleted. Concurrently, every 100 users the user.dataframe is exported for insurance.", "Quick Note: A condition will have to be added to ensure saving any remaining data if the difference between the last overflow save and the current appending dataframe is less than 1,000,000.", "Thus, we have the makings of the master.function:", "But, as mentioned before, there will be errors (and not just from my coding). Thus \u2014 this script is not robust enough (nowhere near) to be able to handle the variety of issues that might arise.", "Setting the foundation, let\u2019s keep track of how many tweets have been harvested, if an error has been produced, and which error it is:", "Then updating this value by creating a function to keep track of the total number of tweets extracted:", "The first step in identifying errors and bugs is to convince yourself that there was no way you could have possibly foreseen them coming and any suggestion to the contrary is baseless.", "Now that that\u2019s done, the second step is wrapping the function that may produce an error in a tryCatch() environment. Thus, a new function is required:", "Quick Note: Keep in mind your environments when utilizing tryCatch(). Nesting multiple tryCatch() creates a difficult environment to transfer various components between sections.", "Here, two things occur when a warning for the rate limit is thrown: the first thing is the master.array is updated: an error is indicated and the reason for the error is a rate-limit causing a wait. It then calls the wait.function().", "When the program goes to wait, in case of any failure during the 15 minute wait portion (power, internet, server issues, etc.) it is a good idea to save your work, perform a count-down so that you know how much longer the count down is (I\u2019m impatient), update the user on key items of information and then update the array when the wait is done.", "That equates to the following functions:", "To write the data to disk an export function is crafted:", "Quick Note: Some of the columns return from the GET request will be lists. Lists cannot be stored as a vector in a csv. Thus, they must be removed. This is performed via the df[, -which\u2026)] command.", "The count function will count down every 10 seconds in the console:", "So then the master function becomes:", "Yet \u2014 a keen observer will note that the output can come in two varieties: in the successful case it will be a dataframe of the GET response and the other will be an updated master.list. Thus, we have to add a condition:", "The if statement ensures that the output is not in fact a table, but rather a dataframe. Thus, if it is a table, then it must be the master.array and sets it appropriately. It then breaks the remaining statements and retries the get.timeline() call.", "Sometimes, you\u2019ll get users whose timelines cannot be gathered. This will present itself as a warning \u2014 just like the rate limits. So, without protections against those, every user (sometimes they can be 100s in a row) will cause a 15 minute wait. This can be taken care of by updating the tryCatch():", "It would be nice if in the event of meeting an authorized user, the script would: update a list containing user_ids that cannot be requested; the list exported as a csv; the user is then skipped.", "Oh boy that\u2019s a lot of change! Let\u2019s look at each function then:", "Quick Note: The if(nrow(\u2026.!=0)) statement is protection against the first user attempted providing no response and either not provoking an error (just a NULL response) or provoking an error and still proceeding to the secondary rbind().", "The add.removed.function() just keeps track of how many removed users there have been. This is accomplished with another update to the array:", "Then the add.removed.function(): This appends the existing dataframe of the removed users with a new entry. The as.character() is added just in case (the user_id is a long string of numbers; occasionally the lazy-evaluating of R will convert it to an integer and thus scientific notation):", "Then to keep track of how many users have been removed, update the k-value so that the next user is picked, and resets the array for errors:", "Then the export function gets updated as well:", "Now \u2014 there is a mechanism by which if an error is thrown due to an unauthorized request on a user\u2019s timeline, the user\u2019s ID will be cataloged and exported, then the array updated appropriately so as to remove the signs of an error as well as move to the next user.", "Occasionally, and at no fault of my own, requests will proceed in a seemingly endless loop quickly approaching the 900 per 15 minute limit without actually accomplishing anything. Although during these times responses are received, it isn\u2019t tenable to let these users waste precious time.", "Thus, a mechanism should be implemented to catch these and to break the function when they occur.", "If there are 3,200 tweets per user, at 200 per request, that\u2019s approximately 18 requests per user. Sometimes there are less than 200 per request received so the limit is set to 20 per user.", "This limit can be monitored by another array value:", "Then the updated request count is added after the get.timeline() call:", "Then we set an if statement in the master function:", "This will ensure that after 20 requests for a specific user, the script is stopped and the next user is requested.", "Errors Errors everywhere and not a (data) byte to eat.", "Once the errors are accounted for, the system state should be reset. This can be accomplished by crafting an error-be-gone function:", "This is then inserted wherever the end-point of an error is.", "This program will take a while: days to weeks depending on the number of users being requested. As such, periodic restarts are advised. To do so, one must keep track of the date and time that the program was initiated, the current date and time. If the condition is met that two days have passed since the program has been running (you can set your own limit), the program should save the most recent versions of the data, and then quit.", "Thus, as always, the array is updated:", "Then, choosing where to put the check: I did so after finishing a user in the master function:", "This requires an update to the export function:", "Then the shut.down() function is called:", "This will end the current R session while making sure that the most recent set is saved.", "I\u2019m impatient. And I need to know things now. With this in mind, I want my program to update me every time a user is completed, or a wait is initiated, or a user presents as an unauthorized GET request. Along with these hard-points, I want updates on the dynamic state of events: number of users completed, number of users remaining, number of tweets extracted, average run time per user, and the estimated completion date.", "The hard-point will be added to the master function. But lets look at the dynamic states. The function that will give us the number of completed users:", "Due to the dynamic state of the function, the completed number of users could be anywhere.", "Quick Note : This could (and should) be done by wrapping the final argument in a tryCatch() environment. But I already typed this version out so. The tryCatch() technique will be shown below.", "The same procedure for getting the total number of users in the pool:", "Why would the dataframe from which we are pulling all of our users from suddenly become hidden in the environment? Who knows \u2014 but has it happened? Yes.", "Now that we have both the total number of users in the pool and the number of users completed, we can discover our user.update() function:", "This will produce lovely output such as:", "The user.update() function is then added along with the other status updates into the master function:", "Now that the bulk of our program is written. There needs to be a way in which the program can restart with minimal (read: I\u2019m lazy) input so as to do several things:", "1 \u2014 I want the program on restart to upload the appropriate files into R", "2 \u2014 I want the files to be manipulated and appended", "3 \u2014 Then the files should be re-written to disk but in different paths specifying back-up file names", "4 \u2014 Make me a cup of coffee.", "Furthermore, as an over-arching theme fetal errors may arise spontaneously and totally in an unpredictable not-related-to-me-not-knowing-how-to-spell some hundreds of thousands of tweets into a script. Thus, the restart function should be able to differentiate from a clean restart versus a \u201cops\u201d restart.", "Quick Note: This function is way too long. I know it. You know it. But it seemed like a better idea to have a self-contained start function since it writes and reads and moves files around on disk ; I didn\u2019t want unforeseen backups deleted or moved because of a calling in some other part of the script.", "From here, the exiting output will be a dataframe that houses the most up-to-date information extracted. From there, the user_ids should be removed from the dataframe that is being iterated across (users.df). And, users.df should be brought in:", "Now that we have the dataframe housing all of the user_ids that we are interested in, and we have the dataframe of the user_ids that we have already extracted, the next obvious step is to remove one from the other. The user_ids that were removed for being unauthorized should be removed as well:", "Et voila, now we have all the pieces we need!", "After all that the final call looks like:", "That\u2019s it folks! That\u2019s the nuts and bolts of a program that can run and extract millions of tweets from users on Twitter using Twitter\u2019s API along with R\u2019s rtweet package. Here we\u2019ve covered many topics: dynamic scripts utilizing an array to store and retrieve relevant information; utilized tryCatch() environments to catch the various and wonderful errors that Twitter\u2019s API can throw; developed a method of waiting when rate-stopped and writing to and uploading from the disk when necessary.", "The script definitely has room for improvements and additions. For instance: how would one switch from using rbinds() to per-allocating data and subsequently utilizing vectorization to append the pre-established data? (Seriously how!?). Or how could one incorporate sending updates to the user when they are not present at the computer? The options are endless!", "I hope you enjoyed and that this helped!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3985b43df86d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://justincocco.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Justin Cocco"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd2c6b502326a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=post_page-d2c6b502326a----3985b43df86d---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3985b43df86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=-----3985b43df86d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3985b43df86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=-----3985b43df86d---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/tag/r?source=post_page-----3985b43df86d---------------r-----------------", "anchor_text": "R"}, {"url": "https://medium.com/tag/programming?source=post_page-----3985b43df86d---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/twitter?source=post_page-----3985b43df86d---------------twitter-----------------", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/cluster-analysis?source=post_page-----3985b43df86d---------------cluster_analysis-----------------", "anchor_text": "Cluster Analysis"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----3985b43df86d---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3985b43df86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=-----3985b43df86d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3985b43df86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=-----3985b43df86d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3985b43df86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd2c6b502326a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=post_page-d2c6b502326a----3985b43df86d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a50a5a544c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&newsletterV3=d2c6b502326a&newsletterV3Id=5a50a5a544c1&user=Justin+Cocco&userId=d2c6b502326a&source=-----3985b43df86d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Written by Justin Cocco"}, {"url": "https://justincocco.medium.com/followers?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "99 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd2c6b502326a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&user=Justin+Cocco&userId=d2c6b502326a&source=post_page-d2c6b502326a----3985b43df86d---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a50a5a544c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Futilization-of-twitters-api-with-r-advanced-techniques-3985b43df86d&newsletterV3=d2c6b502326a&newsletterV3Id=5a50a5a544c1&user=Justin+Cocco&userId=d2c6b502326a&source=-----3985b43df86d---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/swlh/the-adventure-of-pdf-to-data-frame-in-r-f90609035600?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Justin Cocco"}, {"url": "https://medium.com/swlh?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/the-adventure-of-pdf-to-data-frame-in-r-f90609035600?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "The Adventure of PDF to Data Frame in R.PDFs can present a challenge for data scientists. Here is a quick review of one PDF\u2019s journey to being a data frame in R."}, {"url": "https://medium.com/swlh/the-adventure-of-pdf-to-data-frame-in-r-f90609035600?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "\u00b79 min read\u00b7Jul 17, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2Ff90609035600&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fthe-adventure-of-pdf-to-data-frame-in-r-f90609035600&user=Justin+Cocco&userId=d2c6b502326a&source=-----f90609035600----0-----------------clap_footer----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/the-adventure-of-pdf-to-data-frame-in-r-f90609035600?source=author_recirc-----3985b43df86d----0---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff90609035600&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fthe-adventure-of-pdf-to-data-frame-in-r-f90609035600&source=-----3985b43df86d----0-----------------bookmark_preview----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----3985b43df86d----1---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----3985b43df86d----1-----------------bookmark_preview----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----3985b43df86d----2---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----3985b43df86d----2-----------------bookmark_preview----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-look-a-philadelphia-e710eff69a3f?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Justin Cocco"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/a-look-a-philadelphia-e710eff69a3f?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "A Look a PhiladelphiaHow Poverty, Education, and Work-force can help understand the health of a Great City, a series."}, {"url": "https://towardsdatascience.com/a-look-a-philadelphia-e710eff69a3f?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": "\u00b714 min read\u00b7Sep 21, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe710eff69a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-a-philadelphia-e710eff69a3f&user=Justin+Cocco&userId=d2c6b502326a&source=-----e710eff69a3f----3-----------------clap_footer----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/a-look-a-philadelphia-e710eff69a3f?source=author_recirc-----3985b43df86d----3---------------------76cc1465_d56d_46a6_b84a_7cc24757efa8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe710eff69a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-a-philadelphia-e710eff69a3f&source=-----3985b43df86d----3-----------------bookmark_preview----76cc1465_d56d_46a6_b84a_7cc24757efa8-------", "anchor_text": ""}, {"url": "https://justincocco.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "See all from Justin Cocco"}, {"url": "https://towardsdatascience.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----3985b43df86d----0-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----3985b43df86d----1-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b717 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----0-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----3985b43df86d----0---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----3985b43df86d----0-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----3985b43df86d----1---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----3985b43df86d----1-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----2-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----3985b43df86d----2---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----3985b43df86d----2-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/building-your-first-shiny-app-in-r-82c7d1f5f309?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://ivopbernardo.medium.com/?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://ivopbernardo.medium.com/?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Ivo Bernardo"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/building-your-first-shiny-app-in-r-82c7d1f5f309?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "Building your First Shiny app in RLearn how to build a shiny app using R, and showcase your code and work interactively"}, {"url": "https://towardsdatascience.com/building-your-first-shiny-app-in-r-82c7d1f5f309?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": "\u00b712 min read\u00b7Nov 28, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F82c7d1f5f309&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-your-first-shiny-app-in-r-82c7d1f5f309&user=Ivo+Bernardo&userId=74eec53531c0&source=-----82c7d1f5f309----3-----------------clap_footer----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/building-your-first-shiny-app-in-r-82c7d1f5f309?source=read_next_recirc-----3985b43df86d----3---------------------cd7b2b11_307c_4961_b601_237f22a8948a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82c7d1f5f309&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-your-first-shiny-app-in-r-82c7d1f5f309&source=-----3985b43df86d----3-----------------bookmark_preview----cd7b2b11_307c_4961_b601_237f22a8948a-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3985b43df86d--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----3985b43df86d--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}