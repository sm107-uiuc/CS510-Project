{"url": "https://towardsdatascience.com/which-translator-870bae18f3bf", "time": 1683010577.0899498, "path": "towardsdatascience.com/which-translator-870bae18f3bf/", "webpage": {"metadata": {"title": "Which Translator?. Using Data Science to Investigate the\u2026 | by Steven McDonald | Towards Data Science", "h1": "Which Translator?", "description": "As an avid reader of fiction, I\u2019ve often wondered about the impact of the translator\u2019s style on a translated novel. In particular, I\u2019ve been curious about the works of Haruki Murakami. He writes in\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.newyorker.com/books/page-turner/lost-in-translation", "anchor_text": "The New Yorker", "paragraph_index": 0}, {"url": "https://github.com/steven-mcdonald/murakami_translators", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://medium.com/@zazazakaria18/turn-your-ebook-to-text-with-python-in-seconds-2a1e42804913", "anchor_text": "this approach", "paragraph_index": 7}, {"url": "https://pypi.org/project/textacy/", "anchor_text": "textacy", "paragraph_index": 11}, {"url": "https://pypi.org/project/vaderSentiment/", "anchor_text": "VADER", "paragraph_index": 15}, {"url": "https://github.com/steven-mcdonald/murakami_translators", "anchor_text": "GitHub", "paragraph_index": 53}], "all_paragraphs": ["As an avid reader of fiction, I\u2019ve often wondered about the impact of the translator\u2019s style on a translated novel. In particular, I\u2019ve been curious about the works of Haruki Murakami. He writes in Japanese and has three main English language translators: Alfred Birnbaum, Jay Rubin and Philip Gabriel. How much of what I\u2019ve been reading is Murakami and how much is the translator? Do the different translators have different takes on the original work? This seems quite possible to me given the linguistic gulf between Japanese and English. It\u2019s certainly the opinion of one of Murakami\u2019s main translators, Jay Rubin, given in The New Yorker:", "\u201cWhen you read Haruki Murakami, you\u2019re reading me, at least ninety-five per cent of the time,\u201d", "For most of Murakami\u2019s work there is only one translation available and so it is difficult to get a direct comparison of the translator\u2019s styles. However, one of the exceptions is the first chapter of \u2018The Wind-Up Bird Chronicle\u2019. The main translation is by Jay Rubin but it also appears as a short story in \u2018The Elephant Vanishes\u2019, this time translated by Alfred Birnbaum. Here are the two translations.", "\u201cWhen the phone rang I was in the kitchen, boiling a potful of spaghetti and whistling along to an FM broadcast of the overture to Rossini\u2019s The Thieving Magpie , which has to be the perfect music for cooking pasta.\u201d", "\u201cI\u2019m in the kitchen cooking spaghetti when the woman calls. Another moment until the spaghetti is done; there I am, whistling the prelude to Rossini\u2019s La Gazza Ladra along with the FM radio. Perfect spaghetti-cooking music.\u201d", "The overall sense is the same but but there are some quite marked differences, even in this short extract. The translators have made different decisions on the choice of words, sentence structure and even the tenses.", "Could these differences allow a Machine Learning model to predict the translator of a sample of Murakami\u2019s work? And if so, could the features of that model be used to give some insight into the translator\u2019s styles? That was what I aimed to find out. This article outlines the main steps and decisions made during the project but the code can also be found here.", "As with many Data Science projects, the initial challenge was gathering and preparing the data. I had a number of Murakami\u2019s books in various digital formats (epub, pdf, docx) and the first step was to read these various files into standardised text files with python. The epub format was the most challenging and after quite a bit of trial and error, I found this approach worked well using the packages EbookLib and BeautifulSoup.", "Once the books were loaded the next step was perhaps less typical. It is often quite clear what a data point would be for a given dataset. It could be a house when predicting house prices or a single tweet when predicting twitter sentiments. For this project, it was less clear what to use. One option might be to consider a chapter as a data point. However, with a dataset comprising of just seven books, I only had around two hundred chapters in total. We typically need a few thousand data points when performing machine learning on any dataset with more than a handful of features.", "Another consideration was the size of the sample. Some features we might want to use when differentiating between translators could be things like the number of adverbs used or the range of unique words. For these types of features to be comparable, the size of each text sample should be the same. Unfortunately, chapters, sentences and paragraphs can all vary significantly in length and therefore prove challenging to compare, while even pages can vary in length depending on the book formatting. I therefore decided to split the book texts into chunks set at ~1000 characters in length. The actual chunk lengths varied in size as they were split on full stops to avoid chunks containing partial sentences. Any count features generated could then be more confidently normalised to the equivalent for a 1000 character chunk of text so the feature could be used to compare the chunks.", "Engineering suitable features was crucial to the project. Features needed to be related to translation style rather than the overall content or themes of the books. Features such as characters, locations or topics can be very useful when predicting a specific text. However, they are likely to be related to the underlying story rather than any decision made during the translation process.", "I found the textacy library, which is built on top of the high performance spaCy library, to be extremely useful in generating suitable features. Each chunk of text is first converted to a spaCy doc and then various basic measures of the text can be generated. These are things like the number of sentences, number of unique words and number of monosyllabic words. These seemed like features that might help differentiate the translators. One translator may favour longer sentences or another may make use of a wider range of words.", "It is also quite straightforward to do POS (Parts of Speech) analysis with textacy. So for each word in the chunk of text we can generate a label \u2014 verb, pronoun, adjective and so on. It seemed that counts of the different POS types could also be useful in differentiating the translators.", "Could translators have preferences for certain common words? I performed a bag-of-words analysis for each translator and then listed the most common words, in each case normalising to the total number of words used by that translator. Unsurprisingly, words like \u2018the\u2019 and \u2018and\u2019 were very common. Words like \u2018he\u2019, \u2018she\u2019, and \u2018had\u2019 were also commonly used and there were some variations in the frequency of use between the translators. I added these as features as they seemed generic enough to not be related to the underlying theme of a book but could be related to the translator\u2019s style. I\u2019ll come back to this assumption later!", "Perhaps a given translator could also have a preference for certain adjectives or adverbs. I looked at the most common adverbs and adjectives for each translator and again selected a few which appeared generic enough that they could be an indicator of the translator rather than the underlying story, for example words like \u2018good\u2019 or \u2018little\u2019.", "Using sentiment analysis to differentiate between translators seemed potentially risky as the sentiment of a text would likely be linked to the story itself and any translator would hope to accurately translate the overall sentiment of the original text. Nevertheless, I generated sentiment scores using the VADER package which gives values for positive, negative and neutral sentiment adding up to 1.", "At this point, given more time, I would ideally have built up my domain knowledge about translation styles or, even better, discussed with a specialist to try to generate some further well-targeted features. However, I already had 90 features and I was curious to see if they would be enough to built a working model.", "Now that I had some interesting features I could try to predict the translator of a given chunk of text. Starting with a simple Logistic Regression model using just the textacy basic counts, I then added additional groups of features and re-ran the modelling each time to get an understanding of the impact of each type of feature on the prediction accuracy.", "The dataset was train/test split with random shuffling. Model hyperparameters were grid-searched and cross-validated accuracy was used to measure the predictive success of each model, together with confusion matrices and ROC AUC scores.", "I was pleasantly surprised to see the straightforward Logistic Regression models scored well above the baseline accuracy of 0.40 (i.e. better than choosing the most common translator by default) even with limited features.", "We can see that the basic textacy counts and counts of POS types contribute significantly to the accuracy. Individual word counts were particularly beneficial for predicting Philip Gabriel translations as we see the ROC-AUC score improve. Counts of some specific adverbs and adjectives also improved the predictive power slightly. On the other hand, adding VADER sentiment scores did not significantly improve the accuracy and, in fact, generated lower accuracy on the test set. I therefore dropped them from further analysis.", "Overall, this was a very positive outcome and meant that I could continue on to the second objective of gaining insights into the translator\u2019s styles from the model features. However, before that, I wanted to try other machine learning algorithms that could potentially generate even more accurate predictions.", "There are many potential models that could be used and, in general, it is difficult to say which ones will perform better on a given task without testing them. Several alternative models were tested and compared, from relatively simple algorithms such as KNN through to more complex ensembles methods and neural networks.", "From the outset my goal had been to generate an accurate prediction model AND be able to interpret how the predictions were made. Boosting, SVM and Multi-Layer Perceptron Neural Networks all generated greater accuracy in their predictions than Logistic Regression. However, they are typically less open to interpretation. Therefore further analysis and interpretation was continued with the Logistic Regression model.", "Perhaps the most revealing stage of the project was reviewing the most confidently predicted chunk of text for each translator together with the model features. From this I could start to gain some insights into the differences in the translator\u2019s styles.", "The above figure indicates the most important features from the Logistic Regression model for predicting each translator over the others. With positive features in light red and negative in dark red. From this we can say that in general the translation styles have the following features:", "Birnbaum: More monosyllabic words | Shorter sentences | Fewer verbs", "Rubin: Longer sentences | More pronouns | More use of the word \u2018had\u2019", "Gabriel: Fewer pronouns | More verbs | more use of the word \u2018he\u2019", "The figure below helps summarise the values of some of these key features for the most confidently predicted chunks of text for each translator.", "I selected the most confident prediction for each translator (typically with probability of >95%) to see how the actual features of these text chunks compare. In the figure, we can see the full distribution of values for some key predictors as red bands. The grey diamond shows the mean for a given translator. The black spot shows the value for the most confidently predicted chunk in each case. Interestingly we can see that the word \u2018had\u2019 is a strong predictor for Jay Rubin and the word \u2018he\u2019 is a strong predictor for Philip Gabriel.", "By highlighting these words in the strongly predicted samples above, we can see that the Gabriel text is written in the third person whereas the Birnbaum and Rubin are both in first person. The Rubin text is mainly in the past perfect tense whereas the other two are mainly in the simple past tense. It seems likely that these two differences are more related to the original text than any decisions by the translators.", "Investigating the texts more deeply we see that the novel \u2018Kafka on the Shore\u2019, translated by Gabriel, is written in the third person whereas many of Murakami\u2019s other novels are written in first person. The model is therefore more likely to be using the frequency of the word \u2018he\u2019 to predict the novel rather than the translator\u2019s style choices. The same goes for \u2018The Wind-Up Bird Chronicle\u2019, translated by Rubin, which contains a significant amount of text in the past perfect tense and so, once again, the model is likely to be using the frequency of the word \u2018had\u2019 to predict the novel rather than the translator\u2019s style.", "The Logistic Regression modelling was therefore re-run without the features related to the frequency of the words \u2018had\u2019 and \u2018he\u2019.", "From this adjusted model we can better characterise the translation styles:", "Birnbaum: Shorter sentences | Fewer verbs | More unique words", "Rubin: Longer sentences | More pronouns | Fewer adverbs", "Gabriel: Less use of the word \u2018said\u2019 | Fewer pronouns | More verbs", "This issue of features relating to the story itself partly arises due to the initial randomised train/test split which takes some sections of each book to train the model and other sections from the same books when testing the model. We can avoid this issue by setting aside complete books as test sets and training on the remaining books.", "Therefore, as a final confirmation of the modelling approach I re-ran the Logistic Regression modelling (still dropping the \u2018had\u2019 and \u2018he\u2019 count features) with a non-random train/test split.", "I had several chapters of Norwegian Wood and one chapter of \u2018A Wind-Up Bird Chronicle\u2019 which had been translated twice, once by Jay Rubin and again by Alfred Birnbaum. This provided a good control test set as the original Japanese text was the same and the only difference was the translator.", "Two versions of this test ran. Firstly, with the remaining books by all three translators in the training set but only the texts from Birnbaum and Rubin outlined above in the test set.", "The baseline accuracy this time was 0.50. The cross-validated accuracy was less relevant in this case and the focus was on the test set accuracy score which was 0.55. Fortunately, then, this model was still able to beat the baseline (albeit by a smaller margin) and confirmed that it was possible to predict the translator using the available features. The discriminating features shown below include Gabriel even though he was not in the test set, as he was included in the training set:", "Birnbaum: Shorter sentences | Fewer verbs | More unique words", "Rubin: Longer sentences | More pronouns | Fewer adverbs", "Gabriel: Less use of the word \u2018said\u2019 | Fewer pronouns | More verbs", "As the test set consisted of only two translators, Birnbaum and Rubin, I ran a second version with only these two translators in the training set as well. The test accuracy was improved significantly at 0.67 as there were no more false positive Gabriel predictions.", "As there were only 2 target categories there was only one feature set in the model, as shown above, those predicting Rubin rather than Birnbaum:", "Rubin: Longer sentences | More auxiliary words | Fewer characters | Fewer unique words", "Firstly that, with a random train/test split, all models tested were able to predict the translator of a test dataset with accuracy well above the baseline score (i.e. better than choosing the most common translator by default). However, it could be difficult to know if the model was predicting a given book rather than its translator.", "This led to an important lesson that, in this case, a random train/test split was not the best approach. By looking at the model\u2019s most confident predictions for each class and the importance of the features in the model, it became apparent that some features were potentially predicting a book rather than its translator. By using a test set which contained only repeat translations of the same original text I could be sure the model was basing its prediction only on the choices made by the translators. Fortunately, a model generated this way was still able to do a good job, especially when it was also trained only on other texts translated by the two translators in the test set.", "So what about the actual differences in the translation styles? From this final model we can say that Rubin tends to use longer sentences than Birnbaum as well as more auxiliary words and fewer unique words. It is a little more difficult to be certain what sets Gabriel\u2019s translations apart, but from the earlier random train/test split trained models it seems likely that he uses more verbs and adverbs than the others and fewer pronouns.", "This project only touched on what is possible with this type of analysis. More tailored features could certainly be generated, perhaps even making use of the original Japanese text to help develop baseline information to compare to the translation.", "I certainly enjoyed taking a first look at the topic and I hope you found it interesting too! All the code used is available on GitHub. Feel free to get in touch if you have any comments or suggestions.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F870bae18f3bf&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@stevenjmcdonald?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stevenjmcdonald?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Steven McDonald"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Febbd59471c08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&user=Steven+McDonald&userId=ebbd59471c08&source=post_page-ebbd59471c08----870bae18f3bf---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@alvapratt?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Alva Pratt"}, {"url": "https://unsplash.com/s/photos/reading-japan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.newyorker.com/books/page-turner/lost-in-translation", "anchor_text": "The New Yorker"}, {"url": "https://github.com/steven-mcdonald/murakami_translators", "anchor_text": "here"}, {"url": "https://medium.com/@zazazakaria18/turn-your-ebook-to-text-with-python-in-seconds-2a1e42804913", "anchor_text": "this approach"}, {"url": "https://pypi.org/project/textacy/", "anchor_text": "textacy"}, {"url": "https://pypi.org/project/vaderSentiment/", "anchor_text": "VADER"}, {"url": "https://github.com/steven-mcdonald/murakami_translators", "anchor_text": "GitHub"}, {"url": "https://medium.com/tag/data-science?source=post_page-----870bae18f3bf---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/nlp?source=post_page-----870bae18f3bf---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/haruki-murakami?source=post_page-----870bae18f3bf---------------haruki_murakami-----------------", "anchor_text": "Haruki Murakami"}, {"url": "https://medium.com/tag/python?source=post_page-----870bae18f3bf---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----870bae18f3bf---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&user=Steven+McDonald&userId=ebbd59471c08&source=-----870bae18f3bf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&user=Steven+McDonald&userId=ebbd59471c08&source=-----870bae18f3bf---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F870bae18f3bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----870bae18f3bf---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----870bae18f3bf--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----870bae18f3bf--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----870bae18f3bf--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stevenjmcdonald?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stevenjmcdonald?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Steven McDonald"}, {"url": "https://medium.com/@stevenjmcdonald/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "16 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Febbd59471c08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&user=Steven+McDonald&userId=ebbd59471c08&source=post_page-ebbd59471c08--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Febbd59471c08%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-translator-870bae18f3bf&user=Steven+McDonald&userId=ebbd59471c08&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}