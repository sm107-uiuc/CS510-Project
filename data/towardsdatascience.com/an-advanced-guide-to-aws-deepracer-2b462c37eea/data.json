{"url": "https://towardsdatascience.com/an-advanced-guide-to-aws-deepracer-2b462c37eea", "time": 1683009245.182357, "path": "towardsdatascience.com/an-advanced-guide-to-aws-deepracer-2b462c37eea/", "webpage": {"metadata": {"title": "An Advanced Guide to AWS DeepRacer | by Daniel Gonzalez | Towards Data Science", "h1": "An Advanced Guide to AWS DeepRacer", "description": "An advanced guide for AWS DeepRacer, in particular the F1 (Formula 1) time trial racing event, based on Reinforcement Learning / Machine Learning"}, "outgoing_paragraph_urls": [{"url": "https://aws.amazon.com/deepracer/", "anchor_text": "official website", "paragraph_index": 7}, {"url": "https://www.remi-coulom.fr/Publications/Thesis.pdf", "anchor_text": "R\u00e9mi Coulom\u2019s Ph.D. Thesis", "paragraph_index": 10}, {"url": "https://github.com/cdthompson/deepracer-k1999-race-lines", "anchor_text": "this GitHub Repo", "paragraph_index": 10}, {"url": "https://github.com/aws-deepracer-community/deepracer-simapp/tree/master/bundle/deepracer_simulation_environment/share/deepracer_simulation_environment/routes", "anchor_text": "DeepRacer Community\u2019s GitHub Repo", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1", "anchor_text": "this", "paragraph_index": 27}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo", "paragraph_index": 28}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo", "paragraph_index": 41}, {"url": "https://github.com/aws-deepracer-community/deepracer-analysis", "anchor_text": "Log Analysis Tool on GitHub", "paragraph_index": 50}, {"url": "https://blog.deepracing.io/2020/03/30/introducing-aws-deepracer-log-analysis/", "anchor_text": "this blog post", "paragraph_index": 50}, {"url": "https://medium.com/analytics-vidhya/scrapy-vs-selenium-vs-beautiful-soup-for-web-scraping-24008b6c87b8", "anchor_text": "This", "paragraph_index": 55}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo", "paragraph_index": 57}, {"url": "https://github.com/aws-deepracer-community", "anchor_text": "DeepRacer Community\u2019s GitHub", "paragraph_index": 59}, {"url": "https://deepracing.io/", "anchor_text": "website", "paragraph_index": 59}, {"url": "https://www.youtube.com/c/AWSDeepRacerCommunity", "anchor_text": "YouTube channel", "paragraph_index": 59}, {"url": "https://www.linkedin.com/in/natalia-korchagina/", "anchor_text": "Natalia Korchagina", "paragraph_index": 60}, {"url": "https://www.linkedin.com/in/marc-cervera-castro/", "anchor_text": "Marc Cervera", "paragraph_index": 60}], "all_paragraphs": ["Self-driving cars have become a hot field in recent years, with companies such as Tesla pushing the boundary of technology every day. AWS\u2019s DeepRacer is making use of this hype, becoming more and more popular and even organizing a league to compete in.", "In May of 2020, AWS organized a special event, in which it partnered with Formula 1. The track for this event was the highly complex Circuit de Barcelona-Catalunya. In the time trial category, our team managed to become 12th place, out of nearly 1300 participants.", "In this article, we will look at the factors that got our university team to a top 1% ranking in the AWS DeepRacer F1 time trial event. So if you are interested in seeing the advanced techniques that go into training a reinforcement learning model in AWS DeepRacer, this is the right article for you.", "We will be covering the following points:", "To follow this article, you do not need an extensive data science background. In fact, our team has a business background, studying Business Analytics at ESADE Business School in Barcelona, Spain. However, basic knowledge about Python is needed to understand this article.", "AWS DeepRacer is a 1/18th scale autonomous racing car that can be trained with reinforcement learning. The model can be trained and managed in the AWS console using a virtual car and tracks. When using the AWS console, the entire infrastructure, including the training of the model and the virtualization of the racing tracks, is managed by AWS.", "In contrast to classical machine learning, reinforcement learning is used when you have no data, but an environment from which the agent can learn. In our case, the agent is the car, and the environment is the virtual racing track. By giving the agent rewards for desired actions, the agent learns over time to master the problem in the given environment. To learn more about reinforcement learning, check out this article from my team member Marc Cervera:", "DeepRacer was built specifically as a learning product for people to learn about machine learning. 3 components play an important role in making its mission a success: the virtual training environment, the physical car, and the league. If you want to learn more about DeepRacer, feel free to visit the official website.", "In this article, we will focus on the use of the AWS DeepRacer console, so customization with AWS SageMaker will not be covered. Additionally, only virtual racing will be examined as physical racing requires a different approach. Lastly, we will only consider the time trial format. However, the majority of the described approach can also be used for other racing formats.", "In virtual races, overfitting the model to the specific track is a way to achieve a good model with an acceptable amount of training. Therefore, to achieve better times and converge faster towards higher speeds with more reliability, we will use a prescriptive approach, in which we will make the car follow the optimal racing line for that track.", "To compute the racing line, we will use the K1999 Path-Optimization Algorithm described in R\u00e9mi Coulom\u2019s Ph.D. Thesis. The algorithm has already been implemented in this GitHub Repo. It works by iteratively decreasing the line\u2019s curvature, leading the car to cut curves, decreasing the overall path length. All DeepRacer tracks can be downloaded in the DeepRacer Community\u2019s GitHub Repo.", "For the F1 track, the result is an array of 258 non-equally spaced coordinate points, which represent the racing line.", "Compared to other DeepRacer tracks, the F1 track is quite long. Therefore, to have a model that can reliably complete 3 laps, we need a model that is more risk-averse than models for shorter tracks. One way to achieve this is to discourage the car from going too close to the edge of the track. Additionally, the F1 track has speed bumps at the borders, leading to a loss of grip and control when driving too close to the edge. Thus, to balance reliability and speed on this track, we limit the racing line to the inner 80% of the track width.", "The following graphs show the racing line with and without the limitation of only using the inner 80% of the track, in combination with different numbers of iterations.", "Next, we want to calculate the optimal speed. Using a simplified approach, we can calculate the maximum speed for each point on the racing line with", "where \ud835\udc39 is the lateral gripping force, \ud835\udc5a is the mass of the car, and \ud835\udc5f is the radius of the curve. As we do not know \ud835\udc39 or \ud835\udc5a, we can simplify this equation by assigning a constant \ud835\udc50 to these unknown values.", "The radius on each point of the racing line can be calculated by implying a circle through 3 points on our previously computed racing line: the current point and the points in front and behind that. Solving for the radius, we can calculate the radius with this python function:", "Although the points of the racing line are not equally spaced, the calculated radii are still accurate because of the high density of points. Therefore, any inaccuracies should not be significant enough to make a difference.", "Once we have all the radii, we have to figure out \ud835\udc50 through experimentation. We do this by finding the highest possible speed with which the model can complete the tightest turn. For the F1 track, this maximum speed is about 1.3 m/s. We will later use this speed as the minimum speed of the action space.", "The value of \ud835\udc50 was calculated on different tracks and was consistently in the range of 1.6 to 1.75.", "To find the final optimal speed, we cap the speed at the maximum speed of the car, which was set to 4 m/s by our team for this track. Additionally, we introduce a lookahead factor, which we set to 5. This means that the optimal speed is the minimum of the maximum speeds of the next 5 points. The larger the lookahead value, the sooner the car starts breaking before a curve.", "In contrast to the optimal racing line, the optimal speed is only a broad approximation because many factors are not taken into account. To get an exact optimal speed, we would have to consider the exact mass, center of mass, moment of inertia, friction coefficient, cornering stiffness, and maximum acceleration and deceleration rates. We will have to keep this uncertainty in mind when designing the reward function.", "As DeepRacer\u2019s action space is discrete, some points in the action space will never be used, e.g. a speed of 4 m/s together with a steering angle of 30 degrees. Additionally, all tracks have an asymmetry in the direction of curves. For example, the F1 track is driven clockwise, leading to more right than left turns. Out of these 2 reasons, it is beneficial to optimize the action space. We can either opt for faster convergence by removing the actions that will not be used or for more precise driving if we keep the same number of actions but assign them more intelligently. We choose the latter. For the car setup, we use a single camera and a 3-layer Convolutional Neural Network because anything more complex does not improve performance for time trial and would only increase the time to converge.", "Until now, we only have the radius for each point on the racing line. This turning radius has to be converted to a steering angle with", "where \ud835\udefc is the steering angle, \ud835\udc3f=0.165\ud835\udc5a is the axle distance, and \ud835\udc5f is the radius of the curve.", "In a perfect world, the model would always follow the optimal racing line and speed. However, this is never the case, especially not when training of the model has just begun. Therefore, to represent the uncertainty in driving and give the car more flexibility to correct previous decisions, we add Gaussian noise to each action. We only apply Gaussian noise to the steering, not the speed, because correcting previous decisions is primarily driven through the steering, not speed.", "First, we have to determine the desired standard deviation of the Gaussian noise. Then, we generate an array of Gaussian noise, which will later be added to the existing data points.", "The maximum amount of actions, when using the DeepRacer console is 21. We use K-Means clustering on the Gaussian noise infused actions to calculate 19 actions. The last 2 actions will be manually added in the next step. We use K-Means because this allows us to use the Euclidian distance for the 2 dimensions speed and steering \u2014 the closer the points are to one another, the more similar they are. The centroid of a cluster will represent one action. In case you are not familiar with K-Means, this article explains it very well.", "To see which additional pre-processing steps we applied to the initial data points, please refer to our GitHub Repo.", "Between each update of the model, multiple episodes are conducted. For example, if this value is set to 20, the car will start each episode 5% further down the track, compared to the previous episode. Therefore, the car will rarely start exactly on the racing line or its direction. To give the car the possibility to turn into the desired direction at the start of each episode, we want to add 2 additional actions: (min. speed, 30\u00b0) and (min. speed, -30\u00b0).", "To conclude, the method described in chapter 3 is a first approach and is better than the predefined actions. However, asymmetric actions may force the car to decide between turning and higher speed. For example, looking at the action space plot above, the car cannot drive at 4m/s and steer 3\u00b0 at the same time. If it wants to steer at high speeds it has to reduce the speed. Thus, further experimentation with the action space might lead to better results.", "After finding our desired action space, we have to export it to S3, in which the model metadata for DeepRacer is saved. We follow these simple steps:", "Designing the reward function can be seen as the most challenging part of reinforcement learning. This is due to the large range of complexity, which reward functions can have. On the one end, a reward function with 5 lines of code can get us around the track eventually, albeit at low speeds and with lots of zig-zagging. On the other end, there are reward functions with hundreds of lines of code, for example when specifically telling the model where the racing line is.", "The main objective when coding a good reward function for DeepRacer is this: for a given progress, the lower the time, the more reward the car should receive. For example, if 2 episodes both achieved 50% progress, but one was faster than the other, the faster episode should receive more reward. However, we also want to reward other aspects, such as the closeness to the optimal racing line. Therefore, balancing the different goals is the most challenging part of designing a reward function. Now let\u2019s explore how we can deal with these challenges and design an effective reward function.", "The reward function, we used to get to 12th place, has 5 main aspects:", "First, we define a default reward, i.e. a minimum reward that is always given to the car, except for when it takes an obviously bad decision. As going off track results in zero reward, the higher the default reward is, the more crashing hurts the car, so the car will be more risk-averse. However, setting the default reward too high violates our objective that fewer steps equal more reward. Therefore, the default reward should not be too high.", "Second, we add a reward for closeness to the racing line. Calculating this reward relies on the racing line we computed in chapter 2. Adding this reward reduces zig-zagging and is especially helpful when a new model has just started training. Yet, if this reward is too high, the car will only tediously follow the racing line, but not care about speed.", "Third, we add a reward for closeness to the optimal speed. We are not using \u201cmore speed equals more reward\u201d because if we have a wrong proportion of rewards, the car will predominantly care about going fast, and never be able to pass the first curve in training. So, it is easier to define an optimal speed, although we know that it only is an approximation.", "Fourth, we add a significant reward when the car completes a lap, so when it reaches 100% progress. The fewer steps it used, the higher this reward is. We can base the reward on the number of steps because the model takes 15\u00b10.5 steps per second. We start giving a reward once the time is something the model can easily manage to do, while we cap the reward at a time that is equal to the fastest time on the leaderboard. We experimented with not only giving a reward when completing the lap but at more frequent intervals. However, that led to a model caring too much about speed.", "Lastly, we set the total reward to almost zero for obviously wrong decisions, which are:", "The cutoff values of 30 degrees and 0.7 m/s worked well for us, but further experimentation may lead to better results. Additionally, this punishment to almost zero makes our reward function discrete. In theory, continuous reward functions make the model learn faster because even if the car is doing something horrible, a slightly less horrible state should score lightly better. So as for the cutoff values, further experimentation may also lead to better results.", "To see our entire reward function, please refer to our GitHub Repo.", "We define a sub-reward as an aspect of the reward function, such as the reward for closeness to the racing line. Within the reward function, there are 2 main ways to combine sub-rewards to the total reward: adding or multiplying them.", "In our experience, adding sub-rewards together works better than multiplying sub-rewards. We believe that this is the case because if one sub-reward is close to zero, the model will not care about improving the other sub-rewards when using the multiplication approach.", "For example, we tested a multiplication approach for 2 sub-rewards: closeness to the racing line, and closeness to the optimal speed. If the car is far away from the racing line but makes a good decision regarding speed, the car will still get zero reward, even though it took a good decision. Therefore, in our experiments, models with a multiplication approach were never able to complete an entire lap, let alone a fast lap. From this, we learned that we have to reward the car for good speeds even if it is not on the optimal racing line.", "The following plots visualize both approaches. In the multiplication approach, we can see that if the car is far off the racing line, improving the speed does not matter as much anymore.", "Hyperparameters have quite a steep learning curve, so mastering them takes a lot of time. Therefore, we recommend to get your head around action spaces and reward functions first, before experimenting with hyperparameters.", "During our experiments, we learned that starting with default hyperparameters, but higher batch size because of the long track, works well for the first hours of training. As soon as the model starts to converge, we reduce the entropy and learning rate. However, hyperparameters highly depend on the reward function, action space, and track, so we encourage you to experiment a lot.", "A note on entropy: sometimes, a model performs worse after cloning. The reason for this is that entropy decreases over time during training as the model becomes more confident in its decisions. However, when the model is cloned, the entropy is reset to the hyperparameter value, which is defined when setting up the training.", "The aspects we covered until now should only be a starting point for you. Each track, action space, and model behaves differently. This is why analyzing the logs after each training is so important.", "Fortunately, the DeepRacer Community wrote a Log Analysis Tool on GitHub, with which training sessions, evaluations, and the action space can be analyzed. We highly recommend to use them. There are multiple resources, such as this blog post, which explain everything you need to know about the log analysis tool.", "The overall goal of log analysis is to try out different variations of reward functions, hyperparameters, and action spaces and see which variations lead to the best time, progress, improvement, or convergence. This iterative approach takes time. So, you should plan your experiments considering your time and budget constraints. For example, our team of 3 conducted 477 different training sessions, accumulating a total of 2950 hours of training in April and May.", "To decide which variation we want to pursue further, we look at the time and progress. Models that perform well on these two aspects, compared to similar experiments, are further pursued. When creating a new model, we follow a 3 step process:", "A health warning about the cost of training: We as students were only able to train for so many hours because May 2020 was free of charge for the F1 event. So please keep an eye on the billing dashboard as it is very easy to run up a large bill.", "After having trained a model, with which we are happy, we submit it to the race. A good model will have a balance between speed and reliability. Therefore, it will not complete 100% of laps or have consistent lap times. As only the best time out of all submissions counts for the final time, we can submit our model multiple times to improve our ranking in the race. This can either be done manually or automatically through a web scraping tool.", "Multiple web scraping packages for python are available. This article describes the 3 most popular ones: Scrapy, Selenium, and Beautiful Soup.", "Using Selenium, we coded a function, which auto-submits a model to a race for a specified amount of time. The advantage of this is, that we are only using the console, not SageMaker nor the AWS CLI. As a bonus, we also coded a function, which automatically conducts experiments with hyperparameters. This can be used to conduct multiple experiments overnight without having to manually set them up every couple of hours.", "To see the code for our Selenium functions, please refer to our GitHub Repo.", "Only using the AWS DeepRacer console to train models, we showed how to compute the optimal racing line and speed, optimize the action space with K-Means clustering, design a good reward function, analyze logs to continuously improve the model, and auto-submit the model to the race. Using all these tools and spending a bit of time to adapt them to your situation, you will be able to improve your DeepRacer rankings soon. In general, we were able to show that balancing the different goals is the main challenge in applied reinforcement learning. In the case of DeepRacer, these goals are speed, reliability, and fast learning.", "As a next step, once you have a well enough understanding of DeepRacer, you could try training models in AWS SageMaker or even a local setup. These 2 options will give you higher flexibility and possibly lower costs than using the DeepRacer Console. All the necessary resources are located in the DeepRacer Community\u2019s GitHub. Additionally, feel free to check out the community\u2019s website or YouTube channel. The community is always willing to help if you get stuck, need some advice, or simply want to learn more about DeepRacer.", "A big thank you to my team members Natalia Korchagina and Marc Cervera, without whom our team would have never achieved its result. Also, thank you to Lyndon Leggate and Tomasz Ptak from the DeepRacer community for their amazing helpfulness. Finally, thank you to our ESADE professors, who allowed us to participate in DeepRacer as a university project \u2014 we learned so much about reinforcement learning along the way!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2b462c37eea&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2b462c37eea--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dgnzlz?source=post_page-----2b462c37eea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dgnzlz?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Daniel Gonzalez"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F623cd6961373&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&user=Daniel+Gonzalez&userId=623cd6961373&source=post_page-623cd6961373----2b462c37eea---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral", "anchor_text": "chuttersnap"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "dgnzlz/Capstone_AWS_DeepRacerCode that was used in the Article \u201cAn Advanced Guide to AWS DeepRacer\u201dgithub.com"}, {"url": "https://towardsdatascience.com/explaining-reinforcement-learning-for-beginners-based-on-aws-deepracer-efcefff65a9b", "anchor_text": "Explaining Reinforcement Learning for Beginners based on AWS DeepRacerHigh-level explanation of how Reinforcement Learning works with neural networks in autonomous racingtowardsdatascience.com"}, {"url": "https://aws.amazon.com/deepracer/", "anchor_text": "official website"}, {"url": "https://www.remi-coulom.fr/Publications/Thesis.pdf", "anchor_text": "R\u00e9mi Coulom\u2019s Ph.D. Thesis"}, {"url": "https://github.com/cdthompson/deepracer-k1999-race-lines", "anchor_text": "this GitHub Repo"}, {"url": "https://github.com/aws-deepracer-community/deepracer-simapp/tree/master/bundle/deepracer_simulation_environment/share/deepracer_simulation_environment/routes", "anchor_text": "DeepRacer Community\u2019s GitHub Repo"}, {"url": "https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1", "anchor_text": "this"}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo"}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo"}, {"url": "https://github.com/aws-deepracer-community/deepracer-analysis", "anchor_text": "Log Analysis Tool on GitHub"}, {"url": "https://blog.deepracing.io/2020/03/30/introducing-aws-deepracer-log-analysis/", "anchor_text": "this blog post"}, {"url": "https://medium.com/analytics-vidhya/scrapy-vs-selenium-vs-beautiful-soup-for-web-scraping-24008b6c87b8", "anchor_text": "This"}, {"url": "https://github.com/dgnzlz/Capstone_AWS_DeepRacer", "anchor_text": "GitHub Repo"}, {"url": "https://github.com/aws-deepracer-community", "anchor_text": "DeepRacer Community\u2019s GitHub"}, {"url": "https://deepracing.io/", "anchor_text": "website"}, {"url": "https://www.youtube.com/c/AWSDeepRacerCommunity", "anchor_text": "YouTube channel"}, {"url": "https://www.linkedin.com/in/natalia-korchagina/", "anchor_text": "Natalia Korchagina"}, {"url": "https://www.linkedin.com/in/marc-cervera-castro/", "anchor_text": "Marc Cervera"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----2b462c37eea---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/aws-deepracer?source=post_page-----2b462c37eea---------------aws_deepracer-----------------", "anchor_text": "Aws Deepracer"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2b462c37eea---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/formula-1?source=post_page-----2b462c37eea---------------formula_1-----------------", "anchor_text": "Formula 1"}, {"url": "https://medium.com/tag/self-driving-cars?source=post_page-----2b462c37eea---------------self_driving_cars-----------------", "anchor_text": "Self Driving Cars"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&user=Daniel+Gonzalez&userId=623cd6961373&source=-----2b462c37eea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&user=Daniel+Gonzalez&userId=623cd6961373&source=-----2b462c37eea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2b462c37eea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2b462c37eea---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2b462c37eea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2b462c37eea--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2b462c37eea--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2b462c37eea--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2b462c37eea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dgnzlz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dgnzlz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Gonzalez"}, {"url": "https://medium.com/@dgnzlz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "42 Followers"}, {"url": "http://linkedin.com/in/dg4", "anchor_text": "linkedin.com/in/dg4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F623cd6961373&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&user=Daniel+Gonzalez&userId=623cd6961373&source=post_page-623cd6961373--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F805df7ad622e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-advanced-guide-to-aws-deepracer-2b462c37eea&newsletterV3=623cd6961373&newsletterV3Id=805df7ad622e&user=Daniel+Gonzalez&userId=623cd6961373&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}