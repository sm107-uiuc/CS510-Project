{"url": "https://towardsdatascience.com/beginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd", "time": 1682996796.254488, "path": "towardsdatascience.com/beginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd/", "webpage": {"metadata": {"title": "Beginner\u2019s Guide to Create End-to-End Machine Learning Pipeline in PySpark | by Sherry Wang | Towards Data Science", "h1": "Beginner\u2019s Guide to Create End-to-End Machine Learning Pipeline in PySpark", "description": "When I realized my training set includes more than 10 millions rows daily, first thing came to my mind was sub-sampling. However, as I started subsampling, I found it hard to not create any bias\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/Azure/mmlspark", "anchor_text": "mmlspark", "paragraph_index": 1}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "feature engineering and pipeline functions", "paragraph_index": 1}, {"url": "https://changhsinlee.com/pyspark-udf/", "anchor_text": "This blog", "paragraph_index": 4}, {"url": "https://docs.databricks.com/spark/latest/spark-sql/udf-python.html", "anchor_text": "this Databricks notebook", "paragraph_index": 4}, {"url": "https://spark.apache.org/docs/latest/ml-guide.html", "anchor_text": "the documentation", "paragraph_index": 7}, {"url": "https://spark.apache.org/docs/latest/ml-guide.html", "anchor_text": "spark\u2019s announcement", "paragraph_index": 7}, {"url": "https://spark.apache.org/docs/latest/ml-classification-regression.html", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://github.com/Azure/mmlspark", "anchor_text": "mmlspark", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/latest/ml-features.html#vectorassembler", "anchor_text": "VecorAssembler", "paragraph_index": 13}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "here", "paragraph_index": 13}, {"url": "https://spark.apache.org/docs/latest/index.html", "anchor_text": "Spark documentation", "paragraph_index": 14}, {"url": "https://docs.databricks.com/spark/latest/mllib/index.html#apache-spark-mllib", "anchor_text": "Databrick\u2019s notebook documentation for machine learning", "paragraph_index": 15}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "This notebook", "paragraph_index": 15}, {"url": "https://docs.databricks.com/spark/latest/mllib/mllib-mlflow-integration.html", "anchor_text": "this notebook", "paragraph_index": 15}, {"url": "https://en.wikipedia.org/wiki/Apache_Spark", "anchor_text": "Apache Spark wikipedia", "paragraph_index": 16}, {"url": "https://databricks.com/spark/about", "anchor_text": "DataBrick\u2019s spark introduction page", "paragraph_index": 17}], "all_paragraphs": ["When I realized my training set includes more than 10 millions rows daily, first thing came to my mind was sub-sampling. However, as I started subsampling, I found it hard to not create any bias during the process. That\u2019s when I thought of building a model without subsampling using Spark.", "I thought there won\u2019t be much modeling choices in Spark, and the spark machine learning package won\u2019t be as powerful and user friendly as sklearn. However to my surprise, I found everything I needed in Spark easily. I found the model I wanted to use, lightgbm, in mmlspark (an open source package for spark developed by Microsfot); and I found pretty well-documented feature engineering and pipeline functions from spark MLlib package.", "It wasn\u2019t an easy journey to build my first end to end training pipeline though. Spark isn\u2019t as widely used for machine learning as Python just yet, thus its community support is sometimes limited, useful information is very scattered, and there isn\u2019t a good beginner\u2019s guide to help clarify common confusions. Thus in this post, I\u2019ll list go over some foundational concepts, share lessons learned during my journey and list some resources I found useful.", "Python Code and Functions : Python code works with Python objects (list, dictionary, pandas data types, numpy data types etc.) is executable in PySpark, but they won\u2019t benefit from spark at all (i.e. distributed computing).", "Python code can\u2019t be applied to Spark objects (RDD, Spark Datasets, Spark Dataframe etc.) directly though. If needed, such code can be turned into UDFs (User Defined Functions) to apply to each row of Spark objects (just like map in pandas). This blog explains UDF very well, and there\u2019s also code example from this Databricks notebook.", "PySpark Code and Functions: Pyspark code can only be applied to spark objects. They won\u2019t work when applying to Python objects.", "Python and PySpark Object Conversion: It is possible to convert some (but not all) python objects (e.g. pandas dataframe) to spark objects (e.g. spark dataframe) and vise versa when it\u2019s small enough to fit in the driver's memory.", "It was very confusing to me at first that when checking the documentation, you\u2019ll see MLlib being used as the name of machine learning library, but all the code examples import from pyspark.ml. In fact both spark.mllib and spark.ml are spark\u2019s machine learning libraries: spark.mllib is the old library that works with RDD while spark.ml is the new API build around spark dataframe. According to spark\u2019s announcement, the RDD-based API has entered maintenance mode since Spark 2.0.0. This means there won\u2019t be new features added to pyspark.mllib, and after reaching feature parity the RDD-based API will be deprecate; pyspark.mllib is expected to be removed in Spark 3.0. In short, use pyspark.ml and do not use pyspark.mllib whenever you can.", "spark\u2019s machine learning library includes a lot of industry widely used algorithms such as generalized linear models, random forest, gradient boosted tree etc. The full list of supported algorithms can be found here.", "There are also open source library mmlspark. It provides seamless integration of Spark Machine Learning pipelines with Microsoft Cognitive Toolkit (CNTK), LightGBM and OpenCV. Unfortunately another very popular training framework, xgboost, is not supported in PySpark. Even though there\u2019s XGBoost4J-Spark that integrates xgboost frame on spark, there\u2019s no Python API developed yet.", "As mentioned before, technically it\u2019s possible to import the python xgboost or lightgbm module and apply training functions on a pandas dataframe in PySpark, if training data could fit in driver memory. However this approach wouldn\u2019t benefit from Spark at all (i.e. training would be happening on single machine but not distributed across machines just as without Spark,).", "One surprise to me is that ensemble models random forest and gradient boosted trees can\u2019t take values more than 30 for max_depth parameter. Training time also increases exponentially as max_depth increases. With my training set, training a 20 depth random forest took 1 hour and a 30 depth one took 8 hours. In my opinion shallow tree for random forest is a problem because when training data is big, deep individual trees are able to find diverse \u201crules\u201d, and such diversity should help performance.", "It\u2019s important to allocate enough memory for executors during training, and it worth spending time tuning num-cores, num-executors and executor-memory. One of my training runs finished in 10mins with the right resource allocation comparing to 2 hours when I first started tuning for resource allocation.", "Most if not all spark models takes a dataframe of 2 columns, feature and label, as input. Feature column is a list of all the feature values concatenated. VecorAssembler is the function to do it, and should always be used as the last step of feature engineering. There\u2019s an example of using it in modeling pipeline here.", "Google of course is the first choice when it comes to searching for something you need, but I found looking through Spark documentation for functions also very helpful. It\u2019s important to refer to the the right Spark version though (above link is version 2.4.3).", "Spark MLlib documentation already has a lot of code examples, but I found Databrick\u2019s notebook documentation for machine learning even better. This notebook walks through a classification training pipeline, and this notebook demonstrates parameter tuning and mlflow for tracking. These notebooks are created to explain how to use various Spark MLlib features in Databricks, but a lot of functionalities showcased in these notebooks are not for Databricks exclusively.", "Apache Spark wikipedia summarized important Spark modules very nicely. I didn\u2019t get much out of it when I first read it, but after some learning of spark, I grew to appreciate this page as it provides a very good overall introduction of Apache Spark.", "I also liked the \u201cApache Spark Ecosystem\u201d section on DataBrick\u2019s spark introduction page a lot. This is very similar to the information on wikipedia page. Reading both have provided me with a thorough high-level understanding of Spark ecosystem.", "Comparing to python, there\u2019s a less of community support for pyspark, especially when it comes to machine learning tasks. I also didn\u2019t find much open source development for pyspark, other than mmlspark. However Spark is a very powerful tool when it comes to big data: I was able to train a lightgbm model in spark with ~20M rows and ~100 features in 10 minutess. Of course runtime depends a lot on the model parameters, but it showcases the power of Spark.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Love people, art, music, science, tech. Adventurer, creator and dreamer. Doing data science for a living. Dreaming to be a writer. Learning to be a mother."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd3df25a08dfd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sherry_wang?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sherry_wang?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Sherry Wang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d9e595bc5e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&user=Sherry+Wang&userId=6d9e595bc5e8&source=post_page-6d9e595bc5e8----d3df25a08dfd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@freegraphictoday?utm_source=medium&utm_medium=referral", "anchor_text": "AbsolutVision"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/Azure/mmlspark", "anchor_text": "mmlspark"}, {"url": "https://spark.apache.org/docs/latest/ml-pipeline.html", "anchor_text": "feature engineering and pipeline functions"}, {"url": "https://changhsinlee.com/pyspark-udf/", "anchor_text": "This blog"}, {"url": "https://docs.databricks.com/spark/latest/spark-sql/udf-python.html", "anchor_text": "this Databricks notebook"}, {"url": "https://spark.apache.org/docs/latest/ml-guide.html", "anchor_text": "the documentation"}, {"url": "https://spark.apache.org/docs/latest/ml-guide.html", "anchor_text": "spark\u2019s announcement"}, {"url": "https://spark.apache.org/docs/latest/ml-classification-regression.html", "anchor_text": "here"}, {"url": "https://github.com/Azure/mmlspark", "anchor_text": "mmlspark"}, {"url": "https://spark.apache.org/docs/latest/ml-features.html#vectorassembler", "anchor_text": "VecorAssembler"}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "here"}, {"url": "https://spark.apache.org/docs/latest/index.html", "anchor_text": "Spark documentation"}, {"url": "https://docs.databricks.com/spark/latest/mllib/index.html#apache-spark-mllib", "anchor_text": "Databrick\u2019s notebook documentation for machine learning"}, {"url": "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html", "anchor_text": "This notebook"}, {"url": "https://docs.databricks.com/spark/latest/mllib/mllib-mlflow-integration.html", "anchor_text": "this notebook"}, {"url": "https://en.wikipedia.org/wiki/Apache_Spark", "anchor_text": "Apache Spark wikipedia"}, {"url": "https://databricks.com/spark/about", "anchor_text": "DataBrick\u2019s spark introduction page"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d3df25a08dfd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----d3df25a08dfd---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d3df25a08dfd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/big-data?source=post_page-----d3df25a08dfd---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&user=Sherry+Wang&userId=6d9e595bc5e8&source=-----d3df25a08dfd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&user=Sherry+Wang&userId=6d9e595bc5e8&source=-----d3df25a08dfd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd3df25a08dfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d3df25a08dfd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d3df25a08dfd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sherry_wang?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sherry_wang?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sherry Wang"}, {"url": "https://medium.com/@sherry_wang/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "88 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d9e595bc5e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&user=Sherry+Wang&userId=6d9e595bc5e8&source=post_page-6d9e595bc5e8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcadab8e2435f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeginners-guide-to-create-first-end-to-end-machine-learning-pipeline-in-pyspark-d3df25a08dfd&newsletterV3=6d9e595bc5e8&newsletterV3Id=cadab8e2435f&user=Sherry+Wang&userId=6d9e595bc5e8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}