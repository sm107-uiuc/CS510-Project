{"url": "https://towardsdatascience.com/how-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673", "time": 1683001436.188876, "path": "towardsdatascience.com/how-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673/", "webpage": {"metadata": {"title": "How to create a machine learning dataset from scratch? | by Carsten Klein | Towards Data Science", "h1": "How to create a machine learning dataset from scratch?", "description": "My grandmother was an outstanding cook. So when I recently came across her old cook book I tried to read through some of the recipes, hoping I could recreate some of the dishes I enjoyed as a kid\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Fraktur", "anchor_text": "fraktur", "paragraph_index": 0}, {"url": "https://github.com/akcarsten/cook_book", "anchor_text": "the Jupyter Notebooks on Github", "paragraph_index": 3}, {"url": "https://opencv.org/", "anchor_text": "openCV library", "paragraph_index": 5}, {"url": "https://opencv.org/", "anchor_text": "openCV", "paragraph_index": 6}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Standard_score", "anchor_text": "z-scores", "paragraph_index": 10}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook to this article", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/whos-talking-using-k-means-clustering-to-sort-neural-events-in-python-e7a8a76f316", "anchor_text": "different use case here", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/whos-talking-using-k-means-clustering-to-sort-neural-events-in-python-e7a8a76f316", "anchor_text": "PCA and K-Means", "paragraph_index": 13}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST dataset", "paragraph_index": 14}, {"url": "https://github.com/akcarsten/convert_IDX", "anchor_text": "idx_converter", "paragraph_index": 14}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook", "paragraph_index": 14}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "here", "paragraph_index": 16}, {"url": "https://twitter.com/ak_carsten", "anchor_text": "Twitter", "paragraph_index": 16}, {"url": "https://www.linkedin.com/in/carsten-klein/", "anchor_text": "LinkedIn", "paragraph_index": 16}], "all_paragraphs": ["My grandmother was an outstanding cook. So when I recently came across her old cook book I tried to read through some of the recipes, hoping I could recreate some of the dishes I enjoyed as a kid. However this turned out harder than expected since the book was printed around 1911 in a typeface called fraktur. Unfortunately the fraktur typeface deviates from modern typefaces in several instances. For example the letter \u201cA\u201d looks like a \u201cU\u201d in fraktur and every time I see a \u201cZ\u201d in fraktur I read a \u201c3\u201d (see Figure 2).", "So the idea emerged to develop a pipeline that will create a live translation of the fraktur letters into a modern typeface. With such a tool in hand we could easily read through the recipes and focus on the cooking part instead of deciphering the book. Luckily there are many great open source tools out there that will help us to develop such a pipeline. However some aspects of this project have to be build from scratch. Mainly we need a dataset to train our machine learning algorithm(s) on. And this is what we will focus on in this article. But before we get started with the dataset, lets have a quick look on all the tasks that lay ahead of us:", "We will cover the first two topics within this article and continue on topics 3 and 4 in a second and third article. This should give us enough room to explore each of the tasks in detail.", "Also as a general remark: In these articles we will not focus on how to implement each algorithm from scratch. Instead we will see how we can connect different tools to translate the cook book into a modern typeface. If you are more interested in the code than in the explanations you can also go directly to the Jupyter Notebooks on Github.", "So the first task is finding a way to extract individual letters from the pages of the cook book. This is the basis for everything that follows. In the next step we can then create a dataset from the extracted letters and finally train a classifier on it.", "The inputs to our pipeline will always be pictures of pages from the cook book similar to the one shown in Figure 3 above. These inputs can be either single high resolution images from a smartphone camera or a stream of images from a webcam. What we have to ensure is that each image, independent from its source, is processed in a way that the detection algorithm can find all single letters. The first thing to remember here is that digital cameras store images in three separate channels: Red, Green and Blue (RGB). But in our case these three channels contain redundant information as the letters can be identified in each of these three channels separately. Therefore we will convert all images to gray scale first. As a result, instead of three channels we only have to deal with one channel. In addition we also reduced the amount of data to 1/3 which should improve performance. But our detection algorithm will face another problem: varying lightning conditions. This complicates the separation of letters from the background as contrast changes across the image. To solve this we will use a technique called adaptive thresholding which uses close-by pixels to create local thresholds which are then used to binarize the image. As a result the processed image will only consist of black and white pixels; no gray anymore. We can then further optimize the image for letter detection by denoising it with a median blur filter. The code below outlines a Python function that does the image conversion from RGB to black and white with the help of the openCV library. The result of this processing step is further exemplified in Figure 4.", "Ok now that we processed the image it is time to detect the letters. For this we can use the findContours method of the openCV library. The code boils down to a single line which is called by the function below. We can then map the bounding boxes of the contours found by this function back onto the original RGB image to see what was actually detected (Figure 5).", "From Figure 5 we can see that the detection works quite well. However in some cases letters are not detected, e.g. some of the \u201ci\u201ds at the end of line 1. And in other cases a single letter is split into two letters, e.g. \u201cb\u201d at the end of the last line. Another thing to notice is that some letter combinations essentially become a single letter and are detected accordingly by the algorithm, two examples from Figure 5 are \u201cch\u201d and \u201cck\u201d. We will later see how to deal with these issues. But for now we can move on with the current result. So since we have the bounding boxes of each letter we can cut them out and save them as individual images (.png) in a folder on our hard drive. If you are interested in how to do this, have a look into the Jupyter Notebook.", "Having a set of extracted letters is good but we need to organize them in a way that the dataset becomes useful for us. For this we have to do two things:", "Both of the above points are, in principle, easy to solve. However, since we extracted several thousands of potential letters from many pages of the book they pose a long and tedious task. On the bright side, we can automatize the first round of the grouping so that we will later \u201conly\u201d have to correct the result of this pre-grouping step. But there is one more thing to do before we can get started with this clustering step: We have to bring all images of the extracted letters to the same size.", "The reason for this is that the algorithms we will use for the clustering and also for the classification, expect a fixed size of the input images. But as we can see from the bounding boxes in Figure 5 each image currently has a different shape. To overcome this variety of image sizes we will use the resize method of the openCV library and bring all images to the same size. We will then store the images in a Numpy array and normalize them by calculating their z-scores. The normalization is important for the next step, which is reducing the number of dimensions of each image with Principal Component Analysis (PCA). The scores of the first principal components will then be the input to the K-Means clustering algorithm which will do the pre-clustering of the letters for us. If you are interested in the details of this procedure and the K-Means algorithm you can check either the Jupyter Notebook to this article or learn about a different use case here. The results of the K-Means clustering are visualized in Figure 6 where the color of each dot indicates the cluster it belongs to. Looking at Figure 6 it seems like some data points form groups that were also assigned to the same cluster by the K-Means algorithm. However, it is difficult to judge from Figure 6 alone how well the clustering worked. A better way to evaluate the results is to move all images in a cluster to a separate folder and than have a look at the content of each cluster. Figure 7 shows the images in an example folder where the clustering worked very well. The next step would be to rename this folder to \u201ca\u201d.", "In other cases the clustering did not work so well. Figure 8 shows an example of a cluster that contains different types of letters. While most of the letters are \u201cn\u201ds there are also some \u201cK\u201ds and \u201cu\u201ds in the cluster. However we can easily fix this by searching for the \u201cK\u201d and \u201cu\u201d clusters and move the images there. Afterwards the folder can be renamed to \u201cn\u201d.", "We will continue like this until all clusters are cleaned and renamed as described above. The result should look similar to Figure 9, where upper case letters are marked by \u201c_\u201d.", "So, obviously it needed some manual work to get the data into shape. However we were able to automatize a big part of the work by pre-clustering the data with PCA and K-Means. The dataset is now cleaned and organized, but for us to work efficiently we need to save it in a more convenient way than folders on the hard drive.", "The final step, to wrap all of this up is therefore to convert the dataset into the IDX data format. You might be familiar with this format already as the famous MNIST dataset is saved in the same way. Only here instead of reading the data from an IDX file we have to write it.We will do so by using an idx_converter which takes a file structure as we set up above and directly saves it in the IDX format. The output will be two files: one file with the images and a second file with the labels.Since we want to later train a classifier on the data, we should already split the images into a training and a test dataset. For this we will move 30% of the letters to a test folder while the remaining letters stay in the training folder. You can check the code in the Jupyter Notebook for details about the implementation of this procedure.", "Now that we created a fraktur dataset from scratch we can move on to the next article in which we will compare the performance of several classifier algorithms in order to select one for the live translation of the cook book.", "Meanwhile you can check out the complete code for this article here, follow me on Twitter or connect via LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD in neuroscience interested in data analysis and artificial intelligence"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6a24a9fd1673&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://carstenklein.medium.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": ""}, {"url": "https://carstenklein.medium.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Carsten Klein"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc804c71f161a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&user=Carsten+Klein&userId=c804c71f161a&source=post_page-c804c71f161a----6a24a9fd1673---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Fraktur", "anchor_text": "fraktur"}, {"url": "https://github.com/akcarsten/cook_book", "anchor_text": "the Jupyter Notebooks on Github"}, {"url": "https://opencv.org/", "anchor_text": "openCV library"}, {"url": "https://opencv.org/", "anchor_text": "openCV"}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook"}, {"url": "https://en.wikipedia.org/wiki/Standard_score", "anchor_text": "z-scores"}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook to this article"}, {"url": "https://towardsdatascience.com/whos-talking-using-k-means-clustering-to-sort-neural-events-in-python-e7a8a76f316", "anchor_text": "different use case here"}, {"url": "https://towardsdatascience.com/whos-talking-using-k-means-clustering-to-sort-neural-events-in-python-e7a8a76f316", "anchor_text": "PCA and K-Means"}, {"url": "http://yann.lecun.com/exdb/mnist/", "anchor_text": "MNIST dataset"}, {"url": "https://github.com/akcarsten/convert_IDX", "anchor_text": "idx_converter"}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "Jupyter Notebook"}, {"url": "https://github.com/akcarsten/cook_book/blob/master/01_create_first_dataset.ipynb", "anchor_text": "here"}, {"url": "https://twitter.com/ak_carsten", "anchor_text": "Twitter"}, {"url": "https://www.linkedin.com/in/carsten-klein/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6a24a9fd1673---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/image-processing?source=post_page-----6a24a9fd1673---------------image_processing-----------------", "anchor_text": "Image Processing"}, {"url": "https://medium.com/tag/dataset?source=post_page-----6a24a9fd1673---------------dataset-----------------", "anchor_text": "Dataset"}, {"url": "https://medium.com/tag/opencv-python?source=post_page-----6a24a9fd1673---------------opencv_python-----------------", "anchor_text": "Opencv Python"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----6a24a9fd1673---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&user=Carsten+Klein&userId=c804c71f161a&source=-----6a24a9fd1673---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&user=Carsten+Klein&userId=c804c71f161a&source=-----6a24a9fd1673---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6a24a9fd1673&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6a24a9fd1673---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6a24a9fd1673--------------------------------", "anchor_text": ""}, {"url": "https://carstenklein.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://carstenklein.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Carsten Klein"}, {"url": "https://carstenklein.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "669 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc804c71f161a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&user=Carsten+Klein&userId=c804c71f161a&source=post_page-c804c71f161a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F540b346ea76a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-create-a-machine-learning-dataset-from-scratch-6a24a9fd1673&newsletterV3=c804c71f161a&newsletterV3Id=540b346ea76a&user=Carsten+Klein&userId=c804c71f161a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}