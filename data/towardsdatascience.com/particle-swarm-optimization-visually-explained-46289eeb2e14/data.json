{"url": "https://towardsdatascience.com/particle-swarm-optimization-visually-explained-46289eeb2e14", "time": 1683018043.468385, "path": "towardsdatascience.com/particle-swarm-optimization-visually-explained-46289eeb2e14/", "webpage": {"metadata": {"title": "Particle Swarm Optimization (PSO) Visually Explained | by \u2b50Axel Thevenot | Towards Data Science", "h1": "Particle Swarm Optimization (PSO) Visually Explained", "description": "Particle swarm optimization (PSO) has been successfully applied in many research and application areas. For my part, I really enjoyed the application of this algorithm in the article by G. Sermpinis\u2026"}, "outgoing_paragraph_urls": [{"url": "https://axel-thevenot.medium.com/membership", "anchor_text": "one click here", "paragraph_index": 44}], "all_paragraphs": ["Particle swarm optimization (PSO) has been successfully applied in many research and application areas. For my part, I really enjoyed the application of this algorithm in the article by G. Sermpinis [1] on foreign exchange rate forecasting.", "It is demonstrated that PSO can have better results in a faster, cheaper way compared with other methods. It can also be parallelized. Moreover, it does not use the gradient of the problem being optimized. In other words, unlike traditional optimization methods, PSO does not require the problem to be differentiable.", "Last but not least, there are very few hyperparameters. These parameters are very simple to understand and do not require advanced notions. For the same hyperparameters, PSO will work on a very wide variety of tasks, which makes it a very powerful and flexible algorithm.", "Throughout this article, I will detail the mechanisms behind the Particle Swarm Optimization algorithm assuming as a metaphor a group of birds.", "The objective of this article will be to minimize the function you see above. The function in question is clearly defined, includes only 2 variables, and is differentiable. But keep in mind that this function could be a non-differentiable step function, or a function defined by the weights of a neural network for which we do not know the global minimum [1].", "For pedagogical purposes, we will consider the function f(x, y) = x\u00b2 + (y + 1)\u00b2 - 5cos(1.5x + 1.5) - 3cos(2x - 1.5) which allows us a 2D and 3D visualization. Thus the objective of this article will be to optimize the function f its global minimum given x and y.", "Before we dive into our simple application case, let\u2019s jump into the past. Particle Swarm Optimization is a population based stochastic optimization technique developed by Dr. Eberhart and Dr. Kennedy in 1995 [2] inspired by the social behavior of birds or schools of fish.", "Bedtime story: a group of birds is looking for food in a vast valley. There is food in only one place in this valley. None of the birds know where the food is, but all the birds have an idea of how far away they are from the food.", "PSO traduction: a group of particles (potential solutions) of the global minimum in a research space. There is only a global minimum in this search space. None of the particles knows where the global minimum is located, but all particles have fitness values evaluated by the fitness function to be optimized.", "Before going further in the explanation of the PSO algorithm, let\u2019s focus a moment on our particles. As you will have understood, each of these particles is a potential solution of the function to be minimized. They are defined by their coordinates in the search space.", "We can then randomly define particles in the search space as in the image above. But these particles must be in movement to find the optimal function.", "Bedtime story: each of these birds moves with a certain speed of flight through the valley to find food.", "PSO traduction: each of these particles is in movement with a velocity allowing them to update their position over the iterations to find the global minimum.", "The particles have already been randomly distributed in the search space. Their velocity must then be initialized. Defined by its speed in each direction the velocity vector will once again be randomized. For this reason, we speak of stochastic algorithms.", "PSO shares many similarities with evolutionary computation techniques such as Genetic Algorithms (GA). The system is initialized with a population of random solutions and searches for optima by updating generations. However, unlike GA, PSO has no evolution operators such as crossover and mutation. The difference is in the way the generations are updated.", "Bedtime story: while flying through the valley, the birds keep their speed (inertia) but also change their direction. Each bird aims to prove he is better than the others. He tries to find food based on his intuition (cognitive). But because he tends to imitate the others (social), he is also influenced by the experience and knowledge of his group.", "PSO traduction: over the iterations in the search space, the speed of each particle is stochastically accelerated towards its previous best position (personal best) and towards the best solution of the group (global best).", "Concretely, at each iteration, each particle is updated according to its velocity. This velocity is subject to inertia and is governed by the two best values found so far.", "The first value is the best personal solution the particle has found so far. The second one is the best global solution that the swarm of particles has found so far. So each particle has in memory its best personal solution and the best global solution.", "As you might have noticed, I have not yet talked about the inertia, cognitive and social coefficients. These coefficients control the levels of exploration and exploitation. Exploitation is the ability of particles to target the best solutions found so far. Exploration, on the other hand, is the ability of particles to evaluate the entire research space. The challenge of the remaining part of the article will be to determine the impact of these coefficients to find a good balance between exploration and exploitation.", "This assertion of a balance between exploration and exploitation does not make much sense unless both are defined in a measurable way and, moreover, such a balance is neither necessary nor sufficient from an efficiency point of view. But for the sake of understanding, I will use these terms in this article.", "Bedtime story: each day, our emotionally driven birds can more or less get up on the wrong side of the bed. Then they will more or less want to follow their intuition and follow the group.", "PSO traduction: at each iteration, the acceleration is weighted by random terms. Cognitive acceleration and social acceleration are stochastically adjusted by the weights r1 and r2.", "These two weights r1 and r2 are unique for each particle and each iteration. This is not the case for the coefficients that I am going to introduce to you now.", "Bedtime story: in wildlife, there are different bird species. These different species more or less like to change their direction over time.", "PSO traduction: the hyperparameter w allows to define the ability of the swarm to change its direction. The particles have an inertia proportional to this coefficient w.", "To better appreciate the influence of this coefficient w (also called inertia weight), I invite you to visualize the 3 swarms of particles above. We can then see that the lower the coefficient w, the stronger the convergence. In other words, a low coefficient w facilitates the exploitation of the best solutions found so far while a high coefficient w facilitates the exploration around these solutions. Note that it is recommended to avoid w >1 which can lead to a divergence of our particles.", "The inertia weight w thus makes a balance between the exploration and the exploitation of the best solutions found so far. Let\u2019s look at how these solutions are found by studying the coefficients c1 and c2 (also called acceleration coefficients).", "Bedtime story: in wildlife, there are different bird species. Each species has an overall tendency to follow its instinct (personal) and a tendency to focus on the group experience (social).", "PSO traduction: the c1 hyperparameter allows defining the ability of the group to be influenced by the best personal solutions found over the iterations. The hyperparameter c2 allows defining the ability of the group to be influenced by the best global solution found over the iterations.", "On the GIF above, we can see the impact of these two coefficients. For the purposes, I deliberately chose a very low coefficient w and forced the extremes of c1 and c2. We can notice then how the particles of the swarm are more individualistic when c1 is high. There is, therefore, no convergence because each particle is only focused on its own best solutions. In contrast, the particles of the swarm are more influenced by the others when c2 is high. We notice on the GIF that the exploration of the solutions is not optimal and that the exploitation of the best global solution is very important (this is obvious at iteration ~40).", "The coefficients c1 and c2 are consequently complementary. A combination of the two increases both exploration and exploitation.", "Bedtime story: defined as we just did, our bird species are a little weak-minded. What we would like is to have a group of birds that takes advantage of their numbers to explore the valley as well as possible. This same group of birds, after concertation, would exploit the best places by refocusing their search with their progress.", "PSO traduction: we can go even further by updating coefficients over the iterations. Starting with a strong c1, strong w, and weak c2 to increase the exploration of the search space, we want to tend towards a weak c1, weak w, and strong c2 to exploit the best results after exploration by converging towards the global minimum.", "According to the paper by M. Clerc and J. Kennedy [3] to define a standard for Particle Swarm Optimization, the best static parameters are w=0.72984 and c1 + c2 > 4. More exactly c1 = c2 = 2.05. Additionally, the linear decay of the parameter w was initially proposed by Yuhui and Russ Y. H. Shi and R. C. Eberhart [4].", "Based on these ideas and inspired by the paper by G. Sermpinis [1], I suggest the coefficients as specified in the image above.", "For N iterations in total and t the current iteration, c2 grows linearly from 0.5 to 3.5 inversely to c1 which decreases from 3.5 to 0.5 to ensure c1 + c2 = 4. And w is initially 0.8 to slowly converges to 0.4.", "Ultimately, this sounds like a lot of information, but the Particle Swarm Optimization is a very simple algorithm and is even simpler to transcribe into python code.", "Perhaps you will have noticed the only conditions to stop my iterations are:", "These stop evaluation functions are not necessarily the bests. These stopping conditions depend heavily on the size of the swarm. The paper of A. P. Engelbrecht\u2019s paper [5] explicitly shows the choice of the evaluation function is based more on empirical results than on common standards. It also provides a wide benchmark of evaluation functions.", "A website is totally dedicated to PSO. It is rich in resources. If you want to learn more, I strongly invite you to take a look at it.", "Alos, you can find many variants of the PSO algorithm. Generally, they are motivated by two main reasons. First, PSO is close to an evolutionary algorithm so we see hybrid versions to add evolutionary capabilities. Second, there are also adaptive PSO to improve performance by adjusting the hyperparameters. To go further, N. K. Kulkarni [6] proposes in his review:", "I though this article will be ended there. Yet a reader found interesting the idea to test the robustness on a hard benchmark of function he gave me (thanks). Hard because it was specially conceived to challenge optimizations.", "So here I am and enjoy the GIFs! \ud83d\ude04", "Knowledge is all about sharing.Support me and get access of all my articles in one click here.", "[1] G. Sermpinis, K. Theofilatos, A. Karathanasopoulos, E. F. Georgopoulos, & C. Dunis, Forecasting foreign exchange rates with adaptive neural networks using radial-basis functions and Particle Swarm Optimization, European Journal of Operational Research.[2] R. Eberhart & J. Kennedy, A New Optimizer Using Particle Swarm Theory, Sixth International Symposium on Micro Machine and Human Science.[3] Clerc, M., and J. Kennedy. The Particle Swarm \u2014 Explosion, Stability, and Convergence in a Multidimensional Complex Space. IEEE Transactions on Evolutionary Computation 6, no. 1 (February 2002): 58\u201373.[4] Y. H. Shi and R. C. Eberhart, \u201cA modified particle swarm optimizer,\u201d in Proceedings of the IEEE International Conferences on Evolutionary Computation, pp. 69\u201373, Anchorage, Alaska, USA, May 1998.[5] A. P. Engelbrecht, Fitness function evaluations: A fair stopping condition?, IEEE Symposium on Swarm Intelligence.[6] N. K. Kulkarni, S. Patekar, T. Bhoskar, O. Kulkarni, G.M. Kakandikar, & V.M. Nandedkar, Particle Swarm Optimization Applications to Mechanical Engineering- A Review, Materials Today: Proceedings.[7] F. Moslehi, A. Haeri & F. Mart\u00ednez-\u00c1lvarez, A novel hybrid GA\u2013PSO framework for mining quantitative association rules, Soft Comput.[8] V. Miranda, & N. Fonseca, EPSO-evolutionary particle swarm optimization, a new algorithm with applications in power systems, IEEE/PES Transmission and Distribution Conference and Exhibition.[9] Z. Zhan, J. Zhang, Y. Li & H. S. Chung, Adaptive Particle Swarm Optimization, IEEE Transactions on Systems, Man, and Cybernetics.[10] C. A. Coello Coello, & M. S. Lechuga, MOPSO: a proposal for multiple objective particle swarm optimization, Proceedings of the 2002 Congress on Evolutionary Computation.[11] A. H. Kashan, B. Karimi, A discrete particle swarm optimization algorithm for scheduling parallel machines, Computers & Industrial Engineering.", "All the images and GIFs are homemade and free to use.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F46289eeb2e14&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://axel-thevenot.medium.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": ""}, {"url": "https://axel-thevenot.medium.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "\u2b50Axel Thevenot"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8fcc1458e87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&user=%E2%AD%90Axel+Thevenot&userId=a8fcc1458e87&source=post_page-a8fcc1458e87----46289eeb2e14---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://particleswarm.info/index.html", "anchor_text": "IndexBook: Particle Swarm Optimisation: Classical and Quantum Perspectives (2019) Book: Metaheuristics (2017) Book: Search\u2026particleswarm.info"}, {"url": "https://towardsdatascience.com/optimization-eye-pleasure-78-benchmark-test-functions-for-single-objective-optimization-92e7ed1d1f12", "anchor_text": "Optimization & Eye Pleasure: 78 Benchmark Test Functions for Single Objective OptimizationVisualization, description and python GitHub of benchmark optimization functionstowardsdatascience.com"}, {"url": "https://axel-thevenot.medium.com/membership", "anchor_text": "one click here"}, {"url": "https://github.com/AxelThevenot/Particle_Swarm_Optimization", "anchor_text": "My uncleaned script on GitHub."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----46289eeb2e14---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----46289eeb2e14---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----46289eeb2e14---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----46289eeb2e14---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----46289eeb2e14---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://creativecommons.org/publicdomain/mark/1.0/", "anchor_text": "Public domain."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&user=%E2%AD%90Axel+Thevenot&userId=a8fcc1458e87&source=-----46289eeb2e14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&user=%E2%AD%90Axel+Thevenot&userId=a8fcc1458e87&source=-----46289eeb2e14---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F46289eeb2e14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----46289eeb2e14---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----46289eeb2e14--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----46289eeb2e14--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----46289eeb2e14--------------------------------", "anchor_text": ""}, {"url": "https://axel-thevenot.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://axel-thevenot.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "\u2b50Axel Thevenot"}, {"url": "https://axel-thevenot.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "733 Followers"}, {"url": "http://www.linkedin.com/in/axel-thevenot", "anchor_text": "www.linkedin.com/in/axel-thevenot"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8fcc1458e87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&user=%E2%AD%90Axel+Thevenot&userId=a8fcc1458e87&source=post_page-a8fcc1458e87--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbb1ccd160e04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparticle-swarm-optimization-visually-explained-46289eeb2e14&newsletterV3=a8fcc1458e87&newsletterV3Id=bb1ccd160e04&user=%E2%AD%90Axel+Thevenot&userId=a8fcc1458e87&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}