{"url": "https://towardsdatascience.com/a-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f", "time": 1683006839.921592, "path": "towardsdatascience.com/a-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f/", "webpage": {"metadata": {"title": "A Deep Dive into Lane Detection with Hough Transform | by Nushaine Ferdinand | Towards Data Science", "h1": "A Deep Dive into Lane Detection with Hough Transform", "description": "Lane line detection is one of the essential components of self-driving cars. There are many approaches to doing this. Here, we\u2019ll look at the simplest approach using Hough Transform. Alright, let\u2019s\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/Nushaine/lane-detection/blob/master/Untitled33.ipynb", "anchor_text": "Github repo", "paragraph_index": 2}, {"url": "https://www.linkedin.com/in/nushaine-ferdinand-a2ba12177/", "anchor_text": "Linkedin", "paragraph_index": 82}], "all_paragraphs": ["Lane line detection is one of the essential components of self-driving cars. There are many approaches to doing this. Here, we\u2019ll look at the simplest approach using Hough Transform. Alright, let\u2019s dive into it!", "So before we get started, we need a place to write our code. The IDE (environment) that I recommend is Jupyter Notebooks. It has a nice, minimalistic interface yet is really powerful at the same time. Also, Jupyter Notebooks are awesome for visualizing data. Here\u2019s the download link:", "Now that you have Anaconda installed and Jupyter is working, let\u2019s get some data! You can download the test images, videos and source code for the algorithm from my Github repo. Now we\u2019re ready to build the algorithm.", "This article is divided into three parts:", "Parts 1 and 3 are focused on coding and Part 2 is more theory-oriented. Okay, let's dive into the first part.", "The first thing we need to do is import required libraries.", "Next, let\u2019s load in an image from our collection to test our algorithm", "Here, we load the image into the notebook in line 4, then we\u2019re going to read the image and visualize it in lines 5 and 6.", "Now its time to manipulate the image. We\u2019re going to do three things here in particular:", "Okay, in this last code block we defined 3 functions:", "Greyscale the image: This helps by increasing the contrast of the colours, making it easier to identify changes in pixel intensity.", "Gaussian Filter: The purpose of the gaussian filter is to reduce noise in the image. We do this because the gradients in Canny are really sensitive to noise, so we want to eliminate the most noise possible. The cv2.GaussianBlur function takes three parameters:", "Canny: This is where we detect the edges in the image. What it does is it calculates the change of pixel intensity (change in brightness) in a certain section in an image. Luckily, this is made very simple by OpenCV.", "Now that we\u2019ve defined all the edges in the image, we need to isolate the edges that correspond with the lane lines. Here\u2019s how we\u2019re going to do that", "This function will isolate a certain hard-coded region in the image where the lane lines are. It takes one parameter, the Canny image and outputs the isolated region.", "In line 1, we\u2019re going to extract the image dimensions using the numpy.shape function. In line 2\u20134, we\u2019re going to define the dimensions of a triangle, which is the region we want to isolate.", "In line 5 and 6, we\u2019re going to create a black plane and then we\u2019re going to define a white triangle with the dimensions that we defined in line 2.", "In line 7, we\u2019re going to perform the bitwise and operation which allows us to isolate the edges that correspond with the lane lines. Let\u2019s dive deeper into the operation.", "In our image, there are two-pixel intensities: black and white. Black pixels have a value of 0, and white pixels have a value of 255. In 8-bit binary, 0 translates to 00000000 and 255 translates to 11111111. For the bitwise and operation, we\u2019re going to use the pixel\u2019s binary values.", "Now, here\u2019s when the magic happens. We\u2019re going to multiply two pixels in the exact same location on img1 and img2 (we\u2019ll define img1 as the plane with the edge detections and img2 as the mask that we created).", "For example, the pixel at (0, 0) on img1 will be multiplied with the pixel at the point (0, 0) in img2 (and likewise for every other pixel in every other location on the image).", "We would repeat this operation for every pixel on the image, resulting in only the edges in the mask outputting.", "Now that we\u2019ve defined the edges that we want, let's define the function which turns these edges into lines.", "So A LOT is happening in this one line. This one line of code is the heart of the whole algorithm. It is called Hough Transform, the part that turns those clusters of white pixels from our isolated region into actual lines.", "Now if those seemed like gibberish, this next part dives into the nuts and bolts behind the algorithm. So you can come back to this part after you finish reading part 2, and hopefully, it will make more sense.", "Just a quick note, this section is solely theory. If you want to skip this part, you can continue to Part 3, but I encourage you to read through it. The mathematics under the hood of Hough Transform is truly spectacular. Anyways, here it is!", "Let\u2019s talk Hough Transform. In the cartesian plane (x and y-axis), lines are defined by the formula y=mx+b, where x and y correspond to a specific point on that line and m and b correspond to the slope and y-intercept.", "A regular line plotted in the cartesian plane has 2 parameters (m and b), meaning a line is defined by these values. Also, it is important to note that lines in the cartesian plane are plotted as a function of their x and y values, meaning that we are displaying the line with respect to how many (x, y) pairs make up this specific line (there is an infinite amount of x, y pairs that makeup any line, hence the reason why lines stretch to infinity).", "However, it is possible to plot lines as a function of its m and b values. This is done in a plane called Hough Space. To understand the Hough Transform algorithm, we need to understand how Hough Space works.", "In our use case, we can sum up Hough Space into two lines", "Think of the concept of a line. A line is basically an infinitely long grouping of points arranged orderly one after the other. Since on the Cartesian plane, we\u2019re plotting lines as a function of x and y, lines are displayed as infinitely long because there is an infinite number of (x, y) pairs that make up this line.", "Now in Hough Space, we\u2019re plotting lines as a function of their m and b values. And since each line has its only one m and b value per cartesian line, this line would be represented as a point.", "For example, the equation y=2x+1 represents a single line on the Cartesian Plane. Its m and b values are \u20182\u2019 and \u20181\u2019 respectively, and those are the only possible m and b values for this equation. On the other hand, this equation could have many values for x and y that would make this equation come true (left side=right side).", "So if I were to plot this equation using its m and b values, I would only use the point (2, 1). If I were to plot this equation using its x and y values, I would have an infinite amount of options because there are infinite (x, y) pairs.", "So why are lines in the Hough Space are represented as points in the Cartesian Plane (if you understood the theory well from the previous explanation, I challenge you to figure this question out on without reading the explanation.).", "Now let's think of a point on the cartesian plane. A point on the cartesian plane has only one possible (x, y) pair that can represent it, hence the reason it is a point and is not infinitely long.", "What is also true about a point is that there is an infinite amount of possible lines that can pass through this point. In other words, there is an infinite amount of equations (in the form of y=mx + b) that this point can satisfy (LS=RS).", "Currently, in the Cartesian Plane, we\u2019re plotting this point with respect to its x and y values. But in Hough Space, we\u2019re plotting this point with respect to its m and b values, and since there are infinite lines that pass through this point, the result in the Hough Space will be a line which is infinitely long.", "If you would plot each of those lines in Hough Space([-4, 16], [-8/3, 12], [-4/3, 8]), the points that represent each line in cartesian space will form one line in Hough Space (this is the line which corresponds with the point (3, 4)).", "Neat, huh? Now if what if we\u2019d place another point in the cartesian plane? How would this turn out in the Hough Space? Well, by using the Hough Space, we can actually find the line of best fit for these two points on the Cartesian Plane.", "We can do this by plotting the lines in Hough Space that correspond with the 2 points in cartesian space and find the point where these 2 lines intersect in Hough Space(a.k.a their POI, point of intersection).", "Next, get the m and b coordinates of the point where the 2 lines intersect in Hough Space and use those m and b values to form a line in the Cartesian Plane. This line will be the line of best fit for our data.", "Just to sum up what we\u2019ve been talking about,", "While these concepts are really cool and all, why do they matter? Well, remember Canny Edge detection which I mentioned before which uses gradients to measure the pixel intensities in an image and output edges.", "At their core, gradients are simply points on the image. So what we can do is we can find the line of best fit for each set of points (the cluster of gradients on the left of the image and the gradients on the right on the image). These lines of best fit are our lane lines. To get a better understanding of how this works, let's take yet another deep dive!", "So I just explained how we can find the line of best fit by looking at the m and b values of the POI of the two lines which correspond to the points in Hough Space. However, when our dataset grows, there isn\u2019t always going to be one line which perfectly fits our data.", "This is why we\u2019re going to have to use bins instead. When incorporating bins, we\u2019re going to divide the Hough Plane into equally spaced sections. Each section is called a bin. By focusing on the number of POI\u2019s in a bin, it allows us to determine a line which has a good correlation with our data.", "Upon finding the bin with the most intersections, you would then use the m and b values which correspond with that bin and form a line in the cartesian space. This line will be the line of best fit for our data.", "But HOLD UP! That\u2019s not it. We almost overlooked a colossal error!", "In a vertical line, the slope is infinity. We can\u2019t represent infinity in Hough Space. This would result in the program crashing. So instead of using y=mx+b for the equation of a line, we\u2019ll use P (rho) and \u03b8 (theta) to define a line. This is also known as the polar coordinate system.", "In the polar coordinate system, lines are represented with the equation P=xsin\u03b8 + ysin\u03b8. Before we dive deeper, let's define the meanings of these variables:", "By using the polar coordinate system, there won\u2019t be any errors, even if we have a vertical line. For example, let\u2019s take the point (6, 4), and substitute it into the equation P=xcos\u03b8+ysin\u03b8. Now, let's take the vertical line that would pass through this point, x=6 and sub it into the polar equation for a line, P = 6cos(90) + 4sin(90).", "Now let\u2019s work this equation out", "As you can see, we don\u2019t end up with an error. In fact, we didn\u2019t even have to do this calculation, since we technically already know what P is even before we start. Note how P is equal to the x value. Since the line is vertical, the only type of line that is perpendicular to it is a horizontal line. Since this horizontal line starts at the origin, this is the same thing as saying the amount of distance travelled on the x-axis from the origin.", "So now that\u2019s out of the way, are we ready to get back to coding? Not just yet. Remember before when we plotted points in the cartesian plane, we\u2019d end up with lines in Hough Space? Well, when we use polar coordinates, we\u2019d end up with a curve instead of a line.", "However, the concept remains the same. We\u2019re going to find the bin which has the most intersections and use those m and b values to determine the line of best fit.", "So that\u2019s it! I hope you enjoyed that deep dive into the math behind Hough Transform. Now, let\u2019s get back to coding!", "Now this section about averaging out the lines is made to optimize the algorithm. If we don\u2019t average out the lines, they appear very choppy, since the cv2.HoughLinesP outputs a bunch of mini line segments instead of one big line.", "To average the lines, we\u2019re going to define a function called \u201caverage\u201d.", "This function averages out the lines made in the cv2.HoughLinesP function. It will find the average slope and y-intercept of the line segments on the left and the right and output two solid lines instead (one on the left and other on the right).", "In the output of the cv2.HoughLinesP function, each line segment has 2 coordinates: one denotes the start of the line and the other marks the end of the line. Using these coordinates, we\u2019re going to calculate the slopes and y-intercepts of each line segment.", "Then, we\u2019re going to collect all the slopes of the line segments and classify each line segment into either the list corresponding with the left line or the right line (negative slope = left line, positive slope = right line).", "NOTE: Normally, a positive slope=left line and a negative slope=right line but in our case, the image\u2019s y-axis is inversed, hence the reason why the slopes are inversed (all images in OpenCV have inversed y-axes).", "Next, we have to take the average of the slopes and y-intercepts from both lists.", "Note: Do not place this code inside the for loop.", "Now that we have the average slope and y-intercept for both lists, let\u2019s define the start and endpoints for both lists.", "This function takes 2 parameters, the image with the lane lines and the list with the average slope and y_int of the line, and outputs the starting and ending points for each line.", "Just to elaborate a bit further, in line 1, we use the y1 value as the height of the image. This is because in OpenCV, the y-axis is inverted, so the 0 is at the top and the height of the image is at the origin (refer to the image below).", "Also, in Line 2, we multiplied y1 by 3/5. This is because we want the line to start at the origin (y1) and end 2/5 up the image (it's 2/5 since the y-axis is invested, instead of 3/5 up from 0, we see 2/5 down from the max height).", "However, this function does not display the lines, it only calculates the points necessary to display these lines. Next, we\u2019re going to create a function which takes these points and makes lines out of them.", "This function takes in two parameters: the image which we want to display the lines on and the lane lines which were outputted from the average function.", "You may be wondering, why don\u2019t we append the lines onto the real image instead of a black image. Well, the raw image is a little too bright, so it would be nice if we\u2019d darken it a bit to see the lane lines a little more clearly (yes, I know, it's not that big of a deal, but it's always nice to find ways to make the algorithm better)", "So all we have to do is call the cv2.addWeighted function.", "This function gives a weight of 0.8 to each pixel in the actual image, making them slightly darker (each pixel is multiplied by 0.8). Likewise, we give a weight of 1 to the blacked-out image with all the lane lines, so all the pixels in that keep the same intensity, making it stand out.", "We\u2019re almost at the end of the road (*pun intended). All we have to do is call these functions, so let\u2019s do that right now:", "Here, we simply call all the functions that we previously defined, then we output the result on lines 12. The cv2.waitKey function is used to tell the program how long to display the image for. We passed \u201c0\u201d into the function, meaning it will wait until a key is pressed to close the output window.", "Here\u2019s what the output looks like", "We can also apply this same algorithm to a video.", "This code applies the algorithm that we created for images into a video. Remember, a video is just a bunch of pictures that appear one after another really quickly.", "Alright, you just built an algorithm that can detect lane lines! I hope you enjoyed building this algorithm, but don\u2019t stop here, this is just an intro project into the world of computer vision. Nevertheless, you can brag about building this to your friends :)", "If you\u2019re curious, here are the key terms that relate to this algorithm which you can research more in-depth.", "So where to go after this? There are many things to explore in the world of computer vision. Here are some choices:", "Thanks for reading my article, I really hope you enjoyed it and got some value out of it. I am a 16-year-old computer vision and autonomous vehicles enthusiast who loves building all sorts of machine learning and deep learning projects. If you have any questions, concerns, requests for tutorials, or just want to say hi, you can contact me on Linkedin or Email me.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A big AI and car guy. I write on transportation, urban development, deep learning and that sorta stuff."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8f90fdd1322f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nushainef.medium.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": ""}, {"url": "https://nushainef.medium.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Nushaine Ferdinand"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8e2e74cff09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&user=Nushaine+Ferdinand&userId=8e2e74cff09f&source=post_page-8e2e74cff09f----8f90fdd1322f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://i.ytimg.com/vi/EZcHGsPX55Y/maxresdefault.jpg", "anchor_text": "here"}, {"url": "https://docs.anaconda.com/anaconda/install/", "anchor_text": "Installation - Anaconda documentationReview the system requirements listed below before installing Anaconda Individual Edition. If you don't want the\u2026docs.anaconda.com"}, {"url": "https://github.com/Nushaine/lane-detection/blob/master/Untitled33.ipynb", "anchor_text": "Github repo"}, {"url": "https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/924/2015/09/25200328/CNX_CAT_Figure_02_02_007.jpg", "anchor_text": "source"}, {"url": "https://www.researchgate.net/profile/Prabal_Patra/publication/335738299/figure/fig1/AS:801797773996033@1568174894886/A-line-in-cartesian-plane-is-represented-as-a-point-in-Hough-Space-or-space.png", "anchor_text": "source"}, {"url": "https://www.youtube.com/watch?v=VsN6UuBVmYY", "anchor_text": "here"}, {"url": "https://miro.medium.com/max/2022/0*VPVsLApWiEayRGdQ.jpg", "anchor_text": "source"}, {"url": "https://www.youtube.com/watch?v=eLTLtUVuuy4", "anchor_text": "youtube"}, {"url": "https://medium.com/@kael.lascelle/lane-detection-how-cars-see-the-world-8ff3de8ddcc0", "anchor_text": "article"}, {"url": "https://madewithml.com/topics/", "anchor_text": "here's"}, {"url": "https://towardsdatascience.com/a-simple-guide-to-convolutional-neural-networks-751789e7bd88", "anchor_text": "theory"}, {"url": "https://towardsdatascience.com/building-a-road-sign-classifier-in-keras-764df99fdd6a", "anchor_text": "code"}, {"url": "https://www.linkedin.com/in/nushaine-ferdinand-a2ba12177/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----8f90fdd1322f---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/self-driving-cars?source=post_page-----8f90fdd1322f---------------self_driving_cars-----------------", "anchor_text": "Self Driving Cars"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8f90fdd1322f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8f90fdd1322f---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/python-programming?source=post_page-----8f90fdd1322f---------------python_programming-----------------", "anchor_text": "Python Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&user=Nushaine+Ferdinand&userId=8e2e74cff09f&source=-----8f90fdd1322f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&user=Nushaine+Ferdinand&userId=8e2e74cff09f&source=-----8f90fdd1322f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8f90fdd1322f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8f90fdd1322f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8f90fdd1322f--------------------------------", "anchor_text": ""}, {"url": "https://nushainef.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nushainef.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nushaine Ferdinand"}, {"url": "https://nushainef.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "92 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8e2e74cff09f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&user=Nushaine+Ferdinand&userId=8e2e74cff09f&source=post_page-8e2e74cff09f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbf65bb0a55a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f&newsletterV3=8e2e74cff09f&newsletterV3Id=bf65bb0a55a2&user=Nushaine+Ferdinand&userId=8e2e74cff09f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}