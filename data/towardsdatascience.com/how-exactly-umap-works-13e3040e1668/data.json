{"url": "https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668", "time": 1683000703.114262, "path": "towardsdatascience.com/how-exactly-umap-works-13e3040e1668/", "webpage": {"metadata": {"title": "How Exactly UMAP Works. And why exactly it is better than tSNE | by Nikolay Oskolkov | Towards Data Science", "h1": "How Exactly UMAP Works", "description": "This is the twelfth post in the column Mathematical Statistics and Machine Learning for Life Sciences where I try to cover analytical techniques common for Bioinformatics, Biomedicine, Genetics etc\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences?source=post_page---------------------------", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences", "paragraph_index": 0}, {"url": "https://umap-learn.readthedocs.io/en/latest/", "anchor_text": "UMAP", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Single_cell_sequencing", "anchor_text": "Single Cell Genomics", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/how-to-program-umap-from-scratch-e6eff67f55fe", "anchor_text": "how to program UMAP from scratch in Python", "paragraph_index": 0}, {"url": "http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf", "anchor_text": "van der Maaten & Hinton paper from 2008", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "original UMAP paper", "paragraph_index": 6}, {"url": "https://umap-learn.readthedocs.io/en/latest/how_umap_works.html", "anchor_text": "UMAP docs", "paragraph_index": 6}, {"url": "https://www.youtube.com/watch?v=nq6iPZVUxZU&t=765s", "anchor_text": "McInnes talk", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "UMAP paper", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Heaviside_step_function", "anchor_text": "Heaviside step function", "paragraph_index": 13}, {"url": "https://www.nature.com/articles/s41467-018-07582-3", "anchor_text": "Cancer Associated Fibroblasts (CAFs)", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Multidimensional_scaling", "anchor_text": "Multi-Dimensional Scaling (MDS)", "paragraph_index": 20}, {"url": "https://lvdmaaten.github.io/tsne/#faq", "anchor_text": "perplexity values between 5 and 50", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868", "anchor_text": "the square root law \u2248N^(1/2", "paragraph_index": 20}, {"url": "https://medium.com/u/8570b484f56c?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Nikolay Oskolkov", "paragraph_index": 37}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186?source=post_page---------------------------", "anchor_text": "Linkedin", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/how-to-program-umap-from-scratch-e6eff67f55fe", "anchor_text": "how to program UMAP from scratch", "paragraph_index": 37}], "all_paragraphs": ["This is the twelfth post in the column Mathematical Statistics and Machine Learning for Life Sciences where I try to cover analytical techniques common for Bioinformatics, Biomedicine, Genetics etc. Today we are going to dive into an exciting dimension reduction technique called UMAP that dominates the Single Cell Genomics nowadays. Here, I will try to question the myth about UMAP as a too mathematical method, and explain it using simple language. In the next post, I will show how to program UMAP from scratch in Python, and (bonus!) how to create a dimension reduction technique that provides a better visualization than UMAP. However, now we are going to start slowly with intuition behind UMAP and emphasize key differences between tSNE and UMAP.", "If you do not know what tSNE is, how it works, and did not read the original revolutionary van der Maaten & Hinton paper from 2008, you probably do not need to know because tSNE is basically dead by now. Despite tSNE made a dramatic impact for the Single Cell Genomics and Data Science in general, it is widely recognized to have a few disadvantages which have to be fixed sooner or later.", "What is it exactly that makes us uncomfortable using tSNE for Single Cell genomics? Here I summarize a few points with short comments:", "tSNE is a relatively simple Machine Learning algorithm which can be covered by the following four equations:", "Eq. (1) defines the Gaussian probability of observing distances between any two points in the high-dimensional space, which satisfy the symmetry rule. Eq.(2) introduces the concept of Perplexity as a constraint that determines optimal \u03c3 for each sample. Eq.(3) declares the Student t-distribution for the distances between the pairs of points in the low-dimensional embedding. The heavy tails of the Student t-distribution are here to overcome the Crowding Problem when embedding into low dimensions. Eq. (4) gives the Kullback-Leibler divergence loss function to project the high-dimensional probability onto the low-dimensional probability, and the analytical form of the gradient to be used in the Gradient Descent optimization.", "Just looking at the figure above I would say that the heavy tails of the Student t-distribution are supposed to provide the global distance information as they push the points far apart in the high dimensions to be even further apart in the low dimensions. However, this good intention is killed by the choice of the cost function (KL-divergence), we will see later why.", "My first impression when I heard about UMAP was that this was a completely novel and interesting dimension reduction technique which is based on solid mathematical principles and hence very different from tSNE which is a pure Machine Learning semi-empirical algorithm. My colleagues from Biology told me that the original UMAP paper was \u201ctoo mathematical\u201d, and looking at the Section 2 of the paper I was very happy to see strict and accurate mathematics finally coming to Life and Data Science. However, reading the UMAP docs and watching Leland McInnes talk at SciPy 2018, I got puzzled and felt like UMAP was another neighbor graph technique which is so similar to tSNE that I was struggling to understand how exactly UMAP is different from tSNE.", "From the UMAP paper, the differences between UMAP and tSNE are not very visible even though Leland McInnes tries to summarize them in the Appendix C. I would rather say, I do see small differences but it is not immediately clear why they bring such dramatic effects at the output. Here I will first summarize what I noticed is different between UMAP and tSNE and then try to explain why these differences are important and figure out how large their effects are.", "Here \u03c1 is an important parameter that represents the distance from each i-th data point to its first nearest neighbor. This ensures the local connectivity of the manifold. In other words, this gives a locally adaptive exponential kernel for each data point, so the distance metric varies from point to point.", "The \u03c1 parameter is the only bridge between Sections 2 and 3 in the UMAP paper. Otherwise, I do not see what the fuzzy simplicial set construction, i.e. the fancy topological data analysis from the Section 2, has to do with the algorithmic implementation of UMAP from the Section 3, as it seems at the end of the day the fuzzy simplicial sets lead to just nearest neighbor graph construction.", "The symmterization is necessary since after UMAP glues together points with locally varying metrics (via the parameter \u03c1), it can happen that the weight of the graph between A and B nodes is not equal to the weight between B and A nodes. Why exactly UMAP uses this kind of symmetrization instead of the one used by tSNE is not clear. My experimentation with different symmetrization rules which I will show in the next post (programming UMAP from scratch) did not convince me that this was such an important step as it had a minor effect on the final low-dimensional embeddings.", "where a\u22481.93 and b\u22480.79 for default UMAP hyperparameters (in fact, for min_dist = 0.001). In practice, UMAP finds a and b from non-linear least-square fitting to the piecewise function with the min_dist hyperparameter:", "To understand better how the family of curves 1 / (1+a*y^(2b)) behaves let us plot a few of the curves for different a and b:", "We can see that the family of curves is very sensitive to the parameter b, at large b it forms a sort of plateau at small Y. This implies that below the UMAP hyperparameter min_dist all data points are equally tightly connected. Since the Q(Y) function behaves almost like a Heaviside step function it means that UMAP assigns almost the same low-dimensional coordinate for all points that are close to each other in the low-dimensional space. The min_dist is exactly what leads to the super-tightly packed clusters often observed in the UMAP dimensionality reduction plots.", "To demonstrate how exactly the a and b parameters are found, let us display a simple piecewise function (where the plateau part is defined via the min_dist parameter) and fit it using the family of functions 1 / (1+a*y^(2b)) by means of optimize.curve_fit from Scipy Python library. As a result of the fit, we obtain the optimal a and b parameters for the function 1 / (1+a*y^(2b)).", "In the next section we will show that this additional (second) term in the CE cost function makes UMAP capable of capturing the global data structure in contrast to tSNE that can only model the local structure at moderate perplexity values. Since we need to know the gradient of the cross-entropy in order to implement later the Gradient Descent, let us quickly calculate it. Ignoring the constant terms containing only p(X), we can rewrite the cross-entropy and differentiate it as follows:", "Graph Laplacian, Spectral Clustering, Laplacian Eigenmaps, Diffusion Maps, Spectral Embedding, etc. refer to practically the same interesting methodology that combines Matrix Factorization and Neighbor Graph approaches to the dimension reduction problem. In this methodology, we start with constructing a graph (or knn-graph) and formalize it with matrix algebra (adjacency and degree matrices) via constructing the Laplacian matrix, finally we factor the Laplacian matrix, i.e. solving the eigen-value-decomposition problem.", "We can use the scikit-learn Python library and easily display the initial low-dimensional coordinates using the SpectralEmbedding function on a demo data set which is the Cancer Associated Fibroblasts (CAFs) scRNAseq data:", "Now let us briefly discuss why exactly they say that tSNE preserves only local structure of the data. Locality of tSNE can be understood from different points of view. First, we have the \u03c3 parameter in the Eq. (1) that sets how locally the data points \u201cfeel\u201d each other. Since the probability of the pairwise Euclidean distances decays exponentially, at small values of \u03c3, it is basically zero for distant points (large X) and grows very fast only for the nearest neighbors (small X). In contrast, at large \u03c3, the probabilities for distant and close points become comparable and in the limit \u03c3\u2192\u221e, the probability becomes equal to 1 for all distances between any pair of points, i.e. points become equidistant.", "Interestingly, if we expand the probability of pairwise Euclidean distances in high dimensions into Taylor series at \u03c3\u2192\u221e, we will get the power law in the second approximation:", "The power law with respect to the pairwise Euclidean distances resembles the cost function for the Multi-Dimensional Scaling (MDS) which is known to preserve global distances by trying to preserve distances between each pair of points regardless of whether they are far apart or close to each other. One can interpret this as at large \u03c3 tSNE does account for long-range interactions between the data points, so it is not entirely correct to say that tSNE can handle only local distances. However, we typically restrict ourselves by finite values of perplexity, Laurens van der Maaten recommends perplexity values between 5 and 50, although perhaps a good compromise between local and global information would be to select perplexity approximately following the square root law \u2248N^(1/2), where N is the sample size. In the opposite limit, \u03c3 \u2192 0, we end up with the extreme \u201clocality\u201d in the behaviour of the high-dimensional probability which resembles the Dirac delta-function behavior.", "Another way to understand the \u201clocality\u201d of tSNE is to think about the KL-divergence function. Let us try to plot it assuming X is a distance between points in high-dimensional space and Y is a low-dimensional distance:", "From the definition of the KL-divergence, Eq. (4):", "The first term in Eq. (9) is close to zero for both large and small X. It goes to zero for small X since the exponent becomes close to 1 and log(1)=0. For large X this term still goes to zero because the exponential pre-factor goes faster to zero than the logarithm goes to \u2212\u221e. Therefore, for intuitive understanding of the KL-divergence it is enough to to consider only the second term:", "This is a weird looking function, let us plot KL(X, Y):", "The function has a very asymmetric shape. If the distance between the points in high dimensions X is small, the exponential pre-factor becomes 1 and the logarithmic term behaves as log(1+Y^2) meaning that if the distance in low dimensions Y is large, there will be a large penalty, therefore tSNE tries to reduce Y at small X in order to reduce the penalty. In contrast, for large distances X in high dimensions, Y can be basically any value from 0 to \u221e since the exponential term goes to zero and always wins over the logarithmic term. Therefore it might happen that points far apart in high dimensions end up close to each other in low dimensions. Hence, in other words, tSNE does not guarantee that points far apart in high dimensions will be preserved to be far apart in low dimensions. However, it does guarantee that points close to each other in high dimensions will remain close to each other in low dimensions. So tSNE is not really good at projecting large distances into low dimensions, so it preserves only the local data structure provided that \u03c3 does not go to \u221e.", "In contrast to tSNE, UMAP uses Cross-Entropy (CE) as a cost function instead of the KL-divergence:", "This leads to huge changes in the local-global structure preservation balance. At small values of X we get the same limit as for tSNE since the second term disappears because of the pre-factor and the fact that log-function is slower than polynomial function:", "Therefore the Y coordinates are forced to be very small, i.e. Y \u2192 0, in order to minimize the penalty. This is exactly like the tSNE behaves. However, in the opposite limit of large X, i.e. X\u2192\u221e, the first term disappears, pre-factor of the second term becomes 1 and we obtain:", "Here if Y is small, we get a high penalty because of the Y in the denominator of the logarithm, therefore Y is encouraged to be large so that the ratio under logarithm becomes 1 and we get zero penalty. Therefore we get Y \u2192 \u221e at X \u2192 \u221e, so the global distances are preserved when moving from high- to low-dimensional space, exactly what we want. To demonstrate this, let us plot the UMAP CE cost function:", "Here, we can see that the \u201cright\u201d part of the plot looks fairly similar to the KL-divergence surface above. This means that at low X we still want to have low Y in order to reduce the penalty. However, at large X, the Y distance really wants to be large too, because if it is small, the CE (X, Y) penalty will be enormous. Remember, previously, for KL (X, Y) surface, we did not have any difference in penalty between low and high Y at large X. That is why CE (X, Y) cost function is capable of preserving global distances as well as local distances.", "We know that UMAP is faster than tSNE when it concerns a) large number of data points, b) number of embedding dimensions greater than 2 or 3, c) large number of ambient dimensions in the data set. Here, let us try to understand how superiority of UMAP over tSNE comes from the math and the algorithmic implementation.", "Both tSNE and UMAP essentially consist of two steps.", "However, I noticed that the fist step became much faster for UMAP than it was for tSNE. This is because of two reasons.", "Since algorithmically the log-function is computed through the Taylor series expansion, and practically putting a log-prefactor in front of the linear term does not add much since log-function is slower than the linear function, it is nice to skip this step entirely.", "Next, UMAP actually becomes faster on the second step as well. This improvement has also a few reasons:", "In this post, we have learnt that despite tSNE served the Single Cell research area for years, it has too many disadvantages such as speed and the lack of global distance preservation. UMAP overall follows the philosophy of tSNE, but introduces a number of improvements such as another cost function and the absence of normalization of high- and low-dimensional probabilities.", "In the comments below let me know which analyses in Life Sciences seem especially mysterious to you and I will try to address them in this column. Follow me at Medium Nikolay Oskolkov, in Twitter @NikolayOskolkov and connect in Linkedin. Next time we will cover how to program UMAP from scratch, stay tuned.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F13e3040e1668&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c----13e3040e1668---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences"}, {"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences?source=post_page---------------------------", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences"}, {"url": "https://umap-learn.readthedocs.io/en/latest/", "anchor_text": "UMAP"}, {"url": "https://en.wikipedia.org/wiki/Single_cell_sequencing", "anchor_text": "Single Cell Genomics"}, {"url": "https://towardsdatascience.com/how-to-program-umap-from-scratch-e6eff67f55fe", "anchor_text": "how to program UMAP from scratch in Python"}, {"url": "http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf", "anchor_text": "van der Maaten & Hinton paper from 2008"}, {"url": "https://www.nature.com/articles/s41592-018-0308-4", "anchor_text": "FItSNE"}, {"url": "https://towardsdatascience.com/deep-learning-for-single-cell-biology-935d45064438", "anchor_text": "banchmarking for 10X Genomics Mouse Brain 1.3M data set"}, {"url": "https://www.nature.com/articles/s41592-018-0308-4", "anchor_text": "FItSNE"}, {"url": "https://www.nature.com/articles/s41592-018-0308-4", "anchor_text": "FItSNE"}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "original UMAP paper"}, {"url": "https://umap-learn.readthedocs.io/en/latest/how_umap_works.html", "anchor_text": "UMAP docs"}, {"url": "https://www.youtube.com/watch?v=nq6iPZVUxZU&t=765s", "anchor_text": "McInnes talk"}, {"url": "https://arxiv.org/abs/1802.03426", "anchor_text": "UMAP paper"}, {"url": "https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo", "anchor_text": "Markov Chain Monte Carlo (MCMC)"}, {"url": "https://en.wikipedia.org/wiki/Bayes%27_theorem", "anchor_text": "Bayes rule"}, {"url": "https://en.wikipedia.org/wiki/Heaviside_step_function", "anchor_text": "Heaviside step function"}, {"url": "https://jlmelville.github.io/smallvis/init.html", "anchor_text": "the case for tSNE"}, {"url": "https://arxiv.org/pdf/1706.02582.pdf", "anchor_text": "hypothesis of Linderman and Steinerberger"}, {"url": "https://www.nature.com/articles/s41467-018-07582-3", "anchor_text": "Cancer Associated Fibroblasts (CAFs)"}, {"url": "https://en.wikipedia.org/wiki/Multidimensional_scaling", "anchor_text": "Multi-Dimensional Scaling (MDS)"}, {"url": "https://lvdmaaten.github.io/tsne/#faq", "anchor_text": "perplexity values between 5 and 50"}, {"url": "https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868", "anchor_text": "the square root law \u2248N^(1/2"}, {"url": "https://github.com/DmitryUlyanov/Multicore-TSNE", "anchor_text": "can not be multi-threaded"}, {"url": "https://medium.com/u/8570b484f56c?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186?source=post_page---------------------------", "anchor_text": "Linkedin"}, {"url": "https://towardsdatascience.com/how-to-program-umap-from-scratch-e6eff67f55fe", "anchor_text": "how to program UMAP from scratch"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----13e3040e1668---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----13e3040e1668---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----13e3040e1668---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/bioinformatics?source=post_page-----13e3040e1668---------------bioinformatics-----------------", "anchor_text": "Bioinformatics"}, {"url": "https://medium.com/tag/stats-ml-life-sciences?source=post_page-----13e3040e1668---------------stats_ml_life_sciences-----------------", "anchor_text": "Stats Ml Life Sciences"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----13e3040e1668---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----13e3040e1668---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F13e3040e1668&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----13e3040e1668---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----13e3040e1668--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----13e3040e1668--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----13e3040e1668--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----13e3040e1668--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----13e3040e1668--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://nikolay-oskolkov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff4a74ad409c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-exactly-umap-works-13e3040e1668&newsletterV3=8570b484f56c&newsletterV3Id=f4a74ad409c6&user=Nikolay+Oskolkov&userId=8570b484f56c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}