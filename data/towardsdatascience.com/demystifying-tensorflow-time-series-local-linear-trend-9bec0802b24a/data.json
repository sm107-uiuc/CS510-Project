{"url": "https://towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a", "time": 1682996777.362452, "path": "towardsdatascience.com/demystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a/", "webpage": {"metadata": {"title": "Demystifying Tensorflow Time Series: Local Linear Trend | by Wei Yi | Towards Data Science", "h1": "Demystifying Tensorflow Time Series: Local Linear Trend", "description": "This article introduces the Tensorflow time series library. It explains how to use Kalman filter and variational inference for parameter learning. It can serve as a tutorial for these techniques."}, "outgoing_paragraph_urls": [{"url": "https://facebook.github.io/prophet/", "anchor_text": "Prophet", "paragraph_index": 0}, {"url": "https://aws.amazon.com/blogs/opensource/gluon-time-series-open-source-time-series-modeling-toolkit/", "anchor_text": "Gluon Time Series", "paragraph_index": 0}, {"url": "https://azure.microsoft.com/en-gb/services/time-series-insights/", "anchor_text": "Time Series Insights", "paragraph_index": 0}, {"url": "https://medium.com/tensorflow/structural-time-series-modeling-in-tensorflow-probability-344edac24083", "anchor_text": "Tensorflow time series", "paragraph_index": 0}, {"url": "https://medium.com/tensorflow/structural-time-series-modeling-in-tensorflow-probability-344edac24083", "anchor_text": "Tensorflow time series library", "paragraph_index": 1}, {"url": "https://gist.github.com/jasonweiyi/f88b8d61fc72785b84d248bd6fa86a47", "anchor_text": "this code", "paragraph_index": 12}, {"url": "https://pixabay.com/photos/lake-mcdonald-landscape-mountains-1056561/", "anchor_text": "Pixabay", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Log-normal_distribution", "anchor_text": "LogNormal", "paragraph_index": 38}, {"url": "https://en.wikipedia.org/wiki/Lambda_calculus", "anchor_text": "lambda calculus", "paragraph_index": 41}, {"url": "https://en.wikipedia.org/wiki/Chain_rule_(probability)", "anchor_text": "product rule", "paragraph_index": 45}, {"url": "https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804", "anchor_text": "Gaussian Process", "paragraph_index": 58}, {"url": "https://towardsdatascience.com/where-do-confidence-interval-in-linear-regression-come-from-the-case-of-least-square-formulation-78f3d3ac7117", "anchor_text": "least squares linear regression", "paragraph_index": 58}, {"url": "https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf", "anchor_text": "joint probability density for multivariate Gaussian", "paragraph_index": 68}, {"url": "https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf", "anchor_text": "the rule of conditional for multivariate Gaussian", "paragraph_index": 76}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "mean-field variational family", "paragraph_index": 98}, {"url": "https://www.cl.cam.ac.uk/teaching/2003/Probability/prob11.pdf", "anchor_text": "probability density transformation", "paragraph_index": 115}, {"url": "https://en.wikipedia.org/wiki/Change_of_variables", "anchor_text": "replacing variables with functions of other variables", "paragraph_index": 123}, {"url": "https://en.wikipedia.org/wiki/Integration_by_substitution", "anchor_text": "integration by substitution", "paragraph_index": 126}, {"url": "https://gist.github.com/jasonweiyi/c5b9b2aaca3aef4279691d480db7a42a", "anchor_text": "this code", "paragraph_index": 131}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback\u2013Leibler divergence", "paragraph_index": 136}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "theory of variational inference", "paragraph_index": 142}, {"url": "https://stats.stackexchange.com/questions/335197/why-kl-divergence-is-non-negative", "anchor_text": "KL-divergence is non-negative", "paragraph_index": 145}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent", "paragraph_index": 154}, {"url": "http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/", "anchor_text": "here", "paragraph_index": 168}, {"url": "https://stats.stackexchange.com/questions/110961/sampling-from-a-lognormal-distribution", "anchor_text": "here", "paragraph_index": 185}, {"url": "https://towardsdatascience.com/variational-gaussian-process-what-to-do-when-things-are-not-gaussian-41197039f3d4", "anchor_text": "Variational Gaussian Process", "paragraph_index": 189}, {"url": "https://towardsdatascience.com/understanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756", "anchor_text": "human face generation", "paragraph_index": 189}, {"url": "https://gist.github.com/jasonweiyi/43d23da4b8c65a9a6a6aaddd883b5a52", "anchor_text": "Here", "paragraph_index": 216}, {"url": "https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand.ipynb", "anchor_text": "Tensorflow time series examples", "paragraph_index": 216}, {"url": "https://jasonweiyi.medium.com/membership", "anchor_text": "https://jasonweiyi.medium.com/membership", "paragraph_index": 221}, {"url": "https://www.linkedin.com/in/vincent-adam-5a195810/", "anchor_text": "Vincent Adam", "paragraph_index": 223}, {"url": "https://www.linkedin.com/in/lucas-bordeaux-7704b42/", "anchor_text": "Lucas Bordeaux", "paragraph_index": 223}, {"url": "https://www.linkedin.com/in/michaeldavidpedersen/", "anchor_text": "Michael Pedersen", "paragraph_index": 223}, {"url": "https://www.linkedin.com/in/elvijs-sarkans-69087a5b/", "anchor_text": "Elvijs Sarkans", "paragraph_index": 223}, {"url": "https://sites.google.com/site/nicolasdurrandehomepage/", "anchor_text": "Nicolas Durrande", "paragraph_index": 223}, {"url": "https://www.linkedin.com/in/seleftheriadis/", "anchor_text": "Stefanos Eleftheriadis", "paragraph_index": 223}, {"url": "https://10creative.co.uk/about10", "anchor_text": "Joshua Jones", "paragraph_index": 223}, {"url": "https://10creative.co.uk/", "anchor_text": "10Creatives", "paragraph_index": 223}, {"url": "http://cs229.stanford.edu/section/gaussians.pdf", "anchor_text": "the multivariate Gaussian probability density function", "paragraph_index": 250}], "all_paragraphs": ["In the past couple of years, big companies hurried to publish their machine learning based time series libraries. For example, Facebook released Prophet, Amazon released Gluon Time Series, Microsoft released Time Series Insights and Google released Tensorflow time series. This popularity shows that machine learning based time series prediction is in high demand.", "This article introduces the recently released Tensorflow time series library from Google. This library uses probabilistic models to describe time series. In my 7 years\u2019 experience in algorithmic trading, I\u2019ve established the habit of analysing the inner workings of time series libraries. So I digged into the source code of this library to understand the Tensorflow team\u2019s take on time series modelling.", "This turns out to be a fascinating journey. The Tensorflow library models time series as a linear dynamical system with parameters. To learn the model parameters, it uses the Kalman filter algorithm and variational inference.", "This article will explain why and how we use these techniques, and how they work together. To read this article, you don\u2019t need to know dynamical linear systems, Kalman filter or variational inference. I will introduce them as we go along. And I will show you that these techniques naturally occur to enable us to learn the model parameters.", "This article is about time series, so there will be subscripts. I use underscore \u201c_\u201d to lead a subscript. For example, when I write Y_1, Y_t, Y_t-1, Y_T+1, I mean:", "When I write Y_1:t, I mean the sequence of terms (you can understand it as an array of terms):", "If some math notations render as question marks on your phone, please try to read this article from a computer. This is a known issue with some Unicode rendering.", "Local linear trend is the most basic model in Tensorflow time series. It has the following definition:", "In the above three equations, for every time step t, slope_t, level_t, y_t are random variables. \u03b5_1, \u03b5_2 and \u03b5_3 are also random variables. Note that slope_t, level_t and y_t depend on quantities, such as slope_t-1, at the previous time step t-1. But the distribution of noises \u03b5_1, \u03b5_2 and \u03b5_3 do not depend on time.", "We have observations Y_1, Y_2 up to and including Y_T, or more concisely, Y_1:T. To model how the observations are generated by these equations, we use the following generative thinking:", "Note the independent Gaussian noises \u03b5_1, \u03b5_2 and \u03b5_3 have zero mean and standard deviation \u03c3_level, \u03c3_slope and \u03c3_obs. Since these three quantities model standard deviations, they can only take positive real values, denoted by \u211d\u207a. They are the parameters of this model. We don\u2019t know their values; we need to learn them from observations.", "You may ask, what kind of time series can a local linear trend model? You can understand that level_t = level_t-1 + \u03b5_2 represents some trend level. This trend level can change with a stationary rate, governed by \u03b5_2. With the slope_t component, that trend level can change with a different rate over time. Intuitively, the slope_t variable decides how much a new observation can change from the current level_t. I think that\u2019s why Tensorflow people call it slope, taking the analogy from the equation for a straight line y=ax+b. In the line equation, a is called slope and it decides how much y can change in a single step \u0394x.", "To get a concrete feeling of this model, I wrote this code to sample time series from it. The following figure shows 30 time series samples. I generated these curves by setting the standard deviations of all three noises to 1. You can see some curves have clear up or down trend, while others have trends that change directions.", "If I change the standard deviation of \u03b5_1 to 0, effectively disabling the slope_t variable, we get something quite different:", "As you can see, using different values for the model parameters allows you to model different time series.", "Now the question is, if I have a time series, say this one:", "This curve is the skyline of the mountains in the featured image (adapted from Pixabay by illustrator Joshua Jones). It is not your typical \u201ctime series\u201d. But I want to have some fun to see how a local linear trend model tracks skyline from mountain to mountain.", "What values should I pick for the three standard deviations to model this skyline time series? Luckily we don\u2019t need to hand pick those values. We will apply machine learning to figure out their optimal values. Using Tensorflow time series API, you will write code like Listing 1 below:", "In Listing 1, line 9~11 defines a local linear trend model for the skyline training data. Line 13~23 finds the optimal values for model parameters. Line 25~38 predicts future values using the optimised model.", "The snippet above reads fine and the API is intuitive. But you may wonder how it works, and what is the math underlying these lines. Me too. And here is what I found.", "Matrix form of local linear trendLet\u2019s first rewrite the above equations in matrix form to simplify the notation:", "w_t is a 2 dimensional multivariate Gaussian variable. One component dimension is for \u03b5_1 and the other for \u03b5_2. This multivariate Gaussian has 0 mean. Its covariance matrix is diagonal with the variance of \u03b5_1 and \u03b5_2 at its main diagonal. w_t has 0 mean because the random variables \u03b5_1 and \u03b5_2 have 0 mean. The covariance matrix of w_t is diagonal because \u03b5_1 and \u03b5_2 are independent. Similarly, we can treat v_t as a multivariate Gaussian variable with only one dimension. Again, note that w_t and v_t does not depend on quantities from previous time step t-1, unlike level_t, slope_t and y_t.", "Let\u2019s give names to different matrices:", "Then we arrive at a more compact notation of the same equations:", "These two equations describe how the system evolves over time. We call this system a linear dynamical system. In other words, what Tensorflow people call a local linear trend model is the same as a linear dynamical system. They are synonyms.", "In this system, x_t is called state variable at time step t. y_t is called the observation variable. This system is linear because x_t and y_t depend linearly on x_t-1.", "The above linear system is defined in an inductive way \u2014 it describes how quantities at time step t are generated from quantities at previous time step t-1.", "You may ask, where does the system start (or what is the base case for this inductive definition)? You can assume that the system starts from an arbitrary initial state, say, level_0 = 0, slope_0 = 0. In other words, x_0 = [0, 0], or you can choose x_0 =[3, 5]. It doesn\u2019t matter. Even if your initial choice is quite incorrect, after a few steps, the system state will move away from this wrong initial state and become more consistent with the actual observations. If you don\u2019t see why yet, no worries, we will come back to this important point later.", "Model parametersThe above linear dynamical system has three parameters \u03c3_level, \u03c3_slope and \u03c3_obs. We call them model parameters. Before we can use this model to predict future observations, we need to figure out the values of these model parameters. This is called parameter learning.", "Tensorflow time series treats a local linear trend as a Bayesian model. In a Bayesian setting, parameter learning means to calculate the posterior distribution of the model parameters given observed data. Define Y as the vector of the observations Y_1 to Y_T. Y is a vector of length T. Define z as the vector of model parameters [\u03c3_level, \u03c3_slope, \u03c3_obs]. z is a vector of length 3.", "We use p(z|y) to denote the posterior density function. Inside this formula, z is the vector of our model parameters. Define y as the vector of the observation variables y_1, y_2, \u2026, y_T introduced in the second system equation. y is of length T. Note the usage of upper and lower letters. Upper Y is the vector of actual observations; and lower y is the vector of random observation variables.", "In this article, upper letters, A, H, Y, are for constants, and lower letters, x, y, \u03c3, for variables. Except for \u03a3, which I use to represent covariance of noises, such as \u03a3_w, \u03a3_v.", "The posterior density p(z|y) is calculated by the Bayes rule:", "This formula shows that computing the posterior p(z|y) requires three pieces of information:", "(1) the prior distribution p(z), our assumption of how the model parameters look like prior to seeing any observation.", "(2) the likelihood p(y|z), the probability of the observations if they are generated by our model.", "(3) the marginal likelihood, which is the integral in the denominator. This integral scales the whole right hand side of the equation into a proper probability density function that integrates to 1.", "We need to compute these three pieces. As a preview: (1) is trivial, (2) needs some work and (3) is hard. Let\u2019s do it step by step.", "Computing the prior is is trivial because we are in full control of specifying the prior. In a local linear trend model, we assume the priors for each of the three model parameters comes from a LogNormal distribution. So these model parameters are random variables as well. These LogNormal distributions have fixed arguments to decide the shape of the probability density. We don\u2019t care of this shape. The main reason to use LogNormal is to model standard deviations, which can only take positive values in \u211d\u207a.", "We also assume that three model parameters \u03c3_level, \u03c3_slope and \u03c3_obs are independent to each other. So the prior p(z) equals the product of the three individual LogNormal probability densities:", "where LN(\u03c3_level; \u00b7) stands for the LogNormal probability density function with some fixed arguments. In the notation LN(\u03c3_level; \u00b7), LN is the name of the probability density function, here is LogNormal. Inside the parenthesis, before the semicolon, \u03c3_level denotes that this probability density is for the random variable \u03c3_level. After the semicolon, we put the parameters of the density function. A LogNormal density has two parameters. Here we use a dot \u201c\u00b7\u201d to mean that we don\u2019t care about the values of those fixed parameters.", "One thing you will notice is the last blue line and its strange explanation \u201cAPI\u201d. This is a notation to explicitly show the arguments of a function. \u03bbz.p(z) means that p(z) is a function (a probability density function in our case), and this function takes a single argument z. People from programming languages background will immediately see this notation is \u03bb-expression from lambda calculus. \u03bb is a symbol in this calculus to define a function. The dot equal \u201c\u2250\u201d symbol reads \u201chas the API of\u201d.", "This \u03bb notation makes the arguments of a function explicit. As we will build up more and more functions, bookkeeping function APIs helps us \u201cinterface-check\u201d the math. Please note this bookkeeping does not change the math. If you don\u2019t care about function APIs, you can safely ignore all the blue lines.", "I emphasis that the prior p(z) is our modelling assumption that the model parameters are independent to each other and they each come from a LogNormal distribution. We provide our best guess for them to carry on modelling, but we don\u2019t know if this is true.", "The likelihood is the probability of observing the data y given the model parameters z. We denote the likelihood as follows:", "This formula is a generic template for all probabilistic models. We need to work out the analytical form of p(y|z) for our local linear trend model. Let\u2019s rewrite it into a product form by applying the product rule (also called the chain rule) in probability theory in reverse:", "We can see that all the terms in this product have the same structure. Let\u2019s look at an arbitrary term:", "The notation at the condition of this probability y_1:t-1 means y_1 up to and including y_t-1. Our goal is to write down the analytical formula for this term. If we can do that, we can do the same for all the terms in the likelihood.", "To derive the analytical form of the above expression, we need to use the two equations from the linear dynamical system. Let me show its definition again:", "The system is defined in an inductive way, so let\u2019s use some inductive thinking.", "Let\u2019s look at the first equation. This equation tells us that x_t is a linear transformation from x_t-1 with added Gaussian noise w_t. If x_t-1 is a Gaussian random variable, then a property of Gaussian tells us that linear transformation of a Gaussian variable with added Gaussian noise results in another Gaussian variable.", "So if we assume that the random variable x_t-1|y_1:t-1,z is a Gaussian random variable with mean \u03bc_t-1 and variance \u03a3_t-1, and we know the analytical form for both \u03bc_t-1 and \u03a3_t-1 (we will prove this assumption later):", "then we can conclude that x_t | y_1:t-1, z (please pay attention to the subscript difference: x_t-1 in the assumption, x_t in the conclusion) is also a Gaussian random variable, and the rule of Gaussian linear transformation also tells us the formula for its mean and variance:", "You may ask, why do we need to condition x_t on y_1:t-1,z? This is because what values x_t can take depends on what observations that we saw before time step t and the model parameters. This makes common sense. If the previous observation is 100, it makes sense that the distribution of x_t is around 100 as well. In other words, x_t depends on the random variables y_1:t and z.", "You may ask, how do we know that x_t, where t=1, 2, .., T, is a Gaussian variable to start with? That\u2019s easy: we can assume that the system starts from some fixed initial Gaussian distribution, for example, x_0 ~ N(0, 1). 0 is the zero vector of length 2, since x_t is a 2 dimensional vector. 1 is the identity matrix of size 2x2. Note this is also the base case for our system defined before. Then we know x_1|y_1,z is Gaussian, as well as x_2|y_1:2,z, \u2026, x_t|y_1:t,z.", "You may ask, if x_0 has mean 0, in other words, \u03bc_0=0, and all consequent x_t|y_1:t-1,z has their means being a linear transformation from the previous means, will x_t always have 0 mean \u03bc_t=0? The answer is no, because what values \u03bc_t can take depends on actual observations Y_1:t. We will explain this in detail in the next section, the Kalman filter section.", "Now, let\u2019s move on to the second system equation. Since we\u2019ve shown that x_t|y_1:t-1,z is a Gaussian variable, again by the rule of Gaussian linear transformation, y_t|y_1:t-1,z is also a Gaussian variable. Plug in the mean and variance of x_t|y_1:t-1,z into the transformation formula to get the probability density of y_t|y_1:t-1,z:", "This is the analytical form for an arbitrary term in our likelihood p(y|z). The formula is long, but how it is derived is straightforward, we apply the Gaussian linear transformation rule twice according to the first and second equation of the linear dynamical system.", "This multivariate Gaussian linear transformation rule is very important in machine learning, definite worth your time to remember it. It will pop up in many models, for example, Gaussian Process, and even in least squares linear regression to reason about uncertainty.", "There is one more thing, all the above derivations assume that we know the analytical forms for:", "And now we need to show this assumption is true. Concretely, we need to prove that we can derive the analytical forms for x_t|y_1:t,z for all t from 1 to T. We will perform an inductive proof. Don\u2019t worry, the proof is quite simple.", "We want to assume that we know:", "And prove that we can derive the analytical form of:", "Please pay attention to the subscripts inside the induction hypothesis and the proof obligation to realise we are trying to prove some quantities in the next time step, based on quantities at the previous time step and new observation.", "This proof obligation means that we want to find out the analytical form for \u03bc_t and \u03a3_t. Non-surprisingly, they should be expressions of \u03bc_t-1 and \u03a3_t-1.", "The inductive step: given the induction hypothesis:", "According to the two equations in our linear dynamical system and the rule of Gaussian linear transformation, we can derive:", "I use \u03bc_a, \u03a3_aa, \u03bc_b, \u03a3_bb to name the means and variances to shorten the formula, as the formula will become longer. But don\u2019t worry, the formula will become longer in a no-brainer way \u2014 they become longer because we will plug them into two multivariate Gaussian distribution rules. For the purpose of this article, you can safely accept these rules. Here they are: joint probability density, and conditional probability density for multivariate Gaussian.", "Rule 1: Using the rule of joint probability density for multivariate Gaussian, we can derive the joint probability between x_t and y_t:", "We can apply the joint probability density rule for multivariate Gaussian because both x_t|y_1:t-1 and y_t|y_1:t-1 are multivariate Gaussian variables.", "In the above formula, the names \u03a3_ab, and \u03a3_ba (they are transpose of each other) are covariance between x_t|y_1:t-1,z and y_t|y_1:t-1,z. We can derive the analytical form for them as well. For example:", "In the above derivation, I dropped the conditioned part y_1:t-1 to save space. So please remember that x_t and y_t in the above formulas means x_t|y_1:t-1, y_t|y_1:t-1.", "Line (2) is the definition of covariance between two random variables.", "Line (3) uses the second system equation to replace y_t|y_1:t_1 and its mean.", "Line (4) re-organises terms in the formula and uses the linearity property of expectation to split the expectation from line (3) into two expectations. We can recognise that the first expectation is the definition of the variance of x_t|y_1:t-1.", "Line (7) shows that the expectation of noise v is 0 because v is from a 0 mean Gaussian distribution.", "Rule 2: Since the above joint is a 2-dimensional Gaussian distribution, we can use the rule of conditional for multivariate Gaussian to write down the conditional probability:", "The first line is the conditional probability denotation. The second line shows its analytical form, i.e., the formula for \u03bc_t and \u03a3_t. They are given by the rule of conditional of multivariate Gaussian. The third line re-organises terms in the condition to soothe your eyes.", "So we have proved that we can derive the analytical form for the probability density function for x_t|y_1:t, z.", "Let\u2019s investigate the last formula in the proof, the one for p(x_t|y_1:t, z). This formula tells us some important things.", "First, from the second line of the above formula, we can see that \u03bc_t and \u03a3_t only depend on the random variable y_t and the model parameters z (because the terms, such as, \u03bc_a, \u03a3_ab, are expressions of y_1:t-1 and z). In other words, \u03bc_t and \u03a3_t are functions of y_1:t and z. With this realisation, let\u2019s look at an arbitrary term in the likelihood again:", "This term depends on \u03bc_t-1 and \u03a3_t-1, so transitively, it depends on y_1:t-1 and z. From the API point of view, this term starts as a function with three arguments, y_t, y_1:t-1 and z, shown at line 2. We have actual observations Y_1:t-1. After we plugged in the observations Y_t, and Y_1:t-1 into the first two arguments, the whole term becomes a function that only takes z as its single argument. This is shown at line 3.", "Generalising this to all the terms in p(y|z), we can see that when observations Y are plugged in, the likelihood is a function that takes z as its single argument.", "Second, let\u2019s understand how the mean of the state variable x_t changes over time. Let\u2019s look at the expression for \u03bc_t together with the definition of \u03bc_a and \u03bc_b:", "We can see that \u03bc_a = A\u03bc_t-1 is what the system believes the state should be before seeing the new observation Y_T. The algorithm then uses the new observation Y_T to correct its belief about this quantity, resulting in the new, corrected belief \u03bc_t for the next time step t.", "This explanation about \u03bc_t also addresses a previous question, asking whether \u03bc_t will always be 0 if it starts as 0. The answer is no. And now you can see why. If the actual observations are not 0, the correction formula will quickly force the mean \u03bc_t to move away from 0.", "These proof steps can also been understood as the famous Kalman filter algorithm \u2014 an algorithm that derives the distribution of current system state from previous state and new observation. There are many explanations for the Kalman filter algorithm. I found the above version from a probabilistic point of view to be very intuitive.", "Since Kalman filter is such an important algorithm, let me summarise it: for a linear dynamical system with Gaussian noise:", "Assume we know the distribution of the latent variable x_t-1 at time step t-1. Given a new observation y_t, the Kalman filter algorithm derives the distribution of the latent variable x_t at the next time step t. This process is called filtering. Its steps are:", "Please pay attention to the subscripts in these steps. The change of subscripts indicates how the algorithm starts from the system state x_t-1 and derives the system state x_t. Each step applies a single transformation elegantly.", "Please note that all the five terms in the above algorithm represent probability density functions. The algorithm evolves the probability density for the state variable x as new observation is available. The first three steps tell you what the linear dynamical system believes the next system state and observation should be. The last two steps use the actual observation to update such belief.", "Going back to Listing 1, line 9~11 describes a local linear trend model. This model class has methods that returns the prior distribution and the likelihood probability.", "Phew, we have written down the analytical form of the prior p(z) and likelihood p(y|z). Now we move on to the final piece of the three \u2014 the marginal likelihood.", "The marginal likelihood is the integral of the product of the likelihood and the prior. Since z has been integrated out, the result is a function that takes y as its single argument, shown at the second line. After plugging Y=Y_1:t into y, the whole marginal likelihood becomes a constant number, shown at the third line. The constant is denoted by the \u201c\u03bb.\u201d part without anything after the \u03bb and before the dot \u201c.\u201d.", "Unfortunately, the integration is hard to compute analytically. In our case, p(y|z) is a product of many Gaussian density functions, one for each observation. p(z) is a product of three LogNormal probability density functions, one for each model parameter. I can feel the complexity even by writing down their description.", "Since it is hard to analytically compute the marginal likelihood, and marginal likelihood is a prerequisite for the posterior, we cannot compute the posterior p(z|y) analytically either. We need to approximate the posterior numerically.", "Approximating the posterior distribution means to use a new distribution in place of the posterior. This new distribution should be similar to the real posterior. And it should have simple analytical form. Tensorflow time series uses the variational inference technique to find this new distribution.", "Variational inference approximates the posterior distribution p(z|y) with another distribution q(z), called the variational distribution. Let\u2019s first think about what q(z) should look like.", "What probability density function should we propose for q(z)? Tensorflow time series uses a mean-field variational family for q(z).", "A mean-field family is a restriction on the relationship among the random variables in z \u2014 it assumes that all the variables are independent to each other. The benefit of such restriction is that the joint probability density q(z) equals the product of the individual variable probability densities.", "To fully specify q(z), we also need to choose the probability density for each of the variables in z. For that, Tensorflow time series chooses Gaussian distribution for each random variable in z. In formula:", "where N(\u03c3_level; \u03bc_l, \u03c3_l\u00b2) at line 3 stands for the Gaussian probability density function for the variable \u03c3_level, with mean \u03bc_l and standard deviation \u03c3_l. Likewise for the model parameter \u03c3_slope and \u03c3_obs.", "Line 4 and 5 show that q(z) has its own parameters vp=[\u03bc_l, \u03bc_s, \u03bc_o, \u03c3_l, \u03c3_s, \u03c3_o], a vector of length 6. These are parameters that specify the three independent Gaussian distributions. We call these six parameters variational parameters to distinguish them from the parameters of the local linear trend model, which we introduced before as model parameters.", "Line 5 shows that q(z) takes z and vp as its arguments. q(z; vp), with the semicolon inside, means that a probability density for the variable z. And this density has parameters vp to control its shape. Note that at line 1, q(z) is also a function of both z and vp. This doesn\u2019t change from line 1 to 5. We wrote it as q(z) without mentioning vp explicitly just to highlight that q(z) is a probability density function for the random variables in z.", "Please note the relationship between the model parameter z and the variational parameter vp:", "Going back to Listing 1, line 14 constructs the variational distribution q(z). Since q(z) has a mean-field structure, the qs variable in Python code is a dictionary, with each key-value pair being a model parameter and its corresponding variational distribution.", "Let\u2019s check if this q(z) satisfy our requirements: q(z) has a simple structure and analytical form. Also, q(z) has the same set of variables as p(z|y). However, those variables in q(z) have different domains from the variables in p(z|y).", "Variables in q(z) comes from Gaussian distributions, so they have full real number domain, denoted by \u211d.", "How about the domains of variables from the posterior p(z|y)? The domains of variables from the posterior p(z|y) are the same as their domains in the prior p(z). p(z) is a product of LogNormal density functions, whose domain is positive numbers \u211d\u207a.", "There is a domain mismatch between variables in q(z) and variables in p(z|y). This domain mismatch violates the second requirement above for q(z). To solve this problem, we transform the posterior p(z|y) from a probability density function of variables over the \u211d\u207a domain into another probability density function p(u|y) of variable vector u over the \u211d domain.", "You may ask, we don\u2019t know the analytical form of the posterior p(z|y), how can we perform this transformation? Well, we know the structure of the posterior:", "where m stands for the inverse of the marginal likelihood:", "m is a constant that does not involve z since z has been integrated out. When observations Y are plugged in, the posterior becomes a function that takes z as its single argument. This is because it is the product of a constant and two functions that both takes z as their only argument. The blue line above shows this structure clearly.", "We also know the analytical form for both p(y|z) and p(z), so we can transform their product, and the constant m just scales the transformed result.", "You may also ask, why don\u2019t we transform q(z) to another distribution over the positive real domain \u211d\u207a instead? Because this makes q(z) more complicated by adding constraints to it. We want a simple q(z), that\u2019s the point of variational inference.", "We use the technique of probability density transformation.", "Let\u2019s re-state out current goal. Sometimes during a long process, it is easy to forget what we want to do.", "To recap, we have the posterior p(z|y) = m\u00d7p(y|z)p(z) with variables z over positive \u211d\u207a domain. We want to transform it to another distribution p(u|y) with each variable in u coming from the full \u211d domain. This way, the posterior density and the variational distribution density will have the same domain over their input variables.", "What will u look like? Since the three variables \u03c3_level, \u03c3_slope and \u03c3_obs in z are independent, we can transform them independently. So it makes sense to make u contain three variables [u_level, u_slope, u_obs]. Each variable in u is responsible for the corresponding variable in z.", "What will the probability density p(u|y) look like? Let\u2019s first focus on a single variable pair \u03c3_level \u220a \u211d\u207a and u_level \u220a \u211d. We want to write \u03c3_level as a function of u_level. This function has input domain \u211d and output range \u211d\u207a. Many functions do that, such as:", "The following figure shows the curve of the exponential function in green and the curve of the square function in red. Both functions map a value from \u211d to \u211d\u207a.", "Between the two, we want to choose the exponential function. This is because the exponential function is monotonically increasing. So there is a one-to-one mapping between \u03c3_level and u_level. Later we will need this one-to-one mapping property.", "So we decided to use exponential as the transformation function from variables in u to variables in z:", "This is the textbook case of replacing variables with functions of other variables. Now we need to find out how does this variable replacement change our posterior probability density p(z|y) = m\u00d7p(y|z)p(z). To do that, we look at the definition of probability density function \u2014 \u2014 a function that is non-negative and integrates to 1 over the domain of the variables. So our posterior density actually means:", "The first line is the definition of probability density function. The second line explicitly shows the variables and the integration limits.", "Let\u2019s look at the inner most integration:", "In this integral, we want to replace all occurrences of \u03c3_level with the exponential function exp(u_level). In Calculus, the rule of integration by substitution tells us how to do this:", "Now we work our way out for the triple integrations, and arrive at this formula:", "The formula at the second line is the definition of the transformed probability density function of our posterior. That is, p(u|y) = m p(y|u) p(u) for the set of variable u over the full real domain \u211d.", "From now on, we should use p(y|u)p(u) instead of p(y|z)p(z). However, to make things simpler, let\u2019s redefine our z to u. This means from now on:", "This way, all the above formula stay the same, you just need to remember now things are in the transformed domain.", "The third requirement for q(z) listed above requires that q(z) should be as close to p(z|y) as possible. Graphically, this means the curve of q(z) should overlap with the curve of p(z|y) as much as possible. The following figure demonstrates this interesting idea. I wrote this code to generate the figure.", "The blue curve represents the posterior p(z|y) that we want to compute. Its shape is irregular \u2014 notice the left side is larger than the right side. Of course, we don\u2019t know the shape of p(z|y), I just use an irregular shape to convey the idea that p(z|y) is something complicated.", "The green curve represents our proposed variational distribution q(z). I use a regular shape to indicate that q(z) is structurally simple.", "The shape of q(z) is controlled by the six variational parameters vp. We need to adjust these six values to make the green curve overlaps with the blue curve as much as possible.", "Remember, ultimately we want to know the values of the model parameters z. To do that, we need to determine the shape of the variational distribution q(z) by finding out the values of the variational parameters vp. We are looking for the values for vp such that q(z) overlaps with the posterior p(z|y) as much as possible. Once we have the shape of q(z), we can sample from it to get the actual values for z.", "To quantify the level of overlapping between two probability densities, we use the Kullback\u2013Leibler divergence. The KL-divergence between the probability density q(z) and the probability density p(z|y) is:", "The intuition behind KL-divergence is straightforward. It is a weighted average (weighted by q(z)) of the differences between the two probability density at each point in the domain of z.", "We want to find a particular values for vp such that q(z) minimises the distance to the posterior p(z|y). We can express this minimisation in the following formula:", "The \u201cstar\u201d in q(z; vp)* denotes the optimal value for q(z). This means we want to find values of those six variational parameters so the KL-divergence between q(z) and p(z|y) is the smallest.", "See how variational inference converts an inference problem into an optimisation problem! The original problem of using the Bayes rule to compute the posterior p(z|y) is usually referred to as an inference problem. On the other hand, minimising the KL-divergence between q(z) and p(z|y) is an optimisation problem. The KL-divergence is the optimisation objective.", "It is quite surprising that we can minimise the KL between q(z) and p(z|y) even when we don\u2019t know how to compute p(z|y).", "The secret lies on the theory of variational inference. It tells us that minimising the KL-divergence is equivalent to maximising another formula called Evidence Lower Bound, denoted by ELBO(q(z)). If you are not familiar with why, don\u2019t worry. For now, it is enough to accept that these two optimisation problems are equivalent.", "The intuition behind ELBO is best seen from the second line above. It has two terms: one expectation minus another expectation. And we want to maximise the result of the subtraction.", "The first term is the expectation of the log likelihood. It describes how well our model fit the data. Why? Because to make this term large, our q(z) should give large probability to values of z when p(y|z) is also large. We want this term to be large.", "The second term is the KL-divergence (in case you haven\u2019t realised) between q(z) and the prior p(z). We know that a KL-divergence is non-negative. This term describes how different our proposed q(z) is from our prior assumption p(z). We want the difference to be small because we assume our prior makes sense. So we want the second term to be small.", "ELBO conveys our wish that our optimised model fits the data well, and at the same time it stays close to our model assumption, the prior.", "The fifth and sixth line show we expand ELBO(q(z)), an expectation, to an integration.", "Line 7 shows the function inside the integral starts as a function that takes two arguments z and vp (with observations Y plugged in). This is because it consists of the functions are either function of z or functions of z and vp.", "Line 8 shows that after integrating z out, the ELBO is a function of the variational parameters vp only.", "You may ask, why we need ELBO(q(z)) at all? Why can\u2019t we minimise KL(q(z)||p(z|y)) directly? To answer this question, we need to notice:", "This is why we need the ELBO and how it is possible to minimise the KL-divergence between q(z) and p(z|y) even when we don\u2019t know p(z|y). This fact is quite surprising at first. But it is reasonable. Because the likelihood p(y|z) and the prior p(z) contains all the information needed to calculate the posterior p(z|y).", "You may ask, in the probability density transformation section, we transformed the posterior to a function over \u211d domain, and from then on, we need to use the transformed posterior. But ELBO does not mention the posterior at all. What shall we do? In ELBO, we have p(y, z) = p(y|z)p(z). And the transformed posterior is mp(y|z)p(z) with m being a constant. So we can still plug in the transformed result in ELBO. m is a constant; it won\u2019t change the solution of the optimisation.", "Going back to Listing 1, line 14 constructs the ELBO as the optimisation objective.", "Since we know the analytical form of ELBO(q(z)), we can use gradient descent to maximise ELBO(q(z)) with respect to its parameters vp. Actually, we use gradient descend to minimise -ELBO(q(z)).", "We need to calculate the gradient of ELBO(q(z)) with respect to the variational parameters vp:", "where the \ud835\udefb symbol stands for the vector differential operator. It calculates the gradients of a multi-argument function with respect to its arguments. In our case, \ud835\udefb_vp calculates the gradient of ELBO(q(z)) with respect to the vector of parameters in vp.", "A subtle point. In the above formula, the integration is with respect to the model parameters z=[\u03c3_level, \u03c3_slope, \u03c3_obs]. But the gradient calculation outside of the integration is with respect to the variational parameters vp=[\u03bc_l, \u03bc_s, \u03bc_o, \u03c3_l, \u03c3_s, \u03c3_o]. So the integration and the differentiation does not cancel each other.", "Because of the integration, analytically calculating this gradient of ELBO(q(z)) is hard. Since the integration calculates an expectation, we can use sample average to approximate it. At each optimisation step, we can sample some values of z from the current variational distribution q(z). This means to sample some values \u03c3_level, \u03c3_slope and \u03c3_obs from current q(z). And use sample average to approximate the integration. In formula:", "The last line uses n samples Z_1 to Z_n from the current q(z) distribution to calculate sample average. I emphasise that at each optimisation step, we need to draw new samples from the current q(z). This is because each optimisation step changes the q(z) distribution by changing the values of the variational parameters.", "However, the above formula has a problem when we want to apply gradient descent. To see that, let\u2019s keep manipulating the above formula:", "At line 6, the API of the ELBO formula is explicit. Look at the first term. With Y and Z_i plugged in, log(p(Y, Z_i)) becomes a constant. That\u2019s why we have a \u201c\u03bb.\u201d symbol leading its API. The \ud835\udefb_vp operator calculates the gradient of this constant with respect to vp. The gradient is 0. This seems to suggest that the likelihood does not play any role (since it disappears) in the optimisation problem. This does not make sense.", "The reason for this problem is that which samples Z_i we get from q(z) depends on the variational parameters. And we are optimising those variational parameters using gradient descent. But drawing samples from q(z) happens outside of the gradient descent algorithm. This makes the gradient descent algorithm lose the knowledge about q(z). The symptom is that the likelihood term disappears when computing the gradient.", "The reparameterization trick solves this problem.", "In our case, sampling is inevitable because of a hard to compute integration. But sampling happens outside of the gradient descent framework. To solve the problem, we should sample from a simpler distribution. And this distribution must not depend on the variational parameters.", "The idea of the reparameterization trick is, for each model parameter in z, for example, \u03c3_level:", "In formula, let\u2019s continue to use the model parameter \u03c3_level as an example:", "We can rewrite \u03c3_level as a function of \u03b8_level as follows:", "Note in this function, \u03bc_l and \u03c3_l are variational parameters. If you don\u2019t know how we come up with such a function, it\u2019s OK. People have been working on how to design such functions for different distributions, see here. Many of them are not trivial!", "The important thing for us is: \u03c3_level is still a Gaussian distribution with mean \u03bc_l and variance \u03c3_l. This is because the first term at the right hand side of the equation", "is a linear transformation from the Gaussian variable \u03b8_level~N(0, 1) with no added noise. We already know how to write down its distribution:", "Now the reparameterization function adds \u03bc_l to this Gaussian distribution, resulting in the Gaussian distribution N(\u03bc_l, \u03c3_l). In other words, this reparameterization keeps the distribution of \u03c3_level unchanged.", "Let\u2019s define \u03b8=[\u03b8_level, \u03b8_slope, \u03b8_obs] as the vector of reparameterization variables. Let the reparameterization function be r. In our example of \u03b8_level:", "This trick turns q(z) into a function of \u03b8 and vp:", "ELBO(q(z)) becomes a function of the variational parameters vp and and the newly introduced variable vector \u03b8. We introduced \u03b8 because we can sample it independently from the variational parameters. When \u03b8 is replaced with samples \u0398~N(0, 1), the ELBO becomes a function of vp only. In formula:", "Wow, this is scary. Let me explain:", "Now, I will demonstrate how we arrived at the fourth line from the third line above. To keep things simpler, let me treat \u03b8 as a single dimensional variable and use symbols \u03b8, \u03bc and \u03c3, instead of \u03b8_level, \u03bc_l and \u03c3_l. And q becomes a univariate Gaussian distribution:", "We can generalise this univariate case to multivariate case.", "Thank you for reading this long. I know it\u2019s been a long journey. I really want to say \u201cthat\u2019s it\u201d. But, there is one more thing.", "The gradient descent algorithm works on variables that have the full real domain \u211d. It does not allow you to specify bounds to the variables. However, if we look at the variational distribution q(z) again:", "Since \u03c3_l, \u03c3_s and \u03c3_o represents standard deviations, they must be non-negative. By now we should get into the habit of reformulating variables with functions. That\u2019s exactly what we should do here. We introduce three new variables \u03d5_l, \u03d5_s and \u03d5_o and rewrite \u03c3_l, \u03c3_s and \u03c3_o as functions of of them:", "This way, \u03d5_l, \u03d5_s and \u03d5_o can take values from the full real domain while \u03c3_l, \u03c3_s and \u03c3_o stays non-negative only. q(z) becomes:", "With this final step (and of course, everything above), the ELBO becomes a function of \u03bc_l, \u03bc_s, \u03bc_o, \u03d5_l, \u03d5_s, and \u03d5_o. All six variables can take values from the full real domain \u211d. Gradient descent can finally go through.", "We have two places where we adapted variable domains from \u211d\u207a to \u211d:", "You may ask, what do we gain by choosing q(z) as a product of Gaussians? Why is it better than the original prior, which is a product of LogNormals?", "When we look at the optimisation process, the only place that q(z) helps us is that we can sample from q(z) easily. More precisely, we need to be able to reparameterize q(z) so it can be expressed as a function from a fixed distribution. And we can easily sample from that fixed distribution. We already showed that with our proposed q(z), we can do that. But how about LogNormal? It turns out we can also reparameterize LogNormal distribution and sample from it, details here.", "So to answer this question, in our particular case, the proposed q(z) is not a big life-saver. We can perform the optimisation with our LogNormal prior too. But imagine that when the prior is complicated and hard to sample from, a structurally simple q(z) can be a real help.", "Going back to Listing 1, line 17~23 uses gradient descent to find optimal values for vp. It first creates an Adam optimizer with the ELBO as the objective function, and then performs 200 gradient descent steps.", "That marks the end of parameter learning.", "By the way, variational inference is very important in modern day machine learning, and is a topic that you won\u2019t get away with. See its application in Variational Gaussian Process, and human face generation.", "Gradient descend will give you optimal values for the six variational parameters \u03bc_l*, \u03c3_l*, \u03bc_s*, \u03d5_l*, \u03d5_s* and \u03d5_o*. These values fully specify the optimised variational distribution q(z)*:", "We can use q(z)* to approximate the posterior p(z|y).", "Given time series observations Y_1 to Y_T, our interest is to predict future values, Y_T+1, Y_T+2 and so on. To do that, we can run the Kalman filter algorithm from time steps 1 to T to calculate the distribution of the latent variable x_t|y_1:t,z. Copying the Kalman filter algorithm from above:", "We can run the Kalman filter now because now we can know values of its parameters z*=[\u03c3_level*, \u03c3_slope*, \u03c3_obs*], for example, by sampling \u03c3_level*, \u03c3_slope* and \u03c3_obs* from the optimised q(z)* distribution.", "You may ask, why do we need to sample from q(z)*? This is because q(z)* is a distribution, to run Kalman filters, we need concrete values for the three standard deviations \u03c3_level, \u03c3_slope and \u03c3_obs. How many samples do we need for each standard deviation? It is up to you. For example, You can sample 30 for each standard deviation and take the average, and plug these three averages into the local linear trend.", "After the Kalman filter algorithm finishes, the result is the distribution of the system state variable x_t, in other words, the value of \u03bc_t and \u03a3_t:", "From now on, our prediction begins. We can plug x_T|y_1:T,z into the linear dynamical system equations to get predictive distributions for the state variable x_T+1|y_1:T,z and observation variable y_T+1|y_1:T,z.", "In fact, you can do this infinite number of times:", "In the above diagram, we start with the result of the Kalman filtering p(x_T|y_1:T, z). Each right arrow \u201c\u2192\u201d represents an application of the first system equation to get the distribution of the next state variable. Each down arrow \u201c\u2193\u201d represents an application of the second system equation to get the distribution of the next observation.", "This way, you can get the predictive distribution of the observation variable y_T+i|y_1:T,z for arbitrary step i into the future. Remember you still need to plug in actual observations Y_1:T and optimised model parameters z* to the formulas to get fully specified distributions.", "Note that in the above diagram, inside the condition part of all the distributions, the y_1:T part does not change, we don\u2019t have y_1:T+1, y_1:T+2. This is because we don\u2019t have actual observations after time step T any more. We should realise that the process of prediction is to use the first 3 out of 5 steps in the Kalman filter algorithm to derive our belief of the system state and observation possibility distributions in the future. We cannot use the last 2 steps from the Kalman filter to correct our believes any more because we don\u2019t have new observations.", "The math allows you to predict new values infinitely into the future. But this does not mean that you should. The farther into the future your predictions are, the more imprecise they become. This is common sense; and let\u2019s see how this common sense is reflected in math.", "We need to look at the structure of the distribution for the system state variable and observation variable. Let\u2019s first look at the system state variable distributions in the next two time steps T+1 and T+2 by applying the first system equation twice:", "Let\u2019s study the mean and variance component by drawing an inductive conclusion from the above derivations.", "In the above, I use a over bar \u201c-\u201d above level_T and slope_T to denote that these are the mean value components in \u03bc_T. Line 5 shows that the trend level prediction (first entry in matrix) is a straight line starting at the current trend level. And the slope level prediction (second entry) stays the same.", "Now let\u2019s study the variance \u03a3_T+i of the variable x_T+1 and x_T+2:", "The formulas are a bit complicated. But we can see each time we move forward in time, the noise variance \u03a3_w is added into the variance of the system state variable. This causes the variance of the system state variable x_T+i to become larger and larger over time.", "Now we move on to the predictive distribution for the observation variable y_T+i. It is a linear Gaussian transformation from the system state variable x_T+i. So y_T+i follows the same trait:", "Now we can see the mean of the predictive distribution for y_T+i is the same as the mean of x_T+i, a straight line, due to the matrix H is set to [1, 0]. This straight line formula also reminds us why the slope variable is called slope. The variance of y_T+i will have the variance of the noise \u03a3_v added into it ever time step we move into the future. This causes the variance of y_T+i to become larger and larger as well.", "Going back to code Listing 1, line 26 samples values for our model parameters from the optimised q(z) distribution. Line 28~33 builds the predictive distribution for the observation variable y by running the Kalman filter algorithm internally. And line 36~38 performs prediction by reporting the mean and standard deviation from the predictive distribution at every future time step.", "With this mathematical analysis, let\u2019s circle back to our mountain skyline \u201ctime series\u201d. The skyline has 220 observations. I used the the first 200 observations for parameter learning. And then used the learnt model to predict the last 20 points. Here is how it looks like:", "In the above figure, the blue curve is the ground truth mountain skyline observations. The vertical dash line separates training on the left and prediction on the right. The green dash line is the mean of the predictions. The light green cone shape on the right shows the prediction variance at 95% confidence level.", "The prediction mean and variance confirms our mathematical analysis. The mean prediction is a straight line. And the variance becomes larger and larger as we go farther into the future.", "We can also see that the mean prediction is quite wrong (alternatively, we can interpret that the prediction is right if taking the confidence interval into account)! The mean prediction says the mountain skyline should go up, but it actually goes down. This because I deliberately chose a cut-off point, a mountain top, to challenge the algorithm. To make predictions, the algorithm can only rely on previous values before the 200th observation where the mountain goes up. Of course it will predict the mountain keeps going up. Hence the name local linear trend. Mathematically, the algorithm learns that the slope should be positive.", "So what do we do? We get new observations, re-train the model from scratch using all the observations every time when a new observation is available, and then make predictions. Here is a picture if we train our model with 8 more observations and start prediction at the 208th observation:", "Now the predictions are more precise. The additional 8 observations show the mountain goes down, so the algorithm learnt that the slope variable is negative. The prediction is more precise because the mountain keeps going down, in other words, the trend does not change direction.", "Here is the code for the skyline prediction. It is adapted from Tensorflow time series examples.", "You may wonder, or you remember that the Kalman filter algorithm alone can perform time series prediction based on observations. Didn\u2019t we landed on the moon using this algorithm, way before variational inference is invented? Why do we need variational inference? Well, the Kalman filter algorithm only works on a fully specified model without any parameters. Since our local linear model contains parameters, we first need to learn the values for them. A Bayesian approach, with variational inference being the inference algorithm, is the choice of this Tensorflow time series library.", "This article introduced the local linear trend model from the Tensorflow time series library. It focuses on how to learn the parameters of this model:", "These are a lot of steps. I tried to explain the intuition behind each step clearly. And I presented only the necessary math.", "The good news is you only need basic college math to understand all of the above. Here is a list of mentioned math knowledge points:", "If you like my story, I will be grateful if you consider supporting me by becoming a Medium member via this link: https://jasonweiyi.medium.com/membership.", "I will keep writing these stories.", "I would like to thank Vincent Adam for going through the code of Tensorflow time series with me. Thank Lucas Bordeaux, Michael Pedersen, Elvijs Sarkans, Nicolas Durrande, Stefanos Eleftheriadis for their questions and suggestions during the writing of this article. Thank Joshua Jones from 10Creatives to create the featured image.", "I decided to include some appendix. You can understand the full article without this appendix. But the material here gives you a different, and interesting angle.", "This section shows how to derive the likelihood for the linear dynamical system using rules in probability theory, without the Kalman filter algorithm.", "Before we start, a side note on removing random variables from formulas.", "The derivation of the likelihood p(Y) from probability theory requires quite some manipulations to probability density functions. As a side note, let\u2019s first think about how we can remove a random variable from a probability density function. Usually, there are four ways:", "We will use some of these three mechanisms in the derivation of the likelihood p(Y).", "Let me copy the definition of the linear dynamical system from above:", "Here, we use p(Y), instead of p(Y|z) to denote the likelihood. I decide to drop the model parameter z to save space. Since the model parameter z is not relevant in current section. So remember, in this section p(Y) is the likelihood, not the marginal likelihood.", "Let\u2019s use x to denote the set of random variables for each state. So x={x\u2081, x\u2082,\u2026, to x_T}. And use y to represent the set of random variables behind each observation. So y={y\u2081, y\u2082,\u2026, to y_T}. And the corresponding observation is labelled as Y={Y\u2081, Y\u2082,\u2026, to Y_T}.", "The likelihood p(Y) is defined in the probability theory as:", "Line (1) is the formula to derive p(y=Y) by marginalizing the state random variables x from the joint distribution p(Y, x). When I write p(Y,x), it means p(y=Y, x), and reads \u201cthe joint probability density of the random variables y and x and plug in the observation Y into y\u201d. This is a template that you can apply for any probabilistic system.", "This line uses the integrating out and plugging observation mechanisms described above. And we realize that the likelihood p(Y) is a probability number, not a probability density function anymore.", "Line (2) splits the joint distribution p(Y, x) into two using the chain rule in probability theory. This is also a template that are universally applicable.", "Line (3) explicitly lists the random variables x\u2081, to x_T and observations Y\u2081 to Y_T. This is also the case for every probability system. Please note that this formula also explicitly writes out the T integrations for x\u2081, to x_T. Each integration sums over a single random variable.", "Starting from line (4), we start to derive formulas specific to our linear dynamical system.", "Line (4) splits, or factorizes, the big conditional p(Y|x) into T smaller conditionals p(Y\u1d62|X\u1d62). We can do this because the second equation of the linear dynamical system. This equation tells us two things:", "This line uses the dropping irrelevant condition mechanism.", "Line (5) factorizes p(x\u2081, x\u2082, \u2026, x_T) into product of T smaller probabilities. We can do this because we can first apply the chain rule in probability and then use equation 2 of the linear dynamical system. This equation defines x\u209c to only depend on the previous state x\u209c\u208b\u2081, like this:", "Line (6) groups integration for x\u2081, x\u2082, \u2026, using parenthesis. This way, it is easy to see we can first compute the inner most integration over x\u2081, and then the integration over x\u2082, and so on. This line uses the integrating out mechanism.", "Now we demonstrate how to compute the inner most integration. This integration is with respect to random variable x\u2081. If we can do this, we can compute other integrations in the same way.", "Inside the integral, there are three terms. They are all the terms in the likelihood that mentions x\u2081, so we have to list them under the integration with respect to x1. We show what the three parts are and how to compute this integration.", "This is because we already defined x\u2080~N(0, I). And X\u2081 is a linear transformation from X\u2080 according to the first equation of the linear dynamical system.", "This is because of the second equation of the linear dynamical system defines the random variable y\u2081 as a linear Gaussian transformation from the random variable x\u2081, and we plugged in the observation Y\u2081 into y\u2081.", "This is because of the first equation of the linear dynamical system defines the random variable x\u2082 as a linear Gaussian transformation of the random variable x\u2081.", "Note that inside the integral, the three Gaussian probability densities are over different random variables x\u2081, y\u2081 and x\u2082. Since the integration is with respect to x\u2081, I want to transform the three Gaussian probability densities to over the same random variable x\u2081. So I can do the following:", "To see what I mean, let\u2019s carry out this plan. By the way, this is the usual trick to integrate products of Gaussian probability densities.", "First, since p(x\u2081) is already a probability density function for x\u2081, we don\u2019t need to do anything.", "Note the power of 2\u03c0 is 1/2 because y\u2081 is a one dimensional random variable. If in doubt, please look at the definition of the multivariate Gaussian probability density function.", "To transform this formula into a probability density function for x\u2081, we need to extract the H in front of x\u2081. We also need to reverse the sign in front of x\u2081. This way, we can match the definition of the multivariate Gaussian probability density function for x\u2081.", "We multiply HH\u207b\u00b9 in front of the Y\u2081-Hx\u2081. This does not change the value of the term because HH\u207b\u00b9 evaluates to the identity matrix. After some manipulations, we got:", "With this, we can work on the transpose (Y\u2081-HX\u2081)\u1d40:", "We now replace the corresponding terms in the original formula with these two new equivalent transformations. We got:", "Line (1) and line (2) shows the original formula; it is a probability density function for Y\u2081.", "Line (3) performs the term transformations we carried out before. Now we can see that the exponential term is part of a new multivariate Gaussian probability density function for random variable x\u2081. It has mean H\u207b\u00b9Y\u2081, and the inverse of its covariance matrix is H\u1d40\u03a3\u1d65\u207b\u00b9H, so its covariance matrix is (H\u1d40\u03a3\u1d65\u207b\u00b9H)\u207b\u00b9 = H\u207b\u00b9\u03a3\u1d65(H\u207b\u00b9)\u1d40.", "This exponential term is only part of a multivariate Gaussian probability density function because a complete multivariate Gaussian probability density function requires a normalization constant in front of the exponential. We can compute this constant from the covariance matrix, but to save space, we call this constant M\u2081.", "Line (4) writes the signature for this new Gaussian distribution. Since this distribution contains the constant M\u2081, we have to multiple the distribution with M\u2081\u207b\u00b9 to preserve equality.", "And finally, we work on p(x\u2082; Ax\u2081, \u03a3_w) by performing the same steps:", "Note that the power of 2\u03c0 is 2/2 because the dimension of our state is 2. Following the same steps as before, we have:", "And we denote the constant in front of the multivariate Gaussian distribution M\u2082.", "The third line uses the constant M to denote all the constants in front of the probability densities.", "The importance of the above transformations is that it allows us to see now the three probability density functions inside the integral are for the random variable x\u2081. So we can use the following rule of two Gaussian product to derive a combined probability density:", "This two Gaussian product rule shows that the combined probability density is still for the same random variable, with a different mean, covariance and normalization constant.", "Since there are three multivariate Gaussian densities inside the integral, we need to apply this rule twice to derive the final single probability density. Let the normalization constant for this final probability density to be Z\u2093\u2081, and the mean and covariance to be \u03bc\u2093\u2081 and \u03a3\u2093\u2081, we have:", "The fourth line applies the two Gaussian product rule twice to derive the final probability density. Note that this final probability density integrates to 1, as all probability density functions do. So the whole integration evaluates to MZ\u2093\u2081.", "Please note that MZ\u2093\u2081 is an expression that mentions x\u2082 because x\u2082 appears in the mean of the third component Gaussian distribution, see the third line. In fact, MZ\u2093\u2081 is the multivariate Gaussian probability density function p(x\u2082). So when you do the second integration over x\u2082, you will have the same structure as the integration over x\u2081:", "So, you can continue the computation for x\u2082, x\u2083,\u2026 one by one to compute the whole likelihood p(Y). The result will be the same as what we showed before using the Kalman filter algorithm.", "You may ask, why we want to derive the likelihood using different methods:", "Well, in reality, knowing one is enough, meaning that with either method, you can already compute the likelihood. And then you can perform parameter learning, and make predictions. But to do it in both ways:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a senior data scientist at AstraZeneca. Previously I worked at SecondMind, Microsoft Research, and also was CTO of a hedge fund EQB."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9bec0802b24a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jasonweiyi.medium.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": ""}, {"url": "https://jasonweiyi.medium.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Wei Yi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1b4bd5317a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&user=Wei+Yi&userId=1b4bd5317a6e&source=post_page-1b4bd5317a6e----9bec0802b24a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/towards-data-science/inside-ai/home", "anchor_text": "Inside AI"}, {"url": "https://facebook.github.io/prophet/", "anchor_text": "Prophet"}, {"url": "https://aws.amazon.com/blogs/opensource/gluon-time-series-open-source-time-series-modeling-toolkit/", "anchor_text": "Gluon Time Series"}, {"url": "https://azure.microsoft.com/en-gb/services/time-series-insights/", "anchor_text": "Time Series Insights"}, {"url": "https://medium.com/tensorflow/structural-time-series-modeling-in-tensorflow-probability-344edac24083", "anchor_text": "Tensorflow time series"}, {"url": "https://medium.com/tensorflow/structural-time-series-modeling-in-tensorflow-probability-344edac24083", "anchor_text": "Tensorflow time series library"}, {"url": "https://gist.github.com/jasonweiyi/f88b8d61fc72785b84d248bd6fa86a47", "anchor_text": "this code"}, {"url": "https://pixabay.com/photos/lake-mcdonald-landscape-mountains-1056561/", "anchor_text": "Pixabay"}, {"url": "https://en.wikipedia.org/wiki/Log-normal_distribution", "anchor_text": "LogNormal"}, {"url": "https://en.wikipedia.org/wiki/Lambda_calculus", "anchor_text": "lambda calculus"}, {"url": "https://en.wikipedia.org/wiki/Chain_rule_(probability)", "anchor_text": "product rule"}, {"url": "https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804", "anchor_text": "Gaussian Process"}, {"url": "https://towardsdatascience.com/where-do-confidence-interval-in-linear-regression-come-from-the-case-of-least-square-formulation-78f3d3ac7117", "anchor_text": "least squares linear regression"}, {"url": "https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf", "anchor_text": "joint probability density for multivariate Gaussian"}, {"url": "https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf", "anchor_text": "the rule of conditional for multivariate Gaussian"}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "mean-field variational family"}, {"url": "https://www.cl.cam.ac.uk/teaching/2003/Probability/prob11.pdf", "anchor_text": "probability density transformation"}, {"url": "https://en.wikipedia.org/wiki/Change_of_variables", "anchor_text": "replacing variables with functions of other variables"}, {"url": "https://en.wikipedia.org/wiki/Integration_by_substitution", "anchor_text": "integration by substitution"}, {"url": "https://www.cl.cam.ac.uk/teaching/2003/Probability/prob11.pdf", "anchor_text": "This paper"}, {"url": "https://gist.github.com/jasonweiyi/c5b9b2aaca3aef4279691d480db7a42a", "anchor_text": "this code"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback\u2013Leibler divergence"}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "theory of variational inference"}, {"url": "https://stats.stackexchange.com/questions/335197/why-kl-divergence-is-non-negative", "anchor_text": "KL-divergence is non-negative"}, {"url": "https://en.wikipedia.org/wiki/Gradient_descent", "anchor_text": "gradient descent"}, {"url": "http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/", "anchor_text": "here"}, {"url": "https://stats.stackexchange.com/questions/110961/sampling-from-a-lognormal-distribution", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/variational-gaussian-process-what-to-do-when-things-are-not-gaussian-41197039f3d4", "anchor_text": "Variational Gaussian Process"}, {"url": "https://towardsdatascience.com/understanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756", "anchor_text": "human face generation"}, {"url": "https://gist.github.com/jasonweiyi/43d23da4b8c65a9a6a6aaddd883b5a52", "anchor_text": "Here"}, {"url": "https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Structural_Time_Series_Modeling_Case_Studies_Atmospheric_CO2_and_Electricity_Demand.ipynb", "anchor_text": "Tensorflow time series examples"}, {"url": "https://en.wikipedia.org/wiki/Expected_value", "anchor_text": "Definition of expectation"}, {"url": "https://en.wikipedia.org/wiki/Normal_distribution", "anchor_text": "Univariate Gaussian"}, {"url": "https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf", "anchor_text": "Multivariate Gaussian distribution, its joint and conditional"}, {"url": "https://www.statlect.com/probability-distributions/normal-distribution-linear-combinations", "anchor_text": "Linear transformation of Gaussian"}, {"url": "https://en.wikipedia.org/wiki/Log-normal_distribution", "anchor_text": "LogNormal distribution"}, {"url": "https://en.wikipedia.org/wiki/Bayes%27_theorem", "anchor_text": "Bayes rule"}, {"url": "https://en.wikipedia.org/wiki/Chain_rule_(probability)", "anchor_text": "Product/chain rule in probability"}, {"url": "https://en.wikipedia.org/wiki/Marginal_distribution", "anchor_text": "Marginal distribution"}, {"url": "https://en.wikipedia.org/wiki/Probability_density_function", "anchor_text": "Definition of probability density function"}, {"url": "https://en.wikipedia.org/wiki/Integration_by_substitution", "anchor_text": "Integration by substitution"}, {"url": "https://en.wikipedia.org/wiki/Multiple_integral", "anchor_text": "Multiple integration"}, {"url": "https://en.wikipedia.org/wiki/Change_of_variables", "anchor_text": "Replace variable with function"}, {"url": "https://arxiv.org/pdf/1601.00670.pdf", "anchor_text": "ELBO used in variational inference"}, {"url": "https://jasonweiyi.medium.com/membership", "anchor_text": "https://jasonweiyi.medium.com/membership"}, {"url": "https://www.linkedin.com/in/vincent-adam-5a195810/", "anchor_text": "Vincent Adam"}, {"url": "https://www.linkedin.com/in/lucas-bordeaux-7704b42/", "anchor_text": "Lucas Bordeaux"}, {"url": "https://www.linkedin.com/in/michaeldavidpedersen/", "anchor_text": "Michael Pedersen"}, {"url": "https://www.linkedin.com/in/elvijs-sarkans-69087a5b/", "anchor_text": "Elvijs Sarkans"}, {"url": "https://sites.google.com/site/nicolasdurrandehomepage/", "anchor_text": "Nicolas Durrande"}, {"url": "https://www.linkedin.com/in/seleftheriadis/", "anchor_text": "Stefanos Eleftheriadis"}, {"url": "https://10creative.co.uk/about10", "anchor_text": "Joshua Jones"}, {"url": "https://10creative.co.uk/", "anchor_text": "10Creatives"}, {"url": "http://cs229.stanford.edu/section/gaussians.pdf", "anchor_text": "the multivariate Gaussian probability density function"}, {"url": "https://medium.com/tag/kalman-filter?source=post_page-----9bec0802b24a---------------kalman_filter-----------------", "anchor_text": "Kalman Filter"}, {"url": "https://medium.com/tag/variational-inf?source=post_page-----9bec0802b24a---------------variational_inf-----------------", "anchor_text": "Variational Inf"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----9bec0802b24a---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----9bec0802b24a---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/inside-ai?source=post_page-----9bec0802b24a---------------inside_ai-----------------", "anchor_text": "Inside Ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&user=Wei+Yi&userId=1b4bd5317a6e&source=-----9bec0802b24a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&user=Wei+Yi&userId=1b4bd5317a6e&source=-----9bec0802b24a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9bec0802b24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9bec0802b24a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9bec0802b24a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9bec0802b24a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9bec0802b24a--------------------------------", "anchor_text": ""}, {"url": "https://jasonweiyi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jasonweiyi.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Wei Yi"}, {"url": "https://jasonweiyi.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "812 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1b4bd5317a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&user=Wei+Yi&userId=1b4bd5317a6e&source=post_page-1b4bd5317a6e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea93cb78cf1e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-tensorflow-time-series-local-linear-trend-9bec0802b24a&newsletterV3=1b4bd5317a6e&newsletterV3Id=ea93cb78cf1e&user=Wei+Yi&userId=1b4bd5317a6e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}