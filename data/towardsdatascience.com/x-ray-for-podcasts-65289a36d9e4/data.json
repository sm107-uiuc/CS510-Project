{"url": "https://towardsdatascience.com/x-ray-for-podcasts-65289a36d9e4", "time": 1683000994.800013, "path": "towardsdatascience.com/x-ray-for-podcasts-65289a36d9e4/", "webpage": {"metadata": {"title": "X-Ray for Podcasts. How to identify different speakers\u2026 | by Jordan Ryda | Towards Data Science", "h1": "X-Ray for Podcasts", "description": "Unsupervised machine learning to identify different podcast voices in Python."}, "outgoing_paragraph_urls": [{"url": "https://samharris.org/podcasts/123-identity-honesty/", "anchor_text": "#123-Identify & Honesty", "paragraph_index": 2}, {"url": "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html", "anchor_text": "scipy", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Fraunhofer_diffraction", "anchor_text": "Fraunhofer diffraction", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Uncertainty_principle", "anchor_text": "uncertainty", "paragraph_index": 6}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html", "anchor_text": "FFT", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency", "anchor_text": "bandwidth of the male vocal range", "paragraph_index": 8}, {"url": "https://librosa.github.io/librosa/feature.html", "anchor_text": "functions", "paragraph_index": 12}, {"url": "https://docs.scipy.org/doc/scipy/reference/signal.html", "anchor_text": "scipy.signal", "paragraph_index": 12}, {"url": "https://medium.com/linagoralabs/computing-mfccs-voice-recognition-features-on-arm-systems-dae45f016eb6", "anchor_text": "This", "paragraph_index": 14}, {"url": "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html", "anchor_text": "this", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Short-time_Fourier_transform", "anchor_text": "short-time Fourier transform", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Gibbs_phenomenon", "anchor_text": "spurious high-frequency contributions", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Spectral_leakage", "anchor_text": "spectral leakage", "paragraph_index": 17}, {"url": "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.hamming.html", "anchor_text": "window function", "paragraph_index": 17}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "group MNIST digits", "paragraph_index": 19}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "UMAP", "paragraph_index": 21}, {"url": "https://plot.ly/dash/", "anchor_text": "Dash", "paragraph_index": 23}, {"url": "https://github.com/jimmybow/visdcc", "anchor_text": "3rd party library", "paragraph_index": 23}, {"url": "https://gist.github.com/jpryda/7e57e6ce3cf57308aed85478c1ec3975", "anchor_text": "this gist", "paragraph_index": 26}], "all_paragraphs": ["Amazon offers a tool for Kindle and Video it calls \u201cX-Ray\u201d that gives you access to extra information about the scene at hand. The information includes the characters present and helps to navigate between sections of a book or drill into the filmography of a vaguely familiar actor.", "One might imagine the demands of producing such a service require some form of labelling (either exhaustively by hand or for a classifier). However wouldn\u2019t it be cool if we could infer the splits without any labelling labour at all? With this we could calculate the extent to which characters steal the limelight, when and for how long, as well as changing conversation dynamics.", "I chose to look at audio \u2014 simpler than video but also one component of a similar video task. To test a simple base case I selected a podcast that contained slowly alternating dialogue between two people and landed upon Sam Harris\u2019s chat with Ezra Klein in #123-Identify & Honesty \u2014 two different male voices that our ears have no trouble discerning. The final product should look something like this:", "Reading audio in is a breeze with scipy \u2014 monophonic audio is just a 1D array of chronological values. We now consider the tradeoffs in varying the window size used store the \u201cchunks\u201d of data we will label. The sample frequency Fs here is the standard 44.1 kHz which means our arrays will be of size 44,100 * N for chunk time N seconds. The smaller the window the more precise the location in time and less likely the voices interrupt one another.", "But longer time windows can also help in identifying a voice \u2014 and not just a sharp vowel sound. We could suspect this involves looking at some sort of average timbre over a sufficiently long period of time. Five seconds ended up giving good results based on the lengthy speaking times in this discussion (if there were more interruptions this could have been too large).", "There is also a more fundamental compromise in frequency resolution (think shorter time windows give broader spectral peaks). But this phenomenon is only important if we extract the spectrum for the entire chunk. We can steer clear of this if we analyse sub-chunks that collectively inform the chunk label (and this is exactly what I do).", "The Fourier transform is the mathematics that connects \u201creciprocal coordinates\u201d. Its scaling property captures the tradeoff we observe in many physical phenomena such as in spectral analysis (resolution of frequency vs precision in time); Fraunhofer diffraction (the smaller the slit spacing the wider the diffraction pattern); uncertainty in quantum mechanics (the more precisely we determine the position the greater the uncertainty in momentum).", "The time component of a signal doesn\u2019t reveal much about the intrinsic character of a sound. Sound waves are just pressure disturbances in air and the periodicity of these disturbances does reveal a signature of sorts in the frequency domain. A Fast Fourier Transform (FFT) of each chunk does the trick and produces the frequency spectra depicted below.", "These spectra are clearly pretty dense and high dimensional and so we might use the bandwidth of the male vocal range to apply a crude cutoff.", "This reduces the dimensionality of the spectrum, but recall there are actually two values for each frequency component \u2014 a real and imaginary part. When we view a spectrum we\u2019re looking at the magnitude which accounts for both parts. However, it\u2019s the phase in a Fourier transform (the ratio of the two parts) that carries much of the signal for images as for audio.", "We can test this by crossing the magnitude and phase between the Ezra and Sam clips and below are a handful of (unnormalised) mutant clips.", "At this point we could pass the structure of magnitudes and phases to a dimensionality reduction algorithm (see section 4) to visualise the output. This is what I did initially to produce two very fuzzy groups and it wasn\u2019t quick either.", "The librosa library has a number of functions to extract features from the frequency spectrum (e.g. the \u201ccentre of mass\u201d, the energy distribution etc.) or time series (e.g. zero-crossing rate). We might also consider detecting frequency peaks and peak widths using scipy.signal. The features we choose however must be specific to the task of separating voices by their timbre in a way that is pitch-invariant. If the problem centred on pitch detection we would choose features that distinguish pitch and not timbre.", "In other words, we must ensure the features chosen don\u2019t precisely \u201cfingerprint\u201d the data \u2014 we need something fuzzier. We turn to the feature that proved to be the most successful at this \u2014 Mel-Frequency Cepstral Coefficients (MFCCs).", "MFCCs were originally developed to represent sounds made by the human vocal tract. It makes use of the Mel scale, a logarithmic transformation of frequency, that aims to capture the non-linear human perception of sound which results in a lower sensitivity to differences at higher frequencies. This means that a large distance between MFCC vectors relates to a large perceptual change and so capture timbre more robustly and not simply pitch. This and this dive into the mechanics of their computation much better than I can and so I will refrain from doing so here.", "Automatic speech recognition tasks typically look at 12\u201320 cepstral coefficients and the 0th coefficient can be dropped as it only conveys a constant offset of the average power, not relevant to the overall spectrum shape. My results turned out just fine by picking 15 coefficients and dropping the 0th order.", "MFCC extraction involves \u201cframing\u201d or \u201cwindowing\u201d which applies a sliding window over the input, much like a short-time Fourier transform, to produce a few hundred sets of 15 coefficients (within each audio chunk), one for each consecutive frame. The rationale here is we want to preserve frequency contours of the signal that occur when temporarily stationary. These can be lost if we Fourier transform the entire chunk (as I did initially).", "Some additional Fourier theory is worth considering here when analysing small windows of audio. Modelling discontinuities such as the sharp corners of square wave requires many high frequency terms. If we create sharp bins throughout the audio we could expect discontinuities at the edges that produces spurious high-frequency contributions as well as spectral leakage and so it makes sense to taper the edges with a window function.", "The process of calculating MFCCs from a spectrum has the added benefit of greatly reducing the dimensionality of the input. In every frame we are taking a large number of samples (2048 here), reducing these to 15 coefficients per frame. The final feature vector is built up from the mean of the coefficients across all of these frames. Adding the variance didn\u2019t improve results.", "PCA is the de-facto workhorse of dimensionality reduction \u2014 a quick, deterministic, linear transformation that preserves global structure of the data when separating data along the eigenvectors of maximal variance. For example, if we were to group MNIST digits we would see that the centroids for the clusters of 1s is far from the 0s and 4,7,9 clusters are relatively close. However we can\u2019t assume that neighbours close-by are also close in high dimensional space.", "A more modern approach is tSNE, a stochastic technique that benefits from preserving local structure \u2014 it places neighbours in the high dimensional space close to each other, but at the cost of some global structure. For example, grouping MNIST digits we see cleanly isolated clusters while PCA produces a continuous smear.", "UMAP is a newer technique able to capture both the global structure (\u00e0 la PCA) and local structure (\u00e0 la tSNE). It\u2019s also significantly faster than the best multicore tSNE implementations (13X faster on MNIST) and custom distance functions can be supplied too. In this two voice problem the decision of dimensionality reduction technique is probably less critical but it\u2019s also nice to get some hands-on experience. Once the MFCCs do the first stage of reduction, the processing time on 3600 chunks x 15 coefficients is very fast.", "The graph below shows not two distinct clusters but three! The colour of each point indicates the time into the podcast and edges connect consecutive chunks. The dark blue points therefore indicate that the introduction was probably recorded at a different time \u2014 with different equipment or in a different setting. What\u2019s nice here is that the introduction cluster (dark blue) where Sam opens is closer to his dialogue cluster. These two clusters can actually be subsumed if we remove some of the higher MFCC coefficients (8+) although at a cost to the global separation between Sam and Ezra.", "From here we can apply kmeans for k=3 clusters to map each point to a one of three labels by listening to points in each cluster. But wouldn\u2019t it be nice to link each point to its audio chunk for playback on click? This would help with validation of the clusters and answer questions such as \u201cdo points in one cluster closest to another cluster represent a chunk with both voices\u201d? It turned out to be surprisingly challenging, but not insurmountable, using Dash and plotly as well as some javascript and a 3rd party library.", "Not too shabby? Now that we have our kmeans labels we can compute the oft-quoted debate statistic, duration spoken.", "Sam spoke for 57% of the time excluding the intro! Well it is his podcast after all. And adding back in the temporal component of each chunk, here is a rather satisfying final product: the X-Ray timeline for the conversation. The frequency of exchange during Sam\u2019s phase at 2500s suggests this section is particularly interesting/heated.", "I have spruced up my Jupyter notebook which can be found in this gist", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F65289a36d9e4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jpryda?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jpryda?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Jordan Ryda"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2bffef734ec4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&user=Jordan+Ryda&userId=2bffef734ec4&source=post_page-2bffef734ec4----65289a36d9e4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@priscilladupreez?utm_source=medium&utm_medium=referral", "anchor_text": "Priscilla Du Preez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://samharris.org/podcasts/123-identity-honesty/", "anchor_text": "#123-Identify & Honesty"}, {"url": "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html", "anchor_text": "scipy"}, {"url": "http://saadahmad.ca/fft-spectral-leakage-and-windowing/", "anchor_text": "http://saadahmad.ca/fft-spectral-leakage-and-windowing/"}, {"url": "https://en.wikipedia.org/wiki/Fraunhofer_diffraction", "anchor_text": "Fraunhofer diffraction"}, {"url": "https://en.wikipedia.org/wiki/Uncertainty_principle", "anchor_text": "uncertainty"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html", "anchor_text": "FFT"}, {"url": "https://en.wikipedia.org/wiki/Voice_frequency", "anchor_text": "bandwidth of the male vocal range"}, {"url": "https://librosa.github.io/librosa/feature.html", "anchor_text": "functions"}, {"url": "https://docs.scipy.org/doc/scipy/reference/signal.html", "anchor_text": "scipy.signal"}, {"url": "https://medium.com/linagoralabs/computing-mfccs-voice-recognition-features-on-arm-systems-dae45f016eb6", "anchor_text": "This"}, {"url": "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html", "anchor_text": "this"}, {"url": "https://en.wikipedia.org/wiki/Short-time_Fourier_transform", "anchor_text": "short-time Fourier transform"}, {"url": "https://en.wikipedia.org/wiki/Gibbs_phenomenon", "anchor_text": "spurious high-frequency contributions"}, {"url": "https://en.wikipedia.org/wiki/Spectral_leakage", "anchor_text": "spectral leakage"}, {"url": "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.hamming.html", "anchor_text": "window function"}, {"url": "https://www.ijser.org/paper/Performance-analysis-of-isolated-Bangla-speech-recognition-system-using-Hidden-Markov-Model.html", "anchor_text": "https://www.ijser.org/paper/Performance-analysis-of-isolated-Bangla-speech-recognition-system-using-Hidden-Markov-Model.html"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "group MNIST digits"}, {"url": "https://github.com/lmcinnes/umap", "anchor_text": "UMAP"}, {"url": "https://plot.ly/dash/", "anchor_text": "Dash"}, {"url": "https://github.com/jimmybow/visdcc", "anchor_text": "3rd party library"}, {"url": "https://gist.github.com/jpryda/7e57e6ce3cf57308aed85478c1ec3975", "anchor_text": "this gist"}, {"url": "https://musicinformationretrieval.com/mfcc.html", "anchor_text": "mfccThe mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10-20) which\u2026musicinformationretrieval.com"}, {"url": "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html", "anchor_text": "Speech Processing for Machine Learning: Filter banks, Mel-Frequency Cepstral Coefficients (MFCCs)\u2026Speech processing plays an important role in any speech system whether its Automatic Speech Recognition (ASR) or\u2026haythamfayek.com"}, {"url": "https://medium.com/@LeonFedden/comparative-audio-analysis-with-wavenet-mfccs-umap-t-sne-and-pca-cb8237bfce2f", "anchor_text": "Comparative Audio Analysis With Wavenet, MFCCs, UMAP, t-SNE and PCAThis post is on a project exploring an audio dataset in two dimensions. I cover some interesting algorithms such as\u2026medium.com"}, {"url": "https://medium.com/linagoralabs/computing-mfccs-voice-recognition-features-on-arm-systems-dae45f016eb6", "anchor_text": "Computing MFCCs voice recognition features on ARM systemsI worked as a trainee in Linagora\u2019s R&D departement on the LinTO project. Do you know LinTO? If not, you should! LinTO\u2026medium.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----65289a36d9e4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----65289a36d9e4---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----65289a36d9e4---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----65289a36d9e4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----65289a36d9e4---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&user=Jordan+Ryda&userId=2bffef734ec4&source=-----65289a36d9e4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&user=Jordan+Ryda&userId=2bffef734ec4&source=-----65289a36d9e4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F65289a36d9e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----65289a36d9e4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----65289a36d9e4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----65289a36d9e4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----65289a36d9e4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jpryda?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jpryda?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jordan Ryda"}, {"url": "https://medium.com/@jpryda/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "83 Followers"}, {"url": "https://www.linkedin.com/in/jryda", "anchor_text": "https://www.linkedin.com/in/jryda"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2bffef734ec4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&user=Jordan+Ryda&userId=2bffef734ec4&source=post_page-2bffef734ec4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F96a17a180644&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fx-ray-for-podcasts-65289a36d9e4&newsletterV3=2bffef734ec4&newsletterV3Id=96a17a180644&user=Jordan+Ryda&userId=2bffef734ec4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}