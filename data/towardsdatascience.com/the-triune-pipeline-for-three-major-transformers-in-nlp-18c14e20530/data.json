{"url": "https://towardsdatascience.com/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530", "time": 1683002017.5697868, "path": "towardsdatascience.com/the-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530/", "webpage": {"metadata": {"title": "Text Feature Extraction With Scikit-Learn Pipeline | by Jenny Lee | Towards Data Science", "h1": "Text Feature Extraction With Scikit-Learn Pipeline", "description": "First, as promised, I\u2019ll be following up on a previous post in which I compared the speech properties of twenty-one 2020 Democratic primary presidential candidates. I identified a range of linguistic\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b?source=friends_link&sk=521c1d6609bdfb96e41fa2439d5b18d1", "anchor_text": "post", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "1", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b", "anchor_text": "post", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b", "anchor_text": "post", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/modules/compose.html#notes", "anchor_text": "2", "paragraph_index": 9}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/linguistic-rule-writing-for-nlp-ml-64d9af824ee8?source=friends_link&sk=3a063a20b2f3a14ca253ebc33c0ed2f4", "anchor_text": "applying some rules", "paragraph_index": 18}, {"url": "https://towardsdatascience.com/how-to-build-a-reusable-nlp-code-pipeline-with-scikit-learn-with-an-emphasis-on-feature-504f8aa14699?source=friends_link&sk=135abfa127e7094b1a17963b254ab678", "anchor_text": "post", "paragraph_index": 22}, {"url": "https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel", "anchor_text": "macro", "paragraph_index": 24}, {"url": "https://scikit-learn.org/0.16/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion", "anchor_text": "FeatureUnion", "paragraph_index": 27}], "all_paragraphs": ["First, as promised, I\u2019ll be following up on a previous post in which I compared the speech properties of twenty-one 2020 Democratic primary presidential candidates. I identified a range of linguistic features that would distinguish our presidential hopefuls at the descriptive level.", "In this post, I\u2019d like to use those features to build a classification model that can predict who will qualify for the Dec 19th debate. Of course, we now know who has qualified for the debate, but I guess the real motive behind this task is to come away with a more general understanding of how much it matters for someone to talk a certain way (on the debate stage) in order to be taken seriously as a presidential candidate (and be allowed to move on to the next round).", "Second (and more importantly), in building this model, I\u2019d like to share something that I\u2019ve been extremely pleased to discover recently in the world of scikit-learn: Pipeline (I know I\u2019m late to the party. :)) This very powerful class has made my entire ML workflow \u2014 from preprocessing to evaluation \u2014 so much more tractable, more robust, and less susceptible to guesswork, especially in the hyperparameter tuning stage. As a colleague of mine said, it really ought to be part of every sklearn-based ML project! Here\u2019s a description of what it does:", "Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be \u2018transforms\u2019, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. [1]", "Do refer to my earlier post if you want more context and the results of an in-depth descriptive analysis, but in this post, I\u2019ll dive straight into leveraging Pipeline to build the so-called Triune Pipeline \ud83d\udd31, whose component pipelines can transform raw text into what are no other than the three major featural building blocks of NLP tasks:", "Depending on the specific task or model you\u2019re dealing with, one or more of these feature types in the Venn diagram may be particularly important to your model\u2019s performance \u2014 for example, word embeddings accompanied by some subset of custom linguistic features. To understand which overlapping or non-overlapping sets of features are the most important, we\u2019ll need to set up a training flow that can test the impact of each feature type. This is where Pipeline comes to our rescue.", "Using the prepared dataframe from the previous post, we want to add a column for the target variable qualified (1 or 0 for yes or no), which expresses who has qualified for the December debate. Eight candidates have qualified for the debate (including Harris who dropped out):", "We then split the dataset into a training and a test set:", "Now we\u2019re ready for the fun part!", "Pipeline provides a convenient and intuitive way to structure our ML flows, which are characterized by a predictable sequence of core tasks including preprocessing, feature selection, standardization/normalization, and classification. Pipeline automates multiple instances of the fit/transform process by calling fit on each estimator in succession, applying transform to the input, and passing the transformed input on to the next step. This means that every estimator in a Pipeline (except for the last one) must have a transform method [2], like this friendly sklearn transformer TfidfVectorizer:", "The final estimator in a Pipeline need not be a transformer (i.e., have a transform method), but can be (and is typically) a classifier, like SVC. This structure will allow you to call predict on the whole fitted pipeline.", "Taking our debate transcript texts, we create a simple Pipeline object that (1) transforms the input data into a matrix of TF-IDF features and (2) classifies the test data using a random forest classifier:", "We can then call fit on the whole pipeline and predict on the test data. As you can see, there\u2019s nothing to it other than providing the ordered estimators. You can, of course, extend the pipeline by adding a normalization or a standardization step preceding the \u201cclassifier\u201d step. (You\u2019ll see an example of a dimensionality reduction step in the next pipeline.)", "In the classification report below, 0 stands for \u201cnot qualified for the December debate\u201d and 1 stands for \u201cqualified\u201d. We see that using just the debate transcript data \u2014 and knowing nothing else about the candidates (such as their polling status, gender, likeability, and level of political experience) \u2014 we\u2019re able to predict with 70% accuracy who\u2019s going to and not going to advance to the next debate. The words they say on the debate stage really do matter, independent of how they say them (which the third pipeline deals with below) or who they are more generally.", "This second pipeline will require creating a custom transformer that converts text to numerical vectors based on the word embeddings. There are a couple of ways to do this, including downloading pre-trained GloVe word vectors from here and writing a custom function to load the model, like this:", "Alternatively, you can use one of spaCy\u2019s models that come with built-in word vectors, which are accessible through the .vector attribute as you\u2019ll see below. Below I load the \"en_core_web_md\" model which provides 685k keys and 20k unique vectors (300 dimensions). This model is stored as an attribute of SpacyVectorTransformer, a custom transformer that returns the vector averages.", "Once we get the 300-dimensional mean embeddings, we can optionally use TrancatedSVD to reduce the dimensionality of these features.", "We see that the results aren\u2019t quite as good as those of the simpler TF-IDF model.", "By \u201ccustom linguistic features\u201d, I mean the kind that you can extract manually by applying some rules to your data. In this example, I extract the feature number of words before the main verb using the spaCy dependency parser:", "More examples of rule-based custom linguistic features can be found in these two posts:", "This third pipeline requires a custom transformer just like the last one; CustomLinguisticFeatureTransformer takes a fit method (that returns itself) and a transform method. The latter returns the output of featurize which is a method of another class I have created, called SegmentFeaturizer.", "SegmentFeaturizer defines the methods that are used to extract a set of linguistic features. Here\u2019s its basic structure in which a number of feature-extracting functions are followed by the main featurize function that returns a list of feature dictionaries:", "(To learn more about featurize, see this post.) The output of transform then serves as input to the next component of the pipeline, namely, DictVectorizer. The complete pipeline is as follows:", "Not quite as good as the bag-of-words model, but better than the mean embeddings. Here\u2019s a summary table comparing the metrics of the three pipelines:", "(Showing macro averages for precision, recall, and f-score.)", "Having seen that the bag-of-words pipeline and the custom linguistic features pipeline produced the best results independently, I wondered what the effect would be if we created a new pipeline combining the features of the two. And luckily, there\u2019s an easy way to do this!", "Composing sets of features is accomplished by FeatureUnion:", "FeatureUnion combines several transformer objects into a new transformer that combines their output. A FeatureUnion takes a list of transformer objects. During fitting, each of these is fit to the data independently. For transforming data, the transformers are applied in parallel, and the sample vectors they output are concatenated end-to-end into larger vectors.", "Below, the \"classifier\" step has been removed from each pipeline because that step will need to come after we have applied FeatureUnion.", "The final pipeline consists of the combined features joined by FeatureUnion and a final classifier:", "At this point, we can fit final_pipeine and calculate the metrics, but for good measure, I\u2019m going to perform a randomized search over the parameters of the fitted random forest classifier. (You can alternatively run the grid search, but it takes longer.)", "Cool! the results are better with feature unification and grid search-powered parameter optimization!", "On every metric, the hybrid pipeline scored higher than the best-performing individual pipeline:", "As a proper next step, you may try combining all three feature sets and see what happens, thereby creating a truly \u201ctriune\u201d (three-in-one) pipeline. \ud83d\udd31", "In this post, I demonstrated how to set up the Triune Pipeline to predict the likelihood of a presidential candidate qualifying for the next debate. They were:", "Each component pipeline includes a transformer that outputs a major feature type/representation in NLP. I also showed that we can combine distinct feature sets resulting from different pipelines to achieve better results, especially in conjunction with RandomizedSearchCV. I think another good takeaway is the value of combining ML-driven and rule-based methods to boost the performance of a model.", "And I did find it truly fascinating that candidate speech properties alone \u2014 uninfluenced by any other demographic features or information about the candidates\u2019 political achievements \u2014 can predict with reasonable accuracy whether someone will qualify for the next debate, one of many predictors of who our next president will be.", "If you want something less wordy:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F18c14e20530&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----18c14e20530--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dzenilee?source=post_page-----18c14e20530--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dzenilee?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Jenny Lee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8231fa2cbef7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&user=Jenny+Lee&userId=8231fa2cbef7&source=post_page-8231fa2cbef7----18c14e20530---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.looper.com/122484/best-worst-movies-blockbuster-franchises/", "anchor_text": "Source"}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b?source=friends_link&sk=521c1d6609bdfb96e41fa2439d5b18d1", "anchor_text": "post"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html", "anchor_text": "1"}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b", "anchor_text": "post"}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b", "anchor_text": "post"}, {"url": "https://scikit-learn.org/stable/modules/compose.html#notes", "anchor_text": "2"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/linguistic-rule-writing-for-nlp-ml-64d9af824ee8?source=friends_link&sk=3a063a20b2f3a14ca253ebc33c0ed2f4", "anchor_text": "applying some rules"}, {"url": "https://towardsdatascience.com/linguistic-rule-writing-for-nlp-ml-64d9af824ee8", "anchor_text": "Writing Linguistic Rules for Natural Language ProcessingWith a guide to question type extraction with spaCytowardsdatascience.com"}, {"url": "https://towardsdatascience.com/which-presidential-candidate-talks-like-that-b2b16060ff8b", "anchor_text": "Beyond Speaking Time: An Analysis of Democratic Presidential DebatesData preparation and feature engineering for predictive modeling using real-world datatowardsdatascience.com"}, {"url": "https://towardsdatascience.com/how-to-build-a-reusable-nlp-code-pipeline-with-scikit-learn-with-an-emphasis-on-feature-504f8aa14699?source=friends_link&sk=135abfa127e7094b1a17963b254ab678", "anchor_text": "post"}, {"url": "https://scikit-learn.org/stable/modules/model_evaluation.html#from-binary-to-multiclass-and-multilabel", "anchor_text": "macro"}, {"url": "https://scikit-learn.org/0.16/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion", "anchor_text": "FeatureUnion"}, {"url": "https://medium.com/swlh/randomized-or-grid-search-with-pipeline-cheatsheet-719c72eda68", "anchor_text": "A Super Quick Guide to Randomized (or Grid) Search with PipelineFive steps using scikit-learnmedium.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----18c14e20530---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----18c14e20530---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----18c14e20530---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----18c14e20530---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/election-2020?source=post_page-----18c14e20530---------------election_2020-----------------", "anchor_text": "Election 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&user=Jenny+Lee&userId=8231fa2cbef7&source=-----18c14e20530---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&user=Jenny+Lee&userId=8231fa2cbef7&source=-----18c14e20530---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18c14e20530--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F18c14e20530&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----18c14e20530---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----18c14e20530--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----18c14e20530--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----18c14e20530--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----18c14e20530--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----18c14e20530--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dzenilee?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dzenilee?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jenny Lee"}, {"url": "https://medium.com/@dzenilee/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "445 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8231fa2cbef7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&user=Jenny+Lee&userId=8231fa2cbef7&source=post_page-8231fa2cbef7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F630d12d64891&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-triune-pipeline-for-three-major-transformers-in-nlp-18c14e20530&newsletterV3=8231fa2cbef7&newsletterV3Id=630d12d64891&user=Jenny+Lee&userId=8231fa2cbef7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}