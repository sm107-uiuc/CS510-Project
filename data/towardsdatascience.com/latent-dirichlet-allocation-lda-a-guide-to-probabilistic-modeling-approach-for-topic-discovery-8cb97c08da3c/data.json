{"url": "https://towardsdatascience.com/latent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c", "time": 1683005794.2780511, "path": "towardsdatascience.com/latent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c/", "webpage": {"metadata": {"title": "Latent Dirichlet Allocation(LDA): A guide to probabilistic modelling approach for topic discovery | by Awan-Ur-Rahman | Towards Data Science", "h1": "Latent Dirichlet Allocation(LDA): A guide to probabilistic modelling approach for topic discovery", "description": "Latent Dirichlet Allocation(LDA) is one of the most common algorithms in topic modelling. LDA was proposed by J. K. Pritchard, M. Stephens and P. Donnelly in 2000 and rediscovered by David M. Blei\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Dirichlet_distribution", "anchor_text": "Dirichlet distribution", "paragraph_index": 10}, {"url": "https://github.com/aawanRahman/latent-dirichlet-allocation/blob/master/topic_modelling_LDA.ipynb", "anchor_text": "GitHub", "paragraph_index": 19}, {"url": "https://www.kaggle.com/canggih/voted-kaggle-dataset", "anchor_text": "dataset", "paragraph_index": 20}, {"url": "https://github.com/amueller/word_cloud", "anchor_text": "WordCloud", "paragraph_index": 25}, {"url": "https://github.com/aawanRahman/latent-dirichlet-allocation/blob/master/topic_modelling_LDA.ipynb", "anchor_text": "GITHUB", "paragraph_index": 29}], "all_paragraphs": ["Latent Dirichlet Allocation(LDA) is one of the most common algorithms in topic modelling. LDA was proposed by J. K. Pritchard, M. Stephens and P. Donnelly in 2000 and rediscovered by David M. Blei, Andrew Y. Ng and Michael I. Jordan in 2003. In this article, I will try to give you an idea of what topic modelling is. We will learn how LDA works and finally, we will try to implement our LDA model.", "Topic Modelling is one of the most interesting fields in Machine Learning and Natural Language Processing. Topic Modelling means the extraction of abstract \u201ctopics\u201d from the collection of documents. One of the primary application of natural language processing is to know what people are talking about in a large number of text documents. And it is really hard to read through all of these documents and extract or compile topics. In these cases, topic modelling is used to extract documents information. To understand the concept of topic modelling let\u2019s see an example.", "Suppose, you are reading some articles on a newspaper and in those articles, the word \u201cclimate\u201d appears most than any other words. So, in a normal sense, you can say that these articles will more probably about something related to climate. Topic modelling does the same thing in a statistical way. It produces topics by clustering similar words. Here come two terms: one is \u201cTopic Modelling\u201d and the other is \u201cTopic Classification\u201d. Though they look similar, they are totally different processes. The first is an unsupervised machine learning technique and the second one is the supervised technique.Let\u2019s elaborate on the concept.", "Topic classification often involves mutually-exclusive classes. That means each document is labelled with a specific class. On the other hand, Topic modelling is not mutually exclusive. The same document may involve with many topics. As Topic modelling works on the basis of the probability distribution, the same document may have a probability-distribution spread across many topics.", "For topic modelling, there are several existing algorithms that you can use. Non-Negative Matrix Factorization(NMF), Latent Semantic Analysis or Latent Semantic Indexing(LSA or LSI) and Latent Dirichlet Allocation(LDA) are some of these algorithms. Here in this article, we will talk about Latent Dirichlet Allocation, one of the most common algorithms for topic modelling.", "\u201c The latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word\u2019s presence is attributable to one of the document\u2019s topics.\u201d \u2014 Wikipedia", "Okay, Let\u2019s try to understand this definition.", "The basic idea of Latent Dirichlet allocation (LDA) is that documents are considered as random mixtures of various topics and topics are considered a mixture of different words. Now, suppose you need some articles which are related to animals and you have thousands of articles in front of you and you really don\u2019t know what these articles are about. Reading all these articles are really cumbersome to find out the articles related to animals. Let\u2019s see an example of it.", "As an example, let\u2019s consider we have four articles. Article no. 1 related to animal, article no. 2 related to genetic type, article no. 3 related to computer types and article no. 4 is a combination of animal and genetic type. As a human, you can easily differentiate these topics according to the words it contains. But what will you do if there are thousands of articles and each article has thousands of lines? The answer will be like -\u201cIf we can do this with the help of a computer then we should do so\u201d. Yes, Computer can do so with the help of Latent Dirichlet allocation. Now we will try to understand how LDA works. First, we will see the graphical representation of LDA and then we will see the probability calculation formula.", "The above figure is a graphical representation of LDA. In the above figure, we can see that there are six parameters-", "\u03b1(alpha) and \u03b7(eta) \u2014 represents Dirichlet distribution. The high alpha value indicates that each document contains most of the topics and on the contrary, a lower alpha value indicates that the documents are likely to contain a fewer number of topic. Same as alpha, a Higher value of \u03b7 indicates that the topics are likely to cover most of the words and on the contrary, lower eta value indicates that the topics are likely to contain a fewer number of words.", "\u03b2(beta) and \u03b8(theta) \u2014 represents multinomial distribution.", "z \u2014 represents a bunch of topics", "w \u2014 represents a bunch of words", "The left side of the formula indicates the probability of the document. In the right of the formula, there are four terms. The 1st and 3rd term of the formula will help us to find topics. The 2nd and 4th will help us to find the words in articles. The first two terms of the right side of the formula indicate Dirichlet distribution and the rest portion of the right side is multinomial distribution.", "Let\u2019s assume, in the above figure, in the left triangle, the blue circles indicate different articles. Now if we distribute the articles over different topics, it will be distributed as shown in the right triangle. The blue circles will move to the corners of the triangle which depends on the percentage of its being that topic. This process is done by the first term of the right side of the formula. Now we use multinomial distribution to generate topics based on the percentage get from the first term.", "Now after getting the topics we will find which words are more relatable to these topics. This is done by another Dirichlet distribution. Topics are distributed based on the words as shown below.", "Now we will use another multinomial distribution to find the words which are more related to those topics and generate words with probability using that Dirichlet distribution. This process is done multiple times.", "Thus we will find the words which are more relatable to the topics and can distribute the articles based on those topics.", "You can find the code in GitHub. For implementing LDA you can use either gensim or sklearn. Here, we will use gensim.", "For implementing purpose, I have used the Kaggle dataset. This dataset consists of 2150 datasets information in 15 columns:", "For processing the data, first, we select the columns that are meaningful for this process. Then remove the rows containing any missing values.", "We will then calculate the number of unique tag in Tags columns as we will consider this as the number of topics for our model.", "Removing punctuations and transforming the whole text in the lower casing makes the training task easier and increase the efficiency of the model.", "We need to tokenize our dataset and perform stemming operation.", "By using WordCloud, we can verify whether our preprocessing is correctly done or not. A word cloud is an image made of words that together resemble a cloudy shape. It shows us how often a word appeared in a text \u2014 its frequency.", "For the LDA model, we first need to build a dictionary of words where each word is given a unique id. Then need to create a corpus which contains word id mapping with word_frequency \u2014 ->(word_id, word_frequency).", "Coherence measures the relative distance between words within a topic.", "The topic at the top got the highest probability and it is related to something like economic.", "You can find all the code on GITHUB.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer | Data Science and Machine Learning Enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8cb97c08da3c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@awanurrahman.cse?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@awanurrahman.cse?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Awan-Ur-Rahman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80abdb633f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&user=Awan-Ur-Rahman&userId=80abdb633f48&source=post_page-80abdb633f48----8cb97c08da3c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.widewallpapershd.info/preview/26253/3840x2160/newspapers.html", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Dirichlet_distribution", "anchor_text": "Dirichlet distribution"}, {"url": "https://github.com/aawanRahman/latent-dirichlet-allocation/blob/master/topic_modelling_LDA.ipynb", "anchor_text": "GitHub"}, {"url": "https://www.kaggle.com/canggih/voted-kaggle-dataset", "anchor_text": "dataset"}, {"url": "https://github.com/amueller/word_cloud", "anchor_text": "WordCloud"}, {"url": "https://github.com/aawanRahman/latent-dirichlet-allocation/blob/master/topic_modelling_LDA.ipynb", "anchor_text": "GITHUB"}, {"url": "https://ai.stanford.edu/~ang/papers/jair03-lda.pdf", "anchor_text": "Latent Dirichlet Allocation"}, {"url": "https://youtu.be/T05t-SqKArY", "anchor_text": "Latent Dirichlet Allocation"}, {"url": "https://www.youtube.com/watch?v=VTweNS8GiWI", "anchor_text": "Latent Dirichlet Allocation (algorithm)"}, {"url": "https://medium.com/tag/topic-modeling?source=post_page-----8cb97c08da3c---------------topic_modeling-----------------", "anchor_text": "Topic Modeling"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----8cb97c08da3c---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/python?source=post_page-----8cb97c08da3c---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8cb97c08da3c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/implementation?source=post_page-----8cb97c08da3c---------------implementation-----------------", "anchor_text": "Implementation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&user=Awan-Ur-Rahman&userId=80abdb633f48&source=-----8cb97c08da3c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&user=Awan-Ur-Rahman&userId=80abdb633f48&source=-----8cb97c08da3c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8cb97c08da3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8cb97c08da3c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8cb97c08da3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@awanurrahman.cse?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@awanurrahman.cse?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Awan-Ur-Rahman"}, {"url": "https://medium.com/@awanurrahman.cse/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "111 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80abdb633f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&user=Awan-Ur-Rahman&userId=80abdb633f48&source=post_page-80abdb633f48--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffc0caee2dced&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flatent-dirichlet-allocation-lda-a-guide-to-probabilistic-modeling-approach-for-topic-discovery-8cb97c08da3c&newsletterV3=80abdb633f48&newsletterV3Id=fc0caee2dced&user=Awan-Ur-Rahman&userId=80abdb633f48&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}