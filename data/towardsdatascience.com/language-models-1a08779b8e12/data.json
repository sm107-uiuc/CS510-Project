{"url": "https://towardsdatascience.com/language-models-1a08779b8e12", "time": 1683009215.7881632, "path": "towardsdatascience.com/language-models-1a08779b8e12/", "webpage": {"metadata": {"title": "Language Models, RNN, Deep Leaning, Word Vectors | Towards Data Science", "h1": "Language Models", "description": "What is a Language Model and how to train one? Machine Learning approaches used to train, outputs and utility of Language Models"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/393ce2bbf82c?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Ravi Charan", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/the-relationship-between-perplexity-and-entropy-in-nlp-f81888775ccc", "anchor_text": "blog", "paragraph_index": 4}, {"url": "http://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf", "anchor_text": "A Neural Probabilistic Language Model", "paragraph_index": 9}, {"url": "https://www.msn.com/en-us/news/technology/openai-e2-80-99s-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/ar-BB14RvVk", "anchor_text": "GPT-3 is trained on the a trillion words of texts scraped from the Web", "paragraph_index": 14}, {"url": "https://csaurav.online", "anchor_text": "https://csaurav.online", "paragraph_index": 17}], "all_paragraphs": ["I was in a Zoom call where someone said \u2014 \u201cProject A has an elevated risk of ___.\u201d I could not hear the word after \u2018of\u2019, but I know what that word was. And I am sure you know the word too.", "We have a language model in us. Our internal language models tell us that the probability of the sentence \u201cProject A has an elevated risk of delay.\u201d is much higher than the probability of the sentence \u201cProject A has an elevated risk of water.\u201d", "This post is about statistically learned language models (LM)\u2014 what they are, how they are evaluated and how they are learned. Language modelling by itself does not have a direct practical use but it is a crucial component in real-world applications such as machine-translation and automatic speech recognition. A translation system might generate multiple translations of the same target sentence and the language models scores all the sentences to pick the one that is most likely.", "Formally the language modelling task is simply to assign a probability to any sequence of words. Alternatively, we can also pose this problem as a word guessing problem. Fill in the blank: \u201cThe dog ____\u201d. The equation below shows this equivalence mathematically.", "How would you measure the performance of this model? The most common intrinsic metric is Perplexity. Perplexity measures how confused the language model is in predicting the next word in an unseen sequence of words. A good intermediate level overview of perplexity is in Ravi Charan\u2019s blog.", "But, for most practical purposes extrinsic measures are more useful. An extrinsic measure of a LM is the accuracy of the underlying task using the LM. For example, the BLEU score of a translation task that used the given language model.", "Perplexity is a corpus specific metric. We can compare the perplexity of two LMs only if the metric is computed on the same corpus. Perplexity improvements do not guarantee improvements in the extrinsic metric such as BLEU score.", "Language models start with a Markov Assumption. This is a simplifying assumption that the k+1st word is dependent on the previous k words. A 2nd order assumption results in a Bigram model. The models are training using Maximum Likelihood Estimations (MLE) of an existing corpus. The MLE approach then is simply a fraction of work counts.", "There are some advantages of using tradition n-gram language models.", "Nonlinear neural network models solve some of the shortcomings of traditional language models. For instance, the number of parameters of a neural LM increases slowly as compared to traditional models. One of the earliest such model was proposed by Bengio et al in 2003. In a classic paper called A Neural Probabilistic Language Model, they laid out the basic structure of learning word representation using an RNN.", "Quoting from the paper they presented three key ideas \u2014", "Language models can be trained on raw text say from Wikipedia. To train a k-order language model we take the (k + 1) grams from running text and treat the (k + 1)th word as the supervision signal. Thus, we can generate a large amount of training data from a variety of online/digitized data in any language.", "A particularly important by-product of learning language models using Neural Models is the Word Matrix as shown below. Instead of updating just the training parameters, we update the Word Matrix as well. The word matrix can then be used for a variety of different supervised tasks.", "Almost all NLP tasks use Language Models. Language models are used in speech recognition, machine translation, part-of-speech tagging, parsing, Optical Character Recognition, handwriting recognition and information retrieval.", "Traditional language models have performed reasonably well for many of these use cases. The deep learning era has brought new language models that have outperformed the traditional model in almost all the tasks. Typical deep learning models are trained on large corpus of data (GPT-3 is trained on the a trillion words of texts scraped from the Web), have big learning capacity (GPT-3 has 175 billion parameters) and use novel training algorithms (attention networks, BERT).", "Though, the mechanism of how LMs are learned has evolved, the fundamental intuition behind LMs remain the same.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a data scientist solving some interesting problems in the industry. https://csaurav.online"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1a08779b8e12&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://csaurav.medium.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": ""}, {"url": "https://csaurav.medium.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Saurav Chakravorty"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa83474a25c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&user=Saurav+Chakravorty&userId=a83474a25c2&source=post_page-a83474a25c2----1a08779b8e12---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/u/393ce2bbf82c?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Ravi Charan"}, {"url": "https://towardsdatascience.com/the-relationship-between-perplexity-and-entropy-in-nlp-f81888775ccc", "anchor_text": "blog"}, {"url": "https://dl.acm.org/doi/pdf/10.3115/981863.981904?download=true", "anchor_text": "this paper"}, {"url": "http://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf", "anchor_text": "A Neural Probabilistic Language Model"}, {"url": "https://www.msn.com/en-us/news/technology/openai-e2-80-99s-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/ar-BB14RvVk", "anchor_text": "GPT-3 is trained on the a trillion words of texts scraped from the Web"}, {"url": "https://medium.com/tag/ai?source=post_page-----1a08779b8e12---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/word-vectors?source=post_page-----1a08779b8e12---------------word_vectors-----------------", "anchor_text": "Word Vectors"}, {"url": "https://medium.com/tag/nlp?source=post_page-----1a08779b8e12---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1a08779b8e12---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "http://creativecommons.org/publicdomain/zero/1.0/", "anchor_text": "No rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&user=Saurav+Chakravorty&userId=a83474a25c2&source=-----1a08779b8e12---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&user=Saurav+Chakravorty&userId=a83474a25c2&source=-----1a08779b8e12---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1a08779b8e12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1a08779b8e12---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1a08779b8e12--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1a08779b8e12--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1a08779b8e12--------------------------------", "anchor_text": ""}, {"url": "https://csaurav.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://csaurav.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Saurav Chakravorty"}, {"url": "https://csaurav.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "185 Followers"}, {"url": "https://csaurav.online", "anchor_text": "https://csaurav.online"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa83474a25c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&user=Saurav+Chakravorty&userId=a83474a25c2&source=post_page-a83474a25c2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F78212ad6c58e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-1a08779b8e12&newsletterV3=a83474a25c2&newsletterV3Id=78212ad6c58e&user=Saurav+Chakravorty&userId=a83474a25c2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}