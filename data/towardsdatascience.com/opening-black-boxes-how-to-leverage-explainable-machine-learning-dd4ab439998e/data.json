{"url": "https://towardsdatascience.com/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e", "time": 1682997118.890913, "path": "towardsdatascience.com/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e/", "webpage": {"metadata": {"title": "Opening Black Boxes: How to leverage Explainable Machine Learning | by Maarten Grootendorst | Towards Data Science", "h1": "Opening Black Boxes: How to leverage Explainable Machine Learning", "description": "As Machine Learning and AI are becoming more and more popular an increasing number of organizations is adopting this new technology. Predictive modeling is helping processes becoming more efficient\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/johnolafenwa/us-census-data", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://github.com/MaartenGr/InterpretableML", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://github.com/SauceCat/PDPbox", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "here", "paragraph_index": 20}, {"url": "https://github.com/slundberg/shap", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://www.linkedin.com/in/mgrootendorst/", "anchor_text": "LinkedIn", "paragraph_index": 40}, {"url": "https://twitter.com/MaartenGr", "anchor_text": "Twitter", "paragraph_index": 40}, {"url": "http://www.linkedin.com/in/mgrootendorst/", "anchor_text": "www.linkedin.com/in/mgrootendorst/", "paragraph_index": 44}], "all_paragraphs": ["As Machine Learning and AI are becoming more and more popular an increasing number of organizations is adopting this new technology. Predictive modeling is helping processes becoming more efficient but also allow users to gain benefits. One can predict how much you are likely going to be earning based on your professional skills and experience. The output could simply be a number, but users typically want to know why that value is given!", "In this article, I will demonstrate some methods for creating explainable predictions and guide you into opening these black-box models.", "The data used in this article is the US Adult Income data set which is typically used to predict whether somebody makes less than 50K or more than 50, a simple binary classification task. You can get the data here or you can follow along with the notebook here.", "The data is relatively straightforward with information with respect to an individuals\u2019 Relationship, Occupation, Race, Gender, etc.", "The categorical variables are one-hot encoded and the target is set to either 0 (\u226450K) or 1 (>50K). Now let\u2019s say that we would like to use a model that is known for its great performance on classification tasks, but is highly complex and the output difficult to interpret. This model would be LightGBM which, together with CatBoost and XGBoost, is often used in both classification and regression tasks.", "We start by simply fitting the model:", "I should note that preferably you would have a train/test split with additional holdout data in order to prevent any overfitting you would do.", "Next, I quickly check the performance of the model using 10-fold cross-validation:", "Interestingly, scores_accuracy gives an average accuracy across 10-folds of 87% while scores_balanced gives 80%. As it turns out, the target variable is imbalanced with 25% of the target belonging to 1 and 75% to 0. Thus, choosing the correct validation measure is highly important as it may falsely indicate a good model.", "Now that we have created the model, next would be explaining what it exactly has done. Since LightGBM works with highly efficient gradient boosting decision trees, interpretation of the output can be difficult.", "Partial Dependency Plots (DPD) show the effect a feature has on the outcome of a predictive based model. It marginalizes the model output over the distribution of features in order to extract the importance of the feature of interest. The package, PDPbox, that I used can be found here.", "This importance calculation is based on an important assumption, namely that the feature of interest is not correlated with all other features (except for the target). The reason for this is that it will show data points that are likely to be impossible. For example, weight and height are correlated but the PDP might show the effect of a large weight and very small height on the target while that combination is highly unlikely. This can be partially resolved by showing a rug at the bottom of your PDP.", "Thus, we check the correlation between features in order to make sure that there are no problems there:", "We can see that there is no strong correlation present among the features. However, I will do some one-hot encoding, later on, to prepare the data for modeling which could lead to the creation of correlated features.", "PDP plots can be used to visualize the impact of a variable on the output across all data points. Let\u2019s first start with an obvious one, the effect of a continuous variable, namely capital_gain, on the target:", "The x-axis shows the values capital_gain can take and the y-axis indicates the effect it can have on the probability of the binary classification. It is clear that as one\u2019s capital_gain increases their chance of making <50K increases with it. Note, that the rug of data points at the bottom is helpful in identifying data points that do not appear often.", "Now, what if you have categorical variables that you one-hot encoded? You would likely want to see the effect of the categories individually without having to plot them separately. With PDPbox you are able to show the effect on multiple binary categorical variables at the same time:", "Here, you can clearly see that the likelihood of making more is positively affected by being either in a managerial position or that of technology. The chance decreases if you are working in the fishing industry.", "Finally, the interaction between variables might be problematic as PDP will create values for the combination which are unlikely to be possible if the variables are highly correlated.", "This matrix tells you that an individual is likely to make more if they are around 49 years old and work roughly 50 hours a week. I should note that it is important to keep in mind the actual distribution of all interactions in your data set. There is a chance that this plot will show you interesting interactions that will rarely or never happen.", "LIME basically tries to step away from deriving the importance of global features and instead approximates the importance of features for local predictions. It does so by taking the row (or set of data points) from which to predict and generate fake data based on that row. It then calculates the similarity between the fake data and the real data and approximates the effect of the changes based on the similarity between the fake and real data. The package that I used can be found here.", "The output shows the effect of the top 5 variables on the prediction probability. This helps in identifying why your model makes a certain prediction but also allows for explanations to users.", "Note that the neighborhood (kernel width) around which LIME tries to find different values for the initial row is, to an extent, a hyperparameter that can be optimized. At times you want a larger neighborhood depending on the data. It is a bit of trial and error to find the right kernel width as it might hurt the interpretability of explanations.", "A (fairly) recent development has been the implementation of Shapley values into machine learning applications. In its essence, SHAP uses game theory to track the marginal contributions of each variable. For each variable, it randomly samples other values from the data set and calculates the change in your model score. These changes are then averaged for each variable to create a summary score, but also gives information on how important certain variables are for a specific data point.", "Click here for the package that I used in the analyses. For a more in-depth explanation of the theoretical background of SHAP click here.", "SHAP has been well-received due to its ability to satisfy the three axioms of interpretability:", "Let\u2019s see what the result would be if we were to calculate the Shapley values for a single row:", "This plot shows a base value that is used to indicate the direction of the prediction. Seeing as most of the targets are 0 it isn\u2019t strange to see that the base value is negative.", "The red bar shows how much the probability that the target is 1 (>50K) is increased if its Education_num is 13. Higher education typically leads to making more.", "The blue bars show that these variables decrease the probability, with Age having the biggest effect. This makes sense as younger people typically make less.", "Shapley works intuitively a bit better when it concerns regression (continuous variable) rather than binary classification. Just to show an example, let\u2019s train a model to predict age from the same data set:", "Here, you can quickly observe that if you are never married the predicted Age is lowered by roughly 8 years. This helps a bit more with explaining the prediction compared to a classification task since you are directly talking about the value of the target instead of its probability.", "The Additivity axiom allows for summing Shapley values for each feature over all data points in order to create the mean absolute Shapley value. In other words, it gives global feature importances:", "However, you can immediately see the problem using Shapley values for one-hot encoded features, they are shown for each one-hot encoded feature instead of what they originally represented.", "Fortunately, the Additivity axiom allows the Shapley values for each one-hot encoded generated feature to be summed as a representation of the Shapley value for the entire feature.", "First, we need to sum up all the Shapley values for the one-hot encoded features:", "Now that all the Shapley values are average across all features and summed for the one-hot encoded features we can plot the resulting feature importance:", "We can now see that Occupation is way more important than the original Shapley summary plot showed. Thus, make sure to use the Additivity to your advantage when explaining the importance of features to your users. They are likely to be more interested in how important Occupation is rather than a specific Occupation.", "Although this is definitely not the first article to talk about Interpretable and Explainable ML, I hope this helped you understand how these technologies can be used when developing your model.", "There has been a significant buzz around SHAP and I hope that demonstrating the Additivity axiom using one-hot encoded features gives more intuition on how to use such a method.", "If you are, like me, passionate about AI, Data Science, or Psychology, please feel free to add me on LinkedIn or follow me on Twitter.", "All examples and code in this article can be found here:", "Any feedback and comments are, as always, greatly appreciated!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Psychologist. Passionate about anything AI-related! Get in touch: www.linkedin.com/in/mgrootendorst/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdd4ab439998e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@maartengrootendorst?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Maarten Grootendorst"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875----dd4ab439998e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/johnolafenwa/us-census-data", "anchor_text": "here"}, {"url": "https://github.com/MaartenGr/InterpretableML", "anchor_text": "here"}, {"url": "https://github.com/SauceCat/PDPbox", "anchor_text": "here"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "here"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/mgrootendorst/", "anchor_text": "LinkedIn"}, {"url": "https://twitter.com/MaartenGr", "anchor_text": "Twitter"}, {"url": "https://github.com/MaartenGr/InterpretableML", "anchor_text": "https://github.com/MaartenGr/InterpretableML"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dd4ab439998e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dd4ab439998e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----dd4ab439998e---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/shap?source=post_page-----dd4ab439998e---------------shap-----------------", "anchor_text": "Shap"}, {"url": "https://medium.com/tag/lime?source=post_page-----dd4ab439998e---------------lime-----------------", "anchor_text": "Lime"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----dd4ab439998e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----dd4ab439998e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdd4ab439998e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dd4ab439998e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dd4ab439998e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dd4ab439998e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dd4ab439998e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maartengrootendorst?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Maarten Grootendorst"}, {"url": "https://medium.com/@maartengrootendorst/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4.5K Followers"}, {"url": "http://www.linkedin.com/in/mgrootendorst/", "anchor_text": "www.linkedin.com/in/mgrootendorst/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb052d90faf55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fopening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e&newsletterV3=22405c3b2875&newsletterV3Id=b052d90faf55&user=Maarten+Grootendorst&userId=22405c3b2875&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}