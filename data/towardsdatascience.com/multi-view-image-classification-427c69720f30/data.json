{"url": "https://towardsdatascience.com/multi-view-image-classification-427c69720f30", "time": 1683002349.960223, "path": "towardsdatascience.com/multi-view-image-classification-427c69720f30/", "webpage": {"metadata": {"title": "Multi-View Image Classification. From Logistic Regression to Multi-View\u2026 | by Samy TAFASCA | Towards Data Science", "h1": "Multi-View Image Classification", "description": "We tackle the problem of multi-view image classification using traditional feature extraction first, then a custom CNN architecture. Code is also available."}, "outgoing_paragraph_urls": [{"url": "https://github.com/SAMY-ER/Multi-View-Image-Classification", "anchor_text": "code", "paragraph_index": 25}, {"url": "https://modelnet.cs.princeton.edu", "anchor_text": "ModelNet40", "paragraph_index": 25}], "all_paragraphs": ["Not long ago, I took part in a machine learning hackathon hosted by Daimler-Benz. The problem we were presented with was rather interesting and not so common. So I decided to write an article about it, in case my approach(es) can help someone else faced with a similar task.", "In the first chapter of this article, I will try to present my winning approach, walk you through my thought process, justify some design choices and elaborate on some concepts of interest. The second chapter, on the other hand, will be dedicated to a more sophisticated neural network based solution that is inherently adapted to this kind of problem. At the bottom of the page, you can find the link to my Github repository where I share the code to support the information presented in this post.", "The problem we had to solve was to classify 3D models of Car Plugs in one of the five categories available, based on 2D visual information. Solving this task is of great value, especially in the context of autonomous planning of assembly processes for car manufacturing.", "The most interesting aspect of the problem was the availability of 8 images for each Car Plug, 6 of which correspond to orthographic projections of the object (i.e. different views : top, bottom, front, rear, left and right) while the 2 others are random isometric projections. Figure 1 below shows an example of orthographic projections.", "There were three main challenges in this contest, and scoring well rested on identifying these obstacles and addressing them properly. The first of which, and probably the most obvious one, is a case of class imbalance where two classes are a lot less common in the dataset than the three others. It was important to take this into account, because the performance metric used in the competition was an extremely uneven weighted accuracy that factors in the distribution of the classes (i.e. rare classes are comparatively more important to classify correctly, sometimes by a factor of 80). The second challenge was that we had a timeframe of five hours to code everything up, without access to the cloud or any other means of accelerated computing (unless our personal laptops came equipped with Nvidia GPUs, which most weren\u2019t). Lastly, the availability of multiple images for each object to classify posed the question of how to combine the visual information gathered from all 8 images in order to make a well informed prediction. This last challenge is the main motivation behind this post.", "For the problem of class imbalance, resampling techniques were not a good option. Indeed, downsampling was practically impossible as we only had 833 Car Plugs in total (totaling 833x8 = 6664 images) and the rare classes had a very low number of samples. Furthermore, using data augmentation, though technically possible, did not seem like a good idea for me, simply because orthographic projections that produced the image views are a type of engineering drawing with a strict set of rules. Consequently, applying any sort of geometric transformation would result in images that do not belong to the original distribution of the data : using those for training is basically like pushing your model to learn how to predict images that it will never face, thus unnecessarily increasing the complexity of the problem. It is also worth noting that colors have no meaning in our images. To get a better sense of this, Figure 2 below provides an example of the different raw images of a Car Plug.", "The way I decided to address the class imbalance problem is through Cost-Sensitive Learning, which basically means modifying the cost function of the machine learning algorithm by introducing a set of weights, to assign heavier penalties for mistakes that occur in \u201cimportant\u201d classes. This change helps to steer model training towards making less of those costly mistakes at the expense of potentially making more of the \u201ccheaper\u201d mistakes. To illustrate this point further, imagine we have 50 data points, 49 belonging to class A and 1 belonging to class B. For the sake of simplicity, we also assume the 0\u20131 loss (0 for a correct prediction, 1 otherwise) instead of the prevalent cross-entropy loss. Under normal circumstances, where the weights of all the classes are 1, the model will try to learn how to predict most of the data points correctly, irrespective of their class. But if we assume that misclassifying a sample of class B bears x100 the cost of that of class A, and we modify our cost function to take this into account, then the model will end-up choosing to classify that one data point of class B correctly, even if it meant failing in the prediction of all other 49, because that is the setting that minimizes the overall cost: 49*1 + 0*100= 49. Instead, if we made a mistake in the class B data point, and we got all other class A samples right, the cost would be: 49*0 + 1*100 = 100 which is still much higher than the previous case. Using cost-sensitive learning in practice is as simple as passing in a weight dictionary to the algorithm constructor (those that support it at least).", "For the time constraint and absence of suitable computational resources, I decided to stay away from any neural network-based approaches, simply because it would take too much time to configure properly and train on a CPU. Instead, I opted for a more traditional computer vision solution, combining popular hand-engineered feature extractors with classical machine learning algorithms. And this, folks, is the tale of how a Logistic Regression won the 1st prize in a computer vision hackathon.", "First, we will introduce the approach I used during the hackathon. Then, we will present a potentially better alternative based on a neural network architecture that can inherently handle the multi-view problem. I had thought of this second solution as well during the contest, but I knew I wouldn\u2019t be able to implement it given the time and resource restrictions. However, I tried it afterwards, and it provided better results as expected.", "As we can see in Figure 2, there are a couple of issues we need to deal with before feeding these images or their vector representations to any machine learning algorithm. First, we need to get rid of the unnecessary visual artifacts on the right and top sides (search bar, menu, etc.). Second, we need to get rid of the shades of gray in the background which should speed up the training significantly by decreasing noise levels in the data.", "It turns out, we can do both of these things using a simple process: we first detect edges using the Canny Edge Detector, then we apply two successive morphological operations: Dilation to make the edges larger, and connect the parts that got disconnected after edge detection, then we use Erosion to thin the edges back to normal (a dilation followed by an erosion is usually called a Closing, and is used to fill holes that are smaller than the size of the kernel of those operations). Afterward, it is just a matter of finding all the contours and keeping the largest one, which will correspond to the Car Plug in the middle. This way, we also discard all the extra artifacts around the borders. Figure 3 below shows images of a Car Plug before and after this process.", "At this point, we may be thinking since color has no meaningful value, we might as well convert these images into grayscale. In the first approach based on classical machine learning algorithms, we will do just that. But for the following neural network-based one, we keep the 3 channels since we will make use of transfer learning.", "Before the era of deep learning, researchers used to manually craft feature extractors to characterize images. But what do we mean exactly by a feature extractor? In essence, it is a function that extracts a numeric representation of an image or a part of it and is designed to capture some of its distinguishing characteristics. Imagine we had an RGB image, consisting of three 2D matrices for each of the color channels with values between 0 and 255. We could quantize each of these matrices, into say 4 bins (0\u201363, 64\u2013127, 128\u2013191, 192\u2013255), where each bin contains the pixel values that are within the associated range. This way, we can represent a 2D matrix with a vector of 4 numeric values (x_1, x_2, x_3, x_4) where each x_k is the number of values in the matrix, that fall within bin number k. We can repeat this process for the 3 channels of the RGB image, and after concatenation, we would end-up with a vector of size 12 (4 bins * 3 channels) representing this image. We just created a simple feature extractor that captures color information of an image. Although simple in nature, you can actually use such technique for tasks where color is the most informative factor. Figure 4 shows this feature extractor in action. Notice how the higher bins of each image\u2019s dominant color are more distinguished in the feature vector. This representation definitely captures the differences between the three images.", "The academic community came up with a variety of manually designed feature extractors for different purposes over the years. A few important ones are HOG (Histogram of Oriented Gradients), SIFT (Scale Invariant Feature Transform), SURF (Speeded-Up Robust Features), LBP (Local Binary Patterns) etc. The main focus in the design process of these extractors, is to ensure robustness to certain properties of the images : scale, illumination, partial occlusion, rotation, distortion etc. These methods were a central pillar in traditional computer vision and lasted until the advent of deep learning, where they were essentially replaced by neural networks that can learn their own feature extraction mechanism in relation to the task they need to solve in an end-to-end manner. Unsurprisingly, this helped them yield superior results overall.", "Alright, enough chit-chat! So how can we use these feature extractors to solve our problem? First, we will discuss how they were traditionally used to solve standard image classification problems, then we shall present how I adapted this process to the multi-view task.", "Most Feature Extractors operate by first detecting key points of interest in an image, then producing a vector description for each key point. The descriptors are usually numeric vectors of a fixed size.", "Descriptors from all images are collected, and then clustered to come up with a set of prototypes (i.e. centroids) that act as a \u201cVocabulary of Visual Words\u201d. Then, we perform image quantization: we find the visual words in each image, and create the count feature vector, similar to how we would do it in the Bag Of Words approach typically encountered in text classification tasks. The steps of the process are detailed next :", "Because a picture is worth a thousand words, let us further explain this process through a simple flow diagram. Notice the keypoints detected (colored circles) on the grayscaled images after Step 1.", "Armed with this knowledge, we can come up with a way to adapt this approach to our multi-view classification problem. The change we need to introduce is actually very straightforward, and happens at step 3: Instead of extracting features from an image and turning them into a bag of words feature vector, we will extract features from all 8 images, then turn them into a single feature vector representing the Car Plug. If we were to apply the same approach to a multi-view text classification task (where a concept consisting of multiple texts needs to be classified), this would amount to combining the words found in all the texts related to the given concept, and then building the word occurrence feature vector. Figure 6 visualizes the process.", "Alright, now let us talk about some practicalities. Most of my decisions were made in an effort to optimize for both time and performance. In terms of feature extractors, SIFT is a pretty solid choice, but I actually used SURF which is basically a faster version of SIFT with relatively similar performance. For the dimension of SURF features, I chose 64 instead of 128 mainly to speed-up any training further down the line. I expect 128 to provide slightly better performance though. The resulting matrix had about 800K features of size 64. Choosing the number of clusters K in K-means was the next important decision. This is because K represents the number of visual words that will make up the columns of the final feature matrix. Oftentimes in such situations, the higher the value the better, but the law of diminishing returns applies, and past a certain point, the marginal improvement will not be worth the complexity increase. In my case, I opted for K=200, but values up to 800 are standard and should be experimented with. After this point, I just created the final feature matrix of size 833x200 (number of car plugs x number of clusters). Figure 7 shows two examples of feature vectors and one randomly selected image view for each plug.", "After training a Logistic Regression model, I ended up with around 87% of the weighted accuracy on average (the unweighted accuracy is easily in the 90\u201395% range). This is a pretty decent score, but can we do better? We can definitely try!", "This section is devoted to a custom neural network architecture to handle the multi-view problem. If we step back and take a second to think about the problem, how would we use a neural network to map our inputs to their class? Well, in a standard image classification problem, we\u2019d select the base of a popular CNN architecture (ResNet, Inception, VGG, etc.) as a feature extractor, then add a classifier block on top of it, consisting of one or multiple dense layers as a form of transfer learning. If we tried to use a similar principle in our multi-view image task, we could imagine creating the base block of the network (feature extractor) multiple times, one for each image view. This way, we extract features from all of the 8 images separately using transfer learning. However, we will still be left with the same question we had before: instead of having to combine the information from the images at the beginning, we delayed the matter, and now we have to combine the information from multiple sets of feature maps (i.e. the feature maps representing each view produced by the base CNNs). One way to deal with this problem is to stack those feature maps together. For example, if each view\u2019s feature maps had a shape of KxKxC, we could stack the 8 of them along the dimension of channels into one big set of feature maps of shape KxKx8C. Figure 8 illustrates this process.", "The problem with this approach, however we choose to stack, is that it assumes there is an order to the image views, when in fact there isn\u2019t one. If we stack the feature maps of the top view first, and bottom view last, then we are expected to do the same thing for each and every Car Plug. However, there is no reference specifying what is top for a Car Plug and what is bottom, we can consider any view to be any side. Or said otherwise, if we take two Car Plugs, and one view of the first one, there is no way to find the \u201cequivalent\u201d view in the second Car Plug. Thus, any assumption based on order should be avoided.", "We are left with a second option, to find an operation that combines information from multiple values into one. In turns out, in CNNs there is one such function, and we call it Pooling. We could use some form of Pooling across the dimension of Views, to combine 8 sets of feature maps into one of the same shape, thereby combining information from all image views. This is all good and well, but it\u2019s just a theoretical idea so far, is there any evidence that this can actually work ? Well, one such proof can be found in text classification, where we combine word embeddings of every word in a text into a single embedding by taking the average of all embeddings for example. We are trying to do something similar for our image views here. But perhaps, a better proof would be to find a paper that attempted such approach and that provides experimental results supporting it. A quick google search will reveal that there is one such paper (not the only one though), and it\u2019s conveniently called : Multi-View Convolutional Neural Networks for 3D Shape Recognition. Figure 9 shows the architecture proposed in the paper, which is almost exactly what we explained above.", "I implemented this MVCNN architecture in PyTorch and used a ResNet34 Base for the CNN1. After an Average View Pooling layer, I added a block on top, consisting of a series of Dense layers and Dropout regularization which I call the Classifier Block. For training, I initially fixed the base CNN1 and only trained the Classifier Block: this is typically called feature extraction in transfer learning. Then, I unfroze all the weights in the entire network, reduced the learning rate to a very low value, and trained the whole MVCNN end-to-end: this is referred to as fine-tuning in transfer learning. Ultimately, my weighted accuracy was hitting the 98% mark \u2026 pretty impressive, huh? Not so much actually. Aside from the weird performance metric and class imbalance, high scores should be expected because this task is arguably not very challenging for machine learning.", "Yeah, yeah I know you\u2019re probably here just for the code, and I\u2019m happy to oblige! You will find everything you need in this github repo: code. The notebook is well commented, but unfortunately, I cannot share the data. If you\u2019re keen on experimenting with the techniques proposed here, and you don\u2019t have a proper dataset, think of using the benchmark for multi-view image classification: ModelNet40. If you\u2019re more interested in the first approach, any normal image classification dataset would do.", "That\u2019s it for me folks, I hope you learned a thing or two. Don\u2019t hesitate to come back if you enjoyed the content, I\u2019ll be pushing more articles soon.", "[1] Su, Hang, et al. \u201cMulti-view convolutional neural networks for 3d shape recognition.\u201d Proceedings of the IEEE international conference on computer vision. 2015."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F427c69720f30&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@samy.tafasca?source=post_page-----427c69720f30--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Samy TAFASCA"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcfb7b85a39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=post_page-cfb7b85a39----427c69720f30---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F427c69720f30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----427c69720f30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F427c69720f30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=-----427c69720f30---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.stockfreeimages.com/121708322/Motor-Vehicle-Car-Automotive-Design-Vintage-Car.html#", "anchor_text": "Link"}, {"url": "https://github.com/SAMY-ER/Multi-View-Image-Classification", "anchor_text": "code"}, {"url": "https://modelnet.cs.princeton.edu", "anchor_text": "ModelNet40"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----427c69720f30---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/convolution-neural-net?source=post_page-----427c69720f30---------------convolution_neural_net-----------------", "anchor_text": "Convolution Neural Net"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----427c69720f30---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/feature-extraction?source=post_page-----427c69720f30---------------feature_extraction-----------------", "anchor_text": "Feature Extraction"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----427c69720f30---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F427c69720f30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----427c69720f30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F427c69720f30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----427c69720f30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F427c69720f30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=post_page-----427c69720f30--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcfb7b85a39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=post_page-cfb7b85a39----427c69720f30---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fcfb7b85a39%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----427c69720f30---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Written by Samy TAFASCA"}, {"url": "https://medium.com/@samy.tafasca/followers?source=post_page-----427c69720f30--------------------------------", "anchor_text": "55 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcfb7b85a39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=post_page-cfb7b85a39----427c69720f30---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fcfb7b85a39%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-view-image-classification-427c69720f30&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----427c69720f30---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/data-science-a-tour-of-prerequisites-7738c7c900aa?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Samy TAFASCA"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/data-science-a-tour-of-prerequisites-7738c7c900aa?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Data Science : A Tour Of PrerequisitesINTRODUCTION"}, {"url": "https://towardsdatascience.com/data-science-a-tour-of-prerequisites-7738c7c900aa?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "\u00b728 min read\u00b7Sep 15, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7738c7c900aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-a-tour-of-prerequisites-7738c7c900aa&user=Samy+TAFASCA&userId=cfb7b85a39&source=-----7738c7c900aa----0-----------------clap_footer----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/data-science-a-tour-of-prerequisites-7738c7c900aa?source=author_recirc-----427c69720f30----0---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7738c7c900aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-science-a-tour-of-prerequisites-7738c7c900aa&source=-----427c69720f30----0-----------------bookmark_preview----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----427c69720f30----1---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----427c69720f30----1-----------------bookmark_preview----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----427c69720f30----2---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----427c69720f30----2-----------------bookmark_preview----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": "15 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----3-----------------clap_footer----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----427c69720f30----3---------------------77d7054b_602f_488f_bd81_e3b71c1c0bc9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----427c69720f30----3-----------------bookmark_preview----77d7054b_602f_488f_bd81_e3b71c1c0bc9-------", "anchor_text": ""}, {"url": "https://medium.com/@samy.tafasca?source=post_page-----427c69720f30--------------------------------", "anchor_text": "See all from Samy TAFASCA"}, {"url": "https://towardsdatascience.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://conorosullyds.medium.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Conor O'Sullivan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Augmenting Images for Deep LearningUsing Python to augment data by flipping, adjusting brightness, color jitter and random noise"}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b712 min read\u00b7Nov 17, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&user=Conor+O%27Sullivan&userId=4ae48256fb37&source=-----3f1ea92a891c----0-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/augmenting-images-for-deep-learning-3f1ea92a891c?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f1ea92a891c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-images-for-deep-learning-3f1ea92a891c&source=-----427c69720f30----0-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://kennethleungty.medium.com/?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://kennethleungty.medium.com/?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Kenneth Leung"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Practical Guide to Transfer Learning in TensorFlow for Multiclass Image ClassificationClearly-explained step-by-step tutorial for implementing transfer learning in image classification"}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b714 min read\u00b7Dec 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd35fab7b28c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0&user=Kenneth+Leung&userId=dcd08e36f2d0&source=-----d35fab7b28c0----1-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/practical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd35fab7b28c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-guide-to-transfer-learning-in-tensorflow-for-multiclass-image-classification-d35fab7b28c0&source=-----427c69720f30----1-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----427c69720f30----0---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----427c69720f30----0-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Determining the Right Batch Size for a Neural Network to Get Better and Faster ResultsGuidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b74 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----7a8662830f15----1-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----427c69720f30----1---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&source=-----427c69720f30----1-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----427c69720f30----2---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----427c69720f30----2-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Aaweg-I"}, {"url": "https://medium.com/aaweg-i-nterview?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Aaweg Interview"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "Can you explain Jaccard\u2019s Index? How does it differ from Dice Coefficient?In object detection, there are two distinct tasks to measure:"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": "\u00b76 min read\u00b7Nov 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faaweg-i-nterview%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&user=Aaweg-I&userId=5a024f90bf10&source=-----861c4a496b2b----3-----------------clap_footer----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----427c69720f30----3---------------------726afd34_dcf8_416b_82d6_ec8ecbac0692-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&source=-----427c69720f30----3-----------------bookmark_preview----726afd34_dcf8_416b_82d6_ec8ecbac0692-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----427c69720f30--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----427c69720f30--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}