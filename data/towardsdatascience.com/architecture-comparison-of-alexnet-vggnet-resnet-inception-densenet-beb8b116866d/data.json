{"url": "https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d", "time": 1683004575.1002371, "path": "towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d/", "webpage": {"metadata": {"title": "Architecture comparison of AlexNet, VGGNet, ResNet, Inception, DenseNet | by Khush Patel | Towards Data Science", "h1": "Architecture comparison of AlexNet, VGGNet, ResNet, Inception, DenseNet", "description": "AlexNet is the first large scale convolutional neural network architecture that does well on ImageNet classification. AlexNet was entered into the competition and was able to outperform all previous\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.khushpatel.com", "anchor_text": "http://www.khushpatel.com", "paragraph_index": 33}], "all_paragraphs": ["Hello readers, If you are looking for a perfect guide to get all the information about AlexNet, VGGNet, ResNet, Inception and DenseNet then you are at the correct place. Read the blog carefully and you will get the detailed information regarding all the architecture. Enjoy !!!", "AlexNet is the first large scale convolutional neural network architecture that does well on ImageNet classification. AlexNet was entered into the competition and was able to outperform all previous non-deep learning-based models by a significant margin.", "AlexNet architecture is a conv layer followed by pooling layer, normalization, conv-pool-norm, and then a few more conv layers, a pooling layer, and then several fully connected layers afterwards. Actually looks very similar to the LeNet network. There are just more layers in total. There are five of these conv layers, and two fully connected layers before the final fully connected layer going to the output classes.", "AlexNet was trained on ImageNet, with inputs at a size 227 x 227 x 3 images. If we look at this first layer which is a conv layer for the AlexNet, it\u2019s 11 x 11 filters, 96 of these applied at stride 4. I had 55 x 55 x 96 in the output and 35K parameters in this first layer. The second layer is a pooling layer and in this case, we have 3 filters of 3 x 3 applied at stride 2. The output volume of the pooling layer is 27 x 27 x 96 with and 0 parameter to learn. The pooling layer does not learn anything because the parameters are the weights which trying to learn. Convolutional layers have weights that we learn but pooling all we do is have a rule, we look at the pooling region, and we take the max. So there are no parameters that are learned.", "There are 11 x 11 filters at the beginning, then five by five and some three by three filters. In the end, we have a couple of fully connected layers of size 4096 and finally, the last layer, is FC8 going to the softmax, which is going to the 1000 ImageNet classes. This architecture is the first use of the ReLu non-linearity.", "This architecture is the first use of the ReLU non-linearity. AlexNet uses a layer of normalization also. In data augmentation, ALexNet used flipping, jittering, cropping, colour normalization and these things. Other parameters are Dropout with 0.5, SGD + Momentum with 0.9, initial learning rate 1e-2 and again reduced by 10 when validation accuracy become flat. The regularization used in this network is L2 with a weight decay of 5e-4. It was trained on GTX580 GPU which contains 3GB of memory.", "It has an error rate of 16.4 in the ImageNet Large Scale Visual Recognition Challenge(ILSVRC).", "AlexNet was the winner of the ImageNet Large Scale Visual Recognition Challenge(ILSVRC) classification the benchmark in 2012.", "In 2014 there are a couple of architectures that were more significantly different and made another jump in performance, and the main difference with these networks with the deeper networks.", "VGG 16 is 16 layer architecture with a pair of convolution layers, poolings layer and at the end fully connected layer. VGG network is the idea of much deeper networks and with much smaller filters. VGGNet increased the number of layers from eight layers in AlexNet. Right now it had models with 16 to 19 layers variant of VGGNet. One key thing is that these models kept very small filters with 3 x 3 conv all the way, which is basically the smallest conv filter size that is looking at a little bit of the neighbouring pixels. And they just kept this very simple structure of 3 x 3 convs with the periodic pooling all the way through the network.", "VGG used small filters because of fewer parameters and stack more of them instead of having larger filters. VGG has smaller filters with more depth instead of having large filters. It has ended up having the same effective receptive field as if you only have one 7 x 7 convolutional layers.", "VGGNet has conv layers and a pooling layer a couple more conv layers, pooling layer, several more conv layers and so on. VGG architecture has the 16 total number of convolutional and fully connected layers. It has 16 in this case for VGG 16, and then 19 for VGG 19, it\u2019s just a very similar architecture, but with a few more conv layers in there.", "So this is quite costly computations with 138M total Parameter and each image has a memory of 96MB which is so much large than a regular image. It has just a 7.3 error rate in the ILSVRC challenge.", "VGGNet was the runner up of the ImageNet Large Scale Visual Recognition Challenge(ILSVRC) classification the benchmark in 2014.", "The main base element of ResNet is the residual block. As we go deeper into the network with a large number of layers, computation becomes more complex. These layers put on top of each other and every layer try to learn some underlying mapping of the desired function and instead of having these blocks, we try and fit a residual mapping.", "Here on this right where the input to these blocks is just the input coming in whereas on the other side, we\u2019re going to use our layers to try and fit some residual of our H(X) - X instead of the desired function H(X) directly. So basically, at the end of this block it takes the skip connection on this right here, where it just takes the input and pass it through as an identity, and so if it had no weight layers in between it was just going to be the identity. It would be the same thing as the output, but now we use additional weight layers to learn some delta, for some residual from our X.", "In nutshell, as we go deeper into the network it is so hard to learn H(X) as we have a large number of layers. So here we used skip connection and learning F(x) direct input of x as the final output. So F(x) is called as a Residual.", "In ResNet, stacks all these blocks together very deeply. Another thing with this very deep architecture is that it is enabling up to 150 layers deep of this, and then what we do is we stack all these layers periodically. We also double the number of filters and downsample spatially using stride two. In the end, only fully connected layer 1000 to output classes.", "In ResNet, it uses Batch Normalization after every conv layer. It also uses Xavier initialization with SGD + Momentum. The learning rate is 0.1 and is divided by 10 as validation error becomes constant. Moreover, batch-size is 256 and weight decay is 1e-5. The important part is there is no dropout is used in ResNet.", "ResNet secured 1st Position in ILSVRC and COCO 2015 competition with just error rate of 3.6% of error rate. (Better than Human Performance !!!)", "Inception v3 is a widely-used image recognition model that has been shown to attain greater than 78.1% accuracy on the ImageNet dataset. The model is the combination of many ideas developed by multiple researchers over the years.", "The model itself is made up of symmetric and asymmetric building blocks, including convolutions, average pooling, max pooling, dropouts, and fully connected layers. Batchnorm is used extensively throughout the model and applied to activation inputs. Loss is computed via Softmax.", "Inception work with Factorizing Convolutions. Factorizing Convolutions used to reduce the number of connections and parameters to learn. This will increase the speed and gives a good performance.", "GoogleNet used a 5x5 convolution layer whereas in inception work with two 3x3 layers to reduce the number of learning parameters. In 5 x 5 has 25 total parameters were 3 x 3 + 3 x 3 has total 18 parameters to learn. So significantly no learning parameter is reduced by 28%.", "Factorization Into Asymmetric Convolutions is also used in Inception which also helps to help to reduce the learning parameter.", "One 3\u00d71 convolution followed by one 1\u00d73 convolution replaces one 3\u00d73. In one 3 x 3 has a total of 9 parameter whereas, 3 x 1 + 1 x 3 has a total of 6 parameters so it will reduce by 33%. This method is less likely to overfit the model as you go mode deeper in the training. [4]", "With 42 layers deep, the computation cost is only about 2.5 higher than that of GoogleNet and much more efficient than that of VGGNet.", "Inception-v3 with 144 crops and 4 models ensembled, the top-5 error rate of 3.58% is obtained, and finally obtained 1st Runner Up (image classification) in ILSVRC 2015.", "DenseNet is composed of Dense blocks as shown below. Within those blocks, the layers are densely connected together: Each layer gets the input from previous layers output feature maps. This extreme reuse of residuals creates deep supervision because every layer receives more supervision from the previous layer and thus loss function will react accordingly and due to this methodology, it makes it a more powerful network.", "2. Transition layer: In ResNet sum of residual will be performed, instead of summing residual Densenet concatenates all the feature maps. This layer is made of", "Basically, Densenet\u2019s convolution generates less number of feature maps. DenseNet has a lower need for wide layers because as layers are densely connected there is little redundancy in the learned features. Layers of dense block share a piece of collective knowledge. The number of output feature maps of a layer is defined as the growth rate. Eventually, the growth rate controls how much new information each layer contributes to the globally.", "In a nutshell, the DenseNet architecture uses the residual mechanism to its maximum by making every layer densely connected to its subsequent layers. Model\u2019s compactness makes the learned features non-redundant as they are all shared through a collective knowledge. To train deep networks that are densely connected because of implicit deep supervision where the gradient is flowing back more easily due to short connections.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Engineer / Data Scientist | Master\u2019s in AI | DL & CV Nanodegree Holder | Facebook AI Scholar | Inventor | Int\u2019l Medal Winner@USA | http://www.khushpatel.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbeb8b116866d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ikhushpatel.medium.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": ""}, {"url": "https://ikhushpatel.medium.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Khush Patel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6bf5eabb8e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&user=Khush+Patel&userId=e6bf5eabb8e3&source=post_page-e6bf5eabb8e3----beb8b116866d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.techleer.com/articles/259-concepts-of-advanced-deep-learning-architectures/", "anchor_text": "https://www.techleer.com/articles/259-concepts-of-advanced-deep-learning-architectures/"}, {"url": "https://mc.ai/alexnet-review-and-implementation/", "anchor_text": "https://mc.ai/alexnet-review-and-implementation/"}, {"url": "http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture09.pdf", "anchor_text": "http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture09.pdf"}, {"url": "https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/", "anchor_text": "https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/"}, {"url": "https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c", "anchor_text": "https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c"}, {"url": "https://medium.com/tag/object-detection?source=post_page-----beb8b116866d---------------object_detection-----------------", "anchor_text": "Object Detection"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----beb8b116866d---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----beb8b116866d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/convolution-neural-net?source=post_page-----beb8b116866d---------------convolution_neural_net-----------------", "anchor_text": "Convolution Neural Net"}, {"url": "https://medium.com/tag/cnn?source=post_page-----beb8b116866d---------------cnn-----------------", "anchor_text": "Cnn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&user=Khush+Patel&userId=e6bf5eabb8e3&source=-----beb8b116866d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&user=Khush+Patel&userId=e6bf5eabb8e3&source=-----beb8b116866d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbeb8b116866d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----beb8b116866d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----beb8b116866d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----beb8b116866d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----beb8b116866d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----beb8b116866d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----beb8b116866d--------------------------------", "anchor_text": ""}, {"url": "https://ikhushpatel.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ikhushpatel.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Khush Patel"}, {"url": "https://ikhushpatel.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "316 Followers"}, {"url": "http://www.khushpatel.com", "anchor_text": "http://www.khushpatel.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6bf5eabb8e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&user=Khush+Patel&userId=e6bf5eabb8e3&source=post_page-e6bf5eabb8e3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6fcd0f51883a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Farchitecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d&newsletterV3=e6bf5eabb8e3&newsletterV3Id=6fcd0f51883a&user=Khush+Patel&userId=e6bf5eabb8e3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}