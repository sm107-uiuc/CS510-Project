{"url": "https://towardsdatascience.com/fairness-metrics-wont-save-you-from-stereotyping-27127e220cac", "time": 1683017209.090751, "path": "towardsdatascience.com/fairness-metrics-wont-save-you-from-stereotyping-27127e220cac/", "webpage": {"metadata": {"title": "Fairness Metrics Won\u2019t Save You from Stereotyping | by Valerie Carey | Towards Data Science", "h1": "Fairness Metrics Won\u2019t Save You from Stereotyping", "description": "Fairness metrics are often used to verify that machine learning models do not produce unfair outcomes across racial/ethnic groups, gender categories, or other protected classes. Here, I will\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.ecommercetimes.com/story/86351.html", "anchor_text": "Apple Card Algorithm May Tilt Favorably Toward Men", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/explaining-measures-of-fairness-f0e419d4e0d7", "anchor_text": "Explaining Measures of Fairness", "paragraph_index": 38}], "all_paragraphs": ["Fairness metrics are often used to verify that machine learning models do not produce unfair outcomes across racial/ethnic groups, gender categories, or other protected classes. Here, I will demonstrate that, whatever usefulness such metrics might have in identifying other types of bias, they are unable to detect one major form of algorithmic discrimination: stereotyping. In fact, the behavior of fairness metrics is essentially identical whether a model bases its decisions on arguably reasonable factors, or stereotypes due to inclusion of a sensitive feature or a proxy for such a feature.", "Here is a current example. Recently, Apple and Goldman Sachs were accused of sexism in their credit decisions for the Apple Card [1,2]. As far as I know, there are no official answers about whether these accusations were justified, or what the cause of any issue might have been; the matter is still under investigation. However, some possible explanations have been discussed in the media. The speculations I\u2019ve heard tend to fall into 2 major categories:", "These 2 scenarios are very different in terms of fairness. Whatever concerns there may be about scenario 1, scenario 2 is much worse.", "Scenario 1 involves decisions based on income, which may be an appropriate basis for credit determination, even if outcomes are unequal. Personally, I\u2019ve experienced gender-based discrimination, but I don\u2019t see how an Apple card would help me with that. A trendy credit card can\u2019t replace lost income, and having money seems like a necessary condition for paying back a loan.", "Scenario 2 is likely to occur when female status is correlated with loan default due to a confounding feature. Lower average salaries for women would lead to such a correlation. But, basing decisions on typical incomes by gender ensures that all women are disadvantaged due to workplace discrimination that may have been experienced by only some of us. If we assume that all women have lower incomes, we will deny credit even to women who have been spared, or who have overcome, workplace discrimination. This kind of model takes pre-existing discrimination and amplifies it so that it becomes even more widespread. (Stereotyping risk is a reason that including sensitive features such as race or sex in models is widely discouraged, or even illegal in some scenarios.)", "Stereotyping is not the only possible source of unfairness in machine learning models, but it is an insidious one. Our models are designed to estimate population risks, with similar people receiving similar scores. In the context of machine learning, \u201csimilar\u201d means comparable values of the features included in the data (weighted by predictive power). Models are designed to generalize; there is always variation in individuals with the same \u201crisk score\u201d, but, when decisions are made, all people with the same score will receive the same treatment. It may be acceptable if people with similar incomes and debt levels are treated as indistinguishable, but a model can consider sex, race, or other characteristics to be relevant similarities, especially if these are correlated with actual outcomes.", "The usual strategy for mitigating stereotyping risk for machine learning models is to examine input features and verify that (1) sensitive features are not incorporated, and (2) obvious proxies for these are not included in the model. However, less obvious proxies may well occur, especially in a data set with many features.", "Here I\u2019ll use example data to simulate this issue, and to demonstrate that fairness metrics can\u2019t distinguish stereotyping from a decision based on an arguably reasonable factor. Therefore, detection of stereotyping requires a different approach.", "Demonstration code can be found on GitHub [3]. I use a simplified public loans data set [4], which does not contain any gender information (although the source data presumably includes multiple genders). This data contains loan information with default (\u201cbad loan\u201d) status and 13 predictors, which include income, features related to debt load, loan amount, and employment length, and US state of residence (which I group into regions).", "I artificially impose a simplified concept of \u201cgender\u201d on this data set, for simplicity considering only \u201cmale\u201d and \u201cfemale\u201d classes, separated based on income. I assume lower-income borrowers are more likely to be female, and higher-income borrowers more likely to be male. My assignment greatly exaggerates income inequality in the US, with the income of \u201cfemales\u201d about half that of males ($38k vs. $74k), but (importantly) retaining significant overlap between the male and female groups. Because the loans data set contains people with mostly relatively high incomes, \u201cfemales\u201d make up only about 26% of loans. Although my simulation unrealistic, it gives us a very clear contrast which is useful as an example and is relevant for situations where representation is unequal.", "I create two data sets to illustrate different decision bases. The first is just the original data set. The second removes the income feature and replaces it with my inferred \u201cgender\u201d feature (female indicator). I then build an XGBoost classification model for each data set and calculate fairness for my artificial gender groups. Using this process, I hope to illustrate 2 decision paths, one based on income and other features (Model A), and another which has the potential to base decisions on gender (Model B).", "Examining global feature importances show that income is the most important feature in Model A, while gender (a less detailed feature) is of lesser importance in Model B. However, gender does still appear to be an important feature, indicating that Model B uses this factor make predictions.", "The question now is, to what extent can common fairness metrics distinguish Model A (income-based decisions) from Model B (gender-based decisions)? Spoiler alert: They can\u2019t.", "In recent years, attention has been devoted to the development of \u201cfairness metrics\u201d, which promise to detect bias in models. Typically, these are post-hoc tests, with values calculated separately for groups of interest; differences in values are thought to indicate unfairness. There are numerous fairness metrics, and many of these cannot be mutually satisfied [4]. Here I will discuss some of the more common ones used for binary classification.", "One common test of fairness is simply whether a model\u2019s binary yes/no prediction is similar across groups.", "The actual outcomes vary by \u201cgender\u201d, as might be expected because I have preferentially sorted low-income buyers into the artificial \u201cfemale\u201d category. Both model predictions reproduce actual rates fairly well. Importantly, Model A and Model B look very similar to each other!", "A calibration test for fairness examines whether the relationship between actual and predicted risk is similar across groups. One common assessment is to create decile groups from model probability outputs. How do Models A and B fare in this test?", "We see above that the male and female curves lie on top of each other, indicating that both models appear calibrated with respect to gender. Again, Models A and B show similar results.", "False positive/ false negative rate tests are satisfied when these rates are similar across groups. Importantly, these tests are expected to fail for a calibrated model where actual outcomes vary by group [REF], as is the case for our models. But, can these distinguish model A from B?", "As expected, both tests fail for both models. False positive rates are high for females overall, as they tend to have risk scores near the decision boundary, while false negative rates are high for males who default rarely. In general, error rates for Model B are slightly higher than Model A, as expected given that raw income is a stronger predictor than the correlated but much less detailed gender feature. However, there is no strong pattern distinguishing Model A from Model B. Both models fail both tests with similar patterns.", "Another category of fairness metrics address whether model performance is similar across groups. Any performance metric can be used. Below I show accuracy and f1 scores:", "Accuracy is higher for males, partly because the default assumption of no default is more often correct for them. In addition, males are the majority group (~74% of loans). However, the f1 score, which reflects separation in the positive class, is higher for females, probably reflecting a greater number of very high-risk loans in this group. In any case, the general behavior of these metrics is again the same for both models", "The chart below summarizes metric results for both models:", "As we can see, the pass/fail pattern is identical for Models A and B, although Model A bases its decision on income, and Model B leverages gender stereotypes. One conclusion is that metrics are useless in preventing stereotyping. Certainly, fairness metrics can\u2019t detect stereotyping.", "In my opinion, fairness metrics are not helpful when used to \u201cprove\u201d that bias does or does not exist. However, they are very useful when considered as one piece of evidence among many that direct an investigation down certain paths. Fairness metrics help get us oriented to potential risks, and provide evidence that may support or contradict our understanding of our model. Here, the pattern of fairness metrics is very much as expected, or the best that is possible, when we have an actual outcome that varies by sex and the model reproduces the actual distribution.", "Since fairness metrics don\u2019t detect stereotyping, must we rely on existing methods of examining input features for obvious proxy effects? My model B included a feature explicitly called \u201cfemale\u201d, which may be an obvious red flag. However, I could have named this feature something else, or could have created an intermediate feature correlated with both income and \u201cgender\u201d; in other words, this feature does not have to be an obvious proxy for the conclusions to hold.", "Fortunately, we can leverage explainability techniques to isolate features that contribute to group differences. We narrow our investigations to specific features and proceed with additional tests.", "I am following a process for explaining group differences which has been described by Scott Lundberg [6]. However, I make a modification: I use one sex (males) as the reference population, or \u201cfoil\u201d, and generate contrastive explanations for individuals of the other sex (females). Using such a foil simplifies the analysis and may be especially helpful in cases when groups are imbalanced.", "Shapley explanations (\u201cphi values\u201d) distribute model results across input features. The phi values reflect the marginal contributions of each feature to the overall model score by calculating the change in outcome for a given feature value vs. a value randomly drawn from the reference population, averaged over combinations of the other features. When probabilities are allocated by Shapley, the sum of the phi values is the total probability difference between an individual score and the mean score for the foil data. Individual phi values can then be summed to identify features that contribute to overall population differences [6].", "The following plots show the results of this analysis for a sample of female loan recipients for our two models:", "In both models, the technique isolates the exact features that (by design) I expect to drive sex differences! Model A predicts females default more based on the income feature, while for Model B the major determinant is female status. The pattern is very clear, even though income (and therefore female status) have fairly strong correlations with other features such as loan amount and number of credit accounts. And we can see a clear difference between the models, namely the features on which decisions are based.", "It wasn\u2019t guaranteed we would highlight these exact features in the Shapley plots. Income is a very strong overall predictor, which makes it more likely to be used in decisions. If income were a weaker predictor, but correlated with a stronger predictor, that stronger feature may have popped out in the plots. That would have been fine, however, as we need to explain how our model makes decisions, regardless of the construction of the data.", "At this point, we have a lot of information relevant to assessing stereotyping risks. Instead of scrutinizing every feature as a potential proxy, we have isolated key features for additional testing. Even inspection of the features provides information. We can ask follow-up questions such as, \u201cis the feature something with a known causal relationship to our outcome?\u201d, or \u201chow did we calculate this feature, and what is the source of the information\u201d. Or perhaps the most important question, \u201cis this feature important enough to our goal to justify the group differences it generates?\u201d", "Additional tests are possible to examine whether the feature or features obtained by this Shapley-based analysis are likely to be independently associated with the outcome, or a proxy for race or gender; such tests can also help uncover label or feature bias. I hope to discuss some of these in a later article.", "The behavior of commonly-used fairness metrics is similar whether a model basis its decisions on an appropriate predictor or on an incidental feature (such as race or sex) that happens to be correlated with a predictor. Explainability techniques can identify features driving group differences and help distinguish unfair outcomes from justifiable decisions.", "A data scientist is seldom called on to decide what is fair or appropriate. Instead, our role is to understand how our models work and assess them for potential risks. We need to be able to test models, fully understand mechanisms underlying group differences, and communicate those results to stakeholders, regulators, and possibly the public.", "An analysis that focuses solely on metrics can miss important categories of bias. In the case of stereotypes, AKA proxy variables or \u201cstatistical discrimination\u201d, we take pre-existing societal biases and impose those even on people who managed to escape discrimination. Our algorithms have the capacity not only to continue the status quo, but to create additional victims. We data scientists have the responsibility to detect and measure such risks, and therefore must examine decision bases in addition to metrics.", "[1] J. M. Germain, Apple Card Algorithm May Tilt Favorably Toward Men (2019), E-Commerce Times.", "[6] Scott Lundberg, Explaining Measures of Fairness (2020), Towards Data Science.", "Data Scientist /business analyst. In love with all things analytics. Interested in AI ethics, credibility, trust. All opinions are my own."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F27127e220cac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/fairness-and-bias", "anchor_text": "Fairness and Bias"}, {"url": "https://medium.com/@vla6?source=post_page-----27127e220cac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Valerie Carey"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a7c9171898f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=post_page-1a7c9171898f----27127e220cac---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27127e220cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=-----27127e220cac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27127e220cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=-----27127e220cac---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@mitchel3uo", "anchor_text": "Mitchell Luo"}, {"url": "http://unsplash.com", "anchor_text": "Unsplash"}, {"url": "http://www.ecommercetimes.com/story/86351.html", "anchor_text": "Apple Card Algorithm May Tilt Favorably Toward Men"}, {"url": "https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/", "anchor_text": "The Apple Card Didn\u2019t \u2018See\u2019 Gender \u2014 and That\u2019s the Problem"}, {"url": "https://github.com/vla6/Stereotyping_ROCDS", "anchor_text": "https://github.com/vla6/Stereotyping_ROCDS"}, {"url": "https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv", "anchor_text": "https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv"}, {"url": "https://arxiv.org/abs/1709.02012", "anchor_text": "On Fairness and Calibration"}, {"url": "https://towardsdatascience.com/explaining-measures-of-fairness-f0e419d4e0d7", "anchor_text": "Explaining Measures of Fairness"}, {"url": "https://medium.com/tag/classification?source=post_page-----27127e220cac---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/interpretability?source=post_page-----27127e220cac---------------interpretability-----------------", "anchor_text": "Interpretability"}, {"url": "https://medium.com/tag/fairness-and-bias?source=post_page-----27127e220cac---------------fairness_and_bias-----------------", "anchor_text": "Fairness And Bias"}, {"url": "https://medium.com/tag/shapley?source=post_page-----27127e220cac---------------shapley-----------------", "anchor_text": "Shapley"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27127e220cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=-----27127e220cac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27127e220cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=-----27127e220cac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27127e220cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=post_page-----27127e220cac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a7c9171898f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=post_page-1a7c9171898f----27127e220cac---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F39643260a9d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&newsletterV3=1a7c9171898f&newsletterV3Id=39643260a9d4&user=Valerie+Carey&userId=1a7c9171898f&source=-----27127e220cac---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Written by Valerie Carey"}, {"url": "https://medium.com/@vla6/followers?source=post_page-----27127e220cac--------------------------------", "anchor_text": "799 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a7c9171898f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&user=Valerie+Carey&userId=1a7c9171898f&source=post_page-1a7c9171898f----27127e220cac---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F39643260a9d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffairness-metrics-wont-save-you-from-stereotyping-27127e220cac&newsletterV3=1a7c9171898f&newsletterV3Id=39643260a9d4&user=Valerie+Carey&userId=1a7c9171898f&source=-----27127e220cac---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-fix-feature-bias-9e47abccb942?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Valerie Carey"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-fix-feature-bias-9e47abccb942?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "How to Fix Feature BiasChoosing a strategy requires testing and tradeoffs"}, {"url": "https://towardsdatascience.com/how-to-fix-feature-bias-9e47abccb942?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "12 min read\u00b7Feb 8, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e47abccb942&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-fix-feature-bias-9e47abccb942&user=Valerie+Carey&userId=1a7c9171898f&source=-----9e47abccb942----0-----------------clap_footer----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-fix-feature-bias-9e47abccb942?source=author_recirc-----27127e220cac----0---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e47abccb942&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-fix-feature-bias-9e47abccb942&source=-----27127e220cac----0-----------------bookmark_preview----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----27127e220cac----1---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----27127e220cac----1-----------------bookmark_preview----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----27127e220cac----2---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----27127e220cac----2-----------------bookmark_preview----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/what-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Valerie Carey"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/what-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "What (Not) To Say When Your Client Questions Your ResultsUse these pivotal moments to build trust and understanding"}, {"url": "https://towardsdatascience.com/what-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": "\u00b712 min read\u00b7Jul 19, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a5481ff6ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6&user=Valerie+Carey&userId=1a7c9171898f&source=-----6a5481ff6ea6----3-----------------clap_footer----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/what-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6?source=author_recirc-----27127e220cac----3---------------------36030d44_272d_46fd_9a9a_c6b01c972cc5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a5481ff6ea6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-not-to-say-when-your-client-questions-your-results-6a5481ff6ea6&source=-----27127e220cac----3-----------------bookmark_preview----36030d44_272d_46fd_9a9a_c6b01c972cc5-------", "anchor_text": ""}, {"url": "https://medium.com/@vla6?source=post_page-----27127e220cac--------------------------------", "anchor_text": "See all from Valerie Carey"}, {"url": "https://towardsdatascience.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----27127e220cac----0-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----27127e220cac----1-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----0-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----27127e220cac----0---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----27127e220cac----0-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----27127e220cac----1---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----27127e220cac----1-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----2-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----27127e220cac----2---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----27127e220cac----2-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@dimitris.effrosynidis?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/@dimitris.effrosynidis?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Dimitris Effrosynidis"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "Ensemble Feature Selection for Machine LearningSelect the best features by combining individual feature selection methods"}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": "\u00b75 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0df77b970f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fensemble-feature-selection-for-machine-learning-c0df77b970f9&user=Dimitris+Effrosynidis&userId=ff294d269093&source=-----c0df77b970f9----3-----------------clap_footer----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----27127e220cac----3---------------------0567660f_b24c_4e4b_bb9d_fd784f1788e1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0df77b970f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fensemble-feature-selection-for-machine-learning-c0df77b970f9&source=-----27127e220cac----3-----------------bookmark_preview----0567660f_b24c_4e4b_bb9d_fd784f1788e1-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----27127e220cac--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----27127e220cac--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}