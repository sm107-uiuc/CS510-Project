{"url": "https://towardsdatascience.com/accurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4", "time": 1683011968.8025842, "path": "towardsdatascience.com/accurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4/", "webpage": {"metadata": {"title": "Accurately Labeling Subjective Question-Answer Content Using BERT | by Zhe Sun | Towards Data Science", "h1": "Accurately Labeling Subjective Question-Answer Content Using BERT", "description": "Kaggle released Q&A understanding competition at the beginning of 2020. This competition asks each team to build NLP models to predict the subjective ratings of question and answer pairs. We finished\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/google-quest-challenge/overview", "anchor_text": "Q&A understanding competition", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/130243", "anchor_text": "a winning solution blog", "paragraph_index": 0}, {"url": "https://github.com/robinniesert/kaggle-google-quest", "anchor_text": "this", "paragraph_index": 0}, {"url": "https://www.sun-analytics.nl/posts/2020-08-04-accurately-labeling-subjective-question-answer-content-using-bert/", "anchor_text": "blog", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient", "anchor_text": "Spearman\u2019s rank correlation coefficient", "paragraph_index": 4}, {"url": "https://jalammar.github.io/illustrated-transformer/", "anchor_text": "here", "paragraph_index": 8}, {"url": "http://jalammar.github.io/illustrated-bert/", "anchor_text": "here", "paragraph_index": 8}, {"url": "http://mccormickml.com/2019/07/22/BERT-fine-tuning/", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://www.kaggle.com/aerdem4/qa-use-save-model-weights", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://github.com/robinniesert/kaggle-google-quest/tree/master/models", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://huggingface.co/models", "anchor_text": "Huggingface", "paragraph_index": 12}, {"url": "https://huggingface.co/transformers/model_doc/roberta.html", "anchor_text": "Roberta", "paragraph_index": 12}, {"url": "https://huggingface.co/transformers/model_doc/xlnet.html", "anchor_text": "XLNet", "paragraph_index": 12}, {"url": "https://huggingface.co/transformers/model_doc/albert.html", "anchor_text": "Albert", "paragraph_index": 12}, {"url": "https://huggingface.co/transformers/model_doc/bert.html", "anchor_text": "BERT", "paragraph_index": 12}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html", "anchor_text": "GroupKFold", "paragraph_index": 18}, {"url": "http://sun-analytics.nl", "anchor_text": "sun-analytics.nl", "paragraph_index": 24}], "all_paragraphs": ["Kaggle released Q&A understanding competition at the beginning of 2020. This competition asks each team to build NLP models to predict the subjective ratings of question and answer pairs. We finished it with 6th place in all 1571 teams. Apart from a winning solution blog posted in Kaggle, we write this more beginner friendly tutorial to introduce the competition and how we won the gold medal. We also open source our code in this Github repository. You can also find this article in my blog.", "The competition collects question and answer pairs from 70 Stack-Overflow-like websites, Question title, body and answer as text features, also some other features such as url, user id. The target labels are 30 dimensions with values between 0 and 1 to evaluate questions and answer such as if the question is critical, if the answer is helpful, etc. The raters received minimal guidance and training, and the target relied largely on their subjective interpretation. In other words, the target score is simply from raters common-sense. The target variables were the result of averaging the classification of multiple raters. i.e. if there are four raters, one classifies it a positive and the other three as a negative, the target value will be 0.25.", "Here is an example of the question", "The training and test set are distributed as below", "Spearman\u2019s rank correlation coefficient is used as the evaluation metrics in this competition.", "Intuitively, Pearson correlation is a measure of linear correlation of X and Y. For Spearman\u2019s rank correlation, instead of using the value of X and Y, we use the ranking of X and Y in the formula. It is a measure of the monotonic relationship between X and Y. As the figure shown, the data given in the chart, pearson is 0.88 and spearman is 1.", "Why was spearman used in this kaggle competition? Considering the subjective and noisy nature of the labels, Spearman correlation tends to be more robust to outliers as for instance pearson correlation. Also, because the target value is an understanding of question and answer based on rater\u2019s common sense. Suppose we have 3 answers and we evaluate if the answers are well-written. answer A has score 0.5, answer B has score 0.2 and answer C is 0.1, If we claim answer A is 0.3 better than answer B, does it make sense? Not really. Here, we do not need the accurate value difference. It is just enough to know A is better than B and B is better than C.", "A general NLP pipeline is shown as the figure above. And a typical non-neural network-based solution could be:", "Due to the emergence of transformer and BERT in 2017 and 2018, NLP has been experiencing an \u201cImageNet\u201d moment. BERT has become the dominant algorithm for NLP competitions. In this blog, we do not introduce BERT. There are several good tutorials such as here, here and here.", "Now, we can restructure the NLP pipeline by using BERT:", "As illustrated in the figure below, we use four BERT-based models and a Universal Sentence Encoder model as base models, then stack them to generate the final result. In the rest of this blog, we will only focus on the transformer/BERT models. For more information of Universal Sentence Encoder, you can visit the original paper here, and the code is available here.", "The animation below shows how one base model works. The codes are here.", "Huggingface packages most state-of-the-art NLP models Pytorch implementations. In our solution, 4 BERT based models implemented by Huggingface are selected. They are Siamese Roberta base, Siamese XLNet base, Double Albert base V2, Siamese BERT base uncased.", "We have two stage training. Stage 1 is an end-to-end parameter tuning, and stage 2 only tunes the \u201chead\u201d.", "Stacking is the \u201cde-facto\u201d ensemble strategy for kagglers. The animations below illustrate the training and prediction procedure. there are 3 folds in the example. To get the meta training data for each fold, we train iteratively on 2 folds and predict on the remaining fold. And the whole out-of-fold prediction is used as features. Then, we train the stacking model.", "In the prediction stage, we input the test data to all out-of-fold base models to get the predictions. Then, we average the results, pass to the stacking model to get the final prediction.", "Let us first have a look why normal KFold split does not work well in this competition. In the dataset, some samples were collected from one question-answer thread, which means multiple samples share the same question title and body but with different answers.", "If we use a normal KFold split function, answers to the same questions will be distributed in both training set and test set. This will bring an information leakage problem. A better split is to put all question/answer pairs from the same question together in either the training set or the test set.", "Fortunately, sk-learn has provided a function GroupKFold to generate non-overlapping groups for cross validation. Question body field is used to indicate the group, as the code below.", "As many other teams did, one post-processing step had a massive impact on the performance. The general idea is based on rounding predictions downwards to a multiple of some fraction 1/d.", "In our ensemble we exploited this technique even further, applying the rounding first to individual model predictions and again after taking a linear combination of model predictions. In doing so we did find that using a separate rounding parameter for each model, out-of-fold score improvements would no longer translate to leaderboard. We addressed this by reducing the number of rounding parameters using the same d_local across all models:", "All ensembling parameters \u2014 2 rounding parameters and model weights \u2014 were set using a small grid search optimising the spearman rank correlation coefficient metric on out-of-fold while ignoring question targets for rows with duplicate questions. In the end, this post-processing improved our 10 fold GroupKFold CV by ~0.05.", "Zhe Sun, Robin Niesert, Ahmet Erdem and Jing Qin", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "sun-analytics.nl, Staff Machine Learning Engineer @ Meta"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbffe7c6e7c4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ymwdalex.medium.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": ""}, {"url": "https://ymwdalex.medium.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Zhe Sun"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F65fd6480d015&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&user=Zhe+Sun&userId=65fd6480d015&source=post_page-65fd6480d015----bffe7c6e7c4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/c/google-quest-challenge/overview", "anchor_text": "https://www.kaggle.com/c/google-quest-challenge/overview"}, {"url": "https://www.kaggle.com/c/google-quest-challenge/overview", "anchor_text": "Q&A understanding competition"}, {"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/130243", "anchor_text": "a winning solution blog"}, {"url": "https://github.com/robinniesert/kaggle-google-quest", "anchor_text": "this"}, {"url": "https://www.sun-analytics.nl/posts/2020-08-04-accurately-labeling-subjective-question-answer-content-using-bert/", "anchor_text": "blog"}, {"url": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient", "anchor_text": "Spearman\u2019s rank correlation coefficient"}, {"url": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient", "anchor_text": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient"}, {"url": "https://jalammar.github.io/illustrated-transformer/", "anchor_text": "here"}, {"url": "http://jalammar.github.io/illustrated-bert/", "anchor_text": "here"}, {"url": "http://mccormickml.com/2019/07/22/BERT-fine-tuning/", "anchor_text": "here"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf", "anchor_text": "here"}, {"url": "https://www.kaggle.com/aerdem4/qa-use-save-model-weights", "anchor_text": "here"}, {"url": "https://github.com/robinniesert/kaggle-google-quest/tree/master/models", "anchor_text": "here"}, {"url": "https://huggingface.co/models", "anchor_text": "Huggingface"}, {"url": "https://huggingface.co/transformers/model_doc/roberta.html", "anchor_text": "Roberta"}, {"url": "https://huggingface.co/transformers/model_doc/xlnet.html", "anchor_text": "XLNet"}, {"url": "https://huggingface.co/transformers/model_doc/albert.html", "anchor_text": "Albert"}, {"url": "https://huggingface.co/transformers/model_doc/bert.html", "anchor_text": "BERT"}, {"url": "https://github.com/robinniesert/kaggle-google-quest/blob/master/train.py", "anchor_text": "here"}, {"url": "https://github.com/robinniesert/kaggle-google-quest/blob/master/one_cycle.py", "anchor_text": "here"}, {"url": "https://github.com/robinniesert/kaggle-google-quest/blob/master/finetune.py", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html", "anchor_text": "GroupKFold"}, {"url": "https://medium.com/tag/bert?source=post_page-----bffe7c6e7c4---------------bert-----------------", "anchor_text": "Bert"}, {"url": "https://medium.com/tag/kaggle?source=post_page-----bffe7c6e7c4---------------kaggle-----------------", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/nlp?source=post_page-----bffe7c6e7c4---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/ensemble-learning?source=post_page-----bffe7c6e7c4---------------ensemble_learning-----------------", "anchor_text": "Ensemble Learning"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----bffe7c6e7c4---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&user=Zhe+Sun&userId=65fd6480d015&source=-----bffe7c6e7c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&user=Zhe+Sun&userId=65fd6480d015&source=-----bffe7c6e7c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbffe7c6e7c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bffe7c6e7c4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bffe7c6e7c4--------------------------------", "anchor_text": ""}, {"url": "https://ymwdalex.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ymwdalex.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Zhe Sun"}, {"url": "https://ymwdalex.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "41 Followers"}, {"url": "http://sun-analytics.nl", "anchor_text": "sun-analytics.nl"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F65fd6480d015&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&user=Zhe+Sun&userId=65fd6480d015&source=post_page-65fd6480d015--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F65fd6480d015%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faccurately-labeling-subjective-question-answer-content-using-bert-bffe7c6e7c4&user=Zhe+Sun&userId=65fd6480d015&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}