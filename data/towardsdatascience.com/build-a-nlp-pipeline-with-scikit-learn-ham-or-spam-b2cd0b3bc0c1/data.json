{"url": "https://towardsdatascience.com/build-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1", "time": 1683011696.32357, "path": "towardsdatascience.com/build-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1/", "webpage": {"metadata": {"title": "Build a NLP Pipeline with SciKit-Learn: Ham or Spam? | by Edward Krueger | Towards Data Science", "h1": "Build a NLP Pipeline with SciKit-Learn: Ham or Spam?", "description": "Like many NLP problems, deciding which emails belong with spam and which you might want to read is a classification problem. We can ask, to which class does an email belong, spam or not-spam? Thus we\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/edkrueger/", "anchor_text": "Edward Krueger", "paragraph_index": 0}, {"url": "https://www.linkedin.com/in/douglas-franklin-1a3a2aa3/", "anchor_text": "Douglas Franklin", "paragraph_index": 0}, {"url": "https://github.com/edkrueger/spam-detector", "anchor_text": "GitHub Repository", "paragraph_index": 1}, {"url": "https://github.com/edkrueger/spam-detector", "anchor_text": "GitHub Repositor", "paragraph_index": 44}], "all_paragraphs": ["By: Edward Krueger and Douglas Franklin.", "Check out the code in our GitHub Repository!", "Like many NLP problems, deciding which emails belong with spam and which you might want to read is a classification problem.", "We can ask, to which class does an email belong, spam or not-spam? Thus we have two classes in which to sort all of our emails. Where to begin?", "To solve this, we will use supervised machine learning. This means we have a collection of emails that have already been labeled as ham or spam. Ham being emails assumed to be non-spam. Loosely, our model will learn to classify these emails by looking at the content of the email and associating that content with either label.", "After training, our model can receive an unlabeled email and classify it.", "Before we begin, let\u2019s have a look at our data.", "We start with this corpus, or collection of text, containing spam and non-spam emails. The data includes a label column (v1) and a text column (v2). This is the data our model will read to associate messages with class.", "Sounds easy enough, but computers can\u2019t read and learn as we do! However, machines are excellent calculators. So let\u2019s convert our text into a structure our machines can do math with, vectors.", "After some basic text cleaning to handle casing and non-alpha characters, we may begin. The first step of vectorization we\u2019ll discuss is called tokenization.", "Given a sequence of characters and a defined length, tokenization is the task of chopping the document up into pieces, called tokens, of that specified length.", "A Token is not necessarily a term or word. A token is an instance of a sequence of characters in some particular documents that are grouped as a useful semantic unit for processing. In other words, a token is the meaningful bit of language we want our model to learn from.", "Example: Tokenization of a sentence limiting the token length to five characters.", "By tokenizing, we have gone from a string containing words over five characters long and spaces to an array of words or tokens five characters or less and without whitespaces.", "Well, we now have an array of strings, how do we transform these arrays into vectors?", "Scikit-learn\u2019s CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words.", "Any document we see can be encoded as a fixed-length vector with the length of the vocabulary of known words. The value in each position in the vector could be filled with a count or frequency of each word in the document.", "For us, this gives each email a vector of integers. The vector will be the length of the number of distinct words in the corpus. Given a verbose corpus, these vectors can become quite long and cumbersome during calculations.", "This leads us to our next idea, how can we shrink the corpus without losing much meaning?", "Once we\u2019ve transformed the corpus into an array of integers with CountVectorizer, we move onto stopwords.", "Common words that appear to be of little value in helping determine if documents are spam or not are excluded from the vocabulary entirely. These words are called stop words. A general strategy for deciding a stop list is to sort the terms by collection frequency (the total number of times each term appears in the document collection), and then to take the most common terms, sometimes hand-filtered for their meaning relative to the domain of the documents being analyzed, as a stop list. The members of this stop list are then discarded during indexing.", "The addition of stopwords to a stop list can be manual or automated. In Scikit-learn\u2019s CountVectorizer, there is an option for corpus specific stopwords. You can pass an array of stopwords or automate the process with the minimum and maximum document frequency arguments.", "This reduced matrix will train faster and can even improve your model\u2019s accuracy.", "Shrinking the corpus can be super useful for reducing the memory usage of your model. This will save computing costs!", "The CountVectorizer tokenizes, vectorizes, and creates our stop list! So all we have to do is call it in our model pipeline. This function returns a sparse matrix that we will use to train our ML models.", "A machine learning pipeline is used to help automate machine learning workflows. These pipelines operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated all in a single code step.", "For example, take a look at our Naive Bayes pipeline.", "We simply call make_pipline, add the CountVectorizer and our model then callnb.fit to train a model using the pipeline!", "Machine learning algorithms often involve a sequence of tasks including pre-processing, feature extraction, model fitting, and validation stages. Pipelines help us lump these tasks together.", "How can we tell which model is the most effective at solving this problem? First, let\u2019s look at some of our model scores, precision and recall.", "Precision attempts to answer the following question:", "What proportion of positive identifications was actually correct?", "Precision measures the percentage of emails flagged as spam that were correctly classified.", "Recall attempts to answer the following question:", "What proportion of actual positives was identified correctly?", "Recall measures the percentage of actual spam emails that were correctly classified.", "To fully evaluate the effectiveness of a model, you must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa.", "So you need to know which is more important for your problem, precision or recall?", "Let\u2019s take a look at two of our models. Here we have the Naive Bayes model scores.", "And here we have the Logistic regression model scores.", "Notice that the NB model is better than the LR model in all but one category, spam precision. We can\u2019t say that one model is always better than the other, but we can select the one that is right more often.", "Once you have decided on a model, save it as a .joblib, as we have done below with our Naive Bayes model.", "Now you have a model for spam detection saved as a joblib!", "Here we have covered the basic NPL concepts, tokenization, vectorization and stopwords. Then we used these concepts with CountVectorizer in a model pipeline to compare metrics across models. After deciding on the Naive Bayes classifier, we saved it as a joblib for later use in our app.", "Check out the code in our GitHub Repository for a template to get started!", "To serve your model with an app and deploy it check out the further reading below!", "This article discusses building an app to serve our model and how to deploy it to the cloud. We cover building and dockerizing the app, storing the docker image on Google Container Registry, and deploying the App to Cloud run.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist, Software Developer and Educator"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb2cd0b3bc0c1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.edkruegerdata.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": ""}, {"url": "https://medium.edkruegerdata.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Edward Krueger"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4889b755e348&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&user=Edward+Krueger&userId=4889b755e348&source=post_page-4889b755e348----b2cd0b3bc0c1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.linkedin.com/in/edkrueger/", "anchor_text": "Edward Krueger"}, {"url": "https://www.linkedin.com/in/douglas-franklin-1a3a2aa3/", "anchor_text": "Douglas Franklin"}, {"url": "https://github.com/edkrueger/spam-detector", "anchor_text": "GitHub Repository"}, {"url": "https://github.com/edkrueger/spam-detector", "anchor_text": "GitHub Repositor"}, {"url": "https://towardsdatascience.com/deploy-a-scikit-learn-nlp-model-with-docker-gcp-cloud-run-and-flask-ba958733997a", "anchor_text": "Deploy a Scikit-Learn NLP Model with Docker, GCP Cloud Run and FlaskA brief guide to building an app to serve a natural language processing model, containerizing it and deploying it.towardsdatascience.com"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----b2cd0b3bc0c1---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/nlp?source=post_page-----b2cd0b3bc0c1---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/python?source=post_page-----b2cd0b3bc0c1---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b2cd0b3bc0c1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/software-engineering?source=post_page-----b2cd0b3bc0c1---------------software_engineering-----------------", "anchor_text": "Software Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&user=Edward+Krueger&userId=4889b755e348&source=-----b2cd0b3bc0c1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&user=Edward+Krueger&userId=4889b755e348&source=-----b2cd0b3bc0c1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb2cd0b3bc0c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b2cd0b3bc0c1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b2cd0b3bc0c1--------------------------------", "anchor_text": ""}, {"url": "https://medium.edkruegerdata.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.edkruegerdata.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Edward Krueger"}, {"url": "https://medium.edkruegerdata.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "699 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4889b755e348&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&user=Edward+Krueger&userId=4889b755e348&source=post_page-4889b755e348--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f629c0dbfb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-a-nlp-pipeline-with-scikit-learn-ham-or-spam-b2cd0b3bc0c1&newsletterV3=4889b755e348&newsletterV3Id=1f629c0dbfb9&user=Edward+Krueger&userId=4889b755e348&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}