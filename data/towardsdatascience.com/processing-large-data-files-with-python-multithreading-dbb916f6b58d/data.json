{"url": "https://towardsdatascience.com/processing-large-data-files-with-python-multithreading-dbb916f6b58d", "time": 1683007978.874889, "path": "towardsdatascience.com/processing-large-data-files-with-python-multithreading-dbb916f6b58d/", "webpage": {"metadata": {"title": "Processing large data files with Python multithreading | by Miguel Albrecht | Towards Data Science", "h1": "Processing large data files with Python multithreading", "description": "Python multithreading and memory mapped files techniques to speed-up processing time of large data files. Preparing data faster for machine learning and artificial intelligence models."}, "outgoing_paragraph_urls": [{"url": "http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html", "anchor_text": "Google Books Ngram corpus", "paragraph_index": 1}, {"url": "https://gist.github.com/zapalote/30aa2d7b432a08e6a7d95e536e672494", "anchor_text": "GitHub", "paragraph_index": 7}, {"url": "https://hackernoon.com/crunching-large-datasets-made-fast-and-easy-the-polars-library", "anchor_text": "this", "paragraph_index": 9}, {"url": "http://zapalote.com", "anchor_text": "zapalote.com", "paragraph_index": 11}], "all_paragraphs": ["We spend a lot of time waiting for some data preparation task to finish \u2014the destiny of data scientists, you would say. Well, we can speed things up. Here are two techniques that will come handy: memory mapped files and multithreading.", "I had recently to extract terms and term frequencies from the Google Books Ngram corpus and found myself wondering if there are ways to speed up the task. The corpus consists of twenty-six files totalling 24GB of data. Each of the files I was interested in contains a term and other meta data, tab separated. The brute force approach of reading these files as pandas data frames was \u2026 slow. Since we wanted only the unique terms and their match counts, I thought I would try to make it faster :-)", "This technique is not new. It has been around for a long time and originated in Unix (before Linux!). Briefly, mmap bypasses the usual I/O buffering by loading the contents of a file into pages of memory. This works very well for computers with large memory footprints. That\u2019s mostly OK with today\u2019s desktops and laptops where having 32GB of memory is not anymore in the esoteric department. The Python library mimics most of the Unix functionality and offers a handy readline() function to extract the bytes one line at a time.", "The fp is a file-pointer that was previously opened with the r+b access attribute. There you go, with this simple tweak you have made file reading twice as fast (well, the exact improvement will depend on a lot of things such as disk HW, etc).", "The next technique that always helps in making things faster is adding parallelism. In our case, the task was I/O bound. That is a good fit for scaling-up \u2014i.e. adding threads. You will find good discussions on when it is better to scale-out (multi-processing) on search engines.", "Python3 has a great standard library for managing a pool of threads and dynamically assign tasks to them. All with an incredibly simple API.", "The default value of max_workers for ThreadPoolExecutor is 5 threads per CPU core (as of Python v3.8). The map()API will receive a function to be applied to each member of a list and will run the function automatically when threads become available. Wow. That simple. In less than fifty minutes I had converted the 24GB input into a handy 75MB dataset to be analysed with pandas\u2014voil\u00e0.", "The complete code is on GitHub. Comments and remarks are always welcome.", "PS: I added a progress bar with tqdm for each thread. I really don\u2019t know how they manage to avoid scrambling of the lines on the screen \u2026 It works like a charm.", "UPDATE: Two years later, this came up :-)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Scientist by training, creative spirit by choice. web: zapalote.com instagram: @zapalotee"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdbb916f6b58d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://miguel-albrecht.medium.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": ""}, {"url": "https://miguel-albrecht.medium.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Miguel Albrecht"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb6e828908aeb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&user=Miguel+Albrecht&userId=b6e828908aeb&source=post_page-b6e828908aeb----dbb916f6b58d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://zapalote.com", "anchor_text": "zapalote.com"}, {"url": "http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html", "anchor_text": "Google Books Ngram corpus"}, {"url": "https://gist.github.com/zapalote/30aa2d7b432a08e6a7d95e536e672494", "anchor_text": "GitHub"}, {"url": "https://hackernoon.com/crunching-large-datasets-made-fast-and-easy-the-polars-library", "anchor_text": "this"}, {"url": "https://medium.com/tag/python?source=post_page-----dbb916f6b58d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/performance?source=post_page-----dbb916f6b58d---------------performance-----------------", "anchor_text": "Performance"}, {"url": "https://medium.com/tag/multithreading?source=post_page-----dbb916f6b58d---------------multithreading-----------------", "anchor_text": "Multithreading"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dbb916f6b58d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/big-data?source=post_page-----dbb916f6b58d---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "http://creativecommons.org/publicdomain/zero/1.0/", "anchor_text": "No rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&user=Miguel+Albrecht&userId=b6e828908aeb&source=-----dbb916f6b58d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&user=Miguel+Albrecht&userId=b6e828908aeb&source=-----dbb916f6b58d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdbb916f6b58d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dbb916f6b58d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dbb916f6b58d--------------------------------", "anchor_text": ""}, {"url": "https://miguel-albrecht.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://miguel-albrecht.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Miguel Albrecht"}, {"url": "https://miguel-albrecht.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "126 Followers"}, {"url": "http://zapalote.com", "anchor_text": "zapalote.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb6e828908aeb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&user=Miguel+Albrecht&userId=b6e828908aeb&source=post_page-b6e828908aeb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F96d31de3cc2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprocessing-large-data-files-with-python-multithreading-dbb916f6b58d&newsletterV3=b6e828908aeb&newsletterV3Id=96d31de3cc2c&user=Miguel+Albrecht&userId=b6e828908aeb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}