{"url": "https://towardsdatascience.com/understanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb", "time": 1683011693.59389, "path": "towardsdatascience.com/understanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb/", "webpage": {"metadata": {"title": "Understanding Text Vectorizations II: How TF-IDF Gives Your Simple Models the Power to Rival the Advanced Ones | by Bowen Chen | Towards Data Science", "h1": "Understanding Text Vectorizations II: How TF-IDF Gives Your Simple Models the Power to Rival the Advanced Ones", "description": "Remember last time we talked about using the bag of words model to detect sentiments of review texts, which we already have a relatively good performance. Today we will build upon what we have\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 13}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 21}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1", "paragraph_index": 26}, {"url": "https://github.com/chen-bowen/Streamlined_Sentiment_Analysis", "anchor_text": "here", "paragraph_index": 28}, {"url": "http://Archera.ai", "anchor_text": "Archera.ai", "paragraph_index": 31}], "all_paragraphs": ["Let\u2019s continue our sentiment analysis journey.", "Remember last time we talked about using the bag of words model to detect sentiments of review texts, which we already have a relatively good performance. Today we will build upon what we have already accomplished and upgrade the bag of words model with a smart weighting scheme. In this post, we will utilize the custom pipeline StreamlinedModel object from part 1, and witness the amazing improvements gained from applying this TF-IDF transformer from simple models like logistic regression.", "We already know that counting word frequency could help us gauge the sentiment of a review text, but this approach ignores the importance of words across the document. We talked about using a smart weighting scheme to solve this problem, but how exactly do we execute it?", "The answer is using a weighting scheme that is reverse proportionate with the frequency that this word appears in all documents. If the word appears in almost every document (such as \u201cI\u201d, \u201cyou\u201d or \u201cthey\u201d), it is likely to be treated as very important if we equally weight them. Therefore, we would like to up weight those words who appear not very frequently. For example, using the same 3 reviews", "We can see that \u201cadorable\u201d appears only in 1 of the 3 documents, the document frequency is 3/(1+1). We add 1 to the denominator to avoid it to be 0. We will then take the natural log value of the document frequency, which will give us the following", "compare to a word like \u201cI\u201d that appears in 2 out of 3 documents, we will get the inverse document frequency to be the following", "Then we will multiply the bag of words count with this weight to get the tf-idf value. Specifically,", "Now we understand the general idea of TF-IDF, let\u2019s have a look at how we should implement this model as a transformer.", "We will go through the same text preprocessing steps as outlined in part 1. Since the term frequency definitions remain the same as the bag of words model, we will focus on how to efficiently calculate the inverse document frequencies for all words.", "Since we will have to check whether the word exists in every document for every word, the runtime would possibly be O(n\u00b2), which will be rather slow. We can save the precomputed idfs in a class attributed and reference it once we are calculating term frequencies.", "We start with a helper method that gets the document frequency for all words. With the help from pandas .str.contains method that would detect the presence of a partial string within a column of the strings and return a series of 0/1, we can take the sum of the series to obtain the word\u2019s document frequency. We will then repeat the same process and store results in a dictionary.", "We will use the get_document_frequency method in our transformer\u2019s .fit method by applying the log transformation on every word\u2019s document frequency. The resulting idf values will be saved as a class attribute, which will be used as weights when we calculate the word frequencies.", "Our .transform method will consist of two parts. In addition to calculating word frequencies (which also exists in part 1), we will multiply them with their corresponding IDF values. Since for every review, we will have the same IDF weights (as the word index orders are fixed), we will repeat the IDF vector for N times (equal to the number of reviews) to make the IDF matrix the same shape as the word frequency matrix. Finally, we will perform an element-wise multiplication between the two matrices to get the TF-IDF values for all reviews.", "We are now ready to use the tf-idf as a transformer. The full implementation is shown below. As you probably noticed, the TermFrequency_InvDocFrequency transformer shared multiple parts with the WordFrequecyVectorizer transformer in part 1. The best implementation would be class inheritance. Implementing every helper function is solely for clarity purposes in case you are not interested in having a bag of words transformer as the master class.", "Now we have implemented the TF-IDF as a transformer, we will do the same thing and use the StreamlinedModel to build 4 different versions of models and compare the performances.", "Same as part 1, we will use the following function prototypes to generate 4 StreamlinedModel objects.", "We will try 4 different models and collect their prediction AUC scores to make a bar plot. This time we will compare the AUC scores we have obtained previously and see if we are actually able to obtain any improvements.", "Using our tf-idf transformer, we are able to obtain 0.896 AUC even with the logistic regression model. This will give us a significant advantage with model explanations \u2014 as the coefficients of individual words logistic regression could directly be interpreted as importance to a review\u2019s sentiment. No external packages will be needed anymore.", "We are also seeing a small performance bump on the multinomial naive Bayes model, as its AUC increased from 0.883 to 0.898, and is now slightly higher than the old winner lightGBM model, who barely got any improvements.", "Remember the title of this blog post? TF-IDF indeed gives simple models like logistic regression some power to beat out an advanced model like lightGBM. This is a perfect example of using the right feature engineering tools will give you incredible boosts on performance.", "Next, let\u2019s have a look if we find the most wrong positive/negative reviews changed as a result of changing the transformer.", "We will use the same lines as part 1 to get the most wrong positive/negative indices.", "The most wrong positive review (from multinomial naive Bayes model since it is now the best performing model) is", "I honestly could not tell this is a positive review. It contains strong negative words like \u201cfed (up)\u201d and \u201cnot\u201d. It is understandable that our model got it wrong.", "The most wrong negative review (from multinomial naive Bayes) is", "I could discern this review as a negative one, but this review does not really have any strong negative words (seen in the next section), making the mistake would also be understandable.", "We have seen examples of using SHAP to visualize individual reviews in part 1, we can use SHAP to visualize the feature importance on an overall level.", "The most important words are actually obvious sentiment indicating words.", "We have improved our text vectorizer with tf-idf as the feature engineering tools for the sentiment analysis model. In fact, tf-idf is also the foundation for a lot of more complex feature engineering tools such as word2vec. Again, the project GitHub could be found here. Now, let\u2019s summarize what we have learned in this blog post.", "That is all for text vectorizations! Next up, we will have a look at some more advanced feature extraction tools that use deep learning. See you next time!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer@ Archera.ai, Basketball Player Training How to Dunk, Life-long Knicks Fan, Living the Dream"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F79b6c975d7eb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://bowenchen.medium.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": ""}, {"url": "https://bowenchen.medium.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Bowen Chen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe4eab6908bf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&user=Bowen+Chen&userId=e4eab6908bf4&source=post_page-e4eab6908bf4----79b6c975d7eb---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@itfeelslikefilm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "\ud83c\uddf8\ud83c\uddee Janko Ferli\u010d"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/understanding-text-vectorizations-how-streamlined-models-made-feature-extractions-a-breeze-8b9768bbd96a", "anchor_text": "part 1"}, {"url": "https://github.com/chen-bowen/Streamlined_Sentiment_Analysis", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----79b6c975d7eb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----79b6c975d7eb---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/tf-idf?source=post_page-----79b6c975d7eb---------------tf_idf-----------------", "anchor_text": "Tf Idf"}, {"url": "https://medium.com/tag/sklearn-pipeline?source=post_page-----79b6c975d7eb---------------sklearn_pipeline-----------------", "anchor_text": "Sklearn Pipeline"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&user=Bowen+Chen&userId=e4eab6908bf4&source=-----79b6c975d7eb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&user=Bowen+Chen&userId=e4eab6908bf4&source=-----79b6c975d7eb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F79b6c975d7eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----79b6c975d7eb---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----79b6c975d7eb--------------------------------", "anchor_text": ""}, {"url": "https://bowenchen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://bowenchen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bowen Chen"}, {"url": "https://bowenchen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "141 Followers"}, {"url": "http://Archera.ai", "anchor_text": "Archera.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe4eab6908bf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&user=Bowen+Chen&userId=e4eab6908bf4&source=post_page-e4eab6908bf4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7b1d5930fa0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-text-vectorizations-ii-how-tf-idf-gives-your-simple-models-the-power-to-rival-the-79b6c975d7eb&newsletterV3=e4eab6908bf4&newsletterV3Id=7b1d5930fa0e&user=Bowen+Chen&userId=e4eab6908bf4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}