{"url": "https://towardsdatascience.com/designing-a-chatbot-using-python-a-modified-approach-96f09fd89c6d", "time": 1683010482.439904, "path": "towardsdatascience.com/designing-a-chatbot-using-python-a-modified-approach-96f09fd89c6d/", "webpage": {"metadata": {"title": "Designing A ChatBot Using Python: A Modified Approach | by Abhijit Roy | Towards Data Science", "h1": "Designing A ChatBot Using Python: A Modified Approach", "description": "In today\u2019s time, ChatBots have become extremely popular. Highly developed ChatBots like Siri, Cortana, and Alexa have left people surprised with their intelligence and capabilities. A chatbot is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://abhijitroy1998.wixsite.com/abhijitcv", "anchor_text": "https://abhijitroy1998.wixsite.com/abhijitcv", "paragraph_index": 51}], "all_paragraphs": ["In today\u2019s time, ChatBots have become extremely popular. Highly developed ChatBots like Siri, Cortana, and Alexa have left people surprised with their intelligence and capabilities. A chatbot is actually defined as:", "Chatbots can be as simple as rudimentary programs that answer a simple query with a single-line response, or as sophisticated as digital assistants that learn and evolve to deliver increasing levels of personalization as they gather and process information.", "In many articles, I have seen a basic comment-response model. My attempt is to see if we can take this a bit further, to modify the user comments to a broader basis and maybe provide the chatbot with other capabilities using a simple web request, automation, and scraping.", "Before we start, I just want you to know a few things about, what are we looking at. We will not be looking at a super-smart chatbot like Siri because it will need a huge experience and expertise. Now, if we think, it will be pretty cool, if our chatbot can help us book a hotel, play a song for us, tell us about the weather reports, and so on. We will try to implement all these facilities in our chatbot using just some basic python web handling libraries. We will be using NLTK or Python\u2019s Natural Language Toolkit Library. So, let\u2019s start.", "Chatbots are mainly of two types based on their design", "We are going to use a combined version of the two. In the Rule-Based approach generally, a set of ground rules are set and the chatbot can only operate on those rules in a constrained manner. For the self-learned version, Neural networks are used to train the chatbots to reply to a user, based on some training set of interaction. For the task parts, we will be using a rule-based approach and for the general interactions, we will use a self-learned approach. I found this combined approach much effective than a fully self-learned approach.", "Before we jump into the application, let us look at how NLTK works and how it is used in Natural Language Processing. There are 5 main components of Natural Language Processing. They are:", "Morphological and Lexical Analysis: Lexical analysis depicts analyzing, identifying, and description of the structure of words. It includes dividing a text into paragraphs, words, and sentences.", "Syntactic analysis: The words are commonly accepted as being the smallest units of syntax. The syntax refers to the principles and rules that govern the sentence structure of any individual language. Syntax focus on the proper ordering of words which can affect its meaning.", "Semantic Analysis: This component transfers linear sequences of words into structures. It shows how the words are associated with each other. Semantics focuses only on the literal meaning of words, phrases, and sentences.", "Discourse Integration: It means a sense of the context. The meaning of any single sentence which depends upon those sentences. It also considers the meaning of the following sentence.", "Pragmatic Analysis: Pragmatic Analysis deals with the overall communicative and social content and its effect on interpretation. It means abstracting or deriving the meaningful use of language in situations.", "Now, let\u2019s talk about the methods or functions used to implement these five components:", "Tokenization: Tokenization is the process by which big quantity of text is divided into smaller parts called tokens. It takes in a sentence and decomposes it into the smallest extractable units or words.", "Parts of Speech Tagging: It is a very useful tool in NLP. We know, various parts of speech like Verb, Noun, Adjective, and others. Now, if can tag to which parts of speech do a word belongs to, it will be easy for us to understand the context of a sentence.", "Lemmatization: This operation is another very useful tool for NLP. The words which have the same meaning but have some variation according to the context or sentence are brought down to their root word using this operation. This is very important for pattern matching and for rule-based approaches.", "All these facilities are provided by the python\u2019s NLTK libraries. Now, let\u2019s check how the Self Learning Algorithm works.", "We use a bag of words algorithm for the purpose to train our model. We have a file that contains all the intents and input patterns. It looks like:", "We can see that here we have a \u2018tag\u2019 field which actually depicts the intentions. Intentions are usually terms, which are the actual subject or motive behind a sentence given. For example, here there are intentions like \u2018introductions\u2019, \u2018thanks\u2019, \u2018greetings\u2019, and \u2018goodbye\u2019 which are basically motives. Secondly, we have a \u2018patterns\u2019 field which actually depicts the patterns or type of sentences that can have the corresponding motive. Then we have the responses field which contains some responses which may be the bot\u2019s response if the corresponding motive is detected. For example, for the \u2018tag\u2019 or intention of \u2018greeting\u2019 patterns detected can be \u2018Hi\u2019, \u2018Hello\u2019, and the corresponding responses can be \u2018Hello\u2019, \u2018Hi There\u2019.", "Now, we pick all the unique words from the patterns one by one lemmatize them, convert to them to lower case, and then append it to create a list of words. This list will look something like this:", "This will be our bag of words or vocabulary for our model training. Now, we will need to one-hot encode the list to create the encoded vectors which are then fitted to the model as the train set.", "Then, we have the tags which are also put in a list. It looks like this:", "This is also one hot encoded to create a list that will serve as our target data for training our model. Now, how will we do that?", "First, we obtain the filtered bag of words list. In our case, the length of the word list is 47. Now, we create a list of size 47 and mark it\u2019s all indices with 0. Then we mark the indices corresponding to the words present in the input sentence as 1. For example, the input sentence is \u2018Hi There\u2019. Then the list becomes:", "Only the indices corresponding to \u2018hi\u2019 and \u2018there\u2019 are 1 and all others are 0. These encoded vectors are obtained from all the input statements in our batch. So, if the batch size is n. We have n x 47 lists and it is our input dimension of X values of the training set.", "Similarly, We have the target set. We have 7 tags. So, we create a list of size 1. The tag index corresponding to the tag which is denoted by the input statement is 1 and all others are 0. For example, for \u2018Hi There\u2019 in our training data set tag is \u2018greeting\u2019. So, the index corresponding to the greeting tag is 1 and all others are 0. So, if the batch size is n. We have n x 7 lists and it is our input dimension of Y values or the target values of the training set.", "Each sentence present in patterns of all the intents comprises of our total dataset. The model is trained on the basis of these datasets.", "Use: Now, when a user inputs a sentence or statement, it is also tokenized, lemmatized, and converted to lower case. Then after the preprocessing the data from the user, we one hot encode the user data using our vocabulary and form a 47 length encoded vector. We fit this vector to our model, which gives us the predicted tag of the user statement. We then go and find a random response to the user statement from our response lists.", "This is our main library code which is the merging area between our rule-based learning and self-learning. The user sends a message, which is picked up by this code and this code classifies the message. In other words, it tells whether the statement assigns some tasks or is just a common casual conversation.", "Here we will first tokenize the statement and then tag parts of speech. Now, If it is a question there will be a question mark or it will have a \u2018wh\u2019 term. If these characteristics are detected then the statement is classified as a query and corresponding actions are taken. Similarly, if we want weather or news, those terms will appear as the subjects of the statements. In case, if the statement is not a defined query or task, the task is assigned 0 and is taken over by our self-learner model which will now try to classify the statement.", "This is our caller module. which runs in a while loop until the flag is defined 1 by the response function.", "This is our driving response creator code. It receives the user sentence from the caller. It then calls filter_command() to return if any classified task is detected or not. Here we have 6 tasks(0\u20135). 0 being no task detected. Any \u2018wh\u2019 query or statement carrying \u2018?\u2019 is handled by the scrape() snippet. Similarly, task 2 is playing a youtube video, 3 is booking a ticket or room, 4 being weather news. and finally, 5 is News update. 0 invokes the self-learning model.", "All the task handlers are defined in a support file. They use Selenium automation and web scraping mostly. Let me show three of them.", "This is youtube automation. It searches a video and picks up video titles. It searches the subjects of our message in the title. This is done to avoid the advertisement videos which pop on top of the suggested video list. So, we need to be careful of providing correct names in statements. Another problem with this is the \u2018s\u2019 value. This is supposed to retain the video length using Xpath so that we can close the driver once the video finishes. But due to Youtube\u2019s constantly changing its source codes this sometimes generates errors. It can be solved by APIs but I didn\u2019t prefer to use them.", "The next is the News Scraper:", "This is the headlines scraper code. We have used the \u2018Telegraph\u2019 as the source of our news headlines. It has headlines of two types marked by two classes. We here scraped both and with the help of the Soup, we extract the code.", "Next, lastly, let\u2019s look at the query answerer code. It is also a kind of scraper.", "Here we obtain the result options from a google search and if a Wikipedia page is in the search result,s we scrape it to provide the first 4 paragraphs from the page. If wikilinks are not found we just do a basic google search.", "Now, let\u2019s move to the self-learning model part.", "Here, first is the data pre-processing part:", "This code is used for pre-processing. As we have known, all the patterns from all_patterns detected under all tags are tokenized. The words after tokenization are put into a list. So, these lists have repeated values. The corresponding tags are also being saved in the \u2018tags\u2019 list. The docs list is saving the tuples in the format (tokenized_words, tag). So, it is saved as ([\u2018hi\u2019, \u2018there\u2019], \u2018greeting\u2019) for example.", "Now, the word_f lists is a purer version of the list with no repetition of words.", "Here, the bag of words or encoded vectors is formed. This snippet picks the word_tokenized part in our doc to create the encoded vectors which are a part of our X_train set formed, and their corresponding tags are also encoded to form the Y_train or target values of our train set.", "Our model and the train(X) and target(Y) sets of our training data are returned by the function. Our model has 2 hidden layers. It uses categorical cross-entropy as loss function and activation Softmax on the final layer. We used \u2018Adam\u2019 optimizer here.", "Our model is trained at 500 epochs saving best weights only.", "The above code is used for the preprocessing of the new user statement to be predicted by the model. It involves converting to lowercase and lemmatization. Then, the encoded-vector is formed using our vocabulary and sent to the model for prediction. The Bot response depends on the tag predicted.", "This is the overall process of the operation of our Bot.", "The short video shows the use and actions of our bot. There are some version issues with CUDA in my device I suppose. So, I got a few warnings, but I think that\u2019s nothing to worry about.", "There are a few drawbacks and challenges in the field. For example, POS tagging, while tagging \u2018play\u2019 word, it is sometimes tagged as Noun and sometimes as a Verb. Similarly, this issue exists with the \u2018book\u2019 issue also, here I have handled the exceptions but in real-world large scenarios, these things will matter. Matters won\u2019t be bad if we use self-learning models. The challenge with Self-learning models is that they need a huge training set that needs to manually designed. So, that is why chatbots are usually kept to serve certain purposes, like handling front office client complaints and interactions up to a certain level and record the issues. But, currently, they are developing at a very fast rate. Hope, soon we will get to see more evolved bots.", "In this article, we talked about a way, a basic plan chatbot can be given some features. I hope this helps.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a Computer Science and Technology Graduate from NIT, Durgapur. Find Me at https://abhijitroy1998.wixsite.com/abhijitcv"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F96f09fd89c6d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@myac.abhijit?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@myac.abhijit?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Abhijit Roy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4c235a4f4b95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&user=Abhijit+Roy&userId=4c235a4f4b95&source=post_page-4c235a4f4b95----96f09fd89c6d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@agkdesign?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Alex Knight"}, {"url": "https://unsplash.com/s/photos/bot?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/results?search_query=", "anchor_text": "https://www.youtube.com/results?search_query="}, {"url": "http://twitter.com/class", "anchor_text": "@class"}, {"url": "https://www.telegraphindia.com/", "anchor_text": "https://www.telegraphindia.com/"}, {"url": "https://www.google.com/search?q=", "anchor_text": "https://www.google.com/search?q="}, {"url": "https://github.com/abr-98/Chatbot_modified", "anchor_text": "Github link"}, {"url": "https://medium.com/tag/chatbots?source=post_page-----96f09fd89c6d---------------chatbots-----------------", "anchor_text": "Chatbots"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----96f09fd89c6d---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/rule-based?source=post_page-----96f09fd89c6d---------------rule_based-----------------", "anchor_text": "Rule Based"}, {"url": "https://medium.com/tag/nlp?source=post_page-----96f09fd89c6d---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&user=Abhijit+Roy&userId=4c235a4f4b95&source=-----96f09fd89c6d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&user=Abhijit+Roy&userId=4c235a4f4b95&source=-----96f09fd89c6d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F96f09fd89c6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----96f09fd89c6d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----96f09fd89c6d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@myac.abhijit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@myac.abhijit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Abhijit Roy"}, {"url": "https://medium.com/@myac.abhijit/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "458 Followers"}, {"url": "https://abhijitroy1998.wixsite.com/abhijitcv", "anchor_text": "https://abhijitroy1998.wixsite.com/abhijitcv"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4c235a4f4b95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&user=Abhijit+Roy&userId=4c235a4f4b95&source=post_page-4c235a4f4b95--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2ba8066c30a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdesigning-a-chatbot-using-python-a-modified-approach-96f09fd89c6d&newsletterV3=4c235a4f4b95&newsletterV3Id=2ba8066c30a7&user=Abhijit+Roy&userId=4c235a4f4b95&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}