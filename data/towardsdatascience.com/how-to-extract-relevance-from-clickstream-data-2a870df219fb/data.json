{"url": "https://towardsdatascience.com/how-to-extract-relevance-from-clickstream-data-2a870df219fb", "time": 1683011320.484679, "path": "towardsdatascience.com/how-to-extract-relevance-from-clickstream-data-2a870df219fb/", "webpage": {"metadata": {"title": "Solving One of the Biggest Challenges for AI-Based Search Engines: Relevance | by Will Fuks | Towards Data Science", "h1": "Solving One of the Biggest Challenges for AI-Based Search Engines: Relevance", "description": "These steps tend to be what is already necessary for implementing an effective enough search engine system for a given application. Eventually, the requirement to upgrade the system to deliver\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/varepsilon/clickmodels", "anchor_text": "ClickModels", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Graphical_model", "anchor_text": "Probabilistic Graphical Models", "paragraph_index": 5}, {"url": "https://github.com/WillianFuks/pyClickModels", "anchor_text": "pyClickModels", "paragraph_index": 6}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46485.pdf", "anchor_text": "tends to get more clicks", "paragraph_index": 11}, {"url": "https://www.amazon.com/Synthesis-Lectures-Information-Concepts-Retrieval/dp/1627056475", "anchor_text": "Click Models for Web Search", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Dynamic_Bayesian_network#:~:text=A%20Dynamic%20Bayesian%20Network%20(DBN,other%20over%20adjacent%20time%20steps.", "anchor_text": "Dynamic Bayesian Network", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Bernoulli_distribution", "anchor_text": "Bernoulli", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1", "anchor_text": "MLE", "paragraph_index": 37}, {"url": "https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959", "anchor_text": "Expectation-Maximization", "paragraph_index": 41}, {"url": "https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a", "anchor_text": "kMeans", "paragraph_index": 41}, {"url": "https://en.wikipedia.org/wiki/Indicator_function", "anchor_text": "indicator function", "paragraph_index": 46}, {"url": "https://en.wikipedia.org/wiki/Conditional_independence", "anchor_text": "independent", "paragraph_index": 55}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L380", "anchor_text": "pyClickModels", "paragraph_index": 60}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L673", "anchor_text": "here", "paragraph_index": 62}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L89:L136", "anchor_text": "here", "paragraph_index": 80}, {"url": "https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data?filter=solution-type:dataset&filter=category:analytics&id=45f150ac-81d3-4796-9abf-d7a4f98eb4c6&project=pyclickmodels&folder=&organizationId=", "anchor_text": "public datasets", "paragraph_index": 88}], "all_paragraphs": ["Building a search engine system usually follows some well-known steps for the most part:", "These steps tend to be what is already necessary for implementing an effective enough search engine system for a given application.", "Eventually, the requirement to upgrade the system to deliver customized results may arise. Doing so should be simple. One could choose from a set of machine learning ranking algorithms, train some selected models, prepare them for production and observe the results.", "It can be that simple indeed except for one missing part: regardless of the chosen ranking model, we still need to somehow prepare a training dataset capable of teaching the algorithms on how to properly rank. There\u2019s got to be, somehow, a dataset telling the algorithms what is a good document versus a bad one.", "And that\u2019s going to be the main focus of this post . In order to push search engines to the next level with AI algorithms, a training data that \u201cteaches\u201d algorithms on how to properly rank results is fundamental.", "We\u2019ll discuss how to use ClickModels, a field that uses Probabilistic Graphical Models (PGM), to develop a set of variables that explains the interactions between users and the retrieved documents. Those variables will provide us the concept of relevance (or judgment, as also known in the literature) which basically works as a marker of how much valuable a document is for a given search query.", "Our challenge will be to create a probabilistic model that learns from users interactions how much relevant documents are for each query and context. Final code built on top of Cython can be found on pyClickModels repository (Cython is required as the optimization process of these algorithms may take a considerable amount of time to converge).", "So, with no further ado, let\u2019s see how to take search engines to the next level.", "Figuring out what is relevant for people can be quite challenging. Imagine working on building a search engine for an eCommerce store.", "In this environment (and we could argue that most retrieval engines works on similar context), observed data contains:", "We expect that products purchased from a search result page are quite relevant so they should have a good relevance score. But then we realize that there might be products that weren\u2019t shown to the user (for instance, products at page 2 or higher) that they would end up enjoying even more!", "Not only that, several patterns tend to be observed when ranking items to users. For instance, the first document on a result page tends to get more clicks than others, not necessarily because it\u2019s an adequate product for the query but rather simply because it\u2019s on the very first position of the catalog (also known as \u201cposition bias\u201d).", "Well, now things start to get tricky.", "One approach for finding what is relevant to people is simply asking them. And, interestingly enough, that\u2019s actually one available solution used by some companies. But the downsides of this approach is that it doesn\u2019t quite scale well and it tends to be less accurate in general.", "Another approach, one that we are interested in, infers implicit relevance from \u2018clickstream\u2019 data. Clickstream data is basically the recording of the browsing interactions between users and the search engine system itself. Here\u2019s one example:", "We can use this information in order to model how relevant each document likely is for each query.", "One way to extract relevance from clickstream data is by using ClickModels, which consists of PGMs, in order to infer the likelihood of users clicking on documents. We can assume that the higher the probability of a click is, the more relevant the document might be, accordingly.", "From what follows, the ideas and concepts discussed here were extract from the book Click Models for Web Search by Aleksandr Chuklin and others.", "We have numerous ways of modeling users interactions with a ranked list of documents. Here, the Dynamic Bayesian Network (DBN) approach will be the chosen one for the discussion and implementation. Keep in mind though, once you understand the concepts and theory behind the model, you can extrapolate this knowledge using whatever variables you seen fit. The book by Aleksandr discusses several other models for instance.", "To begin with, here\u2019s a graphical representation of the DBN used for extracting relevance from data:", "All variables in this model follow a Bernoulli distribution, meaning they can be either 0 or 1 with some probability p. These are the main concepts to grasp from the net:", "Using our previous example of smartphones, here\u2019s how the DBN would be represented:", "Notice that, for each document, we associate a set of latent variables (Attractiveness, Satisfaction, Examination) that models how and why users interact the way they do with the engine results. Clicks and Purchases are filled with gray as they are observed variables (clickstream data).", "Here\u2019s the catch: if we assign values that represent the probability for each latent variable, we could use those same values to extrapolate what the relevance of each document is for each search query.", "For instance, let\u2019s say we associate \u03b1 to represent the probability that a given document is attractive and \u03c3 to the user being satisfied. If we use some optimization technique to learn from data what those values should be, we could find the relevance for each document as a consequence.", "To do so, let\u2019s begin describing our network with a set of rules (these rules will be used in the optimization process):", "Here\u2019s a summary explanation of each rule:", "(1) means that the probability of a user examining a given document at given rank r is zero case previous document at r-1 was not examined.", "(2) \u03b1 is the parameter that determines the probability of attractiveness being equal to 1.", "(3) We must observe a click if a document is examined and is attractive.", "(4) If a document was not clicked nor purchased then it can\u2019t be considered satisfactory for the given query.", "(5) The probability of document being satisfactory is \u03c3 if a document is clicked but not purchased.", "(6) Satisfaction is 1 if click and purchase are observed.", "(7) If previous document was satisfactory, users won\u2019t continue examining new products.", "(8) If a document is not satisfactory and previous document was examined then customer will continue examining new documents with probability \u03b3.", "(9) Probability of observing a click is given by the probability of click given examination times probability of examination (Bayes rule, which extends for the same as probability of being clicked and examined) given by \u03b1 * \u03b5.", "Having the equations that governs the DBN model, some techniques could be used in order to find values for \u03b1, \u03c3 and \u03b3 that best explain the observed data.", "First technique would be a straightforward implementation of the maximum likelihood estimation (MLE). It basically consists of finding an expression of the likelihood of the model (expressed in terms of log) which is the probability of observing the data given the model variables.", "In our case, our DBN has the following log-likelihood expression:", "The summation happens over \u201cs\u201d which stands for session and it represents the user interactions with the search engine.", "In MLE approach, we could simply take the derivative of this expression with respect to each latent variable and equalize it to zero. But this approach wouldn\u2019t work very well. The problem is that the resulting expression would be intractable to solve due the latent variables.", "This is a known problem actually. And as it turns out, besides MLE, another technique is the Expectation-Maximization algorithm (EM) (it works sort of like the popular kMeans algorithm does).", "It starts by assigning random expected values to the latent variables \u03b1, \u03c3 and \u03b3. It then proceeds to iterate an optimization process by using a specific cost function. New values are assigned for the variables and the process repeats itself until convergence or total iterations has been met.", "The cost function used as reference for optimization is given by:", "It\u2019s similar to the log-likelihood expression as seen before but it replaces part of the expression with expected values of the random variables which turns the derivative much easier (but it also ends up being an approximation for what could be the optimum solution).", "Here\u2019s the cost function Q as defined in our model:", "Par(X)=p refers to the parents of the variable X. For instance, in our DBN, the variable S (satisfaction) has Clicks and Purchases as its parents, given the edges connections of the network. The variable \u03b8 represents the latent parameters we are trying to find (\u03b1 and so on). I is the indicator function and Z is just a reference for values not related to \u03b8 that will be discarded in the derivation process.", "What we accomplish by using the expected value of the random variables is that now deriving this equation is much simpler. Here\u2019s the result we get already isolating for \u03b8:", "That\u2019s basically the essence of the Expectation-Maximization algorithm. We first replace in the log-likelihood expression the random variables by their expected value and then derive the equation equalizing it to zero. We obtain an optimization rule (equation 10) to be used for each variable which should, slowly, converge to local or global minima.", "Let\u2019s see how each variable gets adapted using equation 10 definition.", "To begin with, the attractiveness variable is defined as:", "q extends for query and u represents the document. In our DBN representation, notice that \u03b1 doesn\u2019t have any parents so it\u2019s directly defined.", "To develop its optimization equation, first we need to describe the probability associated to the examination of documents as follows:", "Where cr is the conversion rate of the given document u for given query q, defined as total sales divided by total times the document appeared in results pages for a given query q. It\u2019s only defined if documents are for sale otherwise it\u2019s just considered to be zero.", "Where |S| is the cardinality of all sessions where the search results page for query q returned document u.", "Notice that, given the architecture of our DBN, the variables C and P are independent given C, which means we only need to account for the former:", "Equation 13 can be further developed as follows:", "C_{>r} is 1 if any click is observed above r and 0 otherwise.", "For the numerator of 14, we can further develop it as:", "And the denominator is a bit more complex:", "Equation 14.4 should be implemented recursively. You can see how it was done on pyClickModels, here\u2019s a sample:", "Finally, we can use all these equations and blend them together to come up with the final rule for adapting the attractiveness variable:", "You can see here how this rule was implemented on pyClickModels:", "The satisfaction variable \u03c3 does have parents as defined in our DBN. Therefore, from equation 10, we need to use sessions only where the variable is defined, given appropriate parents.", "Specifically, equation 5 already described it. We have that:", "Using equation 10 we have, therefore:", "S'_{uq} encompass all sessions where document uwas clicked and not purchased.", "The numerator of (16) can be further developed as:", "Which resolves directly into the adaptation rule for satisfaction:", "That was more straightforward than attractiveness. Here\u2019s how this equation was implemented:", "Now comes the most challenging variable of them all.", "Notice that, as defined in our DBN, persistence is globally defined, i.e., it doesn\u2019t depend on either queries or documents to be defined.", "As seen before, it\u2019s given by:", "In order to obtain the updating rule for \ud835\udefe, we\u2019ll be using the following Expected Sufficient Statistics (ESS):", "An auxiliary function \u03a6 can be implemented in order to further develop 19. We\u2019d have that:", "The strategy is to divide equation 20 in 3 main parts:", "The third one is developed as:", "To develop the inner probability equation, we have that:", "First one is developed as (notice the variable conversion rate has been called \u201cw\u201d here):", "And, finally, the second equation is a direct implementation of equations from 1 to 9.", "You can see how these 3 equations were implemented here:", "Updating the parameter is then straightforward:", "And finally, that\u2019s all that it takes to implement the DBN as previously defined.", "Well, now back to our main goal, how do we extract relevance from all that?", "Now it\u2019s simple. After training the model with the clickstream data, we\u2019ll obtain optimized values (remember those can still refer to local optima) for the attractiveness and satisfaction.", "The ranking relevance, or judgments, will simply be the product of both, i.e.:", "It\u2019s possible in pyClickModels to export the values of judgments after fitting the model. A newline delimited JSON file is created for each search query /context and all respective documents.", "Let\u2019s see all these concepts in action now.", "As it turns out, we can use public datasets available on Google BigQuery to test these ideas. In practice, we\u2019ll be querying over a sample of Google Analytics where we can extract customers, what they searched, clicked and purchased (still, we only have access to very few data so it remains as a simple experiment after all).", "Here\u2019s the code necessary for our test:", "It requires GCS client and pyClickModels, both can be installed with:", "Just copy and paste the code to your local and run it with Python. A file will be saved at /tmp/pyclickmodels/model/model.gz . Opening the file, you should see several JSON lines such as this one:", "Notice that the library returns as key the whole context of the search (in this case, it uses as information which channel group the user came through to the website as well as their average spending ticket). Values are each document for that search context and the respective judgment associated, ranging from 0 to 1.", "By using PGMs we can use as many latent variables as we want in order to describe the behavior of the observed data. As we\u2019ve seen, we do so in a way that we can extract concepts such as how attractive a document probably is as well as how satisfied users are when exposed to that document.", "With these relevance values, we can train learning to rank models that bring search engines to the next level of operation making them capable of retrieving personalized results for each user and their respective context, as long as those have been trained in the model.", "From that point on, more sophisticated algorithms can be tailored inside the search engine, ranging from simple decision trees up to deep learning nets fully capturing statistical nuances from data. Still, it can only be possible if the relevance data is available as otherwise there\u2019s no way of teaching the learning algorithm on how to properly rank.", "Full code implementation can be found in pyClickModels open-source repository:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Mainly interested in data science and software development topics."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2a870df219fb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://willian-fuks.medium.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Will Fuks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe9c35a095d0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&user=Will+Fuks&userId=e9c35a095d0d&source=post_page-e9c35a095d0d----2a870df219fb---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/varepsilon/clickmodels", "anchor_text": "ClickModels"}, {"url": "https://en.wikipedia.org/wiki/Graphical_model", "anchor_text": "Probabilistic Graphical Models"}, {"url": "https://clickmodels.weebly.com/uploads/5/2/2/5/52257029/mc2015-clickmodels.pdf", "anchor_text": "clickmodels book"}, {"url": "https://github.com/WillianFuks/pyClickModels", "anchor_text": "pyClickModels"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46485.pdf", "anchor_text": "tends to get more clicks"}, {"url": "https://www.amazon.com/Synthesis-Lectures-Information-Concepts-Retrieval/dp/1627056475", "anchor_text": "Click Models for Web Search"}, {"url": "https://en.wikipedia.org/wiki/Dynamic_Bayesian_network#:~:text=A%20Dynamic%20Bayesian%20Network%20(DBN,other%20over%20adjacent%20time%20steps.", "anchor_text": "Dynamic Bayesian Network"}, {"url": "https://en.wikipedia.org/wiki/Bernoulli_distribution", "anchor_text": "Bernoulli"}, {"url": "https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1", "anchor_text": "MLE"}, {"url": "https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959", "anchor_text": "Expectation-Maximization"}, {"url": "https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a", "anchor_text": "kMeans"}, {"url": "https://en.wikipedia.org/wiki/Indicator_function", "anchor_text": "indicator function"}, {"url": "https://en.wikipedia.org/wiki/Conditional_independence", "anchor_text": "independent"}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L380", "anchor_text": "pyClickModels"}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L673", "anchor_text": "here"}, {"url": "https://github.com/WillianFuks/pyClickModels/blob/master/pyClickModels/DBN.pyx#L89:L136", "anchor_text": "here"}, {"url": "https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data?filter=solution-type:dataset&filter=category:analytics&id=45f150ac-81d3-4796-9abf-d7a4f98eb4c6&project=pyclickmodels&folder=&organizationId=", "anchor_text": "public datasets"}, {"url": "https://github.com/WillianFuks/pyClickModels", "anchor_text": "WillianFuks/pyClickModelsA Cython implementation of ClickModels that uses Probabilistic Graphical Models to infer user behavior when interacting\u2026github.com"}, {"url": "https://www.amazon.com/Synthesis-Lectures-Information-Concepts-Retrieval/dp/1627056475/ref=sr_1_1?ie=UTF8&qid=1449345891&sr=8-1&keywords=chuklin", "anchor_text": "https://www.amazon.com/Synthesis-Lectures-Information-Concepts-Retrieval/dp/1627056475/ref=sr_1_1?ie=UTF8&qid=1449345891&sr=8-1&keywords=chuklin"}, {"url": "https://clickmodels.weebly.com/", "anchor_text": "https://clickmodels.weebly.com/"}, {"url": "https://github.com/varepsilon/clickmodels", "anchor_text": "https://github.com/varepsilon/clickmodels"}, {"url": "https://www.cs.ubc.ca/~murphyk/Thesis/thesis.html", "anchor_text": "https://www.cs.ubc.ca/~murphyk/Thesis/thesis.html"}, {"url": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation", "anchor_text": "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation"}, {"url": "https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959", "anchor_text": "https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46485.pdf", "anchor_text": "ttps://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46485.pdf"}, {"url": "https://en.wikipedia.org/wiki/Conditional_independence", "anchor_text": "https://en.wikipedia.org/wiki/Conditional_independence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2a870df219fb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2a870df219fb---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/search-engine-optimizati?source=post_page-----2a870df219fb---------------search_engine_optimizati-----------------", "anchor_text": "Search Engine Optimizati"}, {"url": "https://medium.com/tag/cython?source=post_page-----2a870df219fb---------------cython-----------------", "anchor_text": "Cython"}, {"url": "https://medium.com/tag/python?source=post_page-----2a870df219fb---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&user=Will+Fuks&userId=e9c35a095d0d&source=-----2a870df219fb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&user=Will+Fuks&userId=e9c35a095d0d&source=-----2a870df219fb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2a870df219fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2a870df219fb---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2a870df219fb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2a870df219fb--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2a870df219fb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2a870df219fb--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2a870df219fb--------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://willian-fuks.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Will Fuks"}, {"url": "https://willian-fuks.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "229 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe9c35a095d0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&user=Will+Fuks&userId=e9c35a095d0d&source=post_page-e9c35a095d0d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa18136e4e9cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-extract-relevance-from-clickstream-data-2a870df219fb&newsletterV3=e9c35a095d0d&newsletterV3Id=a18136e4e9cd&user=Will+Fuks&userId=e9c35a095d0d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}