{"url": "https://towardsdatascience.com/ai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d", "time": 1682997717.7629619, "path": "towardsdatascience.com/ai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d/", "webpage": {"metadata": {"title": "AI Safety \u2014 How Do you Prevent Adversarial Attacks? | by Alex Moltzau | Towards Data Science", "h1": "AI Safety \u2014 How Do you Prevent Adversarial Attacks?", "description": "I made a commitment to write about AI Safety for 50 days, however recently I have focused more on AI Safety and ethics. I would argue the goals of how we are applying solutions within the field of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://zpascal.net/cvpr2018/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.pdf", "anchor_text": "Adversarial perturbation", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1707.08945.pdf", "anchor_text": "another article", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1610.02391", "anchor_text": "Grad-CAM", "paragraph_index": 18}, {"url": "http://www.nora.ai", "anchor_text": "www.nora.ai", "paragraph_index": 25}, {"url": "http://twitter.com/AlexMoltzau", "anchor_text": "twitter.com/AlexMoltzau", "paragraph_index": 25}], "all_paragraphs": ["I made a commitment to write about AI Safety for 50 days, however recently I have focused more on AI Safety and ethics. I would argue the goals of how we are applying solutions within the field of artificial intelligence is an equally important consideration within AI Safety as defence or attack. On the other hand the technical side of AI Safety is important to consider, therefore I will focus more on this aspect the next few days. Today I had a chat with Pin-yu and Sijia. Pin-Yu Chen and Sijia Liu are Research Staff Members of IBM Research AI (T. J. Watson Research Center), MIT-IBM Watson AI Lab.", "As per usual I will place a quick disclaimer in the beginning as there may of course be advanced concepts that I give lacking explanations, this is as much of a process for me to attempt understanding.", "Before I start looking at three papers on this topic I will touch upon the basic concept of adversarial machine learning and poisoning attacks.", "\u201cAdversarial machine learning: is a technique employed in the field of machine learning which attempts to fool models through malicious input. This technique can be applied for a variety of reasons, the most common being to attack or cause a malfunction in standard machine learning models.\u201d", "\u201cPoisoning attacks: machine learning algorithms are often re-trained on data collected during operation to adapt to changes in the underlying data distribution. For instance, intrusion detection systems (IDSs) are often re-trained on a set of samples collected during network operation. Within this scenario, an attacker may poison the training data by injecting carefully designed samples to eventually compromise the whole learning process. Poisoning may thus be regarded as an adversarial contamination of the training data.\u201d", "What Pin-Yu and Sijia is currently working on understanding a possible threat to avert it. Cyber defence focuses on sensing, detecting, orienting, and engaging adversaries in order to assure mission success and to out-manoeuvre that adversary. As such which type of techniques have been proposed to deal with these type of cyber attacks?", "A new concept called \u201cBlock Switching\u201d designed to provide a never-before-seen defense strategy against adversarial attacks by programming parts of an AI\u2019s model layers with randomly assigned run times so that it \u201cfools\u201d the adversary and prevents them from knowing and exploiting model layer weaknesses.", "In computer science, robustness is the ability of a computer system to cope with errors during execution and cope with erroneous input. Robustness can encompass many areas of computer science, such as robust programming, robust machine learning, and Robust Security Network.", "Is block switching a possible defence against adversarial perturbations? The results of their research may indicate so. Then again what is an adversarial perturbation?", "Adversarial perturbation: novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models.", "An important part is to enhance a model and keep test accuracy, and block switching seemingly manages to maintain both.", "\u201cBlock switching is easy to implement which does not require additional training data nor information about potential adversary. Also, it has no extra computational complexity than a regular model in the inference phase since only one channel is used at a time.\u201d", "The IBM researchers have proposed a new \u201cpruning method\u201d that can decrease the success rates of backdoor (harder to identify and track) attacks also known as poisoning attacks. In this research, scientists can identify infected neurons serving as the entry for backdoor attacks, and effectively remove them. The typical example, taken from another article, is the self-driving vehicle.", "There is as such an: \u201cArchitecture for training a model to fool multiple target networks. The fooling loss for training the generator is a linear combination of fooling losses of target models.\u201d", "In: \u201cDefending against Backdoor Attack on Deep Neural Networks\u201d Hao Cheng, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao and Xue Lin propose a pruning method.", "This paper investigates the internal responses of the backdoored deep neural network (DNN) and proposes an effective defensive method. They start from characterising the vanilla and backdoored DNNs through the Grad-CAM. To understand this statement let us run through the basics of what DNN, ANN and Grad-CAM is.", "Deep Neural Networks: is a neural network with a certain level of complexity, aneural network with more than two layers. Deep neural networks use sophisticated mathematical modeling to process data in complex ways.", "Artificial neural networks (ANN) or connectionist systems are computing systems that are inspired by, but not necessarily identical to, the biological neural networks that constitute animal brains. Such systems \u201clearn\u201d to perform tasks by considering examples, generally without being programmed with any task-specific rules.", "Gradient-weighted Class Activation Mapping (Grad-CAM): uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.", "An image gradient is a directional change in the intensity or color in an image.", "The researchers claim they will do further work on both defense and attack. On the defense side they will develop their pruning method to a more general and effective defensive method. For the attack side, they could also try to design a more powerful attack based on the characteristics discovered inthis paper.", "Cyber threat hunting is the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions. Offensive, proactive cyber activities and active cyber defence facilitate anticipatory threat reduction while informing protection, detection and incident response given its ability to engage the adversary at distance and time.", "I was so lucky to be able to catch an interview with Pin-Yu and Sijia, however that will be left for another day of #500daysofAI.", "This is day 74 of #500daysofAI. My current focus for day 50\u2013100 is on AI Safety. If you enjoy this please give me a response as I do want to improve my writing or discover new research, companies and projects. Please get in touch if you want to talk or discuss anything.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI Policy, Governance, Ethics and International Partnerships at www.nora.ai. All views are my own. twitter.com/AlexMoltzau"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fede17480a24d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://alexmoltzau.medium.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": ""}, {"url": "https://alexmoltzau.medium.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Alex Moltzau"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa26ca41a44b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&user=Alex+Moltzau&userId=a26ca41a44b7&source=post_page-a26ca41a44b7----ede17480a24d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://zpascal.net/cvpr2018/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.pdf", "anchor_text": "Adversarial perturbation"}, {"url": "https://arxiv.org/pdf/1707.08945.pdf", "anchor_text": "another article"}, {"url": "https://arxiv.org/abs/1610.02391", "anchor_text": "Grad-CAM"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ede17480a24d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&user=Alex+Moltzau&userId=a26ca41a44b7&source=-----ede17480a24d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&user=Alex+Moltzau&userId=a26ca41a44b7&source=-----ede17480a24d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fede17480a24d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ede17480a24d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ede17480a24d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ede17480a24d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ede17480a24d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ede17480a24d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ede17480a24d--------------------------------", "anchor_text": ""}, {"url": "https://alexmoltzau.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://alexmoltzau.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alex Moltzau"}, {"url": "https://alexmoltzau.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "http://www.nora.ai", "anchor_text": "www.nora.ai"}, {"url": "http://twitter.com/AlexMoltzau", "anchor_text": "twitter.com/AlexMoltzau"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa26ca41a44b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&user=Alex+Moltzau&userId=a26ca41a44b7&source=post_page-a26ca41a44b7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2efc0465f85b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-safety-how-do-you-prevent-adversarial-attacks-ede17480a24d&newsletterV3=a26ca41a44b7&newsletterV3Id=2efc0465f85b&user=Alex+Moltzau&userId=a26ca41a44b7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}