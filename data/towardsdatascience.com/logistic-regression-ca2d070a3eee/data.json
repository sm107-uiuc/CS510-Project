{"url": "https://towardsdatascience.com/logistic-regression-ca2d070a3eee", "time": 1682997767.939191, "path": "towardsdatascience.com/logistic-regression-ca2d070a3eee/", "webpage": {"metadata": {"title": "Logistic Regression. And implementation with Scikit-learn | by Samantha Jackson | Towards Data Science", "h1": "Logistic Regression", "description": "A member of the generalized linear model (GLM) family and similar to linear regression in many ways, logistic regression (despite the confusing name) is used for classification problems with two\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=BfKanl1aSG0", "anchor_text": "StatQuest", "paragraph_index": 9}, {"url": "https://github.com/MsJacksonIYN/BotOrNot_Twitter", "anchor_text": "Github", "paragraph_index": 20}, {"url": "https://www.youtube.com/watch?v=vN5cNN2-HWE", "anchor_text": "StatQuest with Josh Starmer: Logistic Regression Details Pt 1: Coefficients", "paragraph_index": 22}], "all_paragraphs": ["A member of the generalized linear model (GLM) family and similar to linear regression in many ways, logistic regression (despite the confusing name) is used for classification problems with two possible outcomes.", "Logistic regression is handy for classification problems since it fits an S shaped logistic (or Sigmoid) function to the data, squishing the linear equation to an output range of 0\u20131. This convenient range allows logistic regression to model the probabilities of a data point belonging to a particular class, typically with the decision point at the probability of .5.", "So, what does that look like in math? How does the sigmoid function squish the linear equation? As you may know, modeling the relationship between features and target variable for a linear regression looks like this:", "Logistic regression simply takes that linear equation, and uses it as the parameter for the sigmoid function to come up with the probability of the data point belonging to a particular class (in the case below, class 1):", "Since we\u2019ve squished our linear model into a probability range, the coefficients (or weights) of each feature no longer affect the output in an additive way. So, to interpret our models, we can re-stretch our sigmoid function from output range 0\u20131, back to +/- infinity by converting our probabilities to log(odds). We can do this with the logit function:", "Once on a log(odds) scale, we can interpret our coefficients just as we would a linear equation. Assuming all other features and weights remain constant:", "With linear regression, we find the best fit line by minimizing the mean squared error (MSE). However, because our line is on a log(odds) scale ranging from -infinity to +infinity, all of our labeled observations have a value of either +/- infinity. This happens because we are 100% sure which class our label data belongs to. Therefore an observation belonging to class 1, for example, has a Pr(y = 1) = 1. Putting this into the logit function results in:", "Since labeled observations have a y-value of +/- infinity, the values of the residuals, no matter the prospective line fit to the data, are +/- infinity. And without reasonable values for residuals, we can\u2019t use the least squares method to optimize our line. Logistic regression instead uses Maximum Likelihood for optimization.", "To find the maximum likelihood for our prospective line, we project the observations onto the line on the log(odds) scale (creating a prospective log-odds value for each observation), transform the log(odds) to probabilities, and calculate the log-likelihood of the line by adding the log(probabilities that each datapoint would be classified as its label). Then, similar to the least squares method, we keep rotating the log(odds) line and projecting the data onto it, transforming the log(odds) to probabilities, and calculating the log-likelihood. We do this until we find the line with the largest maximum likelihood.", "For a better conceptual understanding of maximum likelihood applied to Logistic Regression, I recommend checking out this StatQuest video.", "I have some data about Twitter accounts, and I\u2019ll use logistic regression to predict if the accounts are real or not. My features for each Twitter account are:", "I\u2019ve split my dataset into a training set and a testing set, and have transformed the continuous variables to a scale range of 0\u20131. I\u2019ve also taken care of any null values. So, it\u2019s time to see if I can create a model that will predict whether an account is fake or not.", "Because I have quite a few features and my intuition (after looking at a correlation matrix) is that not all will be useful, I opted for L1 regularization so that features can be penalized to 0. However, I wanted to tune the hyperparameter, C, so that regularization was useful but wasn\u2019t decreasing the accuracy of my model by too much.", "You\u2019ll notice that my first step is to instantiate a LogisticRegression object. Here, I select 'l1' regularization, my hyperparameter C=c and my solver. This is a pretty standard format for scikit-learn across the machine learning algorithms: you need create an object of the algorithm before fitting it to your data.", "After some more testing, I opted for C=.1 because I felt it eliminated a good chunk of my features (reducing my model complexity) without too large of a compromise on accuracy.", "Because scikit-learn syntax is almost exactly the same for many machine learning algorithms, I tend to use this function to fit classification models:", "So, creating a LogisticRegression object and using my function looks like this:", "As you can see, my test accuracy is a pretty decent 92.5%. This means that my model accurately classified 92.5% of the testing data. To find the weights for my features, I can call lr.coef_. After putting the coefficients into a data frame and sorting, we can see that a number of the features were not terribly useful to the accuracy of our model.", "And plotting the coefficients looks like this:", "Logistic Regression is a useful classification algorithm that is easy to implement with scikit-learn. A regularized logistic regression can also useful for feature selection.", "In addition to the code snippets here, my full Jupyter Notebooks can be found on my Github.", "Please feel free to comment for any reason! I\u2019d love to discuss your thoughts.", "StatQuest with Josh Starmer: Logistic Regression Details Pt 1: Coefficients", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist // Flatiron School Alumni"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fca2d070a3eee&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sjacks?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sjacks?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Samantha Jackson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F358d1e109fb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&user=Samantha+Jackson&userId=358d1e109fb1&source=post_page-358d1e109fb1----ca2d070a3eee---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=BfKanl1aSG0", "anchor_text": "StatQuest"}, {"url": "https://gist.github.com/MsJacksonIYN/a881933a22f5fd8219fff49be33c1535", "anchor_text": "here"}, {"url": "https://github.com/MsJacksonIYN/BotOrNot_Twitter", "anchor_text": "Github"}, {"url": "https://www.youtube.com/watch?v=vN5cNN2-HWE", "anchor_text": "StatQuest with Josh Starmer: Logistic Regression Details Pt 1: Coefficients"}, {"url": "https://christophm.github.io/interpretable-ml-book/logistic.html", "anchor_text": "Interpretable ML Book"}, {"url": "https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_with_l1_regularization/", "anchor_text": "Chris Albon"}, {"url": "http://www.themlbook.com/", "anchor_text": "The Hundred-Page Machine Learning Book"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ca2d070a3eee---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----ca2d070a3eee---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----ca2d070a3eee---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&user=Samantha+Jackson&userId=358d1e109fb1&source=-----ca2d070a3eee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&user=Samantha+Jackson&userId=358d1e109fb1&source=-----ca2d070a3eee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fca2d070a3eee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ca2d070a3eee---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ca2d070a3eee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sjacks?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sjacks?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Samantha Jackson"}, {"url": "https://medium.com/@sjacks/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "184 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F358d1e109fb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&user=Samantha+Jackson&userId=358d1e109fb1&source=post_page-358d1e109fb1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2ee5272d75e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-ca2d070a3eee&newsletterV3=358d1e109fb1&newsletterV3Id=2ee5272d75e2&user=Samantha+Jackson&userId=358d1e109fb1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}