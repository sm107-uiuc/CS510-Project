{"url": "https://towardsdatascience.com/create-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245", "time": 1682993993.7130702, "path": "towardsdatascience.com/create-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245/", "webpage": {"metadata": {"title": "Create AI for your Own Board Game From Scratch \u2014 AlphaZero-Part 3 | by Haryo Akbarianto Wibowo | Towards Data Science", "h1": "Create AI for your Own Board Game From Scratch \u2014 AlphaZero-Part 3", "description": "Hello everyone, welcome to the part 3 of making AI on the EvoPawness (Temporary Name). In this article, we will implement AlphaZero Algorithm to the game. This article will tell you a short summary\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess", "anchor_text": "this", "paragraph_index": 11}, {"url": "https://medium.com/u/2d3c4b088dc6?source=post_page-----f22761372245--------------------------------", "anchor_text": "David Foster", "paragraph_index": 17}, {"url": "http://mcts.ai/about/index.html", "anchor_text": "here", "paragraph_index": 67}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8", "anchor_text": "Create AI for Your Own Board Game From Scratch \u2014 Preparation \u2014 Part 1", "paragraph_index": 124}, {"url": "https://medium.com/@haryoaw/create-ai-for-your-own-board-game-from-scratch-minimax-part-2-517e1c1e3362", "anchor_text": "Create AI for Your Own Board Game From Scratch \u2014 Minimax \u2014 Part 2", "paragraph_index": 125}, {"url": "https://medium.com/u/5178b198735a?source=post_page-----f22761372245--------------------------------", "anchor_text": "Thomas Simonini", "paragraph_index": 127}], "all_paragraphs": ["Hello everyone, welcome to the part 3 of making AI on the EvoPawness (Temporary Name). In this article, we will implement AlphaZero Algorithm to the game. This article will tell you a short summary of the AlphaZero and the implementation of the AlphaZero, albeit the simplified one. We will do it in a step by step. We will use some of terminology stated in the Part 1 such as Result Function, Possible Actions, and Terminal Function.", "The experiment is not done yet. It takes a long time to train the agent for this game, especially with a single computer. I\u2019ve trained the agent for a day. Unfortunately, the agent is still not good enough. Even so, It has learnt a few strategy such as attacking the king continuously with knight if the knight can attack the king.", "I stopped training the agent to let my computer rest. I\u2019m afraid my laptop will be broken if I force it to train more than a day. I also limited the hyperparameter of the AlphaZero to speed up the training time. I\u2019m sorry for my limited resources on doing this experiment \ud83d\ude3f.", "Even though the experiment is not complete, I will try to write how I implement the AlphaZero on this game. I hope that it will give an enlightenment to someone who want to learn about a reinforcement learning algorithm, AlphaZero, and implementing them to their game.", "I\u2019ve made several changes on the game\u2019s rule. The game still remains deterministic.", "This article is targeted for the one who is interested in AI and designing a game. If you are not one of them, of course you can still see this article. I hope that my writing skill will increase by publishing this article and the content benefits you \ud83d\ude04.", "Brace yourself, It will be a long article. It has 25 minutes read !", "In case you start reading the progress of the game with this article, here is the repository:", "I\u2019ve added several changes to the repository:", "Note : For now, I suggest that you do not try to train the model until I refactor and clean the code. And also, the code is still super messy, I will try to clean and refactor it as soon as possible. In the next Saturday, I will try to do it.", "Edit (3/12/2018) : I have cleaned the code. Now we have Config.py to edit the configuration. See main.py -h on how to launch the program. For further information, wait for me to edit the README.md tomorrow.", "AlphaZero is created by Deep Mind which is published in the following paper [Source 4]. What makes it special is that it can beat the best AI of chess and shogi under 24 hours training. It makes this algorithm is the best at that time on AI game. For further information you can see this article on how powerful this algorithm can be.", "It also don\u2019t have human expertise as the input (except the rule of the game). It learns from zero to become the best AI game program which beat the best AI for the board game at that time.", "I also find that the algorithm is very simple yet astonishing. The algorithm will explore the possible paths that is promising with the current knowledge. The searched path will tell whether the current path is favourable or not. The score of how favourable it is is backed down and be used to be a consideration whether this path should be explored again.", "After the exploration on thinking the future possibility, take the action that is explored the most. It means that this action can be good if this path is often explored.", "At the end of the game, evaluate whether the path that it choose match to the outcome of the game. It tells us whether the knowledge misjudged the path that is chosen when exploring the possible future paths. The knowledge will be updated according to the outcome of the game.", "The AlphaZero need the game with perfect information (the game state is fully known to both players) and deterministic. Since this game has both of them, AlphaZero algorithm can be used to this game.", "In this article, we will simplify the architecture used on the paper. We will use a simplified AlphaZero implementation based on the article that I\u2019ve read. In the implementation used by David Foster [Source 2], he uses 4 residual layers that is connected to a policy head and a value head. I used his architecture and change some hyperparameters. I also see the implementation of the AlphaZero in the [Source 1] and modify the implementation to suit this game. I follow the Monte Carlo Tree Search implementation in that article and change the implementation from using recursive to structure data tree.", "The implementation used on these articles are inline with the paper with some skipped parts. There are several steps that I skipped such as v resignation. In these two articles, they do not implement the stacked state. In this article, I implement the stacked state and using 140 planes as the input of the model. In this article, the implementation of the AlphaZero also haven\u2019t implemented multi-thread MCTS by using virtual loss yet.", "This article will implement the AlphaZero in the following order:", "Before we go to this part, I suggest that if you haven\u2019t read the part 1, read it. It will cover the rules of the game.", "We will see the representation state for the input of the neural network in this section. The input of the neural network is an image stack that represents the state. There are 28 input features used in the implementation. Here, we will use 5-step history (Note : in the paper of AlphaZero, the number of step history is 8. Here, this article will try a different number). From the number of step-history that we use, it means that there are 140 input features (28 X 5).", "The history will save the state representation at the previous turn. If we use 5-step history, given the state is at T turn, we will take T, T-1, T-2, T-3, T-4 state that will be stacked and become input for the neural network.", "No 4\u201310, 13 use binary features whereas the others use frequency features.", "Since, the board is 9 x 9, if we have batch_size as the total instance of the input of neural network, we have (batch_size, 9, 9, 140) shape as the input of the neural network. So, we have 4 dimensional data as the input.", "For the code, you can see the get_representation_stack() function in the source code below:", "In the source code, we will use AIElements class which contains the elements that we define in the part 1. We use deque as our data structure (like stack).", "Before we get the input representation of the neural network, we will stack the state, the state representation that we defined at Part 1, into a deque data structure with the desired max length (in this article, we set it to 5). Then we process the deque and change it into an input representation for the neural network.", "There are 5 type of actions that is available in the game. There are Activate, Promote, Move, Attack, and Skip.", "For the activate action, we need to select the pawn that want to be activated. We need the coordinates of the pawn. So we have 81 (9 x 9) different unique activate actions.", "Note: we have a different action key representation that is stated in the Part 1, the new representation is stated below:", "For the Promote action, we need to select the pawn that want to be promoted then select the possible choice to promote the pawn. We need the coordinates of the pawn . We have 9 x 9 different unique actions for selecting the possible pawn. There are 4 promoted pawn type (Queen, Rook, Bishop, Knight), so there are 324 (9 x 9 x 4) unique way to do the promote action.", "For the attack and move action, In this game, we have 7 type of pawns. The direction of the move has been defined in the Part 1. In the part 1, we have attack and move as separate action. In this article, we will combine the attack action and the move action into one (they don\u2019t overlap, so we can combine them). We can see that the direction of move of Soldier, Rook, Bishop, and King is a subset of the Queen. It moves vertical, horizontal, and diagonally in the N, NE, E, SE, W, SW, W, and NW direction. Only knight has different moves. It moves in L-shape in all points direction of the compass. In summary, we have 2 type of moves, Queen and Knight.", "We have 2 steps on doing the action: selecting the pawn and selecting the legal move for the pawn based on the possible action. In this case, we have 81 (9 x 9) different actions for selecting the pawn. Then for selecting the legal move, we have 8 different actions for knight move\u2019s type and 24 (8 x 3) for queen move\u2019s type (Note : we have 3 as the limit of step points, so the queen move can consists of 24 type of move). The total of unique actions that can be made is 2592 (81 x 32) for selecting the legal move for attack and move action.", "Skip if the player cannot do anything.", "The action representation is used to encode the probability distribution that is used for selecting the action later on doing the Monte Carlo Tree Search (MCTS). Later, the action that is not possible to do in the state is masked and set the probability to 0 and re-normalize the probability distribution for the possible action.", "See the repository for the implementation on how to generate all possible action. I used LabelEncoder and OneHotEncoder provided in scikit-learn library to encode the action into One Hot Encoder.", "One Hot Encoder Class (see fit()):", "Generate all unique actions (see action_spaces() function):", "In the paper of AlphaZero, we need to orientate the perspective of the board to the current player. We must decide which side will be the perspective for both players. I choose white as the perspective or Point of View (POV) for both players. So if the current turn is black player, we will make the black player perspective become the white player perspective. If the current turn is white player, we will not change the player perspective.", "If this is a chess game, it will be easy. Just invert the color of the pieces. In this game, we cannot do that. The king is fixed at that position and cannot move. So, inverting the pieces will make the state invalid. So how can we do it?", "We need to mirror or reflect the position of each pawns. After that, invert the color of all the pawns.", "We do that to all of the pawns (King included). We have mirrored the position of the pawns.", "As we change the perspective of the board by changing the pawn\u2019s position, we need to change the action too. We need to mirror the coordinates of the action and the direction if the action is move or attack. It\u2019s similar to change the position of the pawn, we will change the coordinates of the action by mirroring the coordinates by manipulating the y-axis. For the direction, we only need to multiply the y-axis by -1.", "That\u2019s it how we change the perspective of the player.", "For the implementation, see all of the functions defined in this source code:", "It\u2019s essentially the same as the pseudocode, but in OOP way. We will change the attributes of all the object of pawns. The mirror of the action is also defined at the source code.", "We should define some identical states that can be used for the input of the neural network if the game have it. Later, it can be used to increment the input of the neural network. Also, in the paper, the identical state will be used to evaluate the the state in the leaf node of the MCTS, where it will be uniformly selected at random. The identical states usually is a dihedral reflection or rotation of the original state. I think, the purpose of this component is to make the training faster and make sure to include the state that should have the same situation or evaluation.", "Unfortunately, this game doesn\u2019t have the identical states. So we cannot use this component for this game.", "We will use Reward Function to tell the final outcome whether the agent is win or lose. Since we use Monte Carlo Tree Search, we will call the Reward Function at the terminal state. Then it will become the output of the neural network that we want to optimize.", "The reward function is the utility function that we defined at part 2. We will normalize the value to the range to {-1,1}. Here\u2019s the high-level pseudocode implementation:", "Since the reward is only called when the state is in terminal state, this is called sparse reward. The neural network will be trained to evaluate and predict the reward when the state is not terminal.", "For the implementation, you can see the State.sparse_eval() function. how the terminal state is called is defined in the Part 1.", "In this section, we will create the architecture of the neural network used in the AlphaZero. In the paper, they use 20 residual blocks followed by policy head and value head. They used it because it\u2019s the state-of-the-art deep learning architecture at that time in the Computer Vision tasks. Of course, we won\u2019t use that. Especially for me who have a low-budget and minimum resource for doing this experiment \ud83d\ude22.", "Instead, we will use a simplified architecture. We use the architecture defined in the [Source 2] with several changes. Here\u2019s the architecture:", "So, we will have 4 residual blocks with 2 CNNs followed by a policy head and and value head.", "The hyperparameter is also simplified. The output units of each layer is reduced according to my GPU. I think that the hyperparameter used in that article is enough. So, We will follow the hyperparameter used in that article with little changes (such as increase or decrease the output units by a little).", "The input of the neural network is the state representation that we have defined above.", "There are two outputs of the neural network, a scalar features v and vector of move probabilities p. The range of the output of neural network is {-1,1} for the v and {0,1} for the p. This is why we use tanh for the activation function for the v and softmax for the activation function for the p.", "The neural network will minimize the following objective function:", "Where v\u03b8(st) is the output of value head, a scalar one, which evaluate the situation of the current state and p\u03b8(st), the output of policy head, is the predicted policy from state st.", "v\u03b8(st) will be trained to be as close as zt, which is the final outcome of the game for a player in respect to the perspective of the chosen Point of View (POV). in our case, the POV is the white player. zt value can be -1, 0, or 1 depending on the outcome of the game. v\u03b8(st) will be trained to calculate the evaluation of the current state.", "The \u03c0t is the estimate of the policy from state st. We also need to train the parameter of the neural network so that p\u03b8(st) is close enough with the \u03c0t. p\u03b8(st) will be a vector of probability distribution which tell us that the higher the value, the good the action is and has a high chance to be chosen. It will be trained to be as close as \u03c0t. How to get \u03c0t is defined in the next section. Of course, it also needs to be same perspective of the chosen POV.", "The optimizer is using Adam Optimizer with the defined learning rate.", "So, in summary, we will minimize the error on predicting the evaluation of the current state and the policy of the current state. Let the batch_size is the total instance to be input of our Neural Network, The input shape is (batch_size, 9,9,140) for the state representation. There are two outputs, the policy head and value head. Policy head has (batch_size, 2998) (the total of unique actions) and value head has (batch_size, 1) shape.", "Later, the neural network model is used in the Monte Carlo Tree Search simulation for evaluating and predicting the policy (policy evaluation) of the state. The model will be optimized to minimize the loss at the end on every episodes.", "For the implementation, see below (class PawnNetZero):", "Before we dive into the Monte Carlo Tree Search, I suggest to read a brief description about MCTS here.", "We will use the Monte Carlo Tree Search to improve the policy estimation quality (policy improvement). This will be the component to predict the action of an agent given a state. The MCTS is used for simulating the game, which is self-learning (The agent plays as two players that alternately takes the turn). For every step at each episodes ( one full game), the MCTS is simulated until the given number of simulation. It\u2019s also a search algorithm like minimax that we previously used, but the MCTS won\u2019t expand all possible action and use guided \u2018heuristic\u2019 instead to determine which node to be expanded.", "The tree in MCTS will consists of nodes that represent a board configuration. A directed edge exists between each nodes represents the valid action of a state. The edge is different from Minimax Tree Search,not only to save the action name, the edge has several parameters that will be updated each simulations.", "The edge will contains several parameter that we will be updated:", "Whereas the node will contain several parameter:", "At the start of each episodes, the MCTS is initialized with a single root node. The root node is also act as a leaf node when it is initialized. From this root, the MCTS will expand the tree until the limit number of simulation is reached.", "After we initialize the tree, there are 4 steps on doing the MCTS in AlphaZero:", "The step 1\u20133 is iterated by the number of simulations and then do the step 4.", "The simulation in the MCTS will begin at the root node (s0), and finishes if the simulation encounter the leaf node sL at time step L. At each of these time steps, for every node that is already expanded in the Expand and Evaluate step, an action is selected according to the parameter in the edge of each node. Here we will select the action a in the state s which has the highest U(s,a), the Upper Confidence Bound using variant of the PUCT algorithm.", "where cpuct is a hyperparameter to determine the level of exploration. sum of N(s,b) is equal to N(s).", "where \u03b7 is probability distribution by using Dirichlet noise with the chosen parameter and e is 0.25 . This will make the exploration to try all the moves in the root state.", "This step will be done until the leaf node is found. If leaf node is found, the Expand and Evaluate step is called.", "If the current node is the leaf node, this action will be performed. We will evaluate the state sL with the representation that we have defined above to be the input of the neural network. It will output the policy and the value of evaluation of the current state.", "The input will be transformed into any identical state at random in uniform probability distribution (It can choose the unchanged one). Because we don\u2019t have it in this game, the state won\u2019t be transformed and the input of neural network will always be the same. so in the implemention of EvoPawness (Temporary Name), the output of function di will return the sL without transforming the form.", "The output is the policy p and the value v for the state sL explained in the previous section. If p is the action of the transformed state, the action should be transformed back to be the method of the original state.", "in p, the invalid action probability will be masked and the valid action will be normalized, so that the vector will sum to one.", "Then, the Leaf node is expanded with edge containing all possible action in that state. Each edge and the leaf node parameter is initialized to :", "After we expand the leaf node (sL), the parameter will be updated in a backward pass to all of the parent\u2019s node until root node, which is through each step t \u2264 L. These parameters will be updated as follow:", "Note that v = v * -1 if st 's player is different than sL. for example: st\u2019s turn is black and sL\u2019s turn is white. Since this is a zero sum game, the evaluation of opposite player (v) will be the negative of the current player.", "After do Backup steps, do the Select step from the root node again if the maximum of number of simulation hasn\u2019t been reached.", "These steps will be iterated until maximum of number of simulation is reached. If it has been reached, do this step:", "At the end of the search, it is time to select the action a in the root position s0 based on the parameter updated at simulations. Probability of action a given root state (\u03c0a|s) is selected proportional to the exponentiated visit count N(s,a) counted at the simulation.", "We will calculate the policy of all the action with the following formula:", "Where \u03c4 is a temperature that is used to control the degree of exploration. When the turn or step in the game is lower than 30, the \u03c4 is set to 1, infinitesimal otherwise.", "The high-level pseudocode implementation of the MCTS is as follow:", "The implementation can be found here:", "Note that the implementation in the repository will be different but it has the same objective. In the repository, I include select, expand, and evaluate step in the \u2018expand()\u2019 function.", "For maintaining the quality of the model, we must ensure that the model that is used is the best one. To do that, AlphaZero will compare the quality of the the current best model and the current model. It\u2019s quite easy to do it. We need two agents that will fight each other.", "These models are pitted each other for n round by the chosen max simulation and limited by max_step to prevent the game from infinite loop that will make the terminal state unreachable. This will return the score which will determine the best model. n can be fill by any number.", "If the current model wins by a chosen margin (in the paper 55%), the best model is replaced by the current model. The best model is used for the next episode.", "If the best model wins, the best model remains to be used for the next episode.", "We will initiate 2 MCTS, one with the best model neural network and the other with current neural network. The color of the player can be decided by yourself (for example : white is best model and black is current model).", "The implementation can be found here (fight_agent() function):", "That\u2019s it. We have defined all the components ready for the AlphaZero. Now we will connect all of our defined components and do the AlphaZero algorithm.", "After we define all the component that will be used for the MCTS, let\u2019s wrap it up.", "The step of implementing AlphaZero based on the components that we have defined is as follow:", "When the step is doing the self-play, we will do the steps as below:", "First, we need to initiate the state of the game and the MCTS. Then, do the following:", "First, we fill the parameter inside the MCTS (self_play()), then we get the action probability on the root (play()). We fill the deque with the action, the state, and the player information. After the state reached the terminal or the max step, we finally add the reward information to the deque.", "After we fill the reward on the deque, we will append the content of the deque to the global deque which will be used to train the neural network.", "The self_play function is a MCTS simulator which acts this way:", "That\u2019s it, so every simulation of MCTS will simulate until leaf node is found. If it has been found, then do the expand and evaluate. If not, do the selection.", "That\u2019s it, we have defined the how to create the AlphaZero implementation to the game.", "For the implementation, you can see the fit_train() and on the train_module.py in the repository.", "To run the training, use main_from_start.py for training from the start. and main_from_continue.py to train from the checkpoint. For now, I suggest that you don\u2019t try to train the model until I\u2019ve refactored and clean the code. I plan to do it on next Saturday.", "Below is the code of main_from_start.py", "There are several lesson that I learnt on implementing the AlphaZero.", "In this article, we have constructed all the components that will be used to implement the AlphaZero. We also have implemented the AlphaZero algorithm. This article haven\u2019t told the result of the AlphaZero yet since the training is not done yet.", "This article still use a single GPU on training the model. It also uses a single thread to run the simulation of MCTS. So, the training will be very slow.", "Woah, look at my 25 minutes read time article \ud83d\ude06. Finally the article is done and published. Thanks to the several articles that I\u2019ve read, I can experiment the AlphaZero algorithm and understand the algorithm.", "Since the training is not done yet, I plan to create the next part that will focus on the improvement and the result of implementing AlphaZero to this game. Unfortunately, with the limited resource that I have, I\u2019m afraid that this project will be on hold until I get a new computer to experiment it. Well, you see, I\u2019m unemployed (for several reasons) so I have limited money here \ud83d\ude22.", "I will try to fix the mess of the code and make it to be executed easily next week. Currently, the code is very messy and has high verbosity when the program is run.", "I welcome any feedback that can improve myself and this article. I\u2019m in the process of learning on writing and reinforcement learning. I really need a feedback to become better. Just make sure to give feedback in a proper manner \ud83d\ude04.", "Oh, I promised to tell you the details of the project structure and the GUI at the last part. Sorry, I forgot to write it \ud83d\ude05. If I have the time, I will write it on my next article.", "For my several next projects, I will focus on NLP or Computer Vision tasks. I will write something about using GAN on these tasks. I want to learn GAN and implement it, since it\u2019s a hot topic in the Deep Learning at the moment.", "If you want another article from me like this one, please clap this article \ud83d\udc4f \ud83d\udc4f. It will boost my spirit to write my next article. I promise to make a better article about AI .", "See ya in my next article!", "Part 1 : Create AI for Your Own Board Game From Scratch \u2014 Preparation \u2014 Part 1", "Part 2 : Create AI for Your Own Board Game From Scratch \u2014 Minimax \u2014 Part 2", "Part 3 : Create AI for your Own Board Game From Scratch \u2014 AlphaZero-Part 3", "Thanks Thomas Simonini for suggesting me to move on implementing the Deep Q Network to Policy Based Learning.", "Mad AI Enthusiast. I write mostly about Artificial Intelligence and Self Development. I also love to read Engineering, Psychology and Startup. Love to share!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff22761372245&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://haryoaw.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Haryo Akbarianto Wibowo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d82e5d56c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=post_page-6d82e5d56c2----f22761372245---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff22761372245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----f22761372245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff22761372245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=-----f22761372245---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@mvdheuvel?utm_source=medium&utm_medium=referral", "anchor_text": "Maarten van den Heuvel"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://pixabay.com/en/cat-sad-cute-small-sweet-pet-3266673/", "anchor_text": "Source : https://pixabay.com/en/cat-sad-cute-small-sweet-pet-3266673/"}, {"url": "https://github.com/haryoa/evo-pawness", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess", "anchor_text": "Source : https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess"}, {"url": "https://en.chessbase.com/post/the-future-is-here-alphazero-learns-chess", "anchor_text": "this"}, {"url": "https://medium.com/u/2d3c4b088dc6?source=post_page-----f22761372245--------------------------------", "anchor_text": "David Foster"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/util/stacked_state.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/util/action_encoder.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/util/alphazero_util.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/util/state_modifier_util.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/model/state.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/alpha_zero/deep_net_architecture.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "http://mcts.ai/about/index.html", "anchor_text": "here"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/alpha_zero/mcts.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://pixabay.com/en/knight-sword-fighting-middle-ages-2551859/", "anchor_text": "https://pixabay.com/en/knight-sword-fighting-middle-ages-2551859/"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/alpha_zero/train_module.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/reinforcement_learning_train/alpha_zero/train_module.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://github.com/haryoa/evo-pawness/blob/master/main_from_start.py", "anchor_text": "haryoa/evo-pawnessSelf project Evo Pawness (Temporary Name). Contribute to haryoa/evo-pawness development by creating an account on\u2026github.com"}, {"url": "https://pixabay.com/en/cat-cat-face-sleep-exhausted-1551783/", "anchor_text": "https://pixabay.com/en/cat-cat-face-sleep-exhausted-1551783/"}, {"url": "https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png", "anchor_text": "https://cdn.pixabay.com/photo/2017/07/10/16/07/thank-you-2490552_1280.png"}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8", "anchor_text": "Create AI for Your Own Board Game From Scratch \u2014 Preparation \u2014 Part 1"}, {"url": "https://medium.com/@haryoaw/create-ai-for-your-own-board-game-from-scratch-minimax-part-2-517e1c1e3362", "anchor_text": "Create AI for Your Own Board Game From Scratch \u2014 Minimax \u2014 Part 2"}, {"url": "https://web.stanford.edu/~surag/posts/alphazero.html", "anchor_text": "[Source 1] Simple Alpha Zeroweb.stanford.edu"}, {"url": "https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188", "anchor_text": "[Source 2] How to build your own AlphaZero AI using Python and Kerasmedium.com"}, {"url": "https://medium.com/u/2d3c4b088dc6?source=post_page-----f22761372245--------------------------------", "anchor_text": "David Foster"}, {"url": "https://medium.com/u/5178b198735a?source=post_page-----f22761372245--------------------------------", "anchor_text": "Thomas Simonini"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f22761372245---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f22761372245---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----f22761372245---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/projects?source=post_page-----f22761372245---------------projects-----------------", "anchor_text": "Projects"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f22761372245---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff22761372245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----f22761372245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff22761372245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----f22761372245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff22761372245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d82e5d56c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=post_page-6d82e5d56c2----f22761372245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8ef926c2bc14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&newsletterV3=6d82e5d56c2&newsletterV3Id=8ef926c2bc14&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----f22761372245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Written by Haryo Akbarianto Wibowo"}, {"url": "https://haryoaw.medium.com/followers?source=post_page-----f22761372245--------------------------------", "anchor_text": "407 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d82e5d56c2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=post_page-6d82e5d56c2----f22761372245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8ef926c2bc14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-ai-for-your-own-board-game-from-scratch-alpha-zero-part-3-f22761372245&newsletterV3=6d82e5d56c2&newsletterV3Id=8ef926c2bc14&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----f22761372245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Haryo Akbarianto Wibowo"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Create your own board game with powerful AI from scratch \u2014 Part 1Based on my little project about a board game that I come up with, EvoPawness (Temporary Name)"}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "16 min read\u00b7Oct 17, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5dcb028002b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----5dcb028002b8----0-----------------clap_footer----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8?source=author_recirc-----f22761372245----0---------------------3457e801_d4d4_4938_85b3_95db39829790-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5dcb028002b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8&source=-----f22761372245----0-----------------bookmark_preview----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f22761372245----1---------------------3457e801_d4d4_4938_85b3_95db39829790-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----f22761372245----1-----------------bookmark_preview----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f22761372245----2---------------------3457e801_d4d4_4938_85b3_95db39829790-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----f22761372245----2-----------------bookmark_preview----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/create-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Haryo Akbarianto Wibowo"}, {"url": "https://pub.towardsai.net/?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/create-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "Create Indonesian Recipe Generator by Fine-tuning T5, BART, and GPT-2An Indonesian recipe generator Deep Learning model trained by fine-tuning pre-trained models such as T5, BART, and GPT-2"}, {"url": "https://pub.towardsai.net/create-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": "7 min read\u00b7May 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Fa7fc0551190e&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fcreate-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e&user=Haryo+Akbarianto+Wibowo&userId=6d82e5d56c2&source=-----a7fc0551190e----3-----------------clap_footer----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/create-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e?source=author_recirc-----f22761372245----3---------------------3457e801_d4d4_4938_85b3_95db39829790-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7fc0551190e&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fcreate-indonesian-recipe-generator-by-fine-tuning-t5-bart-and-gpt-2-a7fc0551190e&source=-----f22761372245----3-----------------bookmark_preview----3457e801_d4d4_4938_85b3_95db39829790-------", "anchor_text": ""}, {"url": "https://haryoaw.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "See all from Haryo Akbarianto Wibowo"}, {"url": "https://towardsdatascience.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----f22761372245----0-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----f22761372245----1-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----f22761372245----0---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----f22761372245----0-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "LucianoSphere"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Build ChatGPT-like Chatbots With Customized Knowledge for Your Websites, Using Simple ProgrammingLike ChatGPT but in a form that you can plug into your website and expand with any kind of tailored information by combining basic\u2026"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b711 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&user=LucianoSphere&userId=d28939b5ab78&source=-----f393206c6626----1-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----f22761372245----1---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&source=-----f22761372245----1-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----2-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f22761372245----2---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----f22761372245----2-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----3-----------------clap_footer----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----f22761372245----3---------------------684a8c6b_0a8a_47c7_b096_30fe24494868-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----f22761372245----3-----------------bookmark_preview----684a8c6b_0a8a_47c7_b096_30fe24494868-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f22761372245--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----f22761372245--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----f22761372245--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f22761372245--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f22761372245--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f22761372245--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----f22761372245--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}