{"url": "https://towardsdatascience.com/model-explainability-and-jrt-ai-b420531a0d49", "time": 1683011296.937732, "path": "towardsdatascience.com/model-explainability-and-jrt-ai-b420531a0d49/", "webpage": {"metadata": {"title": "Model Explainability and JRT AI. JRT (Justifiable, Responsible and\u2026 | by Kamala Kanta MISHRA (Kamal) | Towards Data Science", "h1": "Model Explainability and JRT AI", "description": "Model explainability is getting more and more common and mainstream into AI models and usage in today\u2019s scenario. Expectation is to understand what is happening in detail and the \u201chow\u201d part of any\u2026"}, "outgoing_paragraph_urls": [{"url": "https://nbviewer.jupyter.org/github/kkm24132/BRUG/blob/8c5e0d15b1250f86a47d288a6ea9912279fe2b8a/src/MLExplainability_using_LIME.ipynb", "anchor_text": "my GitHub code reference here", "paragraph_index": 38}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "Interpretable Machine Learning : A guide for making black box models explainable", "paragraph_index": 41}, {"url": "https://arxiv.org/abs/1602.04938", "anchor_text": "Paper by Marco et al (2016)", "paragraph_index": 42}, {"url": "https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html", "anchor_text": "A reference to LIME example usage with iris dataset by Marco", "paragraph_index": 43}, {"url": "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf", "anchor_text": "Paper: A unified approach to interpreting model predictions by Lundberg and Lee", "paragraph_index": 44}, {"url": "https://arxiv.org/pdf/1802.03888.pdf", "anchor_text": "Paper: Consistent individualized feature attribution for tree ensembles by Lundberg et al 2019", "paragraph_index": 45}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6467492/pdf/nihms-1505578.pdf", "anchor_text": "Paper: Explainable ML predictions for the prevention of hypoxaemia during surgery", "paragraph_index": 46}, {"url": "https://arxiv.org/pdf/1909.09223.pdf", "anchor_text": "InterpretML : A unified framework for ML Interpretability", "paragraph_index": 47}], "all_paragraphs": ["Model explainability is getting more and more common and mainstream into AI models and usage in today\u2019s scenario. Expectation is to understand what is happening in detail and the \u201chow\u201d part of any algorithm or model or with regards to the machine learning pipeline that is used to solve a business use case. Businesses need to get control of what is the decision out of AI models and how it is framed. The attempt here is to cover this topic considering usage and execution around these concepts including reference to few libraries that can be leveraged.", "It is important to understand the ModelOps or operationalization dimension too. Obviously, it is more about adoption and usage since more models are being developed, there is a need for model management and monitoring of multiple models, experiments etc. which correlates to the fact that why we should consider the best model and for what reason.", "We should focus on any solution that is justifiable, that is responsible and that is transparent. (hence abbreviating the need for JRT AI \u2014 Justifiable, Responsible and Transparent AI).", "I would like to structure the content around the following agenda points:", "ii. What is explainable AI/ML solution?", "iii. Why do we need explainability of AI/ML solutions?", "iv. Do we really need explainability all the time?", "Now let\u2019s dive into each of these dimensions.", "There are certain references of legislation and developments in managing risk are to be considered which may impact a decision using a data science model or algorithm or solution. A couple of references could be read as per below reference:", "ii) What is explainable AI/ML solution?", "Some questions that come up to mind are:", "How do we build trust in ML models or solutions?", "How do we know what is happening as part of our ML solution?", "How can we ensure we know details from the model/solution so that we can expect consistency for a period of implementation duration into future? (i.e. if my prediction accuracy is X%, how can it be consistent around X% or with some +- threshold limits in next few models and how can we get a grip on that?) and so on.", "iii) Why do we need explainability of AI/ML solutions?", "Well, it could be due to various aspects.", "a) Model bias, ethics, fairness : Are there any discriminations due to model outcome? e.g. Promotion of employee based on last few years of historical data, to promote based on certain dimensions like gender for example. Loan default problem or loan grant decision \u2014 does it impact due to certain preconceived data parameters that are influencing the target parameter?", "b) Causality of features : Example of similar looking classifiers on set of images. Do we require more data to eliminate causality? Are there multiple images with different background? Examples could be any of such aspects.", "c) Regulatory need : Does the model outcome satisfy regulatory needs? For example, when we consider various regulations across the geography, EU regulation, GDPR related points and so on.", "d) Critical domain and industry specific requirement : Some of the industry segments such as finance, healthcare, risk, judicial are more critical than other industries.", "e) Ability to debug or troubleshoot and know more information : Why is the AI/ML model behaving like the way it is behaving?", "There could be many such categories, pointers and need for which the explainability of what is happening inside the AI/ML solution becomes more important.", "iv) Do we really need explainability all the time?", "This may not be required all the time. We discussed about few dimensions where it may be required. We need to understand that these may be needed based on certain specific scenario:", "a) Does it impact my end customer or end user? \u2014 this is important. If it does not impact our end customer, then it may not be needed for an explanation as long as we are solving the problem. e.g. a situation where we are looking to refine some internal processes and it may not impact the final outcome. Let\u2019s say we would like to classify the call recordings since a call resulted in a dissatisfied customer. We are good as long as we are getting decent performance and outcome and it is solving end customer purpose.", "b) We can also think of another example where it does not impact end customer again. This is related to automation engine which solves the AI problem. e.g. if the problem is well studied, we are confident about end results. For optical character recognition cases, we can get a lot of training data to train our model and it can rely on a good performance or outcome for annotation for the task at hand. So it does not really require explainability aspects inside the engine.", "Framework can be based on scope and model type.", "Global and Local interpretation varies. If we can explain the conditional interaction between dependent and independent variables based on the given complete dataset, then we consider that as \u201cGlobal Interpretation\u201d. If we are able to explain conditional interaction between dependent and independent variables with regards to a single prediction outcome, then we can consider that scenario as \u201cLocal Interpretation\u201d.", "vi) Various techniques / libraries :", "Following are some examples of libraries that are leveraged for ML model explainability. There are other methods as well and below is not exhaustive.", "a) LIME (Local Interpretable Model-agnostic Explanations)", "c) Eli5 (Explain me like I am 5)", "The comparison between LIME, SHAP and ELi5 are illustrated below to give a reflection of how these are compared and what approaches they typically follow.", "This article does not intent to show how to code using any of these libraries in Python. Instead, it uses one of the example illustrating sample dataset for a practical implementation (for ease of understanding we will be referring to the generic titanic dataset and use one of the library and it\u2019s approach) and how business needs are addressed.", "Objective is to predict the survival passengers in Titanic dataset. After performing regular steps on EDA, feature engineering and modelling, we are trying to interpret the model which is providing prediction with the help of LIME package. For our scenario 1, the Male passenger of age 21 travelling in passenger class 3, embarked from class Q, who is not survived is being considered as a case. Let\u2019s see what and how our model predicts his survival.", "Model has predicted that passenger 421 will die. (87% prediction) Biggest effect of parameter is the gender (being a male), this has decreased his chances of survival significantly. Next parameter is the passenger class which is 3. This also contributes towards decreasing his chances of survival. At the same time, if we notice the parameter which are contributing more towards \u201cwill survive\u201d factor are parameters such as \u201cAge\u201d. Anybody less than 22 yrs of age has higher chances of survival and hence since this passenger is of age 21, this parameter has constituted some effect towards this. To summarize, we see the interpretability of which parameters having how much impact in the overall decision making of the model from this simple example.", "We consider passenger id 310 as scenario 2 and try to analyze in a similar manner. Below are the illustrations and result like scenario 1.", "The model is extremely confident that this passenger will survive and chances are at 99% for \u201csurvival\u201d. Largest factor contributing to it is gender, with this passenger being a female and followed by other parameters which can be analyzed and interpreted in a similar fashion.", "Please refer to my GitHub code reference here for details.", "To conclude and summarize, we can use combination of different features and libraries to interpret based on business case and dataset. We can look at below advisory for general models. Of course, these are based on certain experiences that practitioners have recommended. We need to understand data, business goal and situation to be able to recommend and use the most effective approach and interpret it appropriately. Interpretation is key and that\u2019s where the value and impact would be.", "a) Need: Interpretable and Predictive Need", "a) Interpretable Machine Learning : A guide for making black box models explainable \u2014 by Christoph Molnar", "b) Paper by Marco et al (2016): \u201cWhy Should I Trust You?\u201d: Explaining the Predictions of Any Classifier", "d) A reference to LIME example usage with iris dataset by Marco \u2014 using iris dataset", "a) Paper: A unified approach to interpreting model predictions by Lundberg and Lee", "b) Paper: Consistent individualized feature attribution for tree ensembles by Lundberg et al 2019", "c) Paper: Explainable ML predictions for the prevention of hypoxaemia during surgery", "About InterpretML : A unified framework for ML Interpretability \u2014 by Harsha Nori et al 2019 \u2014 interesting aspect of blackbox and glassbox explained. Blackbox(includes LIME, SHAP, Partial dependence, Sensitivity analysis) and Glassbox(includes Explainable boosting, Linear models, Decision tree, Rule list)", "Disclaimer: The postings here are personal point of views from my experiences, thoughts, readings from various sources and don\u2019t necessarily represent any firm\u2019s positions, strategies or opinions.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Master Data Scientist, Entrepreneur, AI/ML Practitioner & Mentor. Evangelise Data & AI to solve business use cases for clients, help in AI adoption & decisions."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb420531a0d49&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b420531a0d49--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mishra.kamal?source=post_page-----b420531a0d49--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mishra.kamal?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Kamala Kanta MISHRA (Kamal)"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1951f8c7bc0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&user=Kamala+Kanta+MISHRA+%28Kamal%29&userId=e1951f8c7bc0&source=post_page-e1951f8c7bc0----b420531a0d49---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://thehill.com/policy/technology/364482-lawmakers-introduce-bipartisan-ai-legislation", "anchor_text": "https://thehill.com/policy/technology/364482-lawmakers-introduce-bipartisan-ai-legislation"}, {"url": "https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm", "anchor_text": "https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm"}, {"url": "https://nbviewer.jupyter.org/github/kkm24132/BRUG/blob/8c5e0d15b1250f86a47d288a6ea9912279fe2b8a/src/MLExplainability_using_LIME.ipynb", "anchor_text": "my GitHub code reference here"}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "Interpretable Machine Learning : A guide for making black box models explainable"}, {"url": "https://arxiv.org/abs/1602.04938", "anchor_text": "Paper by Marco et al (2016)"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "Github reference from Marco"}, {"url": "https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html", "anchor_text": "A reference to LIME example usage with iris dataset by Marco"}, {"url": "http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf", "anchor_text": "Paper: A unified approach to interpreting model predictions by Lundberg and Lee"}, {"url": "https://arxiv.org/pdf/1802.03888.pdf", "anchor_text": "Paper: Consistent individualized feature attribution for tree ensembles by Lundberg et al 2019"}, {"url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6467492/pdf/nihms-1505578.pdf", "anchor_text": "Paper: Explainable ML predictions for the prevention of hypoxaemia during surgery"}, {"url": "https://arxiv.org/pdf/1909.09223.pdf", "anchor_text": "InterpretML : A unified framework for ML Interpretability"}, {"url": "https://medium.com/tag/ai?source=post_page-----b420531a0d49---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----b420531a0d49---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b420531a0d49---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/lime?source=post_page-----b420531a0d49---------------lime-----------------", "anchor_text": "Lime"}, {"url": "https://medium.com/tag/interpretability?source=post_page-----b420531a0d49---------------interpretability-----------------", "anchor_text": "Interpretability"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&user=Kamala+Kanta+MISHRA+%28Kamal%29&userId=e1951f8c7bc0&source=-----b420531a0d49---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&user=Kamala+Kanta+MISHRA+%28Kamal%29&userId=e1951f8c7bc0&source=-----b420531a0d49---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb420531a0d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b420531a0d49---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b420531a0d49--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b420531a0d49--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b420531a0d49--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b420531a0d49--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b420531a0d49--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mishra.kamal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mishra.kamal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kamala Kanta MISHRA (Kamal)"}, {"url": "https://medium.com/@mishra.kamal/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "180 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1951f8c7bc0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&user=Kamala+Kanta+MISHRA+%28Kamal%29&userId=e1951f8c7bc0&source=post_page-e1951f8c7bc0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3f528cf4bae2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-and-jrt-ai-b420531a0d49&newsletterV3=e1951f8c7bc0&newsletterV3Id=3f528cf4bae2&user=Kamala+Kanta+MISHRA+%28Kamal%29&userId=e1951f8c7bc0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}