{"url": "https://towardsdatascience.com/saving-metadata-with-dataframes-71f51f558d8e", "time": 1683017033.4359932, "path": "towardsdatascience.com/saving-metadata-with-dataframes-71f51f558d8e/", "webpage": {"metadata": {"title": "Saving Metadata with DataFrames. Saving metadata with DataFrames using\u2026 | by Darren Smith | Towards Data Science", "h1": "Saving Metadata with DataFrames", "description": "Metadata is important \u2014 okay, perhaps not exactly a life & death issue for most Python data engineers, but its power and utility should not be overlooked. It enriches data with essential context\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/darrenjs/howto/blob/master/python/metadata_with_pandas.py", "anchor_text": "github", "paragraph_index": 10}, {"url": "https://github.com/darrenjs", "anchor_text": "https://github.com/darrenjs", "paragraph_index": 33}], "all_paragraphs": ["Metadata is important \u2014 okay, perhaps not exactly a life & death issue for most Python data engineers, but its power and utility should not be overlooked. It enriches data with essential context, such as when, where and how it was created. Collection and storage of metadata should be considered a key feature to include in data processing applications.", "But how best to do this? If using the popular data analysis toolkit Pandas, how can metadata be stored with the ubiquitous DataFrame?", "Unfortunately Pandas doesn\u2019t have great support for metadata. There\u2019s no conventional way to attach metadata to a DataFrame, or for portable storage of combined data & metadata.", "The essential challenge is information coupling; how to ensure data & metadata remain linked together, not only during a single Python session, but also as they get persisted and passed from one system to the next. This latter question is our focus here; how can data & metadata be stored together in a portable and durable format?", "Naively we might try to save DataFrames as \u201cpickle\u201d files, perhaps adding metadata as a custom attribute or using the experimental attrs. This feels natural, straightforward and initially appears to work. But this approach has serious drawbacks. Pickles can be very specific to the particular version of Python and Pandas used to create them, rendering them unusable by different versions. They are not readily portable to non-Python programs, nor particularly optimised for performance.", "We will take a step-by-step look at an alternative approach, based on Parquet and Arrow, which allows a DataFrame and metadata to be persisted together in a single, portable file. Before proceeding to the details, a brief overview of Parquet and Arrow is in order, because these are relatively less familiar technologies.", "Apache Parquet is a file format. It has the aim of efficient storage of tabular data. Unlike CSV, in which data is written row by row, Parquet stores data column by column. This approach benefits compression and read/write/query performance. Pandas has supported Parquet since version 0.21, so the familiar DataFrame methods to_csv and to_pickle are now joined by to_parquet. Parquet files typically have extension \u201c.parquet\u201d. A feature relevant to the present discussion is that Parquet supports the inclusion of file-level metadata.", "While Parquet describes how data is arranged within files, Apache Arrow is concerned with its layout in memory. Arrow is a cross-language specification that describes how to store columnar data in memory. It serves as the internals of data processing applications & libraries, allowing them to efficiently work with and share large tabular datasets. It has many features, but two of interest here are its ability to convert to and from various Python types (DataFrames, dicts, Numpy arrays etc.), and its support for reading & writing Parquet files.", "In the following solution we will first use Arrow to convert a DataFrame to an Arrow table and then attach metadata. This enriched table will then be saved as a Parquet file. Additionally we will see how to restore the DataFrame and metadata from the saved file.", "But hang on, why don\u2019t we just call the DataFrame\u2019s to_parquet method to write a Parquet file directly? Well as of Pandas 1.1.4, this method doesn\u2019t support custom metadata, hence we employ a work-around of going via Arrow.", "The code that follows is written using Python 3.6.3, Pandas 0.23.0 and Arrow 2.0.0, all running on Ubuntu 18.04. The complete code can be found on github.", "Let\u2019s begin with the imports. We require Pandas, PyArrow (Python bindings for Arrow), Parquet and also JSON (which is used to serialise the metadata).", "We introduce some data we wish to persist. This example imagines a weather IoT device recording a single data item, which is end-of-day values for two time-series variables, max-temperature and rainfall.", "We also introduce some custom metadata. There is no universal format for metadata; typically it\u2019s just key-value pairs, stored as a dict, with optional nesting of further dicts and lists. One caveat is that the value types can serialise to JSON.", "We require a metadata namespace key. As we will shortly see, the custom metadata will be inserted into a global metadata dict owned by an Arrow table, so we require a unique key to separate our custom metadata from other metadata which may already exist or be inserted later. A good choice is application or organisation name.", "As noted earlier, our approach is to convert the DataFrame to an Arrow table. We use PyArrow to do this:", "Out of interest we can inspect this table\u2019s metadata property (a dict instance) to see what it holds by default:", "This shows some initial metadata. This has been created by Pandas and inserted with the key b'pandas'. Pandas adds its own metadata so that it can convert from an Arrow table back to a DataFrame.", "Now to the add custom metadata to this table. This is not immediately possible because Arrow tables are immutable. Instead we construct a new Arrow table which is a copy of the original but with the metadata replaced; the replacement metadata will be a combination of the existing metadata and the custom metadata.", "First to construct the combined metadata. This is a simple merge of the existing table metadata and the custom metadata. There are a few caveats to get this right. The metadata content must be JSON serialisable and encoded as bytes; the metadata key must also be encoded as bytes:", "Next the Arrow table is shallow copied. The copy has the original table metadata replaced by the combined metadata:", "The original table has been discarded; only the copy is retained, and is referenced by the reused variable table. This table now contains both the custom metadata and the Pandas metadata. This can be verified with:", "Saving to Parquet is straightforward. In this example we request compression, which compresses columns internally:", "The DataFrame & metadata are now coupled together in single Parquet file, providing portability across programming languages and different versions of Python & Pandas. But how do we load this file to recover both the DataFrame and the metadata?", "This reverse task is a lot less fuss. First read the Parquet file into an Arrow table.", "The DataFrame is obtained via a call of the table\u2019s to_pandas conversion method. This operation uses the Pandas metadata to reconstruct the DataFrame, but this is under the hood details that we don\u2019t need to worry about:", "The custom metadata is accessible via the Arrow table\u2019s metadata object, by providing the custom metadata key used earlier (taking care to once again encode the key as bytes):", "This returns the metadata as a JSON string. The final step is to deserialise:", "The metadata has been restored (in addition to the DataFrame); it is just a plain dict of key-value pairs, exactly as we originally created.", "Metadata should be an important consideration of any data collection and processing system, but how it can be captured and stored is often overlooked.", "Pandas lacks a dedicated mechanism for saving metadata to a DataFrame. However we have seen that recent libraries, such as Arrow and Parquet, do provide direct support for persisting DataFrames and metadata together in highly portable and performant files", "Having a simple & conventional approach to couple data & metadata is the first step to its wider integration into our applications.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "UK programmer working in finance. Using technology for quant research & high frequency trading. Git projects: https://github.com/darrenjs"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F71f51f558d8e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@darrenjs?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@darrenjs?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Darren Smith"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa197174cb86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&user=Darren+Smith&userId=a197174cb86d&source=post_page-a197174cb86d----71f51f558d8e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/darrenjs/howto/blob/master/python/metadata_with_pandas.py", "anchor_text": "github"}, {"url": "https://medium.com/tag/python?source=post_page-----71f51f558d8e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/parquet?source=post_page-----71f51f558d8e---------------parquet-----------------", "anchor_text": "Parquet"}, {"url": "https://medium.com/tag/arrow?source=post_page-----71f51f558d8e---------------arrow-----------------", "anchor_text": "Arrow"}, {"url": "https://medium.com/tag/metadata?source=post_page-----71f51f558d8e---------------metadata-----------------", "anchor_text": "Metadata"}, {"url": "https://medium.com/tag/pandas?source=post_page-----71f51f558d8e---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&user=Darren+Smith&userId=a197174cb86d&source=-----71f51f558d8e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&user=Darren+Smith&userId=a197174cb86d&source=-----71f51f558d8e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F71f51f558d8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----71f51f558d8e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----71f51f558d8e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----71f51f558d8e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----71f51f558d8e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@darrenjs?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@darrenjs?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Darren Smith"}, {"url": "https://medium.com/@darrenjs/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "31 Followers"}, {"url": "https://github.com/darrenjs", "anchor_text": "https://github.com/darrenjs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa197174cb86d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&user=Darren+Smith&userId=a197174cb86d&source=post_page-a197174cb86d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa197174cb86d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsaving-metadata-with-dataframes-71f51f558d8e&user=Darren+Smith&userId=a197174cb86d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}