{"url": "https://towardsdatascience.com/linear-regression-explained-1b36f97b7572", "time": 1683017098.962614, "path": "towardsdatascience.com/linear-regression-explained-1b36f97b7572/", "webpage": {"metadata": {"title": "Linear Regression Explained. A High Level Overview of Linear\u2026 | by Jason Wong | Towards Data Science", "h1": "Linear Regression Explained", "description": "Regression analysis is a statistical methodology that allows us to determine the strength and relationship of two variables. Regression is not limited to two variables, we could have 2 or more\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.scribbr.com/statistics/simple-linear-regression/", "anchor_text": "Simple Linear Regression", "paragraph_index": 1}, {"url": "https://www.scribbr.com/statistics/multiple-linear-regression/", "anchor_text": "Multiple Linear Regression", "paragraph_index": 1}, {"url": "https://www.xlstat.com/en/solutions/features/ordinary-least-squares-regression-ols", "anchor_text": "Ordinary Least Squares Regression", "paragraph_index": 2}, {"url": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/", "anchor_text": "R-Squared", "paragraph_index": 11}, {"url": "https://www.kaggle.com/bumba5341/advertisingcsv\\", "anchor_text": "Advertising dataset from Kaggle", "paragraph_index": 15}, {"url": "https://www.statisticshowto.com/q-q-plots/", "anchor_text": "Q-Q-Plots", "paragraph_index": 19}, {"url": "https://www.statsmodels.org/stable/generated/statsmodels.stats.stattools.jarque_bera.html#:~:text=The%20Jarque%2DBera%20test%20statistic%20tests%20the%20null%20that%20the,asymptotic%20%CF%8722%20distribution.", "anchor_text": "Jarque-Bera (JB) test", "paragraph_index": 20}, {"url": "https://seaborn.pydata.org/generated/seaborn.pairplot.html", "anchor_text": "pair plots", "paragraph_index": 22}, {"url": "https://seaborn.pydata.org/generated/seaborn.heatmap.html", "anchor_text": "heat maps", "paragraph_index": 22}, {"url": "https://www.statsmodels.org/devel/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html", "anchor_text": "Variance Inflation Factor (VIF)", "paragraph_index": 22}, {"url": "https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html", "anchor_text": "Breusch-Pagan test", "paragraph_index": 28}, {"url": "https://www.statisticshowto.com/durbin-watson-test-coefficient/", "anchor_text": "Durbin-Watson test", "paragraph_index": 31}, {"url": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate", "anchor_text": "OLS Summary", "paragraph_index": 32}, {"url": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/", "anchor_text": "R-Squared", "paragraph_index": 35}, {"url": "https://statisticsbyjim.com/regression/interpret-adjusted-r-squared-predicted-r-squared-regression/", "anchor_text": "Adj. R-Squared", "paragraph_index": 36}, {"url": "https://statisticsbyjim.com/regression/interpret-f-test-overall-significance-regression/", "anchor_text": "Prob (F-statistic)", "paragraph_index": 37}, {"url": "https://online.stat.psu.edu/stat504/node/27/", "anchor_text": "Log-likelihood", "paragraph_index": 38}, {"url": "https://www.statisticshowto.com/akaikes-information-criterion/", "anchor_text": "AIC", "paragraph_index": 39}, {"url": "https://www.statisticshowto.com/Bayesian-Information-Criterion/", "anchor_text": "BIC", "paragraph_index": 40}, {"url": "https://www.statisticshowto.com/what-is-the-standard-error-of-a-sample/", "anchor_text": "std err", "paragraph_index": 41}, {"url": "https://www.statisticshowto.com/t-statistic/", "anchor_text": "t", "paragraph_index": 42}, {"url": "https://www.statisticshowto.com/calculate-chi-square-p-value-excel/", "anchor_text": "P>|t|", "paragraph_index": 43}, {"url": "https://methods.sagepub.com/reference/encyc-of-research-design/n290.xml", "anchor_text": "Omnibus", "paragraph_index": 44}, {"url": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate", "anchor_text": "Prob(Omnibus)", "paragraph_index": 45}, {"url": "https://www.statisticshowto.com/probability-and-statistics/skewed-distribution/", "anchor_text": "Skew", "paragraph_index": 46}, {"url": "https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics", "anchor_text": "Kurtosis", "paragraph_index": 47}, {"url": "https://www.statisticshowto.com/jarque-bera-test/", "anchor_text": "Jarque-Bera (JB)", "paragraph_index": 48}, {"url": "https://www.datarobot.com/blog/ordinary-least-squares-in-python/", "anchor_text": "Prob (JB)", "paragraph_index": 49}], "all_paragraphs": ["Regression analysis is a statistical methodology that allows us to determine the strength and relationship of two variables. Regression is not limited to two variables, we could have 2 or more variables showing a relationship. The results from the regression help in predicting an unknown value depending on the relationship with the predicting variables. For example, someone\u2019s height and weight usually have a relationship. Generally, taller people tend to weigh more. We could use regression analysis to help predict the weight of an individual, given their height.", "When there is a single input variable, the regression is referred to as Simple Linear Regression. We use the single variable (independent) to model a linear relationship with the target variable (dependent). We do this by fitting a model to describe the relationship. If there is more than predicting variable, the regression is referred to as Multiple Linear Regression.", "You may have heard of Ordinary Least Squares Regression. When we are attempting to find the \u201cbest fit line\u201d, the regression model can sometimes be referred to as Ordinary Least Squares Regression. This just means that we\u2019re using the smallest sum of squared errors. The error is the difference between the predicted y value subtracted from the actual y value. The difference is squared so there is an absolute difference, and summed.", "Take a look at the graph to the left. When using the data points (green dots) to draw a regression line, we\u2019re actually working with estimations. Our goal here is to find the line that best describes the data. When working with estimations, we can make use of the \u201chat\u201d notation (^). The formula for drawing the \u201cbest fit line\u201d when working with estimations will be the same as the straight line formula, but with hat notation.", "We\u2019re just estimating a proper intercept and slope. When we have drawn the \u201cbest fit line\u201d we are ready to make some predictions. However, since our prediction is based on the parameter values we estimate, when we predict new y values given x, we will have error or vertical offset (blue lines). This error is denoted as |\ud835\udc66\u0302 \u2212\ud835\udc66| where \ud835\udc66\u0302 is on our regression line and y is the actual observed value (green dot).", "When performing simple linear regression, the four main components are:", "The last two, slope and intercept, are the coefficients/parameters of a linear regression model, so when we calculate the regression model, we\u2019re just calculating these two. In the end, we\u2019re trying to find the best-fit line describing the data, out of an infinite number of lines. To find the slope of a line, we can choose a random part of the line, and divide the change in x by the change in y.", "We need to calculate some statistical measures before calculating the \u201cbest fit line\u201d:", "The formula above is multiplying the slope by the mean of x and subtracting that value from the mean of y.", "Take another look at the plot above, we can see that:", "If we have a new value (x), we can calculate the prediction (y) with the data we already have.", "We know that the goal of linear regression is to find the \u201cbest fit line\u201d that describes the data. However, we saw above that the line won\u2019t fully represent the relationship between variables. There will also be some error (y_actual - y_predicted). The R-Squared measure can be used to determine a how well a model fits the data. This measure is also known as the Coefficient of Determination.", "R-Squared takes a simple model which uses the mean of the actual_y values to predict new_y values. The model will always predict this mean as the new_y regardless of the x value. This simple model is compared to a fit regression model to determine how well its fit.", "The formula above can be read as:", "Regression, being a parametric technique, relies on parameters learned from the data. This also means that the data must fulfill certain assumptions. These assumptions are necessary for obtaining reliable results. If the assumptions aren\u2019t fulfilled, our predictions may be biased.", "The plots used below were created using the Advertising dataset from Kaggle.", "There is a linear relationship between the dependent variable (y) and the independent variable (x). We can check for linearity by creating a scatter plot.", "The plot above is of TV advertisement spending and sales. This plot shows that there is a linear relationship between the two variables. We can interpret the plot to the right by saying \u201cAs TV advertisement spending increases, so do the sales. If you think you\u2019re violating this assumption, try log-scaling your data.", "This assumption states that the residuals (difference between actual_y and predicted_y) of a model are normally distributed. This assumption can be checked by created histograms or Q-Q-Plots.", "Q-Q-Plots (quantile-quantile-plots) are scatterplots of two sets of quantiles plotted against each other.", "To check the normality assumption using qq-plots, we\u2019re looking for a pretty straight line. It is worth noting that this is only a visual check. Another method of checking the normality assumption is the Jarque-Bera (JB) test.", "The plot above is a Q-Q-Plot of TV advertisement spending and sales. The \u201cstraight line\u201d indicates that the residuals of the model are normally distributed.", "Multicollinearity describes the correlation between the predictor variables. This assumption states that the predictor variables are independent. We can check this assumption by creating pair plots and/or heat maps. Another method would be to calculate the Variance Inflation Factor (VIF).", "The variance inflation factor is a measure for the increase of the variance of the parameter estimates if an additional variable, given by exog_idx is added to the linear regression. It is a measure for multicollinearity of the design matrix, exog.", "Looking at the pairplot above, we can see that out of the three features in the \u201csales\u201d dataset, there isn\u2019t a high correlation between them.", "Looking at the heatmap above, we can see the actual correlation coefficients if we set the annot= parameter to True. Radio and newspaper seem to show a correlation coefficient of 0.35 which tells us the features are not highly correlated.", "In general, a VIF value of 5 is too high. Looking at the dataframe to the left we see little multicollinearity between the newspaper and radio features.", "What would it mean if we did have features showing multicollinearity? For example, let\u2019s say that the newspaper and radio features show multicollinearity. This would make it difficult for us to separate the effects of just newspaper on sales.", "Homoscedasticity refers to the variability of the dependent variable being equal across the independent variable values. We can check this assumption by creating a scatterplot of the model predictions and residuals, we\u2019re looking for the residuals to equal across the regression line. We could also use a significance test such as the Breusch-Pagan test.", "Looking at the plot above, we can see the values do not look to be forming a pattern on the right side but are forming a pattern on the left side. This plot shows that the error increases with the predicted values, so it is heteroscedastic.", "The Breusch-Pagan test returning a p-value this low tells us we can reject the null hypothesis (homoscedasticity), and therefore, we\u2019re violating the Homoscedasticity assumption.", "Autocorrelation refers to the model residuals not being independent. If there were to be a correlation in the error terms, our model\u2019s accuracy would decrease. This assumption can be checked using the Durbin-Watson test or creating an error plot. For the Durbin-Watson (DB) test, we\u2019re looking for a value between 1.5\u20132.5. A few things to know regarding the DB test:", "Looking at the OLS Summary, we can see the Durbin-Watson score is 1.935, this score tells us there is no correlation between the model residuals.", "Now that we\u2019ve checked the assumptions, let\u2019s fit a linear regression model and evaluate the summary table.", "The sales feature is our target (dependent) and TV is our predictor (independent).", "R-Squared: Percent of variance explained by the model.", "Adj. R-Squared: R-Squared where additional independent variables are penalized", "Prob (F-statistic): Probability of seeing F-statistic from a sample", "Log-likelihood: Log of the likelihood function", "AIC: Akaike Information Criterion, penalizes model when more independent variables are added.", "BIC: Bayesian Information Criterion, similar to AIC but with higher penalties", "std err: Standard error of the coefficient estimate", "t: Measure of statistical significance for coefficient", "P>|t|: Probability value that the coefficient is equal to 0", "Omnibus: Omnibus D\u2019Angostino\u2019s test, statistical test for skewness and kurtosis", "Prob(Omnibus): Omnibus statistic as a probability", "Skew: Measure of data mean symmetry", "Kurtosis: Measure of shape of the distribution", "Jarque-Bera (JB): Test for skewness & kurtosis", "Prob (JB): Jarque-Bera statistic as a probability", "There you have it, a breakdown of linear regression analysis. Regression analysis is one of the first modeling techniques to learn as a data scientist. It can helpful when forecasting continuous values, e.g., sales, temperature. There are quite a few formulas to learn but they\u2019re necessary to understand what\u2019s happening \u201cunder the hood\u201d when we run linear regression models. As you saw above there are many ways to check the assumptions of linear regression, hopefully you now have a better understanding of them. Thanks so much for taking the time to check out this post!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist with a passion for statistical analysis and machine learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1b36f97b7572&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jwong853.medium.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Jason Wong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1240e6b56e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&user=Jason+Wong&userId=e1240e6b56e3&source=post_page-e1240e6b56e3----1b36f97b7572---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.shutterstock.com/g/Dan+White+1000", "anchor_text": "Dan White 1000"}, {"url": "https://www.scribbr.com/statistics/simple-linear-regression/", "anchor_text": "Simple Linear Regression"}, {"url": "https://www.scribbr.com/statistics/multiple-linear-regression/", "anchor_text": "Multiple Linear Regression"}, {"url": "https://www.xlstat.com/en/solutions/features/ordinary-least-squares-regression-ols", "anchor_text": "Ordinary Least Squares Regression"}, {"url": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/", "anchor_text": "R-Squared"}, {"url": "https://www.shutterstock.com/g/GoodIdeas", "anchor_text": "GoodIdeas"}, {"url": "https://www.kaggle.com/bumba5341/advertisingcsv\\", "anchor_text": "Advertising dataset from Kaggle"}, {"url": "https://www.statisticshowto.com/q-q-plots/", "anchor_text": "Q-Q-Plots"}, {"url": "https://www.statsmodels.org/stable/generated/statsmodels.stats.stattools.jarque_bera.html#:~:text=The%20Jarque%2DBera%20test%20statistic%20tests%20the%20null%20that%20the,asymptotic%20%CF%8722%20distribution.", "anchor_text": "Jarque-Bera (JB) test"}, {"url": "https://seaborn.pydata.org/generated/seaborn.pairplot.html", "anchor_text": "pair plots"}, {"url": "https://seaborn.pydata.org/generated/seaborn.heatmap.html", "anchor_text": "heat maps"}, {"url": "https://www.statsmodels.org/devel/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html", "anchor_text": "Variance Inflation Factor (VIF)"}, {"url": "https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html", "anchor_text": "Breusch-Pagan test"}, {"url": "https://www.statisticshowto.com/durbin-watson-test-coefficient/", "anchor_text": "Durbin-Watson test"}, {"url": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate", "anchor_text": "OLS Summary"}, {"url": "https://statisticsbyjim.com/regression/interpret-r-squared-regression/", "anchor_text": "R-Squared"}, {"url": "https://statisticsbyjim.com/regression/interpret-adjusted-r-squared-predicted-r-squared-regression/", "anchor_text": "Adj. R-Squared"}, {"url": "https://statisticsbyjim.com/anova/f-tests-anova/", "anchor_text": "F-statistic"}, {"url": "https://statisticsbyjim.com/regression/interpret-f-test-overall-significance-regression/", "anchor_text": "Prob (F-statistic)"}, {"url": "https://online.stat.psu.edu/stat504/node/27/", "anchor_text": "Log-likelihood"}, {"url": "https://www.statisticshowto.com/akaikes-information-criterion/", "anchor_text": "AIC"}, {"url": "https://www.statisticshowto.com/Bayesian-Information-Criterion/", "anchor_text": "BIC"}, {"url": "https://www.statisticshowto.com/probability-and-statistics/coefficient-of-determination-r-squared/", "anchor_text": "coef"}, {"url": "https://www.statisticshowto.com/what-is-the-standard-error-of-a-sample/", "anchor_text": "std err"}, {"url": "https://www.statisticshowto.com/t-statistic/", "anchor_text": "t"}, {"url": "https://www.statisticshowto.com/calculate-chi-square-p-value-excel/", "anchor_text": "P>|t|"}, {"url": "https://methods.sagepub.com/reference/encyc-of-research-design/n290.xml", "anchor_text": "Omnibus"}, {"url": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate", "anchor_text": "Prob(Omnibus)"}, {"url": "https://www.statisticshowto.com/probability-and-statistics/skewed-distribution/", "anchor_text": "Skew"}, {"url": "https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics", "anchor_text": "Kurtosis"}, {"url": "https://www.statisticshowto.com/durbin-watson-test-coefficient/", "anchor_text": "Durbin-Watson"}, {"url": "https://www.statisticshowto.com/jarque-bera-test/", "anchor_text": "Jarque-Bera (JB)"}, {"url": "https://www.datarobot.com/blog/ordinary-least-squares-in-python/", "anchor_text": "Prob (JB)"}, {"url": "https://www.datarobot.com/blog/ordinary-least-squares-in-python/", "anchor_text": "Cond. No."}, {"url": "https://www.scribbr.com/statistics/simple-linear-regression/", "anchor_text": "https://www.scribbr.com/statistics/simple-linear-regression/"}, {"url": "https://www.scribbr.com/statistics/multiple-linear-regression/", "anchor_text": "https://www.scribbr.com/statistics/multiple-linear-regression/"}, {"url": "https://www.encyclopedia.com/social-sciences/applied-and-social-sciences-magazines/ordinary-least-squares-regression", "anchor_text": "https://www.encyclopedia.com/social-sciences/applied-and-social-sciences-magazines/ordinary-least-squares-regression"}, {"url": "https://data.library.virginia.edu/understanding-q-q-plots/", "anchor_text": "https://data.library.virginia.edu/understanding-q-q-plots/"}, {"url": "https://www.statisticshowto.com/q-q-plots/", "anchor_text": "https://www.statisticshowto.com/q-q-plots/"}, {"url": "https://www.statisticssolutions.com/assumptions-of-linear-regression/", "anchor_text": "https://www.statisticssolutions.com/assumptions-of-linear-regression/"}, {"url": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate", "anchor_text": "https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate"}, {"url": "https://www.xlstat.com/en/solutions/features/ordinary-least-squares-regression-ols", "anchor_text": "https://www.xlstat.com/en/solutions/features/ordinary-least-squares-regression-ols"}, {"url": "https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html", "anchor_text": "https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html"}, {"url": "https://www.statsmodels.org/stable/index.html", "anchor_text": "https://www.statsmodels.org/stable/index.html"}, {"url": "https://www.kaggle.com/bumba5341/advertisingcsv", "anchor_text": "https://www.kaggle.com/bumba5341/advertisingcsv"}, {"url": "https://medium.com/tag/regression?source=post_page-----1b36f97b7572---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----1b36f97b7572---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/regression-assumptions?source=post_page-----1b36f97b7572---------------regression_assumptions-----------------", "anchor_text": "Regression Assumptions"}, {"url": "https://medium.com/tag/statsmodels?source=post_page-----1b36f97b7572---------------statsmodels-----------------", "anchor_text": "Statsmodels"}, {"url": "https://medium.com/tag/statistical-learning?source=post_page-----1b36f97b7572---------------statistical_learning-----------------", "anchor_text": "Statistical Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&user=Jason+Wong&userId=e1240e6b56e3&source=-----1b36f97b7572---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&user=Jason+Wong&userId=e1240e6b56e3&source=-----1b36f97b7572---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1b36f97b7572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1b36f97b7572---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1b36f97b7572--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1b36f97b7572--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1b36f97b7572--------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jason Wong"}, {"url": "https://jwong853.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "199 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1240e6b56e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&user=Jason+Wong&userId=e1240e6b56e3&source=post_page-e1240e6b56e3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdec1d5eb8281&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-regression-explained-1b36f97b7572&newsletterV3=e1240e6b56e3&newsletterV3Id=dec1d5eb8281&user=Jason+Wong&userId=e1240e6b56e3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}