{"url": "https://towardsdatascience.com/emotion-recognition-using-graph-convolutional-networks-9f22f04b244e", "time": 1683000989.673035, "path": "towardsdatascience.com/emotion-recognition-using-graph-convolutional-networks-9f22f04b244e/", "webpage": {"metadata": {"title": "Emotion Recognition Using Graph Convolutional Networks | by Kevin Shen | Towards Data Science", "h1": "Emotion Recognition Using Graph Convolutional Networks", "description": "Recently, deep learning has made much progress in natural language processing (NLP). With many new inventions such as Attention and Transformers leading to state of the art models such as BERT and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1908.11540", "anchor_text": "DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "graph convolutional network", "paragraph_index": 20}, {"url": "https://arxiv.org/pdf/1704.01212.pdf", "anchor_text": "differentiable message-passing framework", "paragraph_index": 31}, {"url": "https://arxiv.org/abs/1703.06103", "anchor_text": "model relational data", "paragraph_index": 31}, {"url": "https://gombru.github.io/2018/05/23/cross_entropy_loss/", "anchor_text": "categorical-cross-entropy loss", "paragraph_index": 35}, {"url": "https://medium.com/@kshen3778", "anchor_text": "Medium", "paragraph_index": 47}, {"url": "https://www.linkedin.com/in/kevinkwshen/", "anchor_text": "Linkedin", "paragraph_index": 47}], "all_paragraphs": ["Recently, deep learning has made much progress in natural language processing (NLP). With many new inventions such as Attention and Transformers leading to state of the art models such as BERT and XLNet, many tasks such as textual emotion recognition have become easier. This article will introduce a new method to conduct emotion recognition from conversations using graphs.", "Simply put, emotion recognition (ERC) is the task of classifying the emotion behind a piece of written task. Given a piece of text can you tell if the speaker is angry, happy, sad, or perhaps confused? It has many far-ranging applications in healthcare, education, sales, and human resources. At the highest level, the task of ERC is useful because many are convinced that it is a stepping stone to building a conversationally intelligent AI that is able to talk with a human.", "Currently, the two major pieces of innovation that most ERC is built on are recurrent neural networks (RNN) and attention mechanisms. RNNs such as LSTMs and GRUs look at text sequentially. When the text is long, the model\u2019s memory of the beginning parts is lost. Attention mechanisms solve this well by weighing different parts of the sentence differently.", "However, RNNs+Attention still have trouble taking into context of personality, topic, and intent from neighboring sequences and also the speaker (basically all the very important parts of any conversation). Couple this with the lack of labeled benchmark datasets for personality/emotion it becomes really difficult not just to implement but also to measure the result of new models. This article will summarize a recent paper that solves much of this by using a relatively new innovation called graph convolution networks: DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation [1].", "In a conversation, context matters. A simple \u201cOkay\u201d can mean \u201cOkay?\u201d, \u201cOkay!\u201d or \u201cOkay\u2026.\u201d depending on what you and the other said before, how you are feeling, how the other person is feeling, the level of tension and many other things. There are two types of context that matter:", "As you can probably guess, it\u2019s speaker level context that most models have difficulty taking into account. It turns out you can actually model speaker level context very well using graph convolutional neural networks and this is exactly the approach DialogueGCN takes.", "In a conversation there are M speakers/parties represented as p[1], p[2], . . . , p[M]. Each utterance (a piece of text someone sends) is represented as u[1], u[2], . . . , u[N]. The final goal in ERC is to accurately predict each utterance as one of happy, sad, neutral, angry, excited, frustrated, disgust, or fear.", "The entire conversation can be built as a directed graph:", "One thing to notice from the figure is that each utterance has an edge connected to itself. This represents the relation of the utterance to itself. In more practical terms, this is how an utterance impacts the mind of the utterance\u2019s speaker.", "One major problem of a graph representation is that if a conversation is really long, there can be many edges for a single node. And since each node is connected to every other node, it scales quadratically as the size of the graph increases. This is very computationally expensive.", "To resolve this problem, in DialogueGCN, the graph\u2019s edges are constructed based on a context window with a specific size. So for a node/utterance i, only the past size and future size utterances are connected in a graph (any node in the range of i-size to i+size).", "Edge weight are calculated using an attention function. The attention function is set up so that for each node/utterance, the incoming edge weights all sum up to 1. Edge weights are constant and do not change in the learning process.", "In simplified terms, the edge weight represents the importance of the connection between two nodes.", "The relation of an edge depends on two things:", "In a conversation, if there are M different speakers, there will be a maximum of M (speaker of u[j]) * M (speaker of u[j]) * 2 (whether u[i] occurs before u[j], or the reverse) = 2M\u00b2 relations.", "We can list all of the relations from our example graph above:", "Here\u2019s the same graph with the edges\u2019 relation labelled according to the table:", "In our example, we have 8 different relation. At a high level, relation is an important property for the edge because who spoke what and when matters a lot in a conversation. If Peter asks a question and Jenny responds, this is different from Jenny first saying the answer and then Peter asking the question (temporal dependency). Likewise, if Peter asks the same question to Jenny and Bob, they may respond differently (speaker dependency).", "Think of the relation as defining the type of the connection, and the edge weight representing the importance of the connection.", "Think of the relation as defining the type of the connection, and the edge weight representing the importance of the connection.", "The DialogueGCN model uses a type of graph neural network known as a graph convolutional network (GCN).", "Just like above, the example shown is for a 2 speaker 5 utterance graph.", "In stage 1, each utterance u[i] is represented as a feature vector and given sequential context encoding. This is done by running each utterance through a series of GRUs in a sequential context encoder. A graph structure is not needed for stage 1. The new utterance with sequential context is denoted as g[1]\u2026\u2026. g[N] in the paper. This is the input to the GCN.", "In stage 2, the model constructs a graph like discussed in the previous section and will add speaker level context to the graph using feature transformation. The utterances with BOTH sequential and speaker level context is denoted by h[1]\u2026\u2026h[N]. This is the output of the GCN.", "The difference in the looks of the edges and nodes (dash vs solid, different colors) represents a different relation. For example, green g[1] to green g[3], with a solid green edge is relation 1 in the table.", "One of the most important steps of the GCN is feature transformation \u2014 basically how the GCN will embed speaker level context into the utterances. We will first discuss the technique used and then describe where the intuition for it came from.", "There are two steps in a feature transformation. In step 1, for each node h[i] neighboring node information (nodes within the context window size) is aggregated to create a new feature vector h[i]\u00b9.", "The function might look complicated but at its core just think of it as a layer in the network with learnable parameters denoted by W[0]\u00b9 and W[r]\u00b9. One thing that was added is a constant c[i,r] which is a normalization constant. It can be set in advance or learned with the network itself.", "As mentioned before, edge weights are constant and are not changed or learned in the process.", "In step 2, the same thing is basically done again. Neighbor information is aggregated and a similar function is applied to the output of step 1.", "Once again, W\u00b2 and W[0]\u00b2 represent learnable parameters that are modified in the training process.", "At a high level, this two step process essentially takes a normalized sum of all the neighboring utterance information for each utterance. At a deeper level, this two step transformation has its root in what\u2019s known as a simple differentiable message-passing framework [2]. This technique was taken by researchers working on graph convolutional neural networks to model relational data [3]. If you have time, I would highly recommend giving those two papers a read in that order. I believe all the intuition needed for DialogueGCN\u2019s feature transformation process is in those two papers.", "The output of the GCN is denoted by h[1]\u2026..h[N] on the figure.", "In stage 3, the original sequential context encoded vectors are concatenated with the speaker level context encoded vectors. This is similar to combining original layers with later layers to \u201csummarize\u201d the outputs of every layer.", "The concatenated feature vector is then fed into a fully connected network for classification. The final output is a probability distribution of the different emotions the model thinks the utterance is.", "The training of the model is done using a categorical-cross-entropy loss with L2-regularization. This loss is used because the model is predicting the probability of multiple labels (emotion classes).", "Previously we mentioned the lack of benchmark datasets. The authors of the paper were able to solve this by using labeled multimodal datasets (text along with video or audio) and then extracting the textual portion and completely ignoring any audio or visual data.", "DialogueGCN was evaluated on these datasets:", "MELD has a pre-defined train/validation/test split. AVEC and IEMOCAP do not have predefined splits so 10% of the dialogues were used as the validation set.", "DialogueGCN was compared to many baseline and state of the art models for ERC. One particular state of the art model was DialogueRNN by the same authors of the paper.", "In 4 of the 6 categories of IEMOCAP, DialogueGCN shows a noticeable improvement against all models including DialogueRNN. In the \u201cAngry\u201d category, DialogueGCN essentially ties with DialogueRNN (GCN is only worse by 1.09 on the F1 score). Only the \u201cExcited\u201d category shows a large enough difference.", "DialogueGCN is able to produce similar results on AVEC and MELD, beating out the incumbent DialogueRNN.", "What is clear from the result is that adding speaker level context to a conversation graph inherently improves understanding. DialogueRNN, which captured sequential context well, lacked the ability to encode speaker context.", "One parameter that was experimented with is the size of the context window. By extending the size, one is able to increase the number of edges to a specific utterance. It was found that an increase in the size, while more computationally expensive, improved results.", "Another interesting experiment the authors did was an ablation study. The encoders were removed one at a time and the performance was re-measured. It was found that the speaker-level context encoder (stage 2) was slightly more important than the sequential context encoder (stage 1).", "It was also found that misclassification tended to happen among two scenarios:", "Because all the datasets used were multimodal and contained audio and video, it\u2019s possible to improve the accuracy within these two scenarios by integrating audio and visual multimodal learning. And while misclassification still happens, it\u2019s important to note that DialogueGCN still resulted in a very noticeable improvement in accuracy.", "You can connect with me on Medium, Linkedin, or kshen3778@gmail.com", "[1] Ghosal, Deepanway & Majumder, Navonil & Poria, Soujanya & Chhaya, Niyati & Gelbukh, Alexander. (2019). DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation.", "[2] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference, pages 593\u2013607. Springer.", "[3] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1263\u20131272. JMLR. org.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI/ML Developer, Student @ University of Waterloo"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9f22f04b244e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kshen3778?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kshen3778?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Kevin Shen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe7f3f33b99ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&user=Kevin+Shen&userId=e7f3f33b99ec&source=post_page-e7f3f33b99ec----9f22f04b244e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1908.11540", "anchor_text": "DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation"}, {"url": "https://www.mathworks.com/help/matlab/math/directed-and-undirected-graphs.html", "anchor_text": "directed"}, {"url": "https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780", "anchor_text": "graph convolutional network"}, {"url": "https://arxiv.org/pdf/1704.01212.pdf", "anchor_text": "differentiable message-passing framework"}, {"url": "https://arxiv.org/abs/1703.06103", "anchor_text": "model relational data"}, {"url": "https://gombru.github.io/2018/05/23/cross_entropy_loss/", "anchor_text": "categorical-cross-entropy loss"}, {"url": "https://medium.com/@kshen3778", "anchor_text": "Medium"}, {"url": "https://www.linkedin.com/in/kevinkwshen/", "anchor_text": "Linkedin"}, {"url": "https://arxiv.org/abs/1908.11540", "anchor_text": "https://arxiv.org/abs/1908.11540"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9f22f04b244e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9f22f04b244e---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9f22f04b244e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/emotion-recognition?source=post_page-----9f22f04b244e---------------emotion_recognition-----------------", "anchor_text": "Emotion Recognition"}, {"url": "https://medium.com/tag/language?source=post_page-----9f22f04b244e---------------language-----------------", "anchor_text": "Language"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&user=Kevin+Shen&userId=e7f3f33b99ec&source=-----9f22f04b244e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&user=Kevin+Shen&userId=e7f3f33b99ec&source=-----9f22f04b244e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9f22f04b244e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9f22f04b244e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9f22f04b244e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9f22f04b244e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9f22f04b244e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kshen3778?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kshen3778?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kevin Shen"}, {"url": "https://medium.com/@kshen3778/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "64 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe7f3f33b99ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&user=Kevin+Shen&userId=e7f3f33b99ec&source=post_page-e7f3f33b99ec--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fe7f3f33b99ec%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Femotion-recognition-using-graph-convolutional-networks-9f22f04b244e&user=Kevin+Shen&userId=e7f3f33b99ec&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}