{"url": "https://towardsdatascience.com/5-must-know-activation-functions-used-in-neural-networks-8c5052757750", "time": 1683015507.097495, "path": "towardsdatascience.com/5-must-know-activation-functions-used-in-neural-networks-8c5052757750/", "webpage": {"metadata": {"title": "5 Must-Know Neural Network Activation Functions | Towards Data Science", "h1": "5 Must-Know Activation Functions Used in Neural Networks", "description": "The success of neural networks depends on their ability to represent non-linearity which is achieved by the activation functions."}, "outgoing_paragraph_urls": [{"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/", "paragraph_index": 33}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14", "paragraph_index": 33}], "all_paragraphs": ["The universal approximation theorem implies that a neural network can approximate any continuous function that maps inputs (X) to outputs (y). The ability to represent any function is what makes the neural networks so powerful and widely-used.", "To be able to approximate any function, we need non-linearity. That\u2019s where the activation functions come into play. They are used to add non-linearity to neural networks. Without activation functions, neural networks can be considered as a collection of linear models.", "Neural networks are combinations of layers that contain many nodes. Thus, the building process starts with a node. The following represents a node without an activation function.", "The output y is a linear combination of inputs and a bias. We need to somehow add an element of non-linearity. Consider the following node structure.", "Non-linearity is achieved by applying an activation function to the sum of the linear combination of inputs and bias. The added non-linearity depends on the activation function.", "In this post, we will talk about 5 commonly used activations in neural networks.", "The sigmoid function bounds a range of values between 0 and 1. It is also used in logistic regression models.", "Whatever the input values to a sigmoid function are, the output values will be between 0 and 1. Thus, the output of each neuron is normalized into the range 0\u20131.", "The output (y) is more sensitive to the changes on the input (x) for x values close to 0. As the input values move away from zero, the output value becomes less sensitive. After some point, even a large change in the input values result in little to no change in the output value. That is how the sigmoid function achieves non-linearity.", "There is a downside associated with this non-linearity. Let\u2019s first see the derivative of the sigmoid function.", "The derivate tends towards zero as we move away from zero. The \u201clearning\u201d process of a neural network depends on the derivative because the weights are updated based on the gradient which basically is the derivate of a function. If the gradient is very close to zero, weights are updated with very small increments. This results in a neural network that learns so slow and takes forever to converge. This is also known as vanishing gradient problem.", "It is very similar to the sigmoid except that the output values are in the range of -1 to +1. Thus, tanh is said to be zero centered.", "The difference between the sigmoid and tanh is that the gradients are not restricted to move in one direction for tanh. Thus, tanh is likely to converge faster than the sigmoid function.", "The vanishing gradient problem also exist for tanh activation function.", "The relu function is only interested in the positive values. It keeps the input values greater than 0 as is. All the input values less than zero become 0.", "The output values of a neuron can be arranged to be less than 0. If we apply the relu function to the output of that neuron, all the values returned from that neuron become 0. Thus, relu allows cancelling out some of the neurons.", "We are able to activate only some of the neurons with the relu function where as all of the neurons are activated with tanh and sigmoid which results in intense computations. Thus, relu converges faster than tanh and sigmoid.", "The derivative of relu is 0 for input values less than 0. For those values, the weights are never updated during back-propagation and thus the neural network cannot learn. This issue is known as dying relu problem.", "It can be considered as a solution to the dying relu problem. Leaky relu outputs a small value for negative inputs.", "Although leaky relu seems to be solving the dying relu problem, some argue that there is not a significant difference on the accuracy in most cases. I guess it comes down to trying both and see if there is any difference for a particular task.", "Softmax is usually used in multi-class classification tasks and applied to the output neuron. What it does is normalizing the output values into a probability distribution in a way the probability values add up to 1.", "Softmax function divides the exponential of each output by the sum of the exponentials of all all the outputs. The resulting values form a probability distribution with probabilities that add up to 1.", "Let\u2019s do an example. Consider a case in which the target variable has 4 classes. The following is the output of the neural network for 5 different data points (i.e. observations).", "We can apply the softmax function to these outputs as follows:", "In the first line, we applied the softmax function to the values in matrix A. The second line reduced the floating point precision to 2 decimals.", "Here is the output of the softmax function.", "As you can see, the probability values in each column add up to 1.", "We have discussed 5 different activation functions used in the neural networks. It is a must to use activation functions in neural networks in order to add non-linearity.", "There is no free lunch! Activation functions also cause a burden to neural networks in terms of computational complexity. They also have an impact on the convergence of models.", "It is important to know the properties of the activations functions and how they behave so that we can choose the activation function that best fits a particular task.", "In general, the desired properties of an activation function are:", "Thank you for reading. Please let me know if you have any feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Top 10 Writer in AI and Data Science | linkedin.com/in/soneryildirim/ | twitter.com/snr14"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8c5052757750&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sonery.medium.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----8c5052757750---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@drewpatrickmiller?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Drew Patrick Miller"}, {"url": "https://unsplash.com/s/photos/adjust?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8c5052757750---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8c5052757750---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8c5052757750---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8c5052757750---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----8c5052757750---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----8c5052757750---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----8c5052757750---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8c5052757750&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8c5052757750---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8c5052757750--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8c5052757750--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8c5052757750--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8c5052757750--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8c5052757750--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://sonery.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/"}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cdf5377373a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-must-know-activation-functions-used-in-neural-networks-8c5052757750&newsletterV3=2cf6b549448&newsletterV3Id=7cdf5377373a&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}