{"url": "https://towardsdatascience.com/data-processing-example-using-python-bfbe6f713d9c", "time": 1683014394.9813151, "path": "towardsdatascience.com/data-processing-example-using-python-bfbe6f713d9c/", "webpage": {"metadata": {"title": "Data Processing Example using Python | by Kamil Mysiak | Towards Data Science", "h1": "Data Processing Example using Python", "description": "Forbes\u2019s survey found that the least enjoyable part of a data scientist\u2019s job encompasses 80% of their time. 20% is spent collecting data and another 60% is spent cleaning and organizing of data\u2026"}, "outgoing_paragraph_urls": [{"url": "https://rpubs.com/rhuebner/HRCodebook-13", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://stefvanbuuren.name/fimd/sec-MCAR.html", "anchor_text": "resource", "paragraph_index": 21}, {"url": "https://www.linkedin.com/in/kamil-mysiak-b789a614/", "anchor_text": "https://www.linkedin.com/in/kamil-mysiak-b789a614/", "paragraph_index": 30}], "all_paragraphs": ["Forbes\u2019s survey found that the least enjoyable part of a data scientist\u2019s job encompasses 80% of their time. 20% is spent collecting data and another 60% is spent cleaning and organizing of data sets. Personally, I disagree with the notion that 80% is the least enjoyable part of our jobs. I often see the task of data cleansing as an open-ended problem. Typically, each data set can be processed in hundreds of different ways depending on the problem at hand but we can very rarely apply the same set of analyses and transformations from one dataset to another. I find that building different processing pipelines and examining how their differences affect model performance is an enjoyable part of my job.", "With that said, I want to take the time and walk you through the code and the thought process of preparing a dataset for analysis which in this case will be a regression (ie. multiple regression).", "Those of you who follow me know that I\u2019m particular to human resources datasets as I have been working in the industry for most of my career.", "If you have a rare HR dataset please share with us :)", "We will be working with a dataset of 310 active and terminated employees along with information much as marital status, gender, department, pay rate, state, position, etc. Since we are prepping the data for regression analysis, our target feature is EngagementSurvey.", "The code book for our dataset can be found here.", "Upon loading our data we can see a number of unique feature types. We have categorical features such as \u201cEmployee_Name\u201d and \u201cPosition\u201d. We have binary features such as \u201cMarriedID\u201d. We have continuous features such as \u201cPayRate\u201d and \u201cEmpSatisfaction\u201d. We have discrete features such as \u201cDaysLateLast30\u201d and finally we have date features such as \u201cLastPerformanceReview_Date\u201d.", "The first step I typically take is reviewing the unique count of values per feature to determine if any features can be quickly deleted due to very high or very low variability. In other words, do we have any features which have as many unique values as the length of the dataset or features which have just one unique value?", "We can safely remove \u201cEmployee_Name\u201d, \u201cEmp_ID\u201d, \u201cDOB\u201d since most if not all, values are unique for each feature. Also, we can remove \u201cDaysLateLast30\u201d as this feature only contains one unique value.", "Next, by examining the codebook, which contains the definitions for each feature, we can see that we have many duplicate features. For example, \u201cMarriedStatusID\u201d is a numerical feature that produces the code that matches the married statues in \u201cMaritalDesc\u201d feature. We can drop these features.", "You might be asking yourself \u201cWhat about \u2018PositionID\u2019, \u2018Position\u2019, \u2018ManagerID\u2019 and ManagerName\u2019?\u201d. As you can see from the output above, the unique value counts for these feature pairs do not match. \u201cPositionID\u201d has 32 unique values whereas \u201cPosition\u201d has 30.", "We are going to drop \u201cPositionID\u201d as it does not maintain all available positions and we are going to drop \u201cManagerID\u201d as \u201cManagerName\u201d does not contain any missing values.", "Next, let\u2019s examine the individual unique values for each feature. This will help us see any odds values and mistakes which will need to be fixed.", "From the codebook, we know that features such as \u201cFromDiversityJobFairID\u201d, and \u201cTermd\u201d are binary codings for \u201cYes\u201d and \u201cNo\u201d. In order to simplify our analysis and help with formatting, we need to convert the binary to string. We also see trailing spaces for the position of \u201cData Analyst\u201d and Department of \u201cProduction\u201d which need to be removed. Finally, we see a coding mistake for \u201cHispanicLatino\u201d which needs to be corrected.", "You might be asking yourself \u201cHow come some zip codes are 5 digits and some are only 4?\u201d. In the US all zip codes are 5 digits long. After a little bit of googling, many Massachusetts zip codes actually begin with zero, and by default, python stripped the zeros which resulted in 4 digit zip codes. Since we will be treating zip codes as a categorical feature the length wouldn\u2019t matter.", "Believe it or not but datetime features very often contain a plethora of info just waiting to be unleashed. This is especially evident when one is familiar with the industry from which the data originates from.", "First, we need to convert our features to datetime format. Next, using the \u201cdatetime\u201d library we can extract new features from our original datetime features with information such as a month, day, year, quarter, weekday string, and even whether or not the day falls on a weekend. Finally, we can subtract individual dates from each other to calculate things like tenure_termed (terminated date \u2014 hire date) and tenure (today\u2019s date \u2014 hire date). Once we have extracted the necessary information we can drop the original features.", "Perhaps I\u2019m being a little obsessive-compulsive but I like tidy datasets, therefore, let\u2019s remove the irrelevant information such as \u201cdays\u201d and the timestamp from these new features. Finally, we convert the \u2018NaT\u201d and \u201cNa\u201d to true numpy \u201cNaN\u201d.", "Cardinality refers to the number of unique values/categories for each feature. Numeric, especially continuous, features will have very high cardinality but we mainly need to concern ourselves from categorical features. First, we need to identify features that contain values/categories which suck up all the variance. In other words, 90%+ of all the observations fall under one or two values. For example, \u201cCitizenDesc\u201d has three unique values but we see that \u201cUS Citizen\u201d contains 95% of all the observations. Other features which exhibit this pattern, unfortunately, are our newly engineered features such as \u201cDateofHire_weekday\u201d, \u201cDateofTerm_weekday\u201d, \u201cLastPerform_quarter\u201d, \u201cLastPerform_weekday\u201d, and \u201cLastPerform_year\u201d. We can safely drop these features as they do not provide enough variability to be meaningful.", "Using the same code as above, we once again turn our attention onto categorical features but this time we are looking for values which we consider \u201crare\u201d. How you define \u201crare\u201d is really up to you but I have found that this decision has to be made a feature by feature. Some values might be rare if they appear less than 1% of the time. In other features, the threshold might be 2% or even 5%. Our ultimate goal will be to group these values together into a new value/category called \u201crare\u201d. This procedure reduces the overall cardinality of the feature and if you choose to one-hot encode your categories features this method will drastically reduce the number of newly created \u201cdummy\u201d features.", "Deciding how to process missing values is one of the most important and contentious decisions a data scientist will make.", "TermReason is a categorical feature with only a few missing data points. We can impute this data using the mode as this wouldn\u2019t change the distribution of the feature. Furthermore, we can safely assume that a missing TermReason simply means the employee is still active. The remaining features with missing data are what we call \u201cMissing Not At Random\u201d (MNAR). In other words, there is an underlying reason these features are missing. First, the percentages of missing values seem to repeat which gives us a clue that there is a discernible pattern to these missing values. Secondly, we know from the data that roughly 67% of all employees are active and would not have a Termination Date. Lastly, oftentimes employees hired after a recent performance review cycle will not have a date associated with their last performance review date. If you wish to read more about missing values please consider this resource.", "Some would argue 67% of missing values effectively renders the feature useless and I\u2019m going to agree with this notion for our \u201ctenure_termed\u201d feature. Imputing this numerical feature would potentially introduce too much error variance/bias into our data. However, features such as \u201cDateofTerm_month\u201d, and \u201cLastPerform_month\u201d are categorical in nature with a definitive pattern underlying their missing data. I want to capture the importance of the missing values by imputing all missing values with the string \u201cmissing\u201d. This way we are introducing another value/category to each feature that appropriately captures the pattern behind the missing values.", "On the other hand, \u201cdays_since_review\u201d is a numeric feature which is MNAR. In other to capture the significance of these missing values we are going to impute an arbitrary number (ie. -9999) and create a new feature that will indicate whether or not an observation was missing for this feature.", "Outliers are another contentious topic which requires some thought. There are a number of ways of dealing with outliers. If you have a very large dataset and a relatively small number of outliers you can simply delete them. I\u2019m usually wary of this method as it changes the distribution of said feature(s) which might cause new values to become outliers. That said, it is an option often utilized. Other methods include adding an indicator feature, rescaling the entire feature using np.log(), and transforming a continuous feature into discrete by applying discretization which will encompass the outliers into one bin.", "First, we need to identify if we have any outliers. The most well-known method for identifying outliers is the z-score method which standardizes the feature values to a mean of zero, a standard deviation of one, and any value which falls 3 standard deviations (plus or minus) is considered an outlier. Personally, I believe this method is flaw as the z-score relies on the mean and standard deviation of the feature. Both the mean and standard deviation are highly influenced by existing outliers. Any outlier included in the calculation of the mean and standard deviation will expand the range of the z-scores and potentially omitting existing outliers. This problem can be overcome by utilizing the median instead of the mean.", "Let\u2019s utilize a more robust method that relies on the inter-quartile range and the median. You can adjust this method and use (3 * IQR) to identify only the extreme outliers.", "One topic we haven\u2019t discussed is categorical feature encoding. I typically try and avoid using one-hot encoding due to the fact it has a tendency to greatly expand the feature space. The encoding of \u201crare\u201d values/categories certainly helps with this issue if we were to use one-hot encoding. That said, I opted to use Target or Mean encoding as it does not expand the feature set. This method replaces the categories with digits from 0 to k-1. We first calculate the mean for the target variable for each category for each categorical feature and then the means are replaced with the aforementioned digits based on the mean size. For example, we have a binary target and the first categorical feature is gender and it has three categories (male, female, and undisclosed). Let\u2019s assume the mean for male is 0.8, female is 0.5, and undisclosed is 0.2. The encoded values will be male=2, female=1 and undisclosed=0.", "Feel free to provide feedback if you believe I might have missed an important step. Thanks for reading!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | I/O Psychologist | Motorcycle Enthusiast | On a Search for my Personal Legend/ https://www.linkedin.com/in/kamil-mysiak-b789a614/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbfbe6f713d9c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kamilmysiak.medium.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": ""}, {"url": "https://kamilmysiak.medium.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Kamil Mysiak"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98fe4fecb558&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&user=Kamil+Mysiak&userId=98fe4fecb558&source=post_page-98fe4fecb558----bfbe6f713d9c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://rpubs.com/rhuebner/HRCodebook-13", "anchor_text": "here"}, {"url": "https://stefvanbuuren.name/fimd/sec-MCAR.html", "anchor_text": "resource"}, {"url": "https://medium.com/tag/pandas?source=post_page-----bfbe6f713d9c---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/feature-engine?source=post_page-----bfbe6f713d9c---------------feature_engine-----------------", "anchor_text": "Feature Engine"}, {"url": "https://medium.com/tag/data-processing?source=post_page-----bfbe6f713d9c---------------data_processing-----------------", "anchor_text": "Data Processing"}, {"url": "https://medium.com/tag/regression-analysis?source=post_page-----bfbe6f713d9c---------------regression_analysis-----------------", "anchor_text": "Regression Analysis"}, {"url": "https://medium.com/tag/cardinality?source=post_page-----bfbe6f713d9c---------------cardinality-----------------", "anchor_text": "Cardinality"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&user=Kamil+Mysiak&userId=98fe4fecb558&source=-----bfbe6f713d9c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&user=Kamil+Mysiak&userId=98fe4fecb558&source=-----bfbe6f713d9c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbfbe6f713d9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bfbe6f713d9c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bfbe6f713d9c--------------------------------", "anchor_text": ""}, {"url": "https://kamilmysiak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kamilmysiak.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kamil Mysiak"}, {"url": "https://kamilmysiak.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "348 Followers"}, {"url": "https://www.linkedin.com/in/kamil-mysiak-b789a614/", "anchor_text": "https://www.linkedin.com/in/kamil-mysiak-b789a614/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F98fe4fecb558&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&user=Kamil+Mysiak&userId=98fe4fecb558&source=post_page-98fe4fecb558--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F63448b4832be&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-processing-example-using-python-bfbe6f713d9c&newsletterV3=98fe4fecb558&newsletterV3Id=63448b4832be&user=Kamil+Mysiak&userId=98fe4fecb558&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}