{"url": "https://towardsdatascience.com/better-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449", "time": 1682995248.706125, "path": "towardsdatascience.com/better-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449/", "webpage": {"metadata": {"title": "Better, Faster Speech Recognition with Wav2Letter\u2019s Auto Segmentation Criterion | by Zach C | Towards Data Science", "h1": "Better, Faster Speech Recognition with Wav2Letter\u2019s Auto Segmentation Criterion", "description": "In 2016, Facebook AI Research (FAIR) broke new ground with Wav2Letter, a fully convolutional speech recognition system. In Wav2Letter, FAIR showed that systems based on convolutional neural networks\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1609.03193.pdf", "anchor_text": "Wav2Letter", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/what-is-a-neural-network-6010edabde2b", "anchor_text": "convolutional neural networks", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural network-based", "paragraph_index": 1}, {"url": "https://catalog.ldc.upenn.edu/LDC93S1", "anchor_text": "TIMIT", "paragraph_index": 4}, {"url": "http://www.cs.toronto.edu/~graves/icml_2006.pdf", "anchor_text": "Connectionist Temporal Classification (CTC) Algorithm", "paragraph_index": 22}, {"url": "https://distill.pub/2017/ctc/", "anchor_text": "this great article on Distill", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Viterbi_algorithm", "anchor_text": "dynamic programming techniques", "paragraph_index": 32}, {"url": "https://nlp.cs.nyu.edu/nycnlp/lafferty01conditional.pdf", "anchor_text": "various technical reasons", "paragraph_index": 53}, {"url": "http://www.cs.toronto.edu/~graves/icml_2006.pdf", "anchor_text": "Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks", "paragraph_index": 66}, {"url": "https://arxiv.org/pdf/1609.03193.pdf", "anchor_text": "Wav2Letter: an End-to-End ConvNet-Based Speech Recognition System", "paragraph_index": 67}, {"url": "https://arxiv.org/pdf/1812.07625.pdf", "anchor_text": "Wav2Letter++: The Fastest Open-Source Speech Recognition System", "paragraph_index": 68}, {"url": "https://arxiv.org/pdf/1812.06864.pdf", "anchor_text": "Fully Convolutional Speech Recognition", "paragraph_index": 69}, {"url": "https://arxiv.org/pdf/1712.09444.pdf", "anchor_text": "Letter-Based Speech Recognition With Gated Convnets", "paragraph_index": 70}, {"url": "https://nlp.cs.nyu.edu/nycnlp/lafferty01conditional.pdf", "anchor_text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data", "paragraph_index": 71}, {"url": "https://zach.dev", "anchor_text": "https://zach.dev", "paragraph_index": 73}], "all_paragraphs": ["In 2016, Facebook AI Research (FAIR) broke new ground with Wav2Letter, a fully convolutional speech recognition system.", "In Wav2Letter, FAIR showed that systems based on convolutional neural networks (CNNs) could perform as well as traditional recurrent neural network-based approaches.", "In this article, we\u2019ll focus on an understudied module at the core of Wav2Letter: the Auto Segmentation (ASG) Criterion.", "In the Wav2Letter architecture shown above, we\u2019ll find ASG to the right of the acoustic model.", "Using a convolutional approach with ASG, FAIR reported significant improvements in Letter Error Rate (LER) when applied to the TIMIT dataset.", "\u2026 as well as speed increases for short and long sequences, even though Wav2Letter used a CPU-only version of the model for benchmarking.", "Fundamentally, the ASG Criterion is a special type of loss function.", "ASG builds on older algorithms like Connectionist Temporal Classification (CTC), which have long been a mainstay of speech recognition models.", "To understand ASG, we\u2019ll first need to understand the specific problem solved by algorithms like CTC. Then we\u2019ll take a brief look at CTC so we can finally understand how ASG differs and improves upon it.", "The heart of Wav2Letter is an acoustic model that, as you may have already guessed, predicts letters from sound waves.", "Specifically, Wav2Letter processes audio into slices, passes them through various convolutional layers, and outputs a set of probabilities for each audio slice. Each probability set holds estimates for each letter in the model\u2019s dictionary of letters.", "This means that for a slice of audio, we\u2019ll have an estimate that the letter spoken at that moment is an \u2018e\u2019 or \u2018t\u2019 or \u2018s\u2019, or any other possible letter.", "The acoustic model spits out a chain of these probabilities, where each link in the chain represents an estimate that a particular letter appears at that moment.", "This chain contains the hypotheses of our acoustic model. To reach our final prediction, we need to transform this chain of probabilities into the most likely series of letters that occur across audio slices.", "Remember that Wav2Letter\u2019s acoustic model is basically a sound wave-to-letter classifier. The model \u2018sees\u2019 a bit of the sound wave input and says, \u201cOk, that looks like an \u2018H\u2019 or maybe an \u2018S\u2019.", "But unlike a static image, sound waves flow through time. If our phrase is \u201cTHE CAT\u201d, how do we know when the speaker has stopped saying \u2018T\u2019 and moved on to \u2018H\u2019?", "To learn \u201cThis is what a \u2018T\u2019 looks like\u201d, Wav2Letter needs to understand how spoken utterances transition between letters over time.", "Only by understanding these transitions can the model begin to map its representations of a sound to the correct letter label.", "But we have a problem. Training data for speech recognition usually only comes with audio and a written transcript \u2014 no data for alignment between the two. We might input a three second .wav file of someone saying \"The Cat\" alongside a .txt file of the letters: \"The Cat\".", "We know that \u2018T\u2019 comes before \u2018H\u2019 in \u2018The\u2019, but the transcript doesn\u2019t tell us when.", "Aligning every letter by hand to the matching moment in audio would be time-consuming and nearly impossible at scale. We also can\u2019t rely on superficial general rules like \u2018one letter lasts 500 milliseconds\u2019 because people speak at different speeds.", "What do we do? Enter CTC.", "Traditionally, practitioners solved this lack of alignment data with the Connectionist Temporal Classification (CTC) Algorithm (don\u2019t you love these names?).", "In this section, we\u2019ll only touch on the high points of CTC so we can see how ASG differs. You can read a deeper explanation of CTC in this great article on Distill.", "For each slice of audio, CTC expects a set of probabilities for all possible letters plus, crucially, a special \u2018blank\u2019 token.", "Wav2Letter\u2019s acoustic model feeds its output chain of probability sets into CTC, which gets to work finding the highest probability output. And it does it without ever having any timing data.", "Let\u2019s take a simplified example of a single audio file where the speaker says \u2018hello\u2019.", "As we\u2019ve seen, our input is audio transformed by our acoustic model into a set of probabilities for each letter at each audio slice.", "In this example, we\u2019re imagining that our dictionary of letters only contains \u2018h\u2019 \u2018e\u2019 \u2018l\u2019 \u2018o\u2019 and the special blank token mentioned before, which I\u2019ll call by its formal scientific name: squiggly e.", "Every time slice has estimates for each letter. Darker cells represent a higher probability for that letter. Believe it or not, this is all we need to infer likely alignments between sound and letters.", "Imagine this grid of letters as a graph.", "CTC snakes its way through every possible combination, column by column:", "This graph gives us every possible alignment of letters for the audio. (In practice, CTC uses dynamic programming techniques that make this process much more efficient than it sounds).", "CTC sums the probability for each possible alignment. Once finished, CTC surfaces the most probable alignments for a segment.", "Put more formally, CTC aims to maximize the overall score of a path through this graph of possible alignments.", "Here are two highly probable alignments for our \u2018hello\u2019 example:", "Raw alignments will run from the reasonable to the ridiculous.", "Notice that our second alignment, while technically valid, doesn\u2019t even include an \u2018H\u2019! Other alignments might be \u2018HHHHHELLOO\u201d or \u201cHEELLLLLOO\u201d and, on the less-likely side, \u201cOOOOOOOOOO\u201d and \u201cLLLLLOOOOO\u201d.", "To generate its final output CTC removes repeated letters\u2026", "\u2026 and removes the special blank token, the squiggly e.", "With repeats and squiggly e\u2019s removed we end up with: \u201chello\u201d as our highest-probability output.", "This output can be compared with the written transcript for our audio. We can calculate our model\u2019s loss against the ground-truth of our transcript. Nice!", "First, by snaking its way through possible alignments and linking highly-probable individual letter guesses, we end up with a valid prediction of a transcript for the audio without any alignment data.", "This also allows CTC to handle variations in audio, such as when a speaker dwells on the letter \u2018h\u2019, because CTC can include \u2018h\u2019 multiple times in the alignment. When we remove duplicates, we still end up with \u201chello\u201d.", "Second, our special squiggly e does double-duty as the separator for junk-frames (such as silence or breathing that might occur between letters) and as the separator for repeated letters.", "This lets the model cope with noisy frames where it\u2019s not confident about any letter. Plus, it lets the model generate words like \u2018hello\u2019 even though \u2018l\u2019 is a repeated letter and CTC removes repeats.", "The Auto Segmentation Criterion (ASG) is different from CTC in two ways:", "Let\u2019s look at each of these.", "In Wav2Letter FAIR reports that, in practice, there was \u201cno advantage\u201d to using a special blank token to handle junk frames of audio between letters.", "So ASG removes this token. For repeated letters, ASG includes a \u20182\u2019 for repeated letters, instead of the blank token. In our example, \u2018hello\u2019 would become \u2018hel2o\u2019.", "By removing the special token, ASG significantly simplifies the graph that the algorithm must search when generating alignments. This likely leads to some of the performance gains reported.", "CTC expects its input to be normalized at the frame level. For each probability set in the chain created by our acoustic model, the probability of each letter is normalized with the probability of the other letters in that frame.", "For CTC, each frame is its own little world. What matters is to find the highest sum of letter-to-letter predictions across the frames.", "For various technical reasons, ASG doesn\u2019t do frame normalization. The details of the normalization are less important than what it implies:", "ASG gives powers to Wav2Letter\u2019s acoustic model that are usually reserved for language models: the ability to learn the likelihood of transitions between letters.", "In real language, certain combinations of letters are much more likely than others. This likelihood of certain combinations of letters, called \u2018transitions\u2019, could improve model accuracy.", "Some transitions are obviously more likely than others. For example, in English the series \u2018TH\u2019 is much more likely than \u2018TS\u2019 (as in obscure words like \u2018tsar\u2019 or \u2018tsetse fly\u2019).", "ASG contains its own weight matrix that models possible transitions between each letter. Like any other standard weight matrix, these weights are trained through back-propagation.", "Using this matrix, ASG allows the acoustic model to learn transition scores \u2014 the likelihood that a letter follows another letter \u2014 and bake them right into the edges of the graph we use to generate the most likely alignment for our letter-to-letter prediction.", "FAIR\u2019s results suggest that this enhancement of the acoustic model improves the accuracy of the CNN.", "Since the acoustic model contains useful understanding of the letter sequences, Wav2Letter\u2019s decoder actually uses the transition data from the acoustic model as well as output from its real language model when scoring its final transcript.", "Speech recognition systems like Wav2Letter face an annoying problem: there\u2019s rarely data about how sound and transcriptions are aligned in time.", "But to generate an accurate letter-by-letter prediction, we need to know when one letter starts and another letter ends as our acoustic model learns to associate sound waves with certain letters.", "Traditionally, deep learning practitioners solved this problem with an algorithm called CTC. Though CTC works well in many cases, it includes an extra token that increases complexity and may decrease speed. It also includes a form of normalization that limits how much the acoustic model can learn.", "ASG is a special type of loss function that refines CTC by removing CTC\u2019s extra token and allowing the acoustic model to use its own weight matrix to learn transitions between letters.", "If you\u2019re curious to learn more about Wav2Letter or ASG, see the references below.", "A. Graves, S Fern\u00e1ndez, F. Gomez, J. Schmidhuber, Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks (2006), Proceedings of the 23rd International Conference on Machine Learning", "R. Collobert, C. Puhrsch, G Synnaeve, Wav2Letter: an End-to-End ConvNet-Based Speech Recognition System (2016), Facebook AI Research", "V. Pratap, A. Hannun, Q. Xu, J. Cai, J. Kahn, G. Synnaeve, V. Liptchinsky, R. Collobert, Wav2Letter++: The Fastest Open-Source Speech Recognition System (2018), Facebook AI Research", "N. Zeghidour, Q. Xu, V. Liptchinsky, N. Usunier, G. Synnaeve, R. Collobert, Fully Convolutional Speech Recognition (2018)", "V. Liptchinsky, G. Synnaeve, R. Collobert, Letter-Based Speech Recognition With Gated Convnets (2019), Facebook AI Research", "J. Lafferty, A. McCallum, F. Pereira, Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data (2001)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Technical: Node, React, Serverless, GraphQL and more\u2026 | Human: focus, optimism, minimalism | https://zach.dev"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F765efd55449&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----765efd55449--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----765efd55449--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@zachcaceres?source=post_page-----765efd55449--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zachcaceres?source=post_page-----765efd55449--------------------------------", "anchor_text": "Zach C"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa443ed534b11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&user=Zach+C&userId=a443ed534b11&source=post_page-a443ed534b11----765efd55449---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1609.03193.pdf", "anchor_text": "Wav2Letter"}, {"url": "https://towardsdatascience.com/what-is-a-neural-network-6010edabde2b", "anchor_text": "convolutional neural networks"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural network-based"}, {"url": "https://catalog.ldc.upenn.edu/LDC93S1", "anchor_text": "TIMIT"}, {"url": "http://www.cs.toronto.edu/~graves/icml_2006.pdf", "anchor_text": "Connectionist Temporal Classification (CTC) Algorithm"}, {"url": "https://distill.pub/2017/ctc/", "anchor_text": "this great article on Distill"}, {"url": "https://en.wikipedia.org/wiki/Viterbi_algorithm", "anchor_text": "dynamic programming techniques"}, {"url": "https://nlp.cs.nyu.edu/nycnlp/lafferty01conditional.pdf", "anchor_text": "various technical reasons"}, {"url": "https://distill.pub/2017/ctc/", "anchor_text": "Sequence Modeling with CTC"}, {"url": "http://www.cs.toronto.edu/~graves/icml_2006.pdf", "anchor_text": "Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks"}, {"url": "https://arxiv.org/pdf/1609.03193.pdf", "anchor_text": "Wav2Letter: an End-to-End ConvNet-Based Speech Recognition System"}, {"url": "https://arxiv.org/pdf/1812.07625.pdf", "anchor_text": "Wav2Letter++: The Fastest Open-Source Speech Recognition System"}, {"url": "https://arxiv.org/pdf/1812.06864.pdf", "anchor_text": "Fully Convolutional Speech Recognition"}, {"url": "https://arxiv.org/pdf/1712.09444.pdf", "anchor_text": "Letter-Based Speech Recognition With Gated Convnets"}, {"url": "https://nlp.cs.nyu.edu/nycnlp/lafferty01conditional.pdf", "anchor_text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----765efd55449---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----765efd55449---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/speech-recognition?source=post_page-----765efd55449---------------speech_recognition-----------------", "anchor_text": "Speech Recognition"}, {"url": "https://medium.com/tag/data-science?source=post_page-----765efd55449---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----765efd55449---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&user=Zach+C&userId=a443ed534b11&source=-----765efd55449---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&user=Zach+C&userId=a443ed534b11&source=-----765efd55449---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----765efd55449--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F765efd55449&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----765efd55449---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----765efd55449--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----765efd55449--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----765efd55449--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----765efd55449--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----765efd55449--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----765efd55449--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----765efd55449--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----765efd55449--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zachcaceres?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zachcaceres?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Zach C"}, {"url": "https://medium.com/@zachcaceres/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "456 Followers"}, {"url": "https://zach.dev", "anchor_text": "https://zach.dev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa443ed534b11&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&user=Zach+C&userId=a443ed534b11&source=post_page-a443ed534b11--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb2fb52832031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbetter-faster-speech-recognition-with-wav2letters-auto-segmentation-criterion-765efd55449&newsletterV3=a443ed534b11&newsletterV3Id=b2fb52832031&user=Zach+C&userId=a443ed534b11&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}