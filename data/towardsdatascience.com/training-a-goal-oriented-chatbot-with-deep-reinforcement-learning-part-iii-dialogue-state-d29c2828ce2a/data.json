{"url": "https://towardsdatascience.com/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a", "time": 1682994040.5070982, "path": "towardsdatascience.com/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a/", "webpage": {"metadata": {"title": "Training a Goal-Oriented Chatbot with Deep Reinforcement Learning \u2014 Part III | by Max Brenner | Towards Data Science", "h1": "Training a Goal-Oriented Chatbot with Deep Reinforcement Learning \u2014 Part III", "description": "Learn how to code a dialogue state tracker for a goal-oriented chatbot agent"}, "outgoing_paragraph_urls": [{"url": "https://github.com/MiuLab/TC-Bot", "anchor_text": "TC-Bot", "paragraph_index": 2}, {"url": "https://github.com/maxbren/GO-Bot-DRL", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/state_tracker.py", "anchor_text": "state_tracker.py", "paragraph_index": 2}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/db_query.py", "anchor_text": "db_query.py", "paragraph_index": 2}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/train.py", "anchor_text": "train.py", "paragraph_index": 12}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/db_query.py", "anchor_text": "db_query.py", "paragraph_index": 21}, {"url": "https://medium.com/@maxbrenner110/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iv-user-simulator-and-a0efd3829364", "anchor_text": "next part", "paragraph_index": 31}], "all_paragraphs": ["Check out the previous parts if you haven\u2019t yet where we learn about training in this domain and the DQN agent! The goal of this agent is to select an appropriate movie ticket for the user.", "In this part the state tracker is explained along with the query system for the database used by the state tracker.", "This tutorial series is based off of TC-Bot. The github code for this series can be found here. We will be working with state_tracker.py and db_query.py.", "Here is the diagram we are following from the previous two parts:", "The dialogue state tracker or just state tracker (ST) in a goal-oriented dialogue system has the primary job of preparing the state for the agent. As we discussed in the previous part the agent needs a useful state to be able to make a good choice on what action to take. The ST updates its internal history of the dialogue by collecting both user and agent actions as they are taken. It also keeps track of all inform slots that have been contained in any agent and user actions thus far in the current episode. The state used by the agent is a numpy array made of information from the current history and the current informs of the ST. In addition, whenever the agent wishes to inform a slot to the user the ST queries the database for a value that works given its current informs. In essence, the ST prepares a state for the agent given its history of the episode and all of the inform slots uttered by the user and agent so far in the episode, as well as queries the database for the agent.", "Before going further lets go over a few of the notable action intents from part I: inform, request and match found.", "Inform means the action contains inform slots which the sender wishes to supply to the receiver.", "Request means the action contains request slots which all have the value of \u201cUNK\u201d (meaning unknown) as the sender wishes for the filled values to be sent back in the next action from the receiver. For example if the sender requests a date (value of \u201cUNK\u201d) then an appropriate action for the receiver to take (although it doesn\u2019t have to) would be to inform back to the original sender \u201ctomorrow\u201d or some other value.", "Only the agent can send a match found action to the user. This means when the ST receives the agent action it finds a ticket that works with the current informs and fills the inform slots of that action with all the slots from the ticket, in addition to the actual ticket ID itself. However, if the agent decided to take a match found action but there isn\u2019t actually a ticket that works, then the actions inform slots are kept empty except for a special indication that there is no match. This action type is important as the agent MUST at some point in the episode take a match found action that contains a ticket that matches the user\u2019s constraints to succeed in the episode, as will be explained in the next part.", "Final note: an agent can only contain ONE slot unlike the user sim action which can have multiple slots. The only exception to this is a match found action as it might contain all slots of a ticket.", "Example of match found action below.", "update_state_agent(self, agent_action) takes as input an agent action and updates the history and current informs of the ST. update_state_user(self, user_action) takes as input a user action and updates these two variables as well.", "The reset method of this class (called in the reset function in train.py) resets current informs, history and also the round number, which indicates the current round of the episode:", "Think of the action that comes out of the agent being the primitive or unfilled-in version in some cases and the state tracker as filling in any inform slots with database info. If the agent action is an inform then the database will be queried for a matching value that does not conflict with the current informs. If the action is a match found then the database will be queried for a matching ticket that fits the current informs. For all other intents no querying is necessary. Note: self.match_key below is set to 'ticket' in the dialogue configuration.", "Actions of intent \u2018inform\u2019 and \u2018match_found\u2019 are handled in specific ways.", "Finally, add the round number to the agent action and append agent action to history.", "Remember that actions are dictionaries and in python dicts are mutable so the original agent action that is sent into this method is actually updated itself by the query info and round number.", "The most important job of the ST is to provide the agent with a useful state or representation of the history of the current episode. get_state(self, done) takes a done bool which indicates whether the episode is over after this round completes and outputs a numpy array of shape (state size,). The state size isn\u2019t important to know as it is just based on how much info we store in the state. But you can easily change it if you wanted to remove or add more information.", "The state is made up of useful information on the state of the episode such as the last user action and last agent action. This is to inform the agent of the most immediate history which should be enough of the episode to allow the agent to take a close-to-optimal action. In addition, the round_num is encoded to let the agent know the urgency of the episode (if the episode was close to its max number of rounds allowed the agent might consider taking a match found action to see if it has a match before it\u2019s too late). Finally, the state is made of information about the current informs and how many items in the database match those current informs.", "There is a lot of research and work being put into state tracking such as the best way to encode information and what information to provide in the state. This state preparation method is probably far from optimal but it takes a lot of tuning to optimize this process. Take a look at part V for resources on state tracking.", "The state tracker as we saw above needs to query the database for ticket information to fill inform and match found agent actions. It also is used by the state preparation method to gather useful information for the agent. The query system implemented here can be used for any database of the same structure as this movie ticket database.", "I am not going to go into much detail about the actual implementation of the methods in db_query.py as understanding this does not really improve understanding how this dialogue system works. However, if there is enough demand for a full run through on the implementation then I will make a new post about this class.", "get_db_results(constraints) -> dict: Called in update_state_agent(self, agent_action) in response to an agent action with intent \u2018match_found\u2019, explained above. Looks at each item in the database and if the item slots contain all constraint keys as well as have matching values for these slots then the item is added to the return dict. Therefore, it finds all matches in the database given constraints.", "For example, say the database looked like this:", "The output would be {0: {'theater': 'regal 6', 'date': 'tonight', 'city': 'seattle'}} because that was the only item that contained all of the constraint keys and matched all of its values", "fill_inform_slot(inform_slot_to_fill, current_inform_slots) -> dict: Called in update_state_agent(self, agent_action) in response to an action with intent \u2018inform\u2019, explained above. First, it calls get_db_results(current_informs) to get all the database matches. Then the values of matches[inform_slot_to_fill] are tallied and the highest occurring value is returned.", "For example, say these are the matches returned from get_db_results(constraints):", "If inform_slot_to_fill was 'theater' then this method would return {'theater': 'regal 6'}, likewise if inform_slot_to_fill was 'date' then the output would be {'date': 'tomorrow'}. The majority value of the key we care about is selected.", "get_db_results_for_slots(current_informs) -> dict: Called in get_state(self, done=false). Goes through the whole database and counts all occurrences of each slot (key, value) in current informs and returns a dict of key: count for all keys; In addition, 'matching_all_constraints': # which stores how many database items match all of the current inform slots, is another bit of useful information in the state.", "For example, using the same database as above:", "In conclusion, the state tracker uses each agent and user action to update its history and current informs so it can prepare a useful state for the agent when it needs to take an action. It also uses a simple query system to fill in agent inform slots for both inform and match found actions.", "In the next part we will learn about one of the most important parts to training an agent with reinforcement learning: the user simulator. We will learn the specific rules that our user sim will use to make human-like actions!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Interested in all things machine learning, procedural and generative"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd29c2828ce2a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@maxbrenner110?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maxbrenner110?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Max Brenner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe83c3988e008&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&user=Max+Brenner&userId=e83c3988e008&source=post_page-e83c3988e008----d29c2828ce2a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/MiuLab/TC-Bot", "anchor_text": "TC-Bot"}, {"url": "https://github.com/maxbren/GO-Bot-DRL", "anchor_text": "here"}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/state_tracker.py", "anchor_text": "state_tracker.py"}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/db_query.py", "anchor_text": "db_query.py"}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/train.py", "anchor_text": "train.py"}, {"url": "https://github.com/maxbren/GO-Bot-DRL/blob/master/db_query.py", "anchor_text": "db_query.py"}, {"url": "https://medium.com/@maxbrenner110/training-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iv-user-simulator-and-a0efd3829364", "anchor_text": "next part"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d29c2828ce2a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d29c2828ce2a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/chatbots?source=post_page-----d29c2828ce2a---------------chatbots-----------------", "anchor_text": "Chatbots"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----d29c2828ce2a---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&user=Max+Brenner&userId=e83c3988e008&source=-----d29c2828ce2a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&user=Max+Brenner&userId=e83c3988e008&source=-----d29c2828ce2a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd29c2828ce2a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d29c2828ce2a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d29c2828ce2a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maxbrenner110?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@maxbrenner110?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Max Brenner"}, {"url": "https://medium.com/@maxbrenner110/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "238 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe83c3988e008&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&user=Max+Brenner&userId=e83c3988e008&source=post_page-e83c3988e008--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffb2cbe1972e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-a-goal-oriented-chatbot-with-deep-reinforcement-learning-part-iii-dialogue-state-d29c2828ce2a&newsletterV3=e83c3988e008&newsletterV3Id=fb2cbe1972e0&user=Max+Brenner&userId=e83c3988e008&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}