{"url": "https://towardsdatascience.com/the-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2", "time": 1683008911.953799, "path": "towardsdatascience.com/the-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2/", "webpage": {"metadata": {"title": "The Simple Approach to Word Embedding for Natural Language Processing using Python | by Eric Kleppen | Towards Data Science", "h1": "The Simple Approach to Word Embedding for Natural Language Processing using Python", "description": "When brainstorming new data science topics to investigate, I always gravitate towards Natural Language Processing (NLP). It is a rapidly growing field of Data Science with constant innovations to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/3-super-simple-projects-to-learn-natural-language-processing-using-python-8ef74c757cd9", "anchor_text": "simple projects to get started in NLP using \u201cBag of Words\u201d models", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1301.3781.pdf", "anchor_text": "Word2Vec attempts to solve a couple of the issues with the BoW approach", "paragraph_index": 8}, {"url": "https://radimrehurek.com/gensim/index.html", "anchor_text": "Gensim", "paragraph_index": 13}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "Sci-Kit Learn\u2019s Principle Component Analysis", "paragraph_index": 20}, {"url": "https://matplotlib.org/", "anchor_text": "matplitlib", "paragraph_index": 20}, {"url": "https://plotly.com/python/line-and-scatter/", "anchor_text": "Next, construct a scatter plot using ploty Scattergl to get the best performance on large data sets", "paragraph_index": 31}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity", "paragraph_index": 35}, {"url": "http://pythondashboards.com", "anchor_text": "pythondashboards.com", "paragraph_index": 40}, {"url": "http://www.linkedin.com/in/erickleppen01/", "anchor_text": "www.linkedin.com/in/erickleppen01/", "paragraph_index": 40}], "all_paragraphs": ["When brainstorming new data science topics to investigate, I always gravitate towards Natural Language Processing (NLP). It is a rapidly growing field of Data Science with constant innovations to explore, and I love to analyze writing and rhetoric. NLP naturally fits my interests! Previously, I wrote an article about simple projects to get started in NLP using \u201cBag of Words\u201d models. This article aims to go beyond the simple \u201cbag of words\u201d approaches by exploring quick and easy ways to generate word embeddings using Word2Vec through the Python Gensim library.", "When I started exploring Natural Language Processing (NLP), the first models I learned about were simple Bag of Words models. Although they can be very effective, they have limitations.", "A bag-of-words (BoW) is a representation of text that describes the occurrence of words within a text corpus, but doesn\u2019t account for the sequence of the words. That means it treats all words independent from one another, hence the name bag of words.", "BoW consists of a set of words (vocabulary) and a metric like frequency or TF-IDF to describe each word\u2019s value in the corpus. That means BoW can result in sparse matrices and high dimensional vectors that consume a lot of computer resources if the vocabulary is very large.", "To simplify the concept of BoW vectorization, imagine you have two sentences:", "The dog is whiteThe cat is black", "Converting the sentences to a vector space model would transform them in such a way that looks at the words in all sentences, and then represents the words in the sentence with a number. If the sentences were One-Hot encoded:", "The BoW approach effectively transforms the text in to a fixed-length vector to be used in machine learning.", "Developed by a team of researchers at Google, Word2Vec attempts to solve a couple of the issues with the BoW approach:", "Using a neural network with only a couple layers, Word2Vec tries to learn relationships between words and embeds them in a lower-dimensional vector space. To do this, Word2vec trains words against other words that neighbor them in the input corpus capturing some of the meaning in the sequence of words. The researchers devised two novel approaches:", "Either of the approaches result in a vector space that maps word-vectors close together based on contextual meaning. That means, if two word-vectors are close together, those words should have similar meaning based on their context in the corpus. For example, using Cosine Similarity to analyze the vectors produced by their data, researchers were able to construct analogies like king minus man plus woman =?", "The output vector most closely matched Queen.", "If this seems confusing, do not worry. Applying and exploring Word2Vec is simple and will make more sense as I go through examples!", "The Python library Gensim makes it easy to apply Word2Vec, as well as several other algorithms for the primary purpose of topic modeling. Gensim is free and can be installed using Pip or Conda:", "The data and ALL CODE can be found in my GitHub and is the same repo as the spam email dataset used in a previous article.", "I start by loading the libraries and reading the csv file using Pandas.", "Before playing with the email data, I want to explore Word2Vec with a simple example using a small vocabulary of a few sentences:", "Notice the sentences have been tokenized since I want to generate embeddings at the word level, not sentence. Run the sentences through the Word2Vec model.", "Notice when constructing the model, I pass in min_count =1 and size = 5. That means it will include all words that occur \u2265 1 time and generate a vector with a fixed length of 5. Notice when printed, the model displays the count of unique vocab words, array size, and learning rate (default .025)", "Notice it is possible to access the embedding for one word at a time.Notice the words in the vocabulary can be reviewed a couple different ways using w2v.wv.vocab.", "Now that the word embeddings have been created using Word2Vec, they can be visualized using a method to represent the vector in a flattened space. I am using Sci-Kit Learn\u2019s Principle Component Analysis (PCA) functionality to flatten the word vectors to 2D space, and then I\u2019m using matplitlib to visualize the results.", "Fortunately, the corpus is tiny so it is easy to visualize; however, it is hard to decipher any meaning from the plotted points since the model had such little information from which to learn.", "Now that I\u2019ve walked through a simple example, it is time to apply those skills to bigger data. Inspeact the email data by calling the dataframe head().", "Notice the text is has not been pre-processed at all! Using a simple function and some regular expressions, cleaning the text of punctuation and special characters and setting it all to lower case is simple.", "Notice the clean column has been added to the dataframe and the text has been cleaned of punctuation and upper case.", "Since I want word embeddings, the text needs to be tokenized. Using a for loop, I go through the dataframe tokenizing each clean row. After creating the corpus, I generate the word vectors by passing the corpus through Word2vec.", "Notice the data has been tokenized and is ready to be vectorized!", "The corpus for the email data is much larger than the simple example. Because of how many words are included, I can\u2019t plot them like I did using matplotlib.", "Good luck understanding that! It is time to use a different tool. Instead of matplotlib, I\u2019m going to use plotly to generate an interactive visualization that can be zoomed. That will make it easier to explore the data points.", "Again, I use the PCA technique. Then I put the results and words into a dataframe. This will make it easier to graph and annotate in plotly.", "Notice I add the word column to the dataframe so the word displays when hovering over the point on the graph.", "Next, construct a scatter plot using ploty Scattergl to get the best performance on large data sets. Refer to the documentation for more information about the different scatter plot options.", "Notice I use Numpy to generate random numbers for the graph colors. This makes it a bit more visually appealing! Notice I set the text to the word column of the dataframe. The word appears when hovering over the data point.", "Plotly is great since it generates interactive graphs and it allows me to zoom in on the graph and inspect points more closely.", "Beyond visualizing the embeddings, it is possible to explore them with some code. Additionally, the models can be saved as a text file to be used in future modeling. Review the Gensim documentation for the complete list of features.", "Gensim uses cosine similarity to find the most similar words. Notice It is also possible to evaluate analogies and find the word that is least similar or doesn\u2019t match with the other words.", "I won\u2019t cover a complete example in this article, but it is possible to use these vectors in predictive modeling. To use the embeddings, the word vectors need to be mapped. In order to convert a document of multiple words into a single vector using the trained model, it is typical to take the word2vec of all words in the document, then take its mean.", "To learn more about using the word2vec embeddings in predictive modeling, check out this kaggle.com notebook.", "Using the novel approaches available with the Word2Vec model, it is easy to train very large vocabularies while achieving accurate results on machine learning tasks. Natural language processing is a complex field, but there are many libraries and tools for Python that make getting started simple. If you\u2019re interested in learning more about NLP or data science, check out my other articles:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Product Manager at Kipsu. Learn dashboards at pythondashboards.com Top writer. www.linkedin.com/in/erickleppen01/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fae028c8dbfd2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://erickleppen.medium.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Eric Kleppen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e2ea32699c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&user=Eric+Kleppen&userId=1e2ea32699c9&source=post_page-1e2ea32699c9----ae028c8dbfd2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.needpix.com/photo/336813/word-cloud-words-tag-cloud-tagcloud-wordcloud-happy-optimistic-satisfied", "anchor_text": "Picture 1"}, {"url": "https://pixabay.com/photos/model-posture-legs-bodysuit-cube-4689824/", "anchor_text": "Picture 2"}, {"url": "https://towardsdatascience.com/3-super-simple-projects-to-learn-natural-language-processing-using-python-8ef74c757cd9", "anchor_text": "simple projects to get started in NLP using \u201cBag of Words\u201d models"}, {"url": "https://radimrehurek.com/gensim/", "anchor_text": "https://radimrehurek.com/gensim/"}, {"url": "https://arxiv.org/pdf/1301.3781.pdf", "anchor_text": "Word2Vec attempts to solve a couple of the issues with the BoW approach"}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word."}, {"url": "https://radimrehurek.com/gensim/index.html", "anchor_text": "Gensim"}, {"url": "https://github.com/bendgame/nlpBeginnerProjects", "anchor_text": "bendgame/nlpBeginnerProjectsBeginner projects for NLP Medium article. Contribute to bendgame/nlpBeginnerProjects development by creating an account\u2026github.com"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "Sci-Kit Learn\u2019s Principle Component Analysis"}, {"url": "https://matplotlib.org/", "anchor_text": "matplitlib"}, {"url": "https://plotly.com/python/line-and-scatter/", "anchor_text": "Next, construct a scatter plot using ploty Scattergl to get the best performance on large data sets"}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity"}, {"url": "https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm", "anchor_text": "Basic NLP: Bag of Words, TF-IDF, Word2Vec, LSTMExplore and run machine learning code with Kaggle Notebooks | Using data from Personalized Medicine: Redefining Cancer\u2026www.kaggle.com"}, {"url": "https://towardsdatascience.com/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184", "anchor_text": "Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python \u2014\u2026Collect Text through APIs and Web Scrapingtowardsdatascience.com"}, {"url": "https://medium.com/@erickleppen", "anchor_text": "follow me on Medium"}, {"url": "https://erickleppen.medium.com/membership", "anchor_text": "Get FULL ACCESS and help support my content by subscribing"}, {"url": "https://www.linkedin.com/in/erickleppen01/", "anchor_text": "LinkedIn"}, {"url": "https://pythondashboards.com/", "anchor_text": "website"}, {"url": "http://pythondashboards.com/", "anchor_text": "\u2014 Eric Kleppen"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ae028c8dbfd2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----ae028c8dbfd2---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ae028c8dbfd2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/analytics?source=post_page-----ae028c8dbfd2---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/tag/nlp?source=post_page-----ae028c8dbfd2---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----ae028c8dbfd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----ae028c8dbfd2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fae028c8dbfd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ae028c8dbfd2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ae028c8dbfd2--------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Eric Kleppen"}, {"url": "https://erickleppen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "http://pythondashboards.com", "anchor_text": "pythondashboards.com"}, {"url": "http://www.linkedin.com/in/erickleppen01/", "anchor_text": "www.linkedin.com/in/erickleppen01/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e2ea32699c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&user=Eric+Kleppen&userId=1e2ea32699c9&source=post_page-1e2ea32699c9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3968dec87f6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2&newsletterV3=1e2ea32699c9&newsletterV3Id=3968dec87f6a&user=Eric+Kleppen&userId=1e2ea32699c9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}