{"url": "https://towardsdatascience.com/observation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9", "time": 1683006045.872274, "path": "towardsdatascience.com/observation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9/", "webpage": {"metadata": {"title": "Software Risks and Artificial Intelligence Future | by Kevin Li | Towards Data Science", "h1": "Software Risks and Artificial Intelligence Future", "description": "Humans have been living in the most machine-dominant era ever. Before most even noticed it, they have been leaving mundane decisions to Netflix recommendation, Tesla autopilot, or a bot-written\u2026"}, "outgoing_paragraph_urls": [{"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "AlphaStar", "paragraph_index": 2}, {"url": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go", "anchor_text": "AlphaZero", "paragraph_index": 2}, {"url": "https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery", "anchor_text": "human-insurmountable obstacles in biomedical research", "paragraph_index": 15}], "all_paragraphs": ["Humans have been living in the most machine-dominant era ever. Before most even noticed it, they have been leaving mundane decisions to Netflix recommendation, Tesla autopilot, or a bot-written commentary on the New York Times, normally without considering the fact that these machines, coded by human, might also be prone to unintended outcomes such as censorship or fake news. While it is indeed undeniable that machine intelligence in many industries has better the majority\u2019s life quality, a rising number of news pertaining to data privacy and AI, e.g. Cambridge Analytica scandal, or killer drones involved in regional warfare, have imparted some concerns to the public. Let\u2019s admit: We, as the entire human species, are occasionally losing control over our information and algorithms. However, when public figures talk about AI, an overwhelming proportion simply talks about its prospects, leaving some individuals nervous about human\u2019s over-reliance on machine decisions. These fears are understandable: people are afraid of things that they are not certain about, and even experts do not know definitely what direction AI research are eventually heading to. Among those fears, which are rational and which are plainly unnecessary?", "If we enumerate detrimental AI applications that occur to people both in news and sci-fi movies, killer drones and AI fighting bots are often on top of the list. People fear that such entities can go beyond the inventors\u2019 control, subsequently hazarding mankind. Though it is unfortunately true that the US military has been utilizing killer drones on missions, it is still sufficient to say that AI killer bots will remain a fantasy for many decades more. Andrew Ng, former president of the Google Brain group, has it that human has repeatedly suffered from over-expectation from AI throughout history since the 1950s, and that current research is still far from producing an almighty AI that can conquer the mankind, even after AI\u2019s mastery on Go and Starcraft 2.", "Before addressing more on the fears, it is essential to know what present AI are capable of doing. Suppose that we define an AI to be good if one\u2019s performance can rival human\u2019s. In 2016 and 2019, the victory of AlphaGo and AlphaStar indicated that AI is able to \u201cmake good decisions within reasonable number of steps, even when full information is not available.\u201d (e.g. traditional chess AI considers 10,000,000 moves for a step, while AlphaZero considers 10,000). In the last decade, computers also have become extremely good at synthesizing photorealistic images, playing strategy games, and assisting diagnoses.", "With that said, are some other fears valid? In my opinion, yes, but it is equally important to realize what AI cannot do yet. Current AI is incapable of generalization of tasks, meaning that it cannot generalize its trained model to new but similar tasks, e.g. a cat-identifying model will do poorly in identifying dogs. \u201cMachine-learning systems can be confounded by situations they haven\u2019t seen before,\u201d according to MIT Technology Review.", "AI is also suffering from identifying causation. The inability to \u201cinfer\u201d results from AI algorithms\u2019 narrow focus on correlations instead casual relationships. \u201cIt\u2019s as if you knew that clouds made rain likelier, but you didn\u2019t know clouds caused rain,\u201d says Elias Bareinboim, a researcher in Columbia University. Such cluelessness is critical when AI has to answer \u201cwhat if\u201d questions. For example, a patient dies in a clinical trial; was it the fault of the experimental medicine or something else? Such reasoning is far beyond current AI\u2019s proficiency. While researchers have provided possible solutions such as causal Bayesian networks \u2014 an architecture that can detect which variables have the most influence on other ones, such approach still has not yet made many inroads in the AI field.", "The inaptitude of identifying causation can be problematic when machine are used to determine fairness, leading to a plausible concern of current AI \u2014 algorithmic bias. Such controversy emerges in 2016 when COMPAS, a judicial auxiliary system, was accused of being biased against black defendants. ProPublica, a news investigation group, claimed that \u201camong defendants who ultimately did not reoffend, blacks were more than twice as likely as whites to be classified as medium or high risk\u201d in terms of recidivism rate.", "To understand the controversy, one has to deliberate what does it mean for a system to be \u201cfair\u201d? Keep in mind that COMPAS assigns scores based on more than 100 factors, including age, sex, criminal history, and notably, race is \u201cnot\u201d included. The Washington Post reanalyzed the data collected by ProPublica on defendants assigned COMPAS scores, and discovered the following:", "These two traits however, result in the following two observation:", "A vital realization here is that :", "The two parties\u2019 definition of fairness are mutually exclusive, so the disparity in outcomes are mathematically guaranteed.", "Keep in mind that while the system does not consider race for individual decisions, the \u201ctraining data\u201d does include a comprehensive feature list, which presumably, includes race. Thus, it is likely that the real-life data fed into the system has caused the system bias. Should we simply accept the unfortunate outcome? Probably not the answer most would like to hear. However, if we manually tweak the algorithm to conditionally lower the risk prediction for blacks, we are also, by the inventors\u2019 definition, biased against white defendants.", "Another example of algorithmic bias is as the following: the US government tests find even top-performing facial recognition systems misidentify blacks at rates 5 to 10 times higher than they do whites, in 2019. The repeated occurrence of questionable machine decisions left a yet unsolved issue: Is such moral dilemma inevitable for machine decision? Given that algorithms have the potential to improve the effectiveness of consequential decisions, I believe that fairness should be one of the important fears which people should cope with in the near future.", "Starting in 2015, Elon Musk, CEO of Tesla, has been urging for US regulations on all advanced AI researches. \u201cAI is more dangerous than nukes,\u201d Musk explained. \u201cNarrow AI will result in dislocation, lost jobs and better weaponry, but that\u2019s not species-level risks I\u2019m talking about.\u201d Regardless the proposed regulation\u2019s feasibility, Musk\u2019s remark left the AI-optimistic society in confusion, especially when Mark Zuckerberg and John Giannandrea, Google AI chief, along with many researchers refuted his assertion publicly.", "However, the conversation is particularly interesting. Consider this: Elon Musk is far from a technology pessimist. He is adventurous enough to invest in all his 180 million PayPal earnings into SpaceX, Tesla, and Solar City. He is also in charge of the first ever \u201creusable rocket\u201d project in the human history. Musk\u2019s focus here is not company AIs such as Siri, but artificial general intelligence \u2014 some unprecedented, conscious, super-intelligent entity. While I previously stated my skepticism toward these \u201cAI apocalypse\u201d claims, Musk\u2019s answer brought up a critical issue of \u201chuman control over machines.\u201d", "UC Berkeley Professor Stuart Russell, one of the most influential AI researchers ever, once stated that he believe that a beneficial AI has to be \u201cprovably aligned\u201d to human values, and when we are talking about \u201cgeneral intelligence\u201d, the ultimate question is whether we can control AI\u2019s decisions, rather than what it can do.", "The losing-control fear is actually rational. Historically speaking, the computer age invented by Alan Turing is merely 70 years ago, but we have seen machines evolving from struggling to solve tic-tac-toe, to surpassing human knowledge on the board game Go within mere 30 hours of training or even solving human-insurmountable obstacles in biomedical research. From a technical perspective, Reinforcement Learning model\u2019s acumen to environment variables and the ability to generate training data itself on the fly is exponentially better than a newborn baby. Such a rapid learning speed of an entity is undoubtedly beyond human\u2019s comprehension before it has been invented. Thus, it might be fair to speculate that machine intelligence will outperform human\u2019s in perhaps a century or sooner. But, are we prepared for that?", "Uncertainty is good for machine decisions", "Sometimes people are afraid to talk profoundly about the dark side of AI because the scientific practice that we have been embracing for centuries is not designed for a beneficial technology pursuit: in statistics and machine learning you minimize a loss function that is exogenously specified; in operations research, you maximize a reward function. In many disciplines, the way we conceive problems is based on these arbitrary selected directions to interpret the nature in a particular, and arguably skewed lens. \u201cThat\u2019s the wrong problem\u201d said Stuart Russell in an interview in 2019.", "\u201cWe need machines to be uncertain, meaning to be reasonably skeptical to human assignment, so that we won\u2019t lose control over it after it takes off in an assigned direction.\u201d He added, \u201cMachines should never take an input objective as a gospel truth.\u201d Indeed, modern AI training methodology includes human assigning a fixed objective that may actually be erroneous. Sometimes those objectives exist within us but we either don\u2019t know how to explicate it, or we don\u2019t know what we want for our future. If an AI blindly pursue to minimize a number without considering that its goal, the numerical optima, might not make sense in human logic, the result can derail drastically.", "We need machines to be uncertain, so that we won\u2019t lose control over it after it takes off in an assigned direction.", "This vision is perhaps ideal though. If we actually want our machine to be uncertain, all the traditional decision processes, such as Markov decision, standard game tree search, becomes inapplicable. Furthermore, this creates a much more complicated problem because human interaction are now part of the problem in machine decision. In terms of the industry, where money dominates all factors, such humane deliberation is often beyond the cost that any enterprise is willing to dedicate in.", "To ensure a beneficial AI future requires patience in experimenting, and audacity in challenging some old scientific methods. Even some experts\u2019 claims regarding beneficial AI remain ambiguous: for example, if human values are ever-evolving, how can an AI be \u201cprovably aligned\u201d to values? Yet, my perspective holds that fears toward AI are only rational if one considers what AI can and cannot do within the coming decade. The \u201cAI with uncertainty\u201d claim may seems implausible at this moment, but as we progress on making our machine intelligence more \u201cconscious\u201d of human values, such as causations, more clues could be revealed, and perhaps an AI that accounts human interaction into decision would no longer be a fantasy.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Student Researcher @ Berkeley AI Research | Incoming ML Engineer @ Adobe (Generative AI)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F473a1bd55fb9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://yutengli.medium.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": ""}, {"url": "https://yutengli.medium.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Kevin Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe3bdb4f4b4d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&user=Kevin+Li&userId=e3bdb4f4b4d1&source=post_page-e3bdb4f4b4d1----473a1bd55fb9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "AlphaStar"}, {"url": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go", "anchor_text": "AlphaZero"}, {"url": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go", "anchor_text": "Blogpost on AlphaZero"}, {"url": "https://unsplash.com/photos/zbLW0FG8XU8", "anchor_text": "Image Source"}, {"url": "https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery", "anchor_text": "human-insurmountable obstacles in biomedical research"}, {"url": "https://time.com/4281476/ibm-artificial-intelligence-watson-2016/", "anchor_text": "https://time.com/4281476/ibm-artificial-intelligence-watson-2016/"}, {"url": "https://techcrunch.com/2020/02/18/elon-musk-says-all-advanced-ai-development-should-be-regulated-including-at-tesla/", "anchor_text": "https://techcrunch.com/2020/02/18/elon-musk-says-all-advanced-ai-development-should-be-regulated-including-at-tesla/"}, {"url": "https://www.wired.com/2015/05/artificial-intelligence-pioneer-concerns/", "anchor_text": "https://www.wired.com/2015/05/artificial-intelligence-pioneer-concerns/"}, {"url": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go", "anchor_text": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go"}, {"url": "https://youtu.be/bHPeGhbSVpw", "anchor_text": "https://youtu.be/bHPeGhbSVpw"}, {"url": "https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/#comments", "anchor_text": "https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/#comments"}, {"url": "https://www.technologyreview.com/s/615189/what-ai-still-cant-do/", "anchor_text": "https://www.technologyreview.com/s/615189/what-ai-still-cant-do/"}, {"url": "https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/", "anchor_text": "https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/"}, {"url": "https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html", "anchor_text": "https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----473a1bd55fb9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----473a1bd55fb9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/commentary?source=post_page-----473a1bd55fb9---------------commentary-----------------", "anchor_text": "Commentary"}, {"url": "https://medium.com/tag/ethics-in-tech?source=post_page-----473a1bd55fb9---------------ethics_in_tech-----------------", "anchor_text": "Ethics In Tech"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----473a1bd55fb9---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&user=Kevin+Li&userId=e3bdb4f4b4d1&source=-----473a1bd55fb9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&user=Kevin+Li&userId=e3bdb4f4b4d1&source=-----473a1bd55fb9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F473a1bd55fb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----473a1bd55fb9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----473a1bd55fb9--------------------------------", "anchor_text": ""}, {"url": "https://yutengli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://yutengli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kevin Li"}, {"url": "https://yutengli.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "15 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe3bdb4f4b4d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&user=Kevin+Li&userId=e3bdb4f4b4d1&source=post_page-e3bdb4f4b4d1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F79c82a54a717&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fobservation-on-software-risks-and-artificial-intelligence-future-473a1bd55fb9&newsletterV3=e3bdb4f4b4d1&newsletterV3Id=79c82a54a717&user=Kevin+Li&userId=e3bdb4f4b4d1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}