{"url": "https://towardsdatascience.com/deep-ordinal-logistic-regression-1afd0645e591", "time": 1683010613.545105, "path": "towardsdatascience.com/deep-ordinal-logistic-regression-1afd0645e591/", "webpage": {"metadata": {"title": "Deep Representation of Ordinal Logistic Regression | by Rohan Kotwani | Towards Data Science", "h1": "Deep Representation of Ordinal Logistic Regression", "description": "A ranking algorithm can be used if the target variable is numerically ordered. The model will capture the shared variation between adjacent classes. This model can also be useful for semi-supervised\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/dmlc/xgboost/tree/master/demo/rank", "anchor_text": "ranking implementation", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Ordered_logit", "anchor_text": "Ordinal logistic regression", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Peter_McCullagh", "anchor_text": "Peter McCullagh", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Cross_entropy", "anchor_text": "cross entropy loss function", "paragraph_index": 10}, {"url": "https://github.com/freedomtowin/ml-projects/blob/master/Deep-Ordinal-Logistic-Regression/deep-ordinal-regression-v2.ipynb", "anchor_text": "example notebook", "paragraph_index": 16}, {"url": "https://www.gagolewski.com/resources/data/ordinal-regression/", "anchor_text": "source", "paragraph_index": 22}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "earth mover\u2019s distance", "paragraph_index": 22}], "all_paragraphs": ["A ranking algorithm can be used if the target variable is numerically ordered. The model will capture the shared variation between adjacent classes. This model can also be useful for semi-supervised classification, where proxy targets are assigned as a lower rank than the actual targets.", "The simplest ranking model is a regression model. The output of the regression model will be rounded to the closest integer, and the values are also clipped between maximum and minimum of the target. Multi-class models linear models are another option, but it should be noted that each class is treated separately and not in a rank ordered fashion. XGBoost also has a ranking implementation. I haven\u2019t tried it out, but it had success in the Expedia Kaggle competition. Ordinal logistic regression, or proportional odds model, is an extension of the logistic regression model that can be used for ordered target variables. It was first created in the 1980s by Peter McCullagh. In this post, a deep ordinal logistic regression model will be designed and implemented in TensorFlow. The link to the code is posted in the TensorFlow Formulation section.", "The proportional odds model, or ordinal logistic regression, is designed to predict an ordinal target variable. The relationship between the target, y, and input, X, is linear. The output of the linear kernel is defined as y*.", "A set of thresholds will divide the output of the linear kernel into K rank ordered classes. The model will have K-1 thresholds, where K is the maximum rank for y. Notice that each ranked class, in the model, shares parameters w and b.", "The last rank, K, is the catch-all class which captures the last class along with the data points not separated by the other thresholds.", "The thresholds are constrained to be monotonically increasing and greater than or equal to zero, as shown in the equation (3). Using monotonically increasing thresholds ensures the data points are assigned to one and only one ranked classes.", "The plot below illustrates the relationship between the linear kernel and the ranked thresholds. Notice that the thresholds are a subspace of the linear kernel.", "The distance of the linear kernel, of a data point, to a ranked threshold will be mapped to the probability of the data point \u201cbelonging\u201d to a ranked class. The distance, to the ranked threshold, is created by subtracting the output of the linear kernel from each of the K-1 thresholds . The sigmoid function will then map this output to the cumulative distribution function, across the ranked target variable, as shown in equation (4).", "The cumulative probability at j will always be greater than j-1 because of the monotonically increasing constraint on the threshold parameters. The probability of a data point belonging to a ranked class, j, is defined as difference between the cumulative distribution function at j and j-1.", "The edge cases, i.e., rank 0 and rank K , are defined by P(y<0) and 1-P(y < K-1), respectively. Notice that the relative probability of a data point belonging to rank 0 increases as the predicted output decreases or becomes negative. This is due to the monotonic constraint on the thresholds. The probability of a data point belonging to class K, or above, is simply one minus the maximum probability in the cumulative distribution function, in this case the CDF probability at ranked class K-1.", "The ranked class probability distribution defined above, can be optimized with a cross entropy loss function, shown in equation (6).", "The output, y, is a one-hot-encoded matrix used to indicate which class the observation belongs to. Because y is a discrete probability distribution, the cross entropy loss function, shown in equation (6), can be used to maximize the likelihood of the estimated parameters.", "We can inspect the derivative of the log-probability and see the relationship between adjacent threshold parameters, in the loss function. Equation (7) and (8) show useful derivative formulas.", "The derivative of log-probability function w.r.t theta at ranked class j is shown in equation (9) and (10). Note that if a term doesn\u2019t include theta at ranked class j, its derivative is zeroed out in equation (6).", "The simplified form of the derivative above is shown in equation (12). I removed equation (11) showing the steps to convert (10) to (12) because it was too long :)", "The derivative shows an interesting relationship between the differenced cumulative probabilities, at j and j-1, and the ratio of cumulative probabilities, at j and j-1. If the probability at j is zero, the gradient will be undefined. The gradient will also vanish if the probabilities at j and j-1 are too close. In addition, the gradient has the potential to swap signs for negative thresholds.", "There are various ways to formulate ordinal logistic regression in TensorFlow. The main issue will be defining the thresholds so that gradients are consistent with the gradient defined in the previous section. The example notebook can be found here.", "The linear portion of this model is defined by the dot product between the input data and the weights. The output of the linear kernel has shape (Nx1), where N are the number of data points. I decided to use a dense layer with a linear activation as the input to the ordinal layer. You might need to add a non-negative bias in the ordinal layer to handle potential negative values.", "A latent variable, omega, was created to construct the threshold parameters. The latent variable was initialized as an equally-spaced monotonically increasing sequence. The threshold for the last ranked class, K, is dropped and the CDF probability is inferred from the previous ranked class, K-1. The threshold parameter, theta, will have shape (1x(K-1)). The first threshold, at ranked class 0, will be statically defined as a constant zero value.", "Initially, I tried taking the cumulative sum of the squared latent variables to create the threshold parameter. However, the model didn\u2019t seem to converge. I figured that it was an issue with how the gradients were being propagated back to the thresholds. Here are some possible reasons why it didn\u2019t work: 1) the derivative of the cumulative sum propagated the same gradient for all ranked classes \u2264j. In other words, it didn\u2019t take into account the relationship between the j and j-1 threshold parameters 2)The gradient could be unstable around 0 for a squared latent variable, i.e., if the latent variable changes sign during optimization.", "To solve this problem, I first created K-1 thresholds and then took the difference between the j and j-1 latent variables, i.e., the inverse operation of the cumulative function. This results in K-2 threshold parameters. However, the differenced values could still be negative so I added a ReLU layer to ensure the differenced values would be positive. A constant, +1, to ensure that the gradient will always be defined, i.e., greater than zero. Finally, I concatenated the threshold at ranked class 0, which was statically defined to be zero.", "The CDF was created by subtracting linear kernel from the thresholds and then applying the sigmoid function. The CDF can then be transformed into the PDF by applying equation (6). Finally, the model can be optimized using sparse categorical cross entropy loss.", "Three ordinal datasets were collected from this source, i.e., Boston Housing, Stocks, and Kinematics datasets. The models were evaluated on the average cross-validation MAE , accuracy, and earth mover\u2019s distance (EMD). EMD captures the similarity between the predicted CDF and target CDF.", "A stratified 5-fold cross validation strategy was selected to evaluate the performance of these two models. I found there to be a some variability between multiple cross validation results. To limit this variability, I ran the cross-validation strategy 3 times, and saved the predicted and actual values of the validation set for each k-fold.", "The goal is to evaluate and compare the results of an ordinal model to a regression model. For simplicity, the regression model will be trained using the same number of hidden units, i.e., 32 hidden units, and the same optimization strategy. There were two choices for the regression model\u2019s loss function, i.e., mean absolute error (MAE) and mean squared error (MSE). I decided to use MAE as it seemed more appropriate for ranking than MSE.", "Since the ordinal model uses sparse categorical cross entropy loss, I thought it was a good idea to stratify the k-folds on the ranked class variables. Early Stopping was also utilized for both models.", "The table below shows the metrics for both models across each dataset. Unexpectedly, the cross validation MAE produced by the ordinal model was better than the regression model for all three dataset. The ordinal model also performed better on accuracy and the earth mover\u2019s distance metric.", "The ordinal and regression models have similar performance on the Boston Housing dataset. The ordinal model had the biggest improvement, over the regression model, on the Kinematics dataset.", "The plots below show the distributions of the predicted outputs for regression (right) and ordinal (left) models with the actual distribution. These plots show 1) the Boston Housing dataset 2) the Stock Dataset 3) and the Kinematics Dataset.", "The plots below show the variation in threshold parameters across each k-fold model. Interestingly, the variation in thresholds seems to inversely proportional to the improvement over the regression model.", "One potential implementation of an ordinal logistic regression model was designed and implemented in TensorFlow 2.0. The design used the classical proportional odds definition with a custom threshold parameterization. The threshold parameterization was constructed by inspecting and analyzing the gradient of the threshold parameter. The ordinal model model produced competitive results with a MAE regression model on the average cross-validation MAE, accuracy, and EMD metrics.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1afd0645e591&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rohankotwani.medium.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": ""}, {"url": "https://rohankotwani.medium.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Rohan Kotwani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7db535a7549e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&user=Rohan+Kotwani&userId=7db535a7549e&source=post_page-7db535a7549e----1afd0645e591---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/dmlc/xgboost/tree/master/demo/rank", "anchor_text": "ranking implementation"}, {"url": "https://en.wikipedia.org/wiki/Ordered_logit", "anchor_text": "Ordinal logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Peter_McCullagh", "anchor_text": "Peter McCullagh"}, {"url": "https://en.wikipedia.org/wiki/Cross_entropy", "anchor_text": "cross entropy loss function"}, {"url": "https://github.com/freedomtowin/ml-projects/blob/master/Deep-Ordinal-Logistic-Regression/deep-ordinal-regression-v2.ipynb", "anchor_text": "example notebook"}, {"url": "https://www.gagolewski.com/resources/data/ordinal-regression/", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Earth_mover%27s_distance", "anchor_text": "earth mover\u2019s distance"}, {"url": "https://github.com/fabianp/minirank/blob/master/minirank/logistic.py", "anchor_text": "Ordinal Logistic Regression \u2014 Optimized with Scipy Optimize"}, {"url": "https://online.stat.psu.edu/stat504/node/176/", "anchor_text": "PennState \u2014 The Proportional-Odds Cumulative Logit Model"}, {"url": "https://arxiv.org/pdf/1903.10012.pdf", "anchor_text": "A Mixture of Experts Model for Predicting Persistent Weather Patterns"}, {"url": "https://medium.com/tag/ordinal?source=post_page-----1afd0645e591---------------ordinal-----------------", "anchor_text": "Ordinal"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1afd0645e591---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----1afd0645e591---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&user=Rohan+Kotwani&userId=7db535a7549e&source=-----1afd0645e591---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&user=Rohan+Kotwani&userId=7db535a7549e&source=-----1afd0645e591---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1afd0645e591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1afd0645e591---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1afd0645e591--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1afd0645e591--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1afd0645e591--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1afd0645e591--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1afd0645e591--------------------------------", "anchor_text": ""}, {"url": "https://rohankotwani.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://rohankotwani.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rohan Kotwani"}, {"url": "https://rohankotwani.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "160 Followers"}, {"url": "https://www.linkedin.com/in/rkotwani/", "anchor_text": "https://www.linkedin.com/in/rkotwani/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7db535a7549e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&user=Rohan+Kotwani&userId=7db535a7549e&source=post_page-7db535a7549e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7719c6bbf2fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-ordinal-logistic-regression-1afd0645e591&newsletterV3=7db535a7549e&newsletterV3Id=7719c6bbf2fa&user=Rohan+Kotwani&userId=7db535a7549e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}