{"url": "https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7", "time": 1683004099.1488798, "path": "towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7/", "webpage": {"metadata": {"title": "Deep learning image enhancement insights on loss function engineering | by Christopher Thomas BSc Hons. MIAP | Towards Data Science", "h1": "Deep learning image enhancement insights on loss function engineering", "description": "These are a few insights on loss function engineering and deep neural network architectures that I\u2019ve gained from experimentation with using deep learning for various image processing techniques such\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Loss functions based on feature activation and style loss", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Super resolution", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/u-net-deep-learning-colourisation-of-greyscale-images-ee6c1c61aabe", "anchor_text": "Colourisation of black and white images", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Loss functions based on feature activation and style loss", "paragraph_index": 30}, {"url": "https://arxiv.org/abs/1704.03971", "anchor_text": "On the Effects of Batch and Weight Normalization in Generative Adversarial Networks", "paragraph_index": 41}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention Generative Adversarial Networks", "paragraph_index": 43}, {"url": "https://arxiv.org/abs/1802.05957", "anchor_text": "Spectral Normalization for Generative Adversarial Networks", "paragraph_index": 46}, {"url": "https://christiancosgrove.com/blog/2018/01/04/spectral-normalization-explained.html", "anchor_text": "article by Christian Cosgrove", "paragraph_index": 46}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention Generative Adversarial Networks", "paragraph_index": 47}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum", "paragraph_index": 73}], "all_paragraphs": ["These are a few insights on loss function engineering and deep neural network architectures that I\u2019ve gained from experimentation with using deep learning for various image processing techniques such as Super Resolution, Colourisation (inpainting colour into black and white images) and style transfer.", "This article extends from the loss functions described within my article Loss functions based on feature activation and style loss that I used within my research for deep learning based image enhancement for Super resolution and Colourisation of black and white images. These articles have proved so much more popular than I ever expected, especially with my article being at the top of Google\u2019s results when searching for \u2018Super resolution\u2019 at this time and for the last few months.", "My research since over the last year has found some interesting discoveries and insights shared within this article. Effective loss functions are important in training effective models, in some cases, they can be more important than the architecture of the model.", "Loss functions can, in theory, be patented as well. With the growth and rise of deep learning, it won\u2019t be surprising to see jobs like Loss function engineers becoming roles in the future.", "There are examples of generated images using these loss function techniques in the later part of this article for Super Resolution, Colourisation and Style Transfer.", "For image enhancement the loss function is intended to evaluate how far the predicted/generated output of the model is from the target/ground truth image, to train the model to minimise that loss.", "Traditionally and commonly in academia and research papers the pixel loss based on Mean Squared Error (MSE), Root Mean Squared Error (RMSE) or Peak signal-to-noise ratio (PSNR) is used to evaluate this.", "The pixel loss is essentially a measure of how far is the target image\u2019s pixels are from the predicted/generated image\u2019s pixels.", "From Wikipedia: PSNR is most easily defined via the mean squared error (MSE). Given a noise-free m\u00d7n monochrome image I and its noisy approximation K, MSE is defined as follows.", "The Mathematics here make this more complicated than it seems.", "This is compared across each of the three channels in an RGB image. MSE is used to compare how far away the target image\u2019s pixels from the predicted/generated image\u2019s pixels. The mean of each pixel\u2019s difference is taken and then squared.", "With L2 loss the goal is the least square deviations to minimise the sum of the squared differences between the ground truth and the predicted/generated image.", "If the square root of the mean square errors is taken, this allows a consideration of the distance between the generated image and the ground truth image to be evaluated.", "Peak signal-to-noise ratio definition (PSNR) is most commonly used as a quality estimation for the loss of quality through different codecs and image compression where the signal is the original image and the noise is error created by compressing the image.", "PSNR is very common for evaluating image enhancement techniques, such as Super resolution where the signal is the original/ground truth image and the noise is the error not recovered by the model.", "Although PSNR is a logarithm based metric, it is based on the MSE.", "Why Mean Squared Error (MSE) is not a good indication of quality in image enhancement.", "Using MSE or a metric based on MSE is likely to result in training finding a deep learning based blur filter, as that is likely to have the lowest loss and the easiest solution to converge to minimising the loss.", "A loss function that minimises MSE encourages finding pixel averages of plausible solutions that are typically overly smoothed and although minimising the loss, the generated images will have poor perceptual quality from a perspective of appealing to a human viewer.", "Consider an image with salt and pepper noise will result in a loss lower than many other possible generated images that from human perception would be closer to the ground truth.", "With L1 loss, the goal is the least absolute deviations (LAD) to minimise the sum of the absolute differences between the ground truth and the predicted/generated image.", "MAE reduces the average error, whereas MSE does not. Instead, MSE is very prone to being affected by outliers.", "For Image Enhancement, MAE will likely result in an image which appears to be a higher quality from a human viewer\u2019s perspective.", "If a similar equation to the above PSNR using MSE is altered to use MAE this in my experiments results in a more appealing enhanced image than PSNR, although not as effective as the following metrics.", "Structural Similarity Index (SSIM) is a perceptual metric. SSIM is based on visible structures in the image. The usage of SSIM for image enhancement evaluation came about as for some researchers PSNR is no longer regarded as a reliable indicator of image quality degradation. It is a perceptual metric that quantifies image quality degradation caused by processing.", "Again my experiments the use of SSIM as a metric in the loss function results in a more appealing enhanced image than PSNR", "If a difference fixed pre-trained model is used, the activations from it can be compared between the ground truth image and the predicted image at interesting layers by placing callbacks within the model. Interesting layers are those such as those immediately before average or max pooling layers where information is distilled.", "These interesting layers are the model\u2019s perception of features.", "The activations from these interesting layers can be compared for their Mean Absolute Error (MAE) then this can be a metric making up part of the loss function.", "If a generated image can have sharper features the remainder of the pixels are generally less important from a human viewer\u2019s perspective of image quality.", "This is described in more detail in my article Loss functions based on feature activation and style loss", "For super resolution I believe this is the most important metric for perceived image quality. However this type of loss metric is not popular in many research papers, as it is not as easy to compare against other research.", "Very rarely used is Gram Matrix loss which is essentially a form of evaluation of style loss.", "The gram matrix of a set of vectors is the matrix of all possible inner products of those vectors.", "The activations from each channel can be taken, each flattened out into a 1 dimensional vector, then the dot products of each of those vectors with each other is taken to form a gram matrix. The dot product gives an indication of how correlated each combination of the channels are. If a channel was indicating texture and another channel was indicating brightly colours then a high dot product would indicate cells with texture also tend to have bright colours.", "This has been used effectively to evaluate style loss. If two images have the same style then they will have similar gram matrices. The flattening out of the activations removes their spatial information from the comparison. This is one of the reason\u2019s gram matrix loss is so effective for style transfer.", "If a different fixed pre-trained model is used by the loss function, the activations from that pre-trained model can be compared between the ground truth image and the predicted image at interesting layers. Again, interesting layers are those such as those just before average or max pooling layers where information is distilled. Rather than looking at the feature/perceptual loss, the gram matrix of the activations can be compared for their Mean Absolute Error (MAE) then make up a metric as part of the loss function.", "Again, as with the feature loss mentioned previously, this type of loss metric is not popular in many research papers, as it is not as easy to compare against other research.", "If used with other loss metrics within the loss function, an appropriate multiplier is needed to factor this to a similar or appropriate scale.", "Further below the effectiveness of this loss metric in colourisation is shown to be very impressive.", "Batch Normalization is common practice for training Deep Neural Networks, including those for image generations including Generative Adversarial Networks (GANs).", "In the paper On the Effects of Batch and Weight Normalization in Generative Adversarial Networks (Sitao Xiang, Hao Li) it was found that Batch Normalisation could have negative effects on the quality of the trained model and the stability of the training process. A more recent technique, Weight Normalization, was found to improve the reconstruction, training speed and especially the stability of GANs.", "In my experiments I have found Weight Normalization to be effective in the case of training both models for both Super Resolution and Colourisation, not being limited to using GANs for training.", "In the paper Self-Attention Generative Adversarial Networks (Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena) the idea of self attention is implemented based on the attention mechanism used in Natural Language Processing for image generation", "Self attention allows details to be generated using cues from all feature locations. It helps ensure that distant portions of the image are consistent with each other, where as traditionally this is a failing of Convolutional Neural Networks (CNNs).", "In my experiments without GANs for deep learning Super Resolution and Colourisation I\u2019ve found Self Attention to improve the model\u2019s performance at generating images based on the loss criteria and from a human evaluation perspective. This was much more noticeable with Colourisation, with better consistency across similar features across the different portions of the image.", "In the paper Spectral Normalization for Generative Adversarial Networks (Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida) a novel weight normalisation technique called spectral normalization was proposed to stabilize the training of the discriminator. An article by Christian Cosgrove explains what Spectral Normalisation is, constraining the Lipschitz constant of the weights to control the gradients.", "In the paper Self-Attention Generative Adversarial Networks (Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena) Spectral Normalization was used in both the discriminator and the generator.", "In my more recent experiments (without GANs) for Deep Learning based Super Resolution I\u2019ve found Spectral Normalization to be effective at improving the model\u2019s performance at generating images over Weight Normalization and Batch Normalization \u2014 based on the loss criteria and from a human evaluation perspective.", "In my experiments (again without GANs) for Deep Learning based Colourisation (inpainting of colour) of black and white images, I found Spectral Normalisation was not as effective as Batch Normalization.", "The goal for the model was to generate a larger high fidelity image with twice the height and width with 4 times as many pixels as the input image. That is a difficult task for a model to be trained to perform.", "The model generating these images for Super Resolution has a ResNet34 based encoder and decoder in a U-Net architecture. This improved model over my past experiments was trained for super resolution using a loss function that combined SSIM (Structural Similarity Index), feature/perceptual loss from a fixed pretrained VGG16 model and gram matrix (style) loss from a a fixed pretrained VGG16 model, and a small proportion of the MAE (Mean Absolute Error) loss.", "This also used both Spectral Normalization and Self Attention within the training of the model.", "In the below example the low resolution input image is on the left, the generated prediction is in the middle and the ground truth/target image is on the right.", "If you look closely at the rocks and the arm on the surfboard in the top row, the features are brought into focus with clarity and sharp features. The same can be seen in the bottom row images \u2014 with the houses if you look closely at the roofs, windows and the textiles hanging from them. The lines of the fencing in the bottom centre of the image are clearly sharpened.", "The colourisation experiments here use a much smaller U-Net architecture than my previous experiments, based on a ResNet18 based encoder and decoder rather than using a ResNet34 based encoder and decoder.", "This improved model compared to my past experiments was trained for image colourisation using a loss function that combines SSIM (Structural Similarity Index), a small amount of feature/perceptual loss from a fixed pretrained VGG16 model and gram matrix (style) loss from a fixed pretrained VGG16 model, and a very small proportion of MAE (Mean Absolute Error) loss.", "This training of the model used Weight normalisation and Self Attention. Also, training at 16 bit floating point accuracy helped minimise the loss further. The combined or blended loss function combined with this allowed the model to minimise the loss for different factors, resulting in appealing results.", "In the below example the low resolution input image is on the left, the generated prediction is in the middle and the ground truth/target image is on the right.", "In the last example, the generated image of the bears is more visually appealing than the ground truth.", "This result from this model was surprisingly effective. The loss function used for training this model did not use MSE or MAE pixel loss. Neither did the loss function use PSNR, SSIM or feature loss. The loss function only compared the gram matrices of interesting features compared to an ImageNet pre-trained fixed model.", "The results, although not as good as a model trained with other losses, are quite remarkable in my opinion, having inpainted the colours purely from training to minimise the loss of style.", "In the below example the low resolution input image is on the left, the generated prediction is in the middle and the ground truth/target image is on the right.", "A proportion of the generated images, in my opinion, look more visually appealing than the ground truth.", "The goal for the model was to generate a larger high fidelity image with quadruple the height and width with 16 times as many pixels as the input image. This is a very difficult task for a model to perform and be trained to do.", "The training used similar loss functions metrics to the 2x Super Resolution experiments described earlier in this article.", "In the below image the low resolution input image is on the left, the generated prediction is in the middle and the ground truth/target image is on the right. Given the low quality of the input image the model is performing an impressive task to improve the quality of the image.", "In the top image the shrub, waves and rocks are noticeably sharper, as are the two people in the image. In the bottom image the building lines and roofs are again noticeably higher in quality.", "Some recent experiments I\u2019ve tried to evaluate if the above techniques can be applied to Style transfer. These experiments have given some interesting results, using the U-Net architecture, feature loss, and style loss metrics.", "Style transfer is an interesting, different and difficult problem to attempt to tackle as unlike other image enhancement training there is no singular ground truth/target that can be used during training to compare the generated model with.", "These experiments trained a model with a U-Net architecture based on a ResNet34 encoder and decoder. The encoder part of the network was based on a model pre-trained on ImageNet.", "The loss function used a combination of metrics of feature loss and gram matrix loss comparing the activations of interesting layers within a fixed pre-trained VGG-16 model for both the original and generated/stylised image.", "The identity/skip connections of the U-Net architectures I\u2019ve been experimenting with can allow for an unusual algorithm to be learned with a cluster of highly styled sections of the image and large portions of the image remaining not styled. This is what the model found minimised the error most effectively within the loss functions metrics. Careful weighting of the gram matrix/style loss compared to the feature/perceptual loss was needed to generate appealing results.", "These style transfer experiment examples were attempting to transfer the style of Vincent Van Gogh\u2019s Garden of the Asylum, one of my favourite paintings that I had the pleasure of seeing earlier in the year in Amsterdam.", "After some considerable time spent adjusting the loss function and fine tuning it, the trained model learnt to generate interesting images transferring the Van Gogh painting\u2019s style onto them.", "Another very interesting example from the same trained model was this generated image of a wolf that the model decided to give glowing eyes, I think this possibly sums up the sentiment in the original painting with its ominous people lurking in the trees. The glowing eyes are a consequence of the model\u2019s feature detection.", "These examples were attempting to transfer the style of Vincent Van Gogh\u2019s The Starry Night.", "The stylised generated images from the trained model have both the style of the painting and also the image, although the result appears to overuse certain styles. Given adjustment to the loss function, different more appealing results could I\u2019m sure be found. I suspect this style of image is a result of the U-Net\u2019s skip/identity connections.", "Again The stylised generated images from the trained model have both the style of the painting and also the image. The stylised effect is quite interesting and given more adjustment of the loss function and retraining more appealing results I\u2019m sure could have been produced.", "These experiments were partly due to the style loss portion of the loss function having too much weight. Also I believe the model was trained for too long and/or at too high of a learning rate.", "If you look carefully you can still see the outline of the butterfly in the image, although it and its features have been mostly lost. The left and top side have an abundance of style information.", "If you look very carefully you can still see the outline of a few of the features in the image, although hardly at all. Again, the left and top side have an abundance of style information generated.", "These are examples of how difficult it can be to train a model that is effective, especially when there is no singular target or ground truth to evaluate the model on for each training image.", "There are loss functions that can produce visually more appealing generated images compare to the metrics traditionally used in deep learning image enhancement research. Using and comparing activations from separate fixed pre-trained models works very effectively as part of the loss function\u2019s metrics.", "I hope to have more time to revisit this article to provide better presented image generation results, more examples and expanded explanations of the techniques and results outlined here. Also, when time permits I will put the best of these models into a production environment where they can be used.", "I also hope to find a publication or academic institution I could work with to potentially write and produce a paper detailing these experiments and results.", "Finally, I would like to thank Jeremy Howard and Jason Antic for the inspiration to attempt to train deep learning based models to perform these Super resolution and Colourisation tasks.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff57ccbb585d7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@christopher-thomas?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christopher-thomas?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Christopher Thomas BSc Hons. MIAP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F36b521478fa9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&user=Christopher+Thomas+BSc+Hons.+MIAP&userId=36b521478fa9&source=post_page-36b521478fa9----f57ccbb585d7---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Loss functions based on feature activation and style loss"}, {"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Super resolution"}, {"url": "https://towardsdatascience.com/u-net-deep-learning-colourisation-of-greyscale-images-ee6c1c61aabe", "anchor_text": "Colourisation of black and white images"}, {"url": "https://towardsdatascience.com/loss-functions-based-on-feature-activation-and-style-loss-2f0b72fd32a9", "anchor_text": "Loss functions based on feature activation and style loss"}, {"url": "https://arxiv.org/abs/1704.03971", "anchor_text": "On the Effects of Batch and Weight Normalization in Generative Adversarial Networks"}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention Generative Adversarial Networks"}, {"url": "https://arxiv.org/pdf/1805.08318.pdf", "anchor_text": "https://arxiv.org/pdf/1805.08318.pdf"}, {"url": "https://arxiv.org/abs/1802.05957", "anchor_text": "Spectral Normalization for Generative Adversarial Networks"}, {"url": "https://christiancosgrove.com/blog/2018/01/04/spectral-normalization-explained.html", "anchor_text": "article by Christian Cosgrove"}, {"url": "https://arxiv.org/abs/1805.08318", "anchor_text": "Self-Attention Generative Adversarial Networks"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://www.vangoghmuseum.nl/en/collection/s0196V1962", "anchor_text": "Garden of the Asylum"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----f57ccbb585d7---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f57ccbb585d7---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f57ccbb585d7---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/image-processing?source=post_page-----f57ccbb585d7---------------image_processing-----------------", "anchor_text": "Image Processing"}, {"url": "https://medium.com/tag/image-enhancement?source=post_page-----f57ccbb585d7---------------image_enhancement-----------------", "anchor_text": "Image Enhancement"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&user=Christopher+Thomas+BSc+Hons.+MIAP&userId=36b521478fa9&source=-----f57ccbb585d7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&user=Christopher+Thomas+BSc+Hons.+MIAP&userId=36b521478fa9&source=-----f57ccbb585d7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff57ccbb585d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f57ccbb585d7---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f57ccbb585d7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christopher-thomas?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christopher-thomas?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Christopher Thomas BSc Hons. MIAP"}, {"url": "https://medium.com/@christopher-thomas/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "569 Followers"}, {"url": "https://uk.linkedin.com/in/christhomasuk", "anchor_text": "https://uk.linkedin.com/in/christhomasuk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F36b521478fa9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&user=Christopher+Thomas+BSc+Hons.+MIAP&userId=36b521478fa9&source=post_page-36b521478fa9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd1857471e6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7&newsletterV3=36b521478fa9&newsletterV3Id=d1857471e6d&user=Christopher+Thomas+BSc+Hons.+MIAP&userId=36b521478fa9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}