{"url": "https://towardsdatascience.com/create-a-gif-with-3-million-points-using-dask-caf7dcd0667e", "time": 1683008310.767615, "path": "towardsdatascience.com/create-a-gif-with-3-million-points-using-dask-caf7dcd0667e/", "webpage": {"metadata": {"title": "3.6 million points, 1 GIF \u2014 Visualise big data in Python | by LeAnne Chan | Towards Data Science", "h1": "3.6 million points, 1 GIF \u2014 Visualise big data in Python", "description": "A detailed step-by-step guide to create a GIF in Python with Big Data using the Dask and Datashader libraries, with an introduction to geospatial data."}, "outgoing_paragraph_urls": [{"url": "https://data.cityofnewyork.us/Housing-Development/DOB-Permit-Issuance/ipu4-2q9a", "anchor_text": "New York City construction permits", "paragraph_index": 0}, {"url": "https://leannechan.github.io/Gentrification-Trends-In-NYC/", "anchor_text": "project", "paragraph_index": 0}, {"url": "https://github.com/LeanneChan/create-a-GIF", "anchor_text": "https://github.com/LeanneChan/create-a-GIF", "paragraph_index": 1}, {"url": "https://medium.com/swlh/installing-jupyter-notebook-and-using-your-own-environment-on-mac-fa41efd4639d", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://datashader.org/", "anchor_text": "Datashader", "paragraph_index": 2}, {"url": "https://docs.dask.org/en/latest/", "anchor_text": "Dask", "paragraph_index": 2}, {"url": "https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/", "anchor_text": "Coordinate Reference System (CRS)", "paragraph_index": 12}, {"url": "https://docs.dask.org/en/latest/dataframe-best-practices.html?highlight=to%20pandas#reduce-and-then-use-pandas", "anchor_text": "Dask best practices", "paragraph_index": 14}, {"url": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm", "anchor_text": "shapefile", "paragraph_index": 18}, {"url": "https://medium.com/@james.a.bednar", "anchor_text": "@james.a.bednar", "paragraph_index": 39}], "all_paragraphs": ["Hello! This article will walk you through step-by-step to creating a GIF to visualise big data in Python. GIFs are a great way to show changes over time, especially with large datasets. This article uses the New York City construction permits from the past 30 years, published by the Department of Buildings, taken from NYC Open Data. This GIF was created as part of a project I did with my good friend Yap Yun Qi on Gentrification in NYC in Fall 2019.", "The IPython Notebook and environment file can be found here: https://github.com/LeanneChan/create-a-GIF. To download the notebook and open it with Jupyter Notebook, you can follow my other article here. You may also run the code in GoogleColab, but based on past experiences, it takes extra steps to load the geopandas library in GoogleColab.", "A GIF is a collection of images stitched together. Hence our approach to creating the GIF is to create separate plots for each different time frame (years in this case), then stitch them together. If our dataset was small enough, we could use matplotlib to plot the points. But, with larger datasets, we will use Datashader, a library for visualising large datasets. To work with the large dataset, we will use Dask, a library for flexible parallel computing in Python.", "Datashader is part of the HoloViz family (other packages include HoloViews, hvPlot), and is used to create representations of large datasets. It is able to visualise large dataset by rasterising (breaking a plot into pixels) the plotting area and aggregating the value of the points that fall in each pixel. The pixels are then shaded according to this aggregated value.", "Dask allows us to store data that is large than the memory on our laptops. Furthermore, Dask is not too intimidating to use as Dask DataFrames mirror Pandas and Dask Arrays mirror NumPy. Dask splits up the partitions that are Pandas DataFrame objects, and loads the data into our computer\u2019s memory only when necessary.", "dask, datashader, colorcet, matplotlib, numpy, imageio, geopandas", "The dataset has shape (3616003, 60), meaning there are 60 columns/features and 3.6 million rows/points. This is a geospatial dataset and visualisation, so each row represents a point in NYC, which we want to plot. Since there are 3.6M rows, we will need the dask.dataframe library. import is used to load in libraries into your current workspace/session, which allows us to use the methods of the library.", "If you\u2019ve used pandas before, the syntax is really similar, calling read_csv to read in the dataframe, which I downloaded from NYC open data and saved in the same folder as my Jupyter Notebook as \u2018DOB_permit_Issuance.csv\u2019.", "However, if you get the following error, you will also need to address columns with mixed types.", "In this example, I had to specify the dtype for certain columns as they had mixed types, and this threw an error when trying to call the dataframe. The dtype specifies the format of data in the column, so there is an error when pandas/dask had to guess too many column types. I also selected only three columns using usecols rather than working with 60 columns, to make future processes faster. These columns indicated the date the permit was filed (to later extract the year from), and the lat/lng of that permit. Another way around the \u2018mixed dtypes\u2019 problem is to just select only useful columns which, fingers-crossed, do not have mixed dtypes. On hindsight, this is something I could have done instead to save myself much time!", "Calling permits.head() show the first 5 rows of our dataframe. (Fyi, calling dataframe.head(x) where x is any integer , will print out the first x rows of your dataframe!)", "First, we want to extract the year of each permit. I used the to_datetime(), a pandas function, to convert the \u2018filing date\u2019 column to date-time object. Since the column is now a datetime object, I can use another the function .dt.strftime(\u201c%Y\u201d) to access the years of each point to create a new column.", "Secondly, we need to decide on a standardised projection for our coordinates. This is a very important point in geospatial data science, because if your basemap is in a different projection and coordinate system from your points, chaos will ensue. A Coordinate Reference System (CRS), is a code (epsg code) that refers to how spatial data (inherently round because flat earth is a hoax) is projected onto a flat 2D screen. It also specifies the units of measurement, which are usually feet, meters or decimal degrees.", "For this example, I used a Web-Mercator projection (epsg: 3857), a meter based projection. Though not done in this examlpe, this projection is especially useful if you want to use basemaps from OpenStreetMap or GoogleMaps, which are in epsg:3857 projection. Datashader has a useful function lnglat_to_meters that converts longitudes and latitudes (epsg:4326, decimal degrees) to web-mercator (meters). It is super important to ensure that you know which is your lat and lng after conversion, and that you code them in the correct order required in each function.", "We follow some Dask best practices, and set the index to be the column we want to subset by, the year. Even though using set_index takes about 8 minutes, this makes subsetting later a looot faster (0.001 seconds!).", "Partitioning: Dask operates by splitting the large dataset into partitions. One of the best practices mentioned is to set your partitions by the subsets you are interested in (years in our example).", "Compute: .compute() executes all the above processes on our Dask dataframe and returns an ordinary dataframe. Doing so will significantly increase the time needed to create our GIF. If compute() is not called here, all the above data wrangling will be recomputed on each call of the dataframe, taking each frame 10minutes. That\u2019s 300 minutes for 30 frames!", "This takes 9 minutes, but as mentioned above, saves us much more time later on.", "From the example GIF at the start, the plots included an outline of New York City\u2019s boroughs \u2014 Manhattan, Brooklyn, Queens, The Bronx and Staten Island. I downloaded the shapefile \u2018borough boundaries\u2019 from NYC OpenData. We will need the geopandas library to read in the shapefile. Don\u2019t forget to set the CRS to the same as what you are using for data points in step 2.", "As we wish for the plot to fit perfectly around the city as well, we need to set the range of x and y coordinates on the plot to be the NYC limits, which I got from dropping points in GoogleMaps. Once again, not forgetting to convert the coordinates to epsg: 3857. As for plot dimensions, I would suggest playing around with those figures and plotting the canvas (see next section) to see what works best for you.", "At this point, we have all the pieces needed to make the GIF, we just need to put them together! First, we need to import a few libraries to help us with plotting. As mentioned in \u2018Approach\u2019, we will be using datashader to aggregate the points before plotting. We don\u2019t just want points on a map, but for the map to show us where there is a higher frequency of points. Datashader will help us with colouring the points based on this.", "Let\u2019s create a helper function to plot the construction permits that we can use later on in plotting different points for each year.", "The function takes in the parameters: df \u2014 data,x_range , y_range\u2014 the range of x/y coordinates on the base (see step 3), w/h \u2014 width and heigh of plot (see step 3), cmap \u2014 the colour map used to colour the points.", "The function uses datashader\u2019s canvas function to represent the space in which we want to plot the points. First, we create the canvas, specifying the dimensions. Next, we feed in the data using cvs.points() which takes in the data, \u2018x\u2019 \u2014 the converted longitude, and \u2018y\u2019 \u2014 the converted latitude. cvsis the canvas object created in the first line.", "Aggregating dataAnother parameter you can specify in cvs.points() is agg which will inform datashader how to aggregate your data. Suppose you have a third column called \u2018z\u2019, if you wanted to plot the average of z in that aggregated space, you can include agg=ds.mean('z'). If not specified, the default of aggis \u2018count\u2019, which is what we want in this example, thus it is left unspecified.", "Finally, the datashader.transfer_functions.shade specifies how to colour each pixel. The colormap we use is fire, from the colorcet library. how specifies the scale of the colormap. Some options are: \u2018eq_hist\u2019 [default], \u2018cbrt\u2019 (cube root), \u2018log\u2019 (logarithmic), and \u2018linear\u2019. For more information, see the datashader documentation linked at the end. Then we specify the background to be black, and convert the image to the Python Imaging Library (PIL) format.", "We are almost done! We don\u2019t want to be manually creating new images for each time frame, so we package this in another function. For this function, we will need matplotlib\u2019s pyplot to set the axes, and numpy to transform the figure values into range 0\u2013255 (dtype=uint8) to create the final image.", "The function takes in the parameters: fig\u2014 from pyplot,all_data \u2014 our dataframe,year \u2014 the specific year to be plotted,city_limits \u2014 the shapefile of boundaries to be plotted,x_range,y_range \u2014 the range of x/y coordinates on the base (see step 3).", "Using loc to subset our data takes just 0.001 seconds.", "The function also specifies text to be shown on each frame, done so using the matplotlib function ax.text() where ax refers to the image\u2019s axes.", "We\u2019re right at the end, we just need to use theimageio library to convert the array of images into a gif. To create the GIF, we create images using the function in step 5, append them to an array, then stitch them into a GIF using image.io.", "Run the following block code to create the full GIF! If you\u2019re not satisfied with the design, change the parameters (e.g. location/colour/size of labels) in the function in step 5. (see matplotlib documentation)Note: the \u2018years\u2019 array was created in step 3 during the partitioning.", "This block of code that creates 30 frames took just 9.56463 seconds to run!", "That\u2019s it! Thanks for following this and let me know if I can clarify anything!", "Past edits and additional information about time complexity30 May 2020 \u2014 Changed process to make subsetting faster and called .compute() to reduce Dask operations. (Current article reflects correct code.)", "In the initial process (code no longer shown), I skipped step 3 and subsetted the dataframe inside the plot_by_year function. As a result, printing the frame for each year took about 10 minutes. This is also because the data wrangling on the dataset was repeated each time the dataframe was called because of the nature of Dask. My hunch is processes of converting the coordinates into mercator, transforming the \u2018Filing Date\u2019 column and subsetting the dataframe had to be done again in each call of the plot_by_year function. Calling compute() on the Dask dataframe resolved this issue of repetition.", "To check the time taken, I used the time library.", "Time taken to subset: Old method", "Time taken to subset: New method", "This new process is such a huge improvement from my original code that took me a couple of hours to create the GIF! Thank you to @james.a.bednar for the little extra push to improve the original code!", "Acknowledgements: Nicholas Hand, MUSA 620 Professor, who taught me the bulk of my python data visualisation skills!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Passionate about the elegance of mathematics, infiniteness of data science, and practicality of economics. From Singapore \ud83c\uddf8\ud83c\uddec"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcaf7dcd0667e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@leannechannie?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leannechannie?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "LeAnne Chan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3984a193c444&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&user=LeAnne+Chan&userId=3984a193c444&source=post_page-3984a193c444----caf7dcd0667e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://data.cityofnewyork.us/Housing-Development/DOB-Permit-Issuance/ipu4-2q9a", "anchor_text": "New York City construction permits"}, {"url": "https://leannechan.github.io/Gentrification-Trends-In-NYC/", "anchor_text": "project"}, {"url": "https://github.com/LeanneChan/create-a-GIF", "anchor_text": "https://github.com/LeanneChan/create-a-GIF"}, {"url": "https://medium.com/swlh/installing-jupyter-notebook-and-using-your-own-environment-on-mac-fa41efd4639d", "anchor_text": "here"}, {"url": "https://datashader.org/", "anchor_text": "Datashader"}, {"url": "https://docs.dask.org/en/latest/", "anchor_text": "Dask"}, {"url": "https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/", "anchor_text": "Coordinate Reference System (CRS)"}, {"url": "https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/", "anchor_text": "https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/"}, {"url": "https://docs.dask.org/en/latest/dataframe-best-practices.html?highlight=to%20pandas#reduce-and-then-use-pandas", "anchor_text": "Dask best practices"}, {"url": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm", "anchor_text": "shapefile"}, {"url": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm", "anchor_text": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm"}, {"url": "https://medium.com/@james.a.bednar", "anchor_text": "@james.a.bednar"}, {"url": "https://data.cityofnewyork.us/Housing-Development/DOB-Permit-Issuance/ipu4-2q9a", "anchor_text": "https://data.cityofnewyork.us/Housing-Development/DOB-Permit-Issuance/ipu4-2q9a"}, {"url": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm", "anchor_text": "https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm"}, {"url": "https://readthedocs.org/projects/datashader/downloads/pdf/stable/", "anchor_text": "https://readthedocs.org/projects/datashader/downloads/pdf/stable/"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----caf7dcd0667e---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/big-data?source=post_page-----caf7dcd0667e---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----caf7dcd0667e---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----caf7dcd0667e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/geospatial?source=post_page-----caf7dcd0667e---------------geospatial-----------------", "anchor_text": "Geospatial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&user=LeAnne+Chan&userId=3984a193c444&source=-----caf7dcd0667e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&user=LeAnne+Chan&userId=3984a193c444&source=-----caf7dcd0667e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcaf7dcd0667e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----caf7dcd0667e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----caf7dcd0667e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leannechannie?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leannechannie?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "LeAnne Chan"}, {"url": "https://medium.com/@leannechannie/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "199 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3984a193c444&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&user=LeAnne+Chan&userId=3984a193c444&source=post_page-3984a193c444--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff7a40a3ed4e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreate-a-gif-with-3-million-points-using-dask-caf7dcd0667e&newsletterV3=3984a193c444&newsletterV3Id=f7a40a3ed4e0&user=LeAnne+Chan&userId=3984a193c444&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}