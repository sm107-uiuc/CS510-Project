{"url": "https://towardsdatascience.com/how-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252", "time": 1683000200.89029, "path": "towardsdatascience.com/how-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252/", "webpage": {"metadata": {"title": "How to code Gaussian Mixture Models from scratch in Python | by Thalles Silva | Towards Data Science", "h1": "How to code Gaussian Mixture Models from scratch in Python", "description": "GMMs and Maximum Likelihood Optimization Using NumPy"}, "outgoing_paragraph_urls": [{"url": "https://colab.research.google.com/drive/1PChVghOtJSjWwCYVoevnLGXjnbQNvFOY", "anchor_text": "jupyter notebook", "paragraph_index": 9}, {"url": "https://colab.research.google.com/drive/1Eb-G95_dd3XJ-0hm2qDqdtqMugLkSYE8", "anchor_text": "jupyter notebook for 2-D data here", "paragraph_index": 24}, {"url": "https://sthalles.github.io/", "anchor_text": "https://sthalles.github.io/", "paragraph_index": 28}], "all_paragraphs": ["In the realm of unsupervised learning algorithms, Gaussian Mixture Models or GMMs are special citizens. GMMs are based on the assumption that all data points come from a fine mixture of Gaussian distributions with unknown parameters. They are parametric generative models that attempt to learn the true data distribution. Hence, once we learn the Gaussian parameters, we can generate data from the same distribution as the source.", "We can think of GMMs as the soft generalization of the K-Means clustering algorithm. Like K-Means, GMMs also demand the number of clusters K as an input to the learning algorithm. However, there is a key difference between the two. K-Means can only learn clusters with a circular form. GMMs, on the other hand, can learn clusters with any elliptical shape.", "Also, K-Means only allows for an observation to belong to one, and only one cluster. Differently, GMMs give probabilities that relate each example with a given cluster.", "In other words, GMMs allow for an observation to belong to more than one cluster \u2014 with a level of uncertainty.", "For each observation, GMMs learn the probabilities of that example to belong to each cluster k.", "In general, GMMs try to learn each cluster as a different Gaussian distribution. It assumes the data is generated from a limited mixture of Gaussians.", "Assuming one-dimensional data and the number of clusters K equals 3, GMMs attempt to learn 9 parameters.", "Here, each cluster is represented by an individual Gaussian distribution (for this example, 3 in total). For each Gaussian, it learns one mean and one variance parameters from data. The 3 scaling parameters, 1 for each Gaussian, are only used for density estimation.", "To learn such parameters, GMMs use the expectation-maximization (EM) algorithm to optimize the maximum likelihood. In the process, GMM uses Bayes Theorem to calculate the probability of a given observation x\u1d62 to belong to each clusters k, for k = 1,2,\u2026, K.", "Let\u2019s dive into an example. For the sake of simplicity, let\u2019s consider a synthesized 1-dimensional data. But, as we are going to see later, the algorithm is easily expanded to high dimensional data with D > 1. You can follow along using this jupyter notebook.", "To build a toy dataset, we start by sampling points from K different Gaussian distributions. Each one (with its own mean and variance) represents a different cluster in our synthesized data. To make things clearer, let\u2019s use K equals 2.", "Below, you can see the resulting synthesized data. We are going to use it as training data to learn these clusters (from data) using GMMs. Note that some of the values do overlap at some point.", "We can think of GMMs as a weighted sum of Gaussian distributions. The number of clusters K defines the number of Gaussians we want to fit.", "As we said, the number of clusters needs to be defined beforehand. For simplicity, let\u2019s assume we know the number of clusters and define K as 2. In this situation, GMMs will try to learn 2 Gaussian distributions. For 1-dim data, we need to learn a mean and a variance parameter for each Gaussian.", "Before we start running EM, we need to give initial values for the learnable parameters. We can guess the values for the means and variances, and initialize the weight parameters as 1/k.", "Then, we can start maximum likelihood optimization using the EM algorithm. EM can be simplified in 2 phases: The E (expectation) and M (maximization) steps.", "In the E step, we calculate the likelihood of each observation x\u1d62 using the estimated parameters.", "For each cluster k = 1,2,3,\u2026,K, we calculate the probability density (pdf) of our data using the estimated values for the mean and variance. At this point, these values are mere random guesses.", "Then, we can calculate the likelihood of a given example x\u1d62 to belong to the k\u1d57\u02b0 cluster.", "Using Bayes Theorem, we get the posterior probability of the kth Gaussian to explain the data. That is the likelihood that the observation x\u1d62 was generated by k\u1d57\u02b0 Gaussian. Note that the parameters \u03a6 act as our prior beliefs that an example was drawn from one of the Gaussians we are modeling. Since we do not have any additional information to favor a Gaussian over the other, we start by guessing an equal probability that an example would come from each Gaussian. However, at each iteration, we refine our priors until convergence.", "Then, in the maximization, or M step, we re-estimate our learning parameters as follows.", "Here, for each cluster, we update the mean (\u03bc\u2096), variance (\u03c3\u2082\u00b2), and the scaling parameters \u03a6\u2096. To update the mean, note that we weight each observation using the conditional probabilities b\u2096.", "We may repeat these steps until converge. That could be up to a point where parameters\u2019 updates are smaller than a given tolerance threshold. At each iteration, we update our parameters so that it resembles the true data distribution.", "For high-dimensional data (D>1), only a few things change. Instead of estimating the mean and variance for each Gaussian, now we estimate the mean and the covariance. The covariance is a squared matrix of shape (D, D) \u2014 where D represents the data dimensionality. Below, I show a different example where a 2-D dataset is used to fit a different number of mixture of Gaussians.", "Check the jupyter notebook for 2-D data here.", "Note that the synthesized dataset above was drawn from 4 different gaussian distributions. Nevertheless, GMMs make a good case for two, three, and four different clusters.", "That is it for Gaussian Mixture Models. These are some key points to take from this piece.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Computer Vision & Deep Learning. Personal blog: https://sthalles.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9e7975df5252&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e7975df5252--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@thalles.silva?source=post_page-----9e7975df5252--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Thalles Silva"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8db098eb9ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&user=Thalles+Silva&userId=f8db098eb9ca&source=post_page-f8db098eb9ca----9e7975df5252---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://colab.research.google.com/drive/1PChVghOtJSjWwCYVoevnLGXjnbQNvFOY", "anchor_text": "jupyter notebook"}, {"url": "https://colab.research.google.com/drive/1Eb-G95_dd3XJ-0hm2qDqdtqMugLkSYE8", "anchor_text": "jupyter notebook for 2-D data here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9e7975df5252---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----9e7975df5252---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9e7975df5252---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----9e7975df5252---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----9e7975df5252---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&user=Thalles+Silva&userId=f8db098eb9ca&source=-----9e7975df5252---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&user=Thalles+Silva&userId=f8db098eb9ca&source=-----9e7975df5252---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9e7975df5252&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9e7975df5252---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9e7975df5252--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9e7975df5252--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9e7975df5252--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9e7975df5252--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9e7975df5252--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Thalles Silva"}, {"url": "https://medium.com/@thalles.silva/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://sthalles.github.io/", "anchor_text": "https://sthalles.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8db098eb9ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&user=Thalles+Silva&userId=f8db098eb9ca&source=post_page-f8db098eb9ca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea9a35433442&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-code-gaussian-mixture-models-from-scratch-in-python-9e7975df5252&newsletterV3=f8db098eb9ca&newsletterV3Id=ea9a35433442&user=Thalles+Silva&userId=f8db098eb9ca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}