{"url": "https://towardsdatascience.com/i-am-so-done-with-cuda-out-of-memory-c62f42947dca", "time": 1683017819.137907, "path": "towardsdatascience.com/i-am-so-done-with-cuda-out-of-memory-c62f42947dca/", "webpage": {"metadata": {"title": "Resolving CUDA Being Out of Memory With Gradient Accumulation and AMP | by Rishik C. Mourya | Towards Data Science", "h1": "Resolving CUDA Being Out of Memory With Gradient Accumulation and AMP", "description": "Do you remember that delightful time, when you were so happily preprocessing your data, building your model with so many efforts, and then right at the moment when you expect to enjoy that soda while\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/NVIDIA/DeepLearningExamples", "anchor_text": "Nvidia\u2019s official benchmarks", "paragraph_index": 17}, {"url": "https://arxiv.org/pdf/2008.00177.pdf", "anchor_text": "Multi-Node BERT-Pretraining", "paragraph_index": 20}, {"url": "https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/?ref=Welcome.AI", "anchor_text": "article", "paragraph_index": 22}, {"url": "http://Nevronas.in", "anchor_text": "Nevronas.in", "paragraph_index": 31}, {"url": "http://Skylarklabs.ai", "anchor_text": "Skylarklabs.ai", "paragraph_index": 31}], "all_paragraphs": ["Do you remember that delightful time, when you were so happily preprocessing your data, building your model with so many efforts, and then right at the moment when you expect to enjoy that soda while your model trains, an error pops up, telling you to get your butt down here again because you don\u2019t have enough CUDA memory to enjoy? Well, I certainly can\u2019t forget that, and this seriously is a really common issue among ML engineers. Alright then, let\u2019s figure out if there\u2019s a solution to our soda problem.", "There\u2019s nothing to explain actually, I mean the error message is already self-explanatory, but still, let\u2019s have a quick brush up. The issue is, to train the model using GPU, you need the error between the labels and predictions, and for the error, you need to make predictions, and for making the predictions, you need both the model and the input data to be allocated in the CUDA memory. So when you try to execute the training, and you don\u2019t have enough free CUDA memory available, then the framework you\u2019re using throws this out of memory error.", "So keeping that in mind, here are the common reasons why this error is so prone to occur:", "Now the issue is not that you can\u2019t solve the problems above, I mean switching to a smaller model might take not more than 20 to 30 minutes, and decreasing the batch size is, of course, a piece of cake, and such solutions do solve issue for most of the cases, but at the cost of time and model\u2019s accuracy.", "For instance, if you set your batch size too low, then it might just take forever to make the loss converge because your model would be just oscillating too much, not only that, some model architectures don\u2019t even perform well when batch size is not up to the requirements. And, if you decide to switch to a smaller model or reduce the dimensions of the input data, then you might just lose quite a lot of accuracy for obvious reasons.", "So as you can see solving this error is not that hard to tackle, but its the cost of the solution which is too high for a good ML engineer.", "Alright, so now it is pretty obvious that just one solution wouldn\u2019t be enough to solve all of the above problems, in fact, a limited solution would only create even more problems. So after quite a lot of headaches I\u2019ve finally came to these solutions, when applied together, do wonders :)", "Let\u2019s have a look at them one by one.", "This solution has been a de facto for solving out of memory issues. In fact, this is the very only reason why this technique exists in the first place. This technique solves the issue of model oscillation when the batch size is set too low. The nub here is actually very easy to understand.", "The reason why model oscillates when batch size is too low is that the gradients are averages for less number of data instances. So after each training iteration (training a single batch), the model gets too specific updates, and thus parameters are changed too much towards a single direction. And reducing the learning rate would not be helpful here, in fact, it would just make the training even slower and just horrible because not only the updates are less generalized but with low magnitude too.", "So the idea behind gradient accumulation is, keep adding gradients of the parameters for n number of batches, where batch size is small, and then after n batch iterations, apply the updates using the average of all those gradients accumulated over n iterations, that\u2019s why its called gradient accumulation.", "Below is the sample procedure for Pytorch implementation.", "In the above example, note that we are dividing the loss by gradient_accumulations for keeping the scale of gradients same as if were training with 64 batch size. For an effective batch size of 64, ideally, we want to average over 64 gradients to apply the updates, so if we don\u2019t divide by gradient_accumulations then we would be applying updates using an average of gradients over the batch size of 4 only, because we just kept adding the gradients for gradient_accumulations number of batch iterations before calling optimizer.step().", "So, this technique effectively solves the problem of limited gradient averaging. Now mathematically we are totally good here, but the problem is the training time. As our batch size is really low, so definitely we are doing drastically less parallel computations as compared to high batch size.", "And if you are accumulating the gradients for k batch iterations then it would approximately take k times the time for training with the batch size that you actually want. Let\u2019s fix this.", "Almost all of the deep learning frameworks operate on 32-bit floating-point or float32 data type by default. Though there are many operations the does not need to be this much precisely accurate.", "3 years ago Nvidia researchers created a new methodology, that in a nutshell combines single-precision with the half-precision floating-point for training deep learning models, that achieves the same level of accuracy as float32.", "It enables automatic conversion of certain GPU operations from float32 precision to mixed-precision, while improving performance and maintaining same accuracy. For an exact performance and accuracy comparisons make sure to check out Nvidia\u2019s official benchmarks.", "Main plus points of this method are:", "So now you can see why I decided to combine AMP with gradient accumulation. Anyways, below is its Pytorch implementation.", "I\u2019ll let this paper Multi-Node BERT-Pretraining explain this to you", "Typically in a computation graph, not all FP16 operators are numerically safe. This means operators that are considered numerically dangerous will have its calculation in full precision. For example, a plus operator is marked as safe while a 5 power or a log operator is considered numerically dangerous in half precision. Automated mixed precision handles the categorization of the numerical safety level through the rewriting of computation graph \u2014 Authors", "For more info regarding different precisions, make sure to check out this brief article by non other than Nvidia.", "So now, since we are set to use both of the techniques I\u2019ve explained above, let\u2019s put the together to come up with an awesome combo.", "Yuppah, that\u2019s pretty much it :)", "Depending on the model and input sizes, and how much gradients you are accumulating, you could easily get somewhere around 1.2x to 1.5x (and sometimes even more) speed ups with AMP, and of course your loss would converge thanks to gradient accumulation.", "Now for 95% of the times, you wouldn\u2019t need to use techniques that I\u2019m sharing here because AMP and gradient accumulation applied together works juuuuust fine. Though recently I\u2019ve started working for a startup, where we are trying to detect violence in CCTV footages. This task basically is a video classification, where in a batch we would have to deal with one more dimension as compared to image classification, making total 5 dimensions of a single batch. So this definitely means massive input size.", "I wanted to further speed up the training, cuz we had over 16GB of training data so speeding the things was definitely a requirement.", "Yes, these ideas are not necessarily for solving the out of CUDA memory issue, but while applying these techniques, there was a well noticeable amount decrease in time for training, and helped me to get ahead by 3 training epochs where each epoch was approximately taking over 25 minutes.", "Okie then, I hope after reading this article you\u2019d be able to tackle out this really common issue and yeah, enjoy the soda.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "2nd yr Undergrad | ML Engineer at Nevronas.in | Working at Skylarklabs.ai | Web Developer | When you know nothing matters, the universe is yours \u2014 Rick Sanchez"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc62f42947dca&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://brainbust.medium.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": ""}, {"url": "https://brainbust.medium.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Rishik C. Mourya"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F26343475a692&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&user=Rishik+C.+Mourya&userId=26343475a692&source=post_page-26343475a692----c62f42947dca---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/making-sense-of-big-data", "anchor_text": "Making Sense of Big Data"}, {"url": "https://unsplash.com/@ernest_brillo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Ernest Brillo"}, {"url": "https://unsplash.com/s/photos/soda-can?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/NVIDIA/DeepLearningExamples", "anchor_text": "Nvidia\u2019s official benchmarks"}, {"url": "https://arxiv.org/pdf/2008.00177.pdf", "anchor_text": "Multi-Node BERT-Pretraining"}, {"url": "https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/?ref=Welcome.AI", "anchor_text": "article"}, {"url": "https://medium.com/tag/optimization?source=post_page-----c62f42947dca---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----c62f42947dca---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/making-sense-of-big-data?source=post_page-----c62f42947dca---------------making_sense_of_big_data-----------------", "anchor_text": "Making Sense Of Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&user=Rishik+C.+Mourya&userId=26343475a692&source=-----c62f42947dca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&user=Rishik+C.+Mourya&userId=26343475a692&source=-----c62f42947dca---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc62f42947dca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c62f42947dca---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c62f42947dca--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c62f42947dca--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c62f42947dca--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c62f42947dca--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c62f42947dca--------------------------------", "anchor_text": ""}, {"url": "https://brainbust.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://brainbust.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rishik C. Mourya"}, {"url": "https://brainbust.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "49 Followers"}, {"url": "http://Nevronas.in", "anchor_text": "Nevronas.in"}, {"url": "http://Skylarklabs.ai", "anchor_text": "Skylarklabs.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F26343475a692&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&user=Rishik+C.+Mourya&userId=26343475a692&source=post_page-26343475a692--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4a68e90b2db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-am-so-done-with-cuda-out-of-memory-c62f42947dca&newsletterV3=26343475a692&newsletterV3Id=4a68e90b2db&user=Rishik+C.+Mourya&userId=26343475a692&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}