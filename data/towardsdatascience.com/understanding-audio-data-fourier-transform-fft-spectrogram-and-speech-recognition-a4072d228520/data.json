{"url": "https://towardsdatascience.com/understanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520", "time": 1683003046.783983, "path": "towardsdatascience.com/understanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520/", "webpage": {"metadata": {"title": "Understanding Audio data, Fourier Transform, FFT and Spectrogram features for a Speech Recognition System | by Kartik Chaudhary | Towards Data Science", "h1": "Understanding Audio data, Fourier Transform, FFT and Spectrogram features for a Speech Recognition System", "description": "A huge amount of audio data is being generated every day in almost every organization. Audio data yields substantial strategic insights when it is easily accessible to the data scientists for\u2026"}, "outgoing_paragraph_urls": [{"url": "https://dropsofai.com/sound-wave-basics-every-data-scientist-must-know-before-starting-analysis-on-audio-data/", "anchor_text": "click here", "paragraph_index": 2}, {"url": "https://librosa.github.io/librosa/", "anchor_text": "LibROSA", "paragraph_index": 4}, {"url": "https://librosa.github.io/librosa/install.html", "anchor_text": "install this library", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Audio_codec", "anchor_text": "audio codecs", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/WAV", "anchor_text": ".wav(lossless)", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Sampling_(signal_processing)", "anchor_text": "sampling rate", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Fourier_transform", "anchor_text": "Fourier Transform", "paragraph_index": 15}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html", "anchor_text": "scipy", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem", "anchor_text": "Nyquist sampling theorem", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Spectrogram", "anchor_text": "Spectrograms", "paragraph_index": 32}, {"url": "https://www.tek.com/blog/window-functions-spectrum-analyzers", "anchor_text": "click here", "paragraph_index": 37}, {"url": "https://scholar.google.com/scholar?hl=en&as_sdt=0,24&cluster=9680825736551595294", "anchor_text": "Google Scholar Link", "paragraph_index": 47}, {"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com", "paragraph_index": 50}], "all_paragraphs": ["A huge amount of audio data is being generated every day in almost every organization. Audio data yields substantial strategic insights when it is easily accessible to the data scientists for fuelling AI engines and analytics. Organizations that have already realized the power and importance of the information coming from the audio data are leveraging the AI (Artificial Intelligence) transcribed conversations to improve their staff training, customer services and enhancing overall customer experience.", "On the other hand, there are organizations that are not able to put their audio data to better use because of the following barriers \u2014 1. They are not capturing it. 2. The quality of the data is bad. These barriers can limit the potential of Machine Learning solutions (AI engines) they are going to implement. It is really important to capture all possible data and also in good quality.", "This article provides a step-wise guide to start with audio data processing. Though this will help you get started with basic analysis, It is never a bad idea to get a basic understanding of the sound waves and basic signal processing techniques before jumping into this field. You can click here and check out my article on sound waves. That article provides a basic understanding of sound waves and also explains a bit about different audio codecs.", "Before going further, let\u2019s list out the content we are going to cover in this article. Let\u2019s go through each of the following topics sequentially\u2014", "LibROSA is a python library that has almost every utility you are going to need while working on audio data. This rich library comes up with a large number of different functionalities. Here is a quick light on the features \u2014", "As this library is huge, we are not going to talk about all the features it carries. We are just going to use a few common features for our understanding.", "Here is how you can install this library real quick \u2014", "Librosa supports lots of audio codecs. Although .wav(lossless) is widely used when audio data analysis is concerned. Once you have successfully installed and imported libROSA in your jupyter notebook. You can read a given audio file by simply passing the file_path to librosa.load() function.", "librosa.load() \u2014> function returns two things \u2014 1. An array of amplitudes. 2. Sampling rate. The sampling rate refers to \u2018sampling frequency\u2019 used while recording the audio file. If you keep the argument sr = None , it will load your audio file in its original sampling rate. (Note: You can specify your custom sampling rate as per your requirement, libROSA can upsample or downsample the signal for you). Look at the following image \u2014", "sampling_rate = 16k says that this audio was recorded(sampled) with a sampling frequency of 16k. In other words, while recording this file we were capturing 16000 amplitudes every second. Thus, If we want to know the duration of the audio, we can simply divide the number of samples (amplitudes) by the sampling-rate as shown below \u2014", "\u201cYes you can play the audio inside your jupyter-notebook.\u201d", "IPython gives us a widget to play audio files through notebook.", "We have got amplitudes and sampling-rate from librosa. We can easily plot these amplitudes with time. LibROSA provides a utility function waveplot() as shown below \u2014", "This visualization is called the time-domain representation of a given signal. This shows us the loudness (amplitude) of sound wave changing with time. Here amplitude = 0 represents silence. (From the definition of sound waves \u2014 This amplitude is actually the amplitude of air particles which are oscillating because of the pressure change in the atmosphere due to sound).", "These amplitudes are not very informative, as they only talk about the loudness of audio recording. To better understand the audio signal, it is necessary to transform it into the frequency-domain. The frequency-domain representation of a signal tells us what different frequencies are present in the signal. Fourier Transform is a mathematical concept that can convert a continuous signal from time-domain to frequency-domain. Let\u2019s learn more about Fourier Transform.", "An audio signal is a complex signal composed of multiple \u2018single-frequency sound waves\u2019 which travel together as a disturbance(pressure-change) in the medium. When sound is recorded we only capture the resultant amplitudes of those multiple waves. Fourier Transform is a mathematical concept that can decompose a signal into its constituent frequencies. Fourier transform does not just give the frequencies present in the signal, It also gives the magnitude of each frequency present in the signal.", "Inverse Fourier Transform is just the opposite of the Fourier Transform. It takes the frequency-domain representation of a given signal as input and does mathematically synthesize the original signal.", "Let\u2019s see how we can use Fourier transformation to convert our audio signal into its frequency components \u2014", "Fast Fourier Transformation(FFT) is a mathematical algorithm that calculates Discrete Fourier Transform(DFT) of a given sequence. The only difference between FT(Fourier Transform) and FFT is that FT considers a continuous signal while FFT takes a discrete signal as input. DFT converts a sequence (discrete signal) into its frequency constituents just like FT does for a continuous signal. In our case, we have a sequence of amplitudes that were sampled from a continuous audio signal. DFT or FFT algorithm can convert this time-domain discrete signal into a frequency-domain.", "To understand the output of FFT, let\u2019s create a simple sine wave. The following piece of code creates a sine wave with a sampling rate = 100, amplitude = 1 and frequency = 3. Amplitude values are calculated every 1/100th second (sampling rate) and stored into a list called y1. We will pass these discrete amplitude values to calculate DFT of this signal using the FFT algorithm.", "If you plot these discrete values(y1) keeping sample number on x-axis and amplitude value on y-axis, it generates a nice sine wave plot as the following screenshot shows \u2014", "Now we have a sequence of amplitudes stored in list y1. We will pass this sequence to the FFT algorithm implemented by scipy. This algorithm returns a list yf of complex-valued amplitudes of the frequencies found in the signal. The first half of this list returns positive-frequency-terms, and the other half returns negative-frequency-terms which are similar to the positive ones. You can pick out any one half and calculate absolute values to represent the frequencies present in the signal. Following function takes samples as input and plots the frequency graph \u2014", "In the following graph, we have plotted the frequencies for our sine wave using the above fft_plot function. You can see this plot clearly shows the single frequency value present in our sine wave, which is 3. Also, it shows amplitude related to this frequency which we kept 1 for our sine wave.", "To check out the output of FFT for a signal having more than one frequency, Let\u2019s create another sine wave. This time we will keep sampling rate = 100, amplitude = 2 and frequency value = 11. Following code generates this signal and plots the sine wave \u2014", "Generated sine wave looks like the below graph. It would have been smoother if we had increased the sampling rate. We have kept the sampling rate = 100 because later we are going to add this signal to our old sine wave.", "Obviously FFT function will show a single spike with frequency = 11 for this wave also. But we want to see what happens if we add these two signals of the same sampling rate but the different frequency and amplitude values. Here sequence y3 will represent the resultant signal.", "If we plot the signal y3, it looks something like this \u2014", "If we pass this sequence (y3) to our fft_plot function. It generates the following frequency graph for us. It shows two spikes for the two frequencies present in our resultant signal. So the presence of one frequency does not affect the other frequency in the signal. Also, one thing to notice is that the magnitudes of the frequencies are in line with our generated sine waves.", "Now that we have seen how this FFT algorithm gives us all the frequencies in a given signal. let\u2019s try to pass our original audio signal into this function. We are using the same audio clip we loaded earlier into the python with a sampling rate = 16000.", "Now, look at the following frequency plot. This \u20183-second long\u2019 signal is composed of thousands of different frequencies. Magnitudes of frequency values > 2000 are very small as most of these frequencies are probably due to the noise. We are plotting frequencies ranging from 0 to 8kHz because our signal was sampled at 16k sampling rate and according to the Nyquist sampling theorem, it should only posses frequencies \u2264 8000Hz (16000/2).", "Strong frequencies are ranging from 0 to 1kHz only because this audio clip was human speech. We know that in a typical human speech this range of frequencies dominates.", "We got frequencies But where is the Time information?", "Suppose you are working on a Speech Recognition task. You have an audio file in which someone is speaking a phrase (for example: How are you). Your recognition system should be able to predict these three words in the same order (1. \u2018how\u2019, 2. \u2018are\u2019, 3. \u2018you\u2019). If you remember, in the previous exercise we broke our signal into its frequency values which will serve as features for our recognition system. But when we applied FFT to our signal, it gave us only frequency values and we lost the track of time information. Now our system won\u2019t be able to tell what was spoken first if we use these frequencies as features. We need to find a different way to calculate features for our system such that it has frequency values along with the time at which they were observed. Here Spectrograms come into the picture.", "Visual representation of frequencies of a given signal with time is called Spectrogram. In a spectrogram representation plot \u2014 one axis represents the time, the second axis represents frequencies and the colors represent magnitude (amplitude) of the observed frequency at a particular time. The following screenshot represents the spectrogram of the same audio signal we discussed earlier. Bright colors represent strong frequencies. Similar to earlier FFT plot, smaller frequencies ranging from (0\u20131kHz) are strong(bright).", "Idea is to break the audio signal into smaller frames(windows) and calculate DFT (or FFT) for each window. This way we will be getting frequencies for each window and window number will represent the time. As window 1 comes first, window 2 next\u2026and so on. It's a good practice to keep these windows overlapping otherwise we might lose a few frequencies. Window size depends upon the problem you are solving.", "For a typical speech recognition task, a window of 20 to 30ms long is recommended. A human can\u2019t possibly speak more than one phoneme in this time window. So keeping the window this much smaller we won\u2019t lose any phoneme while classifying. The frame (window) overlap can vary from 25% to 75% as per your need, generally, it is kept 50% for speech recognition.", "In our spectrogram calculation, we will keep the window duration 20ms and an overlap of 50% among the windows. Because our signal is sampled at 16k frequency, each window is going to have (16000 * 20 * 0.001) = 320 amplitudes. For an overlap of 50%, we need to go forward by (320/2) = 160 amplitude values to get to the next window. Thus our stride value is 160.", "Have a look at the spectrogram function in the following image. In line-18 we are making a weighting window( Hanning ) and multiplying it with amplitudes before passing it to FFT function in line-20. Weighting window is used here to handle discontinuity of this small signal(small signal from a single frame) before passing it to the DFT algorithm. To learn more about why the weighting window is necessary \u2014 click here.", "A python function to calculate spectrogram features \u2014", "The output of the FFT algorithm is a list of complex numbers (size = window_size /2) which represent amplitudes of different frequencies within the window. For our window of size 320, we will get a list of 160 amplitudes of frequency bins which represent frequencies from 0 Hz \u2014 8kHz (as our sampling rate is 16k) in our case.", "Going forward, Absolute values of those complex-valued amplitudes are calculated and normalized. The resulting 2D matrix is your spectrogram. In this matrix rows and columns represent window frame number and frequency bin while values represent the strength of the frequencies.", "We know how to generate a spectrogram now, which is a 2D matrix representing the frequency magnitudes along with time for a given signal. Now think of this spectrogram as an image. You have converted your audio file into the following image.", "This reduces it to an image classification problem. This image represents your spoken phrase from left to right in a timely manner. Or consider this as an image where your phrase is written from left to right, and all you need to do is identify those hidden English characters.", "Given a parallel corpus of English text, we can train a deep learning model and build a speech recognition system of our own. Here are two well known open-source datasets to try out \u2014", "Popular choices of deep learning architectures can be understood from the following nice research papers \u2014", "This article shows how to deal with audio data and a few audio analysis techniques from scratch. Also, it gives a starting point for building speech recognition systems. Although, Above research shows very promising results for the recognition systems, still many don\u2019t see speech recognition as a solved problem because of the following pitfalls \u2014", "There are huge opportunities in this field of research. Improvements can be done from the data preparation point of view (by creating better features) and also from the model architecture point of view (by presenting a more robust and scalable deep learning architecture).", "Cite this article: Google Scholar Link", "Thanks for reading, please let me know your comments/feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI/ML @ Google | personal blog: https://dropsofai.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa4072d228520&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4072d228520--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kartikgill96?source=post_page-----a4072d228520--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91----a4072d228520---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://dropsofai.com/sound-wave-basics-every-data-scientist-must-know-before-starting-analysis-on-audio-data/", "anchor_text": "click here"}, {"url": "https://librosa.github.io/librosa/", "anchor_text": "LibROSA"}, {"url": "https://librosa.github.io/librosa/install.html", "anchor_text": "install this library"}, {"url": "https://en.wikipedia.org/wiki/Audio_codec", "anchor_text": "audio codecs"}, {"url": "https://en.wikipedia.org/wiki/WAV", "anchor_text": ".wav(lossless)"}, {"url": "https://en.wikipedia.org/wiki/Sampling_(signal_processing)", "anchor_text": "sampling rate"}, {"url": "https://en.wikipedia.org/wiki/Fourier_transform", "anchor_text": "Fourier Transform"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html", "anchor_text": "scipy"}, {"url": "https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem", "anchor_text": "Nyquist sampling theorem"}, {"url": "https://en.wikipedia.org/wiki/Spectrogram", "anchor_text": "Spectrograms"}, {"url": "https://www.tek.com/blog/window-functions-spectrum-analyzers", "anchor_text": "click here"}, {"url": "http://www.openslr.org/12/", "anchor_text": "LibriSpeech"}, {"url": "https://voice.mozilla.org/en", "anchor_text": "Common Voice"}, {"url": "https://arxiv.org/abs/1912.06670", "anchor_text": "Massively-Multilingual Speech Corpus"}, {"url": "https://arxiv.org/pdf/1609.03193.pdf", "anchor_text": "Wave2Lettter"}, {"url": "https://arxiv.org/pdf/1412.5567.pdf", "anchor_text": "Deep Speech"}, {"url": "https://arxiv.org/pdf/1512.02595.pdf", "anchor_text": "Deep Speech 2"}, {"url": "https://arxiv.org/pdf/1707.07413.pdf", "anchor_text": "Deep Speech 3"}, {"url": "https://arxiv.org/pdf/1508.01211.pdf", "anchor_text": "Listen, Attend and Spell"}, {"url": "https://arxiv.org/pdf/1904.03288.pdf", "anchor_text": "JASPER"}, {"url": "https://dropsofai.com/understanding-audio-data-fourier-transform-fft-and-spectrogram-features-for-a-speech-recognition-system/", "anchor_text": "here"}, {"url": "https://scholar.google.com/scholar?hl=en&as_sdt=0,24&cluster=9680825736551595294", "anchor_text": "Google Scholar Link"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a4072d228520---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/speech-recognition?source=post_page-----a4072d228520---------------speech_recognition-----------------", "anchor_text": "Speech Recognition"}, {"url": "https://medium.com/tag/voice-recognition?source=post_page-----a4072d228520---------------voice_recognition-----------------", "anchor_text": "Voice Recognition"}, {"url": "https://medium.com/tag/audio?source=post_page-----a4072d228520---------------audio-----------------", "anchor_text": "Audio"}, {"url": "https://medium.com/tag/voice-assistant?source=post_page-----a4072d228520---------------voice_assistant-----------------", "anchor_text": "Voice Assistant"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----a4072d228520---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=-----a4072d228520---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4072d228520--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa4072d228520&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a4072d228520---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a4072d228520--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a4072d228520--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a4072d228520--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a4072d228520--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a4072d228520--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kartikgill96?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kartik Chaudhary"}, {"url": "https://medium.com/@kartikgill96/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "196 Followers"}, {"url": "https://dropsofai.com", "anchor_text": "https://dropsofai.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3fd5a49d1e91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=post_page-3fd5a49d1e91--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fca74cfd61cd8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520&newsletterV3=3fd5a49d1e91&newsletterV3Id=ca74cfd61cd8&user=Kartik+Chaudhary&userId=3fd5a49d1e91&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}