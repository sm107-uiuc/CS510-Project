{"url": "https://towardsdatascience.com/machine-learning-step-by-step-6fbde95c455a", "time": 1683003789.697133, "path": "towardsdatascience.com/machine-learning-step-by-step-6fbde95c455a/", "webpage": {"metadata": {"title": "Machine Learning: Step-By-Step. A Step-By-Step Guide To Machine\u2026 | by Alexander Cheng | Towards Data Science", "h1": "Machine Learning: Step-By-Step", "description": "As data scientists, we have many options to choose from to create a classification model. One of the most popular and robust methods is using Random Forests. We can perform Hyperparameter Tuning on\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "Hyperparameter Tuning", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2", "anchor_text": "Random Forests", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c", "anchor_text": "Principal Component Analysis (PCA)", "paragraph_index": 1}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "Scikit-learn \u201cbreast cancer\u201d dataset.", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "See this article.", "paragraph_index": 8}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "Scikit-learn Random Forest Classifier documentation.", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "hyperparameter tuning", "paragraph_index": 16}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "Scikit-learn Random Forest Classifier documentation.", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd", "anchor_text": "cross-validations", "paragraph_index": 18}, {"url": "http://linkedin.com/in/alexanderweicheng", "anchor_text": "linkedin.com/in/alexanderweicheng", "paragraph_index": 40}], "all_paragraphs": ["As data scientists, we have many options to choose from to create a classification model. One of the most popular and robust methods is using Random Forests. We can perform Hyperparameter Tuning on Random Forests to try to optimize the model\u2019s performance.", "It is also common practice to try Principal Component Analysis (PCA) before fitting our data to a model. But why should we even add this step? Isn\u2019t the whole point of Random Forest to help us interpret feature importance easily?", "Yes, PCA can make interpreting each \u201cfeature\u201d a little harder when we analyze the \u201cfeature importances\u201d of our Random Forest model. However, PCA performs dimensionality reduction, which can reduce the number of features for the Random Forest to process, so PCA might help speed up the training of your Random Forest model. Note that computational cost is one of the biggest drawbacks of Random Forests (it can take a long time to run the model). PCA can become really important especially when you are working with hundreds or even thousands of predicting features. So if the most important thing is to simply have the best performing model, and interpreting feature importance can be sacrificed, then PCA may be useful to try.", "Now, let\u2019s get started with our example. We will be working with the Scikit-learn \u201cbreast cancer\u201d dataset. We will create 3 models, and compare their performance to each other:", "First, we load the data and create a dataframe. Since this is a pre-cleaned \u201ctoy\u201d dataset from Scikit-learn, we are good to proceed with the modeling process. However, as a best practice, we should always do the following:", "The column named \u201ccancer\u201d is the target variable that we want to predict using our model. \u201c0\u201d means \u201cno cancer\u201d and \u201c1\u201d means \u201ccancer\u201d.", "Now we split our data using the Scikit-learn \u201ctrain_test_split\u201d function. We want to give the model as much data as possible to train with. However, we also want to make sure that we have enough data for the model to test itself on. In general, as the number of rows in the dataset increases, the more data we can give to the training set.", "For example, if we had millions of rows, we could have a 90% train / 10% test split. However, our dataset is only 569 rows, which is not a very large dataset to train or test on. So to be fair to both training and testing, we will split the data into 50% train and 50% test. We set stratify=y to ensure that both the train and test sets have the same proportion of 0s and 1s as the original dataset.", "Before modeling, we need to \u201ccenter\u201d and \u201cstandardize\u201d our data by scaling. We scale to control for the fact that different variables are measured on different scales. We scale so that each predictor can have a \u201cfair fight\u201d against each other in deciding importance. See this article. We also convert \u201cy_train\u201d from a Pandas \u201cSeries\u201d object into a NumPy array for the model to accept the target training data later on.", "Now we create a \u201cbaseline\u201d Random Forest model. This model uses all of the predicting features and of the default settings defined in the Scikit-learn Random Forest Classifier documentation. First, we instantiate the model and fit the scaled data to it. We can measure the accuracy of the model on our training data.", "If we are curious to see which features are most important to the Random Forest model to predict breast cancer, we can visualize and quantify the importances by calling the \u201cfeature_importances_\u201d method:", "Now, how could we improve our baseline model? Using dimension reduction, we can approximate the original dataset with fewer variables, while reducing computational power to run our model. Using PCA, we can study the cumulative explained variance ratio of these features to understand which features explain the most variance in the data.", "We instantiate the PCA function and set the number of components (features) that we want to consider. We\u2019ll set it to \u201c30\u201d to see the explained variance of all the generated components, before deciding where to make the cut. Then we \u201cfit\u201d our scaled X_train data to the PCA function.", "Looking at the dataframe above, when we use PCA to reduce our 30 predicting variables down to 10 components, we can still explain over 95% of the variance. The other 20 components explain less than 5% of the variance, so we can cut them. Using this logic, we will use PCA to reduce the number of components from 30 to 10 for X_train and X_test. We will assign these recreated, \u201creduced dimension\u201d datasets to \u201cX_train_scaled_pca\u201d and \u201cX_test_scaled_pca\u201d.", "Each component is a linear combination of the original variables with corresponding \u201cweights\u201d. We can see these \u201cweights\u201d for each PCA component by creating a dataframe.", "Now, we can fit our X_train_scaled_pca and y_train data to another \u201cbaseline\u201d Random Forest model, to see if we get any improvement on the model\u2019s predictions.", "After performing PCA, we can also try some hyperparameter tuning to tweak our Random Forest to try and get better predicting performance. Hyperparameters can be thought of as \u201csettings\u201d for a model. The perfect settings for one dataset won\u2019t be the same for another, so we have to \u201ctune\u201d the model.", "First, we can start with RandomSearchCV to consider a wide range of values. All of the hyperparameters for Random Forest can be found in the Scikit-learn Random Forest Classifier documentation.", "We generate a \u201cparam_dist\u201d with a range of values to try for each hyperparameter. RandomSearchCV is instantiated, our Random Forest model is passed in first, then our \u201cparam_dist\u201d, the number of iterations to try, and the number of cross-validations to perform.", "The \u201cverbose\u201d hyperparameter gives you more or less output as the model runs (like status updates). The \u201cn_jobs\u201d hyperparameter lets you decide how many cores of your processor you want to use to run the model. Setting \u201cn_jobs = -1\u201d will run the model fastest, because it uses all of your computer cores.", "We will be tuning these hyperparameters:", "With n_iter = 100 and cv = 3, we created 300 Random Forest models, randomly sampling combinations of the hyperparameters input above. We can call \u201cbest_params_\u201d to get the best performing model\u2019s parameters (shown at the bottom of the code box above). However, \u201cbest_params_\u201d at this stage may not give us the best insight to get a range of parameters to try for the next round of hyperparameter tuning. To get a good range of values to try next, we can easily get a dataframe of our RandomSearchCV results.", "Now, let\u2019s create bar plots of each hyperparameter on the x-axis, and the mean score of the models made at each value, to see which values were most successful on average:", "Looking at the plots above, we can extract insights about how well each value for each hyperparameter performed on average.", "min_samples_split: smaller values like 2 and 7 seem to have higher scores. There are also high scores at 23. We can try a few values above 2, and a few values around 23.", "min_samples_leaf: smaller values seem to correlate with higher scores\u2026we can try values between 2\u20137.", "max_features: \u201csqrt\u201d has the highest average score.", "bootstrap: \u201cFalse\u201d has the highest average score.", "So now we can take these insights ^ and move into the second round of hyperparameter tuning to further narrow our selections.", "After using RandomSearchCV, we can use GridSearchCV to perform a more refined search for our best hyperparameters. The hyperparameters are the same, but now we perform a more \u201cexhaustive\u201d search using GridSearchCV. In GridSearchCV, every single combination of hyperparameter values is tried which takes much more computational power than RandomSearchCV, where we can directly control how many iterations we want to try. For example, searching just 10 different parameter values for each of our 6 parameters, with 3-fold cross-validation will require 10\u2076 x 3 or 3,000,000 model fits! This is why we perform GridSearchCV after using RandomSearchCV, to help narrow our search first.", "So using what we learned from our RandomizedSearchCV, let\u2019s plug in the average best performing ranges of each hyperparameter:", "So here ^ we are performing 3-fold cross-validation for 3x 1 x 5x 6 x 6 x 1 = 540 model fits, which is a grand total of 1,620 model fits! And now, after performing RandomizedSearchCV followed by GridSearchCV, we can call \u201cbest_params_\u201d to get the one best model to try and predict our data (shown at the bottom of the code box above).", "Now, we can evaluate each of the models that we have made on our test data. Remember that we are testing 3 models:", "Let\u2019s generate the predictions of each of these models:", "Now, let\u2019s create confusion matrices for each model, to see how well each model was able to predict breast cancer:", "Below, we have the final results of our labor:", "We are using recall as our performance metric because we are dealing with diagnosing cancer \u2014 and are most concerned with minimizing False Negative prediction errors in our model.", "With this ^ in mind, it looks like our Baseline Random Forest model did the best, with the highest recall score of 94.97%. Given our test data set, the baseline model correctly predicted that 170 patients had cancer, out of a total of 179 people who actually had cancer.", "This case study brings up an important note: sometimes, after PCA, or even after extensive hyperparameter tuning, a tuned model may not perform as well as a plain-old \u201cvanilla\u201d model. But it\u2019s important to try. You never know which model will do best unless you try them all. In the case of predicting cancer \u2014 the better the model, the more lives can be saved.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Business Intelligence Manager @ Turner & Townsend. Data enhances decision-making, outcomes, and the way we live. linkedin.com/in/alexanderweicheng"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6fbde95c455a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alexanderweicheng?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexanderweicheng?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Alexander Cheng"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87fb2a6fe457&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&user=Alexander+Cheng&userId=87fb2a6fe457&source=post_page-87fb2a6fe457----6fbde95c455a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.quora.com/How-should-I-start-in-the-field-of-machine-learning-and-AI-with-knowledge-of-programming-and-algorithms", "anchor_text": "Image Source"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://towardsdatascience.com/understanding-random-forest-58381e0602d2", "anchor_text": "Random Forests"}, {"url": "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c", "anchor_text": "Principal Component Analysis (PCA)"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "Scikit-learn \u201cbreast cancer\u201d dataset."}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "See this article."}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "Scikit-learn Random Forest Classifier documentation."}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74", "anchor_text": "hyperparameter tuning"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "Scikit-learn Random Forest Classifier documentation."}, {"url": "https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd", "anchor_text": "cross-validations"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6fbde95c455a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6fbde95c455a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----6fbde95c455a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/code?source=post_page-----6fbde95c455a---------------code-----------------", "anchor_text": "Code"}, {"url": "https://medium.com/tag/guides-and-tutorials?source=post_page-----6fbde95c455a---------------guides_and_tutorials-----------------", "anchor_text": "Guides And Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&user=Alexander+Cheng&userId=87fb2a6fe457&source=-----6fbde95c455a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&user=Alexander+Cheng&userId=87fb2a6fe457&source=-----6fbde95c455a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6fbde95c455a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6fbde95c455a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6fbde95c455a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6fbde95c455a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6fbde95c455a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexanderweicheng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alexanderweicheng?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alexander Cheng"}, {"url": "https://medium.com/@alexanderweicheng/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "332 Followers"}, {"url": "http://linkedin.com/in/alexanderweicheng", "anchor_text": "linkedin.com/in/alexanderweicheng"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87fb2a6fe457&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&user=Alexander+Cheng&userId=87fb2a6fe457&source=post_page-87fb2a6fe457--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff22b1a3c8084&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-step-by-step-6fbde95c455a&newsletterV3=87fb2a6fe457&newsletterV3Id=f22b1a3c8084&user=Alexander+Cheng&userId=87fb2a6fe457&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}