{"url": "https://towardsdatascience.com/geometric-interpretation-of-linear-regression-dd10601a85b1", "time": 1683008723.606195, "path": "towardsdatascience.com/geometric-interpretation-of-linear-regression-dd10601a85b1/", "webpage": {"metadata": {"title": "Geometric Interpretation of Linear Regression | by Satyam Kumar | Towards Data Science", "h1": "Geometric Interpretation of Linear Regression", "description": "Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). In geometric\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). In geometric interpretation terms, the linear regression algorithm tries to find a plane or line that best fits the data points as well as possible. Linear regression is a regression technique that predicts real value.", "What does the term \u201cfinding plane that best fits the data points\u201d mean?", "For the above-given sample 2-dimension dataset (Image 1), the general equation of the line that covers as numbers of points as possible is y = m*x+c, where m is the slope of the line, and c is the intercept term. The linear regression algorithm tries to find a line/plane for which the cost function is minimized. Later in this article, you will know how a cost function is derived.", "We will represent the above equation of plane as y = w1*x + b", "Similarly, for sample 3-dimension dataset (Image 3) the equation of the plane which best fits as many points as possible is y = w1*x1 + w2*x2 + b.", "The same equation can be extended for a d-dimension dataset:", "So, we need to find a plane (W, b) of the above equation that best fit most of the data points.", "Deep Dive into Derivation of Geometric Interpretation of the algorithm:", "For any point P (in image 3), y_iAct is the actual output value of the point whereas y_iPre is the predicted value. Hence the error can be calculated as:", "Since the error can be positive and negative as y_iPred can be above or below the plane/line, so to maintain positive error we square the error for each x_i", "The error function follows a parabolic curve, which means error (Y-axis) will always be positive.", "We need to minimize the errors for all the sets of points which is referred to as MSE (Mean squared Error).", "And the cost function of linear regression is:", "The cost function defines that we need to find a plane with given W, b such that the error for all the sets of points is minimized. Replacing y_iPred with the equation of plane the new cost function becomes:", "Use an optimizer to compute the optimal value of W, b which minimizes the above cost function. A gradient descent optimizer can be used to find the optimal value of the plane for which the mean squared error is minimum.", "For a query point \u2018Qx\u2019 (Image 5) the corresponding predicted value is Ypred which can be computed using the equation of plane (W, w0) using the above equation.", "Implementation of a linear regression model using Gradient Descent optimizer:", "In order to find the plane (W, b), we want the error to be as small as possible. Gradient Descent is an iterative method to get to the minimum error. To find the minimum error we find the gradient of the function.", "Steps to follow for Gradient Descent Method:", "Follow these 3 steps iteratively until we reach the minimum error. With each iteration, the weight vector and bias term are updated to reach minima.", "Implementation of LR algorithm for a sample dataset:", "We take a 2-dimension sample dataset of 300 data points (line 2). Split the dataset into train and test dataset with 210 points (70%) belonging to train data and rest 90 points (30%) for the testing (line 5). The diagram above (Image 6) represents the sample dataset and code implementation is below.", "Step #1: Initialize weight vector and bias term:", "Initialize the weight vector and bias term with random values (lines 8\u201310). The dimension of the weight vector will be equal to the dimension of the dataset.", "Step #2: Find the derivative of the function with respect to weight and bias:", "The above is the equation of MSE derived above in the article. We need to find the derivative of function f(W, b) with respect to W (line 21), and derivative of function f(W, b) with respect to b (line 22).", "The above two equations represent the derivate of function f with respect to weight vector and bias term respectively.", "Step #1: Update the weight and bias:", "The update equation of weight vector and bias term is mentioned above respectively. The weight vector and bias term are updated (lines 24\u201325) for each iteration according to the mentioned equations.\u2018lr\u2019 represents the learning rate which defines how fast the updation should take place.", "If the learning rate is large then minima can never be achieved and it is very small then minima is achieved with some number of iterations.", "The above 3 steps are repeated for some number of iteration (line 16) till W_(i+1) becomes very close to or equal to W_i.", "The weight vector and bias term computed are [50.265], -0.131 respectively (lines 2\u20133). Compute the predicted values for all test dataset (lines 6\u20139). Plot the line and all data points (lines 12\u201319) to observe the result.", "Observation: The line plot (Image 8) can be observed that it best fits the data points as well as possible.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdd10601a85b1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://satyam-kumar.medium.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": ""}, {"url": "https://satyam-kumar.medium.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Satyam Kumar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3d8bf96a415f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&user=Satyam+Kumar&userId=3d8bf96a415f&source=post_page-3d8bf96a415f----dd10601a85b1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@isaacmsmith?utm_source=medium&utm_medium=referral", "anchor_text": "Isaac Smith"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/krsatyam1996/Linear_Regression_from_scratch", "anchor_text": "krsatyam1996/Linear_Regression_from_scratchContribute to krsatyam1996/Linear_Regression_from_scratch development by creating an account on GitHub.github.com"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----dd10601a85b1---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dd10601a85b1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----dd10601a85b1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----dd10601a85b1---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dd10601a85b1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&user=Satyam+Kumar&userId=3d8bf96a415f&source=-----dd10601a85b1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&user=Satyam+Kumar&userId=3d8bf96a415f&source=-----dd10601a85b1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdd10601a85b1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dd10601a85b1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dd10601a85b1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dd10601a85b1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dd10601a85b1--------------------------------", "anchor_text": ""}, {"url": "https://satyam-kumar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://satyam-kumar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Satyam Kumar"}, {"url": "https://satyam-kumar.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.7K Followers"}, {"url": "https://www.linkedin.com/in/satkr7/", "anchor_text": "https://www.linkedin.com/in/satkr7/"}, {"url": "https://satyam-kumar.medium.com/membership", "anchor_text": "https://satyam-kumar.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3d8bf96a415f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&user=Satyam+Kumar&userId=3d8bf96a415f&source=post_page-3d8bf96a415f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fec1ceaec9c6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgeometric-interpretation-of-linear-regression-dd10601a85b1&newsletterV3=3d8bf96a415f&newsletterV3Id=ec1ceaec9c6a&user=Satyam+Kumar&userId=3d8bf96a415f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}