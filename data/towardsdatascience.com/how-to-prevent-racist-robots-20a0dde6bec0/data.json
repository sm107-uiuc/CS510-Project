{"url": "https://towardsdatascience.com/how-to-prevent-racist-robots-20a0dde6bec0", "time": 1682996525.6405609, "path": "towardsdatascience.com/how-to-prevent-racist-robots-20a0dde6bec0/", "webpage": {"metadata": {"title": "How to Prevent Racist Robots. What is algorithmic fairness, and why\u2026 | by Mia Iseman | Towards Data Science", "h1": "How to Prevent Racist Robots", "description": "You\u2019re telling your coworker a story, and you mention your race (not white). All of a sudden your (white) coworker interrupts you to announce: Talking to your boss about something related to you\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/the-establishment/social-justice-must-be-complicated-because-oppression-is-never-simple-3a24ea6c9f88", "anchor_text": "oppressed", "paragraph_index": 4}, {"url": "https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/3/1161/files/2018/07/AEA-P-and-P-algorithms-and-race-2018-suuawi.pdf", "anchor_text": "Algorithmic Fairness", "paragraph_index": 7}, {"url": "https://shecancode.io/blog/is-machine-learningai-sexist", "anchor_text": "\u201crobots\u201d are taking on our human biases", "paragraph_index": 9}, {"url": "https://www.bu.edu/research/articles/algorithmic-fairness/", "anchor_text": "another researcher", "paragraph_index": 24}, {"url": "https://www.britannica.com/topic/affirmative-action", "anchor_text": "Affirmative Action\u2019s", "paragraph_index": 26}, {"url": "http://www.miaiseman.wixsite.com/miaiseman", "anchor_text": "www.miaiseman.wixsite.com/miaiseman", "paragraph_index": 30}], "all_paragraphs": ["Has this ever happened to you?", "You\u2019re telling your coworker a story, and you mention your race (not white). All of a sudden your (white) coworker interrupts you to announce:", "Talking to your boss about something related to you identifying as female? \u201cWhy do you have to bring gender into it? If you want to be treated as an equal, then stop reminding me you\u2019re a woman.\u201d", "Want to get married, but the photographer denies you service? \u201cIt\u2019s just a coincidence that you\u2019re gay! Doesn\u2019t sound like discrimination to me!\u201d", "There are many subgroups of people in America that are oppressed in many ways. Systemic oppression is complex, but just because we close our eyes and plug our ears doesn\u2019t mean injustices will cease to exist. It just means we\u2019re standing in the middle of it, ignoring it.", "Ignorance is not bliss. It just makes you an ignoramus.", "Still, many people don\u2019t understand or seek to understand the experiences of people of color, women, LGBTQ people, differently abled folks, or whatever other targeted subgroup is literally shouting loud and clear to them. They choose to ignore the \u201cotherness.\u201d It should be noted, that this is often well-intentioned, but its result is the direct opposite. The same is the case for certain decisions that machines make on a daily basis.", "In their scholarly article \u201cAlgorithmic Fairness,\u201d the authors make the case that we should include race and other factors representative of an oppressed subgroup if we (and our machines) want to make important decisions with the information. If we do ignore these important factors, we can do more harm than good. Why? Let\u2019s break down what the article says.", "An algorithm is a set of steps, rules, or calculations, and it\u2019s common for computers to have algorithms that they follow. It\u2019s increasingly common for us to use algorithms to make decisions. Just a few common yet important examples: A doctor deciding if someone is at risk for a disease, a judge setting bail, and a school parsing through applications.", "It has been shown time and time again that our \u201crobots\u201d are taking on our human biases and making discriminatory decisions. From the article:", "Because the data used to train these algorithms are themselves tinged with stereotypes and past discrimination, it is natural to worry that biases are being \u2018baked in.\u2019", "A common reaction, then, is to leave the sensitive factors out, to train robots that announce:", "Why is this a bad idea? Before we can say, we must know the definition of one key word: equitable. Equitable means fair. Equal means \u201cthe same.\u201d So, keep in mind that equitable does not mean equal.", "When we treat people equally, we give everyone the same support. When we treat people equitably, we give everyone the support they need so that the result is fair.", "Of course, our world is even more complicated\u2026", "\u2026but this knowledge will serve us enough to understand the article. The article does an experiment that looks like this:", "Imagine we have two different college admissions counselors. One counselor, Erica, is efficient. Erica\u2019s goal is always to admit students to the college that will perform the best during their time there. So, she looks at the student\u2019s application, and she uses a machine learning model to predict what that student\u2019s college GPA will be. All Erica has to do is select the students with the most potential.", "The other counselor, Farrah, is equitable and efficient. Farrah also wants students with the most potential, but she treats the applicants equitably. In the experiment, they limit the student population to white non-Hispanic students and black students. So, the only variable that requires \u201cdifferent\u201d treatment in the predictive model is race. Farrah has to select the students with the highest predicted college GPAs, making sure to have a certain percent of students that are black.", "So Erica is efficient and just wants the applicants that will do the best in college. Farrah is fair and wants the applicants that will do the best in college combined with the fact that she wants to maximize the number of black students at the college.", "The model they used was able to predict the college GPAs because the experiment involved tracking the applicants over time. So, they had a bunch of high school data as well as their actual eventual college GPAs to show how they really performed in college.", "Erica ran the model two ways: excluding race, and including race. Regardless of the model, remember she always chose efficiently \u2014 the students with the highest predicted GPAs.", "Farrah ran the model including race, and she set different thresholds to try and undo some of the systemic bias that black applicants may encounter. For instance, we might worry a black applicant didn\u2019t take SAT prep courses, while a white student did. Then, if the two students got the same SAT score, the model would predict that the black student would have a higher college GPA. This is just one example of many complicated adjustments to the model\u2019s thresholds that Farrah made.", "\u201cAbsent legal constraints, one should include variables such as gender and race for fairness reasons\u2026The inclusion of such variables can increase both equity and efficiency.\u201d", "They ran this experiment using machine learning models of all sorts, but they consistently found that \u201cthe strategy of blinding the algorithm to race inadvertently detracts from fairness.\u201d", "While the article has a cut-and-dry conclusion, accounting for algorithmic bias is not an easy fix. How do we define what is equitable? As another researcher named Sarah Scheffler points out:", "There are many different measures of fairness, and there are trade-offs between them. So to what extent are the \u2026 systems compatible with the notion of fairness we want to achieve?", "Even if some scientists agree on what is equitable, we also often must make sure it is legal to implement our algorithms with different equitable thresholds. As we\u2019ve seen with Affirmative Action\u2019s history, for just one example, there is often a difference of opinion what should be legally implemented.", "I\u2019m hopeful for a couple different things:", "Here\u2019s hoping these two circumstances converge to a society that consistently makes decisions for the greater good with the help of machines.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Consultant | Data Nerd | Writer | Fun Person www.miaiseman.wixsite.com/miaiseman"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F20a0dde6bec0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mia.iseman?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mia.iseman?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Mia Iseman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F60df1dee26cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&user=Mia+Iseman&userId=60df1dee26cd&source=post_page-60df1dee26cd----20a0dde6bec0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/the-establishment/social-justice-must-be-complicated-because-oppression-is-never-simple-3a24ea6c9f88", "anchor_text": "oppressed"}, {"url": "https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/3/1161/files/2018/07/AEA-P-and-P-algorithms-and-race-2018-suuawi.pdf", "anchor_text": "Algorithmic Fairness"}, {"url": "https://shecancode.io/blog/is-machine-learningai-sexist", "anchor_text": "\u201crobots\u201d are taking on our human biases"}, {"url": "https://www.bu.edu/research/articles/algorithmic-fairness/", "anchor_text": "another researcher"}, {"url": "https://www.britannica.com/topic/affirmative-action", "anchor_text": "Affirmative Action\u2019s"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----20a0dde6bec0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----20a0dde6bec0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/equity?source=post_page-----20a0dde6bec0---------------equity-----------------", "anchor_text": "Equity"}, {"url": "https://medium.com/tag/social-justice?source=post_page-----20a0dde6bec0---------------social_justice-----------------", "anchor_text": "Social Justice"}, {"url": "https://medium.com/tag/robotics?source=post_page-----20a0dde6bec0---------------robotics-----------------", "anchor_text": "Robotics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&user=Mia+Iseman&userId=60df1dee26cd&source=-----20a0dde6bec0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&user=Mia+Iseman&userId=60df1dee26cd&source=-----20a0dde6bec0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F20a0dde6bec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----20a0dde6bec0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----20a0dde6bec0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mia.iseman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mia.iseman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mia Iseman"}, {"url": "https://medium.com/@mia.iseman/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "50 Followers"}, {"url": "http://www.miaiseman.wixsite.com/miaiseman", "anchor_text": "www.miaiseman.wixsite.com/miaiseman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F60df1dee26cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&user=Mia+Iseman&userId=60df1dee26cd&source=post_page-60df1dee26cd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F60df1dee26cd%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prevent-racist-robots-20a0dde6bec0&user=Mia+Iseman&userId=60df1dee26cd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}