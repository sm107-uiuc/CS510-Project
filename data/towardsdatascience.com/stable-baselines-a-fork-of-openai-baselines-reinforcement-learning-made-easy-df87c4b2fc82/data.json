{"url": "https://towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82", "time": 1682993625.120512, "path": "towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82/", "webpage": {"metadata": {"title": "Stable Baselines: a Fork of OpenAI Baselines \u2014 Reinforcement Learning Made Easy | by Antonin RAFFIN | Towards Data Science", "h1": "Stable Baselines: a Fork of OpenAI Baselines \u2014 Reinforcement Learning Made Easy", "description": "After several weeks of hard work, we are happy to announce the release of Stable Baselines, a set of implementations of Reinforcement Learning (RL) algorithms with a common interface, based on OpenAI\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines", "paragraph_index": 0}, {"url": "http://stable-baselines.readthedocs.io/", "anchor_text": "http://stable-baselines.readthedocs.io/", "paragraph_index": 1}, {"url": "https://github.com/araffin/rl-baselines-zoo", "anchor_text": "https://github.com/araffin/rl-baselines-zoo", "paragraph_index": 2}, {"url": "https://github.com/araffin/rl-tutorial-jnrr19", "anchor_text": "https://github.com/araffin/rl-tutorial-jnrr19", "paragraph_index": 3}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "try it online", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1709.06560", "anchor_text": "Deep reinforcement learning that matters", "paragraph_index": 10}, {"url": "https://github.com/openai/baselines/pull/490", "anchor_text": "improving their baselines", "paragraph_index": 11}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "README", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1802.04181", "anchor_text": "state representation learning", "paragraph_index": 18}, {"url": "https://worldmodels.github.io/", "anchor_text": "world models", "paragraph_index": 18}, {"url": "https://pathak22.github.io/large-scale-curiosity/", "anchor_text": "Curiosity-Driven learning", "paragraph_index": 18}, {"url": "https://github.com/hill-a/stable-baselines/releases", "anchor_text": "fix some issues", "paragraph_index": 21}, {"url": "https://github.com/openai/baselines/commit/4993286230ac92ead39a66005b7042b56b8598b0", "anchor_text": "previous bug fix from OpenAI", "paragraph_index": 21}, {"url": "https://github.com/openai/baselines/commit/9fa8e1baf1d1f975b87b369a8082122eac812eb1", "anchor_text": "new commits", "paragraph_index": 21}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "basic usage", "paragraph_index": 22}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb", "anchor_text": "try it online", "paragraph_index": 24}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/multiprocessing_rl.ipynb", "anchor_text": "try it online", "paragraph_index": 25}, {"url": "https://stable-baselines.readthedocs.io/en/master/guide/tensorboard.html", "anchor_text": "legacy integration", "paragraph_index": 26}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/monitor_training.ipynb", "anchor_text": "try it online", "paragraph_index": 29}, {"url": "https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/", "anchor_text": "all the preprocessing", "paragraph_index": 30}, {"url": "http://www.mujoco.org/", "anchor_text": "Mujoco", "paragraph_index": 31}, {"url": "https://www.continualai.com/", "anchor_text": "continual learning", "paragraph_index": 34}, {"url": "https://medium.com/u/68d764aba302?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Ashley hill", "paragraph_index": 38}, {"url": "http://u2is.ensta-paristech.fr/index.php?lang=en", "anchor_text": "robotics lab U2IS", "paragraph_index": 39}, {"url": "https://flowers.inria.fr/", "anchor_text": "INRIA Flowers", "paragraph_index": 39}, {"url": "http://www.ensta-paristech.fr/en", "anchor_text": "ENSTA ParisTech", "paragraph_index": 39}, {"url": "http://www.robotsthatdream.eu", "anchor_text": "DREAM project", "paragraph_index": 40}, {"url": "https://medium.com/@araffin/autonomous-racing-robot-with-an-arduino-a-raspberry-pi-and-a-pi-camera-3e72819e1e63", "anchor_text": "building an autonomous racing car", "paragraph_index": 41}, {"url": "https://araffin.github.io/", "anchor_text": "https://araffin.github.io/", "paragraph_index": 44}], "all_paragraphs": ["After several weeks of hard work, we are happy to announce the release of Stable Baselines, a set of implementations of Reinforcement Learning (RL) algorithms with a common interface, based on OpenAI Baselines. We focused on simplicity of use and consistency. In this article, we will present various examples (basic usage, saving/loading agents, easy multiprocessing, training on Atari games and more) along with the origins of the fork.", "Update: Documentation is now online at http://stable-baselines.readthedocs.io/ and Tensorboard support was added", "Update: We added a rl baselines zoo, the collection contains 70+ trained agents https://github.com/araffin/rl-baselines-zoo", "Update: We have written a full tutorial: https://github.com/araffin/rl-tutorial-jnrr19", "With Stable Baselines, training a PPO agent is as simple as:", "But could we make it simpler? Sure, we can! With Stable Baselines, you can now define and train a Reinforcement Learning agent in only one line of code:", "You can try it online using Colab Notebook.", "When we started using OpenAI Baselines for our research, we were happy to find reinforcement learning algorithms that were working (1). However, from the moment we tried to tweak it a bit, for instance to work with learned features instead of images, it became a hell, we had to patch uncommented code.", "Among the difficulties we went through, there was the lack of comments, the absence of meaningful variable names and consistency (no common codestyle) and lots of duplicated code (2).", "So, after a new commit on the master branch of the Baselines repository broke our code, we decided to create a fork with two ideas in mind:", "(1) In our experiments, the Baselines codebase was the one giving the best results (in term of performance) compared to other codebase. Also, in Deep reinforcement learning that matters, they show that Baselines DDPG implementation outperforms other codebase. Recently, OpenAI 5 playing Dota 2 is using PPO in its core.", "(2) at the time of writing, OpenAI seems to put some effort on improving their baselines, however there is still a lot missing.", "OpenAI Baselines (and thus Stable Baselines) include A2C, PPO, TRPO, DQN, ACKTR, ACER and DDPG. You can find a recap table about what is supported (action space, multiprocessing) in the README.", "The Baselines come also with useful wrappers, for example for preprocessing or multiprocessing. We will show their utility in the examples.", "All algorithms follow the same structure, we wanted to have a scikit-learn like interface, and as you will see in the examples, that makes things a lot easier!", "We provide common methods like train (equivalent of fit), save, load and predict (same as in sk-learn) for all algorithms.", "We added saving and loading functions for all the algorithms, the ability to pass a callback (for live plotting), full tensorboard support and an additional method for outputting action probabilities.", "We added support for RL training on arbitrary features, that is to say RL algorithms can be trained on something else than pixels (current OpenAI Baselines only support continuous actions when not using images as input).", "In fact, decoupling state representation learning, feature extraction from policy learning is the main topic of our research, and have been the focus of recent works too (e.g. world models and Curiosity-Driven learning). Therefore, we considered this to be an important feature of our fork.", "When we started refactoring OpenAI Baselines, there was only 16% of code coverage. That is to say, only 16% of all code statements were tested. During the refactoring, we added more tests and attained a coverage of 65%! (Most of the uncovered code comes from Mujoco related features, and because this is a commercial physics engine, it is hard to have continuous integration with it).", "Edit: After more refactoring (GAIL and HER), the coverage is now at 85%!", "We took advantage of commenting the code to fix some issues. For instance, the wrapper for frame-stacking was only working with gray-scale images (the full story is that a previous bug fix from OpenAI was erased by one of their new commits\u2026).", "In the following section, we will go through different examples on how to use stable baselines. We will cover basic usage, saving/loading, multiprocessing, plotting, training on Atari games and more !", "In the following example, we will train, save and load an A2C model on the Lunar Lander environment.", "Associated Colab Notebook: try it online!", "Associated Colab Notebook: try it online !", "OpenAI provided basic tensorboard support (see legacy integration in the documentation), we added full tensorboard integration (visualisation of the graph, learning curves and more).", "To enable tensorboard logging, you just need to fill the tensorboard_log argument with a valid path:", "You can define a custom callback function that will be called inside the agent. This could be useful when you want to monitor training, for instance display live learning curves in Tensorboard (or in Visdom) or save the best agent.", "Associated notebook (includes plotting): try it online!", "Training a RL agent on Atari games is straightforward thanks to make_atari_env helper function. It will do all the preprocessing and multiprocessing for you.", "Normalizing input features may be essential to successful training of an RL agent (by default, images are scaled but not other types of input), for instance when training on Mujoco. For that, a wrapper exists and will compute a running average and standard deviation of input features (it can do the same for rewards).", "Note: we cannot provide a notebook for this example because Mujoco is a proprietary engine and requires a license.", "Stable baselines provides default policy networks for images (CNNPolicies) and other type of inputs (MlpPolicies). However, you can also easily define a custom architecture for the policy network:", "You can also move from learning on one environment to another for continual learning (PPO2 on DemonAttack-v0, then transferred on SpaceInvaders-v0):", "We presented Stable Baselines, a fork that aims at making Reinforcement Learning accessible to a broad audience. We simplified and unified the different algorithms and provide now a scikit-learn like interface for experimenting with RL.", "To any interested in making the baselines better, there is still some documentation that needs to be done. So feel free to create issues and make pull requests on the repository.", "Current WIP: adding support for continuous actions for ACER/ACKTR", "This article was co-written with Ashley hill.", "Stable Baselines was created in the robotics lab U2IS (INRIA Flowers team) at ENSTA ParisTech.", "This work is supported by the DREAM project through the European Union Horizon 2020 FET research and innovation program under grant agreement No 640891.", "We are both doing research in Reinforcement Learning for robotics. The focus of our research is in State Representation Learning (feature extraction for RL). In our part time, we like to do experiments on DIY projects, for instance building an autonomous racing car.", "PS: How to make a gif of a trained agent ?", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Research Engineer in Robotics and Machine Learning https://araffin.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdf87c4b2fc82&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@araffin?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@araffin?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Antonin RAFFIN"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2409d35123af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&user=Antonin+RAFFIN&userId=2409d35123af&source=post_page-2409d35123af----df87c4b2fc82---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines"}, {"url": "https://github.com/DLR-RM/stable-baselines3", "anchor_text": "https://github.com/DLR-RM/stable-baselines3"}, {"url": "http://stable-baselines.readthedocs.io/", "anchor_text": "http://stable-baselines.readthedocs.io/"}, {"url": "https://github.com/araffin/rl-baselines-zoo", "anchor_text": "https://github.com/araffin/rl-baselines-zoo"}, {"url": "https://github.com/araffin/rl-tutorial-jnrr19", "anchor_text": "https://github.com/araffin/rl-tutorial-jnrr19"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "hill-a/stable-baselinesstable-baselines - A fork of OpenAI Baselines, implementations of reinforcement learning algorithmsgithub.com"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "try it online"}, {"url": "https://github.com/openai/baselines/issues/285", "anchor_text": "#285"}, {"url": "https://github.com/openai/baselines/issues/400", "anchor_text": "#400"}, {"url": "https://github.com/openai/baselines/issues/413", "anchor_text": "#413"}, {"url": "https://github.com/openai/baselines/issues/445", "anchor_text": "#445"}, {"url": "https://www.reddit.com/r/MachineLearning/comments/7l23y8/d_is_it_me_or_can_openai_baselines_be_difficult/", "anchor_text": "Reddit"}, {"url": "https://arxiv.org/abs/1709.06560", "anchor_text": "Deep reinforcement learning that matters"}, {"url": "https://github.com/openai/baselines/pull/490", "anchor_text": "improving their baselines"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "README"}, {"url": "https://arxiv.org/abs/1802.04181", "anchor_text": "state representation learning"}, {"url": "https://worldmodels.github.io/", "anchor_text": "world models"}, {"url": "https://pathak22.github.io/large-scale-curiosity/", "anchor_text": "Curiosity-Driven learning"}, {"url": "https://github.com/hill-a/stable-baselines/releases", "anchor_text": "fix some issues"}, {"url": "https://github.com/openai/baselines/commit/4993286230ac92ead39a66005b7042b56b8598b0", "anchor_text": "previous bug fix from OpenAI"}, {"url": "https://github.com/openai/baselines/commit/9fa8e1baf1d1f975b87b369a8082122eac812eb1", "anchor_text": "new commits"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "basic usage"}, {"url": "https://github.com/araffin/rl-tutorial-jnrr19", "anchor_text": "Full Tutorial"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "Getting Started"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb", "anchor_text": "Training, Saving, Loading"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/multiprocessing_rl.ipynb", "anchor_text": "Multiprocessing"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/monitor_training.ipynb", "anchor_text": "Monitor Training and Plotting"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/atari_games.ipynb", "anchor_text": "Atari Games"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb", "anchor_text": "try it online"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/multiprocessing_rl.ipynb", "anchor_text": "try it online"}, {"url": "https://stable-baselines.readthedocs.io/en/master/guide/tensorboard.html", "anchor_text": "legacy integration"}, {"url": "https://gist.github.com/araffin/ee9daee110af3b837b0e3a46a6bb403b", "anchor_text": "https://gist.github.com/araffin/ee9daee110af3b837b0e3a46a6bb403b"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/monitor_training.ipynb", "anchor_text": "try it online"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/atari_games.ipynb", "anchor_text": "try it online"}, {"url": "https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/", "anchor_text": "all the preprocessing"}, {"url": "http://www.mujoco.org/", "anchor_text": "Mujoco"}, {"url": "https://www.continualai.com/", "anchor_text": "continual learning"}, {"url": "https://medium.com/u/68d764aba302?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Ashley hill"}, {"url": "http://u2is.ensta-paristech.fr/index.php?lang=en", "anchor_text": "robotics lab U2IS"}, {"url": "https://flowers.inria.fr/", "anchor_text": "INRIA Flowers"}, {"url": "http://www.ensta-paristech.fr/en", "anchor_text": "ENSTA ParisTech"}, {"url": "http://www.robotsthatdream.eu", "anchor_text": "DREAM project"}, {"url": "https://medium.com/@araffin/autonomous-racing-robot-with-an-arduino-a-raspberry-pi-and-a-pi-camera-3e72819e1e63", "anchor_text": "building an autonomous racing car"}, {"url": "https://github.com/araffin/rl-tutorial-jnrr19", "anchor_text": "Full Tutorial"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/stable_baselines_getting_started.ipynb", "anchor_text": "Getting Started"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb", "anchor_text": "Training, Saving, Loading"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/multiprocessing_rl.ipynb", "anchor_text": "Multiprocessing"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/monitor_training.ipynb", "anchor_text": "Monitor Training and Plotting"}, {"url": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/atari_games.ipynb", "anchor_text": "Atari Games"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----df87c4b2fc82---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----df87c4b2fc82---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----df87c4b2fc82---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/research?source=post_page-----df87c4b2fc82---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/tag/openai?source=post_page-----df87c4b2fc82---------------openai-----------------", "anchor_text": "OpenAI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&user=Antonin+RAFFIN&userId=2409d35123af&source=-----df87c4b2fc82---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&user=Antonin+RAFFIN&userId=2409d35123af&source=-----df87c4b2fc82---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdf87c4b2fc82&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----df87c4b2fc82---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----df87c4b2fc82--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@araffin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@araffin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Antonin RAFFIN"}, {"url": "https://medium.com/@araffin/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "449 Followers"}, {"url": "https://araffin.github.io/", "anchor_text": "https://araffin.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2409d35123af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&user=Antonin+RAFFIN&userId=2409d35123af&source=post_page-2409d35123af--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbf4aff8f2752&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82&newsletterV3=2409d35123af&newsletterV3Id=bf4aff8f2752&user=Antonin+RAFFIN&userId=2409d35123af&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}