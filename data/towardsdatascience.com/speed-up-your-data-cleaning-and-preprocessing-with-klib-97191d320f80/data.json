{"url": "https://towardsdatascience.com/speed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80", "time": 1683011991.425374, "path": "towardsdatascience.com/speed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80/", "webpage": {"metadata": {"title": "Speed up your data cleaning & preprocessing with klib | Towards Data Science", "h1": "Speed up your Data Cleaning and Preprocessing with klib", "description": "Speed up your data cleaning and preprocessing, assess data quality, gain insight and create helpful visualizations using virtually any DataFrame with klib"}, "outgoing_paragraph_urls": [{"url": "https://github.com/akanz1/klib", "anchor_text": "klib", "paragraph_index": 0}, {"url": "https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016", "anchor_text": "NFL Dataset", "paragraph_index": 6}, {"url": "https://github.com/akanz1/klib/blob/master/examples/NFL_DATASET.csv", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://github.com/akanz1/klib", "anchor_text": "GitHub", "paragraph_index": 24}], "all_paragraphs": ["TL;DRThe klib package provides a number of very easily applicable functions with sensible default values that can be used on virtually any DataFrame to assess data quality, gain insight, perform cleaning operations and visualizations which results in a much lighter and more convenient to work with Pandas DataFrame.", "Over the past couple of months I\u2019ve implemented a range of functions which I frequently use for virtually any data analysis and preprocessing task, irrespective of the dataset or ultimate goal.", "These functions require nothing but a Pandas DataFrame of any size and any datatypes and can be accessed through simple one line calls to gain insight into your data, clean up your DataFrames and visualize relationships between features. It is up to you if you stick to sensible, yet sometimes conservative, default parameters or customize the experience by adjusting them according to your needs.", "This package is not meant to provide an Auto-ML style API. Rather it is a collection of functions which you can \u2014 and probably should \u2014 call every time you start working on a new project or dataset. Not only for your own understanding of what you are dealing with, but also to produce plots you can show to supervisors, customers or anyone else looking to get a higher level representation and explanation of the data.", "Alternatively, to install with conda run:", "What follows is a workflow and set of best practices which I repeatedly apply when facing new datasets.", "The data used in this guide is a slightly truncated version of the NFL Dataset found on Kaggle. You can download it here or use any arbitrary data you want to follow along.", "Determining data quality before starting to work on a dataset is crucial. A quick way to achieve that is to use the missing value visualization of klib, which can be called as easy as follows:", "This single plot already shows us a number of important things. Firstly, we can identify columns where all or most of the values are missing. These are candidates for dropping, while those with fewer missing values might benefit from imputation.", "Secondly, we can often times see patterns of missing rows stretching across many features. We might want to eliminate them first before thinking about dropping potentially relevant features.", "And lastly, the additional statistics at the top and the right side give us valuable information regarding thresholds we can use for dropping rows or columns with many missing values. In our example we can see that if we drop rows with more than 30 missing values, we only lose a few entries. At the same time, if we eliminate columns with missing values larger than 80% the four most affected columns are removed.", "A quick note on performance: Despite going through about 2 million entries with 66 features each, the plot takes only seconds to create.", "With this insight, we can go ahead and start cleaning the data. With klib this is as simple as calling klib.data_cleaning(), which performs the following operations:", "You can change the verbosity of the output using the parameter show=None, show=\u201dchanges\u201d or show=\u201dall\u201d. Please note that the memory reduction indicates a very conservative value (i.e. less reduction than is actually achieved), as it only performs a shallow memory check. A deep memory analysis slows down the function for larger datasets but if you are curious about the \u201ctrue\u201d reduction in size you can use the df.info() method as shown below.", "As we can see, pandas assigns 64 bits of storage for each float and int. Additionally, 21 columns are of type \u201cobject\u201d, which is a rather inefficient way to store data. After data cleaning, the memory usage drops to only 58.4 MB, a reduction of almost 80%! This is achieved by converting, where possible, float64 to float32, and int64 to int8. Also, the dtypes string and category are utilized. The available parameters such as convert_dtypes, category, cat_threshold and many more allow you to tune the function to your needs.", "Lastly, we take a look at the column names, which were actually quite well formatted in the original dataset already. However, after the cleaning process, you can rely on lowercase and underscore-connected column names. While not advisable to avoid ambiguity, this now allows you to use df.yards_gained instead of df[\u201cYards.Gained\u201d], which can be really useful when doing quick lookups or when exploring the data for the first time.", "Ultimately, and to sum it all up: we find that not only have the column names been neatly formatted and unified, but also that the features have been converted to more efficient datatypes. With the relatively milde default settings, only 123 rows and 4 columns, of which one column was singled valued, have been eliminated. This leaves us with a lightweight DataFrame of shape: (183337, 62) and 58 MB memory usage.", "Once the initial data cleaning is done, it makes sense to take a look at the relationships between the features. For this we employ the function klib.corr_plot(). Setting the split parameter to \u201cpos\u201d, \u201cneg\u201d, \u201chigh\u201d or \u201clow\u201d and optionally combining each setting with a threshold, allows us to dig deeper and highlight the most important aspects.", "At a glance, we can identify a number of interesting relations. Similarly, we can easily zoom in on correlations above any given threshold, let\u2019s say |0.5|. Not only does this allow us to spot features which might be causing trouble later on in our analysis, it also shows us that there are quite a few highly negatively correlated features in our data. Given sufficient domain expertise, this can be a great starting point for some feature engineering!", "Further, using the same function, we can take a look at the correlations between features and a chosen target. The target column can be supplied as a column name of the current DataFrame, as a separate pd.Series, a np.ndarry or simply as a list.", "Just as before it is possible to use a wide range of parameters for customizations, such as removing annotations, changing the correlation method or changing the colormap to match your preferred style or corporate identity.", "In a last step in this guide, we take a quick look at the capabilities to visualize categorical columns. The function klib.cat_plot() allows to display the top and/or bottom values regarding their frequency in each column. This gives us an idea of the distribution of the values in the dataset what is very helpful when considering to combine less frequent values into a seperate category before applying one-hot-encoding or similar functions. In this example we can see that for the column \u201cplay_type\u201d roughly 75% of all entries are made up of the three most frequent values. Further, we can immediately see that \u201cPass\u201d and \u201cRun\u201d are by far the most frequent values (75k and 55k). Conversely, the plot also shows us that \u201cdesc\u201d is made up of 170384 unique strings.", "The klib package includes many more helpful functions for data analysis and cleaning, not to mention some customized sklearn pipelines, which you can easily stack together using a FeatureUnion and then use with in GridSearchCV or similar. So if you intend to take a shortcut, simply call klib.data_cleaning() and plug the resulting DataFrame into that pipeline. Likely, you will already get a very decent result!", "All of these functions make for a very convenient data cleaning and visualization and come with many more features and settings than described here. They are by no means a one fits all solution but they should be very helpful in your data preparation process. klib also includes various other functions, most notably pool_duplicate_subsets(), to pool subsets of the data across different features as a means of dimensionality reduction, dist_plot(), to visualize distributions of numerical features, as well as mv_col_handling(), which provides a sophisticated 3-step process, attempting to identify any remaining information in columns with many missing values, instead of simply dropping them right away.", "Note: Please let me know what you would like to see next and which functions you feel are missing, either in the comments below or by opening an issue on GitHub. Also let me know if you would like to see some examples on the handling of missing values, subset pooling or the customized sklearn pipelines.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F97191d320f80&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----97191d320f80--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@akanz?source=post_page-----97191d320f80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akanz?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Andreas Kanz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F814f785be4f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&user=Andreas+Kanz&userId=814f785be4f7&source=post_page-814f785be4f7----97191d320f80---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/akanz1/klib", "anchor_text": "klib"}, {"url": "https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016", "anchor_text": "NFL Dataset"}, {"url": "https://github.com/akanz1/klib/blob/master/examples/NFL_DATASET.csv", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/data-preparation-with-klib-ec4add15303a", "anchor_text": "Data preparation with klibFast and simple function calls for efficient data preparationtowardsdatascience.com"}, {"url": "https://github.com/akanz1/klib", "anchor_text": "GitHub"}, {"url": "https://medium.com/tag/pandas?source=post_page-----97191d320f80---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----97191d320f80---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/data-science?source=post_page-----97191d320f80---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-cleaning?source=post_page-----97191d320f80---------------data_cleaning-----------------", "anchor_text": "Data Cleaning"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----97191d320f80---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&user=Andreas+Kanz&userId=814f785be4f7&source=-----97191d320f80---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&user=Andreas+Kanz&userId=814f785be4f7&source=-----97191d320f80---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----97191d320f80--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F97191d320f80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----97191d320f80---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----97191d320f80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----97191d320f80--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----97191d320f80--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----97191d320f80--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----97191d320f80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akanz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@akanz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andreas Kanz"}, {"url": "https://medium.com/@akanz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "131 Followers"}, {"url": "https://github.com/akanz1/klib", "anchor_text": "https://github.com/akanz1/klib"}, {"url": "https://www.linkedin.com/in/akanz/", "anchor_text": "https://www.linkedin.com/in/akanz/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F814f785be4f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&user=Andreas+Kanz&userId=814f785be4f7&source=post_page-814f785be4f7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F118202ced2a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80&newsletterV3=814f785be4f7&newsletterV3Id=118202ced2a5&user=Andreas+Kanz&userId=814f785be4f7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}