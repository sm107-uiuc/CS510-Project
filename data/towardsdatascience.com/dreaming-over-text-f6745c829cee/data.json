{"url": "https://towardsdatascience.com/dreaming-over-text-f6745c829cee", "time": 1683012845.373715, "path": "towardsdatascience.com/dreaming-over-text-f6745c829cee/", "webpage": {"metadata": {"title": "Dreaming over text!. Extending the idea of Deep Dream to\u2026 | by Shivam Kaushik | Towards Data Science", "h1": "Dreaming over text!", "description": "Let us assume we want to check what happens when we increase the highlighted neuron activation h_{i,j}, and we want to reflect these changes onto input image when we increase these activations. That\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1409.4842.pdf", "anchor_text": "InceptionNet", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Inception", "anchor_text": "movie", "paragraph_index": 1}, {"url": "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/mythrex/02f9d3b8575910943b89d9964e7fde56/raw/85e1d59d26662d8166d1fd0edeb2fc7d409f674a/Deep%2520dream%2520text%2520embeddings", "anchor_text": "Try Embeddings here", "paragraph_index": 26}, {"url": "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/mythrex/f91d5aafd9dd5147784704a8ff295655/raw/c8389eee91ae2e3a05ac113296b58ddb699b85a5/Deep%2520dream%2520text%2520embeddings%2520negative", "anchor_text": "Try Embeddings here", "paragraph_index": 33}, {"url": "https://colab.research.google.com/github/mythrex/deep_dream_textual_data/blob/master/demo.ipynb#scrollTo=DiFimXLc-FK_", "anchor_text": "demo in this notebook", "paragraph_index": 51}, {"url": "https://github.com/mythrex/deep_dream_textual_data", "anchor_text": "my Github Repo", "paragraph_index": 52}], "all_paragraphs": ["\u201cDeepDream is an experiment that visualizes the patterns learned by a neural network. Similar to when a child watches clouds and tries to interpret random shapes, DeepDream over-interprets and enhances the patterns it sees in an image.", "It does so by forwarding an image through the network, then calculating the gradient of the image with respect to the activations of a particular layer. The image is then modified to increase these activations, enhancing the patterns seen by the network, and resulting in a dream-like image. This process was dubbed \u201cInceptionism\u201d (a reference to InceptionNet, and the movie Inception).\u201d", "Let me break it down for you. Consider a Convolutional Neural Network.", "Let us assume we want to check what happens when we increase the highlighted neuron activation h_{i,j}, and we want to reflect these changes onto input image when we increase these activations.", "In other words, we are optimizing image so that neuron h_{i,j} fires more.", "We can pose this optimization problem as:", "That is, we need to maximize the square norm (in simple words magnitude), of h_{i,j} by changing image.", "Here is what happens when we do as said above.", "The reason here is that, when the CNN was trained, the neuron in intermediate layers learned to see some patterns(here dog faces). When we increased those activations, the input image started containing more and more dog faces, to maximize the activations.", "Like deep dream in the image, what if we take any hidden layer activation and try to increase its norm, what will happen to the text input?To answer this, a text-classification model was taken and loss function was set-up to increase the magnitude of the hidden layer\u2019s activation.We would expect to see the patterns/representation learned by this hidden layer.", "The neural network model cannot understand words. To feed words as input, these words are converted to a n-dimensional array of numbers called embeddings. Each word is converted to specific n-dimensional array. To get embedding of sentence we simply take mean of sentences and then this array is fed as input to model. This method solves the issue of variable length of sentence and can work with vanilla Artificial Neural Network.", "A model trained to classify IMDB reviews was used. The model achieved validation accuracy of 80.10%.", "The experiment was set up to capture the representation given by Fully Connected layer 2 or FC2 in short with 512 dimensions.", "The cost function used was the norm of fc2 output.", "Note: Because \u201cSequence of Words\u201d are long tensors, they cannot be optimized by back-propagation. Instead, embedding representation of sentence was optimized.", "Step 1: Convert sentence to tensors.", "Step 2: Get the sentence embeddings.", "Step 3: Pass through the fc2 layer, and get the fc2 output.", "Step 4: Optimize the sentence embeddings to increase fc2 layer output.", "Step 5: Repeat step 2 to step 4 with the current sentence embeddings for a given number of iteration.", "Simple sentences were used to get classification results and their corresponding sentence embedding we saved.", "For example: \u201cI hate this.\u201d , \u201cI love this show.\u201d, we used to classify. These sentences are very simple and convey a negative and positive emotion respectively.", "Dreaming or optimization over these embeddings was done and a graph of activation over iteration was recorded.", "There are a couple of things that can be observed here.", "For the sentence: \u201cI love this show.\u201d. The model correctly predicts this as positive.", "Initially sentence embedding as more similar to neutral words like \u201cthis, it, even same\u201d but as we increased the magnitude of the fc2 activations, the sentence embedding became similar to positive words like \u201cgreat, unique\u201d, which makes sense, as the model predicted it a positive sentence. Visualizing embeddings over iterations.", "Try Embeddings here on Tensorflow Projector", "Observe how sentence embedding starts from step_1 and move to step_21. The sentence embedding started in between positive and negative words and as algorithm dreams, the embedding move towards positive words.", "For the sentence: \u201cI hate this\u201d. The model correctly predicts this as negative.", "First, we observe what are the words similar (cosine similarity) to the sentence embeddings before and after dreaming.", "Initially, sentence embedding as more similar to neutral words like \u201cthis, it, even, same\u201d but as we increased the magnitude of the fc2 activations, the sentence embedding became similar to words like \u201cbad, nothing, worse\u201d which convey a negative meaning, which it makes sense, as the model predicted it a negative sentence.", "To visualize embeddings over iteration, TSNE algorithm was used to reduce the embedding dimension from 100 to 2. These embeddings were plotted on a 2d map with red dots as negative words(like a bad, worse, mean, mistake) and green dots as positive words(like great, celebrated, wonderful).", "Grey dots are intermediate locations of sentence embedding and the black dot is the final location of sentence embedding.", "Try Embeddings here on Tensorflow Projector", "The graph clearly shows that embeddings got away from positive words and got near negative words and this is in tune with the model prediction. Moreover, the final sentence embedding is now more similar to red dots(negative words) than green dots(positive words).", "The key observation here is that initially, the sentence embedding was in between positive and negative words, but as dreaming progresses the embeddings were pushed away from negative words.", "The word embeddings after dreaming become similar to the words in `model prediction`, though if we look at similar words of initial embeddings, they were more or less same for the two sentences even when they were conveying very different meanings, final sentence embedding showed some interesting patterns.", "1. negative prediction was pushed near to words like mistake, dirty, bad", "2. positive prediction was pushed near to words like unique, great, celebrated", "We will use difficult sentences now. Sentences which convey one emotion in the first half but change the sentiment in the second half.", "These sentences are difficult for a human to judge what kind of emotion they convey.", "Again we will optimize the sentence embeddings, to maximize activations in fc2 layer.", "Unlike the first case. Activations of the two sentences don\u2019t diverge much, i.e. activations for these sentence are more or less similar, this means there is no classifying power of the model for these sentences.Let\u2019s look at the nearby words of these sentences before and after dreaming.", "For sentence: \u201cThe show was very long and boring but the direction was really amazing.\u201d, the model predicted positive", "We will find words similar to initial vs final sentence embedding.", "Hmm, even though the sentence was classified as positive, the words similar to final sentence embedding don\u2019t reflect any positive sentiment.", "For sentence: \u201cI hated the show because of nudity but the acting was really classy.\u201d, the model predicted negative", "The sentence was classified as negative, the embeddings after dreaming reflect negative sentiment.", "Because the model had no clear understanding of these sentences, the sentence embedding of these two sentences after dreaming are almost similar(look at similar words after dreaming). This is because model does not have a rich representation of these sentences in its hidden layers.", "We started by looking at how deep dream on images work, then we proposed how we can implement deep dream over text. Finally, we have shown how to correctly interpret the results. This method can be used to understand what kind of hidden representation the language model has learnt.", "Experiments like these help us understand these black boxes better.", "You can try a demo in this notebook.", "All the related code is available at my Github Repo.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff6745c829cee&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f6745c829cee--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shivam.kaushik73?source=post_page-----f6745c829cee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivam.kaushik73?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Shivam Kaushik"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F396d46fdd644&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&user=Shivam+Kaushik&userId=396d46fdd644&source=post_page-396d46fdd644----f6745c829cee---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1409.4842.pdf", "anchor_text": "InceptionNet"}, {"url": "https://en.wikipedia.org/wiki/Inception", "anchor_text": "movie"}, {"url": "https://www.tensorflow.org/tutorials/generative/deepdream", "anchor_text": "https://www.tensorflow.org/tutorials/generative/dee"}, {"url": "http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf", "anchor_text": "LeNet-5 Architecture"}, {"url": "https://www.tensorflow.org/tutorials/generative/deepdream", "anchor_text": "Tensorflow Tutorial"}, {"url": "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/mythrex/02f9d3b8575910943b89d9964e7fde56/raw/85e1d59d26662d8166d1fd0edeb2fc7d409f674a/Deep%2520dream%2520text%2520embeddings", "anchor_text": "Try Embeddings here"}, {"url": "https://projector.tensorflow.org/?config=https://gist.githubusercontent.com/mythrex/f91d5aafd9dd5147784704a8ff295655/raw/c8389eee91ae2e3a05ac113296b58ddb699b85a5/Deep%2520dream%2520text%2520embeddings%2520negative", "anchor_text": "Try Embeddings here"}, {"url": "https://colab.research.google.com/github/mythrex/deep_dream_textual_data/blob/master/demo.ipynb#scrollTo=DiFimXLc-FK_", "anchor_text": "demo in this notebook"}, {"url": "https://github.com/mythrex/deep_dream_textual_data", "anchor_text": "my Github Repo"}, {"url": "http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf", "anchor_text": "Gradient-Based Learning Applied to DocumentRecognition"}, {"url": "https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html", "anchor_text": "https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html"}, {"url": "https://www.tensorflow.org/tutorials/generative/deepdream", "anchor_text": "https://www.tensorflow.org/tutorials/generative/deepdream"}, {"url": "https://youtu.be/YHAIrwRVvWg?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT", "anchor_text": "https://youtu.be/YHAIrwRVvWg?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT"}, {"url": "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html", "anchor_text": "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"}, {"url": "https://medium.com/tag/deeplearning?source=post_page-----f6745c829cee---------------deeplearning-----------------", "anchor_text": "Deeplearning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f6745c829cee---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deepdream?source=post_page-----f6745c829cee---------------deepdream-----------------", "anchor_text": "Deepdream"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----f6745c829cee---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&user=Shivam+Kaushik&userId=396d46fdd644&source=-----f6745c829cee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&user=Shivam+Kaushik&userId=396d46fdd644&source=-----f6745c829cee---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff6745c829cee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f6745c829cee---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f6745c829cee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f6745c829cee--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f6745c829cee--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f6745c829cee--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f6745c829cee--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivam.kaushik73?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivam.kaushik73?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shivam Kaushik"}, {"url": "https://medium.com/@shivam.kaushik73/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "23 Followers"}, {"url": "http://github.com/mythrex", "anchor_text": "github.com/mythrex"}, {"url": "http://linkedin.com/in/shivamkaushik73/", "anchor_text": "linkedin.com/in/shivamkaushik73/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F396d46fdd644&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&user=Shivam+Kaushik&userId=396d46fdd644&source=post_page-396d46fdd644--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1c4deeb12581&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdreaming-over-text-f6745c829cee&newsletterV3=396d46fdd644&newsletterV3Id=1c4deeb12581&user=Shivam+Kaushik&userId=396d46fdd644&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}