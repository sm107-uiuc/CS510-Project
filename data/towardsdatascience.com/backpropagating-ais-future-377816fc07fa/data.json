{"url": "https://towardsdatascience.com/backpropagating-ais-future-377816fc07fa", "time": 1682997102.916747, "path": "towardsdatascience.com/backpropagating-ais-future-377816fc07fa/", "webpage": {"metadata": {"title": "Backpropagating AI\u2019s future. A comprehensible primer on exploring\u2026 | by Siddharth Srivastava | Towards Data Science", "h1": "Backpropagating AI\u2019s future", "description": "Discussing key issues in developing future AI systems, considering ethics, biases and safety; also realizing that today is closer to the future than we think."}, "outgoing_paragraph_urls": [{"url": "https://www.amazon.in/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111", "anchor_text": "Superintelligence", "paragraph_index": 5}, {"url": "https://www.amazon.in/Life-3-0-Being-Artificial-Intelligence/dp/1101946598", "anchor_text": "Life 3.0", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Joseph_Weizenbaum", "anchor_text": "Weizenbaum", "paragraph_index": 13}, {"url": "https://www.youtube.com/watch?v=fBVCFcEBKLM", "anchor_text": "Google\u2019s demo", "paragraph_index": 14}, {"url": "https://www.amazon.com/Hello-World-How-Human-Machine/dp/0857525247", "anchor_text": "Hello World", "paragraph_index": 14}, {"url": "https://www.theguardian.com/technology/2019/mar/28/big-tech-ai-ethics-boards-prejudice", "anchor_text": "examples", "paragraph_index": 31}, {"url": "https://www.amazon.com/Computer-Power-Human-Reason-Calculation/dp/0716704633", "anchor_text": "Computer Power and Human Reason \u2014 Joseph Weizenbaum", "paragraph_index": 50}, {"url": "https://www.amazon.com/AI-Nature-Future-Margaret-Boden/dp/0198777981", "anchor_text": "AI: Its nature and its future \u2014 Margaret A. Boden", "paragraph_index": 50}, {"url": "http://www.sidsrivastava.me", "anchor_text": "www.sidsrivastava.me", "paragraph_index": 52}], "all_paragraphs": ["Artificial Intelligence is a challenge first and foremost, in every sense of the word. Technologically, ethically, economically, we have never faced a disruption like this ever before in the history of mankind. It makes sense to explore where this will lead us and where we are today, and try to make a roadmap of where to go from here.", "In Part 1, I present some of the current arguments for what AI\u2019s future will look like, its philosophical implications and the far-fetched.In Part 2, I backpropagate all the way to today and have a more technical discussion about where AI Research is, where it\u2019s heading and what the key issues are.", "Machines today aren\u2019t intelligent/smart (or any other synonym you can think of) in the way you think they are. In fact they aren\u2019t even close. The promise of Terminators and I, Robots (AI cliche #1) is misplaced.", "Computers need A LARGE amount of data to learn anything, and even then they don\u2019t always generalize well. Imagine calling a 5 year-old, intelligent \u2014 who had to see 10,000 images of cats before understanding what a cat looked like. I wouldn\u2019t open a college fund for him. I would also not recommend taking out the time to show anyone 10,000 images of your cats.", "This is not what the future of AI will look like. In the future, artificial agents would be able to generalize almost effortlessly with minimal (or no) data. This is called Artificial General Intelligence, and it will understand or learn any intellectual task that a human can, much better than us, now that you think of it.", "Nick Bostrom\u2019s, thought-provoking book \u2014 Superintelligence presents the concept of an Artificial Super Intelligence (ASI) that will supersede AGI by a good margin, and then some more. Let\u2019s get our hands dirty (with robot oil am I right) and see what all this means.", "These artificial agents would not only be implementable on a computer, but any virtual machine that we come up with (Some researchers also argue, that our mind is a virtual machine too). Needless to say, we have found the most pervasive technology in all of human history. Not only will this be the most advanced technology ever created, it would be an entirely new being \u2014 Life 3.0 as Max Tegmark calls it, in his book of the same name. What moral status do these new beings have?", "Principle of Substrate Non-Discrimination:If two beings have the same functionality and the same conscious experience,and differ only in the substrate of their implementation, then they have thesame moral status.\u00b9", "It wouldn\u2019t matter if I\u2019m carbon and my new AI friend is silicon, just like my skin colour doesn\u2019t matter. Bostrom et al.\u00b9 argue that substrate lacks any moral significance, hence these agents would have the same moral status as us.", "Here\u2019s the problem with moral debates regarding AI: unless moral philosophers can provide an impeccable framework for morality and ethics, all debates would be unfruitful. This job is innately and recursively difficult, and has far-reaching consequences. An AI\u2019s utility function could allow for potential harm, biases and global catastrophes, simply because common sense and ethics cannot be formalized into a language that these agents can understand.", "The moral discussion is important because it\u2019s likely that these beings would be so powerful, that they would be indistinguishable from the concept of a God. An \u201cIntelligence Explosion\u201d could take place as soon as we achieve general intelligence with just one machine. Any agent that is sufficiently intelligent, could enter the loop of self-improvement till it gets out of our human hands.", "Let\u2019s talk about what happens when these beings begin to live between us.", "The leading argument against AI indubitably, is that they\u2019re going to take our jobs. The counter-argument is even if they do, we would be freed to spend our time on meaningful things, avoid all mechanical work and cringe at the fact someday, that ancient humans spent the majority of their lives working on unnecessary, back-breaking, dangerous things.", "Weizenbaum argued that AI should not be used to replace people in positions that require respect and care, such as any of these\u00b2:", "AI is being used in almost all these professions, profusely. Google\u2019s demo of their assistant booking an appointment is a hint to AI\u2019s future dominance in all jobs involving human conversation (therapy, customer service etc). Hannah Fry\u2019s book, Hello World demonstrates many examples of AI being implemented as judges, doctors and discusses issues with this. AI has also proved its mettle in domains like art and music, which was the last thing anybody could have predicted a 100 years ago.", "Jobs and wages are provided on the basis of a person\u2019s contribution to society and is directly proportional (usually) to the difficulty of the problem a person solves. What happens when an effortlessly intelligent being steps up?There are scant reasons why our jobs wouldn\u2019t go to them, and almost none are rational. This needn\u2019t be a bad thing at all, economists and technologists suggest that with these jobs going to AI agents, new jobs will open up for humans, the nature of which we can\u2019t even predict. Looks like you can show 10,000 images of your cats to people after all.", "It\u2019s very difficult to predict what will happen and it\u2019s not wise to extrapolate from past trends, as the rise of true AI is an unprecedented and highly uncertain trend.", "AI is potentially dangerous, not because it\u2019s going to inhabit the body of Arnold Schwarzenegger to unleash their wrath, but simply because they don\u2019t want to. They have no motivation or goals that could instigate them to do such a thing (OR DO THEY). That brings us to the actual danger, what happens when AI\u2019s goals aren\u2019t aligned with ours, and how do we ensure that this does not happen.", "By the very nature of being an intelligent being, we learn to make our decisions on our own, considering our survival and advancement. No AI system today has any goals, although they spit out decisions every second. They are finely tuned to a specific domain restricted task and are completely oblivious to anything other than what they\u2019ve already seen millions of times. It\u2019s possible for these agents to decide something, without the presence of any internal representation of a goal, they do that today billions of times. But it\u2019s hard to imagine a general intelligent being with no goals; even a 2 year old has goals. It makes sense to ask for transparent goals in AGI systems, for fail-safe if nothing else. But as mentioned previously, an intelligence explosion could get out of hand fast and we wouldn\u2019t know or have any tool to interpret the goals of these silicon brains. It\u2019s imperative to tackle this issue before any such advanced machine is even in the making.", "Creativity is perhaps our biggest strength and our most valuable asset, probably in the argument against AI too. They might be able to do a billion calculations per second BUT CAN THEY DRAW THIS", "Recognizing creativity is a difficult problem, let alone coming up with creative ideas. With the advent of Computer Generated art and Neural Style Transfer, which stirred up the Deep Learning Community, we have hints of AI\u2019s creativity in conventional domains. In these restricted domains like painting, music and playing chess, AI already has a head start, but matching human creativity in the general sense is something that we can only make assumptions about.", "Another thing, that is seen as alien when we mention AI is, emotion. AI systems can fake emotions very well (think chatbots). They have recently begun to write beautifully (Open GPT-2) and talk like humans. I say fake emotions because there is no internal representation of any emotions in these algorithms, yet they spit out magnificent pieces of writing, paintings and music. Here\u2019s a kicker: Some researchers argue that feelings like anxiety would also need to be included and used\u00b3 in making AGI systems, it makes sense because our decision making stems not only from our feelings, which we take for emotion, but also functional and phenomenal consciousness and past history; these things enable us to schedule and prioritize motives in our lives \u2014 something that we want to pass on to our intelligent overlords.", "There is a general consensus about what AI\u2019s future will look like, although nobody agrees on the details of it.", "It\u2019s important to be optimistic, imaginative but also skeptical of every piece of information. Trying to predict the future has never worked out very well in the past, and extrapolating extravagantly is even worse. Glaringly obvious facts and their inevitable consequences can lead us astray in the future as everything today is transient and could well turn out to be wrong in the first place. I haven\u2019t discussed a lot of major issues (The Trolley Problem, The problem of Consciousness and qualia, Robot rights etc) but this is indeed a starting point to get your feet wet with some of the key issues in AI ethics, safety and its impact on all of us (Spoiler: it\u2019ll affect us a lot more than just recommending movies and products).", "AI agents will remember what topping I liked on my ice cream, what my favourite movie is, who am I talking with the most and what I have forgotten. They\u2019re continuously taking away our need to perform any mental computation and we like it.", "We aren\u2019t the same humans like our grandparents were, technology has already become an extension of us; we\u2019re cyborgs already, and AI is the next chapter of the revolution.", "It\u2019s important to think critically about whether all this is an actual possibility or have all of us grossly overestimated Alexa. In Part 2, I attempt to explore what is already true, where we\u2019re heading and what happened to the cat images.", "Referring to AI today means referring to either Machine Learning or Deep Learning (or Neural Networks), both of which are subsets of Artificial Intelligence. The underlying principle behind both the classes of algorithms is simple: to solve any problem, you require sufficient examples of the problem being solved \u2014 labelled data, giving us the features and the answer for a question (supervised learning), and we hope that using the features we\u2019ve extracted for a problem, we get a good prediction out of our system. By comparing our prediction with the correct answer and of course beating our computers up with a stick each time it gives a wrong answer, we adjust the parameters so that we get better outputs each time. Do this a million times maybe, for millions of parameters (or more) and we have engendered intelligence.", "Intuitively, it makes sense, you look at the image of a cat, you see feature like eyes, ears, whiskers and with enough training you understand what a cat looks like. This oversimplified version should be enough to convince you that given enough data and time, these algorithms work wonders. There are also big problems with our algorithms today. Let\u2019s look at some of those and see whether the future really is as smart as a 5 year old.", "A very subtle problem is engendered with our current approach to intelligence, by no fault of ours. All of us have inherent biases and unfortunately our machines caught up with that too.", "Computers aren\u2019t intelligent but they are extremely good pattern finders. A google search for images of doctors would reveal more than 95% of the results are of people (predominantly male) from American or English ethnicity. These kinds of biases are prevalent in our algorithms. If I train my cat classifier with only two breeds of cats, it would stop all the other cats from entering the cat cafe. Great care and attention is given to making balanced and representative datasets, but that\u2019s not the only problem.", "The problem begins with humans themselves. Majority of the people behind AI\u2019s progress and the Government representatives have been White males, whereas a problem like AI needs to be addressed by the representatives of humanity. Many examples of bias in the human factor of AI development have been observed and it\u2019s dangerous because AI is one of the most weaponize-able technologies in the world right now. If only a small group of people control it, and god forbid their intentions aren\u2019t right, the future of humanity could be very adversely affected. To the credit of AI researchers, they identified this problem very swiftly and steps are being taken to tackle such issues.", "Bias can slip in not only because of imbalanced datasets, but it can creep in much before, during the framing of problem itself.The prevalent way of coding these algorithms is to use APIs that big companies (eg: Google, Facebook) provide, needless to say if a bias is induced during that stage, it will propagate promptly.", "All\u2019s well and good as far as this is limited to cat cafes and google images, but future AI systems would be deployed in high-stakes situation like courts, job interviews and hospitals. If these biases creep in then, a lot of lives would be affected.", "Imagine an AI judge being presented with identical data about a white and black person, but only sentencing the black person to prison, because it learnt statistically that black people are more likely to be guilty. Here, framing the problem incorrectly and an imbalanced dataset could both play a role (among many other factors) in giving out a wrong or biased decision. So much for our all intelligent overlords.", "For multiple reasons, it makes sense to understand how a computer arrives at its decisions. Many people treat AI algorithms like black boxes, but recent research (eg. Bayesian networks) is opening up frontiers to figuring out why an algorithm arrived at a particular decision.", "This could also be effective against biases in these algorithms. It\u2019s imperative to develop AI in a way that it\u2019s transparent to inspection. Imagine in the future, when your AI doctor advises you to take a particular medicine, and you trust it because you don\u2019t wanna mess with Arnold Schwarzenegger. Here\u2019s the catch: Terminator is not real (it won\u2019t be in the future either) and you don\u2019t trust your AI doctor. You want to know exactly why and how it arrived at its decision, your life depends on it.", "Black boxes aren\u2019t for the long term, AGI agents would need to explain their rationale behind a decision like us humans do. This is another problem that we need to overcome without which AGI systems won\u2019t come into existence.", "What happens when our intelligent overlords are fooled? In the image above, adding a tiny amount of random noise resulted in a rather funny mis-classification, even though a 5 year old could identify the panda in this image. Turns out, this is another important weak point in our algorithms today, that a safe AGI system of the future should stay a million miles away from.", "Adversarial attacks designed by other computers, humans or simply the presence of random noise could break this sophisticated technology. Imagine, if you could place a bomb in your pocket/suitcase such that it easily fools the AI vision security system at the mall, airport or the White House. These systems would be deployed everywhere, and a sufficiently advanced AGI system should not be fooled by manipulations because of humans or computers. Robustness against adversarial attacks is an important factor to consider before we have true intelligent agents.", "A lot of optimistic promises have been made regarding AI\u2019s contribution in medicine and biology. Many argue that only an AI agent would be able to solve cancer, protein folding, genome sequencing and other challenges whose solutions are nowhere in reach. More often than not Computer Vision systems have performed exceedingly well in detecting tumors and other anomalies than radiologists.", "Your personal assistant \u2014 AGI system of the future would have your entire medical history, would have enough data about medical diseases in your locality and would have deduced the several diseases you might be prone to. This is not a difficult feat today, given adequate data and good computing power, this can be implemented right now.", "AGI systems and agents of the future might or might not be more intelligent than us, but at any given time they would have more information and better extrapolation skills than us. It could predict the outbreak of epidemics, mobilize resources and also be your personal doctor. This does not mean that human doctors won\u2019t be needed, but like many domains, a doctor\u2019s job would become exponentially easier.", "Artificial Intelligence goes beyond engineers and scientists. Many companies, start-ups, and universities have recognized the danger AI would pose, and have taken significant steps towards decentralizing it. Countries are coming up with policies and strategies to tackle AI-posed dangers and stay ahead in the world of AI.", "Contributions from everyone is required. We need to have an important conversation about which direction we want to take AI in. How do we implement it? How do we make fail-safe systems in case things go awry? What do we want our future to look like? Will it be an endless cycle of tweets and instagram posts or will it offer something more promising?", "In Part 1, I explored the philosophical implications of what the future of AI will bring with it, In this Part, I presented some areas of interest/issues and how we need to tackle them responsibly to ensure a better, meaningful, safe future, utilizing AI to its fullest.", "I conclude with a humble introspection, which has to be the first step to establish what we want for our future generations. Although Artificial Intelligence has created all the hype \u2014 today, and for the future, it\u2019s important to realize how it\u2019s already affecting society. Personalized recommendations, information retrieval at an instant, data traveling at enormous speeds, all of this is affecting us in ways that nobody could have thought of. I opined that AGI systems if not handled responsibly, without ethical and safety frameworks in place (or at least a way to induce these things in machines) would be disastrous. But it\u2019s not the future we need to worry about most, it\u2019s that we don\u2019t think about the future enough.", "We\u2019re always entertained (cannot be bored in this climate \u2014 watch me fight ants in my next Facebook exclusive), mostly living our lives on virtual platforms (Instagram eats before I touch my food), and this is the kind of future that nobody predicted 50 years ago. The Good-Story bias governs our thinking in subtle ways and gives an optimistic measure of the future, but AI technology has crept up insidiously in almost all domains of life. It\u2019s vital to think critically about where it\u2019s headed, whether we want a generation to live within virtual reality headsets and social media or do we have something else in place?", "AI has and will continue to solve major problems across innumerable domains. But while our networks get deeper, human relationships become ephemeral. It\u2019s important to be vigilant and overcome the hype to see what\u2019s actually going on, to think clearly, decide what we want and to be brave in making choices that are subtly influencing our future.", "AI is changing the world for all of us, and it\u2019s time we had this conversation as a species before things get out of hand and the 5 year old who got frustrated with you showing him pictures of your cats, ends up becoming Terminator himself. Plot twist of the century am I right?", "[1] The Ethics of Artificial Intelligence \u2014 Nick Bostrom and Eliezer Yudkowsky[2] Computer Power and Human Reason \u2014 Joseph Weizenbaum[3] AI: Its nature and its future \u2014 Margaret A. Boden", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Interested in all things tech, science, economics, and society || www.sidsrivastava.me"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F377816fc07fa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----377816fc07fa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@srivastava41099?source=post_page-----377816fc07fa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@srivastava41099?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Siddharth Srivastava"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb6459b5044&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&user=Siddharth+Srivastava&userId=bb6459b5044&source=post_page-bb6459b5044----377816fc07fa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.amazon.in/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111", "anchor_text": "Superintelligence"}, {"url": "https://www.amazon.in/Life-3-0-Being-Artificial-Intelligence/dp/1101946598", "anchor_text": "Life 3.0"}, {"url": "https://en.wikipedia.org/wiki/Joseph_Weizenbaum", "anchor_text": "Weizenbaum"}, {"url": "https://www.youtube.com/watch?v=fBVCFcEBKLM", "anchor_text": "Google\u2019s demo"}, {"url": "https://www.amazon.com/Hello-World-How-Human-Machine/dp/0857525247", "anchor_text": "Hello World"}, {"url": "https://www.theguardian.com/technology/2019/mar/28/big-tech-ai-ethics-boards-prejudice", "anchor_text": "examples"}, {"url": "https://www.amazon.com/Computer-Power-Human-Reason-Calculation/dp/0716704633", "anchor_text": "Computer Power and Human Reason \u2014 Joseph Weizenbaum"}, {"url": "https://www.amazon.com/AI-Nature-Future-Margaret-Boden/dp/0198777981", "anchor_text": "AI: Its nature and its future \u2014 Margaret A. Boden"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----377816fc07fa---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/ethics?source=post_page-----377816fc07fa---------------ethics-----------------", "anchor_text": "Ethics"}, {"url": "https://medium.com/tag/future?source=post_page-----377816fc07fa---------------future-----------------", "anchor_text": "Future"}, {"url": "https://medium.com/tag/philosophy?source=post_page-----377816fc07fa---------------philosophy-----------------", "anchor_text": "Philosophy"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----377816fc07fa---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&user=Siddharth+Srivastava&userId=bb6459b5044&source=-----377816fc07fa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&user=Siddharth+Srivastava&userId=bb6459b5044&source=-----377816fc07fa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F377816fc07fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----377816fc07fa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----377816fc07fa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----377816fc07fa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----377816fc07fa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----377816fc07fa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----377816fc07fa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@srivastava41099?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@srivastava41099?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Siddharth Srivastava"}, {"url": "https://medium.com/@srivastava41099/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "8 Followers"}, {"url": "http://www.sidsrivastava.me", "anchor_text": "www.sidsrivastava.me"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb6459b5044&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&user=Siddharth+Srivastava&userId=bb6459b5044&source=post_page-bb6459b5044--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fbb6459b5044%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbackpropagating-ais-future-377816fc07fa&user=Siddharth+Srivastava&userId=bb6459b5044&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}