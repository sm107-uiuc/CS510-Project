{"url": "https://towardsdatascience.com/nvidia-dali-speeding-up-pytorch-876c80182440", "time": 1683003189.960598, "path": "towardsdatascience.com/nvidia-dali-speeding-up-pytorch-876c80182440/", "webpage": {"metadata": {"title": "NVIDIA DALI: Speeding up PyTorch. Some techniques to improve DALI\u2026 | by Pieterluitjens | Towards Data Science", "h1": "NVIDIA DALI: Speeding up PyTorch", "description": "TL;DR: I showcase some techniques to improve DALI resource usage & create a completely CPU-based pipeline. These techniques stabilize long-term memory usage and allow for ~50% larger batch size\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/NVIDIA/DALI/issues/278", "anchor_text": "278", "paragraph_index": 1}, {"url": "https://devblogs.nvidia.com/fast-ai-data-preprocessing-with-nvidia-dali/", "anchor_text": "Fast AI Data Preprocessing with NVIDIA DALI", "paragraph_index": 6}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "DALI ImageNet example", "paragraph_index": 7}, {"url": "https://github.com/NVIDIA/DALI/issues/278", "anchor_text": "278", "paragraph_index": 8}, {"url": "https://github.com/NVIDIA/DALI/issues/344", "anchor_text": "344", "paragraph_index": 8}, {"url": "https://github.com/NVIDIA/DALI/issues/486", "anchor_text": "486", "paragraph_index": 8}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "CPU pipeline", "paragraph_index": 12}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "example CPU pipeline", "paragraph_index": 12}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "example GPU pipeline", "paragraph_index": 14}, {"url": "https://github.com/yaysummeriscoming/DALI_pytorch_demo/blob/master/dataloader.py", "anchor_text": "data loader class", "paragraph_index": 21}, {"url": "https://github.com/yaysummeriscoming/DALI_pytorch_demo", "anchor_text": "here", "paragraph_index": 31}, {"url": "http://www.private-ai.com", "anchor_text": "www.private-ai.com", "paragraph_index": 34}], "all_paragraphs": ["TL;DR: I showcase some techniques to improve DALI resource usage & create a completely CPU-based pipeline. These techniques stabilize long-term memory usage and allow for ~50% larger batch size compared to the example CPU & GPU pipelines provided with the DALI package. Testing with a Tesla V100 accelerator shows that PyTorch+DALI can reach processing speeds of nearly 4000 images/s, ~4X faster than native PyTorch.", "Update 20/3/2019: DALI 0.19 features improved memory management, eliminating the gradual rise in memory usage (278). I\u2019d still recommend to re-import DALI when using the GPU pipeline however in order to reduce GPU memory usage.", "The last couple of years have seen tremendous progress on the Deep Learning hardware front. Nvidia\u2019s latest offerings, the Tesla V100 & Geforce RTX series, contain dedicated tensor cores to accelerate the operations commonly used in neural networks. The V100, in particular, has enough power to train neural networks at thousands of images per second, bringing single-GPU training on the ImageNet dataset down to just a few hours for small models. That\u2019s a far cry from the 5 days it took to train the AlexNet model on ImageNet in 2012!", "Such powerful GPUs strain the data preprocessing pipeline. To account for this, Tensorflow released a new data loader: tf.data.Dataset. The pipeline is written in C++ and uses a graph-based approach whereby multiple preprocessing operations are chained together to form a pipeline. PyTorch on the other hand uses a data loader written in Python on top of the PIL library \u2014 great for ease of use and flexibility, not so great for speed. Although the PIL-SIMD library does improve the situation a bit.", "Enter the NVIDIA Data Loading Library (DALI): designed to remove the data preprocessing bottleneck, allowing for training and inference to run at full speed. DALI is primarily designed to do preprocessing on a GPU, but most operations also have a fast CPU implementation. This articles focuses on PyTorch, however DALI also supports Tensorflow, MXNet & TensorRT. TensorRT support, in particular, is great. It allows for both the training and inference steps to use the exact same preprocessing code. Different frameworks like Tensorflow & PyTorch typically feature small differences between the data loaders, which might end up affecting accuracy.", "Below are some great resources to get started with DALI:", "Fast AI Data Preprocessing with NVIDIA DALI", "For the remainder of this article I\u2019m going to assume a basic familiarity with ImageNet preprocessing and the DALI ImageNet example. I\u2019ll discuss some issues that I ran up against whilst using DALI, along with how I got around them. We\u2019ll look at both CPU and GPU pipelines.", "The first issue I encountered with DALI is that RAM usage increases with every training epoch, causing OOM errors (even on a VM with 78GB RAM). This has been flagged (278, 344, 486), but has yet to be fixed.", "The only solution I could find wasn\u2019t pretty \u2014 reimport DALI & recreate the train & validation pipelines at every epoch:", "Note that, with this workaround, DALI still requires a lot of RAM to get the best results. Given how cheap RAM is nowadays (relative to Nvidia GPUs at least) this isn\u2019t much of a concern; rather, GPU memory is more of a problem. As can be seen from the table below, the maximum batch size possible whilst using DALI is as much as 50% lower than TorchVision:", "In the following sections, I\u2019ll cover some approaches to reduce GPU memory usage.", "Let\u2019s look at the example CPU pipeline first. The CPU-based pipeline is useful for when peak throughput isn\u2019t required (e.g., when working with medium & large sized models like ResNet50). The CPU training pipeline only does the decoding & resizing operations on CPU however, with the CropMirrorNormalize operation running on GPU. This is significant. I found that even just transferring the output to GPU with DALI used a lot of GPU memory. To circumvent this, I modified the example CPU pipeline to run entirely on CPU:", "The DALI pipeline now outputs an 8-bit tensor on the CPU. We need to use PyTorch to do the CPU-> GPU transfer, the conversion to floating point numbers, and the normalization. These last two ops are done on GPU, given that, in practice, they\u2019re very fast and they reduce the CPU -> GPU memory bandwidth requirement. I tried pinning the tensor before transferring to GPU, but didn\u2019t manage to get any performance uplift from doing so. Putting it together with a prefetcher:", "In my testing, the new full CPU pipeline detailed above is about twice as fast as TorchVision\u2019s data loader, whilst achieving nearly the same maximum batch size. The CPU pipeline works great with large models like ResNet50; however, when using small models like AlexNet or ResNet18, the CPU pipeline still isn\u2019t able to keep up with the GPU. For these cases, the example GPU pipeline works best. The trouble is that the GPU pipeline reduces the maximum possible batch size by almost 50%, limiting throughput.", "One way to significantly reduce GPU memory usage is by keeping the validation pipeline off the GPU until it\u2019s actually needed at the end of an epoch. This is easy to do as we\u2019re already reimporting the DALI library and recreating data loaders at every epoch.", "* For validation, a batch size that evenly divides the dataset size works best e.g. 500 instead of 512 for a validation set size of 50000 \u2014 this avoids a partial batch at the end of the validation dataset.", "* Similar to the Tensorflow & PyTorch data loaders, the TorchVision and DALI pipelines don\u2019t produce bit-identical outputs \u2014 you\u2019ll see the validation accuracies differ slightly. I found that this is due to different JPEG image decoders. There was previously an issue with resizing but this is now fixed. The flipside is that DALI supports TensorRT, allowing for the exact same preprocessing to be used for training & inference.", "* For peak throughput, try setting the number of data loader workers to number_of_virtual_CPU cores. 2 gave the best performance (2 virtual cores = 1 physical core)", "* If you want absolute best performance and don\u2019t care about having outputs similar to TorchVision, try turning off triangular interpolation on the DALI image resize", "* Don\u2019t forget about disk IO. Make sure you have enough RAM to cache the dataset and/or a really fast SSD. DALI can pull up to 400Mb/s from disk!", "To help integrate these modifications easily, I created a data loader class with all the modifications described here, including both DALI and TorchVision backends. Usage is simple. Instantiate the data loader:", "Then get the train & validation data loaders:", "Reset the data loader at the end of every training epoch:", "Optionally, the validation pipeline can be recreated on GPU prior to model validation:", "Here are the max batch sizes I was able to use with ResNet18:", "So, by applying these modifications, the max batch size DALI can use in both CPU & GPU modes is increased by ~50%!", "Here are some throughput figures with Shufflenet V2 0.5 & batch size 512:", "And here are some results of using the DALI GPU pipeline to train various networks included in TorchVision:", "All tests were run on a Google Cloud V100 instance with 12 vCPUs (6 physical cores), 78GB RAM & using Apex FP16 training. To reproduce these results, use the following arguments: \u2014 fp16 \u2014 batch-size 512 \u2014 workers 10 \u2014 arch \u201cshufflenet_v2_x0_5 or resnet18\u201d \u2014 prof \u2014 use-dali", "So, with DALI, a single Tesla V100 can reach speeds of nearly 4000 image/s! That\u2019s just over half of what Nvidia\u2019s super expensive DGX-1 with 8 V100 GPUs can do (albeit using small models). For me, being able to do an ImageNet training run on a single GPU in a few hours was a productivity game changer. Hopefully it will be for you as well. Feedback appreciated!", "The code presented in this article is here", "Many thanks to Patricia Thaine for her feedback on an earlier draft of this post.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Engineer focusing on edge & MLOps. Co-Founder and CTO of Private AI www.private-ai.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F876c80182440&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----876c80182440--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----876c80182440--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@pieterluitjens?source=post_page-----876c80182440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=post_page-----876c80182440--------------------------------", "anchor_text": "Pieterluitjens"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9ecbc5d6813&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&user=Pieterluitjens&userId=c9ecbc5d6813&source=post_page-c9ecbc5d6813----876c80182440---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/NVIDIA/DALI/issues/278", "anchor_text": "278"}, {"url": "https://developer.nvidia.com/DALI", "anchor_text": "DALI Home"}, {"url": "https://devblogs.nvidia.com/fast-ai-data-preprocessing-with-nvidia-dali/", "anchor_text": "Fast AI Data Preprocessing with NVIDIA DALI"}, {"url": "https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html", "anchor_text": "DALI Developer Guide"}, {"url": "https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/examples/getting%20started.html", "anchor_text": "Getting Started"}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "DALI ImageNet example"}, {"url": "https://github.com/NVIDIA/DALI/issues/278", "anchor_text": "278"}, {"url": "https://github.com/NVIDIA/DALI/issues/344", "anchor_text": "344"}, {"url": "https://github.com/NVIDIA/DALI/issues/486", "anchor_text": "486"}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "CPU pipeline"}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "example CPU pipeline"}, {"url": "https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py", "anchor_text": "example GPU pipeline"}, {"url": "https://github.com/yaysummeriscoming/DALI_pytorch_demo/blob/master/dataloader.py", "anchor_text": "data loader class"}, {"url": "https://github.com/yaysummeriscoming/DALI_pytorch_demo", "anchor_text": "here"}, {"url": "https://pixabay.com/users/JacekAbramowicz-1981807/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1201077", "anchor_text": "Jacek Abramowicz"}, {"url": "https://medium.com/tag/pre-processing?source=post_page-----876c80182440---------------pre_processing-----------------", "anchor_text": "Pre Processing"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----876c80182440---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/data-science?source=post_page-----876c80182440---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----876c80182440---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----876c80182440---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&user=Pieterluitjens&userId=c9ecbc5d6813&source=-----876c80182440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&user=Pieterluitjens&userId=c9ecbc5d6813&source=-----876c80182440---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----876c80182440--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F876c80182440&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----876c80182440---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----876c80182440--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----876c80182440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----876c80182440--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----876c80182440--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----876c80182440--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----876c80182440--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----876c80182440--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----876c80182440--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pieterluitjens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pieterluitjens"}, {"url": "https://medium.com/@pieterluitjens/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "44 Followers"}, {"url": "http://www.private-ai.com", "anchor_text": "www.private-ai.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9ecbc5d6813&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&user=Pieterluitjens&userId=c9ecbc5d6813&source=post_page-c9ecbc5d6813--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa9ec15378f74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnvidia-dali-speeding-up-pytorch-876c80182440&newsletterV3=c9ecbc5d6813&newsletterV3Id=a9ec15378f74&user=Pieterluitjens&userId=c9ecbc5d6813&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}