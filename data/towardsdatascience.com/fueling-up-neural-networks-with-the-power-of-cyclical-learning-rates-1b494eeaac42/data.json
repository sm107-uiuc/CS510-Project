{"url": "https://towardsdatascience.com/fueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42", "time": 1683014459.2023711, "path": "towardsdatascience.com/fueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42/", "webpage": {"metadata": {"title": "Fueling up your neural networks with the power of cyclical learning rates | by Bipin Krishnan P | Towards Data Science", "h1": "Fueling up your neural networks with the power of cyclical learning rates", "description": "Choosing the best learning rate for training neural networks is a tedious task and most often it is done by a process of trial and error. But, what if you can provide your neural network with a range\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1506.01186", "anchor_text": "Cyclical Learning Rates for Training Neural Networks", "paragraph_index": 2}, {"url": "https://github.com/bipinKrishnan/fastai_course", "anchor_text": "repository", "paragraph_index": 71}, {"url": "https://bipinkrishnan.github.io/ml-recipe-book", "anchor_text": "https://bipinkrishnan.github.io/ml-recipe-book", "paragraph_index": 73}], "all_paragraphs": ["Choosing the best learning rate for training neural networks is a tedious task and most often it is done by a process of trial and error.", "But, what if you can provide your neural network with a range of learning rate values. The best part is that there is a method to get the best learning rate range without even starting the actual training of your neural network.", "These cool techniques were introduced by Leslie N. Smith in his paper Cyclical Learning Rates for Training Neural Networks.", "By using the techniques discussed in the paper we get a better result in fewer iterations.", "The abstract of the paper clearly says this:", "Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations", "The statement in the abstract is supported by several experiments conducted against other techniques like adaptive learning rates.", "While using cyclical learning rate for training on the CIFAR-10 data set, the following results were obtained:", "The same accuracy obtained by other methods at 70,000 iterations was achieved by the cyclical learning rate method at approximately 25,000 iterations.", "Now, let\u2019s jump straight into the details of the paper.", "Most of the time while passing in a learning rate, what we do is simply give the neural network a fixed value.", "But while using cyclical learning rate what we do is that we pass in a minimum learning rate and maximum learning rate.", "For example, consider the minimum learning rate to be 0.001 and the maximum learning rate to be 0.01. During the training process, the learning rate will change from 0.001(minimum learning rate) up to a value of 0.01(maximum learning rate), then again it will change from 0.01(maximum learning rate) to 0.001(minimum learning rate) and the process continues until the training is complete.", "Just like a cyclical process, it starts from the minimum and goes to the maximum, and then it returns to the minimum. It\u2019s as simple as that.", "Now obviously, you might have a question.", "How many iterations or epochs does it take for the learning rate to go from minimum to the maximum value and vice versa?", "The answer to that question is the step size.", "If the step size is 100, then it takes 100 iterations for the learning rate to go from minimum to the maximum value and another 100 iterations to return to the minimum.", "As shown in the above figure, the learning rate starts from a minimum value of 0.0001 and reaches a maximum value of 0.001 after 100 iterations and again returns to the minimum in the next 100 iterations.", "One complete cycle is the time taken to return to the minimum value. In the above figure, it is equal to 200 iterations.", "One complete cycle = 2*(step size)", "Torch7 code for implementing cyclical learning rate given in the paper is:", "opt.LR \u2014 Minimum value for the learning rate", "maxLR \u2014 Maximum value for the learning rate", "But let\u2019s convert the above code to numpy:", "Now, let\u2019s test whether our numpy implementation is working as expected. For that let\u2019s run a for loop and check whether the learning rate is moving from minimum to maximum as discussed before.", "By running the above code we get a plot as shown below:", "As expected, our learning rate starts from the minimum value and moves linearly up and down within the specified step size.", "The above technique is called triangular policy. There are two more techniques described in the paper:", "As you have an idea of what exactly is cyclical learning rate, let\u2019s train a model using cyclic learning rate and see whether it\u2019s performing better than a model with a single learning rate.", "To make our experiments faster, we will be using a small subset from the MNIST(Modified National Institute of Standards and Technology) data set. Let\u2019s begin with our experimentation:", "2. Download the MNIST data set.", "As I\u2019ve said, we will be downloading only a small subset of the complete MNIST data set.", "3. Now, we will create a custom data set class.", "4. Build the required transforms and load the data set using PyTorch data loader.", "Since the downloaded MNIST data set is in the form of tensors and PyTorch data class only takes in PIL(Python Imaging Library) images, we need to transform the data set into PIL images and convert them to tensors then feed into the data loader.", "The data set is split in such a way that 8000 data points are used for training and the rest is used for validation(approximately 2000 data points).", "5. Now let\u2019s create a validate function to calculate the loss and accuracy of our model on validation data.", "6. Now, let\u2019s create our model.", "We will be using resnet18(without the pre-trained weights) as our model with cross entropy loss and adam optimizer.", "7. Now we are all set to train our model.", "On each iteration through the data loader, we will update the value of learning rate in the optimizer using the cyclical learning rate function that we\u2019ve implemented earlier using numpy.", "In the above code, we are using a step size equal to two times the training data loader and a learning rate boundary between 1e-3 and 1e-2.", "We will also store the value of accuracy after each iteration to compare the results with another model trained using a single learning rate.", "9. Now, we will quickly create and train another model but with a single learning rate value.", "We will train the model using the same data set used before.", "8. Now let\u2019s compare the results of our model trained for 4 epochs and the other model trained for 8 epochs but with a single learning rate, i.e, 0.001(default value for the adam optimizer).", "In the above code, the term \u2018acc1\u2019 is the accuracy values for the model trained with single learning rate and the term \u2018acc\u2019 is the accuracy values for the model trained using cyclic learning rate.", "The above code gives a plot as follows:", "It is clear from the above plot that the model trained using cyclical learning rate(red line) achieved higher accuracy than the model trained with a fixed learning rate(blue line) even at a fewer number of iterations.", "As I\u2019ve said earlier, there is a technique to find the best learning rate range using a technique. This technique is called the \u201cLR range test\u201d as mentioned in the paper.", "There is a simple way to estimate reasonable minimum and maximum boundary values with one training run of the network for a few epochs. It is a \u201cLR range test\u201d.", "This is done by setting the minimum learning rate to a small value like 1e-07 and the maximum learning rate to a high value. Then the model is trained for some iteration and then the loss obtained for each learning rate is plotted.", "This is neatly implemented in the fastai library, but there is also a PyTorch implementation for the same.", "But for that, we need to install a library called torch-lr-finder using pip as shown below:", "Now we can test for the best range of learning rate to pass into our model.", "We will just pass our model, loss function, optimizer and device(cuda or cpu) to initialize the learning rate finder.", "We pass our training data loader, validation data loader, minimum learning rate(very low value) and maximum(very high value) learning rate to start the learning rate range test.", "After running the above code, we get a plot with a learning rate suggestion like the one below:", "From the figure, we can see that the loss value continues to decrease from a value of approximately 3e-4 to a value of 1e-3, thus these values can be used as our minimum and maximum values of the learning rate. The optimum learning rate suggested by the learning rate finder is 5.21e-04 which is also between this range and can be used if you wish to train the model with a single learning rate.", "PyTorch provides a learning rate scheduler to change the learning rate as discussed above.", "So, let\u2019s use PyTorch\u2019s learning rate scheduler to train a model with the same architecture, hyper-parameters, optimizer and loss function that we\u2019ve used before.", "Let\u2019s import the learning rate scheduler from PyTorch and quickly build the model.", "Now we will train our model and use the learning rate scheduler to update the learning rates.", "As seen in the above code, after each iteration through the data loader, the learning rate is updated using the scheduler.", "After 4 epochs, the model gives the same accuracy(98.2638) as the one trained using the cyclical learning rate function built by us.", "\ud83d\udcce Some of the important points to remember are:", "This is such an awesome technique to use in your day to day training of neural networks.", "If you are still in doubt about the capability of cyclical learning rates, then you should definitely check out the experiments section of the paper and you should also try out your own experiments with cyclical learning rates to understand it\u2019s capacity.", "You can combine the power of this technique along with other methods like adaptive learning rate techniques to get powerful models.", "There are a lot of techniques that are not popular among deep learning enthusiasts which may improve the generalization capability of your model or reduce the time to train the model which may save you a lot of your precious time.", "If you wish to get the complete code discussed in the article, you can find it in this repository.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "This is my new book on machine learning: https://bipinkrishnan.github.io/ml-recipe-book"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1b494eeaac42&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bipin4338?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bipin4338?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Bipin Krishnan P"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd88e616d9f42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&user=Bipin+Krishnan+P&userId=d88e616d9f42&source=post_page-d88e616d9f42----1b494eeaac42---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/WE_Kv_ZB1l0", "anchor_text": "https://unsplash.com/photos/WE_Kv_ZB1l0"}, {"url": "https://arxiv.org/abs/1506.01186", "anchor_text": "Cyclical Learning Rates for Training Neural Networks"}, {"url": "https://arxiv.org/abs/1506.01186", "anchor_text": "https://arxiv.org/abs/1506.01186"}, {"url": "https://github.com/bipinKrishnan/fastai_course", "anchor_text": "repository"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1b494eeaac42---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deeplearing?source=post_page-----1b494eeaac42---------------deeplearing-----------------", "anchor_text": "Deeplearing"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----1b494eeaac42---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/research?source=post_page-----1b494eeaac42---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/tag/optimization?source=post_page-----1b494eeaac42---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&user=Bipin+Krishnan+P&userId=d88e616d9f42&source=-----1b494eeaac42---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&user=Bipin+Krishnan+P&userId=d88e616d9f42&source=-----1b494eeaac42---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1b494eeaac42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1b494eeaac42---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1b494eeaac42--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1b494eeaac42--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1b494eeaac42--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bipin4338?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bipin4338?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Bipin Krishnan P"}, {"url": "https://medium.com/@bipin4338/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "87 Followers"}, {"url": "https://bipinkrishnan.github.io/ml-recipe-book", "anchor_text": "https://bipinkrishnan.github.io/ml-recipe-book"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd88e616d9f42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&user=Bipin+Krishnan+P&userId=d88e616d9f42&source=post_page-d88e616d9f42--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9d6b74d8a7bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffueling-up-neural-networks-with-the-power-of-cyclical-learning-rates-1b494eeaac42&newsletterV3=d88e616d9f42&newsletterV3Id=9d6b74d8a7bd&user=Bipin+Krishnan+P&userId=d88e616d9f42&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}