{"url": "https://towardsdatascience.com/ultimate-pyspark-cheat-sheet-7d3938d13421", "time": 1683009192.433225, "path": "towardsdatascience.com/ultimate-pyspark-cheat-sheet-7d3938d13421/", "webpage": {"metadata": {"title": "Ultimate PySpark Cheat Sheet. A short guide to the PySpark DataFrames\u2026 | by Kovid Rathee | Towards Data Science", "h1": "Ultimate PySpark Cheat Sheet", "description": "Spark is one of the major players in the data engineering, data science space today. With the ever-increasing requirements to crunch more data, businesses have frequently incorporated Spark in the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://aws.amazon.com/glue/", "anchor_text": "AWS Glue", "paragraph_index": 0}, {"url": "https://codelabs.developers.google.com/codelabs/cloud-dataproc-starter/#0", "anchor_text": "Google Dataproc", "paragraph_index": 0}, {"url": "https://azure.microsoft.com/en-us/services/databricks/", "anchor_text": "Azure Databricks", "paragraph_index": 0}, {"url": "https://linktr.ee/kovid", "anchor_text": "Having worked on Spark for a bit now", "paragraph_index": 1}, {"url": "https://www.datacamp.com/community/data-science-cheatsheets?page=2", "anchor_text": "here on Datacamp", "paragraph_index": 1}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "documentation", "paragraph_index": 12}, {"url": "https://kovidrathee.medium.com/membership", "anchor_text": "https://kovidrathee.medium.com/membership", "paragraph_index": 25}], "all_paragraphs": ["Spark is one of the major players in the data engineering, data science space today. With the ever-increasing requirements to crunch more data, businesses have frequently incorporated Spark in the data stack to solve for processing large amounts of data quickly. Maintained by Apache, the main commercial player in the Spark ecosystem is Databricks (owned by the original creators of Spark). Spark has seen extensive acceptance with all kind of companies and setups \u2014 on-prem and in the cloud. Some of the most popular cloud offerings that use Spark underneath are AWS Glue, Google Dataproc, Azure Databricks.", "No technology, no programming language is good enough for all use cases. Spark is one of the many technologies used for solving the large scale data analysis and ETL problem. Having worked on Spark for a bit now, I thought of compiling a cheatsheet with real examples. Although there are a lot of resources on using Spark with Scala, I couldn\u2019t find a halfway decent cheat sheet except for the one here on Datacamp, but I thought it needs an update and needs to be just a bit more extensive than a one-pager.", "First off, a decent introduction on how Spark works \u2014", "Before you get into what lines of code you have to write to get your PySpark notebook/application up and running, you should know a little bit about SparkContext, SparkSession and SQLContext.", "We\u2019ll be using the MovieLens database in some of the examples. Here\u2019s the link to that database. You can go ahead and download it from Kaggle.", "Spark supports reading from various data sources like CSV, Text, Parquet, Avro, JSON. It also supports reading from Hive and any database that has a JDBC channel available. Here\u2019s how you read a CSV in Spark \u2014", "Throughout your Spark journey, you\u2019ll find that there are many ways of writing the same line of code to achieve the same result. Many functions have aliases (e.g., dropDuplicates and drop_duplicates). Here\u2019s an example displaying a couple of ways of reading files in Spark.", "Once you\u2019re done transforming your data, you\u2019d want to write it on some kind of persistent storage. Here\u2019s an example showing two different ways to write a Parquet file to disk \u2014", "Obviously, based on your consumption patterns and requirements, you can use similar commands writing other file formats to disk too. When writing to a Hive table, you can use bucketBy instead of partitionBy.", "The idea behind both, bucketBy and partitionBy is to reject the data that doesn\u2019t need to be queried, i.e., prune the partitions. It\u2019s an old concept which comes from traditional relational database partitioning.", "Apart from the direct method df = spark.read.csv(csv_file_path) you saw in the Reading Data section above, there\u2019s one other way to create DataFrames and that is using the Row construct of SparkSQL.", "There\u2019s one more option where you can either use the .paralellize or .textFile feature of Spark to represent a file as a RDD. To convert it into a DataFrame, you\u2019d obviously need to specify a schema. That\u2019s where pyspark.sql.types come into picture.", "We\u2019ll be using a lot of SQL like functionality in PySpark, please take a couple of minutes to familiarize yourself with the following documentation.", "DataFrames abstract away RDDs. Datasets do the same but Datasets don\u2019t come with a tabular, relational database table like representation of the RDDs. DataFrames do. For that reason, DataFrames support operations similar to what you\u2019d usually perform on a database table, i.e., changing the table structure by adding, removing, modifying columns. Spark provides all the functionality in the DataFrames API. Here\u2019s how it goes \u2014", "Aside from just creating new columns, we can also rename existing columns using the following method \u2014", "And, if we have to drop a column or multiple columns, here\u2019s how we do it \u2014", "The whole idea behind using a SQL like interface for Spark is that there\u2019s a lot of data that can be represented as in a loose relational model, i.e., a model with tables without ACID, integrity checks , etc. Given that, we can expect a lot of joins to happen. Spark provides full support to join two or more datasets. Here\u2019s how \u2014", "Filters are just WHERE clauses just like in SQL. In fact, you can use filter and where exchangeably in Spark. Here\u2019s an example of filtering movies rated between 7.5 and 8.2 in the MovieLens databases movie metadata file.", "Filters support all the SQL-like features such as filtering using comparison operators, regular expressions and bitwise operators.", "Filtering out null and not null values is one of the most common use cases in querying. Spark provides a simple isNULL and isNotNull operation on a column object.", "Aggregations are at the centre of the massive effort of processing large scale data as it all usually comes down to BI Dashboards and ML, both of which require aggregation of one sort or the other. Using the SparkSQL library, you can achieve mostly everything what you can in a traditional relational database or a data warehouse query engine. Here\u2019s an example showing how aggregation is done in Spark.", "As with most analysis engines, window functions have become quite the standard with rank, dense_rank , etc., being heavily used. Spark utilizes the traditional SQL based window function syntax of rank() over (partition by something order by something_else desc).", "Please note that sort and orderBy can be used interchangeably in Spark except when it is in Window functions.", "These were some examples that I compiled. Obviously there\u2019s much more to Spark than a cheatsheet. If you\u2019re interested or haven\u2019t found anything useful here, head over to the documentation \u2014 it\u2019s pretty good.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about tech, Indian classical music, literature, and the workplace among other things. 1x engineer on weekdays. https://kovidrathee.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7d3938d13421&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@kovidrathee", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kovidrathee.medium.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": ""}, {"url": "https://kovidrathee.medium.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Kovid Rathee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13d513db037&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&user=Kovid+Rathee&userId=13d513db037&source=post_page-13d513db037----7d3938d13421---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@genessapana?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Genessa Panainte"}, {"url": "https://unsplash.com/s/photos/spark?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://aws.amazon.com/glue/", "anchor_text": "AWS Glue"}, {"url": "https://codelabs.developers.google.com/codelabs/cloud-dataproc-starter/#0", "anchor_text": "Google Dataproc"}, {"url": "https://azure.microsoft.com/en-us/services/databricks/", "anchor_text": "Azure Databricks"}, {"url": "https://linktr.ee/kovid", "anchor_text": "Having worked on Spark for a bit now"}, {"url": "https://www.datacamp.com/community/data-science-cheatsheets?page=2", "anchor_text": "here on Datacamp"}, {"url": "https://mapr.com/blog/how-spark-runs-your-applications/", "anchor_text": "It's How Spark Runs Your ApplicationsRecall from the previous Spark 101 blog that your Spark application runs as a set of parallel tasks. In this blog post\u2026mapr.com"}, {"url": "https://www.kaggle.com/rounakbanik/the-movies-dataset", "anchor_text": "The Movies DatasetMetadata on over 45,000 movies. 26 million ratings from over 270,000 users.www.kaggle.com"}, {"url": "https://luminousmen.com/post/the-5-minute-guide-to-using-bucketing-in-pyspark", "anchor_text": "The 5-minute guide to using bucketing in PysparkThere are many different tools in the world, each of which solves a range of problems. Many of them are judged by how\u2026luminousmen.com"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "documentation"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7d3938d13421---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-engineering?source=post_page-----7d3938d13421---------------data_engineering-----------------", "anchor_text": "Data Engineering"}, {"url": "https://medium.com/tag/software-development?source=post_page-----7d3938d13421---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7d3938d13421---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7d3938d13421---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&user=Kovid+Rathee&userId=13d513db037&source=-----7d3938d13421---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&user=Kovid+Rathee&userId=13d513db037&source=-----7d3938d13421---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7d3938d13421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7d3938d13421---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7d3938d13421--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7d3938d13421--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7d3938d13421--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7d3938d13421--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7d3938d13421--------------------------------", "anchor_text": ""}, {"url": "https://kovidrathee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kovidrathee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kovid Rathee"}, {"url": "https://kovidrathee.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "https://kovidrathee.medium.com/membership", "anchor_text": "https://kovidrathee.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13d513db037&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&user=Kovid+Rathee&userId=13d513db037&source=post_page-13d513db037--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8154c41b0f77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-pyspark-cheat-sheet-7d3938d13421&newsletterV3=13d513db037&newsletterV3Id=8154c41b0f77&user=Kovid+Rathee&userId=13d513db037&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}