{"url": "https://towardsdatascience.com/5-frameworks-for-reinforcement-learning-on-python-1447fede2f18", "time": 1683008592.1982248, "path": "towardsdatascience.com/5-frameworks-for-reinforcement-learning-on-python-1447fede2f18/", "webpage": {"metadata": {"title": "5 Frameworks for Reinforcement Learning on Python | by Mauricio Fadel Argerich | Towards Data Science", "h1": "5 Frameworks for Reinforcement Learning on Python", "description": "There are lots of standard libraries for supervised and unsupervised machine learning like Scikit-learn, XGBoost or even Tensorflow, that can get you started in no time and you can find log nads of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/keras-rl/keras-rl", "anchor_text": "Keras-RL github", "paragraph_index": 3}, {"url": "https://keras-rl.readthedocs.io/en/latest/core/", "anchor_text": "official documentation", "paragraph_index": 4}, {"url": "https://github.com/wau/keras-rl2", "anchor_text": "Keras-RL2", "paragraph_index": 4}, {"url": "http://ceur-ws.org/Vol-2600/short9.pdf", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://github.com/openai/baselines", "anchor_text": "OpenAI Baselines", "paragraph_index": 7}, {"url": "https://github.com/openai/baselines/blob/master/baselines/a2c", "anchor_text": "A2C", "paragraph_index": 7}, {"url": "https://github.com/openai/baselines/blob/master/baselines/ddpg", "anchor_text": "DDPG", "paragraph_index": 7}, {"url": "https://github.com/openai/baselines/blob/master/baselines/deepq", "anchor_text": "DQN", "paragraph_index": 7}, {"url": "https://github.com/openai/baselines/blob/master/baselines/ppo2", "anchor_text": "PPO2", "paragraph_index": 7}, {"url": "https://github.com/openai/baselines/blob/master/baselines/trpo_mpi", "anchor_text": "TRPO", "paragraph_index": 7}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines", "paragraph_index": 9}, {"url": "https://github.com/openai/baselines", "anchor_text": "OpenAI Baselines", "paragraph_index": 9}, {"url": "https://stable-baselines.readthedocs.io/en/master/", "anchor_text": "listed in their official documentation site", "paragraph_index": 9}, {"url": "https://github.com/openai/gym", "anchor_text": "OpenAI Gym environments", "paragraph_index": 10}, {"url": "https://github.com/google/jax/blob/master/README.md", "anchor_text": "JAX", "paragraph_index": 11}, {"url": "https://github.com/deepmind/acme/blob/master/docs/index.md", "anchor_text": "documentation", "paragraph_index": 12}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/", "paragraph_index": 17}], "all_paragraphs": ["There are lots of standard libraries for supervised and unsupervised machine learning like Scikit-learn, XGBoost or even Tensorflow, that can get you started in no time and you can find log nads of support online. Sadly, for Reinforcement Learning (RL) this is not the case.", "It is not that there are no frameworks, as a matter of fact, there are many frameworks for RL out there. The problem is that there is no standard yet, and so finding support online for starting, fixing a problem or customizing a solution is not easily found. This is probably caused by the fact that, while RL is a very popular research topic, it is still in its early days of being implemented and used in the industry.", "But this doesn\u2019t mean there are no great frameworks out there that can help you start and use RL for solving any problem you like. I have made a list here of some frameworks I have come to know and use along time, with their benefits and cons. I hope this gives you a quick overview about some of the RL frameworks currently available, so you can choose the one that better fits your needs.", "I have to admit from the whole list, this is my favorite. I believe it is by far the simplest to understand code implementation of several RL algorithms including Deep Q Learning (DQN), Double DQN, Deep Deterministic Policy Gradient (DDPG), Continuous DQN (CDQN or NAF), Cross-Entropy Method (CEM), Dueling DQN) and SARSA. When I say \u201csimplest to understand code\u201d I refer not to use, but to customize it and utilize it as a building block for your project*. The Keras-RL github also contains some examples that you can use to get started in no time. It uses Keras of course, and you can use it along with Tensorflow or PyTorch.", "Unfortunately, Keras-RL has not been well-maintained for a while already and its official documentation is not the best. This has given light to a fork of this project called Keras-RL2.", "(*) What did I use this framework for? Well, I\u2019m glad you asked \u2014 or was it me? I have used this framework to create a customized Tutored DQN agent, you can read more about it here.", "Keras-RL2 is a fork from Keras-RL and as such it shares support for the same agents as Keras-RL2 and is easily customizable. The big change here is that Keras-RL2 is better maintained and uses Tensorflow 2.1.0. Unfortunately, there is no documentation for this library, even though the documentation for Keras-RL can be easily used for this fork too.", "OpenAI Baselines is a set of high-quality implementations of RL algorithms by OpenAI, one of the leading companies in research and development of AI and in particular RL. It was conceived so researchers could compare their RL algorithms easily, using as a baseline the state-of-the-art implementations from OpenAI \u2014 thus the name. The framework contains implementations of many popular agents such as A2C, DDPG, DQN, PPO2 and TRPO.", "On the downside, OpenAI Baselines is not well documented, even though there are lots of useful comments on the code. In addition, since it was developed to be used as a baseline and not as a building block, the code is not so friendly if you want to customize or modify some of the agents for your projects. In fact, the next framework is a fork from this and solves most of these issues.", "Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring and code cleanups. The changes listed in their official documentation site are the following:", "I have personally used Stable Baselines in the past and I can confirm it is really well documented and easy to use. It is even possible to train an agent for OpenAI Gym environments with a one liner:", "Acme comes from DeepMind, probably the most well-known company working on RL in research. As such, it has been developed for building readable, efficient, research-oriented RL algorithms and contains implementations of several state-of-the-art agents such as D4PG, DQN, R2D2, R2D3 and more. Acme uses Tensorflow as backend and also some agent implementations use a combination of JAX and Tensorflow.", "Acme was developed keeping in mind to make its code as re-usable as possible, so its design is modular and easy to customize. Its documentation is not abundant but enough to give you a nice introduction to the library and there are also some examples to get you started in Jupyter notebooks.", "All of the frameworks listed here are solid options for any RL project; deciding which one to use depends on your preferences and what you want to do with it exactly. To visualize better each framework and its pros and cons, I\u2019ve made the following visual summary:", "If you have already decided on what framework to use, all you need now is an environment. You can start using OpenAI Gym, which is already used in most examples of these frameworks, but if you want to try RL on other tasks such as Trading stocks, networking or producing recommendations, you can find a comprehensible list of ready-to-use environments here:", "If you know about any other good RL framework, please let me know in responses below! Thanks for reading! :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Information Systems Engineer. Research Scientist of AI. More about me on https://www.linkedin.com/in/maufadel/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1447fede2f18&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1447fede2f18--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----1447fede2f18--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193----1447fede2f18---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@carlheyerdahl?utm_source=medium&utm_medium=referral", "anchor_text": "Carl Heyerdahl"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/keras-rl/keras-rl", "anchor_text": "Keras-RL github"}, {"url": "https://keras-rl.readthedocs.io/en/latest/core/", "anchor_text": "official documentation"}, {"url": "https://github.com/wau/keras-rl2", "anchor_text": "Keras-RL2"}, {"url": "http://ceur-ws.org/Vol-2600/short9.pdf", "anchor_text": "here"}, {"url": "https://github.com/openai/baselines", "anchor_text": "OpenAI Baselines"}, {"url": "https://github.com/openai/baselines/blob/master/baselines/a2c", "anchor_text": "A2C"}, {"url": "https://github.com/openai/baselines/blob/master/baselines/ddpg", "anchor_text": "DDPG"}, {"url": "https://github.com/openai/baselines/blob/master/baselines/deepq", "anchor_text": "DQN"}, {"url": "https://github.com/openai/baselines/blob/master/baselines/ppo2", "anchor_text": "PPO2"}, {"url": "https://github.com/openai/baselines/blob/master/baselines/trpo_mpi", "anchor_text": "TRPO"}, {"url": "http://htmlpreview.github.io/?https://github.com/openai/baselines/blob/master/benchmarks_atari10M.htm", "anchor_text": "Stable baselines benchmark"}, {"url": "https://stable-baselines.readthedocs.io/en/master/", "anchor_text": "Stable Baselines documentation"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Stable Baselines"}, {"url": "https://github.com/openai/baselines", "anchor_text": "OpenAI Baselines"}, {"url": "https://stable-baselines.readthedocs.io/en/master/", "anchor_text": "listed in their official documentation site"}, {"url": "https://github.com/openai/gym", "anchor_text": "OpenAI Gym environments"}, {"url": "https://comicbookandbeyond.com/wile-e-coyote-live-action-finally-gets-a-director/", "anchor_text": "Comicbook And Beyond"}, {"url": "https://github.com/google/jax/blob/master/README.md", "anchor_text": "JAX"}, {"url": "https://github.com/deepmind/acme/blob/master/docs/index.md", "anchor_text": "documentation"}, {"url": "https://github.com/keras-rl/keras-rl", "anchor_text": "Github"}, {"url": "https://github.com/wau/keras-rl2", "anchor_text": "Github"}, {"url": "https://github.com/openai/baselines", "anchor_text": "Github"}, {"url": "https://github.com/hill-a/stable-baselines", "anchor_text": "Github"}, {"url": "https://github.com/deepmind/acme/tree/master/acme", "anchor_text": "Github"}, {"url": "https://medium.com/@mauriciofadelargerich/reinforcement-learning-environments-cff767bc241f", "anchor_text": "Reinforcement Learning EnvironmentsI\u2019ve been lately working with Reinforcement Learning (RL) and I have found there are lots of great articles, tutorials\u2026medium.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1447fede2f18---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1447fede2f18---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----1447fede2f18---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1447fede2f18---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/python?source=post_page-----1447fede2f18---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----1447fede2f18---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----1447fede2f18---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1447fede2f18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1447fede2f18---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1447fede2f18--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1447fede2f18--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1447fede2f18--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1447fede2f18--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1447fede2f18--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/@mauriciofadelargerich/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "298 Followers"}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9d5b675a4898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-frameworks-for-reinforcement-learning-on-python-1447fede2f18&newsletterV3=b3931df7d193&newsletterV3Id=9d5b675a4898&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}