{"url": "https://towardsdatascience.com/gpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66", "time": 1683014319.130628, "path": "towardsdatascience.com/gpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66/", "webpage": {"metadata": {"title": "GPT-3: The good, the bad and the ugly | by Frank Schilder | Towards Data Science", "h1": "GPT-3: The good, the bad and the ugly", "description": "If you follow the latest AI news, you probably came across several stunning applications of the latest Language Model (LM) released by OpenAI: GPT-3. The applications that this LM can fuel reach from\u2026"}, "outgoing_paragraph_urls": [{"url": "https://beta.openai.com/", "anchor_text": "GPT-3", "paragraph_index": 0}, {"url": "https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html", "anchor_text": "question answering", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=z8K07a2EIcE", "anchor_text": "generating Python code", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=8psgEDhT1MM", "anchor_text": "GPT-3 demo and explanation", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=G6Z_S6hs29s", "anchor_text": "14 cool GPT-3 apps", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=cpWEXQkpBFQ", "anchor_text": "14 more GPT-3 apps", "paragraph_index": 0}, {"url": "https://bdtechtalks.com/2020/09/24/microsoft-openai-gpt-3-license/", "anchor_text": "Microsoft announced that they acquired the exclusive rights on the language model.", "paragraph_index": 1}, {"url": "https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html", "anchor_text": "T5 with 11 Billion parameters", "paragraph_index": 3}, {"url": "https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00276", "anchor_text": "NaturalQS", "paragraph_index": 16}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.463.pdf", "anchor_text": "recent academic paper", "paragraph_index": 18}, {"url": "http://faculty.washington.edu/ebender/", "anchor_text": "Emily Bender", "paragraph_index": 18}, {"url": "http://www.coli.uni-saarland.de/~koller/", "anchor_text": "Alexander Koller", "paragraph_index": 18}, {"url": "http://garymarcus.com/", "anchor_text": "Gary Marcus", "paragraph_index": 19}, {"url": "https://cs.nyu.edu/faculty/davise/", "anchor_text": "Ernest Davis", "paragraph_index": 19}, {"url": "https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/", "anchor_text": "MIT Technology Review article", "paragraph_index": 19}, {"url": "https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation", "anchor_text": "they released their chatbot Tay in 2016.", "paragraph_index": 23}], "all_paragraphs": ["If you follow the latest AI news, you probably came across several stunning applications of the latest Language Model (LM) released by OpenAI: GPT-3. The applications that this LM can fuel reach from question answering to generating Python code. The list of use cases is growing daily. Check out the following youtube videos: GPT-3 demo and explanation, 14 cool GPT-3 apps and 14 more GPT-3 apps.", "GPT-3 is currently in beta and only a restricted number of people have access, but will be released to everybody on October 1st. OpenAI was very much interested in spreading the hype and showing amazing samples of cool applications. As of September 22, 2020, their strategy obviously worked out. While writing this blog post, Microsoft announced that they acquired the exclusive rights on the language model. OpenAI will probably continue to license the access to the LM via an API, but the purchase by Microsoft allowed OpenAI to get an ROI of their investment of $4.6 million \u2014 the estimated cost of training this massive LM.", "Because OpenAI is quite successful in their marketing by enlisting many people to post fascinating examples which are strictly speaking only anecdotal evidence of the capabilities, one should see the current hype with some skepticism. People will most likely only post examples that confirm their bias that the machine \u201cunderstands\u201d language at a new level. At the same time the negative examples such as racist stories that are automatically generated when your prompt is \u201cthree muslims\u201d, as discussed further below, should raise concern about potentially doing more harm than good.", "Before I discuss in more detail \u201cthe Good, the Bad, and the Ugly\u201d, let\u2019s briefly review what the main contribution of GPT-3 is. OpenAI released a previous version called GPT-2 last year. The technology has not changed since then. It is basically the enormous amount of data that led to the LM with now 175 Billion parameters compared to currently used LM such as T5 with 11 Billion parameters. After training the model data largely crawled from the \u201cInternet\u201d, the authors were able to show that the system was able to reach or even beat State-Of-The-Art systems in various NLP tasks (e.g., question answering, machine translation). Most impressive, however, was the fact that the system was never trained on the tasks and was able to achieve reasonable performance with no, one or just a few examples (i.e., no-shot/one-shot/few-shot learning).", "The figure from the GPT-3 paper illustrates how GPT-3 can be told with just a handful of examples how to do a task in contrast to the traditional approach of fine-tuning a deep learning model by feeding it lots of examples (\u2026). In addition, the fine-tuning also requires you to define the solution space (i.e., the number of labels) in advance and you have to make sure you have enough examples in your training data so that the machine can learn how to distinguish the different classes. All this is not required when using GPT-3 (provided enough data for the task was available in the data that was fed to the LM).", "GPT-3 shows impressive results for a number of NLP tasks such as questions answering (QA), generating code (or other formal languages/editorial assist) and (fictional) story generation. Those applications have shown impressive results and and will most likely be incorporated into already existing system showing improvements over the current state-of-the-art.", "The GPT-3 paper shows, for example, impressive results for various QA tasks such as TriviaQA. It is quite promising that few-shot learning often shows better results than one-shot or zero-shot learning indicating that with more labeled examples the LM may improve even more.", "These are the application that probably will benefit from GPT-3 the most:", "In particular, the last bullet point could lead to the assumption that it will be easy to create applications without much technical knowledge. Using the GPT-3 playground would allow everybody to explore concepts that can be quickly tested via zero- of few-shot learning. The following examples shows how somebody with just two examples would get answers for questions like \u201cWhat are the elements of\u2026?\u201d I looked for answers of the first two questions on the internet and the answer for third question was generated by the system. Without the two examples, the system\u2019s answer were too short and not informative, but just two examples put it on the \u201cright\u201d path (bold is my input, normal font is GPT-3\u2019s continuation):", "Q: What are the elements of trespass?", "A: Trespass is an invasion in to another\u2019s exclusive right to possession of property. It is a direct unlawful interference with another\u2019s property. Generally, the main elements of trespass are an unlawful intrusion or invasion upon a property, intent of intrusion, force, and consequent injury to an owner.", "Q: What are the elements of fraud?", "A: In the United States, common law generally identifies nine elements needed to establish fraud: (1) a representation of fact; (2) its falsity; (3) its materiality; (4) the representer\u2019s knowledge of its falsity or ignorance of its truth; (5) the representer\u2019s intent that it should be acted upon by the person in the manner reasonably contemplated; (6) the injured party\u2019s ignorance of its falsity; (7) the injured party\u2019s reliance on its truth; (8) the injured party\u2019s right to rely thereon; and (9) the injured party\u2019s consequent and proximate injury.", "Q: What are the elements of a civil conspiracy?", "A: (1) an agreement between two or more persons; (2) an overt act by one or more parties to further the purpose of the conspiracy; and (3) damages suffered by the injured party as a result of the conspiracy.", "Although these answers sound very impressive (at least to me as a non-lawyer), one should be aware of the risks that using the LM without any further safeguards might bring.", "One of the QA tasks GPT-3 was tested on was NaturalQS that focusses on factual accuracy. GPT-3 underperformed in this task, whereas it got high marks for trivia questions. This behavior is troubling because it seems to indicate that question answer pairs that are frequently found on the internet are more likely to be given as correct answers. But text understanding that is required to answer a complex question from just one example of text is clearly beyond the capability of the LM. If the answer, however, sounds authoritative and is written in correct English, humans may not spot the wrong answer so easily.", "As a matter of fact, it\u2019s getting more and more difficult for humans to distinguish news written by a machine from articles written by humans. One of the experiments reported in the GPT-3 paper showed that humans have a hard time identifying machine generated news. The larger the LM got the more problems humans had correctly identifying machine-written news and with the largest version of GPT-3 (175B parameters) the decision was basically a coin flip.", "Another risk of using this LM unfiltered is the missing grounding of the answers. Even though the generated sentence may provide the correct answer, there is no way to back up the statement. The language model is only grounded in frequencies of words but not in the deep understanding of statutes and case law, for example. A recent academic paper by Emily Bender and Alexander Koller provides a similar criticism stating that the meaning of language cannot be learned from LMs.", "An even more devastating rebuke of GPT-3 was delivered by Gary Marcus and Ernest Davis in a recent MIT Technology Review article. They showed that the model does not understand what it is generating via various continuations of complex situations that would require social/biological/physical or other kind of reasoning (again, normal font is GPT-3\u2019s continuation) :", "You poured yourself a glass of cranberry juice, but then you absentmindedly poured about a teaspoon of grape juice into it. It looks okay. You try sniffing it, but you have a bad cold, so you can\u2019t smell anything. You are very thirsty. So you drink it.", "Somehow GPT-3 thinks that grape juice is poisonous although the internet offers many drink recipes that contain cranberries and grapes as ingredients. Moreover, the conclusion that the drink may be fatal comes somehow out of nowhere. Marcus and Davies conclude that GPT-3 \u201c[i]s a fluent spouter of bullshit, but even with 175 billion parameters and 450 gigabytes of input data, it\u2019s not a reliable interpreter of the world.\u201d", "In addition to these risks, the LM model works well for language generation only, may this be as an answer or a fictional text. Other NLP tasks, on the other hand, can not so easily be solved with the help of GPT-3. Typical tasks such as named entity extraction (i.e., labeling strings wether they are companies or person names) or text classification task are more challenging for a LM.", "It\u2019s a well-known fact that NLP applications such as chat bots can sometimes be difficult to control and one may end up with a program that spews out racist or sexist comments, as Microsoft had to learn when they released their chatbot Tay in 2016. To their credit, OpenAi addressed this problem right from the start and they identify toxic or simply political content generated with a warning. It needs to be seen how they will control applications that may only by accident (or purposefully) generate racist or sexist language.", "Other beta user were also quick to point out that prompting GPT-3 with \u201cthree muslims\u201d will often lead to text where they are depicted as terrorist or criminals. My own experiments confirmed this bias and I also found a similar tendency of portraying them in a stereotypical fashion when I prompted the LM with other religious groups or nationalities.", "Debiasing LM is an active research topic in the community and I expect to see even more activity in this area. OpenAI is clearly aware of this and they spend a lot of time in the terms of use on how their API should and shouldn\u2019t be used.", "Despite the restrictions and possible toxic text GPT-3 may generate, I believe this LM is a fascinating new tool that will probably trigger improvements of NLP tasks that require to generate language. Combined with other technology and the respective safeguards it will push the AI capabilities we can use for our products even further. People may also come up with new applications of this technology nobody has yet really thought of. Translating Legalese to plain English may only be the start of further innovation this technology will spur.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Director at Thomson Reuters, developing smart products using Artificial Intelligence and Computational Linguistics"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5e2e5b7f0f66&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@schilderf?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@schilderf?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Frank Schilder"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F163bf1f3204&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&user=Frank+Schilder&userId=163bf1f3204&source=post_page-163bf1f3204----5e2e5b7f0f66---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/opinion", "anchor_text": "Opinion"}, {"url": "https://unsplash.com/@raphaelphotoch?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Raphael Schaller"}, {"url": "https://unsplash.com/s/photos/letters?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://beta.openai.com/", "anchor_text": "GPT-3"}, {"url": "https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html", "anchor_text": "question answering"}, {"url": "https://www.youtube.com/watch?v=z8K07a2EIcE", "anchor_text": "generating Python code"}, {"url": "https://www.youtube.com/watch?v=8psgEDhT1MM", "anchor_text": "GPT-3 demo and explanation"}, {"url": "https://www.youtube.com/watch?v=G6Z_S6hs29s", "anchor_text": "14 cool GPT-3 apps"}, {"url": "https://www.youtube.com/watch?v=cpWEXQkpBFQ", "anchor_text": "14 more GPT-3 apps"}, {"url": "https://bdtechtalks.com/2020/09/24/microsoft-openai-gpt-3-license/", "anchor_text": "Microsoft announced that they acquired the exclusive rights on the language model."}, {"url": "https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html", "anchor_text": "T5 with 11 Billion parameters"}, {"url": "https://arxiv.org/abs/2005.14165", "anchor_text": "https://arxiv.org/abs/2005.14165"}, {"url": "https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00276", "anchor_text": "NaturalQS"}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.463.pdf", "anchor_text": "recent academic paper"}, {"url": "http://faculty.washington.edu/ebender/", "anchor_text": "Emily Bender"}, {"url": "http://www.coli.uni-saarland.de/~koller/", "anchor_text": "Alexander Koller"}, {"url": "http://garymarcus.com/", "anchor_text": "Gary Marcus"}, {"url": "https://cs.nyu.edu/faculty/davise/", "anchor_text": "Ernest Davis"}, {"url": "https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/", "anchor_text": "MIT Technology Review article"}, {"url": "https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation", "anchor_text": "they released their chatbot Tay in 2016."}, {"url": "https://beta.openai.com/playground", "anchor_text": "beta.openai.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5e2e5b7f0f66---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5e2e5b7f0f66---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5e2e5b7f0f66---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/opinion?source=post_page-----5e2e5b7f0f66---------------opinion-----------------", "anchor_text": "Opinion"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&user=Frank+Schilder&userId=163bf1f3204&source=-----5e2e5b7f0f66---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&user=Frank+Schilder&userId=163bf1f3204&source=-----5e2e5b7f0f66---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5e2e5b7f0f66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5e2e5b7f0f66---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5e2e5b7f0f66--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@schilderf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@schilderf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Frank Schilder"}, {"url": "https://medium.com/@schilderf/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "217 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F163bf1f3204&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&user=Frank+Schilder&userId=163bf1f3204&source=post_page-163bf1f3204--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fed24a7d16b57&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66&newsletterV3=163bf1f3204&newsletterV3Id=ed24a7d16b57&user=Frank+Schilder&userId=163bf1f3204&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}