{"url": "https://towardsdatascience.com/want-clusters-how-many-will-you-have-8737f4ba9bf2", "time": 1682993897.596305, "path": "towardsdatascience.com/want-clusters-how-many-will-you-have-8737f4ba9bf2/", "webpage": {"metadata": {"title": "Want Clusters? How Many Will You Have? | by Ashok Chilakapati | Towards Data Science", "h1": "Want Clusters? How Many Will You Have?", "description": "K-Means will give you as many clusters as you ask for.. The ratio of inertia and the minimum intercluster distance seems to have a detectable local minimum for the correct K"}, "outgoing_paragraph_urls": [{"url": "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans", "anchor_text": "K-means", "paragraph_index": 1}, {"url": "http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html", "anchor_text": "SciKit", "paragraph_index": 1}, {"url": "https://github.com/ashokc/Choosing-the-Optimal-Number-of-Clusters-for-K-Means", "anchor_text": "github", "paragraph_index": 1}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans", "anchor_text": "K-means", "paragraph_index": 2}, {"url": "http://xplordat.com/2018/09/27/word-embeddings-and-document-vectors-part-1-similarity/", "anchor_text": "xplordat.com", "paragraph_index": 17}], "all_paragraphs": ["Ok, that was in jest, my apologies! But it is a question we should ask ourselves before embarking on a clustering exercise. Clustering hinges on the notion of distance. The members of a cluster are expected to be closer to that cluster\u2019s centroid than they are to the centroids of other clusters. Given some data points, and a means to compute distance measure among them, it would seem that a computer program should be able to do this with enough number crunching. But we have to tread with caution. Given that this exercise is unsupervised, the algorithm has no a-priori knowledge of how the data is distributed in the feature space. Heaven forbid, if the data were to be uniformly distributed then there is no hope of realizing any meaningful clusters. Or worse, we will have as many clusters as the number of data points and we would have learnt nothing. The idea explored here is to check if the data itself can point us to a metric that can indicate the optimal number of clusters. That precisely is the focus of this post.", "We work with synthetic numerical vectors in known clusters, so we can evaluate the approach. We stick to 2-dimensions as we want to visualize the obtained clusters and convince ourselves that it seems to work. K-means implementation in SciKit is the driver for all the simulations here. The source code for all the simulations here can be downloaded from github.", "The popular K-means approach divvies up n data points into k clusters where k is specified as input. K-means identifies these k clusters by requiring that the sum of squares of distances of data points in each cluster to that cluster\u2019s centroid is minimized. With C_i as the ith cluster, x as any data vector/point in that cluster, and \u03bc_i as the centroid vector/point of that cluster, K-means minimizes the overall inertia of the k clusters I_k defined by:", "Figure 1 illustrates this with a 3-cluster example. K-means rightly attempts to make the k clusters as tight as possible, but what is the best value for k is the question. Can I_k and any other auxiliary information tell us if our k is the best?", "Let us consider the following arguments.", "Combining Equations 2 and 3 we define a new metric I_k*", "So we are basically using the intercluster distance as a counterbalance to I_k. They both decrease as k increases, but their ratio is better behaved as per simulations and has a local minimum for k << n.", "Let us be very clear that we are only talking about a local minimum that can be detected by running simulations starting from small k values to larger k values. As k increases towards n, the total number of data points, the global minimum of 0 will be reached as each data point becomes its own cluster.", "To see how this metric can be useful, let us say we have 14400 points in 2-d, grouped into 9 distinct clusters in a 3x3 grid. Each cluster has 1600 points evenly placed on a 40x40 grid. See Figure 2 below.", "When we run K-means with k=9, we get the correct identification of clusters as seen in Figure 2B. The numbers in the figure are the locations of the centroid and they are smack in the center of each cluster as our data would indicate. When K-means is run with k=5 in Figure 2A, it splits true clusters into pieces, and even combines them with pieces from other true clusters to identify as a cluster that it found. Figure 2C shows the same when run K-means with k=23, and we see the data getting split in all manner of ways.", "The point here is that K-means will split the data into however many clusters you ask for. But Figure 2D shows that the metric I_k* oscillates even while both the inertia I_k and the minimum intercluster distance min{r_k^ij} decrease steadily as k increases. Zooming in on small k, Figure 2E shows that we do indeed have a well-established local minimum at k=9. There are other local minima as well but they are all higher. Zooming in on larger k, Figure 2F shows that the minimum intercluster distance approaches the separation distance of individual points, whereas I_k (and so I_k*) dives to zero.", "There is nothing special about the nature of clusters that allows/disallows the detection of this metric. Figure 3 above shows a similar exercise where data is clustered in spirals and the metric is none the worse for it as shown in Figure 3E where a clear local minimum is obtained for I_k* when k = 9.", "So that worked out well for perfectly clustered datasets. How will it do for data where the clusters are not so nicely separated? Let us consider a dataset of the same size as before but with some random error thrown in to the locations of the data points so the clusters are not so clear cut.", "In Figure 4A above we can visually pick out the clusters even without the grid lines helping us out. Not so much in Figure 4C where we only see a thin sliver of data free zone between the clusters. We put K-means to work here to detect these clusters. Figures 4B & 4D show that I_k* has local minimum at k=9 in both cases. This minimum is more clear cut in Figure 4B than in Figure 4D. That is to be expected of course given the diffuse cluster boundaries for the latter.", "Finally we look at the case when the data is uniformly distributed so that there are no clusters. But as we know, K-means will come up with k clusters no matter. Can I_k* help us detect this situation and allows us to conclude that the data is not clusterable? See Figure 5 below where we have 14400 data points evenly distributed on a 120x120 grid.", "Unlike in Figures 2 thru 4, the metric for I_k* in Figure 4C does not show a clear cut local minimum, I_k* does not vary much for the most part as k increases. It will go to zero eventually for large k, just like in the other figures, but for k << n the I_k* is more flat than otherwise. This is likely a clue for deciding that the underlying data is not clustered.", "This post is a precursor to what we really want to get at \u2014 i.e. clustering text. Here we have established a plausible criteria to detect the optimal number of clusters while using K-means. The evidence is empirical and we have no proof that it will work in all cases, especially in higher dimensions with noise. Text is where the rubber meets the road of course with long vectors, context issues, and any number of ways of building those vectors. Should be interesting to see.", "Originally published at xplordat.com on November 5, 2018.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8737f4ba9bf2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ashok.chilakapati?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashok.chilakapati?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Ashok Chilakapati"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc37b40eae29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&user=Ashok+Chilakapati&userId=cc37b40eae29&source=post_page-cc37b40eae29----8737f4ba9bf2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans", "anchor_text": "K-means"}, {"url": "http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html", "anchor_text": "SciKit"}, {"url": "https://github.com/ashokc/Choosing-the-Optimal-Number-of-Clusters-for-K-Means", "anchor_text": "github"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans", "anchor_text": "K-means"}, {"url": "http://xplordat.com/2018/09/27/word-embeddings-and-document-vectors-part-1-similarity/", "anchor_text": "xplordat.com"}, {"url": "https://medium.com/tag/clustering?source=post_page-----8737f4ba9bf2---------------clustering-----------------", "anchor_text": "Clustering"}, {"url": "https://medium.com/tag/k-means?source=post_page-----8737f4ba9bf2---------------k_means-----------------", "anchor_text": "K Means"}, {"url": "https://creativecommons.org/publicdomain/mark/1.0/", "anchor_text": "Public domain."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&user=Ashok+Chilakapati&userId=cc37b40eae29&source=-----8737f4ba9bf2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&user=Ashok+Chilakapati&userId=cc37b40eae29&source=-----8737f4ba9bf2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8737f4ba9bf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8737f4ba9bf2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8737f4ba9bf2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashok.chilakapati?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashok.chilakapati?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ashok Chilakapati"}, {"url": "https://medium.com/@ashok.chilakapati/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "244 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc37b40eae29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&user=Ashok+Chilakapati&userId=cc37b40eae29&source=post_page-cc37b40eae29--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5ab4b71672c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwant-clusters-how-many-will-you-have-8737f4ba9bf2&newsletterV3=cc37b40eae29&newsletterV3Id=5ab4b71672c9&user=Ashok+Chilakapati&userId=cc37b40eae29&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}