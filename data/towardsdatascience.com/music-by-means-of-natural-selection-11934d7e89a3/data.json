{"url": "https://towardsdatascience.com/music-by-means-of-natural-selection-11934d7e89a3", "time": 1682993296.957678, "path": "towardsdatascience.com/music-by-means-of-natural-selection-11934d7e89a3/", "webpage": {"metadata": {"title": "Music by means of human selection | by Irhum Shafkat | Towards Data Science", "h1": "Music by means of human selection", "description": "One of the more interesting questions for deep generative models is, how can a model take user preferences into account during the generation process? Controlling a model\u2019s output can be done by\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1801.08230", "anchor_text": "[1]", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Interactive_evolutionary_computation", "anchor_text": "[3]", "paragraph_index": 6}, {"url": "https://nips2017creativity.github.io/doc/Hierarchical_Variational_Autoencoders_for_Music.pdf", "anchor_text": "[4]", "paragraph_index": 31}, {"url": "https://colab.research.google.com/drive/19AKhmNGVsLljpnQ9FoL858thZ9W_WrXX", "anchor_text": "Colaboratory notebook", "paragraph_index": 37}, {"url": "https://twitter.com/irhumshafkat", "anchor_text": "here", "paragraph_index": 39}, {"url": "https://nips2017creativity.github.io/doc/Hierarchical_Variational_Autoencoders_for_Music.pdf", "anchor_text": "Hierarchical Variational Autoencoders for Music", "paragraph_index": 40}], "all_paragraphs": ["One of the more interesting questions for deep generative models is, how can a model take user preferences into account during the generation process? Controlling a model\u2019s output can be done by passing in a condition with the input, but the samples themselves currently do not organically \u201cevolve\u201d in any meaningful sense, by taking a user\u2019s subjective preferences into account and producing a sample that the user specifically likes.", "Models being able to do so would be greatly useful in a broad spectrum of creative applications, from product design and asset generation to painting and music. A paper[1] released in January, \"Deep Interactive Evolution\", tackles this exact problem rather elegantly, and that is what this post will be discussing.", "The system we ideally want, is one that starts with a batch of completely random samples and asks the user to select their preferred ones, one with some of the attributes of their final desired output. Based on the selected samples, the model generates more samples that have features similar to those of the selected samples. This process repeats until a sample is generated with all of the desired attributes.", "We\u2019re clearly performing an optimization process here, generating newer, better samples at each time step. What\u2019s interesting here is that the reward/fitness function (the function which measures how \u201cgood\u201d a sample is) isn\u2019t a differentiable, mathematical function. It\u2019s you. Your selected choices can be simply represented as a vector of 1\u2019s and 0\u2019s, representing a good and bad sample respectively.", "This formulation of a fitness function is very useful because it saves us from having to define an (intractable) fitness function to predict which samples a user likes. We just directly hand control to the user. However, since a function outputting a vector of discrete numbers is clearly not differentiable, we can\u2019t use back-propagation here.", "One class of optimization methods that naturally lends themselves here are genetic algorithms[2]. For now, all we need to know is that they work by combining the features of the best samples, to produce even better samples (crossover), alongside adding a bit of random noise to the features as well, to explore variations in the features (mutation).", "The samples keep \u201cevolving\u201d to have better features, until one with all the desired features is found. This approach, of using genetic optimization in response to user inputs, is what is known as Interactive Evolutionary Computation(IEC)[3].", "So we now have a way we can evolve our samples, but we\u2019re still left with a question: What is a feature? We could just simply define every single pixel in a photo to be a unique feature. Now, all we have to do is run the genetic algorithm, and we should get great results, right?", "As you can see, this naive approach almost immediately runs into problems. Not only does randomly picking pixels not give us the desired realistic image, but it also doesn\u2019t give us a realistic image, period.", "One of the fundamental necessities of genetic algorithms is that the features used to represent information be independent, or at best, weakly correlated. This is so that the features can be combined and mutated independently, and still hopefully get an output not too far from the original data distribution, that is, not too unrealistic.", "However, for most data types, regardless of the domain (image, text, sound), raw features tend to be strongly correlated with each other. You can\u2019t freely optimize one feature, because whether it will be realistic or not strongly depends on its neighbors.", "For instance, take a photo of a leaf, and pick any three contiguous pixels from it. It\u2019s almost certain that the colors of all three pixels are very close to each other. After all, you wouldn\u2019t expect to just randomly see a red pixel if all the surrounding pixels are green. In fact, if you randomly take many of these pixel triplets, and plot the intensity of their green channels, you\u2019d find that nearly all the triplets lie on a very small subset of the entire 3D space, on a diagonal line from x, y, z = 0, to x, y, z = 1, where x, y, z are the green channel intensities of the three pixels. This is because, for any triplet, the green intensities are strongly correlated with each other. Any triplet that\u2019s not on the line is very unlikely to be part of any real image.", "While the example above uses only three pixels, the core idea, that images lie on a small subset of the true space applies to images of any size. For larger spaces, the relationships become non-linear, but the fact remains all the same that many of the features are highly correlated with each other. This idea extends to text and music as well, words in sentences clearly depend on their neighbors, and most music generated randomly would sound awful and not at all harmonious. Regardless of domain, most data lies on a small subspace of the total space used to represent that data, what we call a manifold. It\u2019s only on this manifold the data represents something one would consider realistic.", "Genetic algorithms at heart, are stochastic optimization algorithms, randomly exploring the search space. On manifolds, their convergence is slow because most of their generated samples aren\u2019t realistic, to begin with. You leave it up to chance to make slow progress by generating a few decent samples every now and then, inching along in the right direction. The human isn\u2019t grading the best among realistic samples, they\u2019re forced to grade whether samples are even realistic or not. This approach is almost certainly not going to converge in any reasonable amount of time.", "Hence, there are usually other forms of representation, such as evolving compositions of functions, which is what picbreeder.com uses, or by approximating images with geometric shapes, etc. While these approaches do dramatically reduce the search space, where local structures maintain the similarity of color i.e. no random noise, globally, most combinations of structure may still not make sense or be realistic enough.", "The search space is still too large, the convergence too slow, as even on picbreeder you need thousands of iterations to produce a single image.", "This is where the findings of the paper come in, and it really can be summarized in a sentence: Let\u2019s just optimize the latent vectors of generative models instead of the raw data, to quickly find a user\u2019s preferred sample.", "It\u2019s a very general solution, seamlessly merging IEC approaches with deep generative models. Many generative models work by using a latent vector and passing it through a decoder/generator network to create a true sample. Most importantly, the latent vectors are typically sampled from a N(0, I) distribution, that is, each component is sampled from a random normal distribution, the components independent of each other (or one forced to be very close to it, in case of VAEs).", "The decoder then learns to associate certain regions of the latent space with certain kinds of outputs. Since space is at a premium in the lower dimensional latent space, the decoder only \u201cassigns\u201d regions of the latent space to fairly realistic samples, close to the manifold. In short, these latent vectors are created that they\u2019re specifically useful for generating realistic samples. During training, the components of the latent vectors are independent of each other, and the decoder/generator must learn to overcome that by associating all these vectors with realistic outputs.", "By random sampling and passing the latent vector to a generator network, you can end up with slightly \u201coff\u201d looking samples, but they\u2019re still far more likely to be close to realistic than random sampling on the true input space, most of which is just pure noise.", "As the components of the latent vectors were mostly independent of each other during training, one can now freely recombine features, along with randomly adding noise in any direction, and still get a vector the generator is \u201cfamiliar\u201d with, producing a realistic image.", "This ensures a much faster convergence rate, as instead of randomly exploring a high-dimensional space, we can just explore a subset of that space in lower dimensions much more efficiently. In other words, instead of exploring every single possible combination of pixels, we just explore the ones which produce realistic images instead.", "The final genetic algorithm works on any latent vector generative model. It assumes that you\u2019ve first trained a generative model, and then, proceed to do the following:", "A. Sample: Sample n (for the purposes of illustration, n=8) random vectors from the same distribution as that of the prior of the latent variables (usually N(0, I))", "B. Generate: Keep repeating the following steps until the user arrives at a sample that has all the attributes he desires, then, terminate the process.", "2. Crossover: For the n total samples allowed per batch, besides the ones allocated for the selected and predefined number of foreign samples, the remainder is filled with cross over samples. Each crossover latent vector is generated by selecting any two of the selected latent vectors, and combining their vector components, with each component having a 50% chance of coming from either parent.", "3. Mutation: All the selected and crossover latent vectors now undergo mutation. Each latent vector has a 50% chance of undergoing mutation at all, and if it does, each component of the vector has a further 50% chance, of having random normal noise added to it, with a standard deviation (\u03c3) \u03f5 [0, 1]set by the user at each time step, the \u201cintensity\u201d of the mutation. \u03c3 = 0 corresponds to no mutation at all, whereas \u03c3 = 1 corresponds to noise on the order of magnitude of the vector components themselves.", "4. Foreign vectors: There may be cases where none of the samples have the desired attribute the user wants. This can be slowly converged towards by mutation, but if it\u2019s a considerably different attribute, it\u2019s much faster to introduce random vectors (with the same distribution as latent variable prior), to introduce genetic diversity. The user can cross these new samples with previous ones to get closer to the desired attribute.", "At the end of a single pass of optimization, we end up with a batch of vectors like this:", "The total number of vectors remains the same at every iteration (in our case, 8), and this new batch of vectors is passed back as input for the next step of the genetic optimization process, continuing until the user stops it.", "And that\u2019s the entire algorithm. The convergence is far better, as in the paper when generating simple images, users usually obtained their preferred image within just 10 generation steps.", "With all that done, now all we are left to do, is to train a generative model on music data, and perform the evolutionary process described above. For our purposes, we use a pre-trained VAE from Google\u2019s Magenta project, the MusicVAE[4] 2-bar melody model, and test the latent vector optimization process on that.", "This model is a VAE, where the encoder is a bidirectional LSTM, a sampling layer in between, and an LSTM based decoder at the end, producing individual 16th note events.", "We sample some latent vectors from the distribution N(0, I) of dimension 512, pass it through the decoder, and keep performing the genetic optimization process on the latent vector until we end up with what we expected.", "We start by randomly sampling and decoding a latent vector:", "And then we optimize it. After 8 generations of optimization, we get this:", "Not what one might consider a breakthrough, but still quite fascinating. The greater point though is the core idea of the paper works even for music (despite the original domain being images). With even more robust models, one could still apply this same approach to obtain even better results.", "P.S. For the more curious, there is a Colaboratory notebook available as well.", "The approach outlined in the paper is something I find quite intriguing, as it finally seems to bridge the gap between taking into account human preferences, and deep generative models. It\u2019s rather unlikely that deep learning is going to replace human creativity in the arts entirely, quite, on the contrary, it may become a powerful tool to augment human creativity. There has been tremendous progress regarding interpolation, and this paper provides a neat approach to the exploration approach as well. With better generative models being discovered every day, it is only bound to improve.", "If you find any major errors in this post, please do let know and I\u2019ll immediately correct them. If you liked this post, you\u2019ll find me on Twitter here.", "4. Hierarchical Variational Autoencoders for Music", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Curious programmer, tinkers around in Python and deep learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F11934d7e89a3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@irhumshafkat?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@irhumshafkat?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Irhum Shafkat"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb2327c63f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&user=Irhum+Shafkat&userId=cb2327c63f48&source=post_page-cb2327c63f48----11934d7e89a3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://vision.cs.utexas.edu/projects/finegrained/utzap50k/", "anchor_text": "UT Zappos50K"}, {"url": "https://arxiv.org/abs/1801.08230", "anchor_text": "[1]"}, {"url": "https://en.wikipedia.org/wiki/Interactive_evolutionary_computation", "anchor_text": "[3]"}, {"url": "https://arxiv.org/abs/1710.10196", "anchor_text": "Fig 6. Karras et. al. (2017)"}, {"url": "https://nips2017creativity.github.io/doc/Hierarchical_Variational_Autoencoders_for_Music.pdf", "anchor_text": "[4]"}, {"url": "https://colab.research.google.com/drive/19AKhmNGVsLljpnQ9FoL858thZ9W_WrXX", "anchor_text": "Colaboratory notebook"}, {"url": "https://twitter.com/irhumshafkat", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1801.08230", "anchor_text": "Deep Interactive Evolution"}, {"url": "https://towardsdatascience.com/introduction-to-genetic-algorithms-including-example-code-e396e98d8bf3", "anchor_text": "Introduction to genetic algorithms"}, {"url": "https://en.wikipedia.org/wiki/Interactive_evolutionary_computation", "anchor_text": "Interactive Evolutionary Computation"}, {"url": "https://nips2017creativity.github.io/doc/Hierarchical_Variational_Autoencoders_for_Music.pdf", "anchor_text": "Hierarchical Variational Autoencoders for Music"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----11934d7e89a3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/music?source=post_page-----11934d7e89a3---------------music-----------------", "anchor_text": "Music"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----11934d7e89a3---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----11934d7e89a3---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----11934d7e89a3---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&user=Irhum+Shafkat&userId=cb2327c63f48&source=-----11934d7e89a3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&user=Irhum+Shafkat&userId=cb2327c63f48&source=-----11934d7e89a3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F11934d7e89a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----11934d7e89a3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----11934d7e89a3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----11934d7e89a3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----11934d7e89a3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@irhumshafkat?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@irhumshafkat?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Irhum Shafkat"}, {"url": "https://medium.com/@irhumshafkat/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.98K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb2327c63f48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&user=Irhum+Shafkat&userId=cb2327c63f48&source=post_page-cb2327c63f48--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd747d0ac846d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmusic-by-means-of-natural-selection-11934d7e89a3&newsletterV3=cb2327c63f48&newsletterV3Id=d747d0ac846d&user=Irhum+Shafkat&userId=cb2327c63f48&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}