{"url": "https://towardsdatascience.com/5-top-tips-for-data-scraping-using-selenium-d8b83804681c", "time": 1683012192.23441, "path": "towardsdatascience.com/5-top-tips-for-data-scraping-using-selenium-d8b83804681c/", "webpage": {"metadata": {"title": "5 Top Tips for Data Scraping Using Selenium in Python | by Stephen Fordham | Towards Data Science", "h1": "5 Top Tips for Data Scraping Using Selenium in Python", "description": "Selenium is a browser automation library. Most often used for testing web-applications, Selenium may be used for any task that requires automating interaction with the browser. This can include\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.bbc.co.uk/news", "anchor_text": "https://www.bbc.co.uk/news", "paragraph_index": 4}, {"url": "https://github.com/StephenFordham", "anchor_text": "https://github.com/StephenFordham", "paragraph_index": 40}], "all_paragraphs": ["Selenium is a browser automation library. Most often used for testing web-applications, Selenium may be used for any task that requires automating interaction with the browser. This can include web-scraping.", "The following tutorial will be a user-led guide of best practices for web-scraping using selenium. I have listed my 5 top tips that will help the user scrape any data they request as efficiently as possible using Python with as little code as possible.", "To extract the Coronavirus global headlines from BBC news.", "To follow this tutorial, you will need to:", "To begin our web scraping task, we must first navigate to the following page, \u2018https://www.bbc.co.uk/news\u2019. This step can be achieved in as little as three lines of code. First we import the webdriver from selenium, create an instance of the chrome webdriver, and finally call the get method on the webdriver object named driver.", "To make this code short and readable, the chromedriver executable can be placed in a user chosen folder. This destination can then be add to PATH under your environmental variables. The webdriver is then ready to go, simply using webdriver.Chrome() with no arguments passed to Chrome in the parentheses.", "When we have navigated to the web-page, we would like to find the search box, click on it and start typing for the \u2018coronavirus global updates\u2019.", "To find this webelement, we can simply, right-click on chrome and select inspect. In the top left corner of the page that opens up when we inspect, we can use the cursor to hover over and select web elements of interest. As shown, the search box has an input tag, with an id value of \u2018orb-search-q\u2019.", "How can we make sure this the only search element we are interested in?", "We can simply select the console tab window, and then type two dollar signs, followed by parentheses and quotations. Inside the quotes, we write the tag input followed by square brackets. In those square brackets we can add the id and its value.", "As shown, an array of only one element is returned. We can be confident we now have the right search box to click on and start typing our search queries.", "The content of the quotes within the console is a valid CSS selector, and we can use it in our script to find the webelement.", "This leads to the next tip.", "We can now call the find_element_by_css_selector method on the webdriver object driver.", "We want our webdriver to move to this webelement, click on it, type our search query \u2018Global coronavirus updates\u2019 and press enter.", "This can easily be accomplished using the ActionChains and Keys classes from selenium. We simply pass driver to ActionChains, and method chain using the methods, move_to_element, click, send_keys to type input and key_downwith Keys.ENTER passed to imitate enter. To run this command, add the perform method at the end of the ActionChain.", "Running the ActionChain takes us here:", "The webelement shown returns an image, headline, sub-headline, and some accessory information such as the date published.", "How can we capture just the headline from each story?", "If we type the webelement shown below in the console it will return a list of 10 web elements. We want to extract just the headline from each of these stories.", "To do this, we can simple iterate over the 10 stories. In order to do this, we call the find_elements_by_css_selectorwith the web element passed. This method returns a list-like object that we can iterate over.", "We can assign this to the variable name top_titles, and iterate over them using a for loop. In the for loop we can find the element associated with each headline using Tip number 2, and extract the text by calling .text on the webelement.", "In addition to printing to the terminal console, we can also write to a .txt file so we have a permanent copy of the headlines whenever we run the script.", "When we run the script to extract the headlines, a browser window will pop up and run as shown in the video below.", "Whilst this can be interesting to watch, for the most part, this may not be desired.", "To remove the browser, import the Options class from the selenium module, create an instance of this class, and call the add_argumentmethod on this instance with the string argument \u2018 \u2014 headless\u2019 passed. Finally, in the webdriver, under the options parameter, add the variable which points to the headless browser.", "To make sure webscraping is successful, we can introduce a wait into our script. This feature can be particularly useful in cases where web pages load slowly. To do this, we import the three classes shown.", "What is nice about introducing waits is that, when they are constructed they can almost be written as a sentence. Furthermore they can search for the webelement for as long as we choose. If the web element is found earlier, the script simply executes earlier too.", "Here, we pass the WebDriverWait class, our driver object, tell it to wait a maximum of 10 seconds, until the element is located. In the until method, we pass theExpectedConditons class with the alias EC, and call the presence of element located method on it. We then pass this method a locator tuple, detailing what element we are searching for (By.CSS_SELECTOR), and the webelement.", "A wait will make your scripts more robust and less susceptible to Timeout Exceptions.", "The script for these examples is shown altogether here.", "When we are sure that the web automation is working as intended, we can now transform the code into a class. To keep things straightforward for any prospective users of this class, I have decided to call the class CoronaVirusHeadlines.", "In the initconstructor, I set a driver attribute in the object which points to the Chrome webdriver.", "The code is exactly the same as the procedural code shown in the previous sections (except I have removed the headless option). The only exception is the driver has been set as an attribute in the object. The driver gets initialised in the init method, and is used in the get_headlinesmethod to retrieve the headlines.", "To get the headlines, I simply create an instance of this class called, virus_data. I then call the get_headlines method on this class to retrieve the headlines in a .txt file.", "In my local directory, I can now check for the file named \u2018Coronavirus_headlines.txt\u2019.", "As shown below, the headlines have been scraped into a\u00a0.txt file. Please bear in mind that if you run the code yourself, the headlines will of course be different, as the coronavirus pandemic is continually evolving with new stories published to the BBC daily.", "These are some of my best tips for scraping using selenium. Some tips including the actionchain and wait tips can be very readable and easily understood by others who may read your code too.", "The script could easily be extended. You could also navigate onto the second page to retrieve the next 10 headlines. Or maybe you would like the headlines to be emailed or converted into an executable file, so the headlines can be shared with you and your interested colleagues/friends who may not necessarily use Python. This can be achieved using the smtplib or PyInstaller modules, respectively.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Articles on Data Science and Programming https://github.com/StephenFordham"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd8b83804681c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b83804681c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@stephenfordham?source=post_page-----d8b83804681c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenfordham?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Stephen Fordham"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d3f46276e7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&user=Stephen+Fordham&userId=5d3f46276e7e&source=post_page-5d3f46276e7e----d8b83804681c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.istockphoto.com/portfolio/AdaYokota?mediatype=illustration", "anchor_text": "Ada Yokota"}, {"url": "https://chromedriver.storage.googleapis.com/index.html?path=85.0.4183.38/", "anchor_text": "here."}, {"url": "https://www.bbc.co.uk/news", "anchor_text": "https://www.bbc.co.uk/news"}, {"url": "https://medium.com/tag/selenium?source=post_page-----d8b83804681c---------------selenium-----------------", "anchor_text": "Selenium"}, {"url": "https://medium.com/tag/programming?source=post_page-----d8b83804681c---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d8b83804681c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/coding?source=post_page-----d8b83804681c---------------coding-----------------", "anchor_text": "Coding"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d8b83804681c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&user=Stephen+Fordham&userId=5d3f46276e7e&source=-----d8b83804681c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&user=Stephen+Fordham&userId=5d3f46276e7e&source=-----d8b83804681c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd8b83804681c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d8b83804681c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d8b83804681c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d8b83804681c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d8b83804681c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d8b83804681c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d8b83804681c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenfordham?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@stephenfordham?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Stephen Fordham"}, {"url": "https://medium.com/@stephenfordham/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "977 Followers"}, {"url": "https://github.com/StephenFordham", "anchor_text": "https://github.com/StephenFordham"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d3f46276e7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&user=Stephen+Fordham&userId=5d3f46276e7e&source=post_page-5d3f46276e7e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbd4ed43cae00&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-top-tips-for-data-scraping-using-selenium-d8b83804681c&newsletterV3=5d3f46276e7e&newsletterV3Id=bd4ed43cae00&user=Stephen+Fordham&userId=5d3f46276e7e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}