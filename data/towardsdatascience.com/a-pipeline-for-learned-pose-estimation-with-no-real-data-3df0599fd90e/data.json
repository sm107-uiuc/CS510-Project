{"url": "https://towardsdatascience.com/a-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e", "time": 1683015909.372132, "path": "towardsdatascience.com/a-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e/", "webpage": {"metadata": {"title": "A Pipeline for Learned Pose Estimation with No Real Data | by Oliver Gyldenberg Hjermitslev | Towards Data Science", "h1": "A Pipeline for Learned Pose Estimation with No Real Data", "description": "Pose Estimation is a rising trend in Computer Vision contexts, enabling researchers to utilize depth information in images \u2014 a necessity for AR and other spatially dependent applications. Moving on\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://bop.felk.cvut.cz/datasets/", "anchor_text": "LineMOD", "paragraph_index": 2}, {"url": "https://lilianweng.github.io/lil-log/2019/05/05/domain-randomization.html", "anchor_text": "This", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "Object Detection post", "paragraph_index": 4}, {"url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_CVPR_2019_paper.pdf", "anchor_text": "normalized object coordinate space (NOCS)", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1505.04597", "anchor_text": "U-Net", "paragraph_index": 11}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch", "paragraph_index": 11}, {"url": "https://www.fast.ai/", "anchor_text": "fast.ai", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "our last project", "paragraph_index": 24}], "all_paragraphs": ["Pose Estimation is a rising trend in Computer Vision contexts, enabling researchers to utilize depth information in images \u2014 a necessity for AR and other spatially dependent applications. Moving on from traditional computer vision, modern studies use deep neural networks to directly predict 6D pose (ie. rotation and translation), for example by minimizing the error from known perturbations, or directly fitting a 3D model to an input image.", "In this post I will be showcasing a complete neural network based pose estimation pipeline using randomly generated low-fidelity rendered data. Specifically, we will be exploring generating images and ground truth data using just a 3D model, as well as estimating keypoints for pose estimation (and how to do it).", "In my last post, found here, we explored ways to train an object detector using only synthetic data generated using a simple Unity3D engine. Object Detectors normally do not necessitate the use of synthetic data as a wide variety of annotation tools are available \u2014 rather, it simplifies the process substantially and reduces the cost of entry. Pose Estimation, however, is much more difficult to annotate manually, especially if you are not looking to estimate the pose of an object included in the LineMOD or similar datasets.", "Domain Randomization (DR) is the perfect method to generate data for such a project. In short, DR aims to widen the variance of the generated data such that the generated samples encompass the real-life data distribution. This post describes the concept very well. This is the method we will be using to generate data for this project; an end-to-end solution to 6D Pose Estimation of arbitrary objects using nothing but a 3D model.", "In the Object Detection post I showcased our Unity3D data generator, a simple low-fidelity image and bounding-box generator. For this project, we are interested in more than just bounding boxes \u2014 in fact, we are going to need a full corresponding 3D representation of the object. I changed the mask shader from the generator to a normalized object coordinate space (NOCS) shader, which renders the object\u2019s local XYZ space to RGB with Alpha indicating whether the object exists within the pixel. An example can be seen below:", "When generating NOCS-images, it is important to disable any type of antialiasing. Interpolating values can wash out the data, and our final product will be less precise. Depending on the size of the images and severity of the restrictions introduced, we can generate anywhere from thousands to hundreds of thousands of images like this every second on a decent laptop. This can give us a significant advantage compared to annotating real images.", "We decided to take advantage of traditional, established computer vision techniques to estimate the pose of the object \u2014 namely solving the 2D to 3D projection of the object, also known as the Perspective-n-Point problem. This also affords additional robustness to the project, as keypoint representations are much more abstract than trying to fit images directly. This is to our advantage, as our object changes appearance from image to image in order to improve the generalization of the end product. In order to do this, we need to establish a set of baseline keypoints throughout the project.", "Good, trackable keypoints are hard to come by. Luckily, we have a near unlimited number of rendered images of the object(s) of interest (in this case, a Bosch drill) and their respective 3D representations and masks. We can zero all outsize pixels and use OpenCV\u2019s \u201cgoodFeaturesToTrack\u201d method to find trackable corners of the drill. This method provides us with pixel positions of N trackable features thresholded by quality level q and a minimum pixel distance d. We can translate the output feature positions to the object\u2019s local space using the corresponding NOCS-image. We decided on N=32, q=0.2, and d=\u221a(min(image_width, image_height)).", "However, in the end this will just return thousands of disjointed 3D positions. In order to actually establish which are best, we use K-Means to find the centroids of large clusters of these trackable positions. Again we decide to look for 32 keypoints. There are a few downsides to using this simple method; firstly, the keypoints are likely to never be exactly on the model, but ever so slightly inside it, depending on the size and position of the clusters. Secondly, the object is randomly generated and symmetrical, meaning the keypoints found on one side on average look exactly like their (potential) mirror partner.", "After analyzing thousands of images and establishing baseline keypoints using the method described above, we can, for each image-and-NOCS pair, calculate the pixel that most accurately represents each keypoint. This is bound to have some error, so we threshold it to exclude keypoints that do not lie within a certain distance in that image. Of course, this margin should be set with the size of the object in mind. The figure above shows thresholds ranging from 1cm to 0.1 cm, assuming the drill is roughly 22.3cm tall.", "Now that we have 32 baseline keypoints, and can estimate their position in the training data, we need to be able to accurately detect them in an image. We want to take advantage of the powerful visual abstractions afforded by Convolutional Neural Networks (CNNs), so that is where we will start.", "Very simply, one might consider this a regression problem, since we merely want to estimate two numbers (an X and a Y coordinate) for each keypoint. However, the issue is not so straightforward. Spatial awareness is key, and without specifically working this into the network, this information will be lost to fully convolutional layers and pooling. In order to circumvent this issue, we employ a U-Net style CNN with 32 output layers, one for each keypoint. The model was created in PyTorch and fast.ai. Specifically, our network consists of:", "Our targets are currently just a series of numbers (32 keypoints, their position in the frame, and the real-life distance to that position from their centroid). We need targets that our network can compare to and learn from. In order to accomplish this, we rasterize the keypoints as 2D gaussians rather than a simple 1-pixel step. This significantly improves the training, as the network is not equally punished for a close-but-not-quite prediction and a very poor prediction.", "Now, not all 32 keypoints are relevant in every image. Some exceed the distance threshold we decided, and so must be discarded in some way. We find that simply ignoring it (masking away the heatmap when calculating loss) and letting the network decide whether to draw it or not worked better than either trying to suppress it or forcing it.", "Now that we have a data point (a rendered image of a drill) and a target (32 heatmaps), we merely need a loss function. We can see that simply matching the target heatmap with the output heatmap (ignoring invisible points) should provide a decent starting point \u2014 the mean square error. This is good up to a certain point, where the network learns to cheat, either by weakened or multiple guesses. We can compensate for this by introducing regression loss too. A 2D SoftArgMax function allows us to reduce the heatmap estimated by the network to a guess with subpixel precision, perfect for our project which outputs heatmaps in smaller scales than the input image.", "Now that we have created two losses, we need to establish the weight between them. Now, the pixel loss (MSE) can significantly help the network learn an initial representation, but it is ultimately not what we are interested in. In the end, we need the location of the keypoint in the image. I find that starting with 100% pixel loss and moving towards regression loss steadily works well.", "Throughout the training, I recommend steadily dropping loss after each epoch. We do not want the network to overfit to the features of the synthetic data, but we also do not want to wait forever, so we start fairly high (in the range of 0.01 with the Adam optimizer). After a few epochs, when we believe the network has started to learn decent representations, we unlock the initial ResNet layers, allowing the downsampling layers to learn as well.", "I tested the training scheme for 20 epochs of 1000 iterations of batch size 32. At the end of each epoch we update the weights of the combination loss and learning rate. They consist of 32000 images of a total 200000 rendered, meaning epochs will have some overlap. With the severely reduced learning rate in the later epochs, this matters much less. In the end, our loss curve looks a bit like this:", "There are two things to take note of: Training loss deviates significantly in some places, namely the initial release of the downsampling layers (epoch 5) and each increase of regression loss and subsequent decrease of pixel loss. The other notable observation to make is the validation loss, how it steadies relative to the training loss with no obvious signs of overfitting. This can be, in part, attributed to the steady decrease in learning rate as well as the split training set combined with the changing combination loss weights.", "In practice, it is nigh impossible to avoid overfitting to the data distribution of our Unity renderer. This can introduce artifacts in the real-life experiments, for example caused by mismatching objects and 3D models. One way to overcome this hurdle is to annotate an additional training set composed of images from the real world, fine-tuning the keypoint detector on real-life images to solve the sim2real transfer problem.", "Now that the network has trained for some time, let us see if it can detect some keypoints.", "This looks fairly accurate, but of course there is no guarantee that the keypoints are correct. We can visualize the heatmaps next to their target as such:", "That also looks pretty good. That should mean that, knowing the physical dimensions of the 3D model, and subsequently the keypoint locations within it, as well as the camera parameters, we can project points into the object space.", "First, we estimate the intrinsic camera parameters. Secondly, we need to determine which keypoints to mask by thresholding. We decided earlier to use distance in the NOCS-image, but this is not feasible for the validation images as we theoretically have no target data. Instead, we decide on a threshold and include any keypoints that satisfy the condition max(heatmap) \u2265 threshold * max(all_heatmaps). Finally, we can estimate the rotation and translation of the camera by utilizing OpenCV\u2019s SolvePnP with an iterative solver \u2014 slower, but the outcome is more robust.", "Now, the final hurdle: How well does the model trained with synthetic data translate to real-world conditions? I made a quick Request/Response server and mobile app using Unity and ARFoundation to test the accuracy of the predictions. In our last project, we had some very good results. Let us see if we can replicate them:", "These results look very decent. There are a few obvious mistakes, but the general orientation of the drill and its size within the camera space is clearly known. Again, the neural network has never seen a real drill, nor the artifacts of image capturing and compression, so for it to guess this well after such a short period of time is a great success.", "There you have it! A complete pipeline for pose estimation from 3D model to results. We have explored data generation using domain randomization in Unity, keypoint estimation and training a neural network to predict their positions, as well as projecting these to 3D. The results show a lot of promise, transferring to real-world image data fairly robustly. This just goes to show that synthetic data can be a great stepping stone for entry into the world of deep learning and computer vision with little to no cost.", "I work at the Alexandra Institute, a Danish non-profit company specializing in state of the art IT solutions. Here in the Visual Computing Lab, we focus on utilizing the newest in computer vision and computer graphics research. We are currently exploring options for data gathering and annotation to allow smaller companies and individuals to get started with deep learning. We are always open to collaboration!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Visual Computing Specialist at the Alexandra Institute, Denmark. I work with computer vision, computer graphics, and deep learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3df0599fd90e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://olivergh.medium.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": ""}, {"url": "https://olivergh.medium.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Oliver Gyldenberg Hjermitslev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe802b1db7727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&user=Oliver+Gyldenberg+Hjermitslev&userId=e802b1db7727&source=post_page-e802b1db7727----3df0599fd90e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "here"}, {"url": "https://bop.felk.cvut.cz/datasets/", "anchor_text": "LineMOD"}, {"url": "https://lilianweng.github.io/lil-log/2019/05/05/domain-randomization.html", "anchor_text": "This"}, {"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "Object Detection post"}, {"url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_CVPR_2019_paper.pdf", "anchor_text": "normalized object coordinate space (NOCS)"}, {"url": "https://arxiv.org/abs/1505.04597", "anchor_text": "U-Net"}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch"}, {"url": "https://www.fast.ai/", "anchor_text": "fast.ai"}, {"url": "https://arxiv.org/abs/1707.02937", "anchor_text": "ICNR PixelShuffle"}, {"url": "https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6", "anchor_text": "our last project"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3df0599fd90e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/domain-randomization?source=post_page-----3df0599fd90e---------------domain_randomization-----------------", "anchor_text": "Domain Randomization"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3df0599fd90e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----3df0599fd90e---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----3df0599fd90e---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&user=Oliver+Gyldenberg+Hjermitslev&userId=e802b1db7727&source=-----3df0599fd90e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&user=Oliver+Gyldenberg+Hjermitslev&userId=e802b1db7727&source=-----3df0599fd90e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3df0599fd90e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3df0599fd90e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3df0599fd90e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3df0599fd90e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3df0599fd90e--------------------------------", "anchor_text": ""}, {"url": "https://olivergh.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://olivergh.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Oliver Gyldenberg Hjermitslev"}, {"url": "https://olivergh.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "64 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe802b1db7727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&user=Oliver+Gyldenberg+Hjermitslev&userId=e802b1db7727&source=post_page-e802b1db7727--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F60dc4c4162cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-pipeline-for-learned-pose-estimation-with-no-real-data-3df0599fd90e&newsletterV3=e802b1db7727&newsletterV3Id=60dc4c4162cd&user=Oliver+Gyldenberg+Hjermitslev&userId=e802b1db7727&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}