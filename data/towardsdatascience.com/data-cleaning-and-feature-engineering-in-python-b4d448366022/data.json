{"url": "https://towardsdatascience.com/data-cleaning-and-feature-engineering-in-python-b4d448366022", "time": 1682995719.32735, "path": "towardsdatascience.com/data-cleaning-and-feature-engineering-in-python-b4d448366022/", "webpage": {"metadata": {"title": "Data cleaning and feature engineering in Python | by Scott Johnson | Towards Data Science", "h1": "Data cleaning and feature engineering in Python", "description": "Housing price data provides a great introduction to machine learning. Anybody who has bought a house or even rented an apartment can easily understand the features: more space, and more rooms\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/RuiChang123/Regression_for_house_price_estimation/blob/master/final_data.csv", "anchor_text": "https://github.com/RuiChang123/Regression_for_house_price_estimation/blob/master/final_data.csv", "paragraph_index": 2}], "all_paragraphs": ["Housing price data provides a great introduction to machine learning. Anybody who has bought a house or even rented an apartment can easily understand the features: more space, and more rooms, generally lead to a higher price.", "So it ought to be easy to develop a model \u2014 but sometimes it isn\u2019t, not because machine learning is hard but because data is messy. Also, prices for the exact same house in different neighborhoods of the same city, even only a mile away, may have significantly different prices. The best way to deal with this is to engineer the data so that the model can better handle this situation.", "Since finding data can be the hardest problem in machine learning, we will use a great sample set from another data science project on Github which is a set of housing prices in San Francisco, mostly over the last few years, scraped from San Francisco Chronicle home sale listings. This data set can be found here: https://github.com/RuiChang123/Regression_for_house_price_estimation/blob/master/final_data.csv", "First, we\u2019ll load the data from a local copy of the file.", "Now, let\u2019s take a look at a few graphs of this data set, graphing the total number of rooms by the last sold price.", "That single point in the far lower-right corner is an outlier. Its value is so extreme that it skews the entire graph, so much that we cannot even see any variation on the main set of data. This will distort any attempt to train a machine learning algorithm on this data set. We need to look more closely at this data point and consider what to do with it. If we sort the data by the total number of rooms, one of our axes above, it should stick out.", "Indeed, that data point does stick out. It is the very last value in the list, which is a house that has 1,264 rooms! That is very suspicious, especially since the plot shows it having a pretty low price. At the very least it is wildly inconsistent with the rest of the data. The same may be the case with the previous value showing 94 rooms. We can take a closer look at these two houses with the following commands, pulling them up by their numeric identifier.", "First let\u2019s look at the house which supposedly has 1,264 rooms:", "This query shows something even more suspicious, which is that the \u201cfinishedsqft\u201d field is also 1264.0. In other words, this is clearly just an error, probably on data entry \u2014 when the original data set was created, somebody accidentally used the same value for both finishedsqft and totalrooms.", "Now, let\u2019s take a look at the value just preceding it, with 94 rooms:", "This home which supposedly has 94.0 rooms has only two bedrooms and two bathrooms! Again, this is an error. It is not clear how this crept in, but we can be pretty certain that if we go to this house, it does not have 94 rooms, but only two bedrooms and two bathrooms. We will need to eliminate these two data points but first let\u2019s take another look at a graph of finishedsqft:", "There is another outlier in the lower-right. Let\u2019s take a closer look at this data:", "First, unexpectedly, there are ten houses listed at 1.0 square feet. This is clearly wrong. Note that these were impossible to see in the graph, we had to look at the actual values. Additionally, the above results show the largest house at 27,275.0 square feet. It turns out, this is a house with only 2.0 bedrooms and 2.0 bathrooms, even though it is listed at 27,275 square feet, so this is almost certainly a mistake, or at least an extreme outlier. Let\u2019s eliminate all of these outliers and take another look at the graph.", "This is looking much better. There still may be some outliers in here, and we could investigate them more closely if we really wanted to, but there are no single data points in this view that are distorting the graph, and probably none (that we can see) that would distort a machine learning model.", "Now that we have cleaned the data, we need to do some feature engineering. This involves transforming the values in the data set into numeric values that machine learning algorithms can use.", "Take the \u201clastsolddate\u201d value, for example. In the current data set, this is a string in the form of \u201cmm/dd/yyyy.\u201d We need to change this into a numeric value, which we can do with the following Pandas command:", "Now let\u2019s create a checkpoint for our data so that we can refer back to it later.", "Additionally, there are a number of fields that we cannot or should not use, so we will eliminate them.", "I prefer to create functions to do this sort of work that we might do again and again, as we will see below, in order to simplify the code as we try out different hypotheses.", "We remove the columns in remove_list for a number of reasons. Some of them are text values we just cannot do much with (info, address, z_address, zipcode, zpid). The latitude and longitude fields might be useful in some form but for this example it may just complicate things \u2014 no reason not to experiment with it in the future though. The zestimate and zindexvalue fields were actually produced by other data science techniques (probably from Zillow), so using them would be cheating! Finally, we will drop usecode (e.g. house, condo, mobile home) which could be quite useful but we will not use it for this example.", "Now that we have cleaned up the data, let\u2019s take a look at how a few algorithms manage using it. We will use scikit-learn.", "First, we need to split the data into testing and training sets, again using a function that we can reuse later. This assures that when we test the data, we are actually testing the model on data it has never seen before.", "This train_eval function can be used for any arbitrary scikit-learn algorithm, for both training and evaluation. This is one of the great benefits of scikit-learn. The first line of the function incorporates a set hyperparameters that we want to evaluate against. In this case, we pass in {} so we can just use the default hyperparameters on the model. The second and third lines of this function do the actual work, fitting the model and then running a prediction on it. The print statements then show some stats that we can evaluate. Let\u2019s see how we faired.", "The first score, R\u00b2, also known as the Coefficient of Determination, is a general evaluation of the model showing the percentage of variation in the prediction that can be explained by the features. In general, a higher R\u00b2 value is better than a lower one. The other two stats are root mean squared error and mean absolute error. These two can only be evaluated in relation to other evaluations of the same statistic on other models. Having said that, an R\u00b2 of .53, and the other stats in the many hundreds of thousands (for houses probably costing one or two million) is not great. We can do better.", "Let\u2019s see how a few other algorithms perform. First, K-Nearest Neighbors (KNN).", "If Linear Regression is mediocre, KNN is terrible!", "Next we will try Decision Tree.", "Finally, let\u2019s look at Random Forrest.", "This one is a bit better, but we can still do better.", "How do we improve on these results? One option is to try other algorithms, and there are many, and some will do better. But we can actually fine tune our results by getting our hands dirty in the data with feature engineering.", "Let\u2019s reconsider some of the features that we have in our data. Neighborhood is an interesting field. The values are things like \u201cPortrero Hill\u201d and \u201cSouth Beach.\u201d These cannot be simply ordered (from most expensive to least expensive neighborhood), or at least, doing so would not necessarily produce better results. But we all know that the same house in two different neighborhoods will have two different prices. So we want this data. How do we use it?", "Python\u2019s Pandas library gives us a simple tool for creating a \u201cone-hot encoding\u201d of these values. This takes the single column of \u201cneighborhood\u201d and creates a new column for each value in the original neighborhood column. For each of these new rows (with new column header names like \u201cPortrero Hill\u201d and \u201cSouth Beach\u201d), if a row of data has that value for the neighborhood in the original column, it is set to 1, otherwise it is set to 0. The machine learning algorithms can now build a weight associated with that neighborhood, which is either applied if the data point is in that neighborhood (if the value for that column is 1) or not (if it is 0).", "First, we need to retrieve our check-pointed data, this time keeping the \u201cneighborhood\u201d field.", "Now we can create a one-hot encoding for the \u201cneighborhood\u201d field.", "We will hold onto the \u201cone_hot\u201d value and add it later. But first, we have to do two more things. We need to split the data into a training set and a test set.", "For our final step, we need to scale and center the data.", "Let\u2019s unpack this step a bit.", "First, we apply StandardScaler(). This function scales and centers the data by subtracting the mean of the column and dividing the standard deviation of the column, for all data points in each column. This standardizes all of the data, giving each column a normal distribution. It also scales the data, because some fields will vary from 0 to 10,000, such as \u201cfinishedsqft,\u201d while others will vary only from 0 to 30, such as number of rooms. Scaling will put them all on the same scale, so that one feature does not arbitrarily play a bigger role than others just because it has a higher maximum value. For some machine learning algorithms, as we will see below, this is critical to getting even a half decent result.", "Second, it is important to note that we have to \u201cfit\u201d the scaler on the training features, X_train. That is, we take the mean and standard deviation of the training data, fit the scaler object with these values, then transform the training data AND the test data using that fitted scaler. We do not want to fit the scaler on the test data, as that would then leak information from the test data set into the trained algorithm. We could end up with results that appear better than they are (because the algorithm already is trained on test data) or appear worse (because the test data is scaled on their own data set, and not on the test data set).", "Now, let\u2019s rebuild our models with the newly engineered features.", "Now, under Linear Regression, the simplest algorithm we have, the results are already better than anything we saw previously.", "This is an a huge improvement.", "Still pretty bad, but better than before.", "There is certainly far more that can be done with this data, from additional feature engineering to trying additional algorithms. But the lesson, from this short tutorial, is that seeking more data or pouring over the literature for better algorithms may not always be the right next step. It may be better to get the absolute most you can out of a simpler algorithm first, not only for comparison but because data cleaning may pay dividends down the road.", "Finally, in spite of its simplicity, K-Nearest Neighbors can be quite affective, so long as we treat it with the proper care.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software developer and data engineer based in the San Francisco Bay Area"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb4d448366022&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b4d448366022--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@scottdonaldjohnson?source=post_page-----b4d448366022--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@scottdonaldjohnson?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Scott Johnson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2459d2d9ebf7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&user=Scott+Johnson&userId=2459d2d9ebf7&source=post_page-2459d2d9ebf7----b4d448366022---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/RuiChang123/Regression_for_house_price_estimation/blob/master/final_data.csv", "anchor_text": "https://github.com/RuiChang123/Regression_for_house_price_estimation/blob/master/final_data.csv"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b4d448366022---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/feature-engineering?source=post_page-----b4d448366022---------------feature_engineering-----------------", "anchor_text": "Feature Engineering"}, {"url": "https://medium.com/tag/python?source=post_page-----b4d448366022---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----b4d448366022---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&user=Scott+Johnson&userId=2459d2d9ebf7&source=-----b4d448366022---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&user=Scott+Johnson&userId=2459d2d9ebf7&source=-----b4d448366022---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b4d448366022--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb4d448366022&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b4d448366022---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b4d448366022--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b4d448366022--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b4d448366022--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b4d448366022--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b4d448366022--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@scottdonaldjohnson?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@scottdonaldjohnson?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Scott Johnson"}, {"url": "https://medium.com/@scottdonaldjohnson/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "84 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2459d2d9ebf7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&user=Scott+Johnson&userId=2459d2d9ebf7&source=post_page-2459d2d9ebf7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F2459d2d9ebf7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-cleaning-and-feature-engineering-in-python-b4d448366022&user=Scott+Johnson&userId=2459d2d9ebf7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}