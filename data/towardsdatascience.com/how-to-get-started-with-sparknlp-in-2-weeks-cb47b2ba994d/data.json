{"url": "https://towardsdatascience.com/how-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d", "time": 1683012715.648494, "path": "towardsdatascience.com/how-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d/", "webpage": {"metadata": {"title": "How to Get Started with Spark NLP in 2 Weeks \u2014 Part I | by Mustafa Aytu\u011f Kaya | Towards Data Science", "h1": "How to Get Started with Spark NLP in 2 Weeks \u2014 Part I", "description": "If you want to make a head start in enterprise NLP, but have no clue about Spark, this article is for you. I have seen many colleagues wanting to step to this domain but disheartened due to the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kdnuggets.com/2019/06/spark-nlp-getting-started-with-worlds-most-widely-used-nlp-library-enterprise.html", "anchor_text": "few reasons", "paragraph_index": 1}, {"url": "https://analyticsindiamag.com/5-reasons-why-spark-nlp-is-the-most-widely-used-library-in-enterprises/", "anchor_text": "benchmarking", "paragraph_index": 3}, {"url": "https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html", "anchor_text": "official website", "paragraph_index": 16}, {"url": "https://medium.com/spark-nlp/introduction-to-spark-nlp-installation-and-getting-started-part-ii-d009f7a177f3", "anchor_text": "here", "paragraph_index": 16}, {"url": "https://medium.com/@GalarnykMichael/install-spark-on-windows-pyspark-4498a5d8d66c", "anchor_text": "this article", "paragraph_index": 17}, {"url": "https://changhsinlee.com/install-pyspark-windows-jupyter/", "anchor_text": "blog page", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c", "anchor_text": "this article", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/dual-boot-is-dead-windows-and-linux-are-now-one-27555902a128", "anchor_text": "WSL 2", "paragraph_index": 20}, {"url": "https://www.phoronix.com/scan.php?page=article&item=windows-10-wsl2&num=2", "anchor_text": "this benchmarking article", "paragraph_index": 20}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "DataFrame API", "paragraph_index": 24}, {"url": "https://spark.apache.org/", "anchor_text": "Spark", "paragraph_index": 25}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy", "paragraph_index": 25}, {"url": "https://learn.datacamp.com/courses/big-data-fundamentals-with-pyspark", "anchor_text": "this course", "paragraph_index": 27}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Transformer", "anchor_text": "Transformer", "paragraph_index": 31}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Estimator", "anchor_text": "Estimator", "paragraph_index": 32}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Pipeline", "anchor_text": "Pipeline", "paragraph_index": 33}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html", "anchor_text": "Pyspark.sql module", "paragraph_index": 36}, {"url": "https://learn.datacamp.com/courses/feature-engineering-with-pyspark", "anchor_text": "Feature Engineering with Pyspark", "paragraph_index": 36}, {"url": "https://learn.datacamp.com/courses/cleaning-data-with-pyspark", "anchor_text": "This course", "paragraph_index": 36}, {"url": "https://hackersandslackers.com/transforming-pyspark-dataframes/", "anchor_text": "these exercises", "paragraph_index": 37}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 37}, {"url": "https://www.gutenberg.org/", "anchor_text": "Project Gutenberg", "paragraph_index": 37}, {"url": "https://github.com/vkocaman/PySpark_Essentials_March_2019/blob/master/PySpark%20-%20From%20Zero%20to%20Hero%20(Sept%202019).ipynb", "anchor_text": "notebook", "paragraph_index": 37}, {"url": "https://github.com/changhsinlee/changhsinlee.github.io/blob/master/notebook/2018-03-04-pyspark-dataframe-basics/dataframe-basics.ipynb", "anchor_text": "this notebook", "paragraph_index": 37}, {"url": "https://github.com/changhsinlee/changhsinlee.github.io/blob/master/notebook/2018-03-04-pyspark-dataframe-basics/dataframe-basics.ipynb", "anchor_text": "this article", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/how-to-wrap-your-head-around-spark-nlp-a6f6a968b7e8", "anchor_text": "Part II \u2014 How to Wrap Your Head Around Spark NLP", "paragraph_index": 38}], "all_paragraphs": ["If you want to make a head start in enterprise NLP, but have no clue about Spark, this article is for you. I have seen many colleagues wanting to step to this domain but disheartened due to the initial learning overhead that comes with Spark. It may seem inconspicuous at first glance since Spark code is a bit different than your regular Python script. However, Spark and Spark NLP basics aren\u2019t really hard to learn. If you axiomatically accept this assertion, I will show you how easy the basics are and will provide a road map to pave the way to learn key elements, which will satisfy most use cases of an intermediate level practitioner. Due to impeccable modularity that comes with Spark NLP pipelines, for an average learner, -mark my words- two weeks will be enough to build basic models. Roll up your sleeves, here we start!", "Why Spark NLP?Supply and Demand is the answer: It Is The Most Widely Used Library In Enterprises! Here are a few reasons why. Common NLP packages today have been designed by academics and they favor ease of prototyping over runtime performance, eclipsing scalability, error handling, target frugal memory consumption and code reuse. Although some libraries like \u2018the industrial-strength NLP library \u2014 spaCy\u2019 might be considered an exception (since they are designed to get things done rather than doing research), they may fall short of enterprise targets when it comes to dealing with data in volume.", "We are going to have a different strategy here. Rather than following the crowds in the routine, we will use basic libraries to brush up \u2018basics\u2019 and then jump directly to address the enterprise sector. Our final aim is to target the niche by building continental pipelines, which are impossible to resolve with standard libraries, albeit their capacity in their league.", "If you are not convinced yet, please read this article for benchmarking and comparison with spaCy, which will give you five good reasons to start with Spark NLP. First of all Spark NLP has the innate trait of scalability it inherits from Spark, which was primarily used for distributed applications, it is designed to be scalable. Spark NLP benefits from this since it can scale on any Spark cluster as well as on-premise and with any cloud provider. Furthermore, Spark NLP optimizations are done in such a way that it could run orders of magnitude faster than what the inherent design limitations of legacy libraries allow. It provides the concepts of annotators and it includes more than what other NLP libs include. It includes sentence detection, tokenization, stemming, lemmatization, POS Tagger, NER, dependency parse, text matcher, date matcher, chunking, context-aware spell checking, sentiment detector, pre-trained models, and training models with very high accuracy according to academic peer-reviewed results. Spark NLP also includes production-ready implementation of BERT embeddings for named entity recognition. For example, it makes much fewer errors on NER compared to spaCy, which we tested in the second part of this article. Also, worthy of notice, Spark NLP includes features that provide full Python API, supports training on GPU, user-defined deep learning networks, Spark, and Hadoop.", "The library comes with a production-ready implementation of BERT embeddings and uses transfer learning for data extraction. Transfer learning is a highly-effective method of extracting data that can leverage even small amounts of data. As a result, there\u2019s no need to collect large amounts of data to train SOTA models.", "Also, John Snow labs Slack channel provides top tier support that is beneficial because developers and new learners tend to band together and create resources that every one of them can benefit from. You will get answers to your questions right from the developers with dedication. I have been there a few times, can attest that they are quick and accurate in their response. Additionally, anyone finding themselves stuck can quickly get help from people that have had similar problems through Stack Overflow or similar platforms.", "Famous \u201cFacts\u201d About Spark That Are Wrong", "- Spark is cluster computing so it can\u2019t be run on local machines", "Wrong! You can run Spark on your local machine, and each CPU core will be used to the core! That\u2019s how it looks like when Spark NLP is in action:", "What\u2019s even more, you can run Spark on GPU.", "- Spark is yet another language to learn!", "Well, if you know SQL, PySpark and Spark NLP is not going to feel like another language at all. SQL and Regex are all languages on their own, but it wasn\u2019t hard to learn their basics, right?", "- Spark is built for big data, so Spark NLP is only good for big data.", "Yes, there is a significant overhead used for Spark internals, but Spark NLP introduces a \u2018Light Pipeline\u2019 for smaller datasets.", "At first, Spark seems like another challenging language to learn. Spark isn\u2019t the easiest library to comprehend, but what we will be doing in the NLP domain has been skillfully crafted in Spark NLP\u2019s infrastructure provided by a simple API that can be easily interacted with.", "While being one of the sharpest pencils in a data scientist\u2019s toolbox, Pandas uses only a single CPU core, and in essence, it is not fast or robust enough to handle bigger datasets. Spark was designed to hurdle those deficiencies using cluster computing, and you can even run it on your local machine, assigning as many CPU cores as you want! Unfortunately, even though it runs on a local machine, pip install Pyspark is not enough to set it up, and a series of dependencies must be installed on PC and Mac. For those who want to jump into action as quickly as possible, I recommend the use of Google Colab.", "1) Setting up on Mac or LinuxTo utilize Spark NLP, Apache Spark version 2.4.3 and higher must be installed. Assuming that you haven\u2019t installed Apache Spark yet, let\u2019s start with Java installation at first. Just go to the official website and from \u201cJava SE Development Kit 8u191\u201d, and install JDK 8. A necessary command-line script can be found in detail here.", "2) Setting up Spark on a PC can be a little bit tricky. Having tried many methods, I found this article to be the only one that works. It also includes a clear and concise video. In addition to the provided documentation, this blog page also helped me.", "3) Unless you have to run Spark on your local machine, the easiest way to get started with PySpark is using Google Colab. Since it is essentially a Jupyter Notebook that runs on Google server, you don\u2019t need to install anything in our system locally.", "To run spark in Colab, first, we need to install all the dependencies in the Colab environment such as Apache Spark 2.3.2 with Hadoop 2.7, Java 8, and Findspark to locate the spark in the system. Please refer to this article for further details.", "For PC users who don\u2019t want to run their notebooks on Colab, I recommend installing Spark NLP on a dual boot Linux system or using WSL 2, however, this benchmarking article reflects some performance loss with WSL 2. To be more precise, I had my best Spark NLP experience after a dual boot Ubuntu 20.04 installation.", "Day 2: Spark Basics, RDD Structure, and NLP Baby Steps with Spark", "As previously mentioned, Apache Spark is a distributed cluster computing framework that is highly efficient for large data sets using in-memory computations for lightning-fast data processing. It is also considered to be more efficient than MapReduce for the complex application running on Disk.", "While libraries like pandas are adequate for most everyday operations, big data requires a cluster computing framework due to the volume, variety, and velocity, which are three defining properties or dimensions of big data.", "At the center of Spark is the Spark Core \u2014 the foundation of the overall project, on top of which the rest of Spark libraries are built. Spark SQL lets you query structured data inside Spark programs, using either SQL or a familiar DataFrame API.", "MLlib fits into Spark\u2019s APIs and interoperates with NumPy in Python and R libraries. You can use any Hadoop data source, making it easy to plug into Hadoop workflows. Spark excels at iterative computation, enabling MLlib to run fast \u2014 up to 100x faster than MapReduce.", "Spark Mllib contains the legacy API built on top of RDDs. Although I find Spark Mllib and RDD structure easier to use as a Python practitioner, as of Spark 2.0, the RDD-based APIs in the Spark.MLlib package has entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the Spark ML package.", "Transformations create new RDDs and actions to perform calculations. Lambda, Map, and Filter are some of the basic functions. Real datasets are generally key, value pairs similar to Python dictionaries but are represented like tuples. Please observe the code below for creating bigrams and word counts to see how similar to Python code it is. I would highly recommend this course for further details.", "Day 3/4: Feature Engineering / Cleaning Data with Pyspark", "Spark ML provides higher-level API built on top of DataFrames for constructing ML pipelines, standardizing APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single workflow. Here we will cover the key concepts introduced by the Spark ML API.", "Machine learning steps can be applied to from Spark SQL to support a variety of data types under a unified Dataset concept. A SchemaRDD can be created either implicitly or explicitly from a regular RDD.", "A Transformer is an abstraction which includes feature transformers and learned models, implementing a method transform() which converts one SchemaRDD into another, generally by appending one or more columns.", "An Estimator abstracts the concept of a learning algorithm or any algorithm which fits or trains on data, implementing a method fit() which accepts a SchemaRDD and produces a Transformer. For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Transformer.", "In machine learning, it is common to run a sequence of algorithms to process and learn from data such as splitting each document text into words, converting words into a numerical feature vector, and training a prediction model using the feature vectors and labels. Spark ML represents such workflows as Pipelines, which consist of a sequence of Transformers and Estimators to be run in a specific order, calling transform() and fit() methods respectively, to produce a Transformer (which becomes part of the PipelineModel, or fitted Pipeline), and that Transformer\u2019s transform() method is called on the dataset.", "A Pipeline is an Estimator. Thus, after a Pipeline\u2019s fit() method runs, it produces a PipelineModel which is a Transformer. Once the PipelineModel\u2019s transform() method is called on a test dataset, the data passes through the Pipeline in order, updating the data set as each stage\u2019s transform() method updates it and passes it to the next stage.", "Pipelines and PipelineModels help to ensure that training and test data go through identical feature processing steps. Below is an example of a pipeline model. Please note that data preprocessing is carried out on a Pandas Dataframe.", "In PySpark, interactions with SparkSQL through DataFrame API and SQL queries are priority subjects to learn. Pyspark.sql module must be perused for a better understanding of basic operations. DataFrame transformations and actions are not too hard to construct programmatically and operations on DataFrames can also be done using SQL queries. If you have time to take only one course, please spend it on Feature Engineering with Pyspark course by John Hogue. This course is also recommended, time permitting (Day 5).", "The best way to learn is practice. You will need a hardened skill set for next week. Try to deep dive into Pyspark modules, since you will be extensively using them. To re-iterate \u201cFirst Steps With PySpark and Big Data Processing\u201d, please follow these exercises. It is a recommended practice to download some datasets from Kaggle or Project Gutenberg and solve pre-processing problems, as well as others. Please follow this excellent notebook from the creators of Spark NLP. For additional resources, please observe this notebook and this article.", "Next Up: Part II \u2014 How to Wrap Your Head Around Spark NLP. In this part, we will understand \u201cAnnotators /Transformers in Spark NLP\u201d and emphasize \u201cText Preprocessing with Spark\u201d, \u201cPretrained Models\u201d and \u201cText Classifiers\u201d using numerous notebooks. Moreover, we will run a complete pipeline with spaCy and SparkNLP and compare the results.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcb47b2ba994d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@m.aytugkaya?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@m.aytugkaya?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Mustafa Aytu\u011f Kaya"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fde9f6a439ca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&user=Mustafa+Aytu%C4%9F+Kaya&userId=de9f6a439ca2&source=post_page-de9f6a439ca2----cb47b2ba994d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/photo/green-mountain-surrounded-by-body-of-water-photo-225203/", "anchor_text": "Photo: Borislav Krutsev"}, {"url": "https://www.kdnuggets.com/2019/06/spark-nlp-getting-started-with-worlds-most-widely-used-nlp-library-enterprise.html", "anchor_text": "few reasons"}, {"url": "https://analyticsindiamag.com/5-reasons-why-spark-nlp-is-the-most-widely-used-library-in-enterprises/", "anchor_text": "benchmarking"}, {"url": "https://spacy.io/usage/examples#multi-processing", "anchor_text": "Joblib for multiprocessing"}, {"url": "https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html", "anchor_text": "official website"}, {"url": "https://medium.com/spark-nlp/introduction-to-spark-nlp-installation-and-getting-started-part-ii-d009f7a177f3", "anchor_text": "here"}, {"url": "https://medium.com/@GalarnykMichael/install-spark-on-windows-pyspark-4498a5d8d66c", "anchor_text": "this article"}, {"url": "https://changhsinlee.com/install-pyspark-windows-jupyter/", "anchor_text": "blog page"}, {"url": "https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c", "anchor_text": "this article"}, {"url": "https://towardsdatascience.com/dual-boot-is-dead-windows-and-linux-are-now-one-27555902a128", "anchor_text": "WSL 2"}, {"url": "https://www.phoronix.com/scan.php?page=article&item=windows-10-wsl2&num=2", "anchor_text": "this benchmarking article"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "DataFrame API"}, {"url": "https://spark.apache.org/", "anchor_text": "Spark"}, {"url": "http://www.numpy.org/", "anchor_text": "NumPy"}, {"url": "https://learn.datacamp.com/courses/big-data-fundamentals-with-pyspark", "anchor_text": "this course"}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Transformer", "anchor_text": "Transformer"}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Estimator", "anchor_text": "Estimator"}, {"url": "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.ml.Pipeline", "anchor_text": "Pipeline"}, {"url": "http://www.[", "anchor_text": "www.["}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html", "anchor_text": "Pyspark.sql module"}, {"url": "https://learn.datacamp.com/courses/feature-engineering-with-pyspark", "anchor_text": "Feature Engineering with Pyspark"}, {"url": "https://learn.datacamp.com/courses/cleaning-data-with-pyspark", "anchor_text": "This course"}, {"url": "https://hackersandslackers.com/transforming-pyspark-dataframes/", "anchor_text": "these exercises"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://www.gutenberg.org/", "anchor_text": "Project Gutenberg"}, {"url": "https://github.com/vkocaman/PySpark_Essentials_March_2019/blob/master/PySpark%20-%20From%20Zero%20to%20Hero%20(Sept%202019).ipynb", "anchor_text": "notebook"}, {"url": "https://github.com/changhsinlee/changhsinlee.github.io/blob/master/notebook/2018-03-04-pyspark-dataframe-basics/dataframe-basics.ipynb", "anchor_text": "this notebook"}, {"url": "https://github.com/changhsinlee/changhsinlee.github.io/blob/master/notebook/2018-03-04-pyspark-dataframe-basics/dataframe-basics.ipynb", "anchor_text": "this article"}, {"url": "https://towardsdatascience.com/how-to-wrap-your-head-around-spark-nlp-a6f6a968b7e8", "anchor_text": "Part II \u2014 How to Wrap Your Head Around Spark NLP"}, {"url": "https://medium.com/tag/spark?source=post_page-----cb47b2ba994d---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/spark-nlp?source=post_page-----cb47b2ba994d---------------spark_nlp-----------------", "anchor_text": "Spark Nlp"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&user=Mustafa+Aytu%C4%9F+Kaya&userId=de9f6a439ca2&source=-----cb47b2ba994d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&user=Mustafa+Aytu%C4%9F+Kaya&userId=de9f6a439ca2&source=-----cb47b2ba994d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcb47b2ba994d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cb47b2ba994d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cb47b2ba994d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@m.aytugkaya?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@m.aytugkaya?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mustafa Aytu\u011f Kaya"}, {"url": "https://medium.com/@m.aytugkaya/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "51 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fde9f6a439ca2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&user=Mustafa+Aytu%C4%9F+Kaya&userId=de9f6a439ca2&source=post_page-de9f6a439ca2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F988bb29068f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d&newsletterV3=de9f6a439ca2&newsletterV3Id=988bb29068f8&user=Mustafa+Aytu%C4%9F+Kaya&userId=de9f6a439ca2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}