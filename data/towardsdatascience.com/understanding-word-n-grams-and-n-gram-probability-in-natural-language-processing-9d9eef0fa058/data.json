{"url": "https://towardsdatascience.com/understanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058", "time": 1683001638.4424589, "path": "towardsdatascience.com/understanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058/", "webpage": {"metadata": {"title": "Understanding Word N-grams and N-gram Probability in Natural Language Processing | by Sunny Srinidhi | Towards Data Science", "h1": "Understanding Word N-grams and N-gram Probability in Natural Language Processing", "description": "N-gram is probably the easiest concept to understand in the whole machine learning space, I guess. An N-gram means a sequence of N words. So for example, \u201cMedium blog\u201d is a 2-gram (a bigram), \u201cA\u2026"}, "outgoing_paragraph_urls": [{"url": "https://blog.contactsunny.com/data-science/optimising-a-fasttext-model-for-better-accuracy", "anchor_text": "optimise our machine learning model", "paragraph_index": 13}, {"url": "https://blog.contactsunny.com/data-science/an-intro-to-text-classification-with-facebooks-fasttext-natural-language-processing", "anchor_text": "intro to the fastText library", "paragraph_index": 13}, {"url": "https://twitter.com/contactsunny", "anchor_text": "Twitter", "paragraph_index": 14}, {"url": "https://blog.contactsunny.com/tag/data-science", "anchor_text": "Data Science", "paragraph_index": 14}, {"url": "https://blog.contactsunny.com/tag/machine-learning", "anchor_text": "Machine Learning", "paragraph_index": 14}, {"url": "https://blog.contactsunny.com/category/tech", "anchor_text": "tech updates", "paragraph_index": 14}, {"url": "https://blog.contactsunny.com/", "anchor_text": "follow my personal blog", "paragraph_index": 14}, {"url": "https://www.patreon.com/bePatron?u=28955887", "anchor_text": "supporting me on Patreon", "paragraph_index": 15}], "all_paragraphs": ["N-gram is probably the easiest concept to understand in the whole machine learning space, I guess. An N-gram means a sequence of N words. So for example, \u201cMedium blog\u201d is a 2-gram (a bigram), \u201cA Medium blog post\u201d is a 4-gram, and \u201cWrite on Medium\u201d is a 3-gram (trigram). Well, that wasn\u2019t very interesting or exciting. True, but we still have to look at the probability used with n-grams, which is quite interesting.", "Before we move on to the probability stuff, let\u2019s answer this question first. Why is it that we need to learn n-gram and the related probability? Well, in Natural Language Processing, or NLP for short, n-grams are used for a variety of things. Some examples include auto completion of sentences (such as the one we see in Gmail these days), auto spell check (yes, we can do that as well), and to a certain extent, we can check for grammar in a given sentence. We\u2019ll see some examples of this later in the post when we talk about assigning probabilities to n-grams.", "Let\u2019s take the example of a sentence completion system. This system suggests words which could be used next in a given sentence. Suppose I give the system the sentence \u201cThank you so much for your\u201d and expect the system to predict what the next word will be. Now you and me both know that the next word is \u201chelp\u201d with a very high probability. But how will the system know that?", "One important thing to note here is that, as for any other artificial intelligence or machine learning model, we need to train the model with a huge corpus of data. Once we do that, the system, or the NLP model will have a pretty good idea of the \u201cprobability\u201d of the occurrence of a word after a certain word. So hoping that we have trained our model with a huge corpus of data, we\u2019ll assume that the model gave us the correct answer.", "I spoke about the probability a bit there, but let\u2019s now build on that. When we\u2019re building an NLP model for predicting words in a sentence, the probability of the occurrence of a word in a sequence of words is what matters. And how do we measure that? Let\u2019s say we\u2019re working with a bigram model here, and we have the following sentences as the training corpus:", "Let\u2019s suppose that after training our model with this data, I want to write the sentence \u201cI really like your garden.\u201d Now because this is a bigram model, the model will learn the occurrence of every two words, to determine the probability of a word occurring after a certain word. For example, from the 2nd, 4th, and the 5th sentence in the example above, we know that after the word \u201creally\u201d we can see either the word \u201cappreciate\u201d, \u201csorry\u201d, or the word \u201clike\u201d occurs. So the model will calculate the probability of each of these sequences.", "Suppose we\u2019re calculating the probability of word \u201cw1\u201d occurring after the word \u201cw2,\u201d then the formula for this is as follows:", "which is the number of times the words occurs in the required sequence, divided by the number of the times the word before the expected word occurs in the corpus.", "From our example sentences, let\u2019s calculate the probability of the word \u201clike\u201d occurring after the word \u201creally\u201d:", "Similarly, for the other two possibilities:", "So when I type the phrase \u201cI really,\u201d and expect the model to suggest the next word, it\u2019ll get the right answer only once out of three times, because the probability of the correct answer is only 1/3.", "As an another example, if my input sentence to the model is \u201cThank you for inviting,\u201d and I expect the model to suggest the next word, it\u2019s going to give me the word \u201cyou,\u201d because of the example sentence 4. That\u2019s the only example the model knows. As you can imagine, if we give the model a bigger corpus (or a bigger dataset) to train on, the predictions will improve a lot. Similarly, we\u2019re only using a bigram here. We can use a trigram or even a 4-gram to improve the model\u2019s understanding of the probabilities.", "Using these n-grams and the probabilities of the occurrences of certain words in certain sequences could improve the predictions of auto completion systems. Similarly, we use can NLP and n-grams to train voice-based personal assistant bots. For example, using a 3-gram or trigram training model, a bot will be able to understand the difference between sentences such as \u201cwhat\u2019s the temperature?\u201d and \u201cset the temperature.\u201d", "I hope this was a clear enough explanation to understand the pretty easy concept of n-grams in Natural Language Processing. We\u2019ll use this knowledge of n-grams and use it to optimise our machine learning model for text classification that we built earlier in the intro to the fastText library post.", "Follow me on Twitter for more Data Science, Machine Learning, and general tech updates. Also, you can follow my personal blog.", "If you like my posts here on Medium or on my personal blog, and would wish for me to continue doing this work, consider supporting me on Patreon.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9d9eef0fa058&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://contactsunny.medium.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": ""}, {"url": "https://contactsunny.medium.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Sunny Srinidhi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6691923bb149&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&user=Sunny+Srinidhi&userId=6691923bb149&source=post_page-6691923bb149----9d9eef0fa058---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/the-fasttext-series", "anchor_text": "The fastText Series"}, {"url": "https://blog.contactsunny.com/data-science/understanding-word-n-grams-and-n-gram-probability-in-natural-language-processing", "anchor_text": "my blog"}, {"url": "https://blog.contactsunny.com/data-science/optimising-a-fasttext-model-for-better-accuracy", "anchor_text": "optimise our machine learning model"}, {"url": "https://blog.contactsunny.com/data-science/an-intro-to-text-classification-with-facebooks-fasttext-natural-language-processing", "anchor_text": "intro to the fastText library"}, {"url": "https://twitter.com/contactsunny", "anchor_text": "Twitter"}, {"url": "https://blog.contactsunny.com/tag/data-science", "anchor_text": "Data Science"}, {"url": "https://blog.contactsunny.com/tag/machine-learning", "anchor_text": "Machine Learning"}, {"url": "https://blog.contactsunny.com/category/tech", "anchor_text": "tech updates"}, {"url": "https://blog.contactsunny.com/", "anchor_text": "follow my personal blog"}, {"url": "https://www.patreon.com/bePatron?u=28955887", "anchor_text": "supporting me on Patreon"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9d9eef0fa058---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/the-fasttext-series?source=post_page-----9d9eef0fa058---------------the_fasttext_series-----------------", "anchor_text": "The Fasttext Series"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9d9eef0fa058---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9d9eef0fa058---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9d9eef0fa058---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&user=Sunny+Srinidhi&userId=6691923bb149&source=-----9d9eef0fa058---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&user=Sunny+Srinidhi&userId=6691923bb149&source=-----9d9eef0fa058---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9d9eef0fa058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9d9eef0fa058---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9d9eef0fa058--------------------------------", "anchor_text": ""}, {"url": "https://contactsunny.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://contactsunny.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sunny Srinidhi"}, {"url": "https://contactsunny.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.6K Followers"}, {"url": "http://blog.contactsunny.com", "anchor_text": "blog.contactsunny.com"}, {"url": "http://linkedin.com/in/sunnysrinidhi/", "anchor_text": "linkedin.com/in/sunnysrinidhi/"}, {"url": "http://twitter.com/contactsunny", "anchor_text": "twitter.com/contactsunny"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6691923bb149&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&user=Sunny+Srinidhi&userId=6691923bb149&source=post_page-6691923bb149--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1d9e5a16cecd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-word-n-grams-and-n-gram-probability-in-natural-language-processing-9d9eef0fa058&newsletterV3=6691923bb149&newsletterV3Id=1d9e5a16cecd&user=Sunny+Srinidhi&userId=6691923bb149&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}