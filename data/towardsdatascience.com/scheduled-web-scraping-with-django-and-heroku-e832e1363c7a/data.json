{"url": "https://towardsdatascience.com/scheduled-web-scraping-with-django-and-heroku-e832e1363c7a", "time": 1683002781.861774, "path": "towardsdatascience.com/scheduled-web-scraping-with-django-and-heroku-e832e1363c7a/", "webpage": {"metadata": {"title": "Scheduled Web Scraping with Django and Heroku | by GreekDataGuy | Towards Data Science", "h1": "Scheduled Web Scraping with Django and Heroku", "description": "We often need a lot of training data for machine learning, and web scraping can be a way to acquire it. But in the past, there was a company I really wanted to work for. They didn\u2019t currently have a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.opencare.com/", "anchor_text": "Opencare", "paragraph_index": 26}, {"url": "https://dbeaver.io/", "anchor_text": "dbeaver", "paragraph_index": 30}, {"url": "http://heroku create flask-ml-api-123", "anchor_text": "Heroku", "paragraph_index": 37}, {"url": "https://github.com/heroku/django-heroku", "anchor_text": "heroku_django", "paragraph_index": 39}, {"url": "http://gmail.com", "anchor_text": "gmail.com", "paragraph_index": 54}], "all_paragraphs": ["We often need a lot of training data for machine learning, and web scraping can be a way to acquire it.", "But in the past, there was a company I really wanted to work for. They didn\u2019t currently have a data science posting but as soon as they did, I wanted to apply.", "The solution? Scrape their job board daily so I was notified anytime a new job was posted.", "Let\u2019s build a simple django app, deploy to Heroku, and scrape a job board daily.", "Create the directory for the app and cd into it.", "Open this in whatever code editor your prefer. I\u2019m using Sublime.", "Create and start our virtual environment. Then install the packages we\u2019ll need.", "Create the project (django\u2019s version of a web application).", "cd into the project and create an app for scraping.", "We\u2019ll only need to define 1 model in this app, a Job model. This represents jobs that we\u2019ll collect.", "Register your model in /scraping/admin.py. This allows us to view records in Django\u2019s default admin panel (we\u2019ll get to this shortly).", "Add scraping to installed apps in /jobs/settings.py .", "Setup the database. I love postgres so we\u2019ll use that.", "At this point, ensure you\u2019ve previously installed postgres on your mac with brew and started it (this is beyond the scope of this article).", "Create a database for this project on the command line. You can open the postgres console with the below command.", "Create a user and a database, then exit.", "In /jobs/settings.py, update DATABASES. In other frameworks you\u2019d want to scope these specifically for the development environment, but here we won\u2019t worry about it. It will work on Heroku anyway (we\u2019ll get there shortly).", "Note these are the user and database names we created above.", "Create migrations, and migrate the database from the command line.", "This will create a table called scraping_job. This is a django namespace convention because it belongs to the scraping app.", "Now create a superuser and give it a password in your command line.", "We\u2019ve done some work so far but we have no idea if anything works. Let\u2019s test it out before going further.", "After logging in, click \u201cjobs\u201d under \u201cscraping\u201d, then \u201cadd job\u201d in the top right. Now fill in some made up information and click \u201csave\u201d. If you can see the job you created, everything works up until this point!", "We\u2019re going to setup a custom django-admin command that scrapes a job board. This is what we\u2019ll automatically schedule at the infrastructure level in order to automate scraping.", "Inside the /scraping module, create a directory called /management, and a directory inside /management called /commands. Then create 2 python files, _private.py and scrape.py in /commands.", "Putting the code in a directory structure like this, then defining a Command class with a handle function tells django this is a custom django-admin command.", "Here we\u2019re using beautiful soup to scrape a Lever job board, then save it in our database. I have no affiliation but the job board I\u2019ve chosen is for a fantastic company called Opencare - you should apply if they post something!", "You can now run this from your command line like below.", "Run it again and you\u2019ll see this.", "That\u2019s because we\u2019ve prevented adding duplicate job records in the scrape.py code above.", "If you have a database administration program setup (like dbeaver), you can also inspect rows in your database. We won\u2019t get into that here but it should look like below.", "Now let\u2019s get this onto Heroku.", "Freeze your requirements so Heroku knows what to install on deploy.", "On the command line, run nano .gitignore and add below.", "Then ctrl+x, y, enter to save and close (on mac). This prevents deploying unnecessary files.", "Create a file named Procfile in your root, and paste below inside. This tells heroku to boot up a web dyno, and the 2nd command migrates the db.", "The file tree will look like.", "Make sure you have a Heroku account then login with heroku login on the command line.", "Create an app with any name you want. But it will needs to be unique across all the apps on Heroku. I ran heroku create django-scraper-879 , where the app name is django-scraper-879 . But you\u2019ll need to pick your own.", "Now add these lines to the very bottom of settings.py. heroku_django takes care of some settings configuration like (Static files / WhiteNoise) for you.", "Update DEBUG in settings. Don\u2019t want to deploy to prod in debug mode.", "Adds files to git with below.", "Now push our app to Heroku with this.", "You can manually run the job from your local command line with heroku run python manage.py scrape but it would be annoying to have to manually run it every day.", "Log into your Heroku console and click on \u201cResources,\u201d then \u201cfind more add-ons\u201d.", "Now find and click on this add-on. Try a \u201cctrl+f\u201d for \u201cschedule\u201d to help locate it. Heroku has a ton of potential add-ons. It looks like below.", "Now add it to your app, so you now have.", "Click on it and create a job, everyday at\u2026 12am UTC . It\u2019s not nice to ping websites more than necessary!", "Input your command and save it.", "Now just wait until 12am UTC (or whatever time you picked) and you\u2019re database will populate.", "We touched on a lot of things here. Django, Heroku, Scheduling, Web Scraping, Postgres.", "While I used the example of wanting to know when a company posted a new job, there are lots of reasons you might want to scrape a website.", "This tutorial was just to illustrate what\u2019s possible. Let me know if you\u2019ve built anything cool with web scraping in the comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Just a developer. Contact: greek.data.guy \u201cat\u201d gmail.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe832e1363c7a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://greekdataguy.medium.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": ""}, {"url": "https://greekdataguy.medium.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "GreekDataGuy"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd67bf018ae6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&user=GreekDataGuy&userId=d67bf018ae6d&source=post_page-d67bf018ae6d----e832e1363c7a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://127.0.0.1:8000/", "anchor_text": "http://127.0.0.1:8000/admin"}, {"url": "https://jobs.lever.co/opencare'", "anchor_text": "https://jobs.lever.co/opencare'"}, {"url": "https://www.opencare.com/", "anchor_text": "Opencare"}, {"url": "https://dbeaver.io/", "anchor_text": "dbeaver"}, {"url": "http://heroku create flask-ml-api-123", "anchor_text": "Heroku"}, {"url": "https://github.com/heroku/django-heroku", "anchor_text": "heroku_django"}, {"url": "https://medium.com/tag/python?source=post_page-----e832e1363c7a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scraping?source=post_page-----e832e1363c7a---------------scraping-----------------", "anchor_text": "Scraping"}, {"url": "https://medium.com/tag/django?source=post_page-----e832e1363c7a---------------django-----------------", "anchor_text": "Django"}, {"url": "https://medium.com/tag/programming?source=post_page-----e832e1363c7a---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/app-development?source=post_page-----e832e1363c7a---------------app_development-----------------", "anchor_text": "App Development"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&user=GreekDataGuy&userId=d67bf018ae6d&source=-----e832e1363c7a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&user=GreekDataGuy&userId=d67bf018ae6d&source=-----e832e1363c7a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe832e1363c7a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e832e1363c7a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e832e1363c7a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e832e1363c7a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e832e1363c7a--------------------------------", "anchor_text": ""}, {"url": "https://greekdataguy.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://greekdataguy.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "GreekDataGuy"}, {"url": "https://greekdataguy.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.97K Followers"}, {"url": "http://gmail.com", "anchor_text": "gmail.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd67bf018ae6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&user=GreekDataGuy&userId=d67bf018ae6d&source=post_page-d67bf018ae6d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F26b33036e2a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscheduled-web-scraping-with-django-and-heroku-e832e1363c7a&newsletterV3=d67bf018ae6d&newsletterV3Id=26b33036e2a7&user=GreekDataGuy&userId=d67bf018ae6d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}