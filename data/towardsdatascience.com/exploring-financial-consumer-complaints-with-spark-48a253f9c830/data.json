{"url": "https://towardsdatascience.com/exploring-financial-consumer-complaints-with-spark-48a253f9c830", "time": 1683003073.454182, "path": "towardsdatascience.com/exploring-financial-consumer-complaints-with-spark-48a253f9c830/", "webpage": {"metadata": {"title": "Exploring Financial Consumer Complaints with Spark | by Allison Stafford | Towards Data Science", "h1": "Exploring Financial Consumer Complaints with Spark", "description": "In perusing Data.gov \u2014 \u201cThe home of the U.S. government\u2019s open data\u201d \u2014 I stumbled across the US Federal Financial Services Consumer Complaint Database. Some preliminary questions came to mind\u2026"}, "outgoing_paragraph_urls": [{"url": "https://mortada.net/3-easy-steps-to-set-up-pyspark.html", "anchor_text": "Mortada Mehyar\u2019s post", "paragraph_index": 2}, {"url": "https://catalog.data.gov/dataset/consumer-complaint-database", "anchor_text": "here", "paragraph_index": 3}, {"url": "https://spark.apache.org/docs/latest/monitoring.html", "anchor_text": "online user interface", "paragraph_index": 9}, {"url": "https://github.com/allisonhonold/spark-blog", "anchor_text": "here", "paragraph_index": 28}], "all_paragraphs": ["In perusing Data.gov \u2014 \u201cThe home of the U.S. government\u2019s open data\u201d \u2014 I stumbled across the US Federal Financial Services Consumer Complaint Database. Some preliminary questions came to mind, including: How far back does this go? How up to date is this? How many complaints do people file? What companies generate the most complaints?", "To answer these questions, I decided to turn to Spark.", "There are plenty of blogs/posts/places to find directions for setting up Spark on your computer already on the interweb (see Mortada Mehyar\u2019s post). Spark used to have a reputation for being a challenge to get up and running on your computer, but I didn\u2019t have to struggle too much using a MacBook Air running macOS Mojave on a 1.6 GHz Intel Core i5 with 8 GB of memory. It may be more challenging with a different setup or with previous versions of Spark.", "Now we\u2019re ready to dive in to some real data with SQL/pandas-style work. Today, we\u2019re investigating the Financial Services Consumer Complaint Database. I downloaded it from Data.gov here. Full disclosure, I had difficulty getting the CSV to load correctly using Spark\u2019s CSV loader, so I used pandas to convert the CSV to a parquet file. I\u2019d love any tips you have to solve my problem where some of the text columns were getting sliced into two (maybe at the commas?), resulting in a table with approximately twice the number of rows and jumbled columns.", "Note: you\u2019ll need to install pyarrow or fastparquet in order to run .to_parquet below.", "After deciding to make the switch, I was SUPER impressed by how quickly the parquet file loaded in Spark as compared to the CSV. The only inconvenience was that it seems like Spark and/or Parquet files don\u2019t handle column names with spaces very well. I chose to remove them in pandas before converting to the Parquet file. In general, here is yet another reason to set up your data base/warehouse/lake with sensible, space-free names.", "If you were using base Spark features and methods, then you would start by initializing a SparkContext to set up your Spark application by connecting to your specific execution environment. If I wanted to run on all of the cores of my local machine, I would use:", "You can always stop the SparkContext with sc.stop().", "For our DataFrame work, we\u2019ll let our SparkSession initialize the SparkContext for us:", "Here we have used the SparkSession builder to \u201cget or create\u201d (if it doesn\u2019t already exist, then create) a SparkSession with the indicated the execution environment (all cores on my local machine) and named the app for identification on the online user interface.", "As a check, I ran spark.sparkContext.defaultParallelism to make sure Spark is using the expected number of cores.", "And that\u2019s it. I did a quick df.count() to confirm that Spark read in the correct number of rows this time.", "Now that we have our data frame, let\u2019s go ahead and use it to answer some questions:", "Here we need to convert to datetime type. I am \u201cselecting\u201d (like SQL) the date received converted to date type with the date format, and giving it an alias. Then I order by date and take 1. Take produces the same results as limit, but I am not sure about the performance difference in various versions of Spark. Take(n) is a base spark classic, returning the first n results, while limit() is more intuitive for the SQL-oriented folks.", "With a few lines of code, we see that the data set spans from December 1, 2011 to January 12, 2020.", "For the total number of complaints, a quick df.count() returns ~1.5 million.", "To get the complaints per day, we\u2019ll work with our datetime objects from above:", "Average number of complaints per day:", "I visualized the daily complaints by converting the PySpark DataFrame to a Pandas DataFrame and using matplotlib:", "I noticed these peaks and decided to investigate. You can use filter (sometimes in combination with where and when) in a similar way to how you would use .loc in pandas.", "The return is formatted in SQL style:", "September 2017 was the Equifax security breach. I\u2019m not sure what was happening in January 2017, besides President Trump\u2019s inauguration on the 20th.", "Here I wanted to visualize the results using matplotlib again, so I converted my results to pandas.", "Then I used matplotlib to visualize the results:", "Not looking cute for the credit reporting agencies\u2026 but we see that this module of Spark gets answers fast with fairly SQL-y code. If you know how to do it in SQL or pandas, the PySpark way will likely be similar, or at least there will likely be a similar way you can use in PySpark. As usual, there are many ways to get the same results.", "How are the complaints received? Mostly via the web.", "Do they get disputed? Sometimes. It depends what null means in this column.", "Last tip for this post: you can shut down your SparkSession with SparkSession.stop() .", "I hope this has helped you get started looking at data with Spark! You can find the repo here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist with a background in business, education, and environmental science."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F48a253f9c830&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----48a253f9c830--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@allison.stafford?source=post_page-----48a253f9c830--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Allison Stafford"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b1f621568d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&user=Allison+Stafford&userId=87b1f621568d&source=post_page-87b1f621568d----48a253f9c830---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@milkovi?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "MILKOV\u00cd"}, {"url": "https://unsplash.com/wallpapers?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://mortada.net/3-easy-steps-to-set-up-pyspark.html", "anchor_text": "Mortada Mehyar\u2019s post"}, {"url": "https://unsplash.com/@obofili?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "A. Shuau (Obofili)"}, {"url": "https://unsplash.com/wallpapers?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/the-what-why-and-when-of-apache-spark-6c27abc19527#b4a0", "anchor_text": "article"}, {"url": "https://hackernoon.com/high-level-overview-of-apache-spark-c225a0a162e9", "anchor_text": "HackerNoon"}, {"url": "https://www.toptal.com/spark/introduction-to-apache-spark", "anchor_text": "Toptal"}, {"url": "https://catalog.data.gov/dataset/consumer-complaint-database", "anchor_text": "here"}, {"url": "https://unsplash.com/@lleung1?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Luke Leung"}, {"url": "https://unsplash.com/wallpapers?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://spark.apache.org/docs/latest/monitoring.html", "anchor_text": "online user interface"}, {"url": "https://github.com/allisonhonold/spark-blog", "anchor_text": "here"}, {"url": "https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/", "anchor_text": "https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/"}, {"url": "https://mapr.com/blog/how-spark-runs-your-applications/", "anchor_text": "https://mapr.com/blog/how-spark-runs-your-applications/"}, {"url": "https://mapr.com/blog/5-minute-guide-understanding-significance-apache-spark/", "anchor_text": "https://mapr.com/blog/5-minute-guide-understanding-significance-apache-spark/"}, {"url": "https://realpython.com/pyspark-intro/", "anchor_text": "https://realpython.com/pyspark-intro/"}, {"url": "https://medium.com/tag/spark?source=post_page-----48a253f9c830---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/spark-dataframe?source=post_page-----48a253f9c830---------------spark_dataframe-----------------", "anchor_text": "Spark Dataframe"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----48a253f9c830---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/python?source=post_page-----48a253f9c830---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/spark-sql?source=post_page-----48a253f9c830---------------spark_sql-----------------", "anchor_text": "Spark Sql"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&user=Allison+Stafford&userId=87b1f621568d&source=-----48a253f9c830---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&user=Allison+Stafford&userId=87b1f621568d&source=-----48a253f9c830---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F48a253f9c830&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----48a253f9c830---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----48a253f9c830--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----48a253f9c830--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----48a253f9c830--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----48a253f9c830--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----48a253f9c830--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@allison.stafford?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Allison Stafford"}, {"url": "https://medium.com/@allison.stafford/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "386 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F87b1f621568d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&user=Allison+Stafford&userId=87b1f621568d&source=post_page-87b1f621568d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb4bbbb8c248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexploring-financial-consumer-complaints-with-spark-48a253f9c830&newsletterV3=87b1f621568d&newsletterV3Id=b4bbbb8c248&user=Allison+Stafford&userId=87b1f621568d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}