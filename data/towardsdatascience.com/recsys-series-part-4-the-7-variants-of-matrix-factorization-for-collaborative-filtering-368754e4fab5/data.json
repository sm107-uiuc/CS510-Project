{"url": "https://towardsdatascience.com/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5", "time": 1683004172.893447, "path": "towardsdatascience.com/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5/", "webpage": {"metadata": {"title": "Recommendation System Series Part 4: The 7 Variants of Matrix Factorization For Collaborative Filtering | by James Le | Towards Data Science", "h1": "Recommendation System Series Part 4: The 7 Variants of Matrix Factorization For Collaborative Filtering", "description": "Update: This article is part of a series where I explore recommendation systems in academia and industry. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, and Part 6. Collaborative\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/recommendation-system-series-part-1-an-executive-guide-to-building-recommendation-system-608f83e2630a", "anchor_text": "Part 1", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58", "anchor_text": "Part 2", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-3-the-6-research-directions-of-deep-recommendation-systems-that-3a328d264fb7", "anchor_text": "Part 3", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5", "anchor_text": "Part 4", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883", "anchor_text": "Part 5", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7", "anchor_text": "Part 6", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/understanding-the-scaling-of-l\u00b2-regularization-in-the-context-of-neural-networks-e3d25f8b50db", "anchor_text": "This article by Shay Palachy", "paragraph_index": 10}, {"url": "https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf", "anchor_text": "original paper on Factorization Machines", "paragraph_index": 26}, {"url": "https://arxiv.org/pdf/1711.08379.pdf", "anchor_text": "Maciej Kula", "paragraph_index": 31}, {"url": "https://en.wikipedia.org/wiki/Variational_Bayesian_methods", "anchor_text": "The Wikipedia page", "paragraph_index": 37}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler divergence", "paragraph_index": 37}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments", "anchor_text": "this repository", "paragraph_index": 39}, {"url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883", "anchor_text": "Recommendation System Part 5", "paragraph_index": 42}, {"url": "https://medium.com/@james_aka_yale", "anchor_text": "Medium", "paragraph_index": 43}, {"url": "https://github.com/khanhnamle1994", "anchor_text": "GitHub", "paragraph_index": 43}, {"url": "https://jameskle.com/", "anchor_text": "https://jameskle.com/", "paragraph_index": 43}, {"url": "https://twitter.com/le_james94", "anchor_text": "Twitter", "paragraph_index": 43}, {"url": "http://www.linkedin.com/in/khanhnamle94", "anchor_text": "find me on LinkedIn", "paragraph_index": 43}, {"url": "http://eepurl.com/deWjzb", "anchor_text": "Sign up for my newsletter", "paragraph_index": 43}], "all_paragraphs": ["Update: This article is part of a series where I explore recommendation systems in academia and industry. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, and Part 6.", "Collaborative filtering lies at the heart of any modern recommendation system, which has seen considerable success at companies like Amazon, Netflix, and Spotify. It works by collecting human judgments (known as ratings) for items in a given domain and matching together people who share the same information needs or the same tastes. Users of a collaborative filtering system share their analytical judgments and opinions regarding each item that they consume so that other users of the system can better decide which items to consume. In return, the collaborative filtering system provides useful personalized recommendations for new items.", "The two primary areas of collaborative filtering are (1) neighborhood methods and (2) latent factor models.", "Some of the most successful latent factor models are based on matrix factorization. In its natural form, matrix factorization characterizes items and users using vectors of factors inferred from item rating patterns. High correspondence between item and user factors leads to a recommendation.", "In this post and those to follow, I will be walking through the creation and training of recommendation systems, as I am currently working on this topic for my Master Thesis.", "In part 4, I dig into the nitty-gritty mathematical details of matrix factorization, arguably the most common baseline model for recommendation system research these days. More specifically, I will show you the seven variants of matrix factorization that can be constructed \u2014 ranging from the use of side features to the application of Bayesian methods.", "A straightforward matrix factorization model maps both users and items to a joint latent factor space of dimensionality D \u2014 such that user-item interactions are modeled as inner products in that space.", "Thus, we have the equation 1 as follow:", "The big challenge is to compute the mapping of each item and user to factor vectors q_i and p_u. Matrix factorization does this by minimizing the regularized squared error on the set of known ratings, as seen in equation 2 below:", "The model is learned by fitting the previously observed ratings. However, the goal is to generalize those previous ratings in a way that predicts future/unknown ratings. Thus, we want to avoid overfitting the observed data by adding an L2 regularization penalty to each element and optimize the learned parameters simultaneously with stochastic gradient descent.", "This article by Shay Palachy did a great job explaining the intuition, based here are the quick notes:", "Let\u2019s see how this looks like in code:", "One benefit of the matrix factorization approach to collaborative filtering is its flexibility in dealing with various data aspects and other application-specific requirements. Recall that equation 1 attempts to capture the interactions between users and items that produce different rating values. However, much of the observed variation in the rating values are due to effects associated with either users or items, known as biases, independent of any interactions. The intuition behind this is that some users give high ratings than others, and some items received high ratings than others systematically.", "Thus, we can extend equation 1 to equation 3 as follows:", "The model is learned by minimizing a new squared error function, as seen in equation 4 below:", "Let\u2019s see how this looks like in code:", "A common challenge in collaborative filtering is the cold start problem due to its inability to address new items and new users. Or many users are supplying very few ratings, making the user-item interaction matrix very sparse. A way to relieve this problem is to incorporate additional sources of information about the users, aka side features. These can be user attributes (demographics) and implicit feedback.", "Going back to my example, let\u2019s say I know the occupation of the user. I have two choices for this side feature: adding it as a bias (artists like movies more than other occupations) and adding it as a vector (realtors love real estate shows). The matrix factorization model should integrate all signal sources with enhanced user representation, as seen in equation 5:", "How does the loss function look like now? Equation 6 below shows that:", "Let\u2019s see how this looks like in code:", "So far, our matrix factorization models have been static. In reality, item popularity and user preferences change constantly. Therefore, we should account for the temporal effects reflecting the dynamic nature of user-item interactions. To accomplish this, we can add a temporal term that affects user preferences and, therefore, the interaction between users and items.", "To mix it up a bit, let\u2019s try out a new equation 7 below with dynamic prediction rule for a rating at time t:", "Equation 8 displays the new loss function that incorporates the temporal features:", "Let\u2019s see how this looks like in code:", "One of the more powerful techniques for the recommendation system is called Factorization Machines, which have a robust, expressive capacity to generalize Matrix Factorization methods. In many applications, we have plenty of item metadata that can be used to make better predictions. This is one of the benefits of using Factorization Machines with feature-rich datasets, for which there is a natural way in which extra features can be included in the model, and higher-order interactions can be modeled using the dimensionality parameter d. For sparse datasets, a second-order Factorization Machine model suffices, since there is not enough information to estimate more complex interactions.", "Equation 9 shows what a second order FM model looks like:", "where the v\u2019s represent k-dimensional latent vectors associated with each variable (users and items), and the bracket operator represents the inner product. Following Steffen Rendle\u2019s original paper on Factorization Machines, if we assume that each x(j) vector is only non-zero at positions u and i, we get the classic Matrix Factorization model with biases (equation 3):", "The main difference between these two equations is that Factorization Machines introduce higher-order interactions in terms of latent vectors that are also affected by categorical or tag data. This means that the models go beyond co-occurrences to find stronger relationships between the latent representations of each feature.", "The loss function for the Factorization Machines model is simply the sum of mean squared error and feature set, as shown in equation 10:", "Let\u2019s see how this looks like in code:", "The techniques presented so far implicitly treat user tastes as unimodal \u2014 aka in a single latent vector. This may lead to a lack of nuance in representing the user, where a dominant taste may overpower more niche ones. Additionally, this may reduce the quality of item representations, decreasing the separation in the embedding space between groups of items belonging to multiple tastes/genres.", "Maciej Kula proposes and evaluates representing users as mixtures if several distinct tastes, represented by different taste vectors. Each of the taste vectors is coupled with an attention vector, describing how competent it is at evaluating any given item. The user\u2019s preference is then modeled as a weighted average of all the user\u2019s tastes, with the weights provided by how relevant each taste is to evaluate a given item.", "Equation 11 gives a mathematical formula for this mixture-of-taste model:", "So equation 12 below captures the loss function:", "Let\u2019s see how this looks like in code:", "The last variant of matrix factorization that I want to present is called Variational Matrix Factorization. While most of what the blog post has discussed so far is about optimizing a point estimate of the model parameters, variational is about optimizing a posterior, which loosely speaking expresses a spectrum of model configurations that are consistent with the data.", "Here are the practical reasons to go variational:", "We can make the matrix factorization in equation 3 variational by: (1) Replace point estimates with samples from a distribution, and (2) Replace regularizing that point with regularizing the new distribution. The math is quite complicated, so I won\u2019t attempt to explain it in this blog post. The Wikipedia page on Variational Bayesian methods is a helpful guide to start. The most common type of variational Bayes uses the Kullback-Leibler divergence as the choice of dis-similarity function, which makes the loss minimization tractable.", "Let\u2019s see how that looks like in code:", "You can check out all 7 Matrix Factorization experiments that I did for the MovieLens1M dataset at this repository. All models were trained for 50 epochs and the results were captured in TensorBoard. The evaluation metric is Mean Squared Error, which is calculated to be the sum of all squared differences between the predicted ratings and the actual ratings.", "The result table is at the bottom of the README, and as you can see:", "In this post, I have discussed the intuitive meaning of matrix factorization and its use in collaborative filtering. I also talked about many different extensions to it: (1) Adding biases, (2) Adding side features, (3) Adding temporal features, (4) Upgrading to Factorization Machines to take advantage of higher-order interactions, (5) Using a mixture of tastes with \u201cattention\u201d mechanism, and (6) Making the model variational. I hope that you have found this mathematical deep-dive into the world of matrix factorization helpful. Stay tuned for future blog posts of this series that go beyond the realm of matrix factorization and into the deep learning approaches to collaborative filtering.", "Now continue on to Recommendation System Part 5!", "If you would like to follow my work on Recommendation Systems, Deep Learning, and Data Science Journalism, you can check out my Medium and GitHub, as well as other projects at https://jameskle.com/. You can also tweet at me on Twitter, email me directly, or find me on LinkedIn. Sign up for my newsletter to receive my latest thoughts on data science, machine learning, and artificial intelligence right at your inbox!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F368754e4fab5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://le-james94.medium.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": ""}, {"url": "https://le-james94.medium.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "James Le"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52aa38cb8e25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&user=James+Le&userId=52aa38cb8e25&source=post_page-52aa38cb8e25----368754e4fab5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-1-an-executive-guide-to-building-recommendation-system-608f83e2630a", "anchor_text": "Part 1"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58", "anchor_text": "Part 2"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-3-the-6-research-directions-of-deep-recommendation-systems-that-3a328d264fb7", "anchor_text": "Part 3"}, {"url": "https://towardsdatascience.com/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5", "anchor_text": "Part 4"}, {"url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883", "anchor_text": "Part 5"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7", "anchor_text": "Part 6"}, {"url": "https://towardsdatascience.com/overview-of-matrix-factorisation-techniques-using-python-8e3d118a9b39", "anchor_text": "https://towardsdatascience.com/overview-of-matrix-factorisation-techniques-using-python-8e3d118a9b39"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-1-an-executive-guide-to-building-recommendation-system-608f83e2630a", "anchor_text": "Part 1"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58", "anchor_text": "Part 2"}, {"url": "https://towardsdatascience.com/recommendation-system-series-part-3-the-6-research-directions-of-deep-recommendation-systems-that-3a328d264fb7", "anchor_text": "Part 3"}, {"url": "https://towardsdatascience.com/understanding-the-scaling-of-l\u00b2-regularization-in-the-context-of-neural-networks-e3d25f8b50db", "anchor_text": "This article by Shay Palachy"}, {"url": "https://en.wikipedia.org/wiki/Tikhonov_regularization", "anchor_text": "Tikhonov Regularization"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Vanilla-MF", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Vanilla-MF"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Biases", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Biases"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Side-Features", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Side-Features"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Temporal-Features", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Temporal-Features"}, {"url": "http://berwynzhang.com/2017/01/22/machine_learning/Factorization_Machines/", "anchor_text": "http://berwynzhang.com/2017/01/22/machine_learning/Factorization_Machines/"}, {"url": "https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf", "anchor_text": "original paper on Factorization Machines"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Factorization-Machines", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Factorization-Machines"}, {"url": "https://arxiv.org/pdf/1711.08379.pdf", "anchor_text": "Maciej Kula"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Mixture-Tastes", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/MF-Mixture-Tastes"}, {"url": "https://en.wikipedia.org/wiki/Variational_Bayesian_methods", "anchor_text": "The Wikipedia page"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler divergence"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Variational-MF", "anchor_text": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments/Variational-MF"}, {"url": "https://github.com/khanhnamle1994/transfer-rec/tree/master/Matrix-Factorization-Experiments", "anchor_text": "this repository"}, {"url": "https://dl.acm.org/doi/10.1109/MC.2009.263", "anchor_text": "Matrix Factorization Techniques for Recommender Systems"}, {"url": "https://cemoody.github.io/simple_mf/", "anchor_text": "Simple and Flexible Deep Recommenders in PyTorch"}, {"url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883", "anchor_text": "Recommendation System Part 5"}, {"url": "https://medium.com/@james_aka_yale", "anchor_text": "Medium"}, {"url": "https://github.com/khanhnamle1994", "anchor_text": "GitHub"}, {"url": "https://jameskle.com/", "anchor_text": "https://jameskle.com/"}, {"url": "https://twitter.com/le_james94", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/in/khanhnamle94", "anchor_text": "find me on LinkedIn"}, {"url": "http://eepurl.com/deWjzb", "anchor_text": "Sign up for my newsletter"}, {"url": "https://medium.com/tag/recommendation-system?source=post_page-----368754e4fab5---------------recommendation_system-----------------", "anchor_text": "Recommendation System"}, {"url": "https://medium.com/tag/collaborative-filtering?source=post_page-----368754e4fab5---------------collaborative_filtering-----------------", "anchor_text": "Collaborative Filtering"}, {"url": "https://medium.com/tag/matrix-factorization?source=post_page-----368754e4fab5---------------matrix_factorization-----------------", "anchor_text": "Matrix Factorization"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----368754e4fab5---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----368754e4fab5---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&user=James+Le&userId=52aa38cb8e25&source=-----368754e4fab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&user=James+Le&userId=52aa38cb8e25&source=-----368754e4fab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F368754e4fab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----368754e4fab5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----368754e4fab5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----368754e4fab5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----368754e4fab5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----368754e4fab5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----368754e4fab5--------------------------------", "anchor_text": ""}, {"url": "https://le-james94.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://le-james94.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "James Le"}, {"url": "https://le-james94.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17.6K Followers"}, {"url": "https://jameskle.com/", "anchor_text": "https://jameskle.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F52aa38cb8e25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&user=James+Le&userId=52aa38cb8e25&source=post_page-52aa38cb8e25--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F171511b90ce0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5&newsletterV3=52aa38cb8e25&newsletterV3Id=171511b90ce0&user=James+Le&userId=52aa38cb8e25&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}