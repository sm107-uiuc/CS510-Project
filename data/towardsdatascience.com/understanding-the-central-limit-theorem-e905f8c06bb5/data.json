{"url": "https://towardsdatascience.com/understanding-the-central-limit-theorem-e905f8c06bb5", "time": 1683002857.722121, "path": "towardsdatascience.com/understanding-the-central-limit-theorem-e905f8c06bb5/", "webpage": {"metadata": {"title": "Understanding the Central Limit Theorem | by Max Miller | Towards Data Science", "h1": "Understanding the Central Limit Theorem", "description": "Underlying every poll you see on the news or every estimate of an effect size in a scientific study are two statistical conclusions: the Law of Large Numbers and the Central Limit Theorem. One of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Bessel's_correction", "anchor_text": "correct for some bias", "paragraph_index": 23}], "all_paragraphs": ["Underlying every poll you see on the news or every estimate of an effect size in a scientific study are two statistical conclusions: the Law of Large Numbers and the Central Limit Theorem. One of these, the Law of Large Numbers, usually strikes people as being fairly intuitive, but the other is a little harder to wrap your head around. It\u2019s a subtle conclusion and its practical uses are non-obvious, yet it might be the single most important piece of statistics for applied data science. It underpins how statisticians and data scientists quantify margins of error, how they test to see if an effect is significant and why normal distributions (those classic, bell curve like distributions) are so common in real world variables. If you work with applied statistics in basically any capacity and want to understand why your tools work the way they do, you first need to understand the Central Limit Theorem.", "Refresher on the Law of Large Numbers", "The Law of Large Numbers states something that for many people may seem obvious: that the average value of numerous repeated trials should be about, well, the average expected value of any one of those trials. Any one trial might deviate from the average, but as you take more and more trials into consideration, their combined average will almost invariably move closer and closer to the expected average. A common example is with flipping a coin. If you flip enough times, you should get about half heads and half tails. If you were to only flip a coin a couple of times, it\u2019s very possible to get a string of just heads or tails but as you keep going the probability of having a ratio of heads to tails that\u2019s substantially different from the average drops away.", "The Law of Large Numbers is also important for surveys and polls. For instance, let\u2019s say that you wanted to figure out what the average height of people was in an age before you could easily look that up on the internet. You decide that performing a survey might be a sensible way to go about this, and set out to ask random people how tall they are. The result of one random survey is itself a random variable \u2014 you might pick someone taller than average or someone lower than average and if you choose them randomly you won\u2019t know whether they are taller or shorter ahead of time. You can\u2019t survey just one person \u2014 what are the odds you\u2019ll randomly get someone who is exactly the average height! \u2014 but if you survey numerous people, your sample average will likely be close to the true average in the overall population, and if you survey more and more people, your sample average will move ever closer and closer to the true average. A sample of 10 is better than a sample of 1 and a sample of 100 is better than a sample of 10.", "This is the law of large numbers at work \u2014 the bigger your sample the closer to the true average you expect to be. You may realize that there are some caveats here, that it isn\u2019t quite as simple as \u2018more surveys equals better results\u2019. In particular, this only works if your trials or surveys are random and belong to the same distribution. You\u2019ll run into trouble if, say, you select your survey subjects randomly from among people in the locker room following an NBA game. The heights of NBA stars are not distributed in the same way as the heights of the general population at large, so don\u2019t be surprised if your sample average is not accurate to the general population. Slightly more subtly, you\u2019ll also have trouble if your choices of who to survey are not independent of each other. Say, for instance, you call up a random person and ask them how tall they are. Great, one more height to add to your survey, but, while you\u2019ve got them on the line, you figure you can save some time calling up strangers and also ask them about the heights of the other people in their family. Now your sample is no longer random. The statistical jargon for a sample or set of random variables that satisfy these requirements is that they are \u2018independant and identically distributed\u2019 \u2014 or i.i.d.", "(There are actually a couple more requirements for the LLN to hold \u2014 that the distribution has a well-defined expected value, for instance \u2014 but these issues do not typically come up that often in real world use cases.)", "The next step: the Central Limit Theorem", "Armed with the LLN, you know that all you need to get a good estimate is a sufficiently large sample. But, how large a sample is \u2018sufficiently large\u2019? To answer that question we\u2019ll need the Central Limit Theorem. The Central Limit Theorem holds that a sample statistic like the sample average is itself a random variable that is about normally distributed as the size of the sample increases regardless of the distribution of the population from which the sample is drawn.* There\u2019s actually a lot there to unpack, so let\u2019s consider what each part of the theorem means.", "A sample statistic like the sample average: An important thing to understand up front is that the CLM doesn\u2019t tell us anything about the distribution of some feature in the overall population or even the distribution of that feature in our sample. Instead, the CLM tells us something interesting about the distribution of the sample average. Remember that a single measurement in our survey was a random variable. The sample average is also a random variable, since it is entirely derived from the measurements, which were themselves random variables. Because of the CLM, we know something important about the shape of the distribution of the sample average \u2014 namely, that as the sample size grows, it becomes normally distributed.", "Normal distribution: the normal distribution is a class of distributions that people tend to be familiar with as the \u2018bell curve\u2019: thin tails surrounding a thicker middle, symmetrically centered around an average value. There\u2019s a formula for the normal distribution, but for our purposes we don\u2019t need to dwell too much on it. What\u2019s important to understand is that the normal distribution is, essentially, just a type of shape with well understood properties, in the same way that \u2018circles\u2019 are a type of shape. Just like a circle can be larger or smaller, normal distributions come in different sizes \u2014 some are taller and narrower and some flatter and wider \u2014 but all have certain things in common. In order to perfectly describe a circle you only need two pieces of information, its radius and where its center is located. Similarly in order to perfectly describe a normal distribution you only need two pieces of information \u2014 its average value (analogous to its \u2018center\u2019) and its standard deviation.", "To get a sense for what it means that the sample average will be normally distributed as the sample size grows, let\u2019s follow a simple example. Instead of a sample of heights, we\u2019ll consider an even simpler random variable, the value of a dice roll. You\u2019ll notice that the distribution of probabilities of a dice roll (assuming it\u2019s a fair die) is decidedly not shaped like a bell curve. Each number is expected to come up with equal likelihood:", "There is an \u2018average\u2019 expected value to this distribution, but that average is actually 3.5, a number we\u2019ll never see on any single roll. It doesn\u2019t matter how many times you roll a die, the probabilities for the next roll stay the same. If we roll a single die a large number of times and simply record what it landed on, we should get a graph that looks very similar to these basic probabilities, plus or minus some differences due to the random chance of our rolls:", "If instead of rolling one die at a time, we roll a handful at once and record the average, something interesting starts to happen. Let\u2019s try rolling 5 dice at once:", "When we roll the dice five at a time, we start to see a peak in the middle. This is in a way the beginning of the Law of Large Numbers \u2014 when we roll one die we get values far away from the overall expected value like 1 and 6 as often as not, but when we roll multiple dice and consider the average of their values, we tend to get numbers closer to the expected value of 3.5. Additionally, the distribution is beginning to get the bell shape. Trying again with even more rolls continues the trend:", "Regardless of the distribution of population from which the sample is drawn: You may be thinking that maybe this isn\u2019t all that impressive of a result, that something as simple as rolling dice might reasonably tend towards this sort of result. What\u2019s incredible is that this result holds regardless of what the underlying distribution of the random variable you\u2019re considering is. Say, for instance, you have a loaded die which doesn\u2019t land on each number with equal probability. Consider these probabilities:", "This die favors some numbers, like 4, and actually never lands on 5. If we roll it a number of times, we get a the sort of results you would expect:", "But, again, if we roll 5 of these dice at a time and average the results, we start to see the beginnings of our bell-curve forming:", "And if we roll 25 at a time, we can no longer really tell that we\u2019re generating these sample averages from a skewed underlying distribution:", "It doesn\u2019t matter what sort of distribution the underlying random variable has, the distribution of the sample average will become closer and closer to a normal distribution as the sample size grows.", "Remember that any normal distribution can be described with just two pieces of information \u2014 the average value and the standard deviation. What will these two values be for our distribution of sample averages? Well, the average value will be the true population average. The standard deviation, however, shrinks as the size of our sample goes up -this is essentially just the LLN again, as the sample grows, the average should move closer to the true population average. As it turns out, the standard deviation of this normal curve is the standard deviation of population divided by the square root of the sample size.", "Why is it so useful to know that the sample average is normally distributed? Particularly if you only ever see one sample average? Well, unlike the distribution of whatever you\u2019re studying, whose shape you may not even know, the normal distribution has a few well known and reliable features. With a reasonably sized sample, the law of large numbers suggests we should find a sample average that\u2019s near to the true population average, but how near? Knowing that the sample average is normally distributed helps. Recall that the normal distribution is a shape with certain predictable properties, one of which is that it is densest around its average value. Most of the area of the normal distribution is centered around the mean, and the tails drop away pretty quickly. A number picked at random from a normal distribution is much more likely to come from the center area of the curve than from out in the tails.", "What\u2019s more, while some normal distributions are taller and narrower than others, we can quantify the amount of area under the curve with the same ratio of standard deviations. To illustrate what I mean by this, consider the following normal curve:", "The blue vertical line represents the mean value of the distribution. The red vertical lines are one standard deviation above and below the mean. The red shaded area between them \u2014 that is, everything under the curve between -1 and 1 standard deviations from the mean \u2014 represents just about 68% of the area under the curve. Similarly, the yellow vertical lines represent two standard deviations above and below the mean and the are between them represents a bit more that 95% of the distribution\u2019s total area. If you pick a value from a normal distribution at random, 95% of the time you\u2019ll get a value from between those two lines. This is true regardless of what value the normal distribution\u2019s mean or standard deviations take on.", "As it turns out, even though we only see one sample and one sample average, these facts about the distribution of the sample average and normal distributions in general give us a lot to work with. The sample average is an unbiased estimator of the true population average and the sample\u2019s standard deviation is an unbiased estimator of the population standard deviation (actually, there\u2019s a minor tweak to the sample standard deviation to correct for some bias, but it doesn\u2019t change the logic here and, anyways, most statistical packages will have applied it for you anyways). Recall that the standard deviation for the distribution of sample averages is derived from the population\u2019s standard deviation (by dividing by the square root of the sample size). We have all the information we need to describe the distribution of the sample average from this one sample!", "Furthermore, we\u2019re pretty sure that this particular sample average falls somewhere in the center of the distribution. We don\u2019t know if it\u2019s a bit above the true population average or below the true population average, but we\u2019re 95% sure that it\u2019s somewhere in between two standard deviations above and below the mean. If we take our sample average and add two standard deviations to create a top end and subtract two standard deviations to get a bottom, we have a range. In 95% of ranges created this way, the true population mean will fall somewhere in the range. This is called the \u2018confidence interval\u2019, because it quantifies a 95% level of confidence. This is also how margins of error on polls are created.", "It may help to see this in action, so let\u2019s consider another simple example. Again, we\u2019ll roll dice (or, rather, I\u2019ll have the computer simulate rolling dice). We\u2019ll roll 20-sided dice, so the \u2018population\u2019 of dice rolls is every number from one to twenty. The \u2018average\u2019, expected value for this population is 10.5. Each sample will be 20 rolls taken together. From this sample we\u2019ll derive an estimate for the population average (the sample average) and a sample standard deviation. From these we\u2019ll construct our 95% confidence intervals in the manner discussed above. Here are the results of 25 simulated trials:", "The red dashes are the sample averages and the blue bars surrounding them are the confidence intervals. For instance, in the first trial there was a sample average of close to 12 and a confidence interval that ranged from 9 to around 14. For easy reference, I\u2019ve put the vertical purple line at 10.5 to represent the true population expected value. You\u2019ll notice that the sample averages bounce around due to random chance, sometimes your sample average will be above the true average, sometimes below. But when you construct the confidence interval, the interval almost always contains the true population average within. Out of the 25 simulated trials here, only two samples were so far from the average that the true population average did not appear somewhere in the confidence interval. Of course, with something like rolling dice we sort of know ahead of time what the true expected value should be, but when dealing with some other random variable in the wild, building a confidence interval like this is critically important.", "The CLM can also be used to answer the question of how big a sample you need. Recall that as the sample size grows, the standard deviation of the sample average falls (it\u2019s the population standard deviation divided by the square root of the sample size). If you did the same experiment up above again, but this time had each trial include 100 dice rolls instead of only 20, you might see results like this:", "This looks a lot like the first time we ran this experiment, until you look at the x-axis and notice that the scale is smaller! Our sample averages our generally closer to the true population average and our confidence intervals are tighter. Using the CLM and these insights about the shape of the the normal distribution we can answer the question of how big the sample needs to be in order to hit some pre-specified level of accuracy.", "*Formal statements of the CLM typically refer to the normalized sum of independent random variables rather than their simple average, but the conclusion holds for the sample average, and for purposes of this introduction, it\u2019s more straightforward to think about the sample average.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist with a particular passion for limericks, policy and renewable energy."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe905f8c06bb5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----e905f8c06bb5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Bessel's_correction", "anchor_text": "correct for some bias"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e905f8c06bb5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/central-limit-theorem?source=post_page-----e905f8c06bb5---------------central_limit_theorem-----------------", "anchor_text": "Central Limit Theorem"}, {"url": "https://medium.com/tag/statistics?source=post_page-----e905f8c06bb5---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/data-science-ground-up?source=post_page-----e905f8c06bb5---------------data_science_ground_up-----------------", "anchor_text": "Data Science Ground Up"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&user=Max+Miller&userId=dfd5ba1a8332&source=-----e905f8c06bb5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&user=Max+Miller&userId=dfd5ba1a8332&source=-----e905f8c06bb5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe905f8c06bb5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e905f8c06bb5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e905f8c06bb5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/@max.samuel.miller/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "409 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F930bd413e257&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-central-limit-theorem-e905f8c06bb5&newsletterV3=dfd5ba1a8332&newsletterV3Id=930bd413e257&user=Max+Miller&userId=dfd5ba1a8332&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}