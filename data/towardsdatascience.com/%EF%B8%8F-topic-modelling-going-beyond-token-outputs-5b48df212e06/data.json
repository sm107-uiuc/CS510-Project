{"url": "https://towardsdatascience.com/%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06", "time": 1683011013.725566, "path": "towardsdatascience.com/%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06/", "webpage": {"metadata": {"title": "Topic Modelling: Going Beyond Token Outputs | by Lowri Williams | Towards Data Science", "h1": "Topic Modelling: Going Beyond Token Outputs", "description": "Note: The methodology behind the approach discussed in this post stems from a collaborative project between the Data Innovation Accelerator and Simply Do Ideas. I recently faced a task where the end\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.cardiff.ac.uk/data-innovation-accelerator", "anchor_text": "Data Innovation Accelerator", "paragraph_index": 0}, {"url": "https://www.simplydo.co.uk/", "anchor_text": "Simply Do Ideas", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/@actsusanli", "anchor_text": "Susan Li", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21", "anchor_text": "Topic Modelling in Python with NLTK and Gensim", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation", "anchor_text": "Latent Dirichlet Allocation", "paragraph_index": 4}, {"url": "https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/dataset.csv", "anchor_text": "Github", "paragraph_index": 5}, {"url": "https://github.com/LowriWilliams/Topic_Modelling_Beyond_Tokens/blob/master/topic_modelling.ipynb", "anchor_text": "https://github.com/LowriWilliams/Topic_Modelling_Beyond_Tokens", "paragraph_index": 36}], "all_paragraphs": ["Note: The methodology behind the approach discussed in this post stems from a collaborative project between the Data Innovation Accelerator and Simply Do Ideas.", "I recently faced a task where the end goal was to automatically aggregate a large number of unstructured sentences and short paragraphs into groups of related topics.", "During this task, I realised that there hasn\u2019t been much coverage across topic modelling approaches, particularly when trying to give topics meaningful names. I quickly realised that the methods that exist have the same problem; they name topics using a list of tokens (single words). It is often left to the human interpreter to determine that, for example,'mouse', 'keyboard', 'monitor', 'cpu' are tokens from a piece of text that describe the parts of a computer.", "This post discusses the application of keyword extraction techniques alongside topic modelling in order to assign topics with meaningful names. In this context, I define \u2018meaningful\u2019 as more than just tokens in which a reader has to interpret the overall semantic relationship between to understand the overall subject. As a reader, and from the aforementioned example, I want to be able to know that this particular topic is about 'computer parts' without having to think much more about it.", "Susan Li is a well-known contributor within the Towards Data Science community. Her particular post titled \u2018Topic Modelling in Python with NLTK and Gensim\u2019 has received several claps for its clear approach towards applying Latent Dirichlet Allocation (LDA), a widely used topic modelling technique, to convert a selection of research papers to a set of topics.", "The dataset in question can be found on Susan\u2019s Github. It consists of 2,507 short research paper titles.", "Let\u2019s first cover the pre-processing techniques we need to consider before we dive into applying the LDA topic modelling approach. Like many Natural Language Processing (NLP) problems, the first thing to usually do is convert the text to lowercase and to strip the text from any punctuation so that we have a standardised set of strings to work with. If we don\u2019t remove them, we often end up with duplicated sets of strings that only differ because they include something that should\u2019ve been removed. Also, I say \u2018many NLP\u2019 problems and not \u2018all NLP\u2019 problems as punctuation in sentiment analysis, an NLP problem which aims to automatically detect whether a piece of text expresses positive or negative sentiment or opinion, is important to consider. As a short example, consider how a reader may interpret the sentiment of They cut my hair short and They cut my hair short!!!! differently based on the over-inclusion of the exclamation marks. Nevertheless, punctuation is relatively meaningless when applying topic modelling. We can remove them by using Regular Expressions. We also want to consider removing additional white spacing that might occur on either end of the strings, as well as within the string itself.", "Now that our text is stripped from punctuation, we want to represent the titles as individual words (tokenise) as well as looking at removing stop words. Stop words (such as \u201cthe\u201d, \u201ca\u201d, \u201can\u201d, \u201cin\u201d) are commonly used words that provide meaningless information and are often removed from the text during the pre-processing stage.", "We can easily tokenise and remove stop words using one of Python\u2019s NLP libraries, Natural Language Toolkit (NLTK). To tokenise, we can apply NLTK\u2019s inbuilt word_tokenize function to the titles. This output represents each text as a list containing each word which construct the titles. We can then initialise NLTK\u2019s stop word function. I\u2019ve noticed that there isn\u2019t a decent stop word list out there and many people, like me, have to add words to the original lists! We then iterate over each list and remove words which correspond to the stop word list.", "Lastly, we\u2019ll want to look at applying lemmatisation to the remaining words from each title. Lemmatisation takes into consideration the morphological analysis of the words. To do so, it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma or its base form of all its inflectional forms (e.g. studies, studying share the lemma study). NLTK contains a lexical database for English words. These words are linked together based on their semantic relationships. The linking is dependent on the meanings of the words. In particular, we can use WordNet, a lexical database of semantic relations between words. Again, we lemmatise as we want to achieve a standardised set of words which describe the paper titles. We initialise the WordNet lemmatiser, which is then applied to each word in the list, replacing it with its lemma. The output should now look something like this:", "Now that our data is processed, we can start looking into applying LDA and group paper titles into topics. Before we do so, there\u2019s one last pre-processing step and that is to represent the titles as vectors, i.e. we need to represent our data into a numerical form so that the model can handle them. There are several representations you can use, with the popular methods being the word\u2019s TF-IDF score or their frequency counts (bag-of-words approach). Here, we\u2019ll stick to a bag-of-words representation. We\u2019ll use the CounterVectorizer function from Sklearn\u2019s feature extraction module. This function converts a collection of text to a matrix of word counts.", "Sklearn also includes a version of LDA. For this concept, let\u2019s say we want to split the paper titles into 1 of 10 topics. Once the parameters are set, we can fit the LDA to the vectorised version of the text. To make it easier to read, we can append the relevance score produced for each topic to each title as a column and calculate the dominant topic by taking the topic with the highest relevance score.", "Great! Now we can see which topic (by its number) a title belongs to. But what keywords has the LDA given to describe the topics? We can view them by calling the vectoriser\u2019s get_feature_names() function:", "How useful is information to us? Well, it\u2019s not that useful as there are some topics with the same keywords, such as network and data. We\u2019ll want to remove those duplicated words as we want a title to belong to one topic only before assigning topics with meaningful titles.", "Now for the interesting part. Let\u2019s first merge the token outputs for each topic to each row which corresponds to that topic in the main dataframe. That way, we\u2019ll have one main dataframe to work from.", "Before I explain what the code does, let\u2019s introduce Rapid Automatic Keyword Extraction (RAKE). RAKE is a well-known keyword extraction tool which uses a list of stop words and phrase delimiters to detect the most relevant words or phrases in a piece of text. Take the following text as an example:", "\u201cKeyword extraction is not that difficult after all. There are many libraries that can help you with keyword extraction. Rapid automatic keyword extraction is one of those.\u201d", "Firstly, RAKE splits the text into a list of words, removing stop words in the process. This returns a list of what is known as content words.", "content_words = [keyword, extraction, difficult, many, libraries, help, rapid, automatic]", "Then, the algorithm splits the text at phrase delimiters and stop words to create candidate expressions. So, the candidate key phrases would be the following:", "Keyword extraction is not that difficult after all. There are many libraries that can help you with keyword extraction. Rapid automatic keyword extraction is one of those.", "Once the text has been split, the algorithm creates a matrix of word co-occurrences. Each row shows the number of times that a given content word co-occurs with every other content word in the candidate phrases. For the example above, the matrix would look like this:", "After the matrix is built, words are given a score which can be calculated using one of three methods: the degree of a word in the matrix (i.e. the sum of the number of co-occurrences the word has with any other content word in the text), as the word frequency (i.e. the number of times the word appears in the text), or as the degree of the word divided by its frequency.", "If we were to compute the degree score divided by the frequency score for each of the words in our example, the results would look like the following:", "Those expressions are also given a score, which is computed as the sum of the individual scores of words. If we were to calculate the score of the phrases in bold above, they would look like this:", "If two keywords or key phrases appear together in the same order more than twice, a new key phrase is created regardless of how many stop words the key phrase contains in the original text. The score of that key phrase is computed just like the one for a single key phrase.", "A keyword or key phrase is chosen if its score belongs to the top T scores, where T is the number of keywords you want to extract. For the example above, the method would have returned the top 3 keywords, which, according to the score we have defined, would have been rapid automatic keyword extraction (13.33), keyword extraction (5.33), and many libraries (4.0).", "So, if we iterate over each topic and apply RAKE to the original paper titles within those topics, we can extract the keywords and phrases, as well as their scores. We want to be able to associate the keywords that are extracted using RAKE to those extracted by the LDA model. We can split RAKE\u2019s keywords into unigrams and bigrams and mask those words against LDA\u2019s output. We do this because RAKE will pull out keywords that might not be associated to that topic.", "Once we\u2019ve filtered out irrelevant keywords, if we order their scores descendingly, we should see the top-scoring keywords for each topic. We can take these top-scoring keywords as the main title of each topic. If there is more than one keyword, we can append them together and separate them by the delimiter /.", "What about the remaining keywords? Those are useful too. In fact, depending on what you\u2019re trying to achieve with topic modelling, those remaining keywords can be used as child terms of the topic. That is, what else is the topic possibly about.", "We have a lot of child terms, so we can limit those by selecting the keywords with a score higher than 10. Let\u2019s visualise the results in a sunburst diagram so we can see it in action.", "Nice! We have 10 main topics, each with a few child terms. But most importantly, each topic title is informative! Let\u2019s look at the pink section of the visualisation. The main topic is titled \u2018mpeg 4 avc h 264 video coding applications\u2019. It has 7 child topics which are all relevant to video configuration frameworks:", "\u2018mpeg reconfigurable video coding framework\u2019, \u2018distributed video coding using wavelet\u2019, \u2018distributed video coding based\u2019, \u2018reconfigurable video coding framework\u2019, \u2018reach 100 coding efficiency\u2019, \u2018inter frame video coding\u2019, and \u2018high resolution video coding\u2019.", "So, what have I learnt from this analysis?", "Associating keyword extraction alongside topic modelling is a very useful approach to determine a more meaningful title to a given topic. Like many data science problems, one of the core tasks of the problem is the pre-processing of the data. But once it\u2019s done, and done well, the results can be quite promising.", "I suspect this approach can also be used to support automatically determining the number of topics to divide the data into. There are already approaches to do this, such as running LDA on a range of topics and considering the lowest perplexity of each model as the optimal number of topics. In this post, we manually chose to distribute the data into 10 topics. However, if one can calculate whether keywords exist for each topic in a given a range and take the highest number of topics with a full set of keywords as the optimal number of topics, the results may be interesting! This is something I\u2019d like to investigate further.", "For the full notebook, check out my GitHub repo below: https://github.com/LowriWilliams/Topic_Modelling_Beyond_Tokens", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5b48df212e06&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lowri-a-williams.medium.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": ""}, {"url": "https://lowri-a-williams.medium.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Lowri Williams"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe98db206e1b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&user=Lowri+Williams&userId=e98db206e1b3&source=post_page-e98db206e1b3----5b48df212e06---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.cardiff.ac.uk/data-innovation-accelerator", "anchor_text": "Data Innovation Accelerator"}, {"url": "https://www.simplydo.co.uk/", "anchor_text": "Simply Do Ideas"}, {"url": "https://towardsdatascience.com/@actsusanli", "anchor_text": "Susan Li"}, {"url": "https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21", "anchor_text": "Topic Modelling in Python with NLTK and Gensim"}, {"url": "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation", "anchor_text": "Latent Dirichlet Allocation"}, {"url": "https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/dataset.csv", "anchor_text": "Github"}, {"url": "https://github.com/LowriWilliams/Topic_Modelling_Beyond_Tokens/blob/master/topic_modelling.ipynb", "anchor_text": "https://github.com/LowriWilliams/Topic_Modelling_Beyond_Tokens"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5b48df212e06---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/topic-modeling?source=post_page-----5b48df212e06---------------topic_modeling-----------------", "anchor_text": "Topic Modeling"}, {"url": "https://medium.com/tag/nlp?source=post_page-----5b48df212e06---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/python?source=post_page-----5b48df212e06---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----5b48df212e06---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%25EF%25B8%258F-topic-modelling-going-beyond-token-outputs-5b48df212e06&user=Lowri+Williams&userId=e98db206e1b3&source=-----5b48df212e06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%25EF%25B8%258F-topic-modelling-going-beyond-token-outputs-5b48df212e06&user=Lowri+Williams&userId=e98db206e1b3&source=-----5b48df212e06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5b48df212e06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5b48df212e06---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5b48df212e06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5b48df212e06--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5b48df212e06--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5b48df212e06--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5b48df212e06--------------------------------", "anchor_text": ""}, {"url": "https://lowri-a-williams.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lowri-a-williams.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lowri Williams"}, {"url": "https://lowri-a-williams.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "233 Followers"}, {"url": "https://lowriwilliams.co.uk", "anchor_text": "https://lowriwilliams.co.uk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe98db206e1b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&user=Lowri+Williams&userId=e98db206e1b3&source=post_page-e98db206e1b3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff5f2750d6328&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F%EF%B8%8F-topic-modelling-going-beyond-token-outputs-5b48df212e06&newsletterV3=e98db206e1b3&newsletterV3Id=f5f2750d6328&user=Lowri+Williams&userId=e98db206e1b3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}