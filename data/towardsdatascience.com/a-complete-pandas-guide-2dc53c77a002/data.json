{"url": "https://towardsdatascience.com/a-complete-pandas-guide-2dc53c77a002", "time": 1683005575.054631, "path": "towardsdatascience.com/a-complete-pandas-guide-2dc53c77a002/", "webpage": {"metadata": {"title": "A Complete Pandas Guide. Building a robust data analysis process | by Soner Y\u0131ld\u0131r\u0131m | Towards Data Science", "h1": "A Complete Pandas Guide", "description": "The most time-consuming part of a data science project is data cleaning and preparation. Pandas is a very powerful and versatile Python data analysis library that expedites the preprocessing steps of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv", "paragraph_index": 9}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html", "anchor_text": "functions", "paragraph_index": 10}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/", "paragraph_index": 104}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14", "paragraph_index": 104}], "all_paragraphs": ["The most time-consuming part of a data science project is data cleaning and preparation. Pandas is a very powerful and versatile Python data analysis library that expedites the preprocessing steps of your project. In this post, I will cover a great deal of Pandas capabilities with many examples that help you build a robust and efficient data analysis process.", "The topics are ordered as below:", "The basic data structure of Pandas is DataFrame which represents data in tabular form with labeled rows and columns.", "As always, we start with importing numpy and pandas.", "In most cases, we read data from a file and convert to a DataFrame. Pandas provide functions to read data from many different file types. The most commonly used is read_csv. Other types are also available such as read_excel, read_json, read_html and so on. Let\u2019s go over an example using read_csv:", "We need to specify the location of the file. In the file is in same working directory or folder, you can just write the name of the file. df.head() displays the first 5 rows.", "If we only need a part of the DataFrame and would not like to read all of it, we can specify the columns with usecols parameter:", "We can also select how many rows to read using nrows parameter. It is useful when working with very large files:", "Original DataFrame has 10000 rows and by setting nrows as 500, we only read the first 500 rows.", "There are many other parameters of read_csv function which makes it powerful and handy.", "In real life cases, we mostly read data from a file instead of creating a DataFrame. Pandas provide functions to create a DataFrame by reading data from various file types. For this post, I will use a dictionary to create a sample DataFrame.", "Pandas describe function provides summary statistics for numerical (int or float) columns. It counts the number of values and show mean, std, min and max values as well as 25%, 50% and 75% quantiles.", "Although all of the columns have the same number of rows, count is different for column d because describe function does not count NaN (missing) values.", "value_counts() shows the values in a column with number of occurrences:", "value_counts() does not count NaN (missing) values.", "We should also check the data types and consider them in our analysis. Some functions can only be performed on certain data types. We can easily check the data types using dtypes:", "Both \u2018d\u2019 and \u2018e\u2019 columns have integers but data type of \u2018d\u2019 column is float. The reason is the NaN values in column d. NaN values are considered to be float so integer values in that column are upcasted to float data type.", "Pandas 1.0.1 allow using NaN as integer data type. We just need to explicitly indicate dtype as pd.Int64Dtype():", "If pd.Int64Dtype() is not used, integer values are upcasted to float:", "Handling missing values is an essential part of data cleaning and preparation process because almost all data in real life comes with some missing values.", "Let\u2019s create a dataframe with missing values first.", "np.nan, None and NaT (for datetime64[ns] types) are standard missing value for Pandas.", "Note: A new missing data type (<NA>) introduced with Pandas 1.0 which is an integer type missing value representation.", "np.nan is a float so if you use them in a column of integers, they will be upcast to floating-point data type as you can see in \u201ccolumn_a\u201d of the dataframe we created. However, <NA> can be used with integers without causing upcasting. Let\u2019s add one more column to the dataframe using <NA> which can be used by explicitly requesting the dtype Int64Dtype().", "Pandas provides isnull(), isna() functions to detect missing values. Both of them do the same thing.", "df.isna() returns the dataframe with boolean values indicating missing values.", "You can also choose to use notna() which is just the opposite of isna().", "df.isna().any() returns a boolean value for each column. If there is at least one missing value in that column, the result is True.", "df.isna().sum() returns the number of missing values in each column.", "Not all missing values come in nice and clean np.nan or None format. For example, \u201c?\u201d and \u201c- -\u201c characters in column_c of our dataframe do not give us any valuable information or insight so essentially they are missing values. However, these characters cannot be detected as missing value by Pandas.", "If we know what kind of characters used as missing values in the dataset, we can handle them while creating the dataframe using na_values parameter:", "Another option is to use pandas replace() function to handle these values after a dataframe is created:", "We have replaced non-informative cells with NaN values. inplace parameter saves the changes in the dataframe. Default value for inplace is False so if it is set it to True, changes will not be saved.", "There is not an optimal way to handle missing values. Depending on the characteristics of the dataset and the task, we can choose to:", "We can drop a row or column with missing values using dropna() function. how parameter is used to set condition to drop.", "Furthermore, using thresh parameter, we can set a threshold for missing values in order for a row/column to be dropped.", "axis parameter is used to select row (0) or column (1).", "Our dataframe do not have a row with full of missing values so setting how=\u2019all\u2019 did not drop any row. The default value is \u2018any\u2019 so we don\u2019t need to specify it if we want to use how=\u2019any\u2019:", "Note: inplace parameter is used to save the changes to the original DataFrame. The default value is false so if we do not set it as True, the changes we make are not saved in the original DataFrame.", "Setting thresh parameter to 3 dropped rows with at least 3 missing values.", "Data is a valuable asset so we should not give it up easily. Also, machine learning models almost alwasy tend to perform better with more data. Therefore, depending on the situation, we may prefer replacing missing values instead of dropping.", "fillna() function of Pandas conveniently handles missing values. Using fillna(), missing values can be replaced by a special value or an aggreate value such as mean, median. Furthermore, missing values can be replaced with the value before or after it which is pretty useful for time-series datasets.", "ffill stands for \u201cforward fill\u201d replaces missing values with the values in the previous row. You can also choose bfill which stands for \u201cbackward fill\u201d.", "If there are many consecutive missing values in a column or row, you may want to limit the number of missing values to be forward or backward filled.", "Limit parameter is set to 1 so only one missing value is forward filled.", "Data science projects usually require us to gather data from different sources. Hence, as part of data preparation, we may need to combine DataFrames. In this section, I will cover the following topics:", "One way to combine or concatenate DataFrames is concat() function. It can be used to concatenate DataFrames along rows or columns by changing the axis parameter. The default value of the axis parameter is 0, which indicates combining along rows.", "As you can see in the first figure above, indices of individual DataFrames are kept. In order to change it and re-index the combined DataFrame, ignore_index parameter is set as True.", "join parameter of concat() function determines how to combine DataFrames. The default value is \u2018outer\u2019 returns all indices in both DataFrames. If \u2018inner\u2019 option is selected, only the rows with shared indices are returned. I will change the index of df2 so that you can see the difference between \u2018inner\u2019 and \u2018outer\u2019.", "Pandas also provides ways to label DataFrames so that we know which part comes from which DataFrame. We just pass the list of combined DataFrames in order using keys parameter.", "It also makes it easier to access different parts of DataFrames conveniently:", "One important note about concat() function is that it makes a copy of the data. To prevent making unnecessary copies, the copy parameter needs to set as False. The default value is True.", "append() function is also used to combine DataFrames. It can be seen as a particular case of concat() function (axis=0 and join=\u2019outer\u2019) so I will not cover it in detail but will just give an example to show the syntax.", "Another widely used function to combine DataFrames is merge(). Concat() function simply adds DataFrames on top of each other or adds them side-by-side. It is more like appending DataFrames. Merge() combines DataFrames based on values in shared columns. Merge() function offers more flexibility compared to concat() function. It will be clear when you see the examples.", "The on parameter selects which column or index level is used to merge.", "The column names do not have to be the same. Our focus is the values in columns. Assume two DataFrames have common values in a column that you want to use to merge these DataFrames but the column names are different. In this case, instead of on parameter, you can use left_on and right_on parameters. To show the difference, I will change the column name in df2 and then use merge:", "Although the returned values are the same in column_a and new_column_a, merged DataFrame includes both columns due to having different names.", "You can also pass multiple values to on parameter. The returned DataFrame only includes rows that have the same values in all the columns passed to on parameter.", "df1 and df2 are merged based on the common values in column_a. It\u2019s time to introduce how parameter of merge(). As the name suggests, it indicates how you want to combine. The possible values for how are \u2018inner\u2019, \u2018outer\u2019, \u2018left\u2019, \u2018right\u2019.", "The concept of how is more clear in the figure below. If you are familiar with SQL, the logic is same as SQL joins.", "The figures below represents the concept of how parameters more clearly.", "\u2018outer\u2019, \u2018left\u2019, and \u2018right\u2019 options include data that is not present in one of the DataFrames. The missing parts are automatically filled with NaN values. NaN is the standard representation of missing values in Pandas.", "The default value of how is \u2018inner\u2019 so you don\u2019t have to explicitly write in the function. \u2018Inner\u2019 only returns the rows with common values in column_a.", "When \u2018outer\u2019 is chosen for how parameter, merged DataFrame includes all values of column_a in both DataFrames. However, common values (column_a = 1 and column_a = 2) are not duplicated.", "When \u2018left\u2019 is chosen for how parameter, merged DataFrame includes all rows from left DataFrame. The columns that come from right DataFrame are filled with NaN values if the value in column_a (the column that is passed to on parameter) is not present in right DataFrame. \u2018right\u2019 option is rarely used because you can just change the order of DataFrames in merge function (instead of (df1,df2) use (df2,df1)).", "You may have noticed that a suffix is added to column names that are same in both DataFrames. It is useful to distinguish which column comes from which DataFrame. You can specify the suffix to be added using suffixes parameter.", "iloc and loc allows selecting part of a DataFrame.", "Let\u2019s go through some examples because, as always, practice makes perfect. I will use the following DataFrame for the examples in this section:", "Select first row, second column (i.e. the second value in the first row):", "All rows, third column (It is same as selecting the second column but I just want to show the use of \u2018:\u2019 ):", "Rows up to 2 and columns up to \u2018b\u2019 :", "You may wonder why we use same values for rows in both loc and iloc. The reason is the numerical index. Loc selects by position but the position of rows are same as index.", "Let\u2019s create a new DataFrame with a non-numerical index so that we can see the difference:", "There are multiple ways to reshape a dataframe. We can choose the one that best fits the task at hand. The functions to reshape a dataframe:", "Melt is used to convert wide dataframes to narrow ones. What I mean by wide is a dataframe with a high number of columns. Some dataframes are structured in a way that consecutive measurements or variables are represented as columns. In some cases, representing these columns as rows may fit better to our task.", "We have three different cities and measurements done on different days. We decide to represent these days as rows in a column. There will also be a column to show the measurements. We can easily accomplish this by using melt function:", "Variable and value column names are given by default. We can use var_name and value_name parameters of melt function to assign new column names. It will also look better if we sort the data by city column:", "Stack function kind of increases the index level of the dataframe. What I mean by increasing the level is:", "It is better explained with examples. Consider the following dataframe:", "Let\u2019s also check the shape and index:", "Stack and unstack functions are more commonly used for dataframes with multi-level indices. Let\u2019s create a dataframe with multi-level index:", "If we apply stack function on this dataframe, the level of index will be increased:", "Now the names of the colums (column_x and column_y) are part of multi-level index. So the resulting dataframe has one column and a 3-level multi-index.", "Unstack is just the opposite of stack. If we apply unstack to the stacked dataframe, we will get back the original dataframe:", "The functions covered in this part:", "Assume your data set includes multiple entries of a feature on a single observation (row) but you want to analyze them on separate rows.", "We want to see the measurements of \u2018c\u2019 on day \u20181\u2019 on separate rows which easily be done using explode:", "It is better to reset the index as well:", "We can also use explode on two columns as a chain:", "Make sure to use reset_index after the first explode or you will get an unexpected result as below:", "Nunique counts the number of unique entries over columns or rows. It is very useful in categorical features especially in cases where we do not know the number of categories beforehand.", "Assume we have the following DataFrame:", "To find the number of unique values in a column:", "We can achieve the same result using value_counts with a slightly more complicated syntax:", "However, nunique allows us to do this operation on all columns or rows at the same time:", "It can be used to look up values in the DataFrame based on the values on other row, column pairs. This function is best explained via an example. Assume we have the following DataFrame:", "For each day, we have measurements of 4 people and a column that includes the names of these 4 people. We want to create a new column that shows the measurement of the person in \u201cSelect\u201d column:", "We do not have to do this operation on all data points. We can use a specific range as long as the row and column labels have the same size:", "\u201cWhere\u201d is used to replace values in rows or columns based on a condition. You can also specify the value to be put as replacement. The default is NaN. Let\u2019s go over an example so that it becomes clear.", "We can specify the replacement value:", "Pandas supports a wide range of data types, one of which is object. Object covers text or mixed (numeric and non-numeric) values. However, it is not preferred to use object data type if a different option is available. Certain operations is executed faster with more specific data types. For example, we prefer to have integer or float data type for numerical values.", "infer_objects attempts to infer better dtypes for object columns. Let\u2019s go through an example.", "Thank you for reading. Please let me know if you have any feedback.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Top 10 Writer in AI and Data Science | linkedin.com/in/soneryildirim/ | twitter.com/snr14"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2dc53c77a002&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sonery.medium.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448----2dc53c77a002---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@threeedil?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "threeedil"}, {"url": "https://unsplash.com/s/photos/complete-guide?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html", "anchor_text": "functions"}, {"url": "https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Markus Winkler"}, {"url": "https://unsplash.com/s/photos/complete-guide?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@fahrulazmi?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Fahrul Azmi"}, {"url": "https://unsplash.com/s/photos/select?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@dnevozhai?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Denys Nevozhai"}, {"url": "https://unsplash.com/s/photos/look-for?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@bpyndus?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Bodie Pyndus"}, {"url": "https://unsplash.com/s/photos/select?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@andre_furtado?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Andre Furtado"}, {"url": "https://unsplash.com/s/photos/select?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@kylejglenn?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Kyle Glenn"}, {"url": "https://unsplash.com/s/photos/unique?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/data-science?source=post_page-----2dc53c77a002---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2dc53c77a002---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----2dc53c77a002---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/programming?source=post_page-----2dc53c77a002---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----2dc53c77a002---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=-----2dc53c77a002---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2dc53c77a002&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2dc53c77a002---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2dc53c77a002--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2dc53c77a002--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2dc53c77a002--------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sonery.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soner Y\u0131ld\u0131r\u0131m"}, {"url": "https://sonery.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21K Followers"}, {"url": "http://linkedin.com/in/soneryildirim/", "anchor_text": "linkedin.com/in/soneryildirim/"}, {"url": "http://twitter.com/snr14", "anchor_text": "twitter.com/snr14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2cf6b549448&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=post_page-2cf6b549448--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cdf5377373a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-pandas-guide-2dc53c77a002&newsletterV3=2cf6b549448&newsletterV3Id=7cdf5377373a&user=Soner+Y%C4%B1ld%C4%B1r%C4%B1m&userId=2cf6b549448&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}