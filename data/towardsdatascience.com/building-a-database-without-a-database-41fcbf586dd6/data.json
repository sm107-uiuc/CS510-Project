{"url": "https://towardsdatascience.com/building-a-database-without-a-database-41fcbf586dd6", "time": 1683015459.5023549, "path": "towardsdatascience.com/building-a-database-without-a-database-41fcbf586dd6/", "webpage": {"metadata": {"title": "Building a Database \u2014 Without a Database | by Dylan Cunningham | Towards Data Science", "h1": "Building a Database \u2014 Without a Database", "description": "Machine learning practitioners and data engineers are well aware of the repeatable nature of data sourcing, gathering, cleaning, transforming, merging, and labeling. The purpose of these activities\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/compose.html", "anchor_text": "Pipeline", "paragraph_index": 0}, {"url": "https://alpaca.markets/", "anchor_text": "Alpaca", "paragraph_index": 17}, {"url": "https://alpaca.markets/", "anchor_text": "Alpaca", "paragraph_index": 30}], "all_paragraphs": ["Machine learning practitioners and data engineers are well aware of the repeatable nature of data sourcing, gathering, cleaning, transforming, merging, and labeling. The purpose of these activities are to prepare data for reduction, exploratory analysis, or modeling. scikit-learn, for example, has done a fantastic job at abstracting data pipelines via their Pipeline class. Still, the problem of pulling data from multiple sources remains as there are not many simple abstractions making the data wrangler\u2019s life easier.", "Problem Statement: Disparate data are disparate and cumbersome to coalesce.", "Solution: Develop a pythonic database abstraction to coalesce your data in an easy-to-use, robust, and production-ready way.", "Abstractions make programming life more manageable. A database \u2014 without a database \u2014 abstraction will make your data wrangling life more comfortable, and will be a robust addition to your production pipeline.", "In an effort not to duplicate the articles on the web, I will not explain abstractions, but here are two references:", "An abstraction is defined as something that sits on top of something more complex and makes it more simple for the user. \u2014 Matt Burgess in \u201cCritical Concept: Abstraction\u201d", "A database \u2014 without a database \u2014 abstraction (which I will refer to as a database abstraction; not to be confused with a SQL database) serves at least four purposes:", "If built with enough foresight, a database abstraction will abstract away the need to do all wrangling operations repeatedly. The challenge is making the abstraction well enough to allow users the flexibility to apply any of their preferred operations in a robust and easy-to-use manner.", "Here is a non-comprehensive list of well-known data wrangling operations: querying, ordering, transforming, filling null values, and merging. Writing code to do these operations (and more) for every experiment and/or for every production model is too much to ask.", "The end goal of an ML pipeline is to make predictions (i.e., for most ML tasks). One issue data scientists face is reproducibility. When a data scientist is in an experimentation phase, they apply all sorts of wrangling operations to test which are optimal. Transferring the best operations into a production scenario is not always easy.", "A database abstraction will allow scientists to transition from an experimentation phase to a production phase, and back, with ease and in a reproducible manner.", "A database abstraction does not need an on-premise or cloud-based data store, but you may wish to grant users that ability. In my case, I did not want to manage a database. I simply build functionality to interact with web APIs, web pages, and the like.", "Their database is my database, but their database problems are not my problems.", "Note: One limitation of this abstraction is query speed. If you manage your own database, you likely can improve the performance of your queries.", "This purpose is essential, and an under-thought-out point. Leaving the order of operations for a user to figure out and remember on their own is too much to ask. The solution is to build it once \u2014 get the logic and order of operations down and built once \u2014 then you will not have to build it again.", "Order of operations failure example: The line chart below shows if you calculate a moving average on an already forward filled price series, then your results will be lagged. Lagged information is not ideal. The proper order of operations, for these sorts of wrangling tasks, are to calculate a moving average before expanding a series across dates, merge to your master dataset, and forward fill afterward.", "The database abstraction below is a powerful and robust way to coalesce, transform, and merge data in a production-ready way. It serves as the first step in a production pipeline (see diagram above). In fact, you might innovate and merge scikit-learn pipeline functionality somehow. One possibility is to create a new class called MyPipeline, make sure to inherit your Database class. Then your service, lambda, or script can call MyPipeline with all the functionality you need.", "You will notice I have not done all the work for you. This abstraction is 25% focused in the field of finance. The only data source is Alpaca (I only show how my class interacts with Alpaca because their API is simple and my purpose is to teach you how to fish, not to give you a database full of fish). You will likely want/need more sources of data. Also, my code assumes the data being wrangled is time series data. The other 75% of the code is generally ready for you to copy, paste, and use out-of-the box. I suggest you tweak this code to your needs.", "Before we jump into all the code, I want to show you how a user or system interacts with this database class.", "Please recognize, I walk you through the Database class backwards. For instance, before I explain the build method, I explain the features and target methods, when the build method uses the features and target methods.", "First, we create our class object and make a way for users to interact with our abstraction easily: via the __init__ method.", "Here, we want our user to pass in a dictionary (if desired, you could build your class to allow users to specify a file path, as a string, where a json file is stored) specifying the location of their desired data, how to get the data, what transformations to apply, what to name the data, etc. This is everything needed by the user.", "Before we learn how a user\u2019s dictionary could look, here are some follow-up points:", "Second, this class provides enough structure to be useful, and is also flexible. User interaction, in my case, is very verbose. I want user interaction to be clear and unmistakable. I also want users to be able to lift and shift easily. To that end, the Database class requires a dictionary with various levels of key: value pairs, like you will see below.", "The first level of keys are globals, target, and features. Globals is used to specify entire dataset level parameters. Target is used to specify what data should be used for a target and what labeling techniques (i.e., transformations) should be applied. Features is used to specify what data should be used as features for modeling.", "The second level of key: value pairs requires information about the source of data, parameters (kwargs), names for returned data from source, which features to drop (not required, depends on source output), and what the data type should be.", "The third level of key: value pairs allows transformations to be applied to the underlying data. These transformations are applied one-by-one to each individual feature \u2014 in an intelligible way.", "Third, the below method requests data regardless of the API. This method takes the url, headers, and kwargs as arguments. Data is returned as a dictionary and processed later.", "Fourth, the below method cleans the dataset based on the clean key in the user dictionary above. The data passed to this method will be the results from the request_data method (above) as a pandas dataframe. The parameter date_int_s is there because some datetime data has seconds, sometime not (default is set to False).", "Features are named. Columns are dropped. Data types are set. Index is sorted.", "Fifth, we need data sources. I use one source, Alpaca, in this example, but, as I stated earlier, your source methods can be of any variety: Web APIs, webpages, S3, SQL Server, CSV, you name it.", "Let\u2019s not hit all the detail of these methods, but here are key points:", "Note: Make sure you have APCA_API_KEY_ID and APCA_API_SECRET_KEY in your environment variables. You can get them from your account.", "Sixth, we need a method that transforms the data we source; we want to build it in a way so as to abstract the code and sequence of wrangling tasks away from the user, make it flexible, and make it robust.", "The transform method below takes a dataframe and a list of transformations to be applied. The output is a transformed feature merged and forward filled into a date dateset. This sequence is key, as described above. Later, you will see how this newly transformed feature gets merged into our target series.", "Seventh, the below function takes the first level of key: value pairs, called target, requests the data, and transforms it, or simply merges the data to a date dataset.", "Eighth, we need a function that retrieves data.", "Ninth, we need a way to quickly source features and transform them: the below methods do.", "Similarly to how we created a method to interact with our multiprocessing engine, we create one for multiprocessing the retrieval and transformation of features. Once completed, the final result is a dataset will all the correct wrangling and transformation techniques applied \u2014 in their proper order.", "Tenth, finally we get to the most important method: the method that brings them all to life. This is the method a user calls to start the build process.", "This method simply creates the final_dataset which comprises a target, transformed, and features, transformed. If a user does not have a target specified in their dictionary, then only transformed features will make up final_dataset.", "In this article, we discussed and proved that wrangling tasks have a proper order of operations. We built a class to abstract away the need for a user to apply these operations themselves; we did so in a novel way.", "I hope you enjoyed, and I would love your feedback/challenge.", "[1] M. Lopez de Prado, Advances in Financial Machine Learning (2018), Wiley", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Seeking to Improve Other\u2019s Lives Through Technology \u2022 Working as a Financial Data Scientist"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F41fcbf586dd6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://dylanwithdata.medium.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": ""}, {"url": "https://dylanwithdata.medium.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Dylan Cunningham"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec6735eb6b7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&user=Dylan+Cunningham&userId=ec6735eb6b7f&source=post_page-ec6735eb6b7f----41fcbf586dd6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn"}, {"url": "https://scikit-learn.org/stable/modules/compose.html", "anchor_text": "Pipeline"}, {"url": "https://www.linkedin.com/in/dylancunningham/", "anchor_text": "Me"}, {"url": "https://medium.com/@mattburgess/critical-concept-abstraction-ba9e9c0f225e", "anchor_text": "Critical Concept: Abstraction"}, {"url": "https://stackify.com/oop-concept-abstraction/", "anchor_text": "OOP Concept for Beginners: What is Abstraction?"}, {"url": "https://www.linkedin.com/in/dylancunningham/", "anchor_text": "Me"}, {"url": "https://www.linkedin.com/in/dylancunningham/", "anchor_text": "Me"}, {"url": "https://alpaca.markets/", "anchor_text": "Alpaca"}, {"url": "https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089", "anchor_text": "here"}, {"url": "https://alpaca.markets/", "anchor_text": "Alpaca"}, {"url": "https://numpy.org/", "anchor_text": "numpy"}, {"url": "https://pandas.pydata.org/", "anchor_text": "pandas"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://docs.python.org/3/library/abc.html", "anchor_text": "abstract"}, {"url": "https://medium.com/tag/data-wrangling?source=post_page-----41fcbf586dd6---------------data_wrangling-----------------", "anchor_text": "Data Wrangling"}, {"url": "https://medium.com/tag/database?source=post_page-----41fcbf586dd6---------------database-----------------", "anchor_text": "Database"}, {"url": "https://medium.com/tag/python?source=post_page-----41fcbf586dd6---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/financial-data-science?source=post_page-----41fcbf586dd6---------------financial_data_science-----------------", "anchor_text": "Financial Data Science"}, {"url": "https://medium.com/tag/abstraction?source=post_page-----41fcbf586dd6---------------abstraction-----------------", "anchor_text": "Abstraction"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&user=Dylan+Cunningham&userId=ec6735eb6b7f&source=-----41fcbf586dd6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&user=Dylan+Cunningham&userId=ec6735eb6b7f&source=-----41fcbf586dd6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F41fcbf586dd6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----41fcbf586dd6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----41fcbf586dd6--------------------------------", "anchor_text": ""}, {"url": "https://dylanwithdata.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://dylanwithdata.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dylan Cunningham"}, {"url": "https://dylanwithdata.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "285 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec6735eb6b7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&user=Dylan+Cunningham&userId=ec6735eb6b7f&source=post_page-ec6735eb6b7f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F358b370635f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-database-without-a-database-41fcbf586dd6&newsletterV3=ec6735eb6b7f&newsletterV3Id=358b370635f1&user=Dylan+Cunningham&userId=ec6735eb6b7f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}