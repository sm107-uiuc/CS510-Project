{"url": "https://towardsdatascience.com/understand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f", "time": 1683005100.4213052, "path": "towardsdatascience.com/understand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f/", "webpage": {"metadata": {"title": "Understand the machine learning Blackbox with ML-interpreter | by Hannah Yan Han | Towards Data Science", "h1": "Understand the machine learning Blackbox with ML-interpreter", "description": "There are dangers in having models running the world and making decisions from hiring to criminal justice. While it\u2019s ideal to have models that are both interpretable & accurate, many of the popular\u2026"}, "outgoing_paragraph_urls": [{"url": "http://ml-interpret.herokuapp.com", "anchor_text": "ML-interpreter", "paragraph_index": 2}, {"url": "https://lime-ml.readthedocs.io/en/latest/", "anchor_text": "LIME", "paragraph_index": 4}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 4}, {"url": "https://github.com/TeamHG-Memex/eli5", "anchor_text": "ELI5", "paragraph_index": 4}, {"url": "https://pypi.org/project/skater/", "anchor_text": "Skater", "paragraph_index": 4}, {"url": "https://pypi.org/project/alibi/", "anchor_text": "ALIBI", "paragraph_index": 4}, {"url": "http://uc-r.github.io/dalex", "anchor_text": "Dalex", "paragraph_index": 4}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://www.smartly.io/blog/data-driven-attribution-101-how-it-helps-incrementality-testing-and-lookback-windows", "anchor_text": "Shapley values", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d", "anchor_text": "post", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1802.03888", "anchor_text": "paper", "paragraph_index": 11}, {"url": "https://archive.ics.uci.edu/ml/datasets/Adult", "anchor_text": "dataset", "paragraph_index": 15}, {"url": "https://github.com/slundberg/shap", "anchor_text": "here", "paragraph_index": 18}, {"url": "https://docs.google.com/forms/d/e/1FAIpQLSdTXKpMPC0-TmWf2ngU9A0sokH5Z0m-QazSPBIZyZ2AbXIBug/viewform", "anchor_text": "feedback", "paragraph_index": 24}, {"url": "http://ml-interpret.herokuapp.com", "anchor_text": "app", "paragraph_index": 24}, {"url": "https://github.com/yanhann10/ml_interpret", "anchor_text": "Github", "paragraph_index": 24}, {"url": "https://christophm.github.io/interpretable-ml-book/ale.html", "anchor_text": "ALEplot", "paragraph_index": 27}, {"url": "https://github.com/blent-ai/ALEPython", "anchor_text": "version", "paragraph_index": 27}, {"url": "https://www.oreilly.com/radar/ideas-on-interpreting-machine-learning/", "anchor_text": "Ideas on Interpreting Machine Learning", "paragraph_index": 33}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable ML book", "paragraph_index": 34}, {"url": "https://www.h2o.ai/wp-content/uploads/2019/08/An-Introduction-to-Machine-Learning-Interpretability-Second-Edition.pdf", "anchor_text": "An introduction to Machine learning interpretability", "paragraph_index": 35}, {"url": "https://www.hannahyan.com/", "anchor_text": "https://www.hannahyan.com/", "paragraph_index": 38}], "all_paragraphs": ["There are dangers in having models running the world and making decisions from hiring to criminal justice. While it\u2019s ideal to have models that are both interpretable & accurate, many of the popular & powerful algorithms are still black-box.", "Among them are highly performant tree ensemble models such as lightGBM, XGBoost, random forest. Knowing their inner workings brings many benefits, including transparency, trust, regulatory compliance and fairness. Or else, one may have to resort to more interpretable yet primitive models.", "To make interpretations easier, I built a web app ML-interpreter .", "Before diving into the detailed functionalities, here\u2019s a primer on interpretability.", "There are many interpretability frameworks nowadays, including Python packages LIME, SHAP, ELI5, Skater, and less-known ones like ALIBI, R package Dalex as well as R wrapper of SHAP and LIME. Dealing with the mechanism, syntax and usage of many different frameworks can be overwhelming at first, which prompted me to build the app. Here are some key concepts.", "To explain a model, we typically want to know (1) the features\u2019 impact on the outcome and (2) the direction of the impact.", "We would also want to know:", "Most of the frameworks can do both global and local interpretation, some focus on local levels, such as LIME.", "Frameworks like SHAP are model-agnostic. Others specialize in specific models, such as ELI5, which mainly covers tree-based models, but also can be used to interpret sklearn linear models and on text/image use cases.", "For global importance, one of the common methods is permutation importance. By shuffling the values of a particular feature and observing how much it impacts the model performance, one can derive how important the feature is. This method is believed to be more consistent than the default feature importance measure in some packages. You may read more about why here.", "For local interpretation, one can train a simple interpretable model such as a decision tree to act as a surrogate, then use this surrogate model to fit the original data with the prediction of the black-box model as a target for interpretation, and explain using this simple model.", "Another approach is based on Shapley values from game theory. The impact of individual features can sum up to explain why the prediction was different from the baseline. You can read more about how SHAP\u2019s treeExplainer works in this blog post or this arXiv paper.", "Next, we will use the app for some interpretation.", "The app consists of 4 main parts: user selection, classification report, global interpretation and local interpretation of each decision point.", "One can choose a demo data or update a small tabular csv, run a classifier (randomforest, XGBoost, lightGBM), and choose between interpretability frameworks. treeSHAP and ELI5, since they cover both global & local interpretation and handles tree ensemble models well.", "Now we will test it out on UCI\u2019s adult income dataset (included in the demo data on the app) which predicts the probability of an individual making over $50K a year based on census. First we can select one of the built-in models (such as lightGBM), choose a framework (SHAP).", "We can start with viewing the classification report and confusion matrix. Note that this is the output without any data cleaning or feature engineering. So if one preprocesses the data in advance, such as removing zero-variance or id columns (if any), the result could be even better.", "After we are content that the model has a decent result, we can inspect the most important features and see that relationship, education and age affect income the most .", "Then to inspect how those features affect income, we can zoom in to individual data points using the slider. You can read more about how to read this plot in the app or here.", "In this example 1, the person is a 21-year-old working as few as 8hours/week, and it\u2019s classified correctly into the lower-income category.", "In this other example 2, the person classified into the higher income budget has worked fairly long hours, is married and has high education status, but the location appears to have pulled down the chance.", "In this final example, the person has worked decent hours but many factors have negative impacts. One can view from the longest arrows the most important factors. And if the factor doesn\u2019t make sense, it could be time to re-process the data, find confounding factors or debug.", "If we switch to ELI5 framework instead, we can view a different visual in tabular format, summarizing what has impacted the individual decision the most.", "There you have it, an auto-interpretability app that runs a chosen algorithm, shows the model performance and indicates what makes the model predicts as it does.", "If you have any ideas/suggestions on how to improve it, here is a feedback form and link to the demo app and Github.", "The main challenge to build this is that interpretability frameworks can get computationally intensive. Packages like SHAP have C++ acceleration, while others take longer to calculate. Some classifiers also take longer than others, exacerbated by data size, though one can try a sample of the data first.", "Initially, I had as one of the plots a PDP/ICE plot from PDPbox showing how each features trend with the outcome, but having a chart calculating for 20 secs before rendering on top of other calculations is not ideal, so eventually I moved it as an optional chart that can be viewed on demand by selecting a checkbox.", "An alternative would be ALEplot (originally an R package), which is supposed to be faster and better (can handle correlated features when PDP couldn\u2019t), which might be handy when its fledgling python version stabilizes. SHAP also has its own version of partial dependence plot showing each datapoint in scatter, yet sometimes the data points just occlude each other (though its local interpretation plot is super awesome).", "Another challenge is that none of these frameworks are exactly self-explanatory. Thanks to the feedback from several ML/DS people who kindly helped with initial testing, I added how-to buttons in each section and links to explain the output in detail.", "Understanding individual decision points is quite a step forward compared to a top view of important features. However, it will be more interesting and practical to know the model predicts on a specific group, clustered based on input features or output categories, and an interactive app is a good way to make that happen. I have yet to find a framework that is good for interpreting clusters. This could also have positive implications for evaluating model fairness.", "While learning these frameworks, I noted how different they are in architecture and implementation. Eli5, for example, offers the results in both (1) tabular data frame format and (2) chart \u2014 even though their chart is also a colored HTML table. SHAP\u2019s approach is rather different \u2014 it directly generates highly compact visualization. One could, however, run some scripts to get the output in a data frame format.", "All of these frameworks boil down to two parts \u2014 the interpretation algorithm and the visual representation. The majority of their charts have the same goal, such as feature importance or partial dependence, yet they all use different charts to present the same kind of insights. It is not so easy for new users to switch gears in interpreting the interpretation. I started to wonder if it would be better to decouple the interpretation algorithms and their visual representations, and have a universal design language for machine learning interpretation that is framework-agnostic and can make communications easier.", "I\u2019ve referred to these articles/books and found them very informative:", "Ideas on Interpreting Machine Learning by O\u2019reilly", "Interpretable ML book by Christoph Molnar", "An introduction to Machine learning interpretability by Patrick Hall and Navdeep Gill at H2o", "If you like this article, please share it. Suggestions or feedbacks are always welcomed.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "#100daysproject on data science and visual storytelling \u2708\ufe0f\ud83d\uddfa\ufe0f https://www.hannahyan.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7b0f9a2d8e9f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@yanhann10?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yanhann10?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Hannah Yan Han"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b4607fd1f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&user=Hannah+Yan+Han&userId=5b4607fd1f47&source=post_page-5b4607fd1f47----7b0f9a2d8e9f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://ml-interpret.herokuapp.com", "anchor_text": "ML-interpreter"}, {"url": "http://ml-interpret.herokuapp.com", "anchor_text": "here"}, {"url": "https://lime-ml.readthedocs.io/en/latest/", "anchor_text": "LIME"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://github.com/TeamHG-Memex/eli5", "anchor_text": "ELI5"}, {"url": "https://pypi.org/project/skater/", "anchor_text": "Skater"}, {"url": "https://pypi.org/project/alibi/", "anchor_text": "ALIBI"}, {"url": "http://uc-r.github.io/dalex", "anchor_text": "Dalex"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "here"}, {"url": "https://www.kaggle.com/dansbecker/permutation-importance", "anchor_text": "ML interpretability by Kaggle"}, {"url": "https://www.smartly.io/blog/data-driven-attribution-101-how-it-helps-incrementality-testing-and-lookback-windows", "anchor_text": "Shapley values"}, {"url": "https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d", "anchor_text": "post"}, {"url": "https://arxiv.org/abs/1802.03888", "anchor_text": "paper"}, {"url": "http://ml-interpret.herokuapp.com", "anchor_text": "ML-Interpreter app"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Adult", "anchor_text": "dataset"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "here"}, {"url": "https://docs.google.com/forms/d/e/1FAIpQLSdTXKpMPC0-TmWf2ngU9A0sokH5Z0m-QazSPBIZyZ2AbXIBug/viewform", "anchor_text": "feedback"}, {"url": "http://ml-interpret.herokuapp.com", "anchor_text": "app"}, {"url": "https://github.com/yanhann10/ml_interpret", "anchor_text": "Github"}, {"url": "https://christophm.github.io/interpretable-ml-book/ale.html", "anchor_text": "ALEplot"}, {"url": "https://github.com/blent-ai/ALEPython", "anchor_text": "version"}, {"url": "https://altair-viz.github.io", "anchor_text": "Atair"}, {"url": "https://www.streamlit.io", "anchor_text": "Streamlit"}, {"url": "https://dev.to/hannahyan/getting-started-in-building-and-deploying-interactive-data-science-apps-with-streamlit-6ab", "anchor_text": "here"}, {"url": "https://dev.to/hannahyan/getting-started-in-deploying-interactive-data-science-apps-with-streamlit-part-2-3ob", "anchor_text": "here"}, {"url": "https://www.kaggle.com/learn/machine-learning-explainability", "anchor_text": "Machine learning interpretability"}, {"url": "https://www.oreilly.com/radar/ideas-on-interpreting-machine-learning/", "anchor_text": "Ideas on Interpreting Machine Learning"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable ML book"}, {"url": "https://www.h2o.ai/wp-content/uploads/2019/08/An-Introduction-to-Machine-Learning-Interpretability-Second-Edition.pdf", "anchor_text": "An introduction to Machine learning interpretability"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7b0f9a2d8e9f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7b0f9a2d8e9f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/web-development?source=post_page-----7b0f9a2d8e9f---------------web_development-----------------", "anchor_text": "Web Development"}, {"url": "https://medium.com/tag/python?source=post_page-----7b0f9a2d8e9f---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/technology?source=post_page-----7b0f9a2d8e9f---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&user=Hannah+Yan+Han&userId=5b4607fd1f47&source=-----7b0f9a2d8e9f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&user=Hannah+Yan+Han&userId=5b4607fd1f47&source=-----7b0f9a2d8e9f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7b0f9a2d8e9f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7b0f9a2d8e9f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7b0f9a2d8e9f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yanhann10?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yanhann10?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hannah Yan Han"}, {"url": "https://medium.com/@yanhann10/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.5K Followers"}, {"url": "https://www.hannahyan.com/", "anchor_text": "https://www.hannahyan.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b4607fd1f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&user=Hannah+Yan+Han&userId=5b4607fd1f47&source=post_page-5b4607fd1f47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff07dfdcc42a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-the-machine-learning-blackbox-with-ml-interpreter-7b0f9a2d8e9f&newsletterV3=5b4607fd1f47&newsletterV3Id=f07dfdcc42a4&user=Hannah+Yan+Han&userId=5b4607fd1f47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}