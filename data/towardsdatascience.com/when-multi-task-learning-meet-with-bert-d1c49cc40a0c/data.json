{"url": "https://towardsdatascience.com/when-multi-task-learning-meet-with-bert-d1c49cc40a0c", "time": 1682995235.519938, "path": "towardsdatascience.com/when-multi-task-learning-meet-with-bert-d1c49cc40a0c/", "webpage": {"metadata": {"title": "When Multi-Task Learning meet with BERT | by Edward Ma | Towards Data Science", "h1": "When Multi-Task Learning meet with BERT", "description": "BERT (Devlin et al., 2018) got the state-of-the-art result in 2018 in multiple NLP problems. It leveraged transformer architecture to learn contextualized word embeddings such that those vectors\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1901.11504.pdf", "anchor_text": "Multi-Task Deep Neural Networks for Natural Language Understanding", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/learning-generic-sentence-representation-by-various-nlp-tasks-df39ce4e81d7", "anchor_text": "GenSen", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT", "paragraph_index": 9}, {"url": "https://github.com/huggingface/pytorch-pretrained-BERT", "anchor_text": "PyTorch implementation of BERT", "paragraph_index": 10}, {"url": "http://medium.com/@makcedward/", "anchor_text": "Medium Blog", "paragraph_index": 11}, {"url": "https://www.linkedin.com/in/edwardma1026", "anchor_text": "LinkedIn", "paragraph_index": 11}, {"url": "https://github.com/makcedward", "anchor_text": "Github", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "Bidirectional Encoder Representations from Transformers (BERT)", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/learning-generic-sentence-representation-by-various-nlp-tasks-df39ce4e81d7", "anchor_text": "General Purpose Distributed Sentence Representation (GenSen)", "paragraph_index": 13}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "paragraph_index": 14}, {"url": "https://arxiv.org/pdf/1804.00079.pdf", "anchor_text": "Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1901.11504.pdf", "anchor_text": "Multi-Task Deep Neural Networks for Natural Language Understanding", "paragraph_index": 16}, {"url": "https://makcedward.github.io/", "anchor_text": "https://makcedward.github.io/", "paragraph_index": 17}], "all_paragraphs": ["BERT (Devlin et al., 2018) got the state-of-the-art result in 2018 in multiple NLP problems. It leveraged transformer architecture to learn contextualized word embeddings such that those vectors represent a better meaning in different domain problems. To extend the usage of BERT, Liu et al. proposed Multi-Task Deep Neural Networks (MT-DNN) to achieve the state-of-the-art result in multiple NLP problems. BERT helped to build a shared text representation in MT-DNN while the fine-tuning part is leveraging multi-task learning.", "This story will discuss about Multi-Task Deep Neural Networks for Natural Language Understanding (Liu et al., 2019) and the following are will be covered:", "Multi-task learning is one of the transfer learning. When learning knowledge from multiple things, we do not need to learn everything from scratch but we can apply knowledge learned from other tasks to shorten the learning curve.", "Taking ski and snowboard as an example, you do not need to spends lots of time to learn snowboard if you already master ski. It is because both sports shares some skill and you just need to understand the different part is ok. Recently, I heard from friends that he was master in snowboard. He only spent 1 months to master ski.", "Go back to data science, researchers and scientists believe that transfer learning can be applied when learning text representation. GenSen (Sandeep et al., 2018) demonstrated multi-task learning improved the sentence embeddings. Part of text representation can be learned from different tasks and those shared parameters can be propagate back to learn a better weights.", "Input is a word sequence which can be a single sentence or combing two sentence into together with a separator. Same as BERT, sentence(s) will be tokenize and transforming to initial word embeddings, segment embeddings and position embeddings. After that multi bidirectional transformer will be used to learn the contextual word embeddings. The different part is leveraging multi-task to learn text representation and applying it to individual task in fine-tuning stage.", "MT-DNN has to go though two stages to train the model. First stage includes pre-training of Lexicon Encoder and Transformer Encoder. By following BERT, both encoders are trained by masked language modeling and next sentence prediction. Second stage is fine-tuning part. mini batch base stochastic gradient descent (SGD) is applied.", "Different from single task learning, MT-DNN will compute the loss across different task and applying the change to the model in the same time.", "The loss is difference across different task. For classification task, it is binary classification problem so crossentropy loss is used. For text similarity task, mean square error is used. For ranking task, negative log likelihood is used.", "From below architecture figure, the shared layers are transferring text to contextual embedding via BERT. After the shared layers, It will go though different sub-flow per to learn representation per specific task. The task specific layers are trained for specific task problems such as single sentence classification and pairwise text similarity.", "MT-DNN is based on PyTorch implementation of BERT and the hyperparametes are:", "I am Data Scientist in Bay Area. Focusing on state-of-the-art in Data Science, Artificial Intelligence , especially in NLP and platform related. You can reach me from Medium Blog, LinkedIn or Github.", "Bidirectional Encoder Representations from Transformers (BERT)", "General Purpose Distributed Sentence Representation (GenSen)", "Devlin J., Chang M. W., Lee K., Toutanova K., 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "Sandeep S., Adam T., Yoshua B., Christopher J P., Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning. 2018", "Liu X. D., He P. C., Chen W. Z., Gao J. F. 2019. Multi-Task Deep Neural Networks for Natural Language Understanding", "Focus in Natural Language Processing, Data Science Platform Architecture. https://makcedward.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd1c49cc40a0c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@makcedward?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Edward Ma"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba547bff904f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=post_page-ba547bff904f----d1c49cc40a0c---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1c49cc40a0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=-----d1c49cc40a0c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1c49cc40a0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=-----d1c49cc40a0c---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@makcedward?utm_source=medium&utm_medium=referral", "anchor_text": "Edward Ma"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://arxiv.org/pdf/1901.11504.pdf", "anchor_text": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"url": "https://unsplash.com/@makcedward?utm_source=medium&utm_medium=referral", "anchor_text": "Edward Ma"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/learning-generic-sentence-representation-by-various-nlp-tasks-df39ce4e81d7", "anchor_text": "GenSen"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "https://github.com/huggingface/pytorch-pretrained-BERT", "anchor_text": "PyTorch implementation of BERT"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "BERT"}, {"url": "http://medium.com/@makcedward/", "anchor_text": "Medium Blog"}, {"url": "https://www.linkedin.com/in/edwardma1026", "anchor_text": "LinkedIn"}, {"url": "https://github.com/makcedward", "anchor_text": "Github"}, {"url": "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb", "anchor_text": "Bidirectional Encoder Representations from Transformers (BERT)"}, {"url": "https://towardsdatascience.com/learning-generic-sentence-representation-by-various-nlp-tasks-df39ce4e81d7", "anchor_text": "General Purpose Distributed Sentence Representation (GenSen)"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"}, {"url": "https://arxiv.org/pdf/1804.00079.pdf", "anchor_text": "Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning"}, {"url": "https://arxiv.org/pdf/1901.11504.pdf", "anchor_text": "Multi-Task Deep Neural Networks for Natural Language Understanding"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d1c49cc40a0c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d1c49cc40a0c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d1c49cc40a0c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----d1c49cc40a0c---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1c49cc40a0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=-----d1c49cc40a0c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1c49cc40a0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=-----d1c49cc40a0c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1c49cc40a0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba547bff904f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=post_page-ba547bff904f----d1c49cc40a0c---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fde3db5912a7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&newsletterV3=ba547bff904f&newsletterV3Id=de3db5912a7c&user=Edward+Ma&userId=ba547bff904f&source=-----d1c49cc40a0c---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Written by Edward Ma"}, {"url": "https://medium.com/@makcedward/followers?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "3.3K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://makcedward.github.io/", "anchor_text": "https://makcedward.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fba547bff904f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&user=Edward+Ma&userId=ba547bff904f&source=post_page-ba547bff904f----d1c49cc40a0c---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fde3db5912a7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-multi-task-learning-meet-with-bert-d1c49cc40a0c&newsletterV3=ba547bff904f&newsletterV3Id=de3db5912a7c&user=Edward+Ma&userId=ba547bff904f&source=-----d1c49cc40a0c---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Edward Ma"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Data Augmentation in NLPIntroduction to Text Augmentation"}, {"url": "https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "5 min read\u00b7Apr 12, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2801a34dfc28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-augmentation-in-nlp-2801a34dfc28&user=Edward+Ma&userId=ba547bff904f&source=-----2801a34dfc28----0-----------------clap_footer----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28?source=author_recirc-----d1c49cc40a0c----0---------------------5371e757_df47_40b9_a743_da5e31178197-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2801a34dfc28&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-augmentation-in-nlp-2801a34dfc28&source=-----d1c49cc40a0c----0-----------------bookmark_preview----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d1c49cc40a0c----1---------------------5371e757_df47_40b9_a743_da5e31178197-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d1c49cc40a0c----1-----------------bookmark_preview----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d1c49cc40a0c----2---------------------5371e757_df47_40b9_a743_da5e31178197-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d1c49cc40a0c----2-----------------bookmark_preview----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Edward Ma"}, {"url": "https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "Data Augmentation for AudioData Augmentation"}, {"url": "https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": "3 min read\u00b7Jun 1, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F76912b01fdf6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40makcedward%2Fdata-augmentation-for-audio-76912b01fdf6&user=Edward+Ma&userId=ba547bff904f&source=-----76912b01fdf6----3-----------------clap_footer----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6?source=author_recirc-----d1c49cc40a0c----3---------------------5371e757_df47_40b9_a743_da5e31178197-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F76912b01fdf6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40makcedward%2Fdata-augmentation-for-audio-76912b01fdf6&source=-----d1c49cc40a0c----3-----------------bookmark_preview----5371e757_df47_40b9_a743_da5e31178197-------", "anchor_text": ""}, {"url": "https://medium.com/@makcedward?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "See all from Edward Ma"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Skanda Vivek"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Fine-Tune Transformer Models For Question Answering On Custom DataA tutorial on fine-tuning the Hugging Face RoBERTa QA Model on custom data and obtaining significant performance boosts"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b75 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&user=Skanda+Vivek&userId=220d9bbb8014&source=-----513eaac37a80----0-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&source=-----d1c49cc40a0c----0-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "The Ultimate Guide to Evaluating Your Recommendation SystemUnderstand the key metrics to measure the performance of your recommender engine"}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b720 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2Fd4fc8d4423cc&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fthe-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----d4fc8d4423cc----1-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd4fc8d4423cc&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fthe-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc&source=-----d1c49cc40a0c----1-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Ruben Winastwan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Interpreting the Prediction of BERT Model for Text ClassificationHow to Use Integrated Gradients to Interpret BERT Model\u2019s Prediction"}, {"url": "https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b713 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5ab09f8ef074&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----5ab09f8ef074----0-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074?source=read_next_recirc-----d1c49cc40a0c----0---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5ab09f8ef074&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074&source=-----d1c49cc40a0c----0-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Imbalanced Multi-Label Classification: Balanced Weights May Not Improve Your Model PerformanceCompare the random forest model and logistic regression model with and without balanced weights on imbalanced multi-class classification"}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b711 min read\u00b7Feb 1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2Fcf71c6df030c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fimbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----cf71c6df030c----1-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/imbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c?source=read_next_recirc-----d1c49cc40a0c----1---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcf71c6df030c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fimbalanced-multi-label-classification-balanced-weights-may-not-improve-your-model-performance-cf71c6df030c&source=-----d1c49cc40a0c----1-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----2-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d1c49cc40a0c----2---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----d1c49cc40a0c----2-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Andrea D'Agostino"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "How to Train a Word2Vec Model from Scratch with GensimIn this article we will explore Gensim, a very popular Python library for training text-based machine learning models, to train a Word2Vec\u2026"}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": "\u00b79 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&user=Andrea+D%27Agostino&userId=4e8f67b0b09b&source=-----c457d587e031----3-----------------clap_footer----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031?source=read_next_recirc-----d1c49cc40a0c----3---------------------53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc457d587e031&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-train-a-word2vec-model-from-scratch-with-gensim-c457d587e031&source=-----d1c49cc40a0c----3-----------------bookmark_preview----53d3aecf_fb2f_435e_a318_9d6c7c5e766e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d1c49cc40a0c--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}