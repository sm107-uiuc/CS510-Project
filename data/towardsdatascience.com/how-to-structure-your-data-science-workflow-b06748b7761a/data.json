{"url": "https://towardsdatascience.com/how-to-structure-your-data-science-workflow-b06748b7761a", "time": 1683017104.8883772, "path": "towardsdatascience.com/how-to-structure-your-data-science-workflow-b06748b7761a/", "webpage": {"metadata": {"title": "How to Structure Your Data Science Workflow | by Mikhail Klassen | Towards Data Science", "h1": "How to Structure Your Data Science Workflow", "description": "From the outside, data science can appear to be a huge and nebulous discipline. Today\u2019s data science experts did not attend university to get data science degrees (although many universities now\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com", "anchor_text": "Kaggle", "paragraph_index": 4}, {"url": "https://www.kaggle.com/c/titanic/overview", "anchor_text": "Titanic: Machine Learning from Disaster", "paragraph_index": 6}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter notebook", "paragraph_index": 15}, {"url": "https://www.kaggle.com/c/titanic/notebooks", "anchor_text": "create a data science notebook", "paragraph_index": 16}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "challenge website", "paragraph_index": 20}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn", "paragraph_index": 24}, {"url": "https://www.dummies.com/education/history/titanic-facts-the-layout-of-the-ship/", "anchor_text": "here", "paragraph_index": 54}, {"url": "https://www.dummies.com/education/history/titanic-facts-the-layout-of-the-ship/", "anchor_text": "deck layout", "paragraph_index": 58}, {"url": "https://www.kaggle.com/c/titanic/discussion/11127", "anchor_text": "discussion about this topic", "paragraph_index": 63}, {"url": "https://anaconda.org/conda-forge/xgboost", "anchor_text": "install it", "paragraph_index": 87}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)", "anchor_text": "Cross-validation", "paragraph_index": 89}, {"url": "https://xgboost.ai/", "anchor_text": "XGBoost", "paragraph_index": 91}, {"url": "https://github.com/EpistasisLab/tpot", "anchor_text": "TPOT", "paragraph_index": 99}, {"url": "https://mikhailklassen.medium.com/membership", "anchor_text": "my link", "paragraph_index": 107}], "all_paragraphs": ["From the outside, data science can appear to be a huge and nebulous discipline. Today\u2019s data science experts did not attend university to get data science degrees (although many universities now offer these programs).", "The first generation of professional data scientists are drawn from the disciplines of mathematics, statistics, computer science, and physics.", "The \u201cscience\u201d part of data science is the classic work of posing a question, generating hypotheses, examining the evidence, and formulating a model that explains the evidence.", "These are skills that anyone can learn, and there are more resources than ever to get started.", "One of the best resources is Kaggle. Their data science competitions are a chance for anyone to get their feet wet with a real project. The community that has formed around these challenges is also a great place to learn from others.", "When I transitioned from physicist to data scientist, Kaggle was one of the resources I used when teaching myself new skills, especially the use of machine learning libraries like scikit-learn.", "In this article, I\u2019ll be using the classic challenge \u201cTitanic: Machine Learning from Disaster\u201d to explain how to approach any data science problem and find a winning solution.", "The aim of this challenge is to build a model that can predict the survival of a passenger, based on information known about them from the passenger manifest. This is based on historical data, and we know things like the names, age, gender, ticket class, and family information for many of the passengers \u2014 and whether they survived the disaster or not.", "Kaggle provides training data and test data. The training data has the \u201cground truth\u201d label of survival (yes/no), but the test data does not include the ground truth label. Kaggle retains those labels and uses them to score your submission. The test-data predictions are up to you to predict, and the accuracy of your predictions are used to determine your place on the leaderboard.", "A side note about the Titanic challenge: if you look at the leaderboard, you\u2019ll see a lot of perfect scores. This naturally leads you to wonder, \u201chow did they do that?\u201d", "The answer is disheartening \u2014 they cheated. If you google around for a while, you\u2019ll discover that the full test data with ground truth labels is available on the internet. Those with perfect scores simply submit the true labels instead of the predictions of a machine learning model\u2026 and receive a perfect score.", "But they have failed the true test \u2014 these challenges exist for mastering a craft, not stealing a high score.", "Before starting your data science project, I recommend setting up your work environment thus:", "For the virtual environment, I recommend using conda to manage your Python environment. My preferred data science libraries are numpy, pandas, matplotlib, seaborn, and scikit-learn. Depending on the nature of the problem, other libraries (like scipy) may be relevant. Deep learning challenges will involve installing either Tensorflow or PyTorch.", "For this data science exercise, we won\u2019t need any deep learning tools, but if you\u2019re curious, I wrote up a guide on setting up a deep learning data science environment in PyTorch.", "Finally, let\u2019s load the data. Assuming you have downloaded the data for the challenge from Kaggle onto your own machine into a subfolder called data and you are writing code inside a Jupyter notebook.", "Alternatively, you can create a data science notebook directly on Kaggle\u2019s platform.", "It\u2019s important not to skip this first step.", "Whenever you work with new data, it\u2019s important to understand what the data contains, what the variables mean, what units and data types are being used, and what the distributions look like.", "This will help you develop an intuition for the data and make it easier to generate hypotheses, which hopefully also makes the solution easier to find.", "The challenge website explains the data well, with a table explaining each variable:", "Most of these are self-explanatory, but sibsp and parch warrant a bit more information:", "sibsp: The dataset defines family relations in this way\u2026Sibling = brother, sister, stepbrother, stepsisterSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)", "parch: The dataset defines family relations in this way\u2026Parent = mother, fatherChild = daughter, son, stepdaughter, stepsonSome children travelled only with a nanny, therefore parch=0 for them.", "The seaborn Python library excels at visualizing distributions, so in this section, I\u2019m going to inspect the data in a few different ways.", "I\u2019m interested to know whether our assumptions about the survival rate of women and children hold up, so I created the following plot.", "Our assumptions hold up fairly well, but it\u2019s notable that quite a few children did not survive, and quite a few men of all ages did indeed survive. Could their survival be related to something else?", "Perhaps the passenger class is predictive of survival. Let\u2019s take a look at the data again, but this time splitting out by class.", "We see a few things here. Of the adult men that survived, a higher fraction of 1st-class passengers survived. There were adult male survivors among 2nd and 3rd class passengers as well, but not as many relative the number of the passengers in each group.", "Of the women that did not survive, most of them were 3rd-class passengers.", "This tells us that sex, age, and passenger class are all likely to be predictive of survival, but that there are outliers in each group. It\u2019s not clear whether this is random, or due to more subtle factors.", "Finally, let\u2019s take a quick look at where these passengers boarded. Perhaps that might tell us something.", "The letters S, C, and Q stand for Southampton, Cherbourg, and Queenstown. The majority of passengers embarked at Southampton. Passengers embarking at Cherbourg appear to have a slightly better chance of survival from among their cohort, but there does not appear to be a strong correlation between port and survival.", "With these insights, we are already starting to formulate hypotheses about the data, which we\u2019ll test later. Without visualizing the data, we wouldn\u2019t have these same intuitions.", "Even under the best of circumstances, data is rarely \u201cclean\u201d, meaning that there could be missing values or mistakes in the data. Other times, data will be recorded in units that need to be converted, filtered, or otherwise processed before any further work can be done.", "There is no single way to do data cleaning. It will depend on your data:", "If we look closely at our Titanic data, we can find a few problems:", "Here I\u2019m using pandas to check for null values with the .isna() method. Missing data or null values produce a \u201cNA\u201d code. If numerical data is expected, it produces a \u201cNaN\u201d, meaning \u201cNot a Number\u201d.", "The Titanic data has a lot of missing values in it. Sometimes we don\u2019t know a person\u2019s age, or what cabin they occupied (if any), or what their port of embarkation was.", "This leaves us with a few options:", "Each approach has its merits. In the first case, we make no assumptions about the data, and just choose to get rid of any incomplete rows in our table. The advantage is we\u2019re not biasing our future model with our assumption, but at the cost of fewer training examples.", "When training a machine learning model, more data is always better. If you have a lot of clean data, it may be fine to throw away any incomplete samples. But if every row in your table is precious, it\u2019s better to find values to plug the holes.", "The Titanic data set isn\u2019t very large. We have less than 1000 passengers in our training set. And we may need to further subdivide our training data to validate our models, so that leaves us with even fewer training examples.", "Machine learning models need numerical data, but a lot of the Titanic data is categorical. We need to convert this data somehow to numbers.", "The Sex column has only two values, female and male. We can remap these to 0 and 1.", "Dealing with categorical data that has more than 2 possibilities, e.g. the port of embarkation (which has 3 possible values), is covered below using a technique called \u201cone-hot encoding\u201d.", "With a few reasonable assumptions, we can actually fill the holes in our data pretty well.", "There are several strategies we could employ here, such as simply imputing the average age of all passengers to the missing values.", "My strategy was to look at the average age of passengers in each ticket class.", "I was not surprised to discover that first-class passengers tended to be older, and that there was a downward gradient in age as you went into second and then third class.", "For all the missing age values, I assigned them the median value based on their passenger class.", "You could improve this technique even further by looking at the median age for women and men within each class, and then filling in missing data based on those two variables.", "There aren\u2019t many missing values here, which is encouraging. The most common port of embarkation was Southhampton, so all else being equal, it\u2019s most likely that a passenger would have boarded there. This was true for passengers of all classes.", "Many of the rows in our table contain a cabin number. It was initially unclear how to make use of this information, but we can determine the ship deck from the cabin number. For example, \u201cC22\u201d is on Deck C.", "Passenger cabins are mostly on Decks B through F. Some information about ship layout can be found here. That same page also indicates where the 1st-, 2nd-, and 3rd-class cabins can be found.", "For passengers with a known cabin number, I used it to infer the deck.", "For passengers without a cabin number, I used their fare class to infer the most likely deck they occupied.", "I created a new column in my data frame called \u201cDeck\u201d and wrote all the inferred deck information there. The \u201cCabin\u201d column can now be deleted.", "My strategy here was to look at the deck layout and see where most of the 1st, 2nd, and 3rd class cabins were. It appeared to be decks C, E, and F, respectively, though I may be wrong.", "For all the passengers with an unknown deck, I assigned them to a deck based on their passenger class.", "I spent a good amount of time investigating what information could be gleaned from the values in the ticket column.", "You\u2019ll notice that some tickets have a prefix, like \u201cS.C./PARIS\u201d, followed by a number. Both the prefix and number could tell us something. My guess is that the prefix indicates the ticket vendor. From the ticket number itself we can sometimes infer groups of people traveling together.", "I did a bunch of deep cleaning and disambiguation on the prefix data, but in the end, I dropped it, since it didn\u2019t seem to be leading to anywhere. Please comment if you found a way to use this information to improve your models.", "There\u2019s a good discussion about this topic on the Kaggle forum.", "Now that we\u2019ve cleaned our data, we could try out a few simple tests. Let\u2019s split off some of our own test data that we can use to test our hypotheses. For this split-off test data, we know the ground truth labels, so we can measure the accuracy of our predictions.", "We know that survivors of the Titanic fled on lifeboats, and these (we assume) would be filled preferentially with women and children. How accurately can we predict survival from just these two variables?", "We\u2019ll use logistic regression to test it:", "78% accuracy is pretty good! Clearly these two variables are highly predictive, as expected.", "Next, we may assume that first class passenger, because of their status or proximity of their cabins to the upper decks, could have more likely been among the survivors, so let\u2019s see if class alone is a good predictor. Then we\u2019ll see if combining it with age and sex improves the previous result.", "I had to do some one-hot encoding of the Pclass variable. I explain what one-hot encoding is below and why it\u2019s important. From these tests, I get the results:", "So using the passenger class as the only predictor, our logistic classifier gets almost 70% accuracy. Combining with age and sex, we improve slightly on the previous result: 79% vs 78%. This difference isn\u2019t great and could be noise.", "What these first few experiments are telling us is that survival will depend in large part on age, sex, and socio-economic status. These three factors alone could probably get us a reasonably good prediction of survival.", "But to eke out those last few percentage points of accuracy, it\u2019s going to take some feature engineering.", "Really good feature engineering is what often distinguishes the experts from the novice data scientists. Anyone can take an off-the-shelf software library, train a machine learning model in a few lines of Python, and use it make predictions. But data science is about more than just model selection. You need to give that model high-quality predictive features to work with.", "Feature engineering typically means creating new features to help your machine learning model make better predictions. There are tools for automating this process, but it\u2019s better to first think deeply about the data and what other factors may be responsible for the target outcome.", "In our Titanic example, we have some information families traveling together. The columns \u201csibsp\u201d and \u201cparch\u201d tell us about the numbers of siblings, spouses, parents, and children that a passenger has. We could create a new variable called \u201cFamily Size\u201d that is the sum of \u201csibsp\u201d and \u201cparch\u201d.", "Many Kagglers will also create a variable called \u201cnot_alone\u201d, which is just a binary identifier describing whether a passenger is traveling by themselves.", "This particular data set contains a lot of categorical data. Consider the port of embarkation. There are 3 possible values: Cherbourg, Queenstown, and Southampton. ML models need numerical data, so we could map the port to a number:", "But think about how that looks to a machine learning model. Is Southampton 3x greater in value than Cherbourg? No, that\u2019s absurd. Each port matters equally.", "We instead perform a \u201cone-hot encoding\u201d of this categorical data, which will create three new columns, one for each port, and we will use the number 0 or 1 to indicate whether the passenger embarked at a particular port or not.", "We can do the same for other categorical variables, such as deck. Sex is a categorical variable in our data set, but since the only values in our data set are \u201cfemale\u201d and \u201cmale\u201d, we just use 0/1 to indicate. No need to create new columns.", "One major disadvantage of one-hot encoding is that it can create many new columns. Each column is considered a separate feature. More features aren\u2019t always a good thing. You want the number of examples in your data to greatly exceed the number of features. This can help to prevent overfitting.", "Some Kagglers find that creating separate \u201cbins\u201d for age or fare ranges is helpful. Consider that when filling life boats, the crew are probably not asking for age, but considering age categories such as \u201cinfant\u201d, \u201cchild\u201d, \u201cyoung\u201d, \u201cold\u201d. You can create similar bins and see if this helps your model. I\u2019m going to leave the age and fare variables as they are.", "The above steps are actually the hardest part and represents about 80% to 90% of the work.", "The next few steps are usually easier and more fun. We can play around with different machine learning models to see how well they perform, and pick a promising one for further optimization.", "Since we are simply trying to predict a binary variable, \u201csurvival\u201d, any binary classifier will work. If you\u2019re using scikit-learn, you have many choices.", "Some of the most popular classifiers are:", "That last one, XGBoost, isn\u2019t part of scikit-learn, so you\u2019ll have to install it separately.", "Let\u2019s take our training data, select a classifier, and test it using k-fold cross-validation.", "Cross-validation is a technique whereby a small portion of the data is left out, while the model is trained on the remaining data. The accuracy of the model is then tested against the left-out data. This process is repeated k times, where the portion of left-out data is drawn randomly each time.", "The point of this technique is to help avoid overfitting. In your zeal to engineer the perfect model with the highest accuracy, you may accidentally create a model that doesn\u2019t generalize to data outside of your sample. So you always need to be testing your models against data outside of your sample.", "Of the classifiers mentioned above, logistic regression and decision trees are the easiest to understand. Random forests are ensemble models constructed from many decision trees. They tend to do well out of the box. AdaBoost and XGBoost are newer, more advanced models. XGBoost is very popular with Kagglers.", "I won\u2019t cover the mechanics of each classifier in this article, but that information is pretty easy to find.", "My assess_model function uses 5-fold cross-validation to test the accuracy of each classifier on both the training set and the test set. The true worth of a model is always how well it performs on the test set. The accuracy of each one:", "It\u2019s important to note that we\u2019ve used the \u201cout-of-the-box\u201d version of each of these classifiers. These use default values for all of their internal tunable parameters.", "Notice how a classifier sometimes gets ~97% accuracy on the training set. That looks amazing, but it\u2019s overfitting. The test accuracy is lower and it\u2019s the variable we care more about.", "Of these classifiers, XGBoost has the highest test accuracy. This is one of the reasons why Kaggler\u2019s love XGBoost \u2014 great performance with zero tuning.", "Most machine learning models have tunable parameters that often influence model accuracy. The best-performing values for these parameters is different for every problem.", "In ML, these parameters are often referred to as \u201chyperparameters\u201d and tuning them is as much art as science.", "There are tools out there to help with tuning. TPOT is one example. But keeping it simple, we\u2019re going to perform a simple grid search and manually test a whole range of plausible hyperparameter values to see which one gives us the best results.", "scikit-learn has a convenient tool for performing grid searches.", "This code takes some time to run, as it tries all the different combinations of hyperparameters.", "You can modify the parameter grid to change the search space. Remember, this technique won\u2019t find the best possible hyperparameter values, only the best combination from within the search space.", "So there you have it. You\u2019d be hard pressed to outperform 83% on the Kaggle Titanic challenge without cheating. I mentioned a few other possible ways of boosting performance, such as age or fare binning, and imputing missing age values based both class and gender. You can try these and see if they boost accuracy.", "In conclusion, approaching a data science problem is stepwise process of starting from a clean slate, getting to know your data, cleaning it, and then iteratively testing different models and adding more features until you achieve good model performance. From there, you optimize your best model to squeeze a little more performance out of it.", "What happens next? Well if you\u2019re a researcher, you publish your results. If you\u2019re an entrepreneur, you operationalize your model to do something useful that others will pay money for. If you\u2019re a Kaggler, you submit your test predictions for a shot at glory (and sometimes money).", "If I missed anything, or you find other techniques for doing even better, let me know in the comments. I hope this has helped you on your data science journey.", "If you enjoy reading stories like these and want to support me as a writer, consider signing up to become a Medium member. It\u2019s $5 a month, which gives you access to all my writing and that of thousands of other writers. If you sign up using my link, I\u2019ll earn a small commission with no extra cost to you.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Entrepreneur, Data Scientist, PhD Astrophysicist, Writer, Mentor"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb06748b7761a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mikhailklassen.medium.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": ""}, {"url": "https://mikhailklassen.medium.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Mikhail Klassen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd9dfda9f9153&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&user=Mikhail+Klassen&userId=d9dfda9f9153&source=post_page-d9dfda9f9153----b06748b7761a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://unsplash.com/@mlenny?utm_source=medium&utm_medium=referral", "anchor_text": "Alexander Hafemann"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/c/titanic/overview", "anchor_text": "Titanic: Machine Learning from Disaster"}, {"url": "https://commons.wikimedia.org/wiki/File:RMS_Titanic_3.jpg", "anchor_text": "Wikimedia Commons"}, {"url": "https://towardsdatascience.com/setting-up-a-new-pytorch-deep-learning-environment-313d8d1c2df0", "anchor_text": "Setting Up a New PyTorch Deep Learning EnvironmentWhether you\u2019re starting on a fresh project, or running on a remote machine, you don\u2019t want to waste time chasing down\u2026towardsdatascience.com"}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter notebook"}, {"url": "https://www.kaggle.com/c/titanic/notebooks", "anchor_text": "create a data science notebook"}, {"url": "https://www.kaggle.com/c/titanic/data", "anchor_text": "challenge website"}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn"}, {"url": "https://en.wikipedia.org/wiki/Stop_word", "anchor_text": "stop words"}, {"url": "https://unsplash.com/@gruu?utm_source=medium&utm_medium=referral", "anchor_text": "Anna Gru"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.dummies.com/education/history/titanic-facts-the-layout-of-the-ship/", "anchor_text": "here"}, {"url": "https://www.dummies.com/education/history/titanic-facts-the-layout-of-the-ship/", "anchor_text": "deck layout"}, {"url": "https://unsplash.com/@purzlbaum?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "\ud83c\udde8\ud83c\udded Claudio Schwarz | @purzlbaum"}, {"url": "https://unsplash.com/s/photos/ticket?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/titanic/discussion/11127", "anchor_text": "discussion about this topic"}, {"url": "https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral", "anchor_text": "Christopher Burns"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@victoriano?utm_source=medium&utm_medium=referral", "anchor_text": "Victoriano Izquierdo"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "Logistic regression"}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_learning", "anchor_text": "Decision tree"}, {"url": "https://en.wikipedia.org/wiki/Random_forest", "anchor_text": "Random forest"}, {"url": "https://en.wikipedia.org/wiki/AdaBoost", "anchor_text": "Adaptive boosting"}, {"url": "https://en.wikipedia.org/wiki/XGBoost", "anchor_text": "XGBoost"}, {"url": "https://anaconda.org/conda-forge/xgboost", "anchor_text": "install it"}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)", "anchor_text": "Cross-validation"}, {"url": "https://xgboost.ai/", "anchor_text": "XGBoost"}, {"url": "https://unsplash.com/@yomex4life?utm_source=medium&utm_medium=referral", "anchor_text": "Yomex Owo"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/EpistasisLab/tpot", "anchor_text": "TPOT"}, {"url": "https://mikhailklassen.medium.com/membership", "anchor_text": "my link"}, {"url": "https://mikhailklassen.medium.com/membership", "anchor_text": "Join Medium with my referral link \u2014 Mikhail KlassenRead every story from Mikhail Klassen (and thousands of other writers on Medium). Your membership fee directly supports\u2026mikhailklassen.medium.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b06748b7761a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b06748b7761a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----b06748b7761a---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----b06748b7761a---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----b06748b7761a---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&user=Mikhail+Klassen&userId=d9dfda9f9153&source=-----b06748b7761a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&user=Mikhail+Klassen&userId=d9dfda9f9153&source=-----b06748b7761a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb06748b7761a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b06748b7761a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b06748b7761a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b06748b7761a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b06748b7761a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b06748b7761a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b06748b7761a--------------------------------", "anchor_text": ""}, {"url": "https://mikhailklassen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mikhailklassen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mikhail Klassen"}, {"url": "https://mikhailklassen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "255 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd9dfda9f9153&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&user=Mikhail+Klassen&userId=d9dfda9f9153&source=post_page-d9dfda9f9153--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2b3390346ce5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-structure-your-data-science-workflow-b06748b7761a&newsletterV3=d9dfda9f9153&newsletterV3Id=2b3390346ce5&user=Mikhail+Klassen&userId=d9dfda9f9153&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.oreilly.com/library/view/mining-the-social/9781491973547/", "anchor_text": "Mining the Social Web: Data Mining Facebook, Twitter, LinkedIn, Instagram, GitHub, and More2019"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}