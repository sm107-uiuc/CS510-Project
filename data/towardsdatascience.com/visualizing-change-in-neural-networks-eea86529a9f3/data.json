{"url": "https://towardsdatascience.com/visualizing-change-in-neural-networks-eea86529a9f3", "time": 1683009582.178556, "path": "towardsdatascience.com/visualizing-change-in-neural-networks-eea86529a9f3/", "webpage": {"metadata": {"title": "Visualizing Change in Neural Networks | by Martin Chobanyan | Towards Data Science", "h1": "Visualizing Change in Neural Networks", "description": "Deep neural networks have captivated the world with their powerful abilities, yet they largely operate as black box models. To help solve this mystery, feature visualization has emerged as a powerful\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/tensorflow/lucid", "anchor_text": "lucid", "paragraph_index": 1}, {"url": "https://github.com/martin-chobanyan/transfer-visualization", "anchor_text": "here on Github", "paragraph_index": 2}, {"url": "http://vision.stanford.edu/aditya86/ImageNetDogs/", "anchor_text": "Stanford Dogs Dataset", "paragraph_index": 5}, {"url": "https://distill.pub/2017/feature-visualization/", "anchor_text": "Distill article", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity", "paragraph_index": 18}, {"url": "https://ai.stanford.edu/~jkrause/cars/car_dataset.html", "anchor_text": "Stanford Cars Dataset", "paragraph_index": 33}], "all_paragraphs": ["Deep neural networks have captivated the world with their powerful abilities, yet they largely operate as black box models. To help solve this mystery, feature visualization has emerged as a powerful tool for looking \u201cunder the hood\u201d of neural networks to visualize what they learn.", "In this article, we will explore how we can visualize what a neural network learns to detect and how these learned artifacts change as we fine-tune the network to perform a new task. In addition, this project provides a pytorch implementation of feature visualization based on the tensorflow lucid library.", "Before we begin, you can find the code for this project here on Github.", "Fine-tuning is a process of adapting a pre-trained neural network to a new task. When fine-tuning, the parameters of the network are initialized with the values learned from the original task. Assuming the tasks are relatively similar, fine-tuning helps the network achieve a higher accuracy on the new task by leveraging the knowledge learned from the original task. This technique is especially useful when the original task has a much larger and richer dataset.", "The architecture used in this project is ResNet-50 [2], a deep convolutional network with fifty layers. For the original task, this network has been trained to classify on ImageNet, a dataset containing millions of images spanning a thousand diverse classes (including animals, plants, vehicles, and objects).", "In this project, we will explore the changes in the pre-trained network\u2019s internal representation of an input image when the network is fine-tuned on the Stanford Dogs Dataset [3]. This dataset contains ~20,000 images of dogs across 120 breeds. With a standard fine-tuning approach and an even train-test split, a classification accuracy score of 80% was achieved on this new dataset.", "Each component in a neural network learns to detect various features within the input image. For example, a particular neuron in a dog classifier may release a large activation (output value) when it encounters snout-like features.", "Feature visualization is a technique of optimizing the input image so that it produces a large activation in a specific component of a pre-trained neural network. Counter to the common deep learning paradigm, this process does not update the parameters of the network. Instead, it freezes the pre-trained network and updates the pixels in the image such that a component of the network is highly activated.", "A general diagram of feature visualization is presented in Figure 2 below. Feature visualization uses gradient ascent to maximize the activation value of the target component in the network. The input image starts off with all pixels randomly initialized. As the algorithm iterates, the image begins to closer resemble the features which the component has learned to detect.", "Also, note how the target component can come from anywhere in the network. In this project specifically, we visualized the mean of each feature map in the last four bottleneck layers of ResNet-50.", "Going back to the example with dog snouts, if feature visualization is applied to the output of that particular neuron, we would expect the resulting image to be the most \u201csnout-looking\u201d input the model can expect. This means that (if the neuron only detects dog snouts) the resulting image would be packed with snouts of various shapes and sizes.", "This technique is useful for getting a glimpse of what different components of the network have learned to detect. Figure 3 below shows feature visualizations from three different channels in the ImageNet pre-trained ResNet-50 model. Note how the features are more complex for the deeper layers in the model. For example in the left image, the only visualized feature appears to be some sort of fur-like texture. On the right, however, we can see entangled representations of dog and snake heads. This suggests that this particular channel in the network has learned to detect dogs and snakes in the input image.", "To learn more about feature visualization and its specific implementation in this project, see this excellent Distill article [5].", "Now that we have discussed the underlying ideas, let\u2019s take a look at how we can visualize the change in a neural network. Recall, there are two networks to consider:", "During fine-tuning, only four components in the architecture were allowed to train (excluding the fully connected layer):", "As such, we will only create feature visualizations for the channels in these four layers. The goal is to compare feature visualizations of matching components across the two networks. For instance, how does the feature visualization of the first channel in layer3-bottleneck5 change between the base network and the dog network? Intuitively, we should expect a lot of the features from the latter network to be more \u201cdog-like\u201d (for example, more fur-like texture).", "A hypothesis going into this analysis is that the feature visualizations will become more and more different as we go deeper into the network. This is based on the observation that deeper layers generally represent more complex features (see Figure 3). Another way to look at this is that the earlier layers in the network represent more basic features which are universal across computer vision tasks (and thus are less likely to be changed during training).", "Comparing the feature visualizations manually would be unwieldy. There are thousands of channels across the target layers. Not to mention, this would insert human bias into the comparisons as one person\u2019s opinion on which images are different is subjective. Instead, we must define a similarity metric between two images.", "When we feed an image through a neural network, the hidden state of the image in each layer is a rich, latent vector representation. If we use this vector representation of the image, we can use cosine similarity to judge how similar two vectors are to one another.", "For each pair of feature visualizations, we feed them individually through the base network and retrieve their hidden vector representations (embeddings) right before the fully-connected layer. We then define the similarity metric between the two visualizations as the cosine similarity of their respective embeddings.", "Before we take a look at the comparisons, it is important to note that a few channels failed to optimize their feature visualizations, resulting in feature-less gray images. Interestingly, this pattern did not occur for any of the feature visualizations in the base network. It is not very clear why these channels failed to optimize. In any case, since those faulty visualizations lack any features to compare, they were discarded (see the Appendix for more details).", "In Figure 5, we can see the top-3 most different and most similar channels in layer3-bottleneck5 between the base network and the dog network. In the most different channels, fur-like texture clearly arises in the feature visualizations of the dog network in channels 667 and 675. Though there is also a noticeable change in channel 963, the new features there are not visually interpretable as \u201cdog-like\u201d. Not surprisingly, there is virtually no detectable change in the top-3 most similar channels as the same patterns are repeated in each image pair.", "Moving on to the next layer in Figure 6, the changes in the top-3 most different feature visualizations are a bit harder to decipher. The visualization for channel 503 in the dog network seems to contain several dog-like features that are scattered across the image, including eyes, noses, and mouths. Channel 1904 is interesting because the visualization almost looks plant-like, which could be a byproduct of the dataset as a lot of the dog images are taken outdoors.", "Also of note, the visualization pairs in the top-3 most similar channels of this layer have more differences among each other than those in the previous layer. Interestingly, they all share an overlaid texture across the images resembling specific symbols/characters (it may help to zoom in for a better view).", "In the next layer in Figure 7, the visualizations in the top-3 most different channels are starting to represent more complete pictures of dogs. For example in channels 700 and 899, the features seem to resemble the heads of pugs and Bernese mountain dogs, respectively. Interestingly, the most-similar channels again contain the texture resembling characters.", "Figure 8 below depicts the top-3 most different and most similar channels in the final layer. Channels 707 and 442 in the top-3 most different channels again showcase more complete dog features, such as heads, in the visualizations.", "In this layer, even channels 1485 and 31 of the top-3 most similar channels showcase dog-like features in their visualizations of the dog network. These channels also contain the particular texture discussed in the examples of the previous two layers. Channel 952 on the other hand does not contain this texture and its pattern remains consistent across its visualizations for the base and dog networks. This may highlight a flaw in our cosine similarity metric, as it ignores the clear changes in the image with respect to the new dog features for channels 1485 and 31. For some reason, the similarity metric pays more attention to their texture than their new content.", "Having visualized the change in features within the target layers, let us now assess the degree of change between the layers. Figure 9 presents the distribution of the cosine similarities within each of the four target layers as boxplots. Aside from the last layer (layer4-bottleneck2), there is a clear downward trend in the cosine similarity distribution as we go deeper into the network. This suggests that on average there are more differences between the feature visualizations of the base network and the dog network for deeper layers (which aligns with our earlier hypothesis).", "It is interesting that the final layer deviates from this pattern and has almost an identical median cosine similarity as the preceding layer. It is more likely that this deviation is a misleading effect of using feature visualization as a means of comparison, rather than a sign that there is less change in the final layer.", "To understand this, let\u2019s take a look at a few more feature visualizations from layer4-bottleneck2 (using just the top-3 extremes may not be a good representation). Figure 10 below shows the changes in feature visualizations from three different channels in this layer. It would appear that the visualizations in this layer are more complex, with a lot of the represented features entangled with one another. In all three examples, we can see that new dog-like features arise in the visualizations from the dog network. However, due to the abundance of other visualized features, these new dog-like features are not as prominent as in the visualizations from the preceding layers.", "Assuming this pattern is common throughout the visualizations in the final layer, this may explain why the average cosine similarity for layer4-bottleneck2 is not lower than that of layer4-bottleneck1. Counter-intuitively, the higher complexity and richness in the feature visualizations in the final layer may \u201cdrown-out\u201d the changes introduced by the new dog-features.", "In this project, we visualized how a neural network\u2019s detected features change as the network is fine-tuned towards a new task. We fine-tuned an ImageNet pre-trained ResNet-50 model to a smaller dataset of dog breed images. As expected, new dog-like features arose in the visualizations in the fine-tuned network, especially in the deeper layers. According to our similarity metric, the final layer in the network broke this pattern, highlighting a potential flaw or difficulty in using feature visualizations to assess change in a network.", "Given this, let\u2019s discuss a few other nuances regarding this project:", "A second fine-tuning task was also performed in this project. As before, the base network was ResNet-50 pre-trained on ImageNet. The second dataset was the Stanford Cars Dataset [4], which contains ~16,000 images of cars across 196 different car models. With a standard fine-tuning approach, a classification accuracy of 70% was achieved on this new dataset.", "This dataset, however, was not included in the discussion due to the lack of interpretability in the changes within the resulting feature visualizations. Though the changes were visible and the boxplot of the similarity distributions followed the pattern in the dog network, the new features were not very \u201ccar-like\u201d. This may be due to a more difficult fine-tuning task (as evident in the resulting accuracy score) or maybe due to a human bias of identifying dog-features better than car-features.", "Since feature visualization is an optimization problem and only one configuration was used for every layer, some of the channels failed to optimize, which resulted in gray images. Figure 11 shows the number of gray images in each layer (there were none in layer3-bottleneck5).", "In order to identify and remove these gray images, a scoring function must be defined. The first step is to create the grayscale version of each image (this can be done using the Pillow python library). Then, the squared error is calculated between the original RGB version of the image and the grayscale version. The gray feature visualizations are very similar to their grayscale versions, resulting in a lower error (Figure 12). In fact, plotting the sorted errors revealed a large spike between the faulty, gray feature visualizations and the normal ones. All that remains is to then remove the feature visualizations which fall to the left of this spike (Figure 13).", "While experimenting with similarity metrics between feature visualizations, a measure was defined based on the Gram matrix. The Gram matrix is introduced in neural style transfer [1] and is a technique which captures the texture information in an image. The Gram matrix distance is then defined as the squared error between the Gram matrices of the first and second image in the comparison.", "The intuition behind this idea is that features within a visualization are often repeated all across the image (with some variations). Comparing texture information between feature visualizations would then make sense because it summarizes local structures within the image without regard to their location.", "Based on visual inspection, however, this metric does not perform as well as cosine similarity. One reason is that the Gram matrix distance varies greatly across different layers in the network, making it difficult to combine them into a single measure.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer at Smile Direct Club (SDC)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Feea86529a9f3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@chobanyan.martin?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chobanyan.martin?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Martin Chobanyan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7331cad90e59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&user=Martin+Chobanyan&userId=7331cad90e59&source=post_page-7331cad90e59----eea86529a9f3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/tensorflow/lucid", "anchor_text": "lucid"}, {"url": "https://github.com/martin-chobanyan/transfer-visualization", "anchor_text": "here on Github"}, {"url": "http://vision.stanford.edu/aditya86/ImageNetDogs/", "anchor_text": "Stanford Dogs Dataset"}, {"url": "https://distill.pub/2017/feature-visualization/", "anchor_text": "Distill article"}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity"}, {"url": "https://ai.stanford.edu/~jkrause/cars/car_dataset.html", "anchor_text": "Stanford Cars Dataset"}, {"url": "https://distill.pub/2017/feature-visualization", "anchor_text": "https://distill.pub/2017/feature-visualization"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----eea86529a9f3---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/model-interpretability?source=post_page-----eea86529a9f3---------------model_interpretability-----------------", "anchor_text": "Model Interpretability"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----eea86529a9f3---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----eea86529a9f3---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----eea86529a9f3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&user=Martin+Chobanyan&userId=7331cad90e59&source=-----eea86529a9f3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&user=Martin+Chobanyan&userId=7331cad90e59&source=-----eea86529a9f3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Feea86529a9f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----eea86529a9f3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----eea86529a9f3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----eea86529a9f3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----eea86529a9f3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chobanyan.martin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chobanyan.martin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Martin Chobanyan"}, {"url": "https://medium.com/@chobanyan.martin/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "28 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7331cad90e59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&user=Martin+Chobanyan&userId=7331cad90e59&source=post_page-7331cad90e59--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F7331cad90e59%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-change-in-neural-networks-eea86529a9f3&user=Martin+Chobanyan&userId=7331cad90e59&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}