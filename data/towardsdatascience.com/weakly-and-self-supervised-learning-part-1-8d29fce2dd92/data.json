{"url": "https://towardsdatascience.com/weakly-and-self-supervised-learning-part-1-8d29fce2dd92", "time": 1683012445.958385, "path": "towardsdatascience.com/weakly-and-self-supervised-learning-part-1-8d29fce2dd92/", "webpage": {"metadata": {"title": "Weakly and Self-supervised Learning \u2014 Part 1 | by Andreas Maier | Towards Data Science", "h1": "Weakly and Self-supervised Learning \u2014 Part 1", "description": "In this tutorial, we present ideas on how to get from image-level annotation to bounding boxes and from boxes to pixel-level."}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning", "paragraph_index": 0}, {"url": "http://autoblog.tf.fau.de/", "anchor_text": "Try it yourself!", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/segmentation-and-object-detection-part-5-4c6f70d25d31", "anchor_text": "Previous Lecture", "paragraph_index": 1}, {"url": "https://youtu.be/Vj_JeSZG1EA", "anchor_text": "Watch this Video", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/weakly-and-self-supervised-learning-part-1-ddfdf8377f1d", "anchor_text": "Next Lecture", "paragraph_index": 1}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here", "paragraph_index": 17}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep", "paragraph_index": 17}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning", "paragraph_index": 17}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture", "paragraph_index": 17}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube", "paragraph_index": 17}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter", "paragraph_index": 17}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook", "paragraph_index": 17}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn", "paragraph_index": 17}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License", "paragraph_index": 17}, {"url": "http://autoblog.tf.fau.de/", "anchor_text": "AutoBlog", "paragraph_index": 17}], "all_paragraphs": ["These are the lecture notes for FAU\u2019s YouTube Lecture \u201cDeep Learning\u201d. This is a full transcript of the lecture video & matching slides. We hope, you enjoy this as much as the videos. Of course, this transcript was created with deep learning techniques largely automatically and only minor manual modifications were performed. Try it yourself! If you spot mistakes, please let us know!", "Previous Lecture / Watch this Video / Top Level / Next Lecture", "Welcome back to deep learning! So, today I want to talk to you about a couple of advanced topics, in particular, looking into sparse annotations. We know that data quality and annotations are extremely costly. In the next couple of videos, we want to talk about some ideas on how to save annotations. The topics will be weakly supervised learning and self-supervised learning.", "Okay. So, let\u2019s look at our slides and see what I have for you. The topic is weakly and self-supervised learning. We start today by looking into limited annotations and some definitions. Later, we will look into self-supervised learning for representation learning. So, what\u2019s the problem with learning with limited annotations? Well so far. we had supervised learning and we\u2019ve seen these impressive results achieved with large amounts of training data and consistent high-quality annotations. Here, you see an example. We had annotations for instance-based segmentation and there we had simply the assumption that all of these annotations are there. We can use them and there may be even publicly available. So, it\u2019s no big deal. But actually, in most cases, this is not true.", "Typically, you have to annotate and annotation is very costly. If you look at image-level class labels, you will spend approximately 20 seconds per sample. So here, you can see for example the image with a dog. There are also ideas where we try to make it faster. For example by instance spotting that you can see here in [11]. If you then go to instance segmentation, you actually have to draw outlines and that\u2019s at least 80 seconds per annotation that you have to spend here. If you go ahead to dense pixel-level annotations, you can easily spend one and a half hours for annotating an image like this one. You can see that in [4].", "Now, the difference between weakly supervised learning and strong supervision, you can see in this graph. Here, you see that if we have image labels, of course, we can classify image labels and train. That would be essentially supervised learning: Training of bounding boxes to predict bounding boxes and training with pixel labels to predict pixel labels. Of course, you could also abstract from pixel-level labels to bounding boxes or from bounding boxes to image labels. That all would be strong supervision. Now, the idea of weakly supervised learning is that you start with image labels and go to bounding boxes, or you start with bounding boxes and try to predict pixel labels.", "So, this is the key idea in weakly supervised learning. You somehow want to use a sparse annotation and then create much more powerful predictors. The key ingredients for weakly supervised learning are that you use priors. You use explicit and implicit priors about shape, size, and contrast. Also, motion can be used, for example, to shift bounding boxes. The class distributions tell us that some classes are much more frequent than others. Also, similarity across images helps. Of course, you can also use hints like image labels, bounding boxes, and image captions as weakly supervised labels. Sparse temporal labels are propagated over time. Scribbles or clicks inside objects are also suitable. Here, are a couple of examples of such sparse annotations for scribbles and clicks.", "There are some general approaches. One from labels to localization would be that you use a pre-trained classification network. Then, for example, you can use tricks like in the lecture on visualization. You produce a qualitative segmentation map. So here, we had this idea of back-propagating the class label into the image domain in order to produce such labels. Now, the problem is that this classifier was never trained for localized decisions. The second problem is good classifiers don\u2019t automatically yield good maps. So, let\u2019s look into another idea. The key idea here is to use a global average pooling. So let\u2019s rethink the fully convolutional networks and what we\u2019ve been doing there.", "You remember that we can replace fully connected layers that have only a fixed input size by M times N convolution. If you do so, we see that if we have some input image and we convolve with a tensor then essentially we get one output. Now, if we have multiple of those tensors then we would essentially get multiple channels. If we now start moving our convolution masks across the image domain, you can see that if we have a larger input image then also our outputs will grow with respect to the output domain. We\u2019ve seen in order to resolve this, we can use global average pooling methods in order to produce the class labels per instance.", "Now, what you can do also as an alternative is that you pool first to the correct size. So let\u2019s say, this is your input then you first pool such that you can apply your classification network. Then, go to the classes in a fully connected layer. So, you essentially switch the order of the fully connected layer and the global average pooling. You global average pool first and then produce the classes. We can use this now in order to generate some labels.", "The idea is that now we look at the penultimate layer and we produce class activation maps. So, you see we have two fully connected layers that are producing the class predictions. We have essentially the input feature maps that we can an upscale to the original image size. Then, we use the weights that are assigned to the outputs of the penultimate layer, scale them accordingly, and then produce a class activation map for every output neuron. You can see that here in the bottom happening and by the way there\u2019s also a generalization of this that is then known as Grad-CAM that you can look at in [12]. So with this, we can produce class activation maps and use that as a label for localization.", "We can also go from bounding boxes to segmentation. The idea here is that we want to replace an expensively annotated, fully supervised training with bounding boxes because they\u2019re less tedious.", "They can be annotated much quicker and of course, this results in a reduced cost. Now, the question is can we use those cheaply annotated labels and weakly supervision in order to produce good segmentations? There is actually a paper out there that looked into this idea.", "You can see that in [6]. The key idea is that you start with the input rectangles. Then, you do one round of training for a convolutional neural network. You can see that the convolutional neural network is somewhat robust to label noise and therefore if you repeat the process and refine the labels over the iterations, you can see that we get better predictions with each round of training and refining the labels. So on the right-hand side, you see the ground truth and how we gradually approach this. Now, actually there\u2019s a problem because the training very quickly degrades. The only way how you can make this actually work is that you use post-processing in the intermediate predictions.", "The idea that they use is that they suppress for example wrong detections. Because you have the bounding boxes, you can be sure that within that bounding box it\u2019s unlikely to have a very different class. Then, you can also essentially remove all the predictions that are outside the bounding box. They are probably not accurate. Furthermore, you can also check if it\u2019s less than a certain percentage of the box area, it\u2019s probably also not an accurate label. In addition, you can use the outside of a conditional random field\u2019s boundaries. We essentially run a kind of traditional segmentation approach to refine the boundary using edge information. You can use that as there\u2019s no information to refine your labels. An additional improvement can be done if you use smaller boxes. On average objects are kind of roundish and therefore the corners and edges contained the least true positives. So, here are some examples of an image, and then you can define regions with unknown labels.", "Here are some results. You can see that if we don\u2019t do any refinement of the labels and just train the network over and over again, then you end up in this red line. In the naive approach over the number of training rounds, you actually are reducing the classification accuracy. So the network degenerates and the labels degenerate. That doesn\u2019t work but if you use the tricks with the refinement of the labels with the boxes and excluding outliers, you can actually see that the two green curves emerge. Over the rounds of iterations, you are actually improving. To be honest, if you just use GrabCut+, then you can see that just a single round of iterations is already better than the multiple reruns of the application. If you combine GrabCut+ with the so-called MCG algorithm \u2014 the Multi-scale Combinatorial Grouping \u2014 you even end up with a better result in just one training round. So, using a heuristic method can also help to improve the labels from bounding boxes to pixel-wise labels. If you look at this, the fully supervised approach is still better. It still makes sense to do the full annotation, but we can already get pretty close in terms of performance if we use one of these weakly supervised approaches. This really depends on your target application. If you\u2019re already ok with let\u2019s say 65% of mean intersection over union then you might be satisfied with the weakly supervised approach. Of course, this is much cheaper than generating the very expensive ground truth annotation.", "So next time, we want to continue talking about our weakly-supervised ideas. In the next lecture, we will actually look not just into 2-D images but we\u2019ll also look into volumes and see some smart ideas on how we can use weak annotations in order to generate volumetric 3-D segmentation algorithms. So thank you very much for listening and see you in the next lecture. Bye-bye!", "If you liked this post, you can find more essays here, more educational material on Machine Learning here, or have a look at our Deep LearningLecture. I would also appreciate a follow on YouTube, Twitter, Facebook, or LinkedIn in case you want to be informed about more essays, videos, and research in the future. This article is released under the Creative Commons 4.0 Attribution License and can be reprinted and modified if referenced. If you are interested in generating transcripts from video lectures try AutoBlog.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I do research in Machine Learning. My positions include being Prof @FAU_Germany, President @DataDonors, and Board Member for Science & Technology @TimeMachineEU"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8d29fce2dd92&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://akmaier.medium.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Andreas Maier"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee----8d29fce2dd92---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/fau-lecture-notes", "anchor_text": "FAU LECTURE NOTES"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning"}, {"url": "http://autoblog.tf.fau.de/", "anchor_text": "Try it yourself!"}, {"url": "https://towardsdatascience.com/segmentation-and-object-detection-part-5-4c6f70d25d31", "anchor_text": "Previous Lecture"}, {"url": "https://youtu.be/Vj_JeSZG1EA", "anchor_text": "Watch this Video"}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level"}, {"url": "https://towardsdatascience.com/weakly-and-self-supervised-learning-part-1-ddfdf8377f1d", "anchor_text": "Next Lecture"}, {"url": "https://github.com/vvo/gifify", "anchor_text": "gifify"}, {"url": "https://youtu.be/CX1hEOV9tlo", "anchor_text": "YouTube"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://github.com/vvo/gifify", "anchor_text": "gifify"}, {"url": "https://youtu.be/CX1hEOV9tlo", "anchor_text": "YouTube"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://github.com/vvo/gifify", "anchor_text": "gifify"}, {"url": "https://youtu.be/CX1hEOV9tlo", "anchor_text": "YouTube"}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here"}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture"}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube"}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter"}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook"}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn"}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License"}, {"url": "http://autoblog.tf.fau.de/", "anchor_text": "AutoBlog"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8d29fce2dd92---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8d29fce2dd92---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8d29fce2dd92---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8d29fce2dd92---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/fau-lecture-notes?source=post_page-----8d29fce2dd92---------------fau_lecture_notes-----------------", "anchor_text": "Fau Lecture Notes"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&user=Andreas+Maier&userId=b1444918afee&source=-----8d29fce2dd92---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&user=Andreas+Maier&userId=b1444918afee&source=-----8d29fce2dd92---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8d29fce2dd92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8d29fce2dd92---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8d29fce2dd92--------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andreas Maier"}, {"url": "https://akmaier.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa5f0dee142a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweakly-and-self-supervised-learning-part-1-8d29fce2dd92&newsletterV3=b1444918afee&newsletterV3Id=a5f0dee142a2&user=Andreas+Maier&userId=b1444918afee&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}