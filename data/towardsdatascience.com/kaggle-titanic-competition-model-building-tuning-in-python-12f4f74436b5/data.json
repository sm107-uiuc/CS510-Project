{"url": "https://towardsdatascience.com/kaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5", "time": 1683009825.021926, "path": "towardsdatascience.com/kaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5/", "webpage": {"metadata": {"title": "Kaggle Titanic Competition: Model Building & Tuning in Python | by Do Lee | Towards Data Science", "h1": "Kaggle Titanic Competition: Model Building & Tuning in Python", "description": "I conducted my initial exploratory analysis and feature engineering in SQL. In my previous article, I demonstrated how powerful SQL can be in exploring data in relational databases. For more context\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@dolee_12121/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://medium.com/@dolee_12121/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQL", "paragraph_index": 2}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html", "anchor_text": "corr function", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient", "anchor_text": "Spearman\u2019s rank-order correlation", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V", "anchor_text": "Cramer\u2019s V", "paragraph_index": 6}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "non-linear models", "paragraph_index": 9}, {"url": "https://link.springer.com/article/10.1186/1471-2105-8-25", "anchor_text": "read", "paragraph_index": 20}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "this", "paragraph_index": 20}, {"url": "https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined", "anchor_text": "this", "paragraph_index": 20}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "website", "paragraph_index": 23}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "cikit-Learn\u2019s website", "paragraph_index": 25}, {"url": "https://blog.datadive.net/selecting-good-features-part-iii-random-forests/#:~:text=Random%20forest%20feature%20importance,impurity%20and%20mean%20decrease%20accuracy.", "anchor_text": "randomness", "paragraph_index": 33}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html", "anchor_text": "page", "paragraph_index": 38}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "page", "paragraph_index": 42}, {"url": "https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py", "anchor_text": "incrementality", "paragraph_index": 44}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "page", "paragraph_index": 45}, {"url": "https://towardsdatascience.com/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQL", "paragraph_index": 50}], "all_paragraphs": ["I conducted my initial exploratory analysis and feature engineering in SQL. In my previous article, I demonstrated how powerful SQL can be in exploring data in relational databases. For more context, it might be worthwhile checking it out before reading this article, although it\u2019s not required. You can find the article here!", "I\u2018ll be using the train/test datasets prepared earlier in the \u201cKaggle Titanic Competition in SQL\u201d article to predict passenger survival.", "Using Pandas, I imported the CSV files as data frames. The resultset of train_df.info() should look familiar if you read my \u201cKaggle Titanic Competition in SQL\u201d article. For model training, I started with 15 features, as shown below, excluding Survived and PassengerId.", "As a first step, I created a pairwise correlation matrix using the corr function built into Pandas and Seaborn to visualize the data. It calculates the Pearson correlation coefficients (linear relationships) as the default method. I also used Spearman and Kendall methods, which are both available in pandas.DataFrame.corr.", "All the results looked similar across the board. Relatively speaking, Spearman\u2019s rank-order correlation method, which measures monotonic relationships, might be the best here without diving deep into the concept of correlation and association for different types of features. One caveat is that Spearman will treat nominal features as ordinal features.", "Just as a side note, at this point, all my features have been converted to numerical values composed of binary (dichotomous), ordinal (categorical and ordered), nominal (categorical and not ordered), and continuous features. I wanted to quickly see what features were correlated with each other and the magnitude beyond the obvious ones.", "If I were to dive deeper into the specifics of this exercise, then we also need to talk about associations between categorical features versus correlation among binary and continuous features. In measuring the association between two nominal features, we would have to dive into Cramer\u2019s V or Pearson\u2019s chi-square test. However, in my opinion, this should be a good enough approach to get an initial baseline read. If I missed anything here, feel free to let me know.", "I generated the correlation coefficient heatmap and paid attention to the absolute values in the 0.8 to 1.0 correlation range. These correlation thresholds are arbitrary, and I\u2019ll be looking at various thresholds to determine what works best later on.", "After diving a bit deeper into the numbers using 0.8 as my Pearson correlation threshold, I found these pairs (shown below; output from df_corr) to be highly correlated. Later on, I\u2019ll leverage Spearman with other methods to select important features for my final model.", "Having identified highly correlated pairs, this analysis will help later when dealing with any regression or linear models. High multicollinearity results in features or coefficient estimates becoming sensitive to small changes in the model. This can also impact non-linear models.", "The bottom line is that multicollinear features can create an ineffective model, and understanding feature importance can be skewed. I\u2019m not going to focus my energy on pairs with mild multicollinearity. For now, I\u2019ll keep this on the back burner and address this issue directly when the time comes.", "To start, I trained nine different models by fitting X_train and y_train. To expedite my workflow, I created a function to output model performance and diagnostic metrics to quickly see the numbers and determine what model might work best. These metrics are listed in the function\u2019s docstring.", "Additionally, I defined a pipeline object (line 27 below) containing a scaler and an instance of an estimator. I do not scale the X_train and X_test in few cases when using random forest because it is not necessary to do so.", "The helper function has three parameters. First, it needs a dictionary with the model's name (string) as the key and model class instantiation as the value. Second, it needs the feature training dataset (X_train) and, lastly, the target class data (y_train). Let\u2019s examine the results!", "Immediately, random forest and decision tree stood out from the rest with an accuracy of 98.54%. I know decision tree tends to overfit, so I wasn\u2019t too surprised. On the other hand, random forest is an ensemble of decision trees designed to minimize overfitting by taking a random subset of features and rows to create a forest of decision trees and voting on the prediction outcomes. This random process generates a better model with higher bias and lower variance.", "At a closer look, the accuracy scores using cross-validation with Kfold of 10 generated more realistic scores of 84.07% for random forest and 81.3% for decision tree. Other models that also stood out were KNN, SVM, logistic regression, and linear SVC, with all respectable scores. A high standard deviation is indicative of a model that might not generalize well with new data, so I paid attention to this as well.", "Let\u2019s take a closer look at precision and recall. In this case, it made sense to maximize both precision and recall, and a high F1 score would be indicative of that. Although there is a precision-recall tradeoff, relatively high precision [TP/(TP+FP)] gives me the accuracy of positive predictions. In contrast, relatively high recall [TP/(TP+FN)] gives me % of actual positives correctly detected by the model. Recall is also known as True Positive Rate (TPR) and sensitivity. Also, I wanted a high AUC under the ROC curve. As a result, I narrowed down my list to four models \u2014 random forest, KNN, logistic regression, and linear SVC.", "In the end, I decided on random forest, although other models had slightly better scores. The slight differences seemed negligible in my eyes. The goal is to leverage random forest\u2019s impurity-based feature importance and permutation importance for the feature selection process.", "To quickly output feature importance ranking using random forest, I created a helper function to do this. It outputs a Pandas data frame with feature names with their corresponding feature importance scores in ranked order.", "Going back to the correlation coefficient matrix, there were five pairs flagged as highly correlated or associated with one another. With all the features as defined by X_train and X_test as shown below, I examined the results of RF\u2019s feature and permutation importance. I also used hierarchical clustering and Spearman\u2019s correlation matrix to assist in feature selection.", "RF\u2019s feature importance is a solid start to gauge what features are important but does not always give a definitive view of importance and can be misleading. The underlying mechanism of RF\u2019s feature importance is biased. It tends to overestimate the importance of certain features, such as continuous or high cardinality categorical features. In a nutshell, the decrease in impurity is averaged for each feature in a forest of decision trees, and then the features are ranked based on this averaged value. Here\u2019s a good read on this and this and this!", "Collinear features will be an issue as well. Therefore, utilizing only RF\u2019s mean decrease in impurity-based feature importance won\u2019t show you the whole picture and must be one of many tools to understand feature importance better.", "My concern at this point is collinear features. As a result, I\u2019m leveraging permutation importance and hierarchical clustering to determine what features are relevant. Conceptually, in permutation importance, it calculates a baseline accuracy for the features using a validation set. Next, it permutes all the values for a single column/feature and measures the change against the baseline accuracy using the test dataset. This would be repeated for every feature.", "In my research, I came across an informative article on this particular topic on Scikit-Learn\u2019s website. I\u2019m going to leverage the code found here and complete my feature selection process. Also, I\u2019ll rely on domain knowledge and guided trial-and-error to see what combinations of features will have the best outcome.", "Permutation importance is relatively more reliable than feature importance, although the former is also influenced by collinear features and inflates the importance of impacted features. One agreeable recommendation that came out of the two initial views was that is_alone, is_mix_group, and is_one_family do not add much value to the model.", "For hierarchical clustering, the y-axis on the dendrogram represents closeness or dissimilarity. As it gets closer to 0, the closer the distance between clustered features indicating correlation/association. In this iteration, I examined all clusters falling under 1.5 \u2014 an arbitrary threshold. The code chunk used here is also available on Scikit-Learn\u2019s website.", "Using the dendrogram, I took a closer look at smaller clusters with two features (e.g., pclass and cabin_level) and heuristically determined what features might need to be dropped. I decided to drop age because it's highly collinear with age_bucket, and it\u2019s a continuous feature. In addition, I decided to drop sex and fare because their correlated features would contribute equally to the model. As a result, a total of 7 features were dropped in the next iteration \u2014 age, sex, fare, is_alone, is_mix_group, and is_one_family", "Let\u2019s take a look at the updated results. In this iteration, I worked with 9 features, which represent the new X_train and X_test.", "I used the output_model_stats function to compare the performance metrics against the original random forest metrics. The iteration 2 metrics are attached to the \u201crf_base \u2014 iteration 2\u201d index. Overall the model performed slightly less effectively than the model with all the features. Most likely, the first random forest model was overfitting (relatively low bias and high variance) and should not be a source of concern at this stage.", "Based on the updated feature and permutation importance ranking, embarked was very close to zero in both. I decided to drop this feature in the next iteration.", "I decided to drop fare_bucket as well as age_bucket. In my mind, the average fare_per_passenger calculation, which was used to create the fare buckets, most likely did not have enough data to generalize well and fare outliers lingering in the training data.", "Similar logical thinking fell onto age_bucket after observing how high it ranked versus pclass and is_woman_child using permutation importance. At the same time, fare_bucket and age_bucket correlated with one another. My intuition told me that keeping these features would most likely decrease bias and increase variance. Therefore, the model's effectiveness to generalize would be reduced.", "As the dendrogram illustrates, the first cluster from the left under 0.5 is composed of pclass and cabin_level. The distance between pclass and cabin_level is very close, and Spearman\u2019s correlation matrix shows these being correlated. I was hesitant to drop either pclass or is_woman_child because both features showed a high correlation to passenger survival during my exploratory analysis.", "Random forest\u2019s randomness of creating root nodes and splitting to create internal and leaf nodes reduce the effects of collinear features but never completely. In my opinion, it does not hurt to use both collinear features in this scenario using random forest.", "The updated X_train and X_test datasets contain 5 features at this stage, which I have deduced to be most relevant.", "Next, I outputted the performance metrics (\u201crb_base \u2014 Iteration 3\u201d) and compared them with earlier results. The accuracy_cv_score was higher than the previous two iterations. Precision improved quite a bit, which meant more true positives (TP) were found within all positives (TP + FP) detected by the model. This was a good sign. Recall dropped slightly as expected, which meant the model\u2019s ability to detect true positives (TP) among actual true positives (TP + FN) outstanding had fallen a bit. F1 score improved from iteration 2, and the AUC under the ROC curve moved up to a new high.", "After taking a closer look at feature importance, permutation importance, and dendrogram accompanied by Spearman\u2019s correlation matrix, I decided these features would generate my first Kaggle submission file. At this point, I was not concerned about one pair of correlated features.", "I outputted the predicted y_test (y_pred_base) using the trained model with X_test. I created my submission file and submitted it to Kaggle. I was able to score 80.382% accuracy with this submission. I think this is a pretty respectable score.", "A good explanation of RandomizedSearchCV is found on Scikit-Learn\u2019s documentation page. It\u2019s good to know Python\u2019s approach to OOP. The model class objects in Scikit-Learn contain parameters, attributes, and methods.", "\u201cThe parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.", "In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.", "If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.\u201d", "I\u2019m focusing on the 6 hyperparameters listed under the rs_grid variable. For a detailed overview of all parameters, the documentation page contains a plethora of information.", "The randomized search took about 5 minutes using all my processor power (n_jobs=-1). The param_distributions contain 8,232 combinations of settings (7*2*2*7*7*6). For my randomized search, I set cv to 5, which equals the number of stratified Kfolds. Therefore, if I started with GridSearchCV, a total of 41,160 parameter settings or fits would be tried. This would take a very long time to run. However, with RandomizedSearchCV, it samples n_iter=200 from total possible settings and thus lowering the number of tasks or fits to 1,000 in this case. Here are the best hyperparameter values from this randomized search.", "Let\u2019s compare the results from my previous runs. The accuracy_cv_score increased by approximately 1.1% and accuracy_cv_stddev went down to about 4%. The precision score improved as well (91.47%) while recall went down a bit. The overall F1 score improved. The AUC score stood steady at 89%. Using what I have learned thus far, the goal is to run a grid search on a smaller set of settings and measure incrementality.", "GridSearchCV is similar to RandomizedSearchCV, except it will conduct an exhaustive search based on the defined set of model hyperparameters (GridSearchCV\u2019s param_grid). In other words, it will go through all of the 41,160 fits from above. However, I\u2019m leveraging the learnings from earlier and reducing the list of values for each hyperparameter. For a detailed overview of GridSearchCV\u2019s parameters, take a look at the documentation page.", "\u201cThe parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\u201d", "Overall, there wasn\u2019t a whole lot of improvement, except AUC went up slightly. Either way, this demonstrated that tuning the right set of hyperparameters and covering a wide range of settings can improve model predictions. Therefore, learning to leverage RandomizedSearchCV and GridSearchCV becomes an important part of the machine learning workflow. However, you also need to know how much time and energy you want to put into the tuning process because the gain can be minimal.", "As the last step, I generated the updated submission file and submitted it to Kaggle. Even with hyperparameter tuning, my score stayed at 80.382% for this set of features and this set of optimized hyperparameters.", "Through trial-and-error and expanding the hyperparameter settings, I reached the current standing score of 80.861%, which, according to Kaggle, falls within the top 6%. In my opinion, this is a pretty solid score.", "Please feel free to share your comments, feedback, and/or questions. If you\u2019re interested in exploratory analysis and feature engineering, check out my first article \u2014 \u201cKaggle Titanic Competition in SQL.\u201d Thanks for reading!", "I recommend these three books if you are looking for good reference books on machine learning, data analysis, and improving your Python programming skill."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F12f4f74436b5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://dolee.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Do Lee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F607ad4750966&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=post_page-607ad4750966----12f4f74436b5---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F12f4f74436b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=-----12f4f74436b5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F12f4f74436b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=-----12f4f74436b5---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@iampaulbiondi?utm_source=medium&utm_medium=referral", "anchor_text": "Paul Biondi"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@dolee_12121/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQLExploratory Data Analysis & Feature Engineeringtowardsdatascience.com"}, {"url": "https://medium.com/@dolee_12121/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQL"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html", "anchor_text": "corr function"}, {"url": "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient", "anchor_text": "Spearman\u2019s rank-order correlation"}, {"url": "https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V", "anchor_text": "Cramer\u2019s V"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "non-linear models"}, {"url": "https://link.springer.com/article/10.1186/1471-2105-8-25", "anchor_text": "read"}, {"url": "https://explained.ai/rf-importance/", "anchor_text": "this"}, {"url": "https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined", "anchor_text": "this"}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "website"}, {"url": "https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html", "anchor_text": "cikit-Learn\u2019s website"}, {"url": "https://blog.datadive.net/selecting-good-features-part-iii-random-forests/#:~:text=Random%20forest%20feature%20importance,impurity%20and%20mean%20decrease%20accuracy.", "anchor_text": "randomness"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html", "anchor_text": "page"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "page"}, {"url": "https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend", "anchor_text": "joblib.parallel_backend"}, {"url": "https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py", "anchor_text": "incrementality"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "page"}, {"url": "https://towardsdatascience.com/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQL"}, {"url": "https://towardsdatascience.com/kaggle-titanic-competition-in-sql-78ae3cd551ce", "anchor_text": "Kaggle Titanic Competition in SQLExploratory Data Analysis & Feature Engineeringtowardsdatascience.com"}, {"url": "https://amzn.to/2Nse7gx", "anchor_text": "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems 2nd Edition"}, {"url": "https://amzn.to/2YE0X6J", "anchor_text": "Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython 2nd Edition"}, {"url": "https://amzn.to/2V9l8r2", "anchor_text": "Fluent Python: Clear, Concise, and Effective Programming 1st Edition"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----12f4f74436b5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/titanic-dataset?source=post_page-----12f4f74436b5---------------titanic_dataset-----------------", "anchor_text": "Titanic Dataset"}, {"url": "https://medium.com/tag/gridsearchcv?source=post_page-----12f4f74436b5---------------gridsearchcv-----------------", "anchor_text": "Gridsearchcv"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----12f4f74436b5---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/tag/feature-engineering?source=post_page-----12f4f74436b5---------------feature_engineering-----------------", "anchor_text": "Feature Engineering"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F12f4f74436b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=-----12f4f74436b5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F12f4f74436b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=-----12f4f74436b5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F12f4f74436b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F607ad4750966&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=post_page-607ad4750966----12f4f74436b5---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F59b34262f320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&newsletterV3=607ad4750966&newsletterV3Id=59b34262f320&user=Do+Lee&userId=607ad4750966&source=-----12f4f74436b5---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Written by Do Lee"}, {"url": "https://dolee.medium.com/followers?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "48 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F607ad4750966&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&user=Do+Lee&userId=607ad4750966&source=post_page-607ad4750966----12f4f74436b5---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F59b34262f320&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkaggle-titanic-competition-model-building-tuning-in-python-12f4f74436b5&newsletterV3=607ad4750966&newsletterV3Id=59b34262f320&user=Do+Lee&userId=607ad4750966&source=-----12f4f74436b5---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understand-implement-logistic-regression-in-python-c1e1a329f460?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Do Lee"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understand-implement-logistic-regression-in-python-c1e1a329f460?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Understand & Implement Logistic Regression in PythonSigmoid Function, Linear Regression, and Parameter Estimation (Log-Likelihood & Cross-Entropy Loss)"}, {"url": "https://towardsdatascience.com/understand-implement-logistic-regression-in-python-c1e1a329f460?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "14 min read\u00b7Jun 15, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1e1a329f460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-implement-logistic-regression-in-python-c1e1a329f460&user=Do+Lee&userId=607ad4750966&source=-----c1e1a329f460----0-----------------clap_footer----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understand-implement-logistic-regression-in-python-c1e1a329f460?source=author_recirc-----12f4f74436b5----0---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1e1a329f460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-implement-logistic-regression-in-python-c1e1a329f460&source=-----12f4f74436b5----0-----------------bookmark_preview----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----12f4f74436b5----1---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----12f4f74436b5----1-----------------bookmark_preview----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----12f4f74436b5----2---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----12f4f74436b5----2-----------------bookmark_preview----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/sql-window-functions-the-intuitive-guide-5b56d7f437cb?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Do Lee"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/sql-window-functions-the-intuitive-guide-5b56d7f437cb?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "SQL Window Functions: The Intuitive GuideIntuitively learn different components of window functions using Postgres and implement into your data workflow"}, {"url": "https://towardsdatascience.com/sql-window-functions-the-intuitive-guide-5b56d7f437cb?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": "8 min read\u00b7Jul 16, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5b56d7f437cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsql-window-functions-the-intuitive-guide-5b56d7f437cb&user=Do+Lee&userId=607ad4750966&source=-----5b56d7f437cb----3-----------------clap_footer----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/sql-window-functions-the-intuitive-guide-5b56d7f437cb?source=author_recirc-----12f4f74436b5----3---------------------13c8aacb_1376_4daa_9272_6ba97d71e4fa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5b56d7f437cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsql-window-functions-the-intuitive-guide-5b56d7f437cb&source=-----12f4f74436b5----3-----------------bookmark_preview----13c8aacb_1376_4daa_9272_6ba97d71e4fa-------", "anchor_text": ""}, {"url": "https://dolee.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "See all from Do Lee"}, {"url": "https://towardsdatascience.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/how-to-clean-data-with-pandas-e8960e4330c5?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://dataforeveryone.medium.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://dataforeveryone.medium.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Data 4 Everyone!"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/how-to-clean-data-with-pandas-e8960e4330c5?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "How to Clean Data With PandasHow to Deal With Outliers, Missing Values, and Dates using Python"}, {"url": "https://levelup.gitconnected.com/how-to-clean-data-with-pandas-e8960e4330c5?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b78 min read\u00b7Nov 28, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fe8960e4330c5&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-clean-data-with-pandas-e8960e4330c5&user=Data+4+Everyone%21&userId=a0fef66b3c1f&source=-----e8960e4330c5----0-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/how-to-clean-data-with-pandas-e8960e4330c5?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe8960e4330c5&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fhow-to-clean-data-with-pandas-e8960e4330c5&source=-----12f4f74436b5----0-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdev.com/predicting-the-premier-league-with-random-forest-fbc7d320a37e?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://footballdotpy.medium.com/?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://footballdotpy.medium.com/?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Paul Corcoran"}, {"url": "https://towardsdev.com/?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Towards Dev"}, {"url": "https://towardsdev.com/predicting-the-premier-league-with-random-forest-fbc7d320a37e?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Predicting the Premier League with Random Forest.The premier league is extremely hard to predict other than predicting Manchester City to win the premier league, but that can not be\u2026"}, {"url": "https://towardsdev.com/predicting-the-premier-league-with-random-forest-fbc7d320a37e?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b79 min read\u00b7Nov 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowardsdev%2Ffbc7d320a37e&operation=register&redirect=https%3A%2F%2Ftowardsdev.com%2Fpredicting-the-premier-league-with-random-forest-fbc7d320a37e&user=Paul+Corcoran&userId=e9c37c48ca1&source=-----fbc7d320a37e----1-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdev.com/predicting-the-premier-league-with-random-forest-fbc7d320a37e?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffbc7d320a37e&operation=register&redirect=https%3A%2F%2Ftowardsdev.com%2Fpredicting-the-premier-league-with-random-forest-fbc7d320a37e&source=-----12f4f74436b5----1-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-perform-kmeans-clustering-using-python-7cc296cec092?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://zoumanakeita.medium.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://zoumanakeita.medium.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Zoumana Keita"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-perform-kmeans-clustering-using-python-7cc296cec092?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "How to Perform KMeans Clustering Using PythonA complete overview of the KMeans clustering and implementation with Python"}, {"url": "https://towardsdatascience.com/how-to-perform-kmeans-clustering-using-python-7cc296cec092?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b77 min read\u00b7Jan 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7cc296cec092&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-kmeans-clustering-using-python-7cc296cec092&user=Zoumana+Keita&userId=e6ae785a30d&source=-----7cc296cec092----0-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-perform-kmeans-clustering-using-python-7cc296cec092?source=read_next_recirc-----12f4f74436b5----0---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7cc296cec092&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-perform-kmeans-clustering-using-python-7cc296cec092&source=-----12f4f74436b5----0-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----12f4f74436b5----1---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----12f4f74436b5----1-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/chi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://angeleastbengal.medium.com/?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Angel Das"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/chi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Chi-square Test \u2014 How to calculate Chi-square using Formula & Python Implementation1. Type of Test"}, {"url": "https://towardsdatascience.com/chi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b77 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6da203f96569&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569&user=Angel+Das&userId=8418ab50405a&source=-----6da203f96569----2-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/chi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569?source=read_next_recirc-----12f4f74436b5----2---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6da203f96569&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchi-square-test-how-to-calculate-chi-square-using-formula-python-implementation-6da203f96569&source=-----12f4f74436b5----2-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://medium.com/@dimitris.effrosynidis?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://medium.com/@dimitris.effrosynidis?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Dimitris Effrosynidis"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "Ensemble Feature Selection for Machine LearningSelect the best features by combining individual feature selection methods"}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": "\u00b75 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0df77b970f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fensemble-feature-selection-for-machine-learning-c0df77b970f9&user=Dimitris+Effrosynidis&userId=ff294d269093&source=-----c0df77b970f9----3-----------------clap_footer----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/ensemble-feature-selection-for-machine-learning-c0df77b970f9?source=read_next_recirc-----12f4f74436b5----3---------------------4a80b29a_6d13_401d_ba8f_b38323a0d376-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0df77b970f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fensemble-feature-selection-for-machine-learning-c0df77b970f9&source=-----12f4f74436b5----3-----------------bookmark_preview----4a80b29a_6d13_401d_ba8f_b38323a0d376-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----12f4f74436b5--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}