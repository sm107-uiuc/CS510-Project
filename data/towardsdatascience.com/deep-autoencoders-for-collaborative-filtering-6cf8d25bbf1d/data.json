{"url": "https://towardsdatascience.com/deep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d", "time": 1682993320.7875662, "path": "towardsdatascience.com/deep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d/", "webpage": {"metadata": {"title": "Deep Autoencoders For Collaborative Filtering | Towards Data Science", "h1": "Deep Autoencoders For Collaborative Filtering", "description": "Collaborative Filtering is used by recommender systems to make predictions about the interest of a specific user by collecting tastes or preferences from other users."}, "outgoing_paragraph_urls": [{"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering", "anchor_text": "GitHub repository", "paragraph_index": 2}, {"url": "https://www.deeplearning-academy.com/", "anchor_text": "www.deeplearning-academy.com", "paragraph_index": 9}, {"url": "https://grouplens.org/datasets/movielens/", "anchor_text": "MovieLens dataset.", "paragraph_index": 15}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering", "anchor_text": "GitHub repository", "paragraph_index": 21}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering/blob/master/train.py", "anchor_text": "GitHub repository", "paragraph_index": 37}, {"url": "https://artem-oppermann.medium.com/subscribe", "anchor_text": "https://artem-oppermann.medium.com/subscribe", "paragraph_index": 40}], "all_paragraphs": ["Collaborative Filtering is a method used by recommender systems to make predictions about the interest of a specific user by collecting taste or preference information from many other users. The technique of Collaborative Filtering has the underlying assumption that if a user A has the same taste or opinion on an issue as the person B, A is more likely to have B\u2019s opinion on a different issue.", "In this article, you will learn how to predict the ratings a user would give a movie based on this user\u2019s taste and the taste of other users who watched and rated the same and other movies.", "An Autoencoder is a deep learning neural network architecture that achieves state of the art performance in the area of collaborative filtering. In the first part of the article I will give you a theoretical overview and basic mathematics behind simple Autoencoders and their extension the Deep Autoencoders. In the second part we will dive in the practical stuff and I will show you how to implement this technique in TensorFlow step by step. In this article I will include and comment only the most important parts of the model. The whole model, the input pipeline and the preprocessing can be viewed in the corresponding GitHub repository.", "Before we can focus on the Deep Autoencoders we should discuss it\u2019s simpler version. An Autoencoder is an artificial neural network used to learn a representation (encoding) for a set of input data, usually to a achieve dimensionality reduction.", "Architecturally, the form of an Autoencoder is a feedforward neural network having an input layer, one hidden layer and an output layer (Fig.1). The output layer has the same number of neurons as the input layer for the purpose of reconstructing it\u2019s own inputs. This makes an Autoencoder a form of unsupervised learning, which means no labelled data are necessary \u2014 only a set of input data instead of input-output pairs.", "It is useful that an Autoencoder has a smaller hidden layer than the input layer. This effect forces the model to create a compressed representation of the data in the hidden layer by learning correlations in the data.", "The transition from the input to the hidden layer is called the encoding step and the transition from the hidden to the output layer is called the decoding step. We can also define these transitions mathematically as a mapping:", "The mapping is realized by multiplying the input data vector x with a weight matrix, adding a bias term and applying to the resulting vector a non linear operation \u03c3 such as sigmoid, tanh or rectified linear unit.", "Coming Soon: Advanced Deep Learning Education for software developers, data analysts, academics and industry insiders", "For more details check out: www.deeplearning-academy.com", "During the training time the encoder takes a input data sample x and maps it to the so called hidden or latent representation z. Then the decoder maps z to the output vector x\u2019 which is (in the best case scenario) the exact representation of the input data x. Please notice that usually an exact recreation of the input x is not possible.", "Having the output x\u2019 the training consists of applying stochastic gradient descent to minimize a predefined loss such as a mean squared error:", "The extension of the simple Autoencoder is the Deep Autoencoder (Fig. 2). As can be seen in the Fig. 2 the only difference to it\u2019s simpler counter part is number of hidden layers.", "The additional hidden layers enable the Autoencoder to learn mathematically more complex underlying patterns in the data. The first layer of the Deep Autoencoder may learn first-order features in the raw input (such as edges in an image). The second layer may learn second-order features corresponding to patterns in the appearance of first-order features (e.g., in terms of what edges tend to occur together \u2014 for example, to form contour or corner detectors). Deeper layers of the Deep Autoencoder tend to learn even higher-order features.", "To put everything together: We need additional layers to be able to handle more complex data \u2014 such as the data we use in collaborative filtering.", "As previously mentioned you will learn to predict the rating a user would give a movie. For that matter we will use the famous MovieLens dataset. MovieLens is a web based recommender system and online community that recommends movies for its users to watch.", "More specifically we will use the ml-1m.zip dataset that contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users. The import file we need is ratings.dat. This file contains 1,000,209 lines all having the following format: user_id::movie_id::rating:time_stamp.", "For example the first line in ratings.dat:", "means that user Nr. 1 gave movie Nr. 595 a five star rating. The time stamp can be ignored because it won\u2019t be used.", "The deep learning model we implement needs a specific data structure for the training and testing. This data structure is a UxM-Matrix where U is the number of users and M the number of movies. Each row i \u2208 U is a unique user id and each column j \u2208 M a unique movie id. A visualization for such a matrix can be seen in Fig.3.", "Each entry in this matrix is a rating a user gave a specific movie. An entry of 0 means that the user did not gave this movie any rating. E.g. user Nr.1 gave movie Nr.3 a rating of 4 stars while movie Nr.1 was not rated at all.", "Since this tutorial focuses on the implementation of the deep learning model the step of making the User-Movie-Matrix out of ratings.dat file won\u2019t be covered here. For further questions on this topic, I would like to redirect you to my GitHub repository where you can examine the corresponding python script.", "Before the model can be implemented and trained another reprocessing step of the data is necessary - dividing the data into training and testing data sets. This step is pretty straight forward. So far we have a User-Movie Matrix where each row is a list of ratings. To obtain the training and testing sets out of this list we must take a subset of the ratings from each row and use them only for training while using the remaining subset only for the testing.", "As an example of the described procedure let\u2019s consider a much smaller data set consisting only out of 15 movies. A specific user may have given these movies the following ratings:", "Remember that 0 means the movie was not rated. Now we take a subset consisting out of the first 10 movies as the training set and pretend that the remaining ones were not rated yet:", "Accordingly the last 5 movie ratings of the original data are used as test data, while movies 1\u201310 are masked as not rated:", "This was just a simple demonstration how the different sets were obtained. In the original MovieLens data set I use for each user only 10 movie ratings for the testing while the rest (vast majority) were used for the training of the model.", "The Deep Autoencoder is implemented as a class with all necessary operations like inference, optimization, loss, accuracy etc. inside the class.", "In the constructor kernel initializers for the weights and biases are set. In the next step all weights and biases in the network get initialized. The weights are normal distributed with a mean of 0.0 and a variance of 0.02, while the biases are all set to 0.0 in the beginning.", "In this particular example the network has three hidden layers each containing 128 neurons. The size of the input layer (and output layer) corresponds to the number of all present movies in the dataset.", "Given an input data sample x (a row of the user-movie matrix) a forward pass that computes the network outputs is made. The hidden layers use sigmoid as an activation function. Please note that the last layer does not have either a non linearity nor a bias term.", "Having the network predictions we can compute the loss between these predictions and the corresponding labels (network inputs x). To compute the mean of the loss we also need to know the number of labels that are non zero \u2014 in other words the number of total ratings of an user in the training set.", "The optimization/training step of the network may appear little tricky, let\u2019s discuss it step by step. Given an input x the corresponding outputs are calculated. As you already probably noticed the majority of the values in the input x are zero values because a user most certainly did not watch and rated all of the 5953 movies what are in the data set. As a consequence it is advisable not use the raw predictions of the network directly. Instead we must identify the indices of zero values in the data input x and set the values in the prediction vector that corresponds to these indices to zeros also. This manipulation of the prediction massively reduces the training time of the network giving the network the opportunity to concentrate it\u2019s training effort only on the ratings the user have actually made.", "After this step the loss can be calculated as well as the regularization loss (optional). The loss function is minimized by the AdamOptimizer. Please notice that the method returns a root mean squared error (RMSE) instead of a mean squared error (MSE) for better accuracy measurement.", "After some epochs of the training phase the neural network has seen all ratings in the training date set of each user multiply times. At this time the model should have learned the underlying hidden patterns in the data and corresponding collaborative movie tastes of the users. Given a user rating training sample x the model predicts an output x\u2019. This vector consists out of the recreation of the input x (as expected ) but now also contains values for the previously zero rating in the input x. Meaning that the model gave yet unrated movies a rating. This ratings corresponds to the taste of the user \u2014 the taste the model have recognized and learned from the data.", "In order that we can measure the accuracy of the model, both the training and testing data sets are required. Based on the training set a prediction is made. Analogous to the training phase we only consider the output values which correspond to the indices of the non zero values in the test set.", "Now we can calculate the root mean squared error loss (RMSE) between the predicted and the actual ratings. The RMSE represents the sample standard deviation of the differences between predicted values and observed values. E.g. a RMSE of 0.5 means that on an average the predicted rating deviates from the actual rating by 0.5 stars.", "The final step consists of executing the training process and examine the models performance. At this point I won\u2019t go into the detail of building the data input pipeline, graph, session etc., since these steps are commonly known. Readers who are interested in this topic can view these steps in my GitHub repository.", "Here you can observe the training and testing performance for the first 50 epochs. After 50 epochs we get a 0.929 star deviation between the predicted and actual ratings on the test set.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Deep Learning & AI Software Developer | MSc. Physics | https://artem-oppermann.medium.com/subscribe"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6cf8d25bbf1d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://artem-oppermann.medium.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": ""}, {"url": "https://artem-oppermann.medium.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Artem Oppermann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F619319ac8220&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&user=Artem+Oppermann&userId=619319ac8220&source=post_page-619319ac8220----6cf8d25bbf1d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.linkedin.com/in/artem-oppermann-929154199/?locale=en_US", "anchor_text": "LinkedIn"}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering", "anchor_text": "GitHub repository"}, {"url": "https://www.deeplearning-academy.com/", "anchor_text": "www.deeplearning-academy.com"}, {"url": "https://www.deeplearning-academy.com/", "anchor_text": "www.deeplearning-academy.com"}, {"url": "https://grouplens.org/datasets/movielens/", "anchor_text": "MovieLens dataset."}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering", "anchor_text": "GitHub repository"}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering/blob/master/train.py", "anchor_text": "GitHub repository"}, {"url": "https://www.linkedin.com/in/artem-oppermann-929154199/?locale=en_US", "anchor_text": "LinkedIn"}, {"url": "https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering", "anchor_text": "artem-oppermann/Deep-Autoencoders-For-Collaborative-FilteringDeep-Autoencoders-For-Collaborative-Filtering - Using Deep Autoencoders for predictions of movie ratings.github.com"}, {"url": "http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf", "anchor_text": "http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf"}, {"url": "http://deeplearning.net/tutorial/SdA.html", "anchor_text": "http://deeplearning.net/tutorial/SdA.html"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6cf8d25bbf1d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6cf8d25bbf1d---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6cf8d25bbf1d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6cf8d25bbf1d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----6cf8d25bbf1d---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&user=Artem+Oppermann&userId=619319ac8220&source=-----6cf8d25bbf1d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&user=Artem+Oppermann&userId=619319ac8220&source=-----6cf8d25bbf1d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6cf8d25bbf1d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6cf8d25bbf1d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6cf8d25bbf1d--------------------------------", "anchor_text": ""}, {"url": "https://artem-oppermann.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://artem-oppermann.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Artem Oppermann"}, {"url": "https://artem-oppermann.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.8K Followers"}, {"url": "https://artem-oppermann.medium.com/subscribe", "anchor_text": "https://artem-oppermann.medium.com/subscribe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F619319ac8220&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&user=Artem+Oppermann&userId=619319ac8220&source=post_page-619319ac8220--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc09555d6711e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d&newsletterV3=619319ac8220&newsletterV3Id=c09555d6711e&user=Artem+Oppermann&userId=619319ac8220&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}