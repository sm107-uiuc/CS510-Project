{"url": "https://towardsdatascience.com/logistic-regression-for-binary-classification-56a2402e62e6", "time": 1683014357.954853, "path": "towardsdatascience.com/logistic-regression-for-binary-classification-56a2402e62e6/", "webpage": {"metadata": {"title": "Logistic Regression for Binary Classification | by Sebasti\u00e1n Gerard Aguilar Kleimann | Towards Data Science", "h1": "Logistic Regression for Binary Classification", "description": "In previous articles, I talked about deep learning and the functions used to predict results. In this article, we will use logistic regression to perform binary classification. Binary classification\u2026"}, "outgoing_paragraph_urls": [{"url": "https://datasciencestreet.com/logistic-regression-for-binary-classification/", "anchor_text": "https://datasciencestreet.com", "paragraph_index": 36}], "all_paragraphs": ["In previous articles, I talked about deep learning and the functions used to predict results. In this article, we will use logistic regression to perform binary classification. Binary classification is named this way because it classifies the data into two results. Simply put, the result will be \u201cyes\u201d (1) or \u201cno\u201d (0). To determine whether the result is \u201cyes\u201d or \u201cno\u201d, we will use a probability function:", "This probability function will give us a number from 0 to 1 indicating how likely this observation will belong to the classification that we have currently determined to be \u201cyes\u201d. With this, we know what we intend to do with our prediction. Now, we\u2019ll see how to use logistic regression to calculate the equation in (1).", "To perform logistic regression, the sigmoid function, presented below with its plot, is used:", "As we can see this function meets the characteristics of a probability function and equation (1). Likewise, we can see that when S(t) is very large positive, the function approaches one, and when S(t) is very large negative, the function approaches zero.", "To be able to understand how logistic regression operates, we will make an example where our function will classify people as tall or not tall. The data that we will use to calibrate our function are those corresponding to the following table (Table 1):", "Suppose t=wx+b, our goal will be to find w and b in such a way that by placing it in S(t) it will give us the correct prediction. We can start with a random number let\u2019s say w=1 and b=0 and if S(t) is greater than 0.5 then we will consider it a tall person.", "Great, we have found the w and b parameters in such a way that our function makes the predictions correctly!", "These parameters work to make the prediction; however, many questions arise such as:", "To answer these questions, we will have to introduce two new topics that will help us optimize the function and understand the loss functions.", "What are the best w and b parameters? The answer to this question is very simple because we want the parameters to give us as little error as possible. For this we use the loss error function:", "The function basically tells us how far away is our estimate of the actual value (\u0177 estimation, y actual value). If we\u2019d make a summation on all our estimation we would get:", "This summation is the total error of all our estimates and trying to reduce this function to 0 means trying to reduce our error to 0. However, when using this function on logistic regression we get a function that is not convex (we will return to this topic later) and since it is not convex there can be several local optimal points, and a great difficulty when calculating the best w and b. To solve this issue, we will use another function:", "The function constructed in (5) has the same purpose as the function (3), to reduce the error. We\u2019ll do an experiment on an observation to see how the function J(\u0177,y) behaves. Let\u2019s imagine 4 possible scenarios of J(\u0177,y)", "We observe that in this scenario our estimation is practically correct and when replacing, we get:", "We observe that in this scenario our estimation is incorrect and when replacing, we get:", "We observe that in this scenario our estimation is incorrect and when replacing, we get:", "We observe that in this scenario our estimation is incorrect and when replacing, we get:", "Intuitively, we can observe what this function does. Correct observations have a very low error, and incorrect observations have a very high error. If we did the summation on all the observations, we\u2019d get.", "The advantage of function (6) over function (4) is that it is convex. With function 6 it\u2019s possible to find the optimal points in a simpler way using the gradient descent method.", "The gradient descent method seeks to tell us in which direction we need to move our b and w parameters, to optimize the function and get the minimum error. The function described in (6) is convex so you could see it as the following graphic.", "Now, suppose our loss function is J(w,b) and the parameters to be adjusted are (w,b). We want to find the point where J(w,b) is as small as possible. The gradient descent method tells us the direction where to move (w,b) to decrease J(w,b). These are the partial derivatives of (w,b), that is \u2202J/\u2202w and \u2202J/\u2202b.", "Knowing the directions where to move w and b. We would only need to know the magnitude to which they would move, this is called a learning rate and is usually defined as \u03b1. To finally get:", "Finally, we will summarize the steps that must be followed to perform the logistic regression:", "These 4 steps should be iterated until you get an acceptable error.", "We finally have all the theoretical elements to apply logistic regression. It is also important to know how to apply them in programming languages such as python. This language is widely used so the implementation of this algorithm is quite easy. For this example, we will use logistic regression to predict the trajectory of basketball players. The data obtained for this exercise was extracted from \u00b9data.world. At the end of the article, the full code is displayed, so that you can follow and run the code along with the article on google colab.", "It\u2019s important to understand what each of the columns in this table mean:", "Before logistic regression, observation and analysis of the data should be done. Pandas library is a very used library on python for handling data and we will use it to read and describe data.", "The code preceded by \u201c#\u201dare just comments, so with this code, we have done only 3 things:", "The description indicates the quantity of data we have, the maximum value, minimum value, standard deviation, etc. By observing the data it can be seen that some fields are empty. Before training the model these issues have to be solved. The empty fields will be substituted by 0, and Pearson Correlation Coefficient will be used to observe the data with the highest correlation.", "Using Pearson Correlation Coefficient we notice the columns with the highest correlation. This way the columns that are more useful should be kept and the others dropped.", "With the clean data we can start training the model. For this, the library sklearn will be used. This library contains many models and is updated constantly making it very useful. In order to train the model, we will indicate which are the variables that predict and the predicted variable.", "Now, using the library sklearn the data will be divided in training and test set. With the training set, the model will be adjusted, and with the test set we will see how good the model is.", "The previous piece of code divides the data between train and test set. The variable X is for the independent variables and y for the dependent variable. This time 75% of the set was used for training and 25% for testing. After separating the data it can be used to fit the model which in this case is the \u201cLogisticRegression\u201d model.", "So, the model has been calibrated using the function .fit and it\u2019s ready to predict using the test data. This is done using the function .predict and using the independent variables for testing (X_test). The results obtained can be compared with the real values (y_test) to see if it\u2019s a good model.", "The resulting matrix is known as confusion matrix. In the first quadrant the number of entries that were classified correctly with 0 are shown(61). The second and third quadrant sum the incorrect classification(99). Lastly, the fourth quadrant shows the classifications that were done correctly with number 1 (175). The accuracy can be calculated as follows:", "With this, we conclude the article. As usual, I\u2019ll leave you the code so you can test, run and try different models. Good day and congratulations on learning how to do logistic regression.", "Originally published at https://datasciencestreet.com on September 25, 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Master in International Business and Entrepreneurship (Universita degli studi di Pavia) Bachelor in Actuary (Universidad Nacional Aut\u00f3noma de M\u00e9xico)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F56a2402e62e6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sgerardak?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgerardak?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Sebasti\u00e1n Gerard Aguilar Kleimann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d3c136f9f7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&user=Sebasti%C3%A1n+Gerard+Aguilar+Kleimann&userId=7d3c136f9f7c&source=post_page-7d3c136f9f7c----56a2402e62e6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://commons.wikimedia.org/wiki/File:Sigmoid.jpg", "anchor_text": "wikicommons"}, {"url": "https://commons.wikimedia.org/wiki/File:Sigmoid.jpg", "anchor_text": "wikicommons"}, {"url": "https://commons.wikimedia.org/wiki/File:Grafico_3d_x2%2Bxy%2By2.png", "anchor_text": "wikicommons"}, {"url": "https://data.world/.", "anchor_text": "https://data.world/."}, {"url": "https://datasciencestreet.com/logistic-regression-for-binary-classification/", "anchor_text": "https://datasciencestreet.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----56a2402e62e6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----56a2402e62e6---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----56a2402e62e6---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----56a2402e62e6---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/classification-algorithms?source=post_page-----56a2402e62e6---------------classification_algorithms-----------------", "anchor_text": "Classification Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&user=Sebasti%C3%A1n+Gerard+Aguilar+Kleimann&userId=7d3c136f9f7c&source=-----56a2402e62e6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&user=Sebasti%C3%A1n+Gerard+Aguilar+Kleimann&userId=7d3c136f9f7c&source=-----56a2402e62e6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F56a2402e62e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----56a2402e62e6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----56a2402e62e6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----56a2402e62e6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----56a2402e62e6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgerardak?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sgerardak?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sebasti\u00e1n Gerard Aguilar Kleimann"}, {"url": "https://medium.com/@sgerardak/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "8 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7d3c136f9f7c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&user=Sebasti%C3%A1n+Gerard+Aguilar+Kleimann&userId=7d3c136f9f7c&source=post_page-7d3c136f9f7c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F7d3c136f9f7c%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-for-binary-classification-56a2402e62e6&user=Sebasti%C3%A1n+Gerard+Aguilar+Kleimann&userId=7d3c136f9f7c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}