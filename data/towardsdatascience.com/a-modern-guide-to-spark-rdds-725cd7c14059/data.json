{"url": "https://towardsdatascience.com/a-modern-guide-to-spark-rdds-725cd7c14059", "time": 1683008662.7042801, "path": "towardsdatascience.com/a-modern-guide-to-spark-rdds-725cd7c14059/", "webpage": {"metadata": {"title": "A modern guide to Spark RDDs. Everyday opportunities to reach the\u2026 | by Leo Lezcano | Towards Data Science", "h1": "A modern guide to Spark RDDs", "description": "The web is full of Apache Spark tutorials, cheatsheets, tips and tricks. Lately, most of them have been focusing on Spark SQL and Dataframes, because they offer a gentle learning curve, with a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark SQL and Dataframes", "paragraph_index": 0}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html", "anchor_text": "RDD API", "paragraph_index": 0}, {"url": "https://data-flair.training/blogs/dag-in-apache-spark/", "anchor_text": "DAGs", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations", "anchor_text": "transformation", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions", "anchor_text": "action", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/2.3.4/api/python/pyspark.sql.html?highlight=row#pyspark.sql.Row", "anchor_text": "Row", "paragraph_index": 11}, {"url": "https://spark.apache.org/docs/2.3.4/api/python/pyspark.sql.html?highlight=row#pyspark.sql.Row", "anchor_text": "Row", "paragraph_index": 11}, {"url": "https://docs.python.org/3/library/copy.html", "anchor_text": "deepcopy operations", "paragraph_index": 13}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey", "anchor_text": "groupByKey", "paragraph_index": 14}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey", "anchor_text": "reduceByKey", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop", "anchor_text": "REPL", "paragraph_index": 15}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter", "paragraph_index": 15}, {"url": "https://zeppelin.apache.org/", "anchor_text": "Zeppelin", "paragraph_index": 15}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.cache", "anchor_text": "RDD.cache", "paragraph_index": 16}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.persist", "anchor_text": "RDD.persist", "paragraph_index": 16}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.unpersist", "anchor_text": "RDD.unpersist", "paragraph_index": 17}, {"url": "https://www.statsmodels.org/", "anchor_text": "statsmodels", "paragraph_index": 21}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn", "paragraph_index": 21}, {"url": "https://numpy.org/", "anchor_text": "numpy", "paragraph_index": 21}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations", "anchor_text": "transformation", "paragraph_index": 21}, {"url": "https://www.nltk.org/", "anchor_text": "NLTK", "paragraph_index": 22}, {"url": "https://www.nltk.org/api/nltk.html#nltk.downloader.download", "anchor_text": "nltk.download", "paragraph_index": 22}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=mappartitions#pyspark.RDD.mapPartitions", "anchor_text": "RDD.mapPartitions", "paragraph_index": 22}], "all_paragraphs": ["The web is full of Apache Spark tutorials, cheatsheets, tips and tricks. Lately, most of them have been focusing on Spark SQL and Dataframes, because they offer a gentle learning curve, with a familiar SQL syntax, as opposed to the steeper curve required for the older RDD API. However, it\u2019s the versatility and stability of RDDs what ignited the Spark adoption in 2015, and turned it into a dominant framework for distributed data processing.", "As you become a regular Spark user, mainly three circumstances will lead you to consider the RDD API:", "This opinionated material covers such circumstances and the questions that frequently arise from them, so that you can enjoy the full potential of PySpark.", "A note on style\u2014 Grow your functional python vertically\u2014 Append the Spark type to variable names", "Turning Dataframes into RDDs & vice versa\u2014 Dataframe to RDD \u2014 RDD to Dataframe", "The expressive Python dictionaries\u2014 One-line dictionary transformations\u2014 Python sets & dictionaries are unhashable", "Caching & Broadcasting\u2014 Caching RDDs\u2014 Unpersisting RDDs\u2014 Cleaning the whole RDD cache", "Distributed execution of Python libraries\u2014 Numpy \u2014 A generic approach\u2014 NLTK \u2014 Partition setup", "Code readability is particularly important when functional programming meets big data, on the one hand because traditional IDE debugging tools have been designed around imperative programming, and on the other, because multiple code runs for debugging purposes is expensive and time consuming.", "Spark logics are defined as DAGs. Keep the code narrow to improve readability by breaking the lines with a BACKSLASH \u201c\\\u201d after every transformation or action.", "Distributed data will largely fall into one of the three types:", "The backbone of a Dataframe is an RDD[Row], a Spark type that behaves very similar to a Python dictionary. As you can see below this Row type serves as a bridge between the two APIs.", "As the chain of operations on an RDD grows long, it\u2019s challenging to keep the code readable and the logic understandable. Python dictionaries play a key role in this regard. As opposed to Scala tuples, they allow accessing fields by name rather than position, and as opposed to Scala Case Classes, they can be created in-line without previous external definition.", "Lambda functions are syntactically restricted to a single expression. In the common scenario where an RDD[dict] transformation is needed, consider these one-line lambdas. Note that **old_dict leads to a shallow copy, but no deepcopy operations are required inside RDD operations, as PySpark guarantees the new dictionary to be totally independent, ie. RDDs are immutable.", "RDD aggregations such as groupByKey and reduceByKey require the Key to be a hashable type for shuffling purposes. Therefore, avoid using Python dictionaries and sets as shuffling keys. If you must, consider using frozensets.", "Learning how to customize Spark\u2019s distributed memory processing leads to optimal resource usage for ETLs and ML training jobs. Also, it\u2019s the key ingredient of a fast and smooth REPL experience for Jupyter and Zeppelin notebooks.", "See RDD.cache for the common use case of persisting to MEMORY, or RDD.persist for other storage levels. Note that line 4 below sets the caching instruction but only an action like line 6 will trigger the DAG execution and subsequent storage in memory.", "There are mainly two reasons to invoke RDD.unpersist and remove all its blocks from memory and disk:", "To avoid duplicate memory allocation, prepend a try-unpersist (line 1\u20134 below) to the Jupyter paragraph that initializes the RDD:", "Unpersisting all RDDs can be achieved as follows:", "The flexibility of RDDs allows to distribute the payload when running practically any Python code. For computationally inexpensive tasks such as O(n) and below, truly big data is required for the benefits of parallelization to be obvious. However, for above linear complexity, parallelization can easily turn hours of medium-sized data jobs into minutes, or minutes of small data jobs into seconds.", "In order to parallelize the execution of libraries such as statsmodels, scikit-learn, numpy, simply invoke them from inside a map, flatMap, filter or any other transformation. In the example below, the np.median call is inside an RDD map, therefore, it will run locally in each Spark executor:", "The Natural Language Toolkit (NLTK) library requires further setup in addition to importing it. The nltk.download call in the example below must run in each executor to guarantee local nltk data availability. In such cases, consider using RDD.mapPartitions to avoid redundant calls to nltk.download inside the same executor. The RDD mapPartitions call allows to operate on the whole list of RDD entries for each partition, while the RDD map/flatMap/filter work on each RDD entry and offer no visibility to which partition the entry belongs to:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Engineering Manager | Spanish Experience Lead @ Walmart"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F725cd7c14059&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----725cd7c14059--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@LeoLezcano?source=post_page-----725cd7c14059--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@LeoLezcano?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Leo Lezcano"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2c55727373d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&user=Leo+Lezcano&userId=2c55727373d7&source=post_page-2c55727373d7----725cd7c14059---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark SQL and Dataframes"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html", "anchor_text": "RDD API"}, {"url": "https://data-flair.training/blogs/dag-in-apache-spark/", "anchor_text": "DAGs"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations", "anchor_text": "transformation"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions", "anchor_text": "action"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html", "anchor_text": "RDD"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Dataframe"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#broadcast-variables", "anchor_text": "Broadcast Variable"}, {"url": "https://spark.apache.org/docs/2.3.4/api/python/pyspark.sql.html?highlight=row#pyspark.sql.Row", "anchor_text": "Row"}, {"url": "https://spark.apache.org/docs/2.3.4/api/python/pyspark.sql.html?highlight=row#pyspark.sql.Row", "anchor_text": "Row"}, {"url": "https://docs.python.org/3/library/copy.html", "anchor_text": "deepcopy operations"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey", "anchor_text": "groupByKey"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey", "anchor_text": "reduceByKey"}, {"url": "https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop", "anchor_text": "REPL"}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter"}, {"url": "https://zeppelin.apache.org/", "anchor_text": "Zeppelin"}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.cache", "anchor_text": "RDD.cache"}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.persist", "anchor_text": "RDD.persist"}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=cache#pyspark.RDD.unpersist", "anchor_text": "RDD.unpersist"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions", "anchor_text": "actions"}, {"url": "https://www.statsmodels.org/", "anchor_text": "statsmodels"}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn"}, {"url": "https://numpy.org/", "anchor_text": "numpy"}, {"url": "https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations", "anchor_text": "transformation"}, {"url": "https://www.nltk.org/", "anchor_text": "NLTK"}, {"url": "https://www.nltk.org/api/nltk.html#nltk.downloader.download", "anchor_text": "nltk.download"}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.html?highlight=mappartitions#pyspark.RDD.mapPartitions", "anchor_text": "RDD.mapPartitions"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----725cd7c14059---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/big-data?source=post_page-----725cd7c14059---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/spark-rdd?source=post_page-----725cd7c14059---------------spark_rdd-----------------", "anchor_text": "Spark Rdd"}, {"url": "https://medium.com/tag/python?source=post_page-----725cd7c14059---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----725cd7c14059---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&user=Leo+Lezcano&userId=2c55727373d7&source=-----725cd7c14059---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&user=Leo+Lezcano&userId=2c55727373d7&source=-----725cd7c14059---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F725cd7c14059&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----725cd7c14059---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----725cd7c14059--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----725cd7c14059--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----725cd7c14059--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----725cd7c14059--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----725cd7c14059--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@LeoLezcano?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@LeoLezcano?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Leo Lezcano"}, {"url": "https://medium.com/@LeoLezcano/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "20 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2c55727373d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&user=Leo+Lezcano&userId=2c55727373d7&source=post_page-2c55727373d7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F2c55727373d7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-modern-guide-to-spark-rdds-725cd7c14059&user=Leo+Lezcano&userId=2c55727373d7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}