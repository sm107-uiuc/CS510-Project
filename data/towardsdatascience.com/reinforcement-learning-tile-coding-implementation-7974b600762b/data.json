{"url": "https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b", "time": 1682997445.896672, "path": "towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b/", "webpage": {"metadata": {"title": "Reinforcement Learning \u2014 Tile Coding Implementation | by Jeremy Zhang | Towards Data Science", "h1": "Reinforcement Learning \u2014 Tile Coding Implementation", "description": "We have come so far and extended our reinforcement learning theories into continuous space(generalisation in continuous space). If you would like to go further, you need to know tile coding, which is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/reinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa", "anchor_text": "generalisation in continuous space", "paragraph_index": 0}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/TileCoding/tile_coding.py", "anchor_text": "full implementation", "paragraph_index": 6}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/TileCoding/tile_coding.py", "anchor_text": "here", "paragraph_index": 14}], "all_paragraphs": ["We have come so far and extended our reinforcement learning theories into continuous space(generalisation in continuous space). If you would like to go further, you need to know tile coding, which is probably the most practical and computationally efficient tools being used in continuous space, reinforcement learning problems. Essentially, tile coding is a representation of features in continuous state space, and in this post you will:", "The simplest example is state aggregation that we learnt in the last post. Recall that in 1000-state random walk example, we grouped 1000 states into 10 groups, each with 100 states, so that we can represent each state in a binary format, that is for state inside a particular group, it is 1, else 0. In fact, this is tile coding in its simplest form, with only 1 component of state and 1 tiling(you can think it as a layer of representation).", "No doubt that it is flawed to represent a feature with only 1 tiling(you can think of it just as grids), so here comes multiple tilings and multi-dimensional features:", "In the graph shows the example of using tile coding in a 2D continuous state space. On the left of the graph, the state space is represented by 1 tiling, which essentially is just a 2D grid. Notice that the grey area is the feature space, and the 2D grid with blue lines is our tiling, which covers the whole state space area(it is not necessarily to tightly fit in the feature space). In this representation, the white spot, which is our state value, can be represented as 1 for the grid it belongs to and 0 for the rest.", "On the right, the representation is extended to multiple tilings, each with different offsets. Under this setting, the white spot is represented by 4 different tilings, the four different grids include the white spot in each tiling.", "From the graph, we can see that tile coding with only one tiling is essentially state aggregation, where a feature will be represented by only the tile it falls into, while multiple tilling extends the idea by representing a feature with multiple tiles belonging to each tiling. This extension is more powerful in the way that each state value may share some tiles and also belong to different tiles at the same time, which is the essence of generalisation.", "If you are still a bit confused by the idea, don\u2019t worry, in this session, we will get our hands dirty and implement a tiling coding step by step. (full implementation)", "Let\u2019s first create 1 tiling for 1 feature:", "I think this one-line function resolves most of your confusion by now. For example, given a feature with range of [0, 1], the function equally divides it into 10 bins, and the final grid is added by an offset of 0.2 . The tested result is shown at the bottom, ranging from 0.3 to 1.1 , and the coding of a value will be the order of the bin it falls into, for example, given a feature value of 0.35 , which falls in to the range of 0.3 to 0.4 , its coding would be 1 , and likewise, coding would be 0 for value less than 0.3 , and 9 for value larger than 1.1 .", "With the function able to create 1 tiling for 1 feature, let\u2019s extend it to multiple tilings for multiple features:", "Now the input feature_ranges will be a list of feature range of multiple features. bins is a list of bins setting on each tiling, and offset likewise. For example, suppose we have 2 features each with range [-1, 1] and [2, 5] , and we\u2019d like to create 3 tilings , each with a 2D grid of size 10x10 and different offset, then the result tiling shape would be (3, 2, 9) , representing n_tilings x n_features x (n_bins - 1) (notice that the number of bins is subtracted by 1 to ensure that for value larger than the range gets a coding of n_bins).", "The best way to think of it is as a cube, with the front side is a grid of feature values and the 3rd dimension is the number of tilings.", "Now that we have tilings ready, let\u2019s get the coding for each input feature values:", "For each tiling and each feature, this function get its coding on that dimension and concatenate the result in the end. With the tilings example we set above, give a feature of [0.1, 2.5] , its coding would be [5, 1] on first tiling(layer), [4, 0] on the second and [3, 0] on the last(notice that how offset plays an role here to distinguish a feature on different tilings).", "With tiling codings ready, it\u2019s time to put it in use with Q value functions. (Check out the full implementation here)", "This is a general form incorporating tile coding with Q function. In the init function, we defined a self.q_tables , in which each q_table has a size of n_bins x n_bins x n_actions , with n_tilings q tables. The idea is that given a state, action and target value, the action will help slice a specific tiling in each q table and that tiling value will be updated accordingly.", "The value function intakes a state, action and returns the value of it. One of the major advantages of tile coding is its computational efficiency. Recall the state aggregation example in random walk, the value of a given state is just the value of the bin that state belongs to, similarly, the value of a given state, action here equals to the sum of the tiles\u2019 value in each tiling(The reason the returned value is divided by num_tilings is that in the updating process each tiling is updated by the non-divided learning rate. If we set self.lr = lr/num_tilings , then the returned value will not need to be divided).", "In the update function, each tiling is updated with the temporal difference times a fixed learning rate as the derivative here is actually 1, and because the learning rate in the init function is not divided by number of tilings, the updated value added together approximate n_tilings*lr , thus need to be further divided in the value function.", "In this post, we together implemented a tiling coding and also learnt how to use it with a Q function. Comparing to parametric function approximations, tile coding discretised the continuous space, and makes the learning process computationally efficient by just getting the indices of active tiles and do some simple operations. Tile coding is a powerful tool and we will be using it to solve some more interesting examples in future posts.", "Lastly, thanks for following up, and if you have any questions, please leave comment below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Hmm\u2026I am a data scientist looking to catch up the tide\u2026"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7974b600762b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://meatba11.medium.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----7974b600762b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/reinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa", "anchor_text": "generalisation in continuous space"}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/TileCoding/tile_coding.py", "anchor_text": "full implementation"}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/TileCoding/tile_coding.py", "anchor_text": "here"}, {"url": "http://incompleteideas.net/book/the-book-2nd.html?source=post_page---------------------------", "anchor_text": "http://incompleteideas.net/book/the-book-2nd.html"}, {"url": "https://github.com/udacity/deep-reinforcement-learning/tree/master/tile-coding", "anchor_text": "https://github.com/udacity/deep-reinforcement-learning/tree/master/tile-coding"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7974b600762b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinf?source=post_page-----7974b600762b---------------reinf-----------------", "anchor_text": "Reinf"}, {"url": "https://medium.com/tag/python3?source=post_page-----7974b600762b---------------python3-----------------", "anchor_text": "Python3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----7974b600762b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----7974b600762b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7974b600762b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7974b600762b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7974b600762b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7974b600762b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7974b600762b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7974b600762b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7974b600762b--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://meatba11.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-tile-coding-implementation-7974b600762b&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}