{"url": "https://towardsdatascience.com/bayesian-nightmare-how-to-start-loving-bayes-1622741fa960", "time": 1683000847.9864142, "path": "towardsdatascience.com/bayesian-nightmare-how-to-start-loving-bayes-1622741fa960/", "webpage": {"metadata": {"title": "Bayesian nightmare. Solved!. Gentle introduction to Bayesian data\u2026 | by Michel Kana, Ph.D | Towards Data Science", "h1": "Bayesian nightmare. Solved!", "description": "Gentle introduction to Bayesian data analysis by examples and code in Python PyMC3. Estimating Signup Rate in a marketing campaign."}, "outgoing_paragraph_urls": [{"url": "https://books.google.cz/books/about/Bayesian_Data_Analysis_Third_Edition.html?id=ZXL6AQAAQBAJ&redir_esc=y", "anchor_text": "Recently", "paragraph_index": 5}, {"url": "https://gist.github.com/michelkana/d0f01cf38e2b0e158e1244b7eaedeb17", "anchor_text": "marketing data set", "paragraph_index": 19}, {"url": "https://docs.pymc.io", "anchor_text": "PyMC3", "paragraph_index": 28}, {"url": "https://books.google.cz/books/about/Bayesian_Data_Analysis_Third_Edition.html?id=ZXL6AQAAQBAJ&redir_esc=y", "anchor_text": "Bayesian Data Analysis from Andrew Gelman et. al.", "paragraph_index": 35}, {"url": "http://www.sumsar.net/about.html", "anchor_text": "Rasmus Baath", "paragraph_index": 36}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "DataCamp", "paragraph_index": 36}, {"url": "https://www.youtube.com/watch?v=3OJEae7Qb_o", "anchor_text": "videos on YouTube", "paragraph_index": 36}], "all_paragraphs": ["In this article, we provide a gentle and practical throughway to become at ease with Bayesian machine learning. Bayesian concepts such as priors, generative model, posterior distribution, Bayes theorem, credible intervals are introduced under the light of practical examples and illustrations. You will be applying the Bayesian approach to estimate signup rate in a marketing campaign using Python. Whereas the 20th century was dominated by null hypothesis significance testing, the 21st century is becoming Bayesian (source: JK Kruschke).", "If you don\u2019t start loving Bayes after reading this article, reach out to Laplace!", "Who has not heard that Bayesian statistics are difficult, computationally slow, cannot scale-up to big data, the results are subjective; and we don\u2019t need it at all? Do we really need to learn a lot of math and a lot of classical statistics first before approaching Bayesian techniques. Why do the most popular books about Bayesian statistics have over 500 pages?", "Bayesian nightmare is real or myth?", "Someone once compared Bayesian approach to the kitchen of a Michelin star chef with high-quality chef knife, a stockpot and an expensive sautee pan; while Frequentism is like your ordinary kitchen, with banana slicers and pasta pots. People talk about Bayesianism and Frequentism as if they were two different religions. Which cook are you? Does Bayes really put more burden on the data scientist to use her brain at the outset because Bayesianism is a religion for the brightest of the brightest? Is \u201cBayesian\u201d the right word after all?", "The essential characteristic of Bayesian methods is their explicit use of probability for quantifying uncertainty in inferences based on statistical data analysis. Recently, an increased emphasis has been placed on interval estimation rather than hypothesis testing. This provides a strong drive to the Bayesian viewpoint, because it seems likely that most users of standard confidence intervals give them Bayesian interpretation by common-sense. We recommend to go through our article below as a refresher about probabilities if needed.", "The Bayesian approach to data analysis typically requires data, a generative model and priors. In the classical approach, data is used to fit a linear regression line for example, in order to estimate the most suitable intercept and slope that best describe a linear trend. There is no direct way to include our prior belief about those parameters we are estimating. Bayesian approach allows us to make a prior good guess of the intercept and slope, based on our real-life domain knowledge and common sense. Additionally we can also make statements about how uncertain this guess is. We can say for example that, from experience, the slope is drawn from a normal distribution with mean \u03bc and standard deviation \u03c3, while typical intercept values will be normally distributed with mean \u03b8 and standard deviation \u03c1. Given the distributions, which describe our prior belief, we can generate simulated data using a generative model, as depicted in the image below.", "Let\u2019s consider a real life example, where we are interested in estimating the percentage of leads conversion in a sales funnel: how many visitors of a website turn into paying customers. Typically marketing would conduct a campaign to attract an audience and encourage them to sign-up. If we observe that out of 16 visitors, 6 of them sign-up, would that mean that the signup rate \u03b8 is 6/16=38%? How uncertain is this percentage, especially given the small set of data? Bayesian data analysis helps finding answers to those questions.", "We start by looking for priors, a belief from the sales department about the typical rate of sign-up they observed from experience or given the current state of the industry. Let\u2019s assume that, according to sales, any signup rate between 0% and 100% is equally likely. Therefore we can put a prior on the signup rate as a uniform distribution.", "Next, we build a generative model that simulates a high number of marketing campaigns for any randomly chosen signup rate from the prior distribution. For example, if 55% is chosen as signup rate, it is like asking 16 potential customers, where the chance of each customer signing up is 55%. Therefore, the generative model is a binomial distribution with parameters 16 and \u03b8. We simulate the generative model 100,000 times. Each time, we draw a random \u03b8 from the uniform distribution and we run the generative model by creating 16 \u201cfake\u201d customers from the binomial distribution. At the end of this process, we have 100,000 samples.", "Now, it is time to bring in our data that is telling us, what the true marketing campaign had achieved, this is 6/16=38% signup rate. Therefore, we filter out simulated samples where the simulated signup rate is not 6/16 and keep only those simulated samples where the simulated signup rate is 6/16. The process is visualized in the image below. Note that, the same prior draw (e.g. 21%) can generate different signup rates from the binomial distribution (e.g. 4/16 and 6/16).", "The image below illustrates the Bayesian sampling and rejection process.", "Now, we consider all the 100,000 draws of \u03b8 from the uniform distribution on one side, and on the other side, we look at the \u03b8 we kept after filtering those which did not produce samples with 6/16 signup rate. If we count the frequency of each value in both buckets, then we end up with the histograms below.", "The blue plot shows the so-called posterior distribution of signup rate. It is the answer we were looking for. As we can see, the signup rate is pretty uncertain, and we cannot say with 100% confidence that it is 38% as marketing found out. It is likely to be between 20% and 60%. Using the posterior distribution, we can deliver statements about uncertainty. The parameter value with the maximum likelihood to generate the data we observed will be the signup rate with the highest probability in the posterior distribution: 38%. This is also called maximum likelihood estimator, which is one of the most common ways of estimating unknown parameters in classical statistics. This is why the Bayesian approach can be seen as an extension of maximum likelihood estimation. We can also compute the mean of all probabilities, the posterior mean as a best guest of signup rate: 39%. It is also common to compute the shortest interval that contains 90% of the probabilities from the posterior distribution, called credible interval, which in this case goes between 30% and 40%. Therefore, we can say that, there is 90% probability that the signup rate is between 30% and 40%.", "6 signups out of 16 leads does NOT ALWAYS mean 38% signup rate!", "How did we go from the prior to the posterior? Let\u2019s look at it with an example, where we draw \u03b8=35% from the uniform distribution, with probability P(35%). In order to not throw \u03b8 away, it has to allow us to simulate data which match the data from marketing. In other words, with the probability P(6|35%) of having 6 signups given \u03b8=35%. By multiplying both quantities, we obtain the probability of drawing \u03b8=35% and simulating data that match the signup rate that we observed. This value will be proportional to the probability of 35% being the best parameter value that results in 6 observed signups. If we divide that quantity by the total probability of generating the data for all possible parameter values, we obtain the exact probability of having a signup rate of 35% given the data P(35%|6). When we repeat this procedure for all the signup rates, drawn from the prior distribution, we obtain all probabilities needed to draw the blue histogram, i.e. the posterior distribution. This process is illustrated in the image below.", "The exercise above can be extended to multiple parameters \u0398, to any generative model and to any dataset D. This generalization is illustrated by the equation below, commonly called Bayes Theorem.", "In order to illustrate the generalization of Bayesian data analysis, let\u2019s consider that the marketing department actually ran two campaigns. In the first, they got 6/16 signups, while the second resulted in 10/16 signups. Furthermore, the sales department came up with a prior belief that signup rate has never been higher than 20% and it uses to be between 5% and 15%. Now, we have two parameters \u03b81 and \u03b82 and two generative models. We are also given an informative prior that is not uniform, which we can represent by a Beta distribution with parameters 2 and 25, as illustrated below.", "We can now sample 100,000 samples from both generative models, retain those matching marketing data and build two posterior distributions, one for each campaign. The posterior distributions can be used to draw conclusions about the effectiveness of the campaigns, when taking the prior belief of salespeople into consideration. We can also compare both campaigns by calculating the difference between the two posterior distributions.", "After we feel more comfortable with the Bayesian philosophy, we are going to perform Bayesian linear regression on a more extended marketing data set, which describes leads conversion (y) versus time (x). In the plot below, x represents the number of weeks before and after launching a new company website at time x=0, with x=-10 being 10 weeks before launch, x=+10 being 10 weeks after launch. y represents the signup rate for positive values of y, or the churn rate for negative values of y. Churn happens when the website looses visitors. Marketing is interested in estimating the uncertainty around what signup rate or churn rate to expect in the future.", "As introduced in the previous sections, Bayesian statistics is a mathematical method that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. Bayes\u2019 theorem describes the conditional probability of an event based on data as well as prior information or beliefs about the event or conditions related to the event. Bayes\u2019 theorem can be used to calculate the posterior probability (which is the revised probability of an event occurring after taking into consideration new information). The posterior probability is calculated by updating the prior probability. The prior probability is the probability of an outcome based on the current knowledge before an experiment.", "Bayesian linear regression might allow a useful mechanism to deal with insufficient data, or poor distributed data as it appeared to be the case in the plot above. It allows us to put a prior on the parameters and on the noise so that in the absence of data, the priors can take over.", "In the Bayesian viewpoint, we formulate linear regression using probability distributions. The response y is not estimated as a single value, but is assumed to be drawn from a probability distribution.", "However, according to the linear regression equation, we believe that the most probable value for y is as follow.", "Even though \u03bc is the most probable value for y, y can also include some error or noise. Accordingly, we model such errors \u03f5 in the observations by adjusting the variance term \u03c3 to compensate for the deviations of y from \u03bc.", "Not only is the response generated from a probability distribution, but the model parameters are assumed to come from a distribution as well. The noise on y is assumed normally distributed, and we also include priors for the slope and intercept as follows.", "The posterior probability of the model parameters is conditional upon the training inputs and outputs:", "The equation above reflects again the Bayes theorem as we learnt before in a simpler example. The specific computation method we used so far for calculation the posterior probabilities by generating 100,000 samples and excluding those which do not match the data works only in rare cases. It is called Approximate Bayesian Computation. Although it is conceptually simple, it can be incredibly slow and scale horribly with large dataset. There are faster methods, mostly within the so-called Markov chain Monte Carlo (MCMC) family of algorithms. Specific popular examples include Hamiltonian Monte Carlo and Metropolis\u2013Hastings.", "Below we implement MCMC to find the posterior distribution of the model parameters using the Python library PyMC3.", "The Bayesian Model provides more opportunities for interpretation than the ordinary least squares regression because it provides a posterior distribution. Rather than a single point estimate of the model weights, Bayesian linear regression will give us a posterior distribution for the model weights. We can use this distribution to find the most likely single value as well as the entire range of likely values for our model parameters.", "PyMC3 has many built-in tools for visualizing and inspecting model runs. These let us see the distributions and provide estimates with a level of uncertainty, which should be a necessary part of any model. Below we see the trace for all model parameters. The trace plots tend to be normally distributed around the true parameters, what is a good sign that the samples converged towards the target distribution.", "The posterior distribution of model parameters is given below. Marketing can expect the signup rate (slope) to increase by 4.7% per year on average. There is 94% probability that the signup will increase by a rate between 4.4.% and 5.1% in the future. The signup rate at the moment of website launch (intercept at week 0) was between 4.6% and 7.2% with 94% probability. The standard deviation of signup rate is expected to be 6.6% on average.", "We can also visualize the credibility interval of model parameters. The rate of change in signups (slope) has less uncertainty than the signup rate at week 0.", "We can also generate predictions of the linear regression line using the model results. The following plot shows 100 different estimates of the regression line drawn from the posterior. The distribution of the lines gives an estimate of the uncertainty in the estimate. Bayesian Linear Regression has the benefit that it gives us a posterior distribution rather than a single point estimate in the frequentist ordinary least squares regression (OLS).", "In this article we provided a gentle introduction the Bayesian approach to statistics and machine learning. Especially we quantified uncertainty around point estimates of signup rate in a marketing campaign. Bayesian concepts such as priors, generative models, posterior distribution, Bayes theorem, credible intervals were introduced under the light of practical examples and illustrations. We also presented a Python implementation of linear regression using a Bayesian approach and compared it to the classical ordinary least squares method. The article offers few take-out on PyMC3, an easy to use Python library for Bayesian analysis.", "Rather than trying to cram too much into one article, you might redirect to books, such as Bayesian Data Analysis from Andrew Gelman et. al.", "This article was inspired by materials from Rasmus Baath, who instructs about Bayesian data analysis in a very intuitive way. I highly recommend his course at DataCamp about Fundamentals of Bayesian Data Analysis in R and his videos on YouTube.", "Well, this article has somehow already motivated readers to start loving Bayes. I would understand if you still prefer a non-Bayesian approach to machine learning. In this case you will get served by my article below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Husband & Dad. Mental health advocate. Top Medium Writer. 20 years in IT. AI Expert @Harvard. Empowering human-centered organizations with high-tech."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1622741fa960&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://michel-kana.medium.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Michel Kana, Ph.D"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb0b01fe20d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=post_page-cb0b01fe20d2----1622741fa960---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://faculty.washington.edu/kenrice/BayesIntroClassEpi2018.pdf", "anchor_text": "source"}, {"url": "https://books.google.cz/books/about/Bayesian_Data_Analysis_Third_Edition.html?id=ZXL6AQAAQBAJ&redir_esc=y", "anchor_text": "Recently"}, {"url": "https://towardsdatascience.com/understanding-probability-finally-576d54dccdb5", "anchor_text": "Understanding probability. Finally!Practical guide to probability concepts for data scientiststowardsdatascience.com"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "source"}, {"url": "http://faculty.washington.edu/kenrice/BayesIntroClassEpi2018.pdf", "anchor_text": "source"}, {"url": "https://gist.github.com/michelkana/d0f01cf38e2b0e158e1244b7eaedeb17", "anchor_text": "marketing data set"}, {"url": "https://docs.pymc.io", "anchor_text": "PyMC3"}, {"url": "https://books.google.cz/books/about/Bayesian_Data_Analysis_Third_Edition.html?id=ZXL6AQAAQBAJ&redir_esc=y", "anchor_text": "Bayesian Data Analysis from Andrew Gelman et. al."}, {"url": "http://www.sumsar.net/about.html", "anchor_text": "Rasmus Baath"}, {"url": "https://www.datacamp.com/courses/fundamentals-of-bayesian-data-analysis-in-r", "anchor_text": "DataCamp"}, {"url": "https://www.youtube.com/watch?v=3OJEae7Qb_o", "anchor_text": "videos on YouTube"}, {"url": "https://towardsdatascience.com/why-deep-learning-works-289f17cab01a", "anchor_text": "Why Deep Learning Works: solving a farmer\u2019s problemIn the beginning was the neuron: a gentle review of gradient descent, backpropagation, regression, autoencoder, CNNs\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1622741fa960---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1622741fa960---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----1622741fa960---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----1622741fa960---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1622741fa960---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----1622741fa960---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----1622741fa960---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1622741fa960&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1622741fa960---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1622741fa960--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1622741fa960--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1622741fa960--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1622741fa960--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1622741fa960--------------------------------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michel Kana, Ph.D"}, {"url": "https://michel-kana.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5.4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb0b01fe20d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=post_page-cb0b01fe20d2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F69e95067d2a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-nightmare-how-to-start-loving-bayes-1622741fa960&newsletterV3=cb0b01fe20d2&newsletterV3Id=69e95067d2a1&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}