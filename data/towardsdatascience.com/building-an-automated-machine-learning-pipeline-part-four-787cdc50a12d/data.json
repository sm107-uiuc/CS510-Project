{"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-four-787cdc50a12d", "time": 1683008914.521896, "path": "towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-four-787cdc50a12d/", "webpage": {"metadata": {"title": "Building an Automated Machine Learning Pipeline: Part Four | by Ceren Iyim | Towards Data Science", "h1": "Building an Automated Machine Learning Pipeline: Part Four", "description": "Automate your Machine Learning pipeline with Docker, Luigi and Python. Integrate and run each step of the Machine Learning Pipeline."}, "outgoing_paragraph_urls": [{"url": "https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/data_root/raw/wine_dataset.csv", "anchor_text": "a sample dataset", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35?source=friends_link&sk=8de05327eedb3d0dadcfa4b1a8e8cc75", "anchor_text": "the first article", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Docker_(software)", "anchor_text": "The official definition of Docker from Wikipedia", "paragraph_index": 14}, {"url": "https://www.geeksforgeeks.org/python-virtual-environment/", "anchor_text": "virtual environments", "paragraph_index": 16}, {"url": "https://hub.docker.com/search?q=python&type=image", "anchor_text": "Docker Hub", "paragraph_index": 25}, {"url": "https://pythonspeed.com/articles/base-image-python-docker-images/", "anchor_text": "select an existing Python Image that is suitable for your case", "paragraph_index": 25}, {"url": "https://luigi.readthedocs.io/en/stable/", "anchor_text": "The official definition from the docs", "paragraph_index": 33}, {"url": "https://www.datarevenue.com/en-our-team#the-team", "anchor_text": "the awesome engineers of Data Revenue", "paragraph_index": 51}, {"url": "https://luigi.readthedocs.io/en/stable/parameters.html", "anchor_text": "is not available as a parameter in the Luigi", "paragraph_index": 51}, {"url": "https://click.palletsprojects.com/en/7.x/", "anchor_text": "Click", "paragraph_index": 55}, {"url": "https://docs.docker.com/compose/", "anchor_text": "The official definition for Docker Compose from the Docker Docs", "paragraph_index": 58}, {"url": "https://towardsdatascience.com/5-reasons-to-use-yaml-files-in-your-machine-learning-projects-d4c7b9650f27", "anchor_text": "you use a YAML file", "paragraph_index": 59}, {"url": "https://docs.docker.com/compose/", "anchor_text": "here", "paragraph_index": 60}, {"url": "https://en.wikipedia.org/wiki/Shell_script", "anchor_text": "a shell script", "paragraph_index": 63}, {"url": "https://medium.com/u/87256f335321?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Serkan Durusoy", "paragraph_index": 73}, {"url": "https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model", "anchor_text": "the repository", "paragraph_index": 75}, {"url": "https://twitter.com/cereniyim", "anchor_text": "Twitter", "paragraph_index": 76}, {"url": "https://www.linkedin.com/in/ceren-iyim", "anchor_text": "Linkedin", "paragraph_index": 76}, {"url": "http://linkedin.com/in/ceren-iyim/", "anchor_text": "linkedin.com/in/ceren-iyim/", "paragraph_index": 79}, {"url": "http://github.com/cereniyim", "anchor_text": "github.com/cereniyim", "paragraph_index": 79}], "all_paragraphs": ["Disclaimer: This article series is not a tutorial about Docker and Luigi. It is the last article of an article series \u201cBuilding an Automated Machine Learning Pipeline\u201d that focuses on building end-to-end ML pipeline and showing how to automate it using certain elements of both tools. This article will make more sense to you if you read the previous ones from the links above.", "In this article series, we set our course to build a 9-step machine learning (ML) pipeline and automate it using Docker and Luigi.", "As a result of this pipeline, we built our ML solution and called it, the wine rating predictor because we are trying to infer the quality of wine represented with the points using a sample dataset. We defined the requirements for our wine rating predictor in the first article as:", "- understandable because our audience will likely have limited knowledge of statistics and ML.", "- performant because the complete production dataset could have millions of rows.", "- automated in a way that it can run on any production system without requiring specialized configurations and setups.", "We have so far satisfied the understandability and addressed performance \u2014 to some extent:", "Today, we will wear a software engineer\u2019s hat and address the last requirement \u2014 automation. We will take the steps below from the ML pipeline, run them on Docker Containers and connect them with Luigi Tasks. (Don\u2019t worry we will elaborate on them throughout the article \ud83d\ude42)", "If you have noticed we have two additional steps because a typical real-world ML pipeline starts with getting the data from a source. Also, we included the training-test dataset split and the rest is the known steps of the ML pipeline.", "To run the flow above, we will first look at Docker and Luigi and understand their use in the context of this article series. Therefore, we will start by explaining these tools and their necessary elements.", "Then, we will connect the dots using these tools. Eventually, we will put the pieces together and run the flow which will accomplish our mission of automation!", "You can find the GitHub Repository here:", "One more disclaimer before we start:", "Disclaimer: Structure of the repository and download_data.py , util.py , docker-clean.sh and docker-compose.yml files are provided to me as the basis of the code challenge. Rest of the code is written by me.", "The official definition of Docker from Wikipedia is as follows:", "Docker is a set of platform as a service products that uses operating system-level virtualization to deliver software in packages called containers.", "I would define it as creating virtual environments for your application/software/data science/ML projects so that it can run seamlessly on any system that has Docker.", "Via containers. They are isolated virtual environments to run your applications, for our case, ML solutions.", "From images. They are templates that are used to create containers. They contain information about your underlying operating system, environment and libraries \u2014 with versions.", "By reading the instructions from a Dockerfile. It is a set of instructions and commands that a user could call on the command line to create an image. You can create a local image in your system with the docker build Dockerfile -t <image_name> command.", "Containers are the running instances of images. When you run an image you create a container that is an isolated environment.", "We used Docker to build virtual environments and manage the dependencies of the libraries so that we can run the flow seamlessly. The automation flow below is designed so that each box runs on a separate Docker container.", "I am sure you have noticed some directories and files in the repository that we haven\u2019t mentioned yet. You can think of download_data, make_dataset, clean_data, extract_features, transform_data, impute_data, train_model and evaluate_model directories as the boundaries of the boxes in the automation flow that contains a Dockerfile and the source code as a Python file.", "Before looking at how to create a Dockerfile, let\u2019s understand the use of base_docker here.", "Each step of the automation flow runs on a separate container. However, they are modules written in Python and the only difference between them are the libraries used. So, base_docker is used to specify the common environment variables and install the required Python version and the libraries. It also contributed to the performance of the wine rating predictor by installing required packages once rather than installing them every time on a separate container.", "When creating a Dockerfile start by the steps as if you are creating a local environment on your machine. Considering your aim is to deploy an ML solution with Python, you can build your image on top of an existing Python Image in the Docker Hub. An important point here is to select an existing Python Image that is suitable for your case since there are several versions and sizes are available.", "slim variant is chosen and Python version 3.7 is specified, same Python version as in my local system.", "ENV command is used to update the PATH environment variable for the underlying operating system (Python 3.7-slim for our case) that your container installs.", "Libraries with the versions mentioned in the requirements.txt are copied and installed with the pip_install. In addition to the aforementioned libraries of Python, click is also installed \u2014 more on the use of that later.", "As the last instruction, the working directory of a Docker Container is defined with the WORKDIR command.", "Now, our base_docker is ready, exploring any Dockerfile from the automation flow will be sufficient because all other Dockerfiles have been written with the same logic. Here is an example from clean_data:", "Now our base image become the base_docker. Every file in the clean_data directory is copied and a working directory of a Docker container is created.", "It is time to have a look at Spotify\u2019s beloved Luigi!", "The official definition from the docs is as follows:", "Luigi is a Python package that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization, handling failures, command line integration, and much more.", "It is basically an orchestration tool to stitch many tasks together in a directed acyclic graph (DAG) structure:", "When you build an ML solution and as the scale grows, this can easily become complex and messy. Luigi is a robust workflow management tool that can prevent chaos and complexity.", "There are two fundamental building blocks of Luigi: Task and Target", "The steps of a workflow are tasks, usually a single unit of work, where computations are done. A Luigi workflow is built on top of tasks.", "Each task is connected with a target. A target can be a file, a checkpoint in the workflow or any kind of output generated by the task.", "We are dumping outputs generated by each task in the data_root:", "In the flow, each task is dependent on the output of the previous task except the initial task download_data. Each file is passed as a Parameter so that it can be consumed by the latter step in the workflow.", "When designing a workflow, Luigi recommends the atomic structure: Each task should have a single file as output like in the download_data and train_model tasks.", "For the rest of the tasks, we imitate atomicity with the SUCCESS flag. When we perform computations on both training and test datasets, we create a SUCCESS flag as an output of the task, after dumping the output files in the directory. This way, the next task only checks whether a SUCCESS flag exists.", "Task dependencies are defined with the requires() method. Here is a task outline from Luigi documentation:", "For our case, task dependencies are obvious since we defined a linear automation flow.", "Unfortunately, Luigi does not come with a triggering mechanism. If you want to run a Luigi workflow you use the command line specifying the module name and the last task in the project directory:", "When a workflow is triggered, Luigi checks if the output of the last step exists. If not, then it checks backwards if the outputs of the predecessor steps exist. For our case, this would be train_model, impute_data, transform_data, extract_features, clean_data, make_dataset and download_data .", "If an output of a task from any step of the flow exists Luigi resumes the flow where it has left of. This is a very useful and important trait to prevent your ML pipeline from crashing when it contains partial data.", "Now we know the essential elements of Luigi and Docker we can move forward with completing the picture!", "We will put the pieces of Docker and Luigi in the docker-compose.yml and orchestrator directory.", "The utility functions provided by the awesome engineers of Data Revenue has enabled me to connect the pieces of Docker and Luigi. Functions and classes available in the util.py played an important role that connected Docker and Luigi for the wine rating predictor. For example, DockerTask \u2014 the object that we pass as a parameter between the tasks \u2014 is not available as a parameter in the Luigi normally.", "First, let\u2019s have a look at task.py in the orchestrator directory where I built the automation flow using utilities. Then, let\u2019s understand the purpose of docker-compose.yml.", "Recall that source codes for each step of the flow is available in the respective directory as Python file. Let\u2019s have a look at the source code of train_model :", "After defining the helper functions convert_features_to_array and convert_target_to_array, we defined necessary click commands.", "Click, as defined in the official documentation:", "It is a Python package for creating beautiful command line interfaces in a composable way with as little code as necessary.", "We used Click to be able to pass the arguments to the python scripts from the command line. Finally, we train the model with the fine-tuned parameters that we have decided in the Perform Hyperparameter Tuning on the Selected Model step on the training dataset. Finally, we save the trained model in model.sav file as an output.", "The official definition for Docker Compose from the Docker Docs is as follows:", "Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application\u2019s services. Then, with a single command, you create and start all the services from your configuration.", "This definition suits to our case since we run the automation flow on 9 containers including base_docker. You can read more about the use and commands of docker-compose here.", "The important part for us here the command to run Luigi tasks is written here, so when we run containers through docker-compose, it will trigger the automation flow with the luigi \u2014 module task EvaluateModel-scheduler-host luigiid command.", "This is the moment of truth! We are going to run the automation flow and automate the 9-Step ML Pipeline. It is the last of the last step, stick with it for one more minute \ud83d\ude09", "Instead of building multiple Docker Containers one by one, we are going to use a shell script to build Docker Containers: build-task-images.sh", "The below message shows that Containers are built successfully. So we are good to go for triggering automation flow.", "We will trigger the workflow with", "Upon writing this command, Luigi checks whether each task is complete and outputs the following information:", "Then runs the task in one by one. Another important information for us is:", "After a successful run you see a \ud83d\ude42:", "Bonus Points: Let\u2019s see how Luigi resumes the flow where it has left ofLet\u2019s say you prepared training datasets and run the automation flow, then you will build the next steps afterwards starting with the training the model. Luigi won\u2019t repeat successfully run previous steps and only runs TrainModel and EvaluateModel tasks in that case.", "It was quite a journey spanning over 4 articles and a month \u26f5\ufe0f", "We started from the very beginning and analyzed every step of the 9-step ML pipeline through the first, second and third article.", "In this last article, we introduced the relevant elements of Docker and Luigi and explained their importance and use for the wine rating predictor. We completed the last missing piece of our comprehensive pipeline and did a dry run of an ML solution \u2014 just as if it runs on production systems.", "I think it is time to thank my significant other Serkan Durusoy. He has been the most precious mentor, editor and study buddy I had in my data science expedition!", "He helped me to overcome the ups and downs of changing a career. Also, I want to acknowledge his support to complete this article series as well as the grit he provided for me. Thank you, my dear \u2764\ufe0f", "Thanks for reading \ud83d\ude42 Please feel free to use this pipeline, the code and the repository for your own projects.", "For comments or constructive feedback, you can reach out to me on responses, Twitter or Linkedin!", "Before we go, I also want to share some of the useful resources that I used to prepare for this project. See you in the next article \ud83d\udc4b", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer and Data Scientist | linkedin.com/in/ceren-iyim/ | github.com/cereniyim"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F787cdc50a12d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@cereniyim?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cereniyim?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Ceren Iyim"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F287e9909d3b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&user=Ceren+Iyim&userId=287e9909d3b5&source=post_page-287e9909d3b5----787cdc50a12d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/machine-learning/home", "anchor_text": "MACHINE LEARNING"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35?source=friends_link&sk=8de05327eedb3d0dadcfa4b1a8e8cc75", "anchor_text": "Part 1: Understand, clean, explore, process data"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-two-1d3c86e6fe42?source=friends_link&sk=a005d5ead7a844adb7819403ddc6dc0e", "anchor_text": "Part 2: Set metric and baseline, select and tune model"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-a74acda76b98?source=friends_link&sk=1790d8dd404126a45828c3905f47432c", "anchor_text": "Part 3: Train, evaluate and interpret model"}, {"url": "https://unsplash.com/@ekrull?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Eric Krull"}, {"url": "https://unsplash.com/collections/10621375/medium-ejcuhcdfwrs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/data_root/raw/wine_dataset.csv", "anchor_text": "a sample dataset"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35?source=friends_link&sk=8de05327eedb3d0dadcfa4b1a8e8cc75", "anchor_text": "the first article"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-two-1d3c86e6fe42?source=friends_link&sk=a005d5ead7a844adb7819403ddc6dc0e", "anchor_text": "in the second"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-a74acda76b98?source=friends_link&sk=1790d8dd404126a45828c3905f47432c", "anchor_text": "third article"}, {"url": "https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model", "anchor_text": "cereniyim/Wine-Rating-Predictor-ML-ModelIn this project, I built a wine rating predictor for an online wine seller. This wine predictor aims to show good\u2026github.com"}, {"url": "https://en.wikipedia.org/wiki/Docker_(software)", "anchor_text": "The official definition of Docker from Wikipedia"}, {"url": "https://www.geeksforgeeks.org/python-virtual-environment/", "anchor_text": "virtual environments"}, {"url": "https://hub.docker.com/search?q=python&type=image", "anchor_text": "Docker Hub"}, {"url": "https://pythonspeed.com/articles/base-image-python-docker-images/", "anchor_text": "select an existing Python Image that is suitable for your case"}, {"url": "https://luigi.readthedocs.io/en/stable/", "anchor_text": "The official definition from the docs"}, {"url": "https://en.wikipedia.org/wiki/Directed_acyclic_graph", "anchor_text": "Wikipedia"}, {"url": "https://luigi.readthedocs.io/en/stable/tasks.html", "anchor_text": "luigi.readthedocs.io"}, {"url": "https://www.datarevenue.com/en-our-team#the-team", "anchor_text": "the awesome engineers of Data Revenue"}, {"url": "https://luigi.readthedocs.io/en/stable/parameters.html", "anchor_text": "is not available as a parameter in the Luigi"}, {"url": "https://click.palletsprojects.com/en/7.x/", "anchor_text": "Click"}, {"url": "https://click.palletsprojects.com/en/7.x/", "anchor_text": "click.palletsprojects.com"}, {"url": "https://docs.docker.com/compose/", "anchor_text": "The official definition for Docker Compose from the Docker Docs"}, {"url": "https://towardsdatascience.com/5-reasons-to-use-yaml-files-in-your-machine-learning-projects-d4c7b9650f27", "anchor_text": "you use a YAML file"}, {"url": "https://docs.docker.com/compose/", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Shell_script", "anchor_text": "a shell script"}, {"url": "https://github.com/datarevenue-berlin/code-challenge-2019/releases/download/0.1.0/dataset_sampled.csv", "anchor_text": "https://github.com/datarevenue-berlin/code-challenge-2019/releases/download/0.1.0/dataset_sampled.csv"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35", "anchor_text": "Building an Automated Machine Learning Pipeline: Part OneData Cleaning, Exploratory Data Analysis and Feature Engineering stepstowardsdatascience.com"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-two-1d3c86e6fe42", "anchor_text": "Building an Automated Machine Learning Pipeline: Part TwoSetting the Evaluation Metric & Establishing a Baseline, Selecting the Algorithm and Performing Hyperparameter Tuning\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-a74acda76b98", "anchor_text": "Building an Automated Machine Learning PipelineTraining and evaluating the model, interpretation of model results and final conclusionstowardsdatascience.com"}, {"url": "https://medium.com/u/87256f335321?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Serkan Durusoy"}, {"url": "https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model", "anchor_text": "the repository"}, {"url": "https://twitter.com/cereniyim", "anchor_text": "Twitter"}, {"url": "https://www.linkedin.com/in/ceren-iyim", "anchor_text": "Linkedin"}, {"url": "https://www.datarevenue.com/en-blog/how-to-scale-your-machine-learning-pipeline", "anchor_text": "Scale Your Machine Learning Pipeline"}, {"url": "https://www.datarevenue.com/", "anchor_text": "Data Revenue"}, {"url": "https://www.youtube.com/watch?v=zJ6WbK9zFpI&t=659s", "anchor_text": "Docker for Beginners: Full Course"}, {"url": "https://www.youtube.com/channel/UCSWj8mqQCcrcBlXPi4ThRDQ", "anchor_text": "KodeKloud"}, {"url": "https://towardsdatascience.com/build-a-docker-container-with-your-machine-learning-model-3cf906f5e07e", "anchor_text": "Build a Docker Container with Your Machine Learning Model"}, {"url": "https://medium.com/u/e2511f99cdfc?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Tina Bu"}, {"url": "https://luigi.readthedocs.io/en/stable/index.html", "anchor_text": "Luigi Documentation"}, {"url": "https://docs.docker.com/get-started/", "anchor_text": "Docker Documentation"}, {"url": "https://intoli.com/blog/luigi-jupyter-notebooks/", "anchor_text": "Building Data Science Pipelines With Luigi and Jupyter Notebooks"}, {"url": "https://mattiaciollaro.github.io/", "anchor_text": "Mattia Ciollaro"}, {"url": "https://medium.com/tag/docker?source=post_page-----787cdc50a12d---------------docker-----------------", "anchor_text": "Docker"}, {"url": "https://medium.com/tag/luigi?source=post_page-----787cdc50a12d---------------luigi-----------------", "anchor_text": "Luigi"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----787cdc50a12d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----787cdc50a12d---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----787cdc50a12d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&user=Ceren+Iyim&userId=287e9909d3b5&source=-----787cdc50a12d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&user=Ceren+Iyim&userId=287e9909d3b5&source=-----787cdc50a12d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F787cdc50a12d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----787cdc50a12d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----787cdc50a12d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----787cdc50a12d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----787cdc50a12d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cereniyim?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cereniyim?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ceren Iyim"}, {"url": "https://medium.com/@cereniyim/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "504 Followers"}, {"url": "http://linkedin.com/in/ceren-iyim/", "anchor_text": "linkedin.com/in/ceren-iyim/"}, {"url": "http://github.com/cereniyim", "anchor_text": "github.com/cereniyim"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F287e9909d3b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&user=Ceren+Iyim&userId=287e9909d3b5&source=post_page-287e9909d3b5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff788c50c2bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-automated-machine-learning-pipeline-part-four-787cdc50a12d&newsletterV3=287e9909d3b5&newsletterV3Id=f788c50c2bf3&user=Ceren+Iyim&userId=287e9909d3b5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}