{"url": "https://towardsdatascience.com/building-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2", "time": 1682996889.3056, "path": "towardsdatascience.com/building-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2/", "webpage": {"metadata": {"title": "Building an ML application using MLlib in Pyspark | by Yashwanth Madaka | Towards Data Science", "h1": "Building an ML application using MLlib in Pyspark", "description": "Apache Spark is one of the on-demand big data tools which is being used by many companies around the world. Its ability to do In-Memory computation and Parallel-Processing are the main reasons for\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.informit.com/articles/article.aspx?p=2928186", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167", "anchor_text": "link", "paragraph_index": 22}, {"url": "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html", "anchor_text": "SMOTE", "paragraph_index": 39}, {"url": "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html", "anchor_text": "link", "paragraph_index": 40}, {"url": "https://github.com/jpmml/pyspark2pmml", "anchor_text": "https://github.com/jpmml/pyspark2pmml", "paragraph_index": 53}, {"url": "https://github.com/yashwanthmadaka24/Stroke-Classification---Decision-Tree", "anchor_text": "here", "paragraph_index": 64}, {"url": "http://localhost:8080/openscoring/model/stroke", "anchor_text": "http://localhost:8080/openscoring/model/stroke", "paragraph_index": 72}, {"url": "https://github.com/yashwanthmadaka24/React-Js-Website", "anchor_text": "Github link", "paragraph_index": 74}, {"url": "https://chrome.google.com/webstore/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf?hl=en", "anchor_text": "chrome extension", "paragraph_index": 76}], "all_paragraphs": ["Apache Spark is one of the on-demand big data tools which is being used by many companies around the world. Its ability to do In-Memory computation and Parallel-Processing are the main reasons for the popularity of this tool.", "MLlib is a scalable Machine learning library which is present alongside other services like Spark SQL, Spark Streaming and GraphX on top of Spark.", "In this article, we are going to concentrate on a dataset called Stroke dataset. Stoke is a condition in which either the blood flow to the brain stops or blood flow is excessive. The risk factors of stroke are", "The dataset contains almost all the risk factors of the stroke mentioned above. Hence it is important to choose a dataset with appropriate risk factors.", "We are going to change the string values of the columns into a numerical values. The reason for this will be explained later. Using replace function in Excel, I had changed the dataset into the below", "The below image showcases a brief architecture of our whole project.", "Google cloud has a service called Dataproc which is used to create clusters which come preinstalled with Apache Spark. We can resize our clusters anytime we want to. Google cloud provides free $300 credit as an introductory offer. So, we will be using these free credits to set up our cluster.", "Click on \u2018Activate\u2019 to get the free $300 credit.", "Select your country and click on \u201ccontinue\u201d. In the next page, you will be prompted to enter your billing details and credit or debit card details. Fill them and click the bottom button.", "Console page will be opened. On top of the page, type Dataproc in the search bar and the above page will be opened. Click on create a cluster to start creating a cluster.", "Make sure you enter the same above settings. Click on Advanced options and follow the above image settings and click on create. It might take 2 to 3 mins to create a cluster.", "Navigate to the cluster and click on VM instances. Under the VM instances, we can see that a master node and two worker nodes are created. The role of the master node is it usually requests the resources in the cluster and makes them available to the spark driver. It monitors and tracks the status of worker nodes whose work is to host the executor process which stores output data from tasks and also hosts the JVM. A detailed description can be found here", "Now click on the SSH button of the master node.", "A new terminal is opened in a new chrome tab. This is the command line interface through which we can interact with our cluster. Type \u201cpyspark\u201d to check the installation on spark and its version. Make sure the version of spark is above 2.2 and python version is 3.6.", "Now to setup jupyter notebook, we need to create a firewall rule. Follow the images to setup new firewall rule. Make sure you select \u201cAllow all\u201d in the protocols and ports.", "Click on save and navigate to \u201cExternal IP addresses\u201d.", "change the TYPE of \u2018spark-cluster-m\u2019 to static. Give any name and click on \u201cRESERVE\u201d.", "Now navigate to \u201cSSH\u201d and type the below commands.", "copy the below lines and paste it. Press CTRL+o, Enter, CTRL+x.", "Now we can open jupyter notebook by below command", "type the above command in the SSH and then open a new tab and type \u201chttps://localhost:5000\u201d in your google chrome to open Jupyter notebook. In my case, the localhost is 35.230.35.117", "Before going into this section, we need to install a few external libraries.", "We need Imblearn library to perform SMOTE as our dataset is highly imbalanced. More information about smote can be found in this link.", "and then type the below line", "exit from the root folder and then open Jupyter notebook. Let\u2019s start coding.", "Now we need to create a spark session.", "We need to access our datafile from storage. Navigate to \u201cbucket\u201d in google cloud console and create a new bucket. I had given the name \u201cdata-stroke-1\u201d and upload the modified CSV file.", "Now we need to load the CSV file which we had uploaded in our bucket.", "We can check our dataframe by printing it using the command shown in the below figure.", "Now, we need to create a column in which we have all the features responsible to predict the occurrence of stroke.", "Make sure all the columns are in double values. Next, let's remove all the entries which are under age below 2.", "Now let's print a bar graph to check the type of classes present in our data", "Now, it's very important to do proper missing data management to get a very good model at the end. It's not always good to use \u201cdf.na.drop()\u201d which removes all the rows which have missing data. Filling them with proper reasonable values is one idea which we can implement.", "As we can see, we have missing values in BMI column and Smoking history column. One possible way to fill up these BMI values is to use the Age values to fill them up.", "For smoking history, it is very difficult to find reasonable values to fill them up. Usually, people below 16 years are not that addicted to smoking and hence we can fill up the values of those age group people with 0. People between age 17 to 24 might have tried smoking at least once in their life and so we can give 0.25 value to those people. Now a few people after a certain age quit and few of them still continue even though they have health problems. We cannot decide which value to give to them and so by default, we will give assign the value 0 to them.", "We can either drop all the rows which have missing values in these columns or we can fill in those by the above logic. But for the purpose of this tutorial, I had filled the missing rows by the above logic but practically tampering with the data with no data-driven logic to back it up is usually not a good idea.", "We are going to perform a few operations on this dataframe and spark dataframe doesn\u2019t support any operations. So we replicate our dataframe to pandas dataframe and then perform the actions.", "We will be dividing the full dataframe into many dataframes based on the age and fill them with reasonable values and then, later on, combine all the dataframes into one and convert it back to spark dataframe.", "Step 3B. Dealing with imbalanced data", "We will perform SMOTE technique to deal with imbalanced data. SMOTE can be referred from here:", "Please refer to this link to know about the parameters", "X_train contains all the columns of the data except the Stroke column.", "Y_train contains the Stroke column data.", "Combine the resampled data into one spark dataframe", "change it back to spark dataframe", "Check the Resampled data. Its the same code we used earlier.", "As we can see, we resampled our data successfully. Now we will be getting into the next part.", "Below is a common pipeline of a spark ml project except in our case we had not used string indexer and oneHotEncoder.", "Now to build an assembler and for this, we need a Binarizer.", "What this does is it creates a new column with name \u201clabel\u201d and values the same as the values in stroke column.", "Assembler assembles all the columns which are required to predict stroke and produces one vector called features.", "And now over to Splitting Data", "As we can see, we got the score of AUC-ROC around 98 which is very good. The model might be overfitted due to the usage of SMOTE technique. (But Logistic Regression works well for this dataset. But there seem to be some bugs in pyspark2pmml library which doesn\u2019t export the logistic regression model properly.) So for demonstration purpose I am going to use Decision Tree model file.", "To do this, we are going to use a library called PySPark2PMML and its details can be found here (https://github.com/jpmml/pyspark2pmml)", "Save the jupyter file and exit the jupyter notebook.", "After upload, if we check by running \u201cls\u201d command we see our file.", "Now we need to setup jupyter notebook in such a way that when we type pyspark in the ssh, we need to fire open jupyter notebook. To do so, we need to change the environment variable.", "add the below lines to your ~/.bashrc (or ~/.zshrc) file. Press \u201ci\u201d to insert the new lines. Copy the below code and paste it using \u201cCTRL+V\u201d.", "To save and exit the vi editor, press \u201cESC\u201d and \u201c:wq\u201d to save it.", "Restart your terminal and then type \u201cpyspark\u201d. You should be able to run jupyter notebook.", "You should be able to see the port number in one of the lines.", "Now to use the pmml library, open jupyter notebook by calling with the below command.", "After opening the jupyter notebook, run all the cells which we had written earlier. Now, add the below piece of code.", "After running the above code, a new file will be created at the location mentioned. Download this file to your local desktop and let\u2019s start building a website to interact with our model file.", "The entire jupyter notebook can be found here.", "Step 6a. Building a REST server from our model files:", "For an application to interact with the model file, we need to expose the application as a REST web service. To do this, we are going to use the help of Openscoring library.", "We need to install Openscoring using maven. Make sure you place the model file which we downloaded from our Google clouds VM machine into PATH/openscoring/openscoring-client/target folder.", "where PATH = the path where the openscoring files exist.", "After installation, we need to start the server by following the below commands.", "First, start a server by going into the server folder and type the commands below", "Next, start the client side by going to the client folder and type the below commands. Next, open a new cmd and type the below commands.", "When we visit the http://localhost:8080/openscoring/model/stroke we can see the below structure", "Step 6b. Downloading the ReactJS Frontend and running it:", "Now visit the this Github link and clone this project.", "After downloading, open this project folder using the VS Code. Open the terminal inside and type", "Before starting our ReactJS application, we need to enable CORS. To do this, we can add a chrome extension.", "After switching on the CORS, type the below command in VS Code terminal.", "A web interface will open as shown below.", "We can input any values and test it. We will get the prediction, the probability of occurrence of stroke and the probability of non-occurrence of stroke.", "All the methods of interacting with the REST server are coded in the index.js file.", "Reality model scores of 98 are impossible to achieve and the main significance of this blog is to show how to interact with ML models made in pyspark.", "The better is our data preprocessing, the better will be our model. The quality of the model directly depends on the quality and diversity of the data we use. So, it\u2019s better to spend more time doing proper data cleaning and data filtering techniques.", "And now, its time for a break \ud83d\ude07", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac13f01606e2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@yashwanthmadaka?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yashwanthmadaka?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Yashwanth Madaka"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1304f337a5b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&user=Yashwanth+Madaka&userId=1304f337a5b0&source=post_page-1304f337a5b0----ac13f01606e2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://bigml.com/user/francisco/gallery/model/508b2008570c6372100000b1#info", "anchor_text": "https://bigml.com/user/francisco/gallery/model/508b2008570c6372100000b1#info"}, {"url": "http://www.informit.com/articles/article.aspx?p=2928186", "anchor_text": "here"}, {"url": "https://www.youtube.com/redirect?event=comments&stzid=UgwMLhVicKWXmwMzyJ54AaABAg&q=http%3A%2F%2Fconfig.py%2F&redir_token=7XHzrHJ0cqu2HG4iRpSCumF2asJ8MTU2MDUzMTgyMEAxNTYwNDQ1NDIw", "anchor_text": "config.py"}, {"url": "https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167", "anchor_text": "link"}, {"url": "https://dqydj.com/bmi-distribution-by-age-calculator-for-the-united-states/", "anchor_text": "https://dqydj.com/bmi-distribution-by-age-calculator-for-the-united-states/"}, {"url": "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html", "anchor_text": "SMOTE"}, {"url": "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html", "anchor_text": "link"}, {"url": "https://github.com/jpmml/pyspark2pmml", "anchor_text": "https://github.com/jpmml/pyspark2pmml"}, {"url": "https://github.com/jpmml/jpmml-sparkml/releases", "anchor_text": "https://github.com/jpmml/jpmml-sparkml/releases"}, {"url": "https://github.com/yashwanthmadaka24/Stroke-Classification---Decision-Tree", "anchor_text": "here"}, {"url": "http://localhost:8080/openscoring/model/stroke", "anchor_text": "http://localhost:8080/openscoring/model/stroke"}, {"url": "http://localhost:8080/openscoring/model/stroke", "anchor_text": "http://localhost:8080/openscoring/model/stroke"}, {"url": "https://github.com/yashwanthmadaka24/React-Js-Website", "anchor_text": "Github link"}, {"url": "https://chrome.google.com/webstore/detail/allow-cors-access-control/lhobafahddgcelffkeicbaginigeejlf?hl=en", "anchor_text": "chrome extension"}, {"url": "https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167", "anchor_text": "https://medium.com/coinmonks/smote-and-adasyn-handling-imbalanced-data-set-34f5223e167"}, {"url": "https://github.com/jpmml/pyspark2pmml", "anchor_text": "https://github.com/jpmml/pyspark2pmml"}, {"url": "https://github.com/openscoring/openscoring", "anchor_text": "https://github.com/openscoring/openscoring"}, {"url": "https://github.com/yashwanthmadaka24/React-Js-Website", "anchor_text": "https://github.com/yashwanthmadaka24/React-Js-Website"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----ac13f01606e2---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ac13f01606e2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/google-cloud-platform?source=post_page-----ac13f01606e2---------------google_cloud_platform-----------------", "anchor_text": "Google Cloud Platform"}, {"url": "https://medium.com/tag/spark?source=post_page-----ac13f01606e2---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/reactjs?source=post_page-----ac13f01606e2---------------reactjs-----------------", "anchor_text": "Reactjs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&user=Yashwanth+Madaka&userId=1304f337a5b0&source=-----ac13f01606e2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&user=Yashwanth+Madaka&userId=1304f337a5b0&source=-----ac13f01606e2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac13f01606e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac13f01606e2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac13f01606e2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac13f01606e2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac13f01606e2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yashwanthmadaka?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@yashwanthmadaka?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yashwanth Madaka"}, {"url": "https://medium.com/@yashwanthmadaka/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "223 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1304f337a5b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&user=Yashwanth+Madaka&userId=1304f337a5b0&source=post_page-1304f337a5b0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Faf4bc4baac86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-ml-application-with-mllib-in-pyspark-part-1-ac13f01606e2&newsletterV3=1304f337a5b0&newsletterV3Id=af4bc4baac86&user=Yashwanth+Madaka&userId=1304f337a5b0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}