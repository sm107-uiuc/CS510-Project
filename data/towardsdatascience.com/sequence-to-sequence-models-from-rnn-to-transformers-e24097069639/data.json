{"url": "https://towardsdatascience.com/sequence-to-sequence-models-from-rnn-to-transformers-e24097069639", "time": 1683013504.638547, "path": "towardsdatascience.com/sequence-to-sequence-models-from-rnn-to-transformers-e24097069639/", "webpage": {"metadata": {"title": "Sequence-to-Sequence Models: Encoder-Decoder using Tensorflow 2 | by Nahid Alam | Towards Data Science", "h1": "Sequence-to-Sequence Models: Encoder-Decoder using Tensorflow 2", "description": "Sequence-to-sequence models are fundamental Deep Learning techniques that operate on sequence data. It converts sequence from one domain to sequence in another domain [1]. These models can be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/nahidalam/", "anchor_text": "LinkedIn", "paragraph_index": 3}, {"url": "https://twitter.com/nahidalam", "anchor_text": "https://twitter.com/nahidalam", "paragraph_index": 18}], "all_paragraphs": ["Sequence-to-sequence models are fundamental Deep Learning techniques that operate on sequence data. It converts sequence from one domain to sequence in another domain [1]. These models can be RNN-based simple encoder-decoder network or the advanced attention-based encoder-decoder RNN or the state-of-the-art transformer models. There are many applications of sequence-to-sequence models such as \u2014 machine translation, speech recognition, text summarization, question answering, demand forecasting, and so on.", "This article is part \u2014 1 of a three-part article on sequence-to-sequence models where we focus on building a machine translation system. In this part, we will focus on the inner workings on an RNN based encoder-decoder network. To illustrate, we will build a Spanish to English translation model.", "The focus of this article is on model architecture, training, and the inference process using Tensorflow 2.0. Therefore, we will leave out the discussion on data preparation. As a reference, you can follow the Tensorflow tutorial [2] for the data preparation part. If you are new to Tensorflow 2.0, you may want to pay special attention to the create a tf.data dataset section [2]", "If you find this article interesting, feel free to connect on LinkedIn.", "Intuitively, an encoder encodes the input and a decoder will decode it to the desired domain. In our case, the encoder will encode the input Spanish sentences and the decoder will decode them to the English language. In a Recurrent Neural Network (RNN) based architecture, the encoder and decoder are both RNN or one of its variants such as LSTM or GRU. In this article, we are going to use a GRU unit.", "A critical concept in sequence-to-sequence model is to understand how the training and inference model differs. And it is about the decoder. How we feed input to the decoder during the inference time is different from the training time. You can probably understand intuitively that during inference time, we don\u2019t know the target translated word. So the decoder will be feed with the output of the previous time step. Off course, for the very 1st timestep, the decoder is given start-of-sequence (SOS).", "We will use Tensorflow 2 to build an Encoder class. First, make sure you import the necessary library", "The Encoder and Decoder class will both inherit from tf.keras.Model. At a minimum, these classes will have two methods \u2014 an initializer __init__ method and a call method. The call method is executed during the forward pass of your network. If you are familiar with Pytorch, you are probably familiar with this style of defining a model.", "In the Encoder class, we will also define a method to initialize the hidden state.", "Inside the __init__ method, we need to define the layers \u2014 for example Embeddinglayer, GRUlayer or fully connected Dense layer. We also need to initialize the variables that are needed to define those layers. Specifically, we need to define", "Inside the call method, you want to do the operations that you think your model should do in the forward propagation of the network. In the case of the encoder, we need to get the input word embedding and pass it through a GRU layer.", "The Decoder class is pretty similar to the Encoder class. Except, you need to pass the output of the GRU unit through a fully connected Dense layer to get the prediction out of the network.", "First, we will define the optimizer and the loss function for the network. We will use Adam optimizer. Since it is a classification problem, we will use CrossEntropy loss as the loss function.", "You might have noticed that while training, we saved the model checkpoint. Saving the checkpoint is a way of saving the model. Or if you have a keras.Model object then you can use saved_model.save for saving the model [8]. To run the inference, you need to reload the checkpoint back [9].", "As discussed earlier, the inference process is very similar to the training process except how we feed the decoder. Here the input of the decoder is the output of the decoder in previous time step \u2014 whatever it predicted, not the target. The code is straightforward if you understood the training process.", "If you have understood till this point, can write an RNN based encoder-decoder, can do the training and code up the inference method \u2014 congratulation!", "Coming soon! part 2 \u2014 Attention RNN based encoder-decoder network", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Working on Computer Vision at Meraki Camera Intelligence https://twitter.com/nahidalam"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe24097069639&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e24097069639--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e24097069639--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nahidalam?source=post_page-----e24097069639--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nahidalam?source=post_page-----e24097069639--------------------------------", "anchor_text": "Nahid Alam"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9c3cc6db069e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&user=Nahid+Alam&userId=9c3cc6db069e&source=post_page-9c3cc6db069e----e24097069639---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/MonikaP-2515080/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1661731", "anchor_text": "MonikaP"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1661731", "anchor_text": "Pixabay"}, {"url": "https://www.linkedin.com/in/nahidalam/", "anchor_text": "LinkedIn"}, {"url": "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html", "anchor_text": "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"}, {"url": "https://www.tensorflow.org/tutorials/text/nmt_with_attention", "anchor_text": "https://www.tensorflow.org/tutorials/text/nmt_with_attention"}, {"url": "https://arxiv.org/pdf/1409.3215.pdf", "anchor_text": "https://arxiv.org/pdf/1409.3215.pdf"}, {"url": "https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/", "anchor_text": "https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/"}, {"url": "https://youtu.be/QuELiw8tbx8?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&t=1190", "anchor_text": "Richard Socher\u2019s lecture on Machine Translation"}, {"url": "https://www.tensorflow.org/guide/eager", "anchor_text": "https://www.tensorflow.org/guide/eager"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/GradientTape", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/GradientTape"}, {"url": "https://www.tensorflow.org/guide/saved_model", "anchor_text": "https://www.tensorflow.org/guide/saved_model"}, {"url": "https://www.tensorflow.org/guide/checkpoint", "anchor_text": "https://www.tensorflow.org/guide/checkpoint"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e24097069639---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e24097069639---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e24097069639---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----e24097069639---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----e24097069639---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&user=Nahid+Alam&userId=9c3cc6db069e&source=-----e24097069639---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&user=Nahid+Alam&userId=9c3cc6db069e&source=-----e24097069639---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e24097069639--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe24097069639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e24097069639---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e24097069639--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e24097069639--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e24097069639--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e24097069639--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e24097069639--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e24097069639--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e24097069639--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e24097069639--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nahidalam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nahidalam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nahid Alam"}, {"url": "https://medium.com/@nahidalam/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "503 Followers"}, {"url": "https://twitter.com/nahidalam", "anchor_text": "https://twitter.com/nahidalam"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9c3cc6db069e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&user=Nahid+Alam&userId=9c3cc6db069e&source=post_page-9c3cc6db069e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8381e62a44b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsequence-to-sequence-models-from-rnn-to-transformers-e24097069639&newsletterV3=9c3cc6db069e&newsletterV3Id=8381e62a44b0&user=Nahid+Alam&userId=9c3cc6db069e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}