{"url": "https://towardsdatascience.com/recommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138", "time": 1683011583.391617, "path": "towardsdatascience.com/recommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138/", "webpage": {"metadata": {"title": "Recommender systems: value-alignment, reinforcement learning, and ethics | by Nathan Lambert | Towards Data Science", "h1": "Recommender systems: value-alignment, reinforcement learning, and ethics", "description": "This story appeared in my weekly writing on making automation and AI accessible and fair, at Democratizing Automation. This encompasses a brief intro to recommendation systems online, ethics of such\u2026"}, "outgoing_paragraph_urls": [{"url": "https://robotic.substack.com/", "anchor_text": "Democratizing Automation", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Recommender_system", "anchor_text": "Wikipedia had the most to the point summary for me", "paragraph_index": 2}, {"url": "https://research.netflix.com/research-area/recommendations", "anchor_text": "some of their research in the area", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1511.05263.pdf", "anchor_text": "A survey from 2015", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Decision_tree", "anchor_text": "decision trees", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Bayesian_inference#:~:text=Bayesian%20inference%20is%20a%20method,and%20especially%20in%20mathematical%20statistics.", "anchor_text": "Bayesian methods", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1707.07435.pdf", "anchor_text": "survey on exclusively deep learning", "paragraph_index": 3}, {"url": "https://participatoryml.github.io/papers/2020/42.pdf", "anchor_text": "paper", "paragraph_index": 6}, {"url": "https://participatoryml.github.io/", "anchor_text": "workshop", "paragraph_index": 6}, {"url": "https://participatoryml.github.io/papers/2020/42.pdf", "anchor_text": "What are you optimizing for? Aligning Recommender Systems with Human Values", "paragraph_index": 6}, {"url": "https://www.wired.com/story/tiktok-finally-explains-for-you-algorithm-works/", "anchor_text": "There are also companies that won\u2019t describe how they operate", "paragraph_index": 8}, {"url": "https://dl.acm.org/doi/pdf/10.1145/3306618.3314250?casa_token=nGByQyqI-vAAAAAA%3AwFL1xCEWvZSBgUUS9ylzqq5x1lUmn3d_bv5rSY0wxsjK8VGCuJS5LqUmI6SgIJ2rsf4WizUGzosZ6g", "anchor_text": "Hadfield-Menell & Hadfield, 2019", "paragraph_index": 15}, {"url": "https://link.springer.com/chapter/10.1007/978-3-030-39627-5_11", "anchor_text": "Stocker, 2019", "paragraph_index": 17}, {"url": "https://fairmlbook.org/", "anchor_text": "Barocas et al., 2019", "paragraph_index": 17}, {"url": "https://www.sciencedirect.com/science/article/pii/S0747563217306581", "anchor_text": "Hasan et al., 2018", "paragraph_index": 17}, {"url": "https://link.springer.com/article/10.1007/s40429-015-0056-9", "anchor_text": "Andreassen, 2015)", "paragraph_index": 17}, {"url": "https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_26", "anchor_text": "Castells et al., 2015", "paragraph_index": 17}, {"url": "https://books.google.com/books?hl=en&lr=&id=MVRuDwAAQBAJ&oi=fnd&pg=PP1&dq=Benkler,+Y.,+Faris,+R.,+and+Roberts,+H.+Network+propaganda:+Manipulation,+disinformation,+and+radicalization+in+American+politics.+Oxford+University+Press,+2018.&ots=W7mpAkGznh&sig=z9hR7vzs8oaLujF-MP2JCSW-tMg#v=onepage&q&f=false", "anchor_text": "Benkler et al., 2018", "paragraph_index": 17}, {"url": "https://books.google.com/books?hl=en&lr=&id=M1eFDwAAQBAJ&oi=fnd&pg=PT6&dq=human+compatible+book&ots=k_Vqa9Ac13&sig=iD5t7xb-HH1NovGRij2AI--2nt8#v=onepage&q=human%20compatible%20book&f=false", "anchor_text": "Russell \u2014 Human Compatible, 2019", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Optimization_problem#:~:text=In%20mathematics%2C%20computer%20science%20and,solution%20from%20all%20feasible%20solutions.&text=A%20problem%20with%20continuous%20variables,continuous%20function%20must%20be%20found.", "anchor_text": "optimization problem", "paragraph_index": 23}, {"url": "https://deepmind.com/blog/article/deep-reinforcement-learning", "anchor_text": "Reinforcement learning (RL) has had a lot of success with confined games.", "paragraph_index": 25}, {"url": "https://web.stanford.edu/class/cs234/CS234Win2018/slides/cs234_2018_l13.pdf", "anchor_text": "batch RL course material", "paragraph_index": 28}, {"url": "https://arxiv.org/pdf/2005.13239.pdf", "anchor_text": "offline RL research", "paragraph_index": 28}, {"url": "https://arxiv.org/pdf/1904.12901.pdf", "anchor_text": "broad challenges of real-world RL", "paragraph_index": 28}, {"url": "http://robotic.substack.com", "anchor_text": "robotic.substack.com", "paragraph_index": 30}, {"url": "http://natolambert.com", "anchor_text": "natolambert.com", "paragraph_index": 30}], "all_paragraphs": ["This story appeared in my weekly writing on making automation and AI accessible and fair, at Democratizing Automation.", "This encompasses a brief intro to recommendation systems online, ethics of such systems, ways we can formulate human reward, and views of human recommendations as a slowly updated batch reinforcement learning problem (the game, where our reward is not even in the loop).", "The news feed systems, so to say. The recommender systems (Wikipedia had the most to the point summary for me) decide what content to give us, which is a function of our profile data and our past interactions. The interactions can include many things depending on the interface (mobile vs desktop) and platform (app, operative system, webpage). Netflix, often touted as making the most advancements to the technology, has a webpage describing some of their research in the area.", "What kind of machine learning do these systems use? A survey from 2015 found that many applications used decision trees and Bayesian methods (because they give you interpretability). Only 2 years later there was a survey on exclusively deep learning approaches. I think many companies are using neural networks and are okay with the tradeoff of dramatically improved performance at the cost of interpretability \u2014 it\u2019s not like they would tell the customer why they\u2019re seeing certain content, would they?", "I drew up a fun diagram that is your baseline, and it\u2019ll be expanded throughout the article. It\u2019s a sort of incomplete reinforcement learning framework of the agent takes action a -> environment moves to state s -> returns reward r.", "Clickthrough (a heuristic of engagement, reward) was an early metric used to create recommendations. The clickbait problem (open link, close it immediately) led to a dwell time metrics on pages. I have been satisfactorily burnt out of clickbait sites, so I started this direct-to-reader blog. That\u2019s just the surface level effect for me, and I am sure there\u2019s more. At one point, Facebook\u2019s go-to metric for a while was the usage of the click to share button \u2014 okay, you get the point, on to the paper.", "I found a paper from a workshop on Participatory Approaches to Machine Learning (when you look closer, there are many great papers to draw on, I will likely revisit) at the International Conference on Machine Learning last week. When you see block quotes, they are from What are you optimizing for? Aligning Recommender Systems with Human Values, Stray et. al, 2020. There\u2019s some great context on how the systems are used and deployed.", "Most large production systems today (including Flipboard (Cora, 2017) and Facebook (Peysakhovich & Hendrix, 2016)) instead train classifiers on human-labelled clickbait and use them to measure and decrease the prevalence of clickbait within the system.", "Human labeled content is a bottleneck when generated content outpaces labeling capacity. Also, labeling a classifier will be outdated immediately at deployment (constantly moving test set). There are also companies that won\u2019t describe how they operate. Another point regarding industry usage I found interesting is:", "Spotify is notable for elaborating on the fairness and diversity issues faced by a music platform. Their recommendation system is essentially a two-sided market, since artists must be matched with users in a way that satisfies both, or neither will stay on the platform.", "And, obvious comment below, but requisite.", "Especially when filtering social media and news content, recommenders are key mediators in public discussion. Twitter has attempted to create \u201chealthy conversation\u201d metrics with the goal to \u201cprovide positive incentives for encouraging more constructive conversation\u201d (Wagner, 2019).", "My impression of the learned models is: If the big companies do it, it\u2019s because it works. Again, don\u2019t assume malintent, assume profits. Now that we have covered how the companies are using their platforms to addict us to their advertisements, here is a small update to our model \u2014 a feedback loop and bidirectional arrows.", "Our computers are deciding what to put in front of us, primarily so that the companies retain us as reliable customers. What could go wrong? What are you okay with robots recommending for you? Your social media content \u2014 okay. How I decide my career path \u2014 I don\u2019t know.", "I don\u2019t blame companies for making these tools and putting them in front of us \u2014 they want to make money after all. These issues will come to the forefront as the negative effects compound over the next few years. Here are a few points where I don\u2019t think companies are held to high enough standards:", "I want to start with what has been called the Value Alignment Problem in at-scale, human-facing AI (example paper on legal contracts, AI, and value alignment Hadfield-Menell & Hadfield, 2019).", "I define the ethical problem here as short term results (highlighted below) and long term mental-rewiring of humans whose lives are run by algorithms.", "Concerns about recommender systems include the promotion of disinformation (Stocker, 2019), discriminatory or otherwise unfair results (Barocas et al., 2019), addictive behavior (Hasan et al., 2018)(Andreassen, 2015), insufficient diversity of content (Castells et al., 2015), and the balkanization of public discourse and resulting political polarization (Benkler et al., 2018).", "Stray et. al, 2020 continue and introduce the Recommender Alignment Problem. It is a specific version of the value alignment problem that could have increased emergence because of the prevalence of the technologies in our lives. If at this point you aren\u2019t thinking about how they affect you, have you been reading closely? Finally, a three-phase approach to alignment:", "We observe a common three phase approach to alignment: 1) relevant categories of content (e.g., clickbait) are identified; 2) these categories are operationalized as evolving labeled datasets; and 3) models trained off this data are used to adjust the system recommendations", "This can be summarized as identification (of content and issues), operalization (of models and data), adjustment of deployment. This sounds relatively close to how machine learning models are deployed to start with, but it is detailed below.", "The high-level ideas again are from the paper, but the comments are my own.", "The interaction between what the optimization problem is defined as and what the optimization problem really is is the long term battle of applying machine learning systems in safe interactions with humans.", "The model used by most machine learning tools now is to optimize a reward function given to the computer by a human. The Standard Model (Russell \u2014 Human Compatible, 2019) is nothing more than an optimization problem where the outcomes will improve when the metric on a certain reward function is improved. This falls flat on its face when we consider comparing weighing reward of multiple humans (magnitude and direction), that AIs will exploit unmentioned avenues for action (I tell the robot I want coffee, but the nearest coffee shop is $12, that\u2019s not an outcome I wanted, but it \u201cdid it\u201d), and more deleterious unmodeled effects.", "What is a better way to do this? The better way is again, interactive value learning. Value learning is a framework that would allow the AIs we make to never assume they have a full model for what humans want. If an AI only thinks that it will have a 80% chance of acting correctly, it will be much timider in its actions to maintain high expected utility (I think about the 20% chance including some very negative outcomes). Recommender systems need to account for this as well, otherwise, we will be spiraling in a game that we have little control over.", "Reinforcement learning is an iterative framework where an agent interacts with an environment via actions to maximize reward. Reinforcement learning (RL) has had a lot of success with confined games. In this case, there are two \u2018game\u2019 framings.", "Ultimately, the FAANG companies are going to be logging all of the traffic data (including heuristics towards true human reward that we talked about earlier) and trying to learn how your device should interact with you. It\u2019s a complicated system that has the downstream effect of everyone else you interact within the feedback loop. As an RL researcher, I know the algorithms are fragile, and I do not want that applied to me (but I struggle to remove myself, frequently). The diagram above is most of the point \u2014 there is no way that a single entity can design an optimization to \u201csolve\u201d that net.", "Let\u2019s talk about the data and modeling. To my knowledge, FAANG is not using RL yet, but they are acquiring a large dataset to potentially do so. The process of going from a large dataset of states, actions, and rewards to a new policy is called batch reinforcement learning (or offline RL). It tries to distill a history of unordered behavior into an optimal policy. My view of the technology companies\u2019 applications is that they are already playing this game, but an RL agent doesn\u2019t determine updates to the recommender system, a team of engineers do. The only case that could be made is that maybe TikTok\u2019s black box has shifted towards an RL algorithm prioritizing viewership. If recommendation systems are going to become a reinforcement learning problem, the ethic solutions need to come ASAP.", "Here are resources for readers interested in batch RL course material, offline RL research, and broad challenges of real-world RL.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Trying to think freely and create equitable & impactful automation @ UCBerkeley EECS. Subscribe directly at robotic.substack.com. More at natolambert.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F625eefaaf138&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://natolambert.medium.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Nathan Lambert"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890b1765e6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&user=Nathan+Lambert&userId=890b1765e6d&source=post_page-890b1765e6d----625eefaaf138---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://robotic.substack.com/", "anchor_text": "Democratizing Automation"}, {"url": "https://en.wikipedia.org/wiki/Recommender_system", "anchor_text": "Wikipedia had the most to the point summary for me"}, {"url": "https://research.netflix.com/research-area/recommendations", "anchor_text": "some of their research in the area"}, {"url": "https://arxiv.org/pdf/1511.05263.pdf", "anchor_text": "A survey from 2015"}, {"url": "https://en.wikipedia.org/wiki/Decision_tree", "anchor_text": "decision trees"}, {"url": "https://en.wikipedia.org/wiki/Bayesian_inference#:~:text=Bayesian%20inference%20is%20a%20method,and%20especially%20in%20mathematical%20statistics.", "anchor_text": "Bayesian methods"}, {"url": "https://arxiv.org/pdf/1707.07435.pdf", "anchor_text": "survey on exclusively deep learning"}, {"url": "https://participatoryml.github.io/papers/2020/42.pdf", "anchor_text": "paper"}, {"url": "https://participatoryml.github.io/", "anchor_text": "workshop"}, {"url": "https://participatoryml.github.io/papers/2020/42.pdf", "anchor_text": "What are you optimizing for? Aligning Recommender Systems with Human Values"}, {"url": "https://www.wired.com/story/tiktok-finally-explains-for-you-algorithm-works/", "anchor_text": "There are also companies that won\u2019t describe how they operate"}, {"url": "https://www.nytimes.com/2020/07/08/technology/robinhood-risky-trading.html", "anchor_text": "Financial Technology (Fintech) Companies"}, {"url": "https://www.wsj.com/articles/facebook-criticized-in-india-over-free-limited-internet-1453398493", "anchor_text": "High-traffic Media Platforms"}, {"url": "https://open.nytimes.com/how-the-new-york-times-is-experimenting-with-recommendation-algorithms-562f78624d26", "anchor_text": "News Sources"}, {"url": "https://dl.acm.org/doi/pdf/10.1145/3306618.3314250?casa_token=nGByQyqI-vAAAAAA%3AwFL1xCEWvZSBgUUS9ylzqq5x1lUmn3d_bv5rSY0wxsjK8VGCuJS5LqUmI6SgIJ2rsf4WizUGzosZ6g", "anchor_text": "Hadfield-Menell & Hadfield, 2019"}, {"url": "https://link.springer.com/chapter/10.1007/978-3-030-39627-5_11", "anchor_text": "Stocker, 2019"}, {"url": "https://fairmlbook.org/", "anchor_text": "Barocas et al., 2019"}, {"url": "https://www.sciencedirect.com/science/article/pii/S0747563217306581", "anchor_text": "Hasan et al., 2018"}, {"url": "https://link.springer.com/article/10.1007/s40429-015-0056-9", "anchor_text": "Andreassen, 2015)"}, {"url": "https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_26", "anchor_text": "Castells et al., 2015"}, {"url": "https://books.google.com/books?hl=en&lr=&id=MVRuDwAAQBAJ&oi=fnd&pg=PP1&dq=Benkler,+Y.,+Faris,+R.,+and+Roberts,+H.+Network+propaganda:+Manipulation,+disinformation,+and+radicalization+in+American+politics.+Oxford+University+Press,+2018.&ots=W7mpAkGznh&sig=z9hR7vzs8oaLujF-MP2JCSW-tMg#v=onepage&q&f=false", "anchor_text": "Benkler et al., 2018"}, {"url": "https://books.google.com/books?hl=en&lr=&id=M1eFDwAAQBAJ&oi=fnd&pg=PT6&dq=human+compatible+book&ots=k_Vqa9Ac13&sig=iD5t7xb-HH1NovGRij2AI--2nt8#v=onepage&q=human%20compatible%20book&f=false", "anchor_text": "Russell \u2014 Human Compatible, 2019"}, {"url": "https://en.wikipedia.org/wiki/Optimization_problem#:~:text=In%20mathematics%2C%20computer%20science%20and,solution%20from%20all%20feasible%20solutions.&text=A%20problem%20with%20continuous%20variables,continuous%20function%20must%20be%20found.", "anchor_text": "optimization problem"}, {"url": "https://deepmind.com/blog/article/deep-reinforcement-learning", "anchor_text": "Reinforcement learning (RL) has had a lot of success with confined games."}, {"url": "https://web.stanford.edu/class/cs234/CS234Win2018/slides/cs234_2018_l13.pdf", "anchor_text": "batch RL course material"}, {"url": "https://arxiv.org/pdf/2005.13239.pdf", "anchor_text": "offline RL research"}, {"url": "https://arxiv.org/pdf/1904.12901.pdf", "anchor_text": "broad challenges of real-world RL"}, {"url": "https://robotic.substack.com/", "anchor_text": "Democratizing AutomationA blog about robots & artificial intelligence, making them beneficial for everyone, and the coming automation wave\u2026robotic.substack.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----625eefaaf138---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----625eefaaf138---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/technology?source=post_page-----625eefaaf138---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/ethics?source=post_page-----625eefaaf138---------------ethics-----------------", "anchor_text": "Ethics"}, {"url": "https://medium.com/tag/recommendations?source=post_page-----625eefaaf138---------------recommendations-----------------", "anchor_text": "Recommendations"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&user=Nathan+Lambert&userId=890b1765e6d&source=-----625eefaaf138---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&user=Nathan+Lambert&userId=890b1765e6d&source=-----625eefaaf138---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F625eefaaf138&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----625eefaaf138---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----625eefaaf138--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----625eefaaf138--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----625eefaaf138--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----625eefaaf138--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----625eefaaf138--------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nathan Lambert"}, {"url": "https://natolambert.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "653 Followers"}, {"url": "http://robotic.substack.com", "anchor_text": "robotic.substack.com"}, {"url": "http://natolambert.com", "anchor_text": "natolambert.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890b1765e6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&user=Nathan+Lambert&userId=890b1765e6d&source=post_page-890b1765e6d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F15278b7ad062&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecommender-systems-value-alignment-reinforcement-learning-and-ethics-625eefaaf138&newsletterV3=890b1765e6d&newsletterV3Id=15278b7ad062&user=Nathan+Lambert&userId=890b1765e6d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}