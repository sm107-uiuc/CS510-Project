{"url": "https://towardsdatascience.com/7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9", "time": 1683005114.566151, "path": "towardsdatascience.com/7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9/", "webpage": {"metadata": {"title": "7 Things to Think About When Developing Reinforcement Learners | by Marin Vlastelica | Towards Data Science", "h1": "7 Things to Think About When Developing Reinforcement Learners", "description": "We all know how reinforcement learning paper mostly works. Researcher A publishes an algorithm B, algorithm B outperforms a subset of other \u201cstate-of-the-art\u201d algorithms, on a strategically chosen\u2026"}, "outgoing_paragraph_urls": [{"url": "https://jimimvp.github.io/", "anchor_text": "https://jimimvp.github.io/", "paragraph_index": 15}, {"url": "https://www.linkedin.com/in/mvlastelica/", "anchor_text": "https://www.linkedin.com/in/mvlastelica/", "paragraph_index": 15}], "all_paragraphs": ["We all know how reinforcement learning paper mostly works. Researcher A publishes an algorithm B, algorithm B outperforms a subset of other \u201cstate-of-the-art\u201d algorithms, on a strategically chosen subset of environments which coincidentally work well for the algorithm. In addition, the authors may or may not optimize the hyperparameters of the baselines, but in turn, report the best runs for algorithm B.", "Not to get into detail about what has caused this research trend, we can do something to improve it. Proper evaluation metrics of algorithms (in addition to proper benchmarks) are essential in order to have a valid comparison. Mostly what researchers use in order to evaluate the performance of algorithms is the mean performance across runs, if you get lucky, then they would even report the median which is perhaps a bit more informative. Although sounding a bit cynical regarding RL research, I have to say that RL is bread and butter compared to the things that happen in other subfields of machine learning, such as not even having multiple runs of the algorithm (vision people, I am talking to you :) ).", "Hence, this post is about what do we have to look at to compare one reinforcement learning algorithm to another, a great source of inspiration is [1], where the authors suggest a concrete way of calculating various metrics for RL algorithms, but we\u2019ll look at it more from a top-level perspective since the intricacies are just technical details of the greater goal.", "Most intuitively, when one develops an algorithm, you should look at how sensitive it is to various factors during the training procedure, such as the random seed and hyperparameters. Less variability means that the algorithm is more stable, robust, reliable etc. Except for general variability, we want to look at the worst case of different things, i.e. when having the metric, what is it in the lower tail of the distribution. No wonder that the authors from [1] took inspiration from finance in order to define concrete metrics since it turns out that we care about risk and variability in RL also. All in all, the different \u201creliability\u201d categories can be separated as follows:", "Ideally, we would like to have continuous, monotonous improvement. Meaning that the average performance should increase with each rollout and within rollouts and that the performance shouldn\u2019t get (significantly) worse from rollout to rollout. This is unfortunately mostly the case, that RL algorithms tend to be unstable. The source of the variability though can be the environment, so what you want to do is to account for the stochasticity in the environment also and adjust for it in the metric. Ideally, you wouldwant to obtain the best performance at the end of the training run, not somewhere in the middle.", "The initial conditions of the training shouldn\u2019t influence the algorithm\u2019s performance significantly, this is why it is important to look at different random seeds in different training runs (vision people, I am looking at you!). Sensitivity to hyperparameters should also be accounted for.", "We would like the algorithm to produce similar performance and behavior in evaluation. This shows how the algorithm deals with the stochasticity of the environment and different initialization conditions. One also must take into account though that the maximum achievable performance within the rollout can depend on the initial state, should also be taken into account.", "The algorithm should exhibit some guarantees in worst-case performance. This is especially important in situations with safety considerations during training. In the short-term case, we want the algorithm\u2019s performance not to wiggle too much, locally. Looking at the risk effectively means looking at the expected value of the lowest tail of the (local) distribution, below a certain percentile (let's say 5%).", "Looking at the whole rollout, we want to close the gap between the worst and best performance within the rollout. In comparison to the short-term case, here we would fit the distribution based on the whole rollout. The expected value of the performance in the worst performance that we rarely obtain within the rollout, but it is possible. Obviously, again, this can come from the instability of the algorithm, but also the characteristics of the environment.", "In contrast to the 1. point where we look at the variability after discarding outliers, here we want to see what happens with low probability, that we get a really bad seed or with a really bad set of hyperparameters.", "In contrast to the 3. point, we look at the worst-case performance across many rollouts in evaluation. Again, the source of the variability can be the algorithm but also the environment.", "These are some nice things to think about when developing reinforcement learning algorithms. After obtaining them, standard statistical significance tests can be used in order to determine if algorithm A is better than algorithm B. Possibly, incorporating these metrics in research papers would save tons of time for scientists, and also cause realistic expectations. Not limited to science, if you come from industry, considering these aspects can help you decide which algorithm to choose for your specific problem.", "Although I don\u2019t completely agree with what is written in [1], it\u2019s a good read and the authors bring up some important points. More importantly, the code is open-source, so you can get up and running with evaluation right away.", "[1] Measuring the Reliability of Reinforcement Learning Algorithms, Chan et al. ICLR 2020", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD @ Max Planck Institute for Intelligent Systems | All things ML/AI | Gutar | https://jimimvp.github.io/ | https://www.linkedin.com/in/mvlastelica/ |"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F71e6fa5434d9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://marinvp.medium.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": ""}, {"url": "https://marinvp.medium.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Marin Vlastelica"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8f3ed874afef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&user=Marin+Vlastelica&userId=8f3ed874afef&source=post_page-8f3ed874afef----71e6fa5434d9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@franckinjapan?utm_source=medium&utm_medium=referral", "anchor_text": "Franck V."}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://uscresl.github.io/humanoid-gail/", "anchor_text": "https://uscresl.github.io/humanoid-gail/"}, {"url": "http://www.iri.upc.edu/files/scidoc/2168-Learning-cloth-manipulation-with-demonstrations.pdf", "anchor_text": "http://www.iri.upc.edu/files/scidoc/2168-Learning-cloth-manipulation-with-demonstrations.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----71e6fa5434d9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----71e6fa5434d9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----71e6fa5434d9---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----71e6fa5434d9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/research?source=post_page-----71e6fa5434d9---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&user=Marin+Vlastelica&userId=8f3ed874afef&source=-----71e6fa5434d9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&user=Marin+Vlastelica&userId=8f3ed874afef&source=-----71e6fa5434d9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F71e6fa5434d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----71e6fa5434d9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----71e6fa5434d9--------------------------------", "anchor_text": ""}, {"url": "https://marinvp.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://marinvp.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marin Vlastelica"}, {"url": "https://marinvp.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://jimimvp.github.io/", "anchor_text": "https://jimimvp.github.io/"}, {"url": "https://www.linkedin.com/in/mvlastelica/", "anchor_text": "https://www.linkedin.com/in/mvlastelica/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8f3ed874afef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&user=Marin+Vlastelica&userId=8f3ed874afef&source=post_page-8f3ed874afef--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9131bca7a450&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-things-to-think-about-when-developing-reinforcement-learners-71e6fa5434d9&newsletterV3=8f3ed874afef&newsletterV3Id=9131bca7a450&user=Marin+Vlastelica&userId=8f3ed874afef&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}