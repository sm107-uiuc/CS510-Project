{"url": "https://towardsdatascience.com/illustrating-online-learning-through-temporal-differences-6a09daf61604", "time": 1683001902.878589, "path": "towardsdatascience.com/illustrating-online-learning-through-temporal-differences-6a09daf61604/", "webpage": {"metadata": {"title": "Illustrating Online Learning through Temporal Differences | by Adrian Yijie Xu | Towards Data Science", "h1": "Illustrating Online Learning through Temporal Differences", "description": "Over the course of our articles covering the fundamentals of reinforcement learning at GradientCrescent, we\u2019ve studied both model-based and sample-based approaches to reinforcement learning. Briefly\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-markov-decision-processes-policies-value-functions-94f7389e1e82", "anchor_text": "model-based", "paragraph_index": 0}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-markov-decision-processes-policies-value-functions-94f7389e1e82", "anchor_text": "Markovian Decision Processes", "paragraph_index": 0}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-automating-pong-in-using-a-policy-model-an-implementation-b71f64c158ff", "anchor_text": "sample-based learning methods", "paragraph_index": 0}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-automating-pong-in-using-a-policy-model-an-implementation-b71f64c158ff", "anchor_text": "last article", "paragraph_index": 0}, {"url": "https://medium.com/gradientcrescent", "anchor_text": "GradientCrescent covering applied AI", "paragraph_index": 17}], "all_paragraphs": ["Over the course of our articles covering the fundamentals of reinforcement learning at GradientCrescent, we\u2019ve studied both model-based and sample-based approaches to reinforcement learning. Briefly, the former class is characterized by requiring knowledge of the complete probability distributions of all possible state transitions, and is exemplified by Markovian Decision Processes. In contrast, sample-based learning methods allow for the determination of state values simply through repeated observations, eliminating the need for transition dynamics. In our last article, we discussed the applications of Monte Carlo approaches in determining the values of different states and actions simply through environmental sampling.", "More generally, Monte Carlo approaches belong to the offline family of learning approaches, insofar as to allow updates to the values of states only when the terminal state is reached, or at the end of an episode. While this approach may seem sufficient for many controlled or simulated environments, it would be woefully inadequate for applications requiring rapid changes, such as in the training of autonomous vehicles. The use of offline learning for such applications could possibly result in an accident, as a delay in updating the state values would result in an unacceptable loss of life or property.", "As such, the majority of reinforcement learning algorithms in use today are classified as online learning. In other words, the values of states and actions is continuously updated throughout time through sets of estimates. This is also known as temporal difference learning, and is the foundation of more advanced algorithms that are used to train agents tackling game environments such as those observed in the OpenAI Atari gyms.", "Just as in Monte Carlo, Temporal Difference Learning (TD) is a sampling-based method, and as such does not require knowledge of the model in order to estimate its value functions. However, unlike Monte Carlo approaches, TD is an online method, relying on intra-episode updates with incremental timesteps. At the core of temporal difference learning is a incremental update function (\u201cbootstrapping\u201d) of a state St, featuring a TD error (shown in red at the bottom):", "Notice the introduction of the two different timesteps (t and t+1) in the TD update function. The TD error contains the sum of the return at the next timestep and the current estimate for state St+1, with the value of the previous state St subtracted from this sum. Essentially, we update the estimate of a state with another estimate obtained at a later time-step, in a facsimile gradient descent observed previously for neural networks.", "How does this work in practice? Consider the sequence of States (S), Actions (A), and (Rewards)", "Due to this cyclic behavior, we can update the value of the previous state as soon as we reach the next state. Defined more formally,", "To best illustrate the difference between online versus offline learning, consider the case of predicting the duration of trip home from the office, introduced in the Reinforcement Learning Course at the University of Alberta. At each location or state named below, the predicted remaining time is shown within the circle in minutes, with the actual true elapsed time shown in between each state.", "Let\u2019s use a Monte Carlo approach first. We\u2019ll wait for the episode to finish in order to acquire the actual total elapsed time of the trip, and then update each of our states by updating the value with the return. So in the case of the departure point (leave), we can accumulate our return (with no discount factor in this case), and update its value at the end of the episode as follows:", "Similarly, we can update the next state\u2019s estimate of 35 by using the real elapsed return of 38:", "We then repeat this process for each of the intermediate destinations in turn, and achieve a final update as follows:", "As such, our state values now better reflect the actual elapsed time of our trip. However, note how we had to wait until the end of our journey to perform our updates. What if our trip featured an objective of fetching a package at a particular time at an intermediate destination? A delayed update may result in significant delays.", "Let\u2019s repeat our estimation using temporal difference analysis. Using our new estimate and actual time elapsed, we can update our previous initial estimate using temporal difference analysis. Starting from the office (t), estimate that it will take us 30 minutes to reach home. However, after reaching the \u201cexit\u201d state in five minutes (t+1), we observe that we\u2019re behind schedule, and so update the time remaining from timestep t to 40 minutes.", "Continuing on, we take 15 minutes to reach \u201cexit highway\u201d, from which we estimate it\u2019ll take another 15 minutes to reach home. As this is faster than we expected, we can then use this incremental return to update our previous estimate:", "We can then repeat this for our entire trip.", "Comparing the two approaches, it\u2019s clear that temporal difference analysis allows access into intra-episode optimization, increasing the reactivity of our agent to better converge to finding optimal policies in a minimum amount of time. In an autonomous driving application, this would allow us to monitor and evaluate the performance of an agent at a much earlier point in time, and allow us to make adjustments more rapidly, preventing unnecessary accidents from exploration.", "That wraps up this introduction to Temporal Difference Analysis. In our next tutorial, we\u2019ll build upon this foundation and introduce TD for state-action values through SARSA and Q-learning, the latter a well-known online learning approach used to optimize agent policy in a variety of game environments.", "We hope you enjoyed this article, and hope you check out the many other articles on GradientCrescent covering applied AI. To stay up to date with the latest updates on GradientCrescent, please consider following the publication.", "White et. al, Fundamentals of Reinforcement Learning, University of Alberta", "Silva et. al, Reinforcement Learning, UCL"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6a09daf61604&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----6a09daf61604--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Adrian Yijie Xu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc834a59b6354&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=post_page-c834a59b6354----6a09daf61604---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a09daf61604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----6a09daf61604---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a09daf61604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=-----6a09daf61604---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-markov-decision-processes-policies-value-functions-94f7389e1e82", "anchor_text": "model-based"}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-markov-decision-processes-policies-value-functions-94f7389e1e82", "anchor_text": "Markovian Decision Processes"}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-automating-pong-in-using-a-policy-model-an-implementation-b71f64c158ff", "anchor_text": "sample-based learning methods"}, {"url": "https://medium.com/gradientcrescent/fundamentals-of-reinforcement-learning-automating-pong-in-using-a-policy-model-an-implementation-b71f64c158ff", "anchor_text": "last article"}, {"url": "https://medium.com/gradientcrescent", "anchor_text": "GradientCrescent covering applied AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6a09daf61604---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6a09daf61604---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----6a09daf61604---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/temporal-difference?source=post_page-----6a09daf61604---------------temporal_difference-----------------", "anchor_text": "Temporal Difference"}, {"url": "https://medium.com/tag/monte-carlo?source=post_page-----6a09daf61604---------------monte_carlo-----------------", "anchor_text": "Monte Carlo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a09daf61604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----6a09daf61604---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6a09daf61604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----6a09daf61604---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6a09daf61604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----6a09daf61604--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc834a59b6354&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=post_page-c834a59b6354----6a09daf61604---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F362de3a1de04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&newsletterV3=c834a59b6354&newsletterV3Id=362de3a1de04&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----6a09daf61604---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Written by Adrian Yijie Xu"}, {"url": "https://medium.com/@adrianitsaxu/followers?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "604 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://github.com/EXJUSTICE/", "anchor_text": "https://github.com/EXJUSTICE/"}, {"url": "https://www.linkedin.com/in/yijie-xu-0174a325/", "anchor_text": "https://www.linkedin.com/in/yijie-xu-0174a325/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc834a59b6354&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=post_page-c834a59b6354----6a09daf61604---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F362de3a1de04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrating-online-learning-through-temporal-differences-6a09daf61604&newsletterV3=c834a59b6354&newsletterV3Id=362de3a1de04&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----6a09daf61604---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/gradientcrescent/generating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Adrian Yijie Xu"}, {"url": "https://medium.com/gradientcrescent?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "GradientCrescent"}, {"url": "https://medium.com/gradientcrescent/generating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Generating Swipeable Tinder Profiles using AI: Adversarial & Recurrent Neural Networks in\u2026This is a edited article based on the original publication, which was removed due to the privacy risks created through the use of the the\u2026"}, {"url": "https://medium.com/gradientcrescent/generating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "10 min read\u00b7May 15, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgradientcrescent%2Fdd68bd98c2f3&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgradientcrescent%2Fgenerating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----dd68bd98c2f3----0-----------------clap_footer----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/gradientcrescent/generating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3?source=author_recirc-----6a09daf61604----0---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdd68bd98c2f3&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgradientcrescent%2Fgenerating-swipeable-tinder-profiles-using-ai-adversarial-recurrent-neural-networks-in-dd68bd98c2f3&source=-----6a09daf61604----0-----------------bookmark_preview----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6a09daf61604----1---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----6a09daf61604----1-----------------bookmark_preview----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6a09daf61604----2---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6a09daf61604----2-----------------bookmark_preview----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/optimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Adrian Yijie Xu"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/optimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "Optimizing Blackjack Strategy through Monte Carlo MethodsFundamentals of Reinforcement Learning"}, {"url": "https://towardsdatascience.com/optimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": "\u00b711 min read\u00b7Nov 19, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcbb606e52d1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b&user=Adrian+Yijie+Xu&userId=c834a59b6354&source=-----cbb606e52d1b----3-----------------clap_footer----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/optimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b?source=author_recirc-----6a09daf61604----3---------------------4d979c42_bb34_4679_9e34_91abc4e0963b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbb606e52d1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-blackjack-strategy-through-monte-carlo-methods-cbb606e52d1b&source=-----6a09daf61604----3-----------------bookmark_preview----4d979c42_bb34_4679_9e34_91abc4e0963b-------", "anchor_text": ""}, {"url": "https://medium.com/@adrianitsaxu?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "See all from Adrian Yijie Xu"}, {"url": "https://towardsdatascience.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----0-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----6a09daf61604----0-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Anand Mishra"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Deep reinforcement learning \u2014 current state of artCurrent"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "5 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&user=Anand+Mishra&userId=86f86a9a5573&source=-----383190b14464----1-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&source=-----6a09daf61604----1-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Aniruddha Mukherjee"}, {"url": "https://medium.com/dsckiit?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "GDSC KIIT"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Reinforcement Learning: An Introduction and Guide to its FundamentalsPolicies, Rewards, the Bellman Equation, and the Markov Decision Process (MDP)"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "5 min read\u00b7Apr 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdsckiit%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&user=Aniruddha+Mukherjee&userId=68f97387c191&source=-----467c6a2ed25e----0-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----6a09daf61604----0---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&source=-----6a09daf61604----0-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6a09daf61604----1---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6a09daf61604----1-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Aaron Master"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Please Stop Drawing Neural Networks WrongThe Case for GOOD Diagrams"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "12 min read\u00b7Mar 21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&user=Aaron+Master&userId=31905cfe67ce&source=-----ffd02b67ad77----2-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----6a09daf61604----2---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "33"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&source=-----6a09daf61604----2-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@artem.a.arutyunov?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/@artem.a.arutyunov?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Artem Arutyunov"}, {"url": "https://medium.com/the-power-of-ai?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "The Power of AI"}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "Win at Blackjack with Reinforcement LearningAs a popular casino card game, many have studied Blackjack closely in order to devise strategies for improving their likelihood of winning."}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": "13 min read\u00b7Dec 30, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fthe-power-of-ai%2F95f588dd670c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-power-of-ai%2Fblackjack-with-reinforcement-learning-95f588dd670c&user=Artem+Arutyunov&userId=8d26b20a79d4&source=-----95f588dd670c----3-----------------clap_footer----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----6a09daf61604----3---------------------73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95f588dd670c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-power-of-ai%2Fblackjack-with-reinforcement-learning-95f588dd670c&source=-----6a09daf61604----3-----------------bookmark_preview----73e346aa_8457_4c1b_b2ed_ac6baf6f7e8e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6a09daf61604--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----6a09daf61604--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}