{"url": "https://towardsdatascience.com/transfer-an-artistic-image-style-to-any-image-bf71a256ba4", "time": 1683007377.978868, "path": "towardsdatascience.com/transfer-an-artistic-image-style-to-any-image-bf71a256ba4/", "webpage": {"metadata": {"title": "Transfer an artistic image style to any content image | by Milind Sahay | Towards Data Science", "h1": "Transfer an artistic image style to any content image", "description": "Have you ever had a desire to be painted by the revolutionary painters of the past? Have you ever been amused by the intricacies and fine art, the painters left on this world? Let\u2019s dive deep into\u2026"}, "outgoing_paragraph_urls": [{"url": "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/", "anchor_text": "Convolutional Neural Networks", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0", "anchor_text": "activations", "paragraph_index": 2}, {"url": "https://www.saama.com/different-kinds-convolutional-filters/", "anchor_text": "filter", "paragraph_index": 2}, {"url": "https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/", "anchor_text": "loss functions", "paragraph_index": 3}, {"url": "https://iq.opengenus.org/vgg19-architecture/", "anchor_text": "VGG-19", "paragraph_index": 4}, {"url": "https://www.kaggle.com/teksab/imagenetvggverydeep19mat", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://github.com/milindsahay/Neural_style_transfer/blob/master/nst_utils.py", "anchor_text": "This", "paragraph_index": 4}, {"url": "https://www.deeplearning.ai/", "anchor_text": "deeplearning.ai", "paragraph_index": 4}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 5}, {"url": "https://www.tensorflow.org/", "anchor_text": "TensorFlow", "paragraph_index": 6}, {"url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "anchor_text": "preprocess", "paragraph_index": 9}, {"url": "http://www.georeference.org/doc/images_and_channels.htm", "anchor_text": "Channels", "paragraph_index": 10}, {"url": "https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/", "anchor_text": "hyper-parameter", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250", "anchor_text": "forward propagation", "paragraph_index": 13}, {"url": "https://mathworld.wolfram.com/GramMatrix.html", "anchor_text": "Gram matrix", "paragraph_index": 14}, {"url": "https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/", "anchor_text": "hyperparameter", "paragraph_index": 18}, {"url": "https://databricks.com/tensorflow/interactive-sessions", "anchor_text": "interactive session", "paragraph_index": 21}, {"url": "https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/Session.Run", "anchor_text": "run()", "paragraph_index": 21}, {"url": "https://www.kite.com/python/docs/tensorflow.Tensor.eval", "anchor_text": "eval()", "paragraph_index": 21}, {"url": "https://www.tutorialspoint.com/how-are-arguments-passed-by-value-or-by-reference-in-python", "anchor_text": "by reference", "paragraph_index": 28}, {"url": "https://algorithmia.com/blog/introduction-to-optimizers", "anchor_text": "optimizer", "paragraph_index": 30}, {"url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "anchor_text": "epochs", "paragraph_index": 32}, {"url": "https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/", "anchor_text": "learning rate", "paragraph_index": 32}, {"url": "https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/", "anchor_text": "Inception", "paragraph_index": 36}, {"url": "https://iq.opengenus.org/residual-neural-networks/", "anchor_text": "ResNet", "paragraph_index": 36}, {"url": "https://github.com/milindsahay/Neural_style_transfer", "anchor_text": "this", "paragraph_index": 36}], "all_paragraphs": ["Have you ever had a desire to be painted by the revolutionary painters of the past? Have you ever been amused by the intricacies and fine art, the painters left on this world? Let\u2019s dive deep into how we can use machine learning to reproduce our content using these impeccable styles. By the end of this article, you\u2019ll be acquainted with various machine learning concepts and utilities that\u2019ll enable you to transfer any style to any content image of your own choice.", "Convolutional Neural Networks also referred to as CNNs are the basic building blocks required for Neural Style Transfer. These kinds of deep networks are used to detect patterns/strokes in an image and are generally used in image classification and generation. Below is the structure for a basic CNN.", "CNNs implicates convolving over parts of activations in a layer, defined by the filter (kernel) size over many layers until we finally reach our output layer, which classifies our image in terms of encountered inputs. You can get acquainted with various nuances of CNNs from here.", "Our main idea is to use different activations provided by intermediate layers of CNNs, on using our content and style images as inputs. We will define two separate loss functions, content loss and style loss, which will track how \u2018further away\u2019 our generated image is, from our content image and style image. The goal of our Neural network will be to minimize these loss functions and therefore improving our generated image in terms of both content and style.", "Instead of training a CNN model from scratch, we\u2019ll use a pre-trained model, which will save us all the training and computation. We\u2019ll use a VGG-19 model, which is a 19 layered CNN. The main idea behind using a pre-trained model is, to use a model trained on a different task and apply that learning to a new task. You can use any open-source implementation of VGG19 with pre-trained weights. Pre-trained weights can be obtained from here. This is the implementation I used, courtesy deeplearning.ai.", "Neural Networks model takes lot of computations and time and therefore, a GPU surely comes in handy. Be sure to check out Google Colab which gives you free access to a GPU for over 12 hours in a single session.", "We\u2019ll use TensorFlow as our deep learning framework. Several other libraries are imported to enable utilities such as saving, importing, resizing, and displaying an image.", "Note : nst_utils is not a library, but is the name of our python file, in our directory, in which we have our pre-trained VGG-19 model implemented and stored.", "We\u2019ll use the Louvre museum in Paris as our content image and sandstone as our style image.", "We\u2019ll need to preprocess our images according to the inputs desired by our VGG-19 model. The image consists of pixel values ranging from 0\u2013255 across 3 RGB channels. Images occur in various resolutions too, depending on the number of pixels it contains.", "Note: Channels in an input image remain 3 for colored i.e. RGB images, whereas 1 for grayscale images. It is the width and height that changes i.e. the number of pixels, according to resolution.", "Let\u2019s say our image has a dimension of (W, H, C), where W and H are the width and height respectively and C, the number of channels. The dimensions of input tensor, needed to be fed into our VGG-19 model must be (m,300,400,3) and normalized. variable m, also known as the batch size is a hyper-parameter, which is set to 1 by expanding the dimensions of our image to process a single image training example, using np.expand_dims() utility. Our function returns the pre-processed image.", "The generated image should be similar in content, to our content image. For this, we choose activations from a layer to represent our content image\u2019s activations. Earlier layers in CNNs detect low-level features such as edges and textures of an image, whereas deeper layers detect high-level features such as objects. We have chosen the last layer\u2019s activation to represent our content\u2019s activation. This is again a hyper-parameter, which can be fiddled around to regulate results.", "After picking us a suitable intermediate layer, we set the content image as input to our VGG-19 model and obtain Ac as activations through forward propagation. We repeat the same process for our generated image and obtain Ag as activations. Note for clarity, Ac and Ag are multi-dimensional vectors. Content cost J is defined as:", "Intuitively, the style of an image can be seen as how textures and pixels of different channels change with respect to each other. Style can quantitively be defined by the Gram matrix. In this case, the Gram matrix captures the inner product of a matrix with its transpose. Style can also be identified as a correlation between activations, between different channels in a single layer. To compute correlations between different channels, we get our 3-D activation outputs with dimension (nw, nh, nc) and flatten it out to a dimension of (nh*nw, nc).", "Calculating the gram matrix of this flattened version will essentially provide us with a correlation between different activations in a channel (corresponding to a row), with different channels (corresponding to a column).", "After calculating the gram matrix, to define style cost, we select a style layer i.e. a layer in VGG-19 on whose activations we will base our style cost. Let \u2018G\u2019 be defined as the gram matrix of activations, for a single style layer and superscripts \u2018S\u2019 and \u2018G\u2019 denote the input image as style image and generated image respectively. Then style cost for a single layer is defined as:", "Minimizing the cost above will eventually help us redefine style in our generated image.", "This cost function targets only a single layer of activations. We\u2019ll get better results if we \u201cmerge\u201d style costs from different layers. To calculate style cost, iterate on multiple style layers (a hyperparameter). Each layer is provided with weights that reflect how much, a single layer contributes to the style.", "In this function, variable \u2018weights\u2019 can be tuned, to assign weights to the individual style layer. We have kept weights equal between all the style layers. All the weights sum to 1.", "To display and preferably save our output image, we\u2019ll need to revoke all the changes we did to our original image. This includes denormalizing and clipping the pixels of the output, keeping our pixels strictly in the range of 0\u2013255.", "We have evaluated all the pre-processing and cost functions required to build our model. To build our model, we first create an interactive session with Tensorflow. An interactive session makes itself the default session, making us not call our session explicitly while running run() or eval() functions.", "We specify the paths in our directory, from where our content and style images can be fetched.", "We define our final cost that our network will eventually minimize, as the weighted sum of content cost and style cost.", "The weights \u0251 and \ud835\udefd are again hyper-parameters, which can be tuned to assign priority to content and style in our generated image. They define the relative weightings between content and style.", "Let\u2019s now compile all our functions into our final model!", "We load the content and style images from content and style path respectively and define content and style layers (hyper-parameters), required by our cost functions.", "In our model, we have initialised generated image(variable \u2018input_image\u2019) as our content image. This allows our model to converge faster, as our generated image will more rapidly match and eventually converge towards our content image.", "Note: Don\u2019t simply assign input_image = content_image. This will assign input_image by reference, which will change content_image, on changes to input_image.", "After loading our pre-trained VGG-19 model, we compute content cost and style cost by passing content image and style image as inputs through our CNN network respectively.", "After defining the total cost, using content cost and style cost with parameters \u0251 and \ud835\udefd, we pass this total cost to our optimizer to minimize. An optimizer is a gradient descent algorithm that helps our model in updating weights so that our cost function converges to a minima.", "In our training routine, we have used Adam as our optimizing algorithm.", "We run our model for 2000 iterations (epochs) with a learning rate of 2. Running this model on a GPU provided by Google Colab takes around 5\u201310 minutes.", "Using the pixels returned by our model and passing these pixels to our utility \u2018display_image\u2019 spits out our generated image as shown.", "We can clearly distinguish the outlines of the Louvre Museum in a sandstone style, as we intended! Go on and try this model on with your own photograph in a style painted by Claude Monet!", "Voila! With this, we have successfully implemented Neural Style Transfer. All that is left for you to do is find new content and style pairs and let your inner artist unfold!", "You can try and see the variations in the generated image with different learning rates and epochs. Appointing varying layers for content and style cost can also be an interesting dimension to explore. Try and analyze other pre-trained models like Inception or ResNet and see whether they provide any further refinements or not. You can follow this repository for a compiled version of our model and analyze losses corresponding to each iteration.", "Some more resources you can follow:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Undergraduate student at Delhi Technological University | TensorFlow | Deep learning | AI"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbf71a256ba4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@milind_sahay?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@milind_sahay?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Milind Sahay"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff83b59f1b544&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&user=Milind+Sahay&userId=f83b59f1b544&source=post_page-f83b59f1b544----bf71a256ba4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://painting-planet.com/sunset-in-venice-by-claude-monet/", "anchor_text": "San Giorgio Maggoire by Twilight, Claude Monet"}, {"url": "https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/", "anchor_text": "Convolutional Neural Networks"}, {"url": "https://missinglink.ai/guides/convolutional-neural-networks/convolutional-neural-network-tutorial-basic-advanced/", "anchor_text": "Typical CNN"}, {"url": "https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0", "anchor_text": "activations"}, {"url": "https://www.saama.com/different-kinds-convolutional-filters/", "anchor_text": "filter"}, {"url": "https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148", "anchor_text": "here"}, {"url": "https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/", "anchor_text": "loss functions"}, {"url": "https://iq.opengenus.org/vgg19-architecture/", "anchor_text": "VGG-19"}, {"url": "https://www.kaggle.com/teksab/imagenetvggverydeep19mat", "anchor_text": "here"}, {"url": "https://github.com/milindsahay/Neural_style_transfer/blob/master/nst_utils.py", "anchor_text": "This"}, {"url": "https://www.deeplearning.ai/", "anchor_text": "deeplearning.ai"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://www.tensorflow.org/", "anchor_text": "TensorFlow"}, {"url": "https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/", "anchor_text": "preprocess"}, {"url": "http://www.georeference.org/doc/images_and_channels.htm", "anchor_text": "Channels"}, {"url": "https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/", "anchor_text": "hyper-parameter"}, {"url": "https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250", "anchor_text": "forward propagation"}, {"url": "https://mathworld.wolfram.com/GramMatrix.html", "anchor_text": "Gram matrix"}, {"url": "https://github.com/enggen/Deep-Learning-Coursera/blob/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/NST_LOSS.png", "anchor_text": "image source"}, {"url": "https://github.com/enggen/Deep-Learning-Coursera/blob/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/NST_GM.png", "anchor_text": "image source"}, {"url": "https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/", "anchor_text": "hyperparameter"}, {"url": "https://databricks.com/tensorflow/interactive-sessions", "anchor_text": "interactive session"}, {"url": "https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/Session.Run", "anchor_text": "run()"}, {"url": "https://www.kite.com/python/docs/tensorflow.Tensor.eval", "anchor_text": "eval()"}, {"url": "https://www.tutorialspoint.com/how-are-arguments-passed-by-value-or-by-reference-in-python", "anchor_text": "by reference"}, {"url": "https://algorithmia.com/blog/introduction-to-optimizers", "anchor_text": "optimizer"}, {"url": "https://ruder.io/optimizing-gradient-descent/index.html", "anchor_text": "Here is an overview of various gradient descent optimization algorithms"}, {"url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/", "anchor_text": "epochs"}, {"url": "https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/", "anchor_text": "learning rate"}, {"url": "https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/", "anchor_text": "Inception"}, {"url": "https://iq.opengenus.org/residual-neural-networks/", "anchor_text": "ResNet"}, {"url": "https://github.com/milindsahay/Neural_style_transfer", "anchor_text": "this"}, {"url": "https://arxiv.org/abs/1508.06576", "anchor_text": "Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style"}, {"url": "https://harishnarayanan.org/writing/artistic-style-transfer/", "anchor_text": "Harish Narayanan, Convolutional neural networks for artistic style transfer"}, {"url": "http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style", "anchor_text": "Log0, TensorFlow Implementation of \u201cA Neural Algorithm of Artistic Style\u201d"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----bf71a256ba4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bf71a256ba4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-style-transfer?source=post_page-----bf71a256ba4---------------neural_style_transfer-----------------", "anchor_text": "Neural Style Transfer"}, {"url": "https://medium.com/tag/ai?source=post_page-----bf71a256ba4---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/tech?source=post_page-----bf71a256ba4---------------tech-----------------", "anchor_text": "Tech"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&user=Milind+Sahay&userId=f83b59f1b544&source=-----bf71a256ba4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&user=Milind+Sahay&userId=f83b59f1b544&source=-----bf71a256ba4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbf71a256ba4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bf71a256ba4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bf71a256ba4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bf71a256ba4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bf71a256ba4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@milind_sahay?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@milind_sahay?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Milind Sahay"}, {"url": "https://medium.com/@milind_sahay/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "26 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff83b59f1b544&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&user=Milind+Sahay&userId=f83b59f1b544&source=post_page-f83b59f1b544--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5eb8188ccfe3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-an-artistic-image-style-to-any-image-bf71a256ba4&newsletterV3=f83b59f1b544&newsletterV3Id=5eb8188ccfe3&user=Milind+Sahay&userId=f83b59f1b544&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}