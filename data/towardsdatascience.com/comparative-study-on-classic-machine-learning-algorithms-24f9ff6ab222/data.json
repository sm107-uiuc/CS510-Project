{"url": "https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222", "time": 1682994092.971536, "path": "towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222/", "webpage": {"metadata": {"title": "Comparative Study on Classic Machine learning Algorithms | by Danny Varghese | Towards Data Science", "h1": "Comparative Study on Classic Machine learning Algorithms", "description": "Machine learning is a scientific technique where the computers learn how to solve a problem, without explicitly program them. Deep learning is currently leading the ML race powered by better\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@dannymvarghese/comparative-study-on-classic-machine-learning-algorithms-part-2-5ab58b683ec0", "anchor_text": "next story", "paragraph_index": 1}, {"url": "https://medium.com/@dannymvarghese/comparative-study-on-classic-machine-learning-algorithms-part-2-5ab58b683ec0", "anchor_text": "please refer Part-2 of this series for remaining algorithms.", "paragraph_index": 2}], "all_paragraphs": ["Machine learning is a scientific technique where the computers learn how to solve a problem, without explicitly program them. Deep learning is currently leading the ML race powered by better algorithms, computation power and large data. Still ML classical algorithms have their strong position in the field.", "I will be doing a comparative study over different machine learning supervised techniques like Linear Regression, Logistic Regression, K nearest neighbors and Decision Trees in this story. In the next story, I\u2019ll be covering Support Vector machine, Random Forest and Naive Bayes. There are so many better blogs about the in-depth details of algorithms, so we will only focus on their comparative study. We will look into their basic logic, advantages, disadvantages, assumptions, effects of co-linearity & outliers, hyper-parameters, mutual comparisons etc.", "please refer Part-2 of this series for remaining algorithms.", "If you want to start machine learning, Linear regression is the best place to start. Linear Regression is a regression model, meaning, it\u2019ll take features and predict a continuous output, eg : stock price,salary etc. Linear regression as the name says, finds a linear curve solution to every problem.", "LR allocates weight parameter, theta for each of the training features. The predicted output(h(\u03b8)) will be a linear function of features and \u03b8 coefficients.", "During the start of training, each theta is randomly initialized. But during the training, we correct the theta corresponding to each feature such that, the loss (metric of the deviation between expected and predicted output) is minimized. Gradient descend algorithm will be used to align the \u03b8 values in the right direction. In the below diagram, each red dots represent the training data and the blue line shows the derived solution.", "In LR, we use mean squared error as the metric of loss. The deviation of expected and actual outputs will be squared and sum up. Derivative of this loss will be used by gradient descend algorithm.", "Two features are said to be colinear when one feature can be linearly predicted from the other with somewhat accuracy.", "Outlier is another challenge faced during training. They are data-points that are extreme to normal observations and affects the accuracy of the model.", "As the linear regression is a regression algorithm, we will compare it with other regression algorithms. One basic difference of linear regression is, LR can only support linear solutions. There are no best models in machine learning that outperforms all others(no free Lunch), and efficiency is based on the type of training data distribution.", "Just like linear regression, Logistic regression is the right algorithm to start with classification algorithms. Eventhough, the name \u2018Regression\u2019 comes up, it is not a regression model, but a classification model. It uses a logistic function to frame binary output model. The output of the logistic regression will be a probability (0\u2264x\u22641), and can be used to predict the binary 0 or 1 as the output ( if x<0.5, output= 0, else output=1).", "Logistic Regression acts somewhat very similar to linear regression. It also calculates the linear output, followed by a stashing function over the regression output. Sigmoid function is the frequently used logistic function. You can see below clearly, that the z value is same as that of the linear regression output in Eqn(1).", "when value of z is 0, g(z) will be 0.5. Whenever z is positive, h(\u03b8) will be greater than 0.5 and output will be binary 1. Likewise, whenever z is negative, value of y will be 0. As we use a linear equation to find the classifier, the output model also will be a linear one, that means it splits the input dimension into two spaces with all points in one space corresponds to same label.", "The figure below shows the distribution of a sigmoid function.", "We can\u2019t use mean squared error as loss function(like linear regression), because we use a non-linear sigmoid function at the end. MSE function may introduce local minimums and will affect the gradient descend algorithm.", "So we use cross entropy as our loss function here. Two equations will be used, corresponding to y=1 and y=0. The basic logic here is that, whenever my prediction is badly wrong, (eg : y\u2019 =1 & y = 0), cost will be -log(0) which is infinity.", "In the equation given, m stands for training data size, y\u2019 stands for predicted output and y stands for actual output.", "Logistic regression hyperparameters are similar to that of linear regression. Learning rate(\u03b1) and Regularization parameter(\u03bb) have to be tuned properly to achieve high accuracy.", "Logistic regression assumptions are similar to that of linear regression model. please refer the above section.", "Logistic Regression vs Decision Tree :", "Logistic Regression vs Neural network :", "Logistic Regression vs Naive Bayes :", "K-nearest neighbors is a non-parametric method used for classification and regression. It is one of the most easy ML technique used. It is a lazy learning model, with local approximation.", "The basic logic behind KNN is to explore your neighborhood, assume the test datapoint to be similar to them and derive the output. In KNN, we look for k neighbors and come up with the prediction.", "In case of KNN classification, a majority voting is applied over the k nearest datapoints whereas, in KNN regression, mean of k nearest datapoints is calculated as the output. As a rule of thumb, we selects odd numbers as k. KNN is a lazy learning model where the computations happens only runtime.", "In the above diagram yellow and violet points corresponds to Class A and Class B in training data. The red star, points to the testdata which is to be classified. when k = 3, we predict Class B as the output and when K=6, we predict Class A as the output.", "There is no training involved in KNN. During testing, k neighbors with minimum distance, will take part in classification /regression.", "KNN mainly involves two hyperparameters, K value & distance function.", "A general difference between KNN and other models is the large real time computation needed by KNN compared to others.", "Decision tree is a tree based algorithm used to solve regression and classification problems. An inverted tree is framed which is branched off from a homogeneous probability distributed root node, to highly heterogeneous leaf nodes, for deriving the output. Regression trees are used for dependent variable with continuous values and classification trees are used for dependent variable with discrete values.", "Decision tree is derived from the independent variables, with each node having a condition over a feature.The nodes decides which node to navigate next based on the condition. Once the leaf node is reached, an output is predicted. The right sequence of conditions makes the tree efficient. entropy/Information gain are used as the criteria to select the conditions in nodes. A recursive, greedy based algorithm is used to derive the tree structure.", "In the above diagram, we can see a tree with set of internal nodes(conditions) and leaf nodes with labels( decline/accept offer).", "the attribute with maximum gini index is selected as the next condition, at every phase of creating the decision tree. When set is unequally mixed, gini score will be maximum.", "Decision tree includes many hyperparameters and I will list a few among them.", "Decision tree vs Random Forest :", "Decision tree vs naive Bayes :", "Decision tree vs neural network :", "In the next story I will be covering the remaining algorithms like, naive bayes, Random Forest and Support Vector Machine.If you have any suggestions or corrections, please give a comment.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F24f9ff6ab222&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dannymvarghese?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dannymvarghese?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Danny Varghese"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F208860849314&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&user=Danny+Varghese&userId=208860849314&source=post_page-208860849314----24f9ff6ab222---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/@dannymvarghese/comparative-study-on-classic-machine-learning-algorithms-part-2-5ab58b683ec0", "anchor_text": "next story"}, {"url": "https://medium.com/@dannymvarghese/comparative-study-on-classic-machine-learning-algorithms-part-2-5ab58b683ec0", "anchor_text": "please refer Part-2 of this series for remaining algorithms."}, {"url": "https://medium.com/@kabab/linear-regression-with-python-d4e10887ca43", "anchor_text": "https://medium.com/@kabab/linear-regression-with-python-d4e10887ca43"}, {"url": "https://www.fromthegenesis.com/pros-and-cons-of-k-nearest-neighbors/", "anchor_text": "https://www.fromthegenesis.com/pros-and-cons-of-k-nearest-neighbors/"}, {"url": "https://brookewenig.github.io", "anchor_text": "https://brookewenig.github.io"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----24f9ff6ab222---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----24f9ff6ab222---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----24f9ff6ab222---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&user=Danny+Varghese&userId=208860849314&source=-----24f9ff6ab222---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&user=Danny+Varghese&userId=208860849314&source=-----24f9ff6ab222---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F24f9ff6ab222&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----24f9ff6ab222---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----24f9ff6ab222--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dannymvarghese?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dannymvarghese?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Danny Varghese"}, {"url": "https://medium.com/@dannymvarghese/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "189 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F208860849314&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&user=Danny+Varghese&userId=208860849314&source=post_page-208860849314--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd6e0f036e329&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcomparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222&newsletterV3=208860849314&newsletterV3Id=d6e0f036e329&user=Danny+Varghese&userId=208860849314&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}