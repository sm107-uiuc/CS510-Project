{"url": "https://towardsdatascience.com/train-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9", "time": 1683012379.849685, "path": "towardsdatascience.com/train-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9/", "webpage": {"metadata": {"title": "Train without labeling data using Self-Supervised Learning by Relational Reasoning | by Chien Vu | Towards Data Science", "h1": "Train without labeling data using Self-Supervised Learning by Relational Reasoning", "description": "In a modern deep learning algorithm, the dependence on manual annotation of unlabeled data is one of the major limitations. To train a good model, usually, we have to prepare a vast amount of labeled\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/2006.05849", "anchor_text": "paper", "paragraph_index": 4}, {"url": "https://www.linkedin.com/in/vumichien/", "anchor_text": "Linkedin", "paragraph_index": 27}], "all_paragraphs": ["In a modern deep learning algorithm, the dependence on manual annotation of unlabeled data is one of the major limitations. To train a good model, usually, we have to prepare a vast amount of labeled data. In the case of a small number of classes and data, we can use the pre-trained model from the labeled public dataset and fine-tune a few last layers with your data. However, in real life, it\u2019s easily faced with the problem when your data is considerably large (the products in the store or the face of a human,..) and it will be difficult for the model to learn with just a few trainable layers. Furthermore, the amount of unlabeled data (e.g. document text, images on the Internet) is uncountable. Labeling all of them for the task is almost impossible but not utilizing them is definitely a waste.", "In this case, training a deep model again from scratch with a new dataset will be an option but it takes a lot of time and effort for labeling data while using a pre-trained deep model seems no longer helpful. That is the reason why Self-supervised learning was born. The idea behind this is simple, which serves two main tasks:", "There are much different training approaches proposed to learn such representations: Relative position [1]: the model needs to understand the spatial context of objects to tell the relative position between parts; Jigsaw puzzle [2]: the model needs to place 9 shuffled patches back to the original locations; Colorization [3]: the model has trained to color a grayscale input image; precisely the task is to map this image to a distribution over quantized color value outputs; Counting features [4]: The model learns a feature encoder using feature counting relationship of input images transforming by Scaling and Tiling; SimCLR [5]: The model learns representations for visual inputs by maximizing agreement between differently augmented views of the same sample via a contrastive loss in the latent space.", "However, I would like to introduce one interesting approach that is able to recognize things like a human. The key factor in human learning is the acquisition of new knowledge by comparing relating and different entities. So, it is a nontrivial solution if we can apply a similar mechanism in self-supervised machine learning via the Relational reasoning approach [6].", "The relational reasoning paradigm is based on a key design principle: the use of a relation network as a learnable function on the unlabeled dataset to quantify the relationships between views of the same object (intra-reasoning) and relationships between different objects in different scenes (inter-reasoning). The possibility to exploit a similar mechanism in self-supervised machine learning via relational reasoning was evaluated by the performance on standard datasets (CIFAR-10, CIFAR-100, CIFAR-100\u201320, STL-10, tiny-ImageNet, SlimageNet), learning schedule, and backbones (bothshallow and deep). The results show that the Relational reasoning approach largely outperforms the best competitor in all conditions by an average 14% accuracy and the most recent state-of-the-art method by 3% indicating in this paper [6].", "For the simplest explanation, Relational Reasoning is just a methodology that tries to help learners understanding relations between different objects (ideas) rather than learning objects individually. That could help learners easily distinguish and remember the object based on their difference. There are two main components in the Relational reasoning system [6]: backbone structure and relation head. The relation head was used in the pretext task phase for supporting the underlying neural network backbone learning useful representations in the unlabeled dataset and then it will be discarded. The backbone structure was used in downstream tasks such as classification or image retrieval after training in the pretext task.", "Let\u2019s discuss the important point in some part of the Relational reasoning system:", "As mentioned before, this system introduced intra-reasoning and inter-reasoning? So why we need them? It is not possible to create pairs of similar and dissimilar objects when labels are not given. To solve this problem, the bootstrapping technique was applied and resulted in forming intra-reasoning and inter-reasoning, where:", "Furthermore, the utilization of the random augmentations functions (e.g. geometric transformation, color distortion) is also considered to make between-scenes reasoning more complicated. The benefit of these augmentations functions forces the learner (backbone) to pay attention to the correlation between a wider set of features (e.g. color, size, texture, etc.). For instance, in the pair {foot ball, basket ball}, the color alone is a strong predictor of the class. However, with the random changing of color as well as the shape size, the learner now is difficult to discriminate the difference between this pair. The learner has to take a look at another feature, consequently, it results in better representation.", "The aim of metric learning s to use a distance metric to bring closer representations of similar inputs (positives) while moving away representations of dissimilar inputs (negatives). However, in Relational reasoning, metric learning is fundamentally different:", "The learning objective is a binary classification problem over the presentation pairs. Therefore we can use a binary cross-entropy loss to the maximization of a Bernoulli log-likelihood, where the relation score y represents a probabilistic estimate of representation membership inducing through a sigmoid activation function.", "Finally, this paper [6] also supplied the result of Relational reasoning on standard datasets (CIFAR-10, CIFAR-100, CIFAR-100\u201320, STL-10, tiny-ImageNet, SlimageNet), different backbones (shallow and deep), same learning schedule (epochs). The results are below, for further information you can check out his paper.", "In this article, I want to reproduce the Relational reasoning system on the public image dataset STL-10. This dataset comprises of 10 classes (airplane, bird, automobile, cat, deer, dog, horse, monkey, ship, truck) with 96x96 pixels color.", "First of all, we need to import some important library", "STL-10 dataset consists of 1300 labeled images (500 for training and 800 for testing). However, it also includes 100000 unlabeled images from a similar but broader distribution of images. For instance, it contains other types of animals (bears, rabbits, etc.) and vehicles (trains, buses, etc.) in addition to the ones in the labeled set", "And then we will create the Relational reasoning class based on the suggestion of the author", "To compare the performance of Relational reasoning methodology on the shallow and deep model, we will create a shallow model (Conv4) and use the structure of a deep model (Resnet34).", "Some hyperparameters and augmentation strategies were set based on the suggestion of the author. We will train our backbone with relation head on unlabeled STL-10 dataset.", "Up to now, we\u2019ve already created everything necessary to train our model. Now we will train the backbone and relation head model in 10 epochs and 16 augmentation images (K), it took 4 hours with the shallow model (Conv4) and 6 hours on the deep model (Resnet34) by 1 GPU Tesla P100-PCIE-16GB (you can freely change the number of epochs as well as another hyperparameter to obtain better results)", "After training our backbone model, we discard the relation head and use only the backbone for the downstream tasks. We need to fine-tune our backbone with labeled data in STL-10 (500 images) and test the final model in the test set (800 images). Training and testing datasets will load in Dataloader without augmentations.", "We will load the pretrained backbone model and use a simple linear model to connect the output feature with a number of classes in the dataset.", "In this time, only the linear model will be trained, the backbone model will be frozen. First, we will see the result of fine-tuned Conv4", "And then check on the test set", "Conv4 obtained 49.98% accuracy on the test set, it means that the backbone model could learn useful feature in the unlabeled dataset, we just need to fine-tune with few epochs to achieve a good result. Now let check the performance of the deep model.", "Then evaluating on the test dataset", "It\u2019s much better, we can obtain 55.38% accuracy on the test set. In this article, the main goal is to reproduce and evaluate the Relational reasoning methodology to teach the model distinguishing the object without the label, therefore, these results were very promising. If you feel unsatisfied, you can freely do the experiment by changing the hyperparameter such as the number of augmentation, epochs, or model structure.", "Self-supervised relational reasoning is effective in both a quantitative and qualitative manners, and with backbones of different size from shallow to deep structure. Representations learned through comparison can be easily transferred from one domain to another, they are fine-grained and compact, which may be due to the correlation between accuracy and number of augmentations. In relational reasoning, the number of augmentations has a primary role affecting the quality of the clusters of objects based on the author\u2019s experiment [4]. Self-supervised learning has a strong potential to become the future of machine learning in many aspects.", "You can contact me if you want further discussion. Here is my Linkedin", "[1] Carl Doersch et. al, Unsupervised Visual Representation Learning by Context Prediction, 2015.", "[2] Mehdi Noroozi et. al, Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles, 2017.", "[4] Mehdi Noroozi et. al, Representation Learning by Learning to Count, 2017.", "[5] Ting Chen et. al, A Simple Framework for Contrastive Learning of Visual Representations, 2020.", "[6] Massimiliano Patacchiola et. al, Self-Supervised Relational Reasoning forRepresentation Learning, 2020.", "[7] Adam Santoro et. al, Relational recurrent neural networks, 2018.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb0298ad818f9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@chienvu?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chienvu?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Chien Vu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff2928e8b6c04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&user=Chien+Vu&userId=f2928e8b6c04&source=post_page-f2928e8b6c04----b0298ad818f9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral", "anchor_text": "Jason Leung"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/abs/2006.05849", "anchor_text": "paper"}, {"url": "https://www.linkedin.com/in/vumichien/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/self-supervised-learning?source=post_page-----b0298ad818f9---------------self_supervised_learning-----------------", "anchor_text": "Self Supervised Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----b0298ad818f9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b0298ad818f9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b0298ad818f9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----b0298ad818f9---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&user=Chien+Vu&userId=f2928e8b6c04&source=-----b0298ad818f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&user=Chien+Vu&userId=f2928e8b6c04&source=-----b0298ad818f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb0298ad818f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b0298ad818f9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b0298ad818f9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b0298ad818f9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b0298ad818f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chienvu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chienvu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chien Vu"}, {"url": "https://medium.com/@chienvu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "141 Followers"}, {"url": "https://www.linkedin.com/in/vumichien/", "anchor_text": "https://www.linkedin.com/in/vumichien/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff2928e8b6c04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&user=Chien+Vu&userId=f2928e8b6c04&source=post_page-f2928e8b6c04--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f7bb0947485&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9&newsletterV3=f2928e8b6c04&newsletterV3Id=1f7bb0947485&user=Chien+Vu&userId=f2928e8b6c04&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}