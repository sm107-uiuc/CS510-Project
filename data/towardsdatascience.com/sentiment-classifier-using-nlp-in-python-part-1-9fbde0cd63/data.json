{"url": "https://towardsdatascience.com/sentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63", "time": 1683017893.717611, "path": "towardsdatascience.com/sentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63/", "webpage": {"metadata": {"title": "Sentiment Classifier Using NLP in Python | by Shivangi Sareen | Towards Data Science", "h1": "Sentiment Classifier Using NLP in Python", "description": "The aim is to train a supervised Stochastic Gradient Descent classifier on a training set containing reviews of movies from IMDB, with labels, 0 for a negative review and 1 for a positive review\u2026"}, "outgoing_paragraph_urls": [{"url": "https://ai.stanford.edu/~amaas/data/sentiment/", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://scikit-learn.org/stable/modules/sgd.html", "anchor_text": "Stochastic Gradient Descent", "paragraph_index": 5}, {"url": "https://www.youtube.com/watch?v=vMh0zPT0tLI&t=385s&ab_channel=StatQuestwithJoshStarmer", "anchor_text": "video", "paragraph_index": 7}, {"url": "https://datascience.stackexchange.com/questions/36450/what-is-the-difference-between-gradient-descent-and-stochastic-gradient-descent", "anchor_text": "article", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model#", "anchor_text": "source", "paragraph_index": 12}, {"url": "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text", "anchor_text": "Sci-kit learn vectorizers", "paragraph_index": 19}], "all_paragraphs": ["The aim is to train a supervised Stochastic Gradient Descent classifier on a training set containing reviews of movies from IMDB, with labels, 0 for a negative review and 1 for a positive review. We\u2019ll use the trained model to predict the polarity of reviews in our testing set. We\u2019ll be training the model using a unigram, bigram, unigram with tf-idf and bigram with tf-idf approach. Read onward to see what it\u2019s all about!", "The dataset consists of 50,000 reviews from IMDB. Number of positive and negative reviews are equal, at 25k. Negative reviews have scores \u2264 4 out of 10 while a positive review \u2265 7 out of 10; neutral reviews are not included. The overall distribution of labels is balanced (25k pos and 25k neg). The dataset can be found here.", "There is also an additional 50,000 unlabelled documents for unsupervised learning, however, we will be focussing on supervised learning techniques here.", "There\u2019s a train/ and test/ folder, each with pos/ and neg/ directories containing text files of reviews named named as [[id]_[rating].txt] where [id] is a unique id and [rating] is the rating corresponding to the review on a 1\u201310 scale.", "Focussing only on supervised learning, the unsup/ directories can be ignored.", "We\u2019ll be using Python\u2019s sci-kit learn library to train a Stochastic Gradient Descent classifier.", "In both SGD (Stochastic Gradient Descent) and GD (Gradient Descent), we update parameters iteratively to minimise the loss function. In GD, we run through the whole training data per epoch to update one set of parameters in a given iteration. On the other hand, SGD, as the name suggests (stochastic), randomly chooses only a single training example per epoch to update the parameter in a particular iteration. Mini-batch Gradient Descent lies in between GD and SGD where a small number of training samples (subset) are used per epoch.", "Here is a very helpful video and article on SGD.", "The aim is to train our SGD classifier on 25k training samples and then use that to predict the polarity (0 for negative review and 1 for positive review) of the test data.", "We\u2019ll do some data preprocessing first \u2014 to combine the pos/ and neg/ data to create a training and testing file. Next we\u2019ll do some data cleaning to get rid of any noise in the data.", "SGD has to be fitted with two arrays: an array X of shape (n_samples, n_features) holding the training samples, and an array y of shape (n_samples,) holding the target values (class labels) for the training samples.", "To convert our text data into such numerical form, we use Bag-of-Words models.", "\u201cThe bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.\u201d [source]", "The most common type of feature extracted from the Bag-of-words model is term frequency, i.e., the number of times a term appears in the text. In our case of sentiment analysis, the more times a word like \u2018dislike\u2019, \u2018hate\u2019, \u2018suck\u2019, etc, the more likely its polarity be 0 (negative). And so this is how we\u2019ll be training our model.", "In BoW models, only the count of the words matter. As an alternative, we tend to look at n-gram models.", "An n-gram model considers the frequency of a word given the previous n-1 words have occurred. So instead of using the whole sequence of words in a sentence, we approximate using the last n-1 words.", "Let\u2019s look at a uni-gram model. Here, the frequency of a word is irrespective of any other word. So this model simply corresponds to calculating the number of times each appears in the document. This is the most basic type of representation and does not take into account the context of any word. This unigram model fits into the BoW representation. We can also view this as a special case of the n-gram model with n=1.", "In the bi-gram model, we will be looking at n-1 = 1 past words.", "E.g. document: I love going swimming. The bi-gram model will split the whole document into units: (I, love), (love, going), (going, swimming), and store the term frequency of each unit as before.", "Sci-kit learn vectorizers are one of the most efficient ways to achieve the above document-term matrix steps, including specifying which n-gram model, all in one. They come in three forms:", "Let\u2019s get right into the code now.", "The below function is defined so as to create both test and training csv files. If train = True then it will use the training data path. If False, then it will use the path to the test data.", "In both train/ and test/ directories, there are pos/ and neg/ folders with .txt files containing the review.", "Each .txt file is read and then written to the respective training or test file. We are also including the polarity header for the test file to get the true values of the reviews that we will later compare with the predicted values.", "We use the below function to create X_train (list of all the reviews) and y_train (the polarity label for each of the training reviews) from the training csv file. From the test csv file, we create X_test (list of all the reviews whose sentiment we want to predict) and the true polarities of the test review as y_test_true.", "The function remove_special_chars is used to clean up the data. The first regex sub removes html tags and everything in between them. The second regex sub removes anything but characters and a period.", "The function data_preprocess applies the function remove_special_chars to each row of a list of strings and replaces the original row with the cleaned string", "Now let\u2019s start using the above functions!", "First let\u2019s call create_csv_file to create the training file. Let\u2019s call it imdb_tr.csv.", "Next, let\u2019s create the test file called imdb_te.csv.", "Now, we\u2019ll call the create_list_of_docs function on both imdb_tr.csv and imdb_te.csv.", "docs_train is a list of all the reviews for training; docs_test contains the reviews for testing; y_train contains the polarity of the reviews in docs_train and y_test_true contains the true polarity of the reviews in docs_test.", "You\u2019ll also notice the progress of the loop with the help of tqdm.", "Next, we\u2019re going to clean the string reviews in docs_train and docs_test.", "We\u2019ll also convert y_train and y_test_true to a list of integers as the polarity got appended as strings.", "What about the stop-words you may ask? Read on to find out.", "We\u2019ve got our data all ready now! Onto the classifier!", "As mentioned before, we\u2019ll be using a stochastic gradient descent classifier, which requires an array X of shape (n_samples, n_features) holding the training samples, and an array y of shape (n_samples,) holding the target values (class labels) for the training samples.", "Recall in the above theory, we achieve numerical representation of our text data using Bag-of-Word models or n-grams. And sci-kit learn vectorizers help us do just that.", "We\u2019ll be using CountVectorizer and TfidfVectorizer. The steps for both are the same.", "2. fit_transform on the training data learns the vocabulary dictionary and returns document-term matrix. Stored as X_train.", "3. transform transforms the test data to the document-term matrix. Stored as X_test.", "Finally, we\u2019ll initialise the SDGClassifier. I\u2019ve given it a loss = \"hinge\" and penalty = \"l1\".", "Next, we use the fit method on X_train and y_train to fit linear model with Stochastic Gradient Descent.", "And then we use the predict method to predict class labels for samples in X_test.", "The below function covers both TfidfVectorizer and CountVectorizer by using tfidf = True and tfidf = False respectively.", "Finally, we\u2019ll predict using different n-gram combinations and get the accuracy of the model.", "We get an accuracy of 83.6% for the below unigram without tfidf.", "We get an accuracy of 84.04% for the below bigram without tfidf.", "We get an accuracy of 86.94% for the below unigram with tfidf.", "We get an accuracy of 85.77% for the below unigram with tfidf.", "Tfidf scales down frequent words and scales up rarer ones. The tdfidf value of stop-words will be very low. So the argument is that do we really need to remove stop-words when using the TfidfVectorizer? The answer is yes. Even though stop-words removal may not help the unigram model (give it a try), in the higher n-gram models like bigrams and trigrams, it surely has an effect. Keeping the stop-words can create noise.", "There you have it! I highly recommend if you\u2019re reading this, that you follow along in Jupyter Notebook just to see what the output looks like at each stage, from combining to create training and test data, to cleaning it, and finally getting the predictions.", "How about try and see how the above classifier be improved? There are many more parameters to TfidfVectorizer, CountVectorizer and the SGDClassifier. Also add some more steps to data preprocessing \u2014 use a lemmatizer and stemmer and see what the results are.", "Thank you for taking out the time to read this. Hope this helped!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer @Apple | Reader | Writer | The Sustainable Edit"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9fbde0cd63&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shivangisareen?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivangisareen?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Shivangi Sareen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dedb13989c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&user=Shivangi+Sareen&userId=3dedb13989c6&source=post_page-3dedb13989c6----9fbde0cd63---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@denizen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Orkun Azap"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://ai.stanford.edu/~amaas/data/sentiment/", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/sgd.html", "anchor_text": "Stochastic Gradient Descent"}, {"url": "https://www.youtube.com/watch?v=vMh0zPT0tLI&t=385s&ab_channel=StatQuestwithJoshStarmer", "anchor_text": "video"}, {"url": "https://datascience.stackexchange.com/questions/36450/what-is-the-difference-between-gradient-descent-and-stochastic-gradient-descent", "anchor_text": "article"}, {"url": "https://en.wikipedia.org/wiki/Bag-of-words_model#", "anchor_text": "source"}, {"url": "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text", "anchor_text": "Sci-kit learn vectorizers"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer", "anchor_text": "CountVectorizer"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer", "anchor_text": "HashingVectorizer"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer", "anchor_text": "cons"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer", "anchor_text": "TfidfVectorizer"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9fbde0cd63---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/python3?source=post_page-----9fbde0cd63---------------python3-----------------", "anchor_text": "Python3"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----9fbde0cd63---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----9fbde0cd63---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/tag/classification?source=post_page-----9fbde0cd63---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&user=Shivangi+Sareen&userId=3dedb13989c6&source=-----9fbde0cd63---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&user=Shivangi+Sareen&userId=3dedb13989c6&source=-----9fbde0cd63---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9fbde0cd63&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9fbde0cd63---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9fbde0cd63--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9fbde0cd63--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9fbde0cd63--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivangisareen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shivangisareen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shivangi Sareen"}, {"url": "https://medium.com/@shivangisareen/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "668 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dedb13989c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&user=Shivangi+Sareen&userId=3dedb13989c6&source=post_page-3dedb13989c6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5aef5c3fb45e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-classifier-using-nlp-in-python-part-1-9fbde0cd63&newsletterV3=3dedb13989c6&newsletterV3Id=5aef5c3fb45e&user=Shivangi+Sareen&userId=3dedb13989c6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}