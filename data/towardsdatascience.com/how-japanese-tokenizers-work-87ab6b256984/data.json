{"url": "https://towardsdatascience.com/how-japanese-tokenizers-work-87ab6b256984", "time": 1683013463.897857, "path": "towardsdatascience.com/how-japanese-tokenizers-work-87ab6b256984/", "webpage": {"metadata": {"title": "How Japanese Tokenizers Work. A deep dive into Japanese tokenization\u2026 | by Wanasit Tanakitrungruang | Towards Data Science", "h1": "How Japanese Tokenizers Work", "description": "I recently have been working on Kotori and doing research on Japanese NLP tools. I\u2019m writing this article to share what I have learned so far about Japanese tokenization and its components. If you\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori", "paragraph_index": 0}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori is a Japanese tokenizer and morphological analysis engine written in Kotlin", "paragraph_index": 1}, {"url": "https://taku910.github.io/mecab/", "anchor_text": "MeCab", "paragraph_index": 4}, {"url": "https://taku910.github.io/mecab/#download", "anchor_text": "MeCab\u2019s IPA dictionary", "paragraph_index": 5}, {"url": "http://taku910.github.io/mecab/dic.html", "anchor_text": "MeCab\u2019s dictionary format", "paragraph_index": 9}, {"url": "https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7MWVlSDBCSXZMTXM", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori on Github", "paragraph_index": 36}, {"url": "https://www.atilika.org/", "anchor_text": "Atilika", "paragraph_index": 37}, {"url": "https://github.com/WorksApplications", "anchor_text": "WorkApplicaitons", "paragraph_index": 37}, {"url": "https://github.com/mocobeta", "anchor_text": "Tomoko Uchida", "paragraph_index": 37}], "all_paragraphs": ["I recently have been working on Kotori and doing research on Japanese NLP tools. I\u2019m writing this article to share what I have learned so far about Japanese tokenization and its components.", "If you haven\u2019t heard of it, Kotori is a Japanese tokenizer and morphological analysis engine written in Kotlin. Please check Kotori on Github and give it some stars if you like this article.", "Tokenization, or breaking a text into a list of words, is an important step before other NLP tasks (e.g. text classification). In English, words are often separated by whitespace or other symbols, which make it easier to tokenize. However, in Japanese, words are normally written without any space between. Japanese tokenization requires reading/analyzing the whole sentence, recognizing words, and determining word boundaries without any explicit delimiters.", "Most Japanese tokenizers use Lattice-based tokenization. As the name suggested, a lattice-based tokenizer builds a lattice (or a graph-like data structure) consisting of all possible tokens (terms or substrings) that surface on the input text. It uses the Viterbi algorithm to find the best connected-path through the lattice.", "The most popular lattice-based tokenizer is MeCab (written in C++). Most open-source Japanese tokenizer libraries are either simply MeCab\u2019s wrapper or re-implementation of Lattice-based tokenization in different platforms.", "MeCab\u2019s IPA dictionary (IPADIC) is also the most popular dictionary. It is used as a baseline or primary dictionary for most tokenizers.", "In this article, I\u2019ll explain in detail how the Lattice-based dictionary and tokenization works through a simplified version of Kotori\u2019s code and MeCab\u2019s references.", "For Lattice-based tokenizers, a dictionary is an object or a data structure that provides information about available terms as well as how those terms should appear next to each other according to Japanese grammar or the probability.", "Although different tokenizer libraries use different in-memory data structures and read different dictionary file formats, all Lattice-based tokenizer dictionaries share mostly the same interface or logical structure.", "In this article, we will look into MeCab\u2019s dictionary format. Specifically, MeCab\u2019s IPADIC, which you can download here (to see the content and compare with the note for yourself).", "A tokenizer dictionary consists of two important parts:", "Term-Dictionary (\u5358\u8a9e\u8f9e\u66f8 or Lexicon) is a list of known terms (or words). In MeCab\u2019s dictionary directory, all CSV files together make up this term dictionary part.", "For example, in Noun.place.csv, you can find rows such as:", "Each term (or row) consists of multiple columns (or fields), but only the first four columns are important to the tokenization.", "The remaining columns are additional features about the terms (e.g. part-of-speech, normalized form, pronunciation, \u2026, etc)", "Connection Cost (\u9023\u63a5\u30b3\u30fc\u30b9) is a cost structure to measure how likely it is for a term to be before or after one another.", "The connection likelihood is explained as a cost of connecting the right context ID of the previous word with the left context ID of the following word.", "Similar to the term\u2019s cost, the higher the connection cost, the less likely the given terms should be connected.", "This mapping is matrix.def file in MeCab\u2019s dictionary. The file structure is pretty straight-forward. The first line is the number of possible rigthIDs and leftIDs (both are 1316 in the example) follow by the list of (rightID, leftID, cost) tuples.", "In addition to Term-Dictionary and Connection Cost, another dictionary component that is crucial to tokenization in practice is an unknown term (or out-of-vocabulary) handling strategy. It is for recognizing some words, substrings, or symbols outside of term-dictionary (e.g. people names) and allows tokenizers to skip or tokenize them.", "In MeCab, unknown term handling is done by heuristic rules based-on character types (e.g. consecutive Katakana characters is probably a noun). The rules and character types are defined in unk.def and char.def files.", "In this article, I am leaving the details of unknown word handling and assume that term-dictionary includes every term in the text.", "As mentioned, Lattice-based tokenization is building a lattice of terms and find the best path through the lattice.", "Given the dictionary, the tokenizer identifies all terms that \u201csurface\u201d on the text as sub-string, add all of them into the lattice together with their substring starting/ending location, then runs the algorithm to find the best path of connected terms.", "The simplified code would look like this:", "In the example code, we use findAllTermStartingAt(..) to find all terms in the dictionary having surface form starting at the location.", "The Lattice is a graph structure containing all surfaced terms as nodes. The edges of the graph connect nodes (or terms) starting at each location with nodes ending at the same location.", "Each node and connection will have a cost associate with it:", "Note from the example that, in addition to the nodes from surfaced terms, we need to include two special nodes into the lattice.", "Both term and connection costs represent how commonly used they are. The lower the cost the more likely the terms and connections. Thus, the tokenizer's goal is to find the minimal cost path (or the \u2018best\u2019 path) from start to end. Doing so will result in the token sequence that is the most likely in Japanese.", "Viterbi Algorithm is an algorithm to find the optimal path (or most likely path, or minimal cost path, etc) through the graph. Most Viterbi algorithm examples come from its application with Hidden Markov Model (e.g. POS tagging). However, I found the Viterbi algorithm usage in tokenization is very different.", "My explanation of the Viterbi Algorithm for Lattice-based tokenization application is as follows:", "To find the minimal path from start to t\u1d57\u02b0 node, we need to consider paths through each (t-1)\u1d57\u02b0 node leading to t\u1d57\u02b0 node by calculating each path\u2019s total cost and pick the minimal path among them.", "Then, among the paths through different (t-1)\u1d57\u02b0 nodes to t\u1d57\u02b0 node, pick the path with the minimal total cost.", "An efficient way to implement this algorithm is dynamic programming. We can start finding the minimal path from the nodes closet to the start and reuse their minimal path to the nodes following them. Keep repeating until we calculate the minimal path for each node.", "After executing the algorithm, the minimal path from Start to End can be found that the End node. We simply need to follow the prevNode pointer back to the Start node.", "This article summarizes the knowledge I learned from building a Japanese tokenizer from scratch. Again, if you like this article or what to learn more about Japanese tokenization, please checkout Kotori on Github.", "Note: Kotori has been heavily influenced by other open-source libraries. Special thanks to Atilika (Kuromoji), WorkApplicaitons (Sudachi), and Tomoko Uchida (Janome).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A software engineer interested in Search, and ML problems. Currently working as a Software Engineer in @Google Tokyo."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F87ab6b256984&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----87ab6b256984--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@wanasit?source=post_page-----87ab6b256984--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanasit?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Wanasit Tanakitrungruang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9c53864550a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&user=Wanasit+Tanakitrungruang&userId=9c53864550a7&source=post_page-9c53864550a7----87ab6b256984---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori"}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori is a Japanese tokenizer and morphological analysis engine written in Kotlin"}, {"url": "https://unsplash.com/@hiro7jp?utm_source=medium&utm_medium=referral", "anchor_text": "Hiroshi Tsubono"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://taku910.github.io/mecab/", "anchor_text": "MeCab"}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori"}, {"url": "https://github.com/WorksApplications/Sudachi", "anchor_text": "Sudachi"}, {"url": "https://github.com/atilika/kuromoji", "anchor_text": "Kuromoji"}, {"url": "https://mocobeta.github.io/janome/en/", "anchor_text": "Janome"}, {"url": "https://github.com/WorksApplications/SudachiPy", "anchor_text": "SudachiPy"}, {"url": "https://github.com/ikawaha/kagome", "anchor_text": "Kagome"}, {"url": "https://taku910.github.io/mecab/#download", "anchor_text": "MeCab\u2019s IPA dictionary"}, {"url": "http://taku910.github.io/mecab/dic.html", "anchor_text": "MeCab\u2019s dictionary format"}, {"url": "https://drive.google.com/uc?export=download&id=0B4y35FiV1wh7MWVlSDBCSXZMTXM", "anchor_text": "here"}, {"url": "https://github.com/wanasit/kotori", "anchor_text": "Kotori on Github"}, {"url": "https://www.atilika.org/", "anchor_text": "Atilika"}, {"url": "https://github.com/WorksApplications", "anchor_text": "WorkApplicaitons"}, {"url": "https://github.com/mocobeta", "anchor_text": "Tomoko Uchida"}, {"url": "https://techlife.cookpad.com/entry/2016/05/11/170000", "anchor_text": "\u65e5\u672c\u8a9e\u5f62\u614b\u7d20\u89e3\u6790\u306e\u88cf\u5074\u3092\u8997\u304f\uff01MeCab \u306f\u3069\u306e\u3088\u3046\u306b\u5f62\u614b\u7d20\u89e3\u6790\u3057\u3066\u3044\u308b\u304b"}, {"url": "https://medium.com/tag/nlp?source=post_page-----87ab6b256984---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/japanese?source=post_page-----87ab6b256984---------------japanese-----------------", "anchor_text": "Japanese"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----87ab6b256984---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/programming?source=post_page-----87ab6b256984---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/tokenization?source=post_page-----87ab6b256984---------------tokenization-----------------", "anchor_text": "Tokenization"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&user=Wanasit+Tanakitrungruang&userId=9c53864550a7&source=-----87ab6b256984---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&user=Wanasit+Tanakitrungruang&userId=9c53864550a7&source=-----87ab6b256984---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F87ab6b256984&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----87ab6b256984---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----87ab6b256984--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----87ab6b256984--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----87ab6b256984--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----87ab6b256984--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----87ab6b256984--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanasit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanasit?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Wanasit Tanakitrungruang"}, {"url": "https://medium.com/@wanasit/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "154 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9c53864550a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&user=Wanasit+Tanakitrungruang&userId=9c53864550a7&source=post_page-9c53864550a7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F9c53864550a7%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-japanese-tokenizers-work-87ab6b256984&user=Wanasit+Tanakitrungruang&userId=9c53864550a7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}