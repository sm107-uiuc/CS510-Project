{"url": "https://towardsdatascience.com/identifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85", "time": 1683008159.173389, "path": "towardsdatascience.com/identifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85/", "webpage": {"metadata": {"title": "Identifying the Number of Open Ion Channels with Hidden Markov Models | by Gilles Vandewiele | Towards Data Science", "h1": "Identifying the Number of Open Ion Channels with Hidden Markov Models", "description": "A write-up on how signal processing and extensions to a Hidden Markov Model resulted in the third place in the Kaggle \"Ion Switching competition\"."}, "outgoing_paragraph_urls": [{"url": "http://www.kaggle.com", "anchor_text": "Kaggle", "paragraph_index": 0}, {"url": "https://www.liverpool.ac.uk/", "anchor_text": "University of Liverpool", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/132527", "anchor_text": "me reluctant to join", "paragraph_index": 0}, {"url": "https://www.kaggle.com/khahuras", "anchor_text": "Kha Vo", "paragraph_index": 1}, {"url": "https://www.kaggle.com/zidmie", "anchor_text": "Zidmie", "paragraph_index": 1}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/153824", "anchor_text": "The number one and two managed to find a leak in the private test data", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Ion_channel", "anchor_text": "Ion channels", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Patch_clamp", "anchor_text": "patch clamp techniques", "paragraph_index": 3}, {"url": "https://www.kaggle.com/waylongo", "anchor_text": "Waylon Wu", "paragraph_index": 10}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/133142", "anchor_text": "discovered", "paragraph_index": 10}, {"url": "https://www.kaggle.com/eunholee", "anchor_text": "Eunho Lee", "paragraph_index": 12}, {"url": "https://www.kaggle.com/friedchips", "anchor_text": "Markus F", "paragraph_index": 12}, {"url": "https://www.kaggle.com/eunholee/remove-drift-using-a-sine-function", "anchor_text": "sine function with a very low frequency", "paragraph_index": 12}, {"url": "https://www.kaggle.com/cdeotte", "anchor_text": "Chris Deotte", "paragraph_index": 12}, {"url": "https://www.kaggle.com/cdeotte/data-without-drift", "anchor_text": "make a dataset out of it", "paragraph_index": 12}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/1%20-%20Align%20Channels%20and%20Signal.ipynb", "anchor_text": "We provide a notebook with python code that illustrates this.", "paragraph_index": 16}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html", "anchor_text": "scipy.optimize", "paragraph_index": 20}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/2%20-%20Remove%20Power%20Line%20Interference.ipynb", "anchor_text": "Again, a notebook is provided to demonstrate this with python code.", "paragraph_index": 21}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/153824", "anchor_text": "discovered (part of) this leak", "paragraph_index": 24}, {"url": "https://www.nature.com/articles/s42003-019-0729-3", "anchor_text": "this paper", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm", "anchor_text": "Baum-Welch algorithm", "paragraph_index": 29}, {"url": "https://www.kaggle.com/group16/lb-0-936-1-feature-forward-backward-vs-viterbi", "anchor_text": "Initial experiments", "paragraph_index": 30}, {"url": "https://hmmlearn.readthedocs.io/en/latest/", "anchor_text": "hmmlearn", "paragraph_index": 30}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/3%20-%20Fit%204-state%20HMM%20(Cat%203).ipynb", "anchor_text": "Please see this notebook for a more elaborate example.", "paragraph_index": 32}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/140634", "anchor_text": "pointed out", "paragraph_index": 34}, {"url": "https://www.kaggle.com/friedchips", "anchor_text": "Markus F", "paragraph_index": 34}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/5%20-%20Fit%2020-state%20HMM%20(Cat%203).ipynb", "anchor_text": "Python code for this can be found in this notebook.", "paragraph_index": 36}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/4%20-%20Setting%20the%20Transition%20Matrix.ipynb", "anchor_text": "this notebook.", "paragraph_index": 36}, {"url": "http://www.ee.columbia.edu/~sfchang/course/svia-F03/papers/factorial-HMM-97.pdf", "anchor_text": "Factorial Hidden Markov Models", "paragraph_index": 38}, {"url": "https://github.com/regevs/factorial_hmm", "anchor_text": "factorialHMM", "paragraph_index": 38}, {"url": "http://pyro.ai/", "anchor_text": "Pyro.ai", "paragraph_index": 38}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/6%20-%20Custom%20Forward-Backward%20(Cat%203).ipynb", "anchor_text": "A working example of this custom forward-backward algorithm can be found here.", "paragraph_index": 45}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/7%20-%20Prediction%20Post-Processing%20(Cat%203).ipynb", "anchor_text": "Please check out this notebook with our post-processing code.", "paragraph_index": 48}, {"url": "https://www.kaggle.com/khahuras", "anchor_text": "Kha Vo", "paragraph_index": 52}, {"url": "https://www.kaggle.com/zidmie", "anchor_text": "Zidmie", "paragraph_index": 52}, {"url": "https://www.kaggle.com/marcogorelli", "anchor_text": "Marco Gorelli", "paragraph_index": 53}], "all_paragraphs": ["On the 24th of February, Kaggle released a new \u201cResearch\u201d competition, with a prize pool of $25,000, in collaboration with the University of Liverpool. In this competition, we were provided with electrical signals corresponding to ion channel data, and our goal was to create an algorithm that could automatically identify the number of channels that were open at each time point. Initially, the competition launched with an exotic \u201cQuadratic Weighted Cohen Kappa Score (QWK)\u201d, but this resulted in near-perfect results a few moments after release, which made me reluctant to join. After a while, the competition metric changed to a more reasonable macro F1-score, after which it was clear that we were still far away from a perfect solution. I decided to join because of several reasons:", "I had the honor to team up with two of the brightest people I ever had a chance of working with: Kha Vo and Zidmie. In the end, we managed to secure ourselves the third spot and $5,000 and came out on top of over 2600 teams. The number one and two managed to find a leak in the private test data towards the end of the competition that we did not discover (only right after knowing of its existence). One other way to re-phrase this, is that we had the best non-leaky solution! In the end, we were able to find this leak ourselves in a short amount of time, which makes it even more frustrating\u2026", "This blog post will provide a detailed overview of our solution, and provides the insights that were required for us to come up with our solution. Below is a table of contents:", "Ion channels are pore-forming membrane proteins, present in animals and plants, that allow ions to pass through the channel pore. They encode learning and memory, help fight infections, enable pain signals, and stimulate muscle contraction. These ion channels can be recorded through patch clamp techniques and analyzed to infer certain properties of diseases.", "The organizers describe the challenge as follows: \u201cWhen ion channels open, they pass electric currents. Existing methods of detecting these state changes are slow and laborious. Humans must supervise the analysis, which imparts considerable bias, in addition to being tedious. These difficulties limit the volume of ion channel current analysis that can be used in research. Scientists hope that technology could enable rapid automatic detection of ion channel current events in raw data. Technology to analyze electrical data in cells has not changed significantly over the past 20 years. If we better understand ion channel activity, the research could impact many areas related to cell health and migration. From human diseases to how climate change affects plants, faster detection of ion channels could greatly accelerate solutions to major world problems.\u201d", "The data provided to us is rather simple, which is one of the nice things about this competition. The data contains only three columns:", "The training dataset consists of 5 million rows while the testing dataset consists of 2 million rows. The goal of the competition is to maximize the macro F1-score on those 2 million rows. The F1 score of a certain class is defined as the harmonic average of the precision and recall:", "The \u201cmacro\u201d F1 is simply the average F1 score per class. So if we would have K classes, we would calculate K F1 scores and then take the mean of those K scores. If we inspect the provided data, we can already conclude a few interesting things\u2026", "First, by inspecting the open channels in the training data, we can see that the data consists of batches of 500K measurements. We can see these transitions in batches in the electrical signal as well. In the test set, we can find batches of 100K. Moreover, as it turns out, the batches of 500K in the training set actually consist of 5x 100K batches.", "By inspecting the open channels in the training set more, we can find five different groups in the training set:", "When combining this insight with the competition metric, it becomes clear that the group with up to 10 open channels (category 5) will have the largest impact on the macro F1 average. It has 5 unique classes (6, 7, 8, 9, 10) that do not appear in other groups, as such, this group of data contributes for more than 50% to our macro F1 score. During the course of the competition, Waylon Wu discovered, by probing, that the public LB consisted of the first 30% (or 600000) test values, while the private LB consisted of the remaining 70% (1400000).", "We noticed that weird drift is present in the beginning and in the end of our training signal, and in different places of the test signal\u2026 We notice two types of drift: curved drift (e.g. in the end of the training signal) and linear drift (e.g. in the start of the training signal, around time=50).", "In the end, it turned out that the \u201clinear\u201d drift was not linear at all, but was actually just a small part of the \u201ccurved\u201d drift (e.g. the first half of our curved drift looks linear as well). Shortly after the start of the competition, Eunho Lee and Markus F discovered that the competition organizers introduced artificial noise in the data, by using a sine function with a very low frequency (with a period of 1.000.000 values). Chris Deotte bundled the insights from the two independent analysis to perform the cleanest drift removal and make a dataset out of it that could be used by all other competitors (thanks Chris!). Our new data now looks as follows:", "We can notice that something is still going wrong from time=360 until time=390. We decided to not bother about this, since such an anomaly was not present in the test set, and we removed this data from our training set.", "By inspecting the data, it becomes clear that the train signal and number of open channels are extremely correlated. As a matter of fact, applying a linear transformation on the electrical signal and then rounding the resulting values already performs rather well.", "We decided to learn a linear transformation per category of data that best maps the electrical signal values to the number of open channels, this allowed easier analysis in future steps. The transformation is rather simple, we learned two different parameters for the following function (1D Linear Regression):", "We provide a notebook with python code that illustrates this.", "As I mentioned in the previous section, rounding our aligned electrical signal values would already result in a strong baseline. Unfortunately, it would not result in a perfect score\u2026 That is due to the fact that noise is present in our dataset (luckily, or this would have been quite a trivial challenge)! We can inspect this noise by simply calculating the following:", "Below is a plot of the first 10000 noise values of our training set:", "While it may be hard to see with the eye, there is somewhat of a wave pattern present within our noise. This becomes even more clear if we take a moving average with a centered window of size 50:", "We can clearly see a wave with a peak every 200 values on average. A periodic signal, measured at a sampling frequency of 10 kHz, with a period of around 200, corresponds to a frequency of 50 Hz. It turns out that the AC power in the UK (competition is by Uni of Liverpool) has a frequency of 50 Hz! In order to remove this pattern from our noise, we decided to fit a sine function on each batch of 100000 noise values (you can use scipy.optimize for that). While signal processing techniques, such as bandpass and bandstop filters can do this for you as well, we had better results with a simple sine function. It also turned out that having multiple components in the sine function (i.e. multiple sine waves with different amplitudes, phases and frequencies) worked the best.", "Again, a notebook is provided to demonstrate this with python code.", "It seemed that our noise removal technique worked really well for all categories, except for one\u2026 There was something unique about the data in category 5 that distinguished it from all the rest. By doing some experimentation, we noticed that we could mimic data from category 5 very well by just adding two random batches from category 4 together.", "By making this assumption, we can also assume that the noise in cat 5 is the addition of two sine functions. Moreover, this insight allows for data augmentation which could be useful for, e.g., neural networks.", "As it turns out, this insight was actually the leak as well. We did not pursue this avenue long enough, but the private test data was EXACTLY the sum of two category 4 batches, of which one can be found in the TRAINING set... After the competition, my teammate Zidmie, discovered (part of) this leak in roughly 30 minutes of looking for it (improving our private score to 0.95430). A bit frustrating to know that we improved our model much more in 30 minutes due to a leak than our work of 2 months. Later, he discovered the entire leak:y_test[570000:5800000] = predict(X_test[5700000:5800000] - X_train[4000000:4100000]) + y_train[4000000:4100000]. Since you are predicting category 4 data (with up to 5 channels) now, it becomes a much easier task.", "Sequential state space models, such as Hidden Markov Models, were the state-of-the-art for a long time for these types of problems. It is only more recently that deep learning variants have been proposed (e.g. this paper by the competition organizers), as these are often more robust against things such as drift. Since we are pre-processing our data to remove all artifacts, we decided to go for Hidden Markov Models are our modeling technique in this competition.", "There are many great introductions to Hidden Markov Models out there, so I will not go much in detail here. All we need to know is that there are different parameters that belong to each Hidden Markov Model:", "In short, the open channels (hidden variables) follow a certain Markov Process and transit from one value to the other with certain probabilities that are determined by the transition matrix. When the Markov Process is in a certain hidden/latent state, it emits an observable value, which is the electrical signal here.", "As an example, we are going to focus on category 2 which has a binary response variable (open channels = 0 or 1), and assume our Markov Model to have 2 hidden states. A hidden state for when the number of open channels is equal to 0 and one hidden state for when it is equal to 1. We can estimate both the transition matrix & the emission distributions easily by looking at our training data (i.e. count transitions from one state to the other and look at signal values corresponding to a certain number of open channels):", "This means that, for example, if the number of open channels equals to 1, the signal value will be around 1 as well (with a bit of variance). The next value will be equal to 1 with a probability of 93.6% or 0 with a probability of 6.4%. These parameters can be estimated by using the training data, as illustrated above, but also by applying the Baum-Welch algorithm. This algorithm is a special case of the Expectation-Maximization algorithm, which is an unsupervised algorithm (no cross-validation was needed which allowed faster iterations). In a nutshell (and simplistic way), it will make predictions based on its initial parameters and then use these predictions to update the parameters until convergence. Once the parameters are learned, we can perform inference by applying one of two algorithms:", "Initial experiments already showed that the Forward-Backward algorithm worked slightly better (albeit slower) than the Viterbi. Note that these algorithms are also used in the Baum-Welch algorithm. A great library to apply all these algorithms in Python is hmmlearn.", "Let\u2019s fit a 2-state HMM on our pre-processed data of category 2:", "So by using this rather simple approach, we can already achieve a F1 score of 0.9961 on category 2 of our data. It should be noted that categories 1 and 2 of our data are by far the easiest ones, with near-perfect performance. The F1 scores quickly drops in function of the maximum number of open channels. As an example, we cannot reach an F1 score of 0.9 on category 5 of our data. Please see this notebook for a more elaborate example.", "When reading a paper published by the organizers, it becomes clear that while the number of open channels follow a Markovian Process, they are in turn generated by a Hidden Markov Model.:", "This Hidden Markov Model consists of more hidden states than the number of unique open channel values. This was pointed out during the competition by Markus F.", "A simple way to approach this, is by ignoring the middle layer (y(t)) in our 2-layer model. As such, we have a Hidden Markovian Process with a number of hidden states larger than the number of unique open channels. Let\u2019s apply this insight to our category 2 data. We will use 4 hidden states in our HMM (we have experimented with other numbers, but 4 worked best). The first two hidden states will correspond to when the number of open channels is equal to 1, the 2 following hidden states correspond to when the open channels is 0. Estimating the initial transition matrix now becomes more difficult as we cannot directly estimate it from our training data, we tuned the transition matrix manually.", "As can be noticed, we now achieve a F1 score of 0.9972, which is an increase of roughly 0.001 as opposed to using only 2 hidden states. This improvement is very significant, especially considering the fact that this improvement increases even more with higher numbers of open channels. A difference of 0.001 in F1 scores is the difference between a silver and gold medal in the end. The F1 can probably be improved even more by introducing more hidden states or by adjusting the initial transition matrix, but a smaller transition matrix had several advantages, which will be more clear later. Python code for this can be found in this notebook. For more information on how we manually tuned the transition matrix, we refer the reader through to this notebook.", "It seems that we can very accurately model category 1 and 2 of our data, which has up to 1 open channel. The question (of $25,000) is now whether we can apply this approach to the other categories of our data with more than 1 open channel. It turns out that this is far from a trivial case\u2026 Designing a large initial transition matrix and determining which hidden states correspond to which numbers of open channels is hard and expensive (our search space is infinitely large actually).", "As such, we made the assumption that when the maximum number of open channels in a batch of data equals K that we are then dealing with K independent binary Markovian processes. Moreover, each of these Markovian processes have very similar parameters as category 2 of our data. Having several independent hidden processes resulting in an observable variable is a perfect fit for Factorial Hidden Markov Models. Unfortunately, we did not find a good library in Python (there\u2019s factorialHMM, which is a great package, but we did not get it working quickly enough during the competition and there\u2019s Pyro.ai but the learning curve is very steep (at least to me)).", "With no implementations available, we realized that it was going to be a difficult and long process to implement this ourselves. We therefore decided to \u201chack\u201d our way around the aspect of independent processes, by converting the smaller transition matrices, used to model data up to 1 open channels, into larger transition matrices. Each of the hidden states in our new large Markov process corresponds to the possible combinations of hidden states in the independent processes. The order does not matter (i.e. (0, 2) (which means that 1 process is in hidden state 0 and the other in hidden state 2) is the same as (2, 0)). This construction is done recursively as illustrated below:", "In each iteration, we first expand our transition matrix. If the initial transition matrix is N x N, then our newly expanded matrix will be N*K x N*K which capture all possible interactions of our N initial states with K new possibly states. When there are 2 independent processes, an example would be that process 1 is in hidden state 0 and process 2 in hidden state 1. After this expansion, we group similar states together (such as the green cells in our figure). Using our example, process 1 being in hidden state 0 and process 2 in hidden state 1 is equivalent to process 1 being in hidden state 1 and process 2 in hidden state 0. Our newly generated matrix will be of dimensions C x C after this procedure, with C equal to the number of combinations with repetition, from P independent processes out of K possible states. As an example, with 4 hidden states and 3 independent processes, C would be equal to 20 (Comb_with_Repetition(4, 3) = Comb(4 + 3 \u2013 1, 3) = 20).", "Below is Python code to do this:", "It should be noted that this algorithm was not that straight-forward to implement, and that a simple (but much more readable) implementation resulted in estimated runtimes of a few weeks when the number of processes was equal to 10. It already took this implementation around 2 minutes to generate the transition matrix with 10 processes with a 4x4 initial matrix, and already much longer for a 5x5 matrix (hence why we stayed with a 4x4).", "We implemented the forward-backward algorithm ourselves, which gaves us a lot of degrees of freedom. We tried many different adjustments to the vanilla implementation of the algorithm, but the one that resulted in the most significant improvement was the introduction of memory. When calculating the probabilities at timestep t in the backward pass, we use the calculated probabilities at timestep t of the forward pass:", "In total, we perform three passes. One forward pass, of which we use the alphas in our next backward pass and finally a last forward pass using our newly calculated betas. Our Psig is calculated as follows:", "A working example of this custom forward-backward algorithm can be found here.", "After our forward backward algorith, we are left with a TxK with probabilities for each possible hidden state and each timestep. As we have multiple hidden states that correspond to the same value of open channels, we need another post-processing step to convert these probabilities into predictions. As a first step, we took the dot product of our K probabilities in each timestep with our K states, which is the same as a weighted sum and thus results in a continuous value Y. We then decided to learn thresholds for each class and each category of data. If Y falls between two thresholds, then it is assigned to the corresponding class.", "To determine these thresholds, we used somewhat of an unsupervised technique. First, we filtered out the signals that were close to their rounded value (as not a lot of noise was present in these) and used their rounded values as labels. Then, we determined the distribution of these rounded values and picked the thresholds such that it would produce a similar distribution.", "Please check out this notebook with our post-processing code.", "Many variants of this HMM have been made in the course of this competition. My teammate Zidmie used a counter in his scripts, and he was at 342 in the end (so 342 different scripts have been written by himself only). Throughout the course of the competition, we kept marginally improving both our CV and public LB score. Often, the number of differences between consecutive versions were a lot higher than the differences in CV scores, which means that not all of the changes made by the new version were actually correct. We therefore blended different outputs of our forward-backward algorithms together (by using their calculated probabilities). This gave us some marginal increases.", "I am extremely proud of our final result. I think the solution is rather elegant, given that it is not the typical ensemble of 1001 different models that you often see on Kaggle and that it runs in less than one hour. We also never used the code of the competition organizers to create extra data or to reverse engineer the data generation process. In the end, I was a bit disappointed to drop two spots due to a leak that was discovered by other teams and not by us. Nevertheless, I learned a whole lot during this competition as I never used a Hidden Markov Model before and got to know 2 great and bright people!", "Keep an eye on this page, as it probably can/will receive minor updates over the next few days. Also, we are working towards releasing our code!", "Thank you again Kha Vo and Zidmie a lot of fun during this competition!", "Acknowledgements: the authors would like to thank Marco Gorelli for his constructive feedback."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F334fab86fc85&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://gillesvandewiele.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Gilles Vandewiele"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e8cbc53806e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=post_page-3e8cbc53806e----334fab86fc85---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F334fab86fc85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----334fab86fc85---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F334fab86fc85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=-----334fab86fc85---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching", "anchor_text": "EDIT 04/06/2020: We have now released our code!"}, {"url": "http://www.kaggle.com", "anchor_text": "Kaggle"}, {"url": "https://www.liverpool.ac.uk/", "anchor_text": "University of Liverpool"}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/132527", "anchor_text": "me reluctant to join"}, {"url": "https://www.kaggle.com/khahuras", "anchor_text": "Kha Vo"}, {"url": "https://www.kaggle.com/zidmie", "anchor_text": "Zidmie"}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/153824", "anchor_text": "The number one and two managed to find a leak in the private test data"}, {"url": "https://en.wikipedia.org/wiki/Ion_channel", "anchor_text": "Ion channels"}, {"url": "https://en.wikipedia.org/wiki/Patch_clamp", "anchor_text": "patch clamp techniques"}, {"url": "https://en.wikipedia.org/wiki/Ion_channel", "anchor_text": "Wikipedia"}, {"url": "https://www.kaggle.com/cdeotte/one-feature-model-0-930", "anchor_text": "\u201cOne Feature Model\u201d"}, {"url": "https://www.kaggle.com/cdeotte", "anchor_text": "Chris Deotte"}, {"url": "https://www.kaggle.com/waylongo", "anchor_text": "Waylon Wu"}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/133142", "anchor_text": "discovered"}, {"url": "https://www.kaggle.com/eunholee", "anchor_text": "Eunho Lee"}, {"url": "https://www.kaggle.com/friedchips", "anchor_text": "Markus F"}, {"url": "https://www.kaggle.com/eunholee/remove-drift-using-a-sine-function", "anchor_text": "sine function with a very low frequency"}, {"url": "https://www.kaggle.com/cdeotte", "anchor_text": "Chris Deotte"}, {"url": "https://www.kaggle.com/cdeotte/data-without-drift", "anchor_text": "make a dataset out of it"}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/1%20-%20Align%20Channels%20and%20Signal.ipynb", "anchor_text": "We provide a notebook with python code that illustrates this."}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html", "anchor_text": "scipy.optimize"}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/2%20-%20Remove%20Power%20Line%20Interference.ipynb", "anchor_text": "Again, a notebook is provided to demonstrate this with python code."}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/153824", "anchor_text": "discovered (part of) this leak"}, {"url": "https://www.nature.com/articles/s42003-019-0729-3", "anchor_text": "this paper"}, {"url": "https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm", "anchor_text": "Baum-Welch algorithm"}, {"url": "https://en.wikipedia.org/wiki/Viterbi_algorithm", "anchor_text": "The Viterbi Algorithm"}, {"url": "https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm", "anchor_text": "The Forward-Backward Algorithm"}, {"url": "https://www.kaggle.com/group16/lb-0-936-1-feature-forward-backward-vs-viterbi", "anchor_text": "Initial experiments"}, {"url": "https://hmmlearn.readthedocs.io/en/latest/", "anchor_text": "hmmlearn"}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/3%20-%20Fit%204-state%20HMM%20(Cat%203).ipynb", "anchor_text": "Please see this notebook for a more elaborate example."}, {"url": "https://www.nature.com/articles/s42003-019-0729-3/figures/1", "anchor_text": "Figure taken from a paper by the organizers."}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/discussion/140634", "anchor_text": "pointed out"}, {"url": "https://www.kaggle.com/friedchips", "anchor_text": "Markus F"}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/5%20-%20Fit%2020-state%20HMM%20(Cat%203).ipynb", "anchor_text": "Python code for this can be found in this notebook."}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/4%20-%20Setting%20the%20Transition%20Matrix.ipynb", "anchor_text": "this notebook."}, {"url": "http://www.ee.columbia.edu/~sfchang/course/svia-F03/papers/factorial-HMM-97.pdf", "anchor_text": "Factorial Hidden Markov Models"}, {"url": "https://github.com/regevs/factorial_hmm", "anchor_text": "factorialHMM"}, {"url": "http://pyro.ai/", "anchor_text": "Pyro.ai"}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/6%20-%20Custom%20Forward-Backward%20(Cat%203).ipynb", "anchor_text": "A working example of this custom forward-backward algorithm can be found here."}, {"url": "https://github.com/GillesVandewiele/Liverpool-Ion-Switching/blob/master/notebooks/7%20-%20Prediction%20Post-Processing%20(Cat%203).ipynb", "anchor_text": "Please check out this notebook with our post-processing code."}, {"url": "https://www.kaggle.com/khahuras", "anchor_text": "Kha Vo"}, {"url": "https://www.kaggle.com/zidmie", "anchor_text": "Zidmie"}, {"url": "https://www.kaggle.com/marcogorelli", "anchor_text": "Marco Gorelli"}, {"url": "https://www.kaggle.com/c/liverpool-ion-switching/overview", "anchor_text": "University of Liverpool - Ion SwitchingIdentify the number of channels open at each time pointwww.kaggle.com"}, {"url": "https://en.wikipedia.org/wiki/Ion_channel", "anchor_text": "Ion channelIon channels are pore-forming membrane proteins that allow ions to pass through the channel pore. Their functions\u2026en.wikipedia.org"}, {"url": "https://www.nature.com/articles/s42003-019-0729-3", "anchor_text": "Deep-Channel uses deep neural networks to detect single-molecule events from patch-clamp dataNuman Celik et al. present a deep learning model that automatically detects single-molecule events against a noisy\u2026www.nature.com"}, {"url": "https://papers.nips.cc/paper/1144-factorial-hidden-markov-models", "anchor_text": "Factorial Hidden Markov ModelsElectronic Proceedings of Neural Information Processing Systemspapers.nips.cc"}, {"url": "https://github.com/hmmlearn/hmmlearn", "anchor_text": "hmmlearn/hmmlearnhmmlearn is a set of algorithms for unsupervised learning and inference of Hidden Markov Models. For supervised\u2026github.com"}, {"url": "https://medium.com/tag/hidden-markov-models?source=post_page-----334fab86fc85---------------hidden_markov_models-----------------", "anchor_text": "Hidden Markov Models"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----334fab86fc85---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/kaggle?source=post_page-----334fab86fc85---------------kaggle-----------------", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/competition?source=post_page-----334fab86fc85---------------competition-----------------", "anchor_text": "Competition"}, {"url": "https://medium.com/tag/signal-processing?source=post_page-----334fab86fc85---------------signal_processing-----------------", "anchor_text": "Signal Processing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F334fab86fc85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----334fab86fc85---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F334fab86fc85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----334fab86fc85---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F334fab86fc85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e8cbc53806e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=post_page-3e8cbc53806e----334fab86fc85---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7b38ac3fda1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&newsletterV3=3e8cbc53806e&newsletterV3Id=e7b38ac3fda1&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----334fab86fc85---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Written by Gilles Vandewiele"}, {"url": "https://gillesvandewiele.medium.com/followers?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "231 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e8cbc53806e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=post_page-3e8cbc53806e----334fab86fc85---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7b38ac3fda1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fidentifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85&newsletterV3=3e8cbc53806e&newsletterV3Id=e7b38ac3fda1&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----334fab86fc85---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/creating-the-perfect-connect-four-ai-bot-c165115557b0?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Gilles Vandewiele"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/creating-the-perfect-connect-four-ai-bot-c165115557b0?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Creating the (nearly) perfect connect-four bot with limited move time and file sizeOn bit operations, alpha-beta pruning and hard-coding initial game states to create a very strong AI agent for connect four."}, {"url": "https://towardsdatascience.com/creating-the-perfect-connect-four-ai-bot-c165115557b0?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "17 min read\u00b7Nov 28, 2017"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc165115557b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-the-perfect-connect-four-ai-bot-c165115557b0&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----c165115557b0----0-----------------clap_footer----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/creating-the-perfect-connect-four-ai-bot-c165115557b0?source=author_recirc-----334fab86fc85----0---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc165115557b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-the-perfect-connect-four-ai-bot-c165115557b0&source=-----334fab86fc85----0-----------------bookmark_preview----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----334fab86fc85----1---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----334fab86fc85----1-----------------bookmark_preview----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----334fab86fc85----2---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----334fab86fc85----2-----------------bookmark_preview----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/enriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Gilles Vandewiele"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/enriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "Enriching shapelets with positional information for timeseries classificationHow a neat simple trick can boost both predictive performance and interpretability."}, {"url": "https://towardsdatascience.com/enriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": "4 min read\u00b7Feb 9, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F42b6009a54a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8&user=Gilles+Vandewiele&userId=3e8cbc53806e&source=-----42b6009a54a8----3-----------------clap_footer----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/enriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8?source=author_recirc-----334fab86fc85----3---------------------8796788c_2ab4_4054_99e0_c09387d760f6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F42b6009a54a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fenriching-shapelets-with-positional-information-for-timeseries-classification-42b6009a54a8&source=-----334fab86fc85----3-----------------bookmark_preview----8796788c_2ab4_4054_99e0_c09387d760f6-------", "anchor_text": ""}, {"url": "https://gillesvandewiele.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "See all from Gilles Vandewiele"}, {"url": "https://towardsdatascience.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----334fab86fc85----0-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----334fab86fc85----1-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@nikoskafritsas?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Nikos Kafritsas"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Temporal Fusion Transformer: Time Series Forecasting with Deep Learning \u2014 Complete TutorialCreate accurate & interpretable predictions"}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b712 min read\u00b7Nov 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd32c1e51cd91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91&user=Nikos+Kafritsas&userId=bec849d9e1d2&source=-----d32c1e51cd91----0-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/temporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91?source=read_next_recirc-----334fab86fc85----0---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "15"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd32c1e51cd91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-fusion-transformer-time-series-forecasting-with-deep-learning-complete-tutorial-d32c1e51cd91&source=-----334fab86fc85----0-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://shawhin.medium.com/?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://shawhin.medium.com/?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Shawhin Talebi"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "The Wavelet TransformAn Introduction and Example"}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b76 min read\u00b7Dec 21, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe9cfa85d7b34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-wavelet-transform-e9cfa85d7b34&user=Shawhin+Talebi&userId=f3998e1cd186&source=-----e9cfa85d7b34----1-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-wavelet-transform-e9cfa85d7b34?source=read_next_recirc-----334fab86fc85----1---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9cfa85d7b34&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-wavelet-transform-e9cfa85d7b34&source=-----334fab86fc85----1-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----2-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----334fab86fc85----2---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----334fab86fc85----2-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://venali.medium.com/an-introduction-to-volatility-targeting-985605abb797?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://venali.medium.com/?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://venali.medium.com/?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "Venali Sonone"}, {"url": "https://venali.medium.com/an-introduction-to-volatility-targeting-985605abb797?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "An Introduction to Volatility TargetingThe Theory of Portfolio Management blog series presents my favorite selected list of research articles related to essential portfolio\u2026"}, {"url": "https://venali.medium.com/an-introduction-to-volatility-targeting-985605abb797?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": "\u00b713 min read\u00b7Dec 10, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F985605abb797&operation=register&redirect=https%3A%2F%2Fvenali.medium.com%2Fan-introduction-to-volatility-targeting-985605abb797&user=Venali+Sonone&userId=7aecdc84c720&source=-----985605abb797----3-----------------clap_footer----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://venali.medium.com/an-introduction-to-volatility-targeting-985605abb797?source=read_next_recirc-----334fab86fc85----3---------------------d692e665_b7eb_48fb_9419_7b4feb95bfd8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F985605abb797&operation=register&redirect=https%3A%2F%2Fvenali.medium.com%2Fan-introduction-to-volatility-targeting-985605abb797&source=-----334fab86fc85----3-----------------bookmark_preview----d692e665_b7eb_48fb_9419_7b4feb95bfd8-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----334fab86fc85--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----334fab86fc85--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}