{"url": "https://towardsdatascience.com/every-data-scientist-can-need-some-spark-magic-853da0b81006", "time": 1683007734.746392, "path": "towardsdatascience.com/every-data-scientist-can-need-some-spark-magic-853da0b81006/", "webpage": {"metadata": {"title": "Every Data Scientist needs some SparkMagic | by Jan Teichmann | Towards Data Science", "h1": "Every Data Scientist needs some SparkMagic", "description": "While data science is touted as the sexiest job of the 21st century, it is not spared of the infamous Pareto principle or 80/20 rule. 80% of a commercial data scientist\u2019s time is spent on finding\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/jupyter-incubator/sparkmagic", "anchor_text": "Sparkmagic", "paragraph_index": 6}, {"url": "https://www.linkedin.com/in/janteichmann/", "anchor_text": "https://www.linkedin.com/in/janteichmann/", "paragraph_index": 25}], "all_paragraphs": ["While data science is touted as the sexiest job of the 21st century, it is not spared of the infamous Pareto principle or 80/20 rule. 80% of a commercial data scientist\u2019s time is spent on finding, cleansing, and preparing data. It is the least productive as well as the most dreaded part of a data scientist\u2019s job.", "The internet offers endless opinions on how to break the 80/20 rule for data science but good advice is nevertheless hard to come by. A main source for the low productivity lies in the duality of data preparation:", "Big data is mostly unstructured and stored in production environments with enterprise governance and security restrictions in place. Accessing the data at speed requires costly distributed systems which are centrally managed by IT and have to be commonly shared with other data scientists and analysts.", "Spark is the data industries gold standard for working with data in distributed data lakes. But to work with Spark clusters cost-efficiently, and even allow multi-tenancy, it is difficult to accommodate individual requirements and dependencies. The industry trend for distributed data infrastructure is towards ephemeral clusters which makes it even harder for data scientists to deploy and manage their Jupyter notebook environments.", "It\u2019s no surprise that many data scientists work locally on high-spec laptops where they can install and persist their Jupyter notebook environments more easily. So far so understandable. How do many data scientists then connect their local development environment with the data in the production data lake? They materialise csv files with Spark and download them from the cloud storage console.", "Manually downloading csv files from cloud storage consoles is neither productive nor is it particularly robust. Wouldn\u2019t it be so much better to seamlessly connect a local Jupyter Notebook with a remote cluster in an end-user friendly and transparent way? Meet SparkMagic!", "Sparkmagic is a project to interactively work with remote Spark clusters in Jupyter notebooks through the Livy REST API. It provides a set of Jupyter Notebook cell magics and kernels to turn Jupyter into an integrated Spark environment for remote clusters.", "You can use the following Dockerfile to build a Jupyter Notebook with SparkMagic support:", "Build the image and tag it with:", "And start a local Jupyter container with Spark Magic support mounting your current working directory:", "To be able to connect to the Livy REST API on your remote Spark cluster you have to use ssh port forwarding on your local computer. Get the IP address of your remote cluster and run:", "First, create a new Notebook with the SparkMagic enabled PySpark kernel as follows:", "In the SparkMagic enabled Notebook, you have a series of cell magics available to work across the local notebook as well as your remote Spark cluster as an integrated environment. The %%help magic prints out all the available magic commands:", "You can configure your remote Spark Application with the %%configure magic:", "As you can see in the screenshot above the SparkMagic automatically started a remote PySpark Session and provides some useful links to connect to the Spark UI and logs.", "The following code cell first imports the SparkSql types remotely. Secondly, it loads the Enigma-JHU Covid-19 data-set onto our remote Spark cluster using the remote SparkSession. We can see the output of the remote .show() command within our Notebook:", "But that\u2019s just where the Magic begins. We can register the dataframe as a Hive table and use the %%sql magic to execute Hive queries against the data on our remote cluster and create automated visualisations of the results in our local Notebook. While this isn\u2019t rocket science it is extremely convenient for data analysts and for quick data exploration in the early stages of a data science project.", "A truly useful feature of SparkMagic is to seamless pass data between the local Notebook and the remote cluster. The daily challenge of data scientists is to create and persist their Python environments while working with ephemeral clusters to interact with their company\u2019s data lake.", "In the following example, you can see how we import seaborn as a local library and use it to plot covid_data pandas data frame. But where does that data come from? It\u2019s been created and send by the remote Spark cluster. The magic %%spark -o allows us to define a remote variable to transfer to the local notebook context on cell execution. Our variable covid_data is a", "The ability to aggregate big data in a remote cluster to work with locally in a Jupyter Notebook using Pandas is extremely helpful for data exploration. E.g. to use Spark to pre-aggregate data for a histogram into counts by bins to plot the histogram in Jupyter using the pre-aggregated counts and a simple bar plot. Another useful feature is the ability to sample a remote Spark DataFrame with the magic %%spark -o covid_data -m sample -r 0.5", "The integrated environment allows you also to sent local data to the remote Spark cluster using the magic %%send_to_spark", "The two data types supported are Pandas DataFrames and strings. To send anything more else or more complex, for example, a trained scikit model for scoring, to the remote Spark cluster you can use serialisation to create a string representation for transfer:", "As you saw, there is a big pain point to this pattern of ephemeral PySpark clusters: bootstrapping EMR clusters with Python packages. This problem isn\u2019t going away when you deploy production workloads. You can read how to use PEX to speed up deployment of PySpark applications on ephemeral AWS EMR clusters in my previous blog post:", "Jan is a successful thought leader and consultant in the data transformation of companies and has a track record of bringing data science into commercial production usage at scale. He has recently been recognised by dataIQ as one of the 100 most influential data and analytics practitioners in the UK.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m a Data Scientist by Profession; Techie, Geek and Innovator with Passion. https://www.linkedin.com/in/janteichmann/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F853da0b81006&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----853da0b81006--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jan.teichmann?source=post_page-----853da0b81006--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jan.teichmann?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Jan Teichmann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F941c2fa7cfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&user=Jan+Teichmann&userId=941c2fa7cfd&source=post_page-941c2fa7cfd----853da0b81006---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining#/media/File:CRISP-DM_Process_Diagram.png", "anchor_text": "Kenneth Jensen"}, {"url": "https://github.com/jupyter-incubator/sparkmagic", "anchor_text": "Sparkmagic"}, {"url": "https://raw.githubusercontent.com/jupyter-incubator/sparkmagic/master/sparkmagic/example_config.json", "anchor_text": "https://raw.githubusercontent.com/jupyter-incubator/sparkmagic/master/sparkmagic/example_config.json"}, {"url": "https://towardsdatascience.com/pex-the-secret-sauce-for-the-perfect-pyspark-deployment-of-aws-emr-workloads-9aef0d8fa3a5", "anchor_text": "PEX \u2014 The secret sauce for the perfect PySpark deployment of AWS EMR workloadsHow to use PEX to speed up deployment of PySpark applications on ephemeral AWS EMR clusterstowardsdatascience.com"}, {"url": "https://www.linkedin.com/in/janteichmann/", "anchor_text": "https://www.linkedin.com/in/janteichmann/"}, {"url": "https://medium.com/@jan.teichmann", "anchor_text": "https://medium.com/@jan.teichmann"}, {"url": "https://medium.com/tag/data-science?source=post_page-----853da0b81006---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----853da0b81006---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----853da0b81006---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/spark?source=post_page-----853da0b81006---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/jupyter-notebook?source=post_page-----853da0b81006---------------jupyter_notebook-----------------", "anchor_text": "Jupyter Notebook"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&user=Jan+Teichmann&userId=941c2fa7cfd&source=-----853da0b81006---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&user=Jan+Teichmann&userId=941c2fa7cfd&source=-----853da0b81006---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----853da0b81006--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F853da0b81006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----853da0b81006---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----853da0b81006--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----853da0b81006--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----853da0b81006--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----853da0b81006--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----853da0b81006--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jan.teichmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jan.teichmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jan Teichmann"}, {"url": "https://medium.com/@jan.teichmann/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://www.linkedin.com/in/janteichmann/", "anchor_text": "https://www.linkedin.com/in/janteichmann/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F941c2fa7cfd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&user=Jan+Teichmann&userId=941c2fa7cfd&source=post_page-941c2fa7cfd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F463734a42bc7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevery-data-scientist-can-need-some-spark-magic-853da0b81006&newsletterV3=941c2fa7cfd&newsletterV3Id=463734a42bc7&user=Jan+Teichmann&userId=941c2fa7cfd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}