{"url": "https://towardsdatascience.com/spectral-clustering-82d3cff3d3b7", "time": 1682994852.034018, "path": "towardsdatascience.com/spectral-clustering-82d3cff3d3b7/", "webpage": {"metadata": {"title": "Spectral clustering. The intuition and math behind how it\u2026 | by Neerja Doshi | Towards Data Science", "h1": "Spectral clustering", "description": "Clustering is a widely used unsupervised learning method. The grouping is such that points in a cluster are similar to each other, and less similar to points in other clusters. Thus, it is up to the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Laplacian_matrix", "anchor_text": "Graph Laplacian", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors", "anchor_text": "eigenvalues", "paragraph_index": 12}, {"url": "https://medium.com/@neerja.doshi", "anchor_text": "other blogs", "paragraph_index": 17}, {"url": "https://www.linkedin.com/in/neerja-doshi/", "anchor_text": "https://www.linkedin.com/in/neerja-doshi/", "paragraph_index": 18}, {"url": "https://www.linkedin.com/in/neerja-doshi/", "anchor_text": "https://www.linkedin.com/in/neerja-doshi/", "paragraph_index": 20}], "all_paragraphs": ["Clustering is a widely used unsupervised learning method. The grouping is such that points in a cluster are similar to each other, and less similar to points in other clusters. Thus, it is up to the algorithm to find patterns in the data and group it for us and, depending on the algorithm used, we may end up with different clusters.", "There are 2 broad approaches for clustering:1. Compactness \u2014 Points that lie close to each other fall in the same cluster and are compact around the cluster center. The closeness can be measured by the distance between the observations. E.g.: K-Means Clustering2. Connectivity \u2014 Points that are connected or immediately next to each other are put in the same cluster. Even if the distance between 2 points is less, if they are not connected, they are not clustered together. Spectral clustering is a technique that follows this approach.", "The difference between the 2 can easily be shown by this illustration:", "In spectral clustering, the data points are treated as nodes of a graph. Thus, clustering is treated as a graph partitioning problem. The nodes are then mapped to a low-dimensional space that can be easily segregated to form clusters. An important point to note is that no assumption is made about the shape/form of the clusters.", "Spectral clustering involves 3 steps:1. Compute a similarity graph2. Project the data onto a low-dimensional space3. Create clusters", "We first create an undirected graph G = (V, E) with vertex set V = {v1, v2, \u2026, vn} = 1, 2, \u2026, n observations in the data. This can be represented by an adjacency matrix which has the similarity between each vertex as its elements . To do this, we can either compute:", "1) The \u03b5-neighborhood graph: Here we connect all points whose pairwise distances are smaller than \u03b5. As the distances between all connected points are roughly of the same scale (at most \u03b5), weighting the edges would not incorporate more information about the data to the graph. Hence, the \u03b5-neighborhood graph is usually considered as an unweighted graph.", "2) KNN Graph: Here we use K Nearest Neighbors to connect vertex vi with vertex vj if vj is among the k-nearest neighbors of vi. But we may have an issue if the nearest neighbors are not symmetric, i.e. if there is a vertex vi which has vj as a nearest neighbor, it is not necessary that vi is a nearest neighbor of vj. Thus, we end up getting a directed graph which is a problem as we do not know what similarity between 2 points means in that case. There are two ways of making this graph undirected. The first way is to simply ignore the directions of the edges, i.e. we connect vi and vj with an undirected edge if vi is among the k-nearest neighbors of vj or if vj is among the k-nearest neighbors of vi . The resulting graph is what is usually called the k-nearest neighbor graph. The second choice is to connect vertices vi and vj if both vi is among the k-nearest neighbors of vj and vj is among the k-nearest neighbors of vi . The resulting graph is called the mutual k-nearest neighbor graph. In both cases, after connecting the appropriate vertices we weight the edges by the similarity of the adjacent points.", "3) Fully connected graph: To construct this graph, we simply connect all points with each other, and we weight all edges by similarity sij. This graph should model the local neighborhood relationships, thus similarity functions such as Gaussian similarity function are used.", "Here the parameter \u03c3 controls the width of the neighborhoods, similar to the parameter \u03b5 in case of the \u03b5-neighborhood graph.", "Thus, when we create an adjacency matrix for any of these graphs, Aij ~ 1 when the points are close and Aij \u2192 0 if the points are far apart. Consider the following graph with nodes 1 to 4, weights (or similarity) wij and its adjacency matrix:", "As we can see in Figure 1, data points in the same cluster may also be far away\u2013even farther away than points in different clusters. Our goal then is to transform the space so that when the 2 points are close, they are always in same cluster, and when they are far apart, they are in different clusters. We need to project our observations into a low-dimensional space. For this, we compute the Graph Laplacian, which is just another matrix representation of a graph and can be useful in finding interesting properties of a graph. This can be computed as:", "The whole purpose of computing the Graph Laplacian L was to find eigenvalues and eigenvectors for it, in order to embed the data points into a low-dimensional space. So now, we can go ahead and find eigenvalues. We know that:", "Let us consider an example with numbers:", "We then compute eigenvalues and eigenvectors for L.", "For this step, we use the eigenvector corresponding to the 2nd eigenvalue to assign values to each node. On calculating, the 2nd eigenvalue is 0.189 and the corresponding eigenvector v2 = [0.41, 0.44, 0.37, -0.4, -0.45, -0.37]. To get bipartite clustering (2 distinct clusters), we first assign each element of v2 to the nodes such that {node1:0.41 , node2:0.44 , \u2026 node6: -0.37}. We then split the nodes such that all nodes with value > 0 are in one cluster, and all other nodes are in the other cluster. Thus, in this case, we get nodes 1, 2 & 3 in one cluster, and 4, 5 & 6 in the 2nd cluster.", "It is important to note that the 2nd eigenvalue indicates how tightly connected the nodes are in the graph. For good, clean partitioning, lower the 2nd eigenvalue, better the clusters.", "In this blog I have explained the math behind spectral clustering. Any feedback or suggestions are welcome! Do check out my other blogs in the mean time!", "A data scientist, currently protecting AWS customers from fraud. Prior work in building predictive and recommendation algorithms for businesses in the financial space.LinkedIn : https://www.linkedin.com/in/neerja-doshi/", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist @ AWS, MS Data Science @ USF, https://www.linkedin.com/in/neerja-doshi/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F82d3cff3d3b7&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@neerja.doshi?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@neerja.doshi?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Neerja Doshi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dff2ff1664&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&user=Neerja+Doshi&userId=3dff2ff1664&source=post_page-3dff2ff1664----82d3cff3d3b7---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/UVzcwmngd2s?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Alexandre Chambon"}, {"url": "https://unsplash.com/search/photos/semi-circles?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Laplacian_matrix", "anchor_text": "Graph Laplacian"}, {"url": "https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors", "anchor_text": "eigenvalues"}, {"url": "https://medium.com/@neerja.doshi", "anchor_text": "other blogs"}, {"url": "https://calculatedcontent.com/2012/10/09/spectral-clustering/", "anchor_text": "https://calculatedcontent.com/2012/10/09/spectral-clustering/"}, {"url": "http://ai.stanford.edu/~ang/papers/nips01-spectral.pdf", "anchor_text": "http://ai.stanford.edu/~ang/papers/nips01-spectral.pdf"}, {"url": "https://www.youtube.com/watch?v=zkgm0i77jQ8", "anchor_text": "https://www.youtube.com/watch?v=zkgm0i77jQ8"}, {"url": "https://www.linkedin.com/in/neerja-doshi/", "anchor_text": "https://www.linkedin.com/in/neerja-doshi/"}, {"url": "https://medium.com/tag/data-science?source=post_page-----82d3cff3d3b7---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-algebra?source=post_page-----82d3cff3d3b7---------------linear_algebra-----------------", "anchor_text": "Linear Algebra"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----82d3cff3d3b7---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/clustering?source=post_page-----82d3cff3d3b7---------------clustering-----------------", "anchor_text": "Clustering"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----82d3cff3d3b7---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&user=Neerja+Doshi&userId=3dff2ff1664&source=-----82d3cff3d3b7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&user=Neerja+Doshi&userId=3dff2ff1664&source=-----82d3cff3d3b7---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F82d3cff3d3b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----82d3cff3d3b7---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----82d3cff3d3b7--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@neerja.doshi?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@neerja.doshi?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Neerja Doshi"}, {"url": "https://medium.com/@neerja.doshi/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "677 Followers"}, {"url": "https://www.linkedin.com/in/neerja-doshi/", "anchor_text": "https://www.linkedin.com/in/neerja-doshi/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dff2ff1664&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&user=Neerja+Doshi&userId=3dff2ff1664&source=post_page-3dff2ff1664--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F57721081e405&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspectral-clustering-82d3cff3d3b7&newsletterV3=3dff2ff1664&newsletterV3Id=57721081e405&user=Neerja+Doshi&userId=3dff2ff1664&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}