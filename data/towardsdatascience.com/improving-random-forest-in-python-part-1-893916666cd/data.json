{"url": "https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd", "time": 1682993195.2360792, "path": "towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd/", "webpage": {"metadata": {"title": "Improving the Random Forest in Python Part 1 | by Will Koehrsen | Towards Data Science", "h1": "Improving the Random Forest in Python Part 1", "description": "In a previous post we went through an end-to-end implementation of a simple random forest in Python for a supervised regression problem. Although we covered every step of the machine learning\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@williamkoehrsen/random-forest-in-python-24d0893d51c0", "anchor_text": "previous post", "paragraph_index": 0}, {"url": "http://scikit-learn.org/", "anchor_text": "Scikit-Learn library", "paragraph_index": 0}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf", "anchor_text": "\u2018The Unreasonable Effectiveness of Data\u201d", "paragraph_index": 2}, {"url": "http://data-informed.com/why-more-data-and-simple-algorithms-beat-complex-analytics-models/", "anchor_text": "echoed the idea", "paragraph_index": 2}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained", "anchor_text": "GitHub page", "paragraph_index": 3}, {"url": "https://www.ncdc.noaa.gov/cdo-web/", "anchor_text": "NOAA Climate Data Online Tool", "paragraph_index": 4}, {"url": "http://www.noaa.gov/", "anchor_text": "NOAA", "paragraph_index": 6}, {"url": "https://www.r-project.org/", "anchor_text": "R statistical language", "paragraph_index": 7}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib library", "paragraph_index": 13}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained", "anchor_text": "GitHub", "paragraph_index": 13}, {"url": "http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/", "anchor_text": "strong positive correlation", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/42_(number)#The_Hitchhiker's_Guide_to_the_Galaxy", "anchor_text": "42", "paragraph_index": 21}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/blob/master/random_forest_explained/Improving%20Random%20Forest%20Part%201.ipynb", "anchor_text": "notebook", "paragraph_index": 23}, {"url": "http://projects.ict.usc.edu/itw/gel/EricssonDeliberatePracticePR93.PDF", "anchor_text": "human abilities", "paragraph_index": 28}, {"url": "https://climate.nasa.gov/effects/", "anchor_text": "limate change is increasing temperatures", "paragraph_index": 30}, {"url": "http://blog.datadive.net/selecting-good-features-part-iii-random-forests/", "anchor_text": "random forest performs implicit feature selection", "paragraph_index": 30}, {"url": "https://en.wikipedia.org/wiki/Dimensionality_reduction", "anchor_text": "reducing the number of features", "paragraph_index": 30}, {"url": "http://www.cs.cmu.edu/~tom/10601_fall2012/slides/pca.pdf", "anchor_text": "principal components analysis", "paragraph_index": 30}, {"url": "http://wwwf.imperial.ac.uk/~nsjones/TalkSlides/HyvarinenSlides.pdf", "anchor_text": "independent component analysis", "paragraph_index": 30}, {"url": "https://docs.python.org/3/tutorial/datastructures.html", "anchor_text": "tuples", "paragraph_index": 32}, {"url": "https://www.python-course.eu/list_comprehension.php", "anchor_text": "list comprehensive", "paragraph_index": 32}, {"url": "https://www.bradmontgomery.net/blog/pythons-zip-map-and-lambda/", "anchor_text": "zip", "paragraph_index": 32}, {"url": "https://docs.python.org/3/howto/sorting.html", "anchor_text": "sorting", "paragraph_index": 32}, {"url": "https://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/", "anchor_text": "argument unpacking", "paragraph_index": 32}], "all_paragraphs": ["In a previous post we went through an end-to-end implementation of a simple random forest in Python for a supervised regression problem. Although we covered every step of the machine learning process, we only briefly touched on one of the most critical parts: improving our initial machine learning model. The model we finished with achieved decent performance and beat the baseline, but we should be able to better the model with a couple different approaches. This article is the first of two that will explore how to improve our random forest machine learning model using Python and the Scikit-Learn library. I would recommend checking out the introductory post before continuing, but the concepts covered here can also stand on their own.", "There are three general approaches for improving an existing machine learning model:", "These are presented in the order in which I usually try them. Often, the immediate solution proposed to improve a poor model is to use a more complex model, often a deep neural network. However, I have found that approach inevitably leads to frustration. A complex model is built over many hours, which then also fails to deliver, leading to another model and so on. Instead, my first question is always: \u201cCan we get more data relevant to the problem?\u201d. As Geoff Hinton (the father of deep neural networks) has pointed out in an article titled \u2018The Unreasonable Effectiveness of Data\u201d, the amount of useful data is more important to the problem than the complexity of the model. Others have echoed the idea that a simple model and plenty of data will beat a complex model with limited data. If there is more information that can help with our problem that we are not using, the best payback in terms of time invested versus performance gained is to get that data.", "This post will cover the first method for improving ML models, and the second approach will appear in a subsequent article. I will also write end-to-end implementations of several algorithms which may or may not beat the random forest (If there are any requests for specific algorithms, let me know in the comments)! All of the code and data for this example can be found on the project GitHub page. I have included plenty of code in this post, not to discourage anyone unfamiliar with Python, but to show how accessible machine learning has become and to encourage anyone to start implementing these useful models!", "As a brief reminder, we are dealing with a temperature prediction problem: given historical data, we want to predict the maximum temperature tomorrow in our city. I am using Seattle, WA, but feel free to use the NOAA Climate Data Online Tool to get info for your city. This task is a supervised, regression machine learning problem because we have the labels (targets) we want to predict, and those labels are continuous values (in contrast to unsupervised learning where we do not have labels, or classification, where we are predicting discrete classes). Our original data used in the simple model was a single year of max temperature measurements from 2016 as well as the historical average max temperature. This was supplemented by the predictions of our \u201cmeteorologically-inclined\u201d friend, calculated by randomly adding or subtracting 20 degrees from the historical average.", "Our final performance using the original data was an average error of 3.83 degrees compared to a baseline error of 5.03 degrees. This represented a final accuracy of 93.99%.", "In the first article, we used one year of historical data from 2016. Thanks to the NOAA (National Atmospheric and Oceanic Administration), we can get data going back to 1891. For now, let\u2019s restrict ourselves to six years (2011\u20132016), but feel free to use additional data to see if it helps. In addition to simply getting more years of data, we can also include more features. This means we can use additional weather variables that we believe will be useful for predicting the max temperature. We can use our domain knowledge (or advice from the experts), along with correlations between the variable and our target to determine which features will be helpful. From the plethora of options offered by the NOAA (seriously, I have to applaud the work of this organization and their open data policy), I added average wind speed, precipitation, and snow depth on the ground to our list of variables. Remember, because we are predicting the maximum temperature for tomorrow, we can\u2019t actually use the measurement on that day. We have to shift it one day into the past, meaning we are using today\u2019s precipitation total to predict the max temperature tomorrow. This prevents us from \u2018cheating\u2019 by having information from the future today.", "The additional data was in relatively good shape straight from the source, but I did have to do some slight modifications before reading it into Python. I have left out the \u201cdata munging\u201d details to focus on the Random Forest implementation, but I will release a separate post showing how to clean the data. I use the R statistical language for munging because I like how it makes data manipulation interactive, but that\u2019s a discussion for another article. For now, we can load in the data and examine the first few rows.", "ws_1: average wind speed from the day before (mph)", "prcp_1: precipitation from the day before (in)", "snwd_1: snow depth on the ground from the day before (in)", "Before we had 348 days of data. Let\u2019s look at the size now.", "There are now over 2000 days of historical temperature data (about 6 years). We should summarize the data to make sure there are no anomalies that jump out in the numbers.", "Nothing appears immediately anomalous from the descriptive statistics. We can quickly graph all of the variables to confirm this. I have left out the plotting code because while the matplotlib library is very useful, the code is non-intuitive and it can be easy to get lost in the details of the plots. (All the code is available for inspection and modification on GitHub).", "First up are the four temperature plots.", "Next we can look at the historical max average temperature and the three new variables.", "From the numerical and graphical inspection, there are no apparent outliers n our data. Moreover, we can examine the plots to see which features will likely be useful. I think the snow depth will be the least helpful because it is zero for the majority of days, likewise, the wind speed looks to be too noisy to be of much assistance. From prior experience, the historical average max temperature and prior max temperature will probably be most important, but we will just have to see!", "We can make one more exploratory plot, the pairplot, to visualize the relationships between variables. This plots all the variables against each other in scatterplots allowing us to inspect correlations between features. The code for this impressive-looking plot is rather simple compared to the above graphs!", "The diagonal plots show the distribution of each variable because graphing each variable against itself would just be a straight line! The colors represent the four seasons as shown in the legend on the right. What we want to concentrate on are the trends between the actual max temperature and the other variables. These plots are in the bottom row, and to see a specific relationship with the actual max, move to the row containing the variable. For example, the plot in the bottom left shows the relationship between the actual max temperature and the max temperature from the previous day (temp_1). This is a strong positive correlation, indicating that as the max temperature one day prior increases, the max temperature the next day also increases", "The data has been validation both numerically and graphically, and now we need to put it in a format understandable by the machine learning algorithm. We will perform exactly the same data formatting procedure as in the simple implementation:", "We can do all of those steps in a few lines of Python.", "We set a random seed (of course it has to be 42) to ensure consistent results across runs. Let\u2019s quickly do a check of the sizes of each array to confirm everything is in order.", "Good to go! We have about 4.5 years of training data and 1.5 years of testing data. However, before we can get to the fun part of modeling, there is one additional step.", "In the previous post, we used the historical average maximum temperature as our target to beat. That is, we evaluated the accuracy of predicting the max temperature tomorrow as the historical average max temperature on that day. We already know even the model trained on a single year of data can beat that baseline so we need to raise our expectations. For a new baseline, we will use the model trained on the original data. To make a fair comparison, we need to test it against the new, expanded test set. However, the new test set has 17 features, whereas the original model was only trained on 14 features. We first have to remove the 3 new features from the test set and then evaluate the original model. The original random forest has already been trained on the original data and code below shows preparing the testing features and evaluating the performance (refer to the notebook for the model training).", "The random forest trained on the single year of data was able to achieve an average absolute error of 4.3 degrees representing an accuracy of 92.49% on the expanded test set. If our model trained with the expanded training set cannot beat these metrics, then we need to rethink our method.", "The great part about Scikit-Learn is that many state-of-the-art models can be created and trained in a few lines of code. The random forest is one example:", "Now, we can make predictions and compare to the known test set targets to confirm or deny that our expanded training dataset was a good investment:", "Well, we didn\u2019t waste our time getting more data! Training on six years worth of historical measurements and using three additional features has netted us a 16.41% improvement over the baseline model. The exact metrics will change depending on the random seed, but we can be confident that the new model outperforms the old model.", "Why does a model improve with more data? The best way to answer this is to think in terms of how humans learn. We increase our knowledge of the world through experiences, and the more times we practice a skill, the better we get. A machine learning model also \u201clearns from experience\u201d in the sense that each time it looks at another training data point, it learns a little more about the relationships between the features and labels. Assuming that there are relationships in the data giving the model more data will allow it to better understand how to map a set of features to a label. For our case, as the model sees more days of weather measurements, it better understands how to take those measurements and predict the maximum temperature on the next day. Practice improves human abilities and machine learning model performance alike.", "In some situations, we can go too far and actually use too much data or add too many features. One applicable example is a machine learning prediction problem involving building energy which I am currently working on. The problem is to predict building energy consumption in 15-minute intervals from weather data. For each building, I have 1\u20133 years of historical weather and electricity use data. Surprisingly, I found as I included more data for some buildings, the prediction accuracy decreased. Asking around, I determined some buildings had undergone retrofits to improve energy efficiency in the middle of data collection, and therefore, recent electricity consumption differed significantly from before the retrofit. When predicting current consumption, using data from before the modification actually decreased the performance of my models. More recent data from after the change was more relevant than the older data, and for several buildings, I ended up decreasing the amount of historical data to improve performance!", "For our problem, the length of the data is not an issue because there have been no major changes affecting max temperatures in the six years of data (climate change is increasing temperatures but on a longer timescale). However, it may be possible we have too many features. We saw earlier that some of the features, especially our friend\u2019s prediction, looked more like noise than an accurate predictor of the maximum temperature. Extra features can decrease performance because they may \u201cconfuse\u201d the model by giving it irrelevant data that prevents it from learning the actual relationships. The random forest performs implicit feature selection because it splits nodes on the most important variables, but other machine learning models do not. One approach to improve other models is therefore to use the random forest feature importances to reduce the number of variables in the problem. In our case, we will use the feature importances to decrease the number of features for our random forest model, because, in addition to potentially increasing performance, reducing the number of features will shorten the run time of the model. This post does not touch on more complex dimensionality reductions such as PCA (principal components analysis) or ICA (independent component analysis). These do a good job of decreasing the number of features while not decreasing information, but they transform the features such that they no longer represent our measured variables. I like machine learning models to have a blend of interpretability and accuracy, and I generally therefore stick to methods that allow me to understand how the model is making predictions.", "Finding the feature importances of a random forest is simple in Scikit-Learn. The actual calculation of the importances is beyond this blog post, but this occurs in the background and we can use the relative percentages returned by the model to rank the features.", "The following Python code creates a list of tuples where each tuple is a pair, (feature name, importance). The code here takes advantage of some neat tricks in the Python language, namely list comprehensive, zip, sorting, and argument unpacking. Don\u2019t worry if you do not understand these entirely, but if you want to become skilled at Python, these are tools you should have in your arsenal!", "These stats definitely prove that some variables are much more important to our problem than others! Given that there are so many variables with zero importance (or near-zero due to rounding), it seems like we should be able to get rid of some of them without impacting performance. First, let\u2019s make a quick graph to represent the relative differences in feature importances. I left this plotting code in because it\u2019s a little easier to understand.", "We can also make a cumulative importance graph that shows the contribution to the overall importance of each additional variable. The dashed line is drawn at 95% of total importance accounted for.", "We can now use this to remove unimportant features. 95% is an arbitrary threshold, but if it leads to noticeably poor performance we can adjust the value. First, we need to find the exact number of features to exceed 95% importance:", "We can then create a new training and testing set retaining only the 6 most important features.", "We decreased the number of features from 17 to 6 (although to be fair, 7 of those features were created from the one-hot encoding of day of the week so we really only had 11 pieces of unique information). Hopefully this will not significantly decrease model accuracy and will considerably decrease the training time.", "Now we go through the same train and test procedure as we did with all the features and evaluate the accuracy.", "The performance suffers a minor increase of 0.12 degrees average error using only 6 features. Often with feature reduction, there will be a minor decrease in performance that must be weighed against the decrease in run-time. Machine learning is a game of making trade-offs, and run-time versus performance is usually one of the critical decisions. I will quickly do some bench-marking to compare the relative run-times of the two models (see Jupyter Notebook for code).", "Overall, the reduced features model has a relative accuracy decrease of 0.131% with a relative run-time decrease of 35.1%. In our case, run-time is inconsequential because of the small size of the data set, but in a production setting, this trade-off likely would be worth it.", "Instead of developing a more complex model to improve our random forest, we took the sensible step of collecting more data points and additional features. This approach was validated as we were able to decrease the error of compared to the model trained on limited data by 16.7%. Furthermore, by reducing the number of features from 17 to 6, we decreased our run-time by 35% while suffering only a minor decrease in accuracy. The best way to summarize these improvements is with another graph. The model trained on one year of training data is on the left, the model using six years of data and all features is in the middle, and the model on the right used six years of data but only a subset of the most important features.", "This example has demonstrated the effectiveness of increasing the amount of data. While most people make the mistake of immediately moving to a more powerful model, we have learned most problems can be improving by collecting more relevant data points. In further parts of this series, we will take a look at the other ways to improve our model, namely, hyperparameter tuning and using different algorithms. However, getting more data is likely to have the largest payoff in terms of time invested versus increase in performance in this situation. The next time you see someone rushing to implement a complex deep learning model after failing on the first model, nicely ask them if they have exhausted all sources of data. Chances are, if there is still data out there relevant to their problem, they can get better performance and save time in the process!", "As always, I appreciate any comments and constructive feedback. I can be reached at wjk68@case.edu", "Data Scientist at Cortex Intel, Data Science Communicator"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F893916666cd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----893916666cd---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F893916666cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----893916666cd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F893916666cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=-----893916666cd---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@williamkoehrsen/random-forest-in-python-24d0893d51c0", "anchor_text": "previous post"}, {"url": "http://scikit-learn.org/", "anchor_text": "Scikit-Learn library"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf", "anchor_text": "\u2018The Unreasonable Effectiveness of Data\u201d"}, {"url": "http://data-informed.com/why-more-data-and-simple-algorithms-beat-complex-analytics-models/", "anchor_text": "echoed the idea"}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained", "anchor_text": "GitHub page"}, {"url": "https://www.ncdc.noaa.gov/cdo-web/", "anchor_text": "NOAA Climate Data Online Tool"}, {"url": "http://www.noaa.gov/", "anchor_text": "NOAA"}, {"url": "https://www.r-project.org/", "anchor_text": "R statistical language"}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib library"}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained", "anchor_text": "GitHub"}, {"url": "http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/", "anchor_text": "strong positive correlation"}, {"url": "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html", "anchor_text": "Numpy arrays"}, {"url": "https://en.wikipedia.org/wiki/42_(number)#The_Hitchhiker's_Guide_to_the_Galaxy", "anchor_text": "42"}, {"url": "https://github.com/WillKoehrsen/Data-Analysis/blob/master/random_forest_explained/Improving%20Random%20Forest%20Part%201.ipynb", "anchor_text": "notebook"}, {"url": "http://projects.ict.usc.edu/itw/gel/EricssonDeliberatePracticePR93.PDF", "anchor_text": "human abilities"}, {"url": "https://climate.nasa.gov/effects/", "anchor_text": "limate change is increasing temperatures"}, {"url": "http://blog.datadive.net/selecting-good-features-part-iii-random-forests/", "anchor_text": "random forest performs implicit feature selection"}, {"url": "https://en.wikipedia.org/wiki/Dimensionality_reduction", "anchor_text": "reducing the number of features"}, {"url": "http://www.cs.cmu.edu/~tom/10601_fall2012/slides/pca.pdf", "anchor_text": "principal components analysis"}, {"url": "http://wwwf.imperial.ac.uk/~nsjones/TalkSlides/HyvarinenSlides.pdf", "anchor_text": "independent component analysis"}, {"url": "https://docs.python.org/3/tutorial/datastructures.html", "anchor_text": "tuples"}, {"url": "https://www.python-course.eu/list_comprehension.php", "anchor_text": "list comprehensive"}, {"url": "https://www.bradmontgomery.net/blog/pythons-zip-map-and-lambda/", "anchor_text": "zip"}, {"url": "https://docs.python.org/3/howto/sorting.html", "anchor_text": "sorting"}, {"url": "https://www.geeksforgeeks.org/packing-and-unpacking-arguments-in-python/", "anchor_text": "argument unpacking"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----893916666cd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----893916666cd---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----893916666cd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/learning?source=post_page-----893916666cd---------------learning-----------------", "anchor_text": "Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F893916666cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----893916666cd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F893916666cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----893916666cd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F893916666cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----893916666cd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7d4a87a913e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&newsletterV3=e2f299e30cb9&newsletterV3Id=e7d4a87a913e&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----893916666cd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Written by Will Koehrsen"}, {"url": "https://williamkoehrsen.medium.com/followers?source=post_page-----893916666cd--------------------------------", "anchor_text": "38K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----893916666cd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7d4a87a913e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimproving-random-forest-in-python-part-1-893916666cd&newsletterV3=e2f299e30cb9&newsletterV3Id=e7d4a87a913e&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----893916666cd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Hyperparameter Tuning the Random Forest in PythonImproving the Random Forest Part Two"}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "12 min read\u00b7Jan 10, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F28d2aa77dd74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----28d2aa77dd74----0-----------------clap_footer----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=author_recirc-----893916666cd----0---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F28d2aa77dd74&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&source=-----893916666cd----0-----------------bookmark_preview----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----893916666cd----1---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----893916666cd----1-----------------bookmark_preview----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----893916666cd----2---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----893916666cd----2-----------------bookmark_preview----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "Random Forest in PythonA Practical End-to-End Machine Learning Example"}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": "21 min read\u00b7Dec 27, 2017"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24d0893d51c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-in-python-24d0893d51c0&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----24d0893d51c0----3-----------------clap_footer----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0?source=author_recirc-----893916666cd----3---------------------8fed2c74_ff79_4211_81f2_e465270a7aef-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "61"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24d0893d51c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frandom-forest-in-python-24d0893d51c0&source=-----893916666cd----3-----------------bookmark_preview----8fed2c74_ff79_4211_81f2_e465270a7aef-------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "See all from Will Koehrsen"}, {"url": "https://towardsdatascience.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "275"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----893916666cd----0-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----893916666cd----1-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b717 min read\u00b75 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----0-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----893916666cd----0---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----893916666cd----0-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----893916666cd----1---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----893916666cd----1-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@rfeers?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Josep Ferrer"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Stop doing this on ChatGPT and get ahead of the 99% of its usersUnleash the Power of AI Writing with Effective Prompts"}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b78 min read\u00b7Mar 31"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&user=Josep+Ferrer&userId=8213af8f3ccf&source=-----f3441bf7a25a----2-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/stop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a?source=read_next_recirc-----893916666cd----2---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "71"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3441bf7a25a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fstop-doing-this-on-chatgpt-get-ahead-99-users-ai-artificial-intelligence-productivity-prompt-engineering-4-f3441bf7a25a&source=-----893916666cd----2-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-does-xgboost-handle-multiclass-classification-6c76ba71f6f0?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@guillaume.saupin?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/@guillaume.saupin?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Saupin Guillaume"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-does-xgboost-handle-multiclass-classification-6c76ba71f6f0?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "How Does XGBoost Handle Multiclass Classification?It\u2019s crucial to understand the underlying workings of classification using this kind of model, as it impacts performance."}, {"url": "https://towardsdatascience.com/how-does-xgboost-handle-multiclass-classification-6c76ba71f6f0?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": "\u00b77 min read\u00b7Jan 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6c76ba71f6f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-does-xgboost-handle-multiclass-classification-6c76ba71f6f0&user=Saupin+Guillaume&userId=891e27328f3a&source=-----6c76ba71f6f0----3-----------------clap_footer----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-does-xgboost-handle-multiclass-classification-6c76ba71f6f0?source=read_next_recirc-----893916666cd----3---------------------36f37047_762a_4f37_8745_5a89e02a720e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c76ba71f6f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-does-xgboost-handle-multiclass-classification-6c76ba71f6f0&source=-----893916666cd----3-----------------bookmark_preview----36f37047_762a_4f37_8745_5a89e02a720e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----893916666cd--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----893916666cd--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----893916666cd--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----893916666cd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----893916666cd--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----893916666cd--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----893916666cd--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}