{"url": "https://towardsdatascience.com/image-clustering-implementation-with-pytorch-587af1d14123", "time": 1683016184.376965, "path": "towardsdatascience.com/image-clustering-implementation-with-pytorch-587af1d14123/", "webpage": {"metadata": {"title": "Image Clustering Implementation with PyTorch | by Anders Ohrn | Towards Data Science", "h1": "Image Clustering Implementation with PyTorch", "description": "Supervised image classification with Deep Convolutional Neural Networks (DCNN) is nowadays an established process. With pre-trained template models plus fine-tuning optimization, very high accuracies\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pubmed.ncbi.nlm.nih.gov/31926806/", "anchor_text": "this recent study", "paragraph_index": 0}, {"url": "https://pytorch.org/hub/pytorch_vision_inception_v3/", "anchor_text": "template Inception v3 model", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1903.12355", "anchor_text": "Local Aggregation by Zhuang et al.", "paragraph_index": 5}, {"url": "https://arxiv.org/abs/1801.07648", "anchor_text": "many possible DCNN clustering techniques", "paragraph_index": 5}, {"url": "https://pytorch.org", "anchor_text": "PyTorch library", "paragraph_index": 6}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo", "paragraph_index": 6}, {"url": "https://science.sciencemag.org/content/313/5786/504.abstract", "anchor_text": "including dimensionality reduction", "paragraph_index": 10}, {"url": "https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/", "anchor_text": "this", "paragraph_index": 11}, {"url": "https://afagarap.works/2020/01/26/implementing-autoencoder-in-pytorch.html", "anchor_text": "this", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1511.00561.pdf", "anchor_text": "SegNet", "paragraph_index": 11}, {"url": "https://www.geeksforgeeks.org/vgg-16-cnn-model/", "anchor_text": "VGG template convolutional network", "paragraph_index": 11}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html#classification", "anchor_text": "readily available in the PyTorch library", "paragraph_index": 16}, {"url": "https://naokishibuya.medium.com/up-sampling-with-transposed-convolution-9ae4f2df52d0", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo", "paragraph_index": 30}, {"url": "https://arxiv.org/abs/1903.12355", "anchor_text": "Local Aggregation (LA) method", "paragraph_index": 35}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn", "paragraph_index": 46}, {"url": "https://arxiv.org/pdf/1808.04699.pdf", "anchor_text": "paper by Wu et al", "paragraph_index": 51}, {"url": "https://mathworld.wolfram.com/HyperspherePointPicking.html", "anchor_text": "Marsaglia\u2019s method", "paragraph_index": 57}, {"url": "https://pytorch.org/docs/stable/notes/autograd.html", "anchor_text": "PyTorch\u2019s back-propagation machinery", "paragraph_index": 66}, {"url": "https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting", "anchor_text": "numpy arrays cannot be broadcast", "paragraph_index": 67}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo", "paragraph_index": 69}, {"url": "http://journal.sjdm.org/20/200330/jdm200330.pdf", "anchor_text": "decision heuristics have evolved", "paragraph_index": 78}], "all_paragraphs": ["Supervised image classification with Deep Convolutional Neural Networks (DCNN) is nowadays an established process. With pre-trained template models plus fine-tuning optimization, very high accuracies can be attained for many meaningful applications \u2014 like this recent study on medical images, which attains 99.7% accuracy on prostate cancer diagnosis with the template Inception v3 model, pre-trained on images of everyday objects.", "For unsupervised image machine learning, the current state of the art is far less settled.", "Clustering is one form of unsupervised machine learning, wherein a collection of items \u2014 images in this case \u2014 are grouped according to some structure in the data collection per se. Images that end up in the same cluster should be more alike than images in different clusters.", "Image data can be complex \u2014 varying backgrounds, multiple objects in view \u2014so it is not obvious what it means for a pair of images to be more alike than another pair of images. Without a ground truth label, it is often unclear what makes one clustering method better than another.", "On the one hand, unsupervised problems are therefore vaguer than the supervised ones. There is no given right answer to optimize for. On the other hand, it is from vague problems, hypothesis generation, problem discovery, tinkering, that the most interesting stuff emerge. Tools that afford new capacities in these areas of a data and analytics workflow are worth our time and effort.", "I will describe the implementation of one recent method for image clustering (Local Aggregation by Zhuang et al. from 2019). This is one of many possible DCNN clustering techniques that have been published in recent years.", "I use the PyTorch library to show how this method can be implemented and I provide several detailed code snippets throughout the text. Complete code is available in a repo.", "Despite that image clustering methods are not readily available in standard libraries, as their supervised siblings are, PyTorch nonetheless enables a smooth implementation of what really is a very complex method. Hence I am able to explore, test and gently poke at the enigmatic problem of what DCNNs can do when applied to a clustering task.", "My goal is to show how starting from a few concepts and equations, you can use PyTorch to arrive at something very concrete that can be run on a computer and guide further innovation and tinkering with respect to whatever task you have.", "I will apply this to images of fungi. Why fungi? You\u2019ll see later.", "Before I get to the clustering method, I will implement an Auto-Encoder (AE). AEs have a variety of applications, including dimensionality reduction, and are interesting in themselves. Their role in image clustering will become clear later.", "Basic AEs are not that diffucult to implement with the PyTorch library (see this and this for two examples). I will implement the specific AE architecture that is part of the SegNet method, which builds on the VGG template convolutional network. VGG defines an architecture and was originally developed for supervised image classifications.", "The architecture of the AE is illustrated below.", "The steps of the image auto-encoding are:", "Time to put this design into code.", "I start with creating an Encoder module. The first lines, including the initialization method, look like:", "The architecture of the Encoder is the same as the feature extraction layers of the VGG-16 convolutional network. That part is therefore readily available in the PyTorch library, torchvision.models.vgg16_bn, see line 19 in the code snippet.", "Unlike the canonical application of VGG, the Code is not fed into the classification layers. The last two layers vgg.classifier and vgg.avgpool are therefore discarded.", "The layers of the encoder require one adjustment. In the unpooling layers of the Decoder, the pooling indices from the max-pooling layers of the Encoder must be available, which the dashed arrows represent in the previous image. The template version of VGG-16 does not generate these indices. The pooling layers can however be re-initialized to do so. That is what the _encodify method of the EncoderVGG module accomplishes.", "As this is a PyTorch Module (inherits from nn.Module), a forward method is required to implement the forward pass of a mini-batch of image data through an instance of EncoderVGG:", "The method executes each layer in the Encoder in sequence, and gathers the pooling indices as they are created. After execution of the Encoder module, the Code is returned along with an ordered collection of pooling indices.", "It is a \u201ctransposed\u201d version of the VGG-16 network. I use scare quotes because the Decoder layers look a great deal like the Encoder in reverse, but strictly speaking it is not an inverse or transpose.", "The initialization of the Decoder module is a touch thicker:", "The _invert_ method iterates over the layers of the Encoder in reverse.", "A convolution in the Encoder (green in the image) is replaced with the corresponding transposed convolution in the Decoder (light green in the image). The nn.ConvTranspose2d is the library module in PyTorch for this and it upsamples the data, rather than downsample, as the better-known convolution operation does. For further explanation see here.", "A max-pooling in the Encoder (purple) is replaced with the corresponding unpooling (light purple), or nn.MaxUnpool2d referring to the PyTorch library module.", "The Code is the input, along with the list of pooling indices as created by the Encoder. The pooling indices are taken one at a time, in reverse, whenever an unpooling layer is executed. That way information about how the Encoder performed max pooling is transferred to the Decoder.", "Therefore, following the transposed layers that mirror the Encoder layers, the output of forward is a tensor of identical shape as the tensor of the image input to the Encoder.", "The complete Auto-Encoder module is implemented as a basic combination of Encoder and Decoder instances:", "A set of parameters of the AE that produces an output quite similar to the corresponding input is a good set of parameters. I use the mean-square error for each channel of each pixel between input and output of the AE to quantify this as an objective function, or nn.MSELoss in the PyTorch library.", "With the AE model defined plus a differentiable objective function, the powerful tools of PyTorch are deployed for back-propagation in order to obtain a gradient, which is followed by network parameter optimization. I will not get into the details of how the training is implemented (the curious reader can look at ae_learner.py in the repo).", "After training the AE, it contains an Encoder that can approximately represent recurring higher-level features of the image dataset in a lower dimension. For an image data set of fungi, these features can be shapes, boundaries, and colours that are shared between several images of mushrooms. In other words, the Encoder embodies a compact representation of mushroom-ness plus typical backgrounds.", "Two images that are very similar with respect to these higher-level features should therefore correspond to Codes that are closer together \u2014 as measured by Euclidean distance or cosine-similarity for example \u2014 than any pair of random Codes.", "On the other hand, the compression of the image into the lower dimension is highly non-linear. Therefore, a distance between two Codes, greater than some rather small threshold, is expected to say little about the corresponding images. This is not ideal for the creation of well-defined, crisp clusters.", "The Encoder trained as part of an AE is a starting point. The Encoder is next to be refined to compress images into Codes by exploiting a learned mushroom-ness and to create Codes that also form inherently good clusters.", "The Local Aggregation (LA) method defines an objective function to quantify how well a collection of Codes cluster. The objective function makes no direct reference to a ground truth label about the content of the image, like the supervised machine learning methods do. Rather, the objective function quantifies how amenable to well-defined clusters the encoded image data intrinsically is.", "It is not self-evident that well-defined clusters obtained in this manner should create meaningful clusters, that is, images that appear similar are part of the same cluster more often than not. That\u2019s why implementation and testing is needed.", "First a few definitions from the LA publication of what to implement.", "The cluster objective in LA is:", "The x\u1d62 in this equation is an image tensor, and \u03b8 denote the parameters of the Encoder. The v\u1d62 on the right-hand side is the Code corresponding to x\u1d62. The two sets C\u1d62 and B\u1d62 are comprised of Codes of other images in the collection, and they are named the close neighbours and background neighbours, respectively, to v\u1d62.", "The probabilities, P, are defined for a set of Codes A as:", "In other words, an exponential potential defines the probability, where one Code v\u2c7c contributes more probability density the greater the dot-product with v\u1d62 is. Hence, a set A that is comprised of mostly other Codes similar (in the dot-product sense) to v\u1d62, defines a cluster to which v\u1d62 is a likely member.", "The scalar \u03c4 is called temperature and defines a scale for the dot-product similarity.", "For a given collection of images of fungi, {x\u1d62}, the objective is to find parameters \u03b8 that minimize the cluster objective for the collection. The authors of the LA paper present an argument why this objective makes sense. I will not repeat that argument here. To put it very simply, the cleaner the assignment of the Codes are to one cluster, as compared to the complement of that cluster, the lower the value of the cluster objective.", "In the section above on AE, the custom Encoder module was described. What is missing is the objective function of LA, since that one is not part of the library loss functions in PyTorch.", "A custom loss function module needs to be implemented.", "The initialization of the loss function module initializes a number of scikit-learn library functions that are needed to define the background and close neighbour sets in the forward method.", "The NearestNeighbors instance provides an efficient means to compute nearest neighbours for data points. This will be used to define the sets B. The KMeans instances provide an efficient means to compute clusters of data points. These will be used to define the sets C. This will be clearer once the execution of the module is dealt with.", "Speaking of which: the required forward method of LocalAggregationLoss.", "The forward method accepts a mini-batch of Codes which the current version of the Encoder has produced, plus the indices of said Codes within the complete data set. Since it is common to shuffle data when creating a mini-batch, the indices can be a list of non-contiguous integers, though in equal number to the size of the mini-batch of Codes (checked bythe assert statement).", "There are two principal parts of forward. First the neighbour sets B, C and their intersection, are evaluated. Second, the probability densities are computed for the given batch of Codes and the sets, which then are aggregated into the ratio of log-probabilities of the LA cluster objective function as defined above.", "The creators of LA adopt a trick of a memory bank, which they attribute to another paper by Wu et al. It is a way to deal with that the gradient of the LA objective function depends on the gradients of all Codes of the data set.", "A proper gradient of said function would have to compute terms like these:", "The sum over all Codes on the right-hand side means a large number of tensors has to be computed and kept at all time for the back-propagation. To iterate over mini-batches of images will not help with the efficiency because the tangled gradients of the Codes with respect to Decoder parameters must be computed regardless.", "Because the quality of clustering relates one image to all other images of the data set, rather than a fixed ground truth label, this entanglement is understandable.", "The memory bank trick amounts to treating other Codes than the ones in a current mini-batch as constants. The entanglement with derivatives of other Codes therefore goes away. As long as the approximated gradients are good enough to guide the optimization towards a minimum, this is a useful approximation.", "The memory bank class is implemented as:", "It consists of unit data vectors of the same dimension and same number as the data set to be clustered (initialized uniformly on the hypersphere by Marsaglia\u2019s method). So a task involving one-thousand images with Encoder that generates Codes of dimension 512, implies a memory bank of one-thousand unit vectors in the real coordinate vector space of dimension 512. Once a new set of vectors are given to the memory bank, along with the corresponding indices, the memory is updated with some mixing rate memory_mixing_rate. The class also contains a convenience method to convert a collection of integer indices into a boolean mask for the entire data set.", "And note that the memory bank only deals with numbers. The memory bank can in no way connect to the back-propagation machinery of PyTorch tensors. The memory bank is updated, but through running averages, not directly as a part of the back-propagation.", "It is an instance of MemoryBank that is stored in thememory_bank attribute of LocalAggregationLoss.", "Back again to the forward method of LocalAggregationLoss. I implement the neighbour set creations using the previously initialized scikit-learn classes.", "The _nearest_neighbours and _intersecter are fairly straightforward. The former relies on the method to find nearest neighbours. It considers all data points in the memory bank.", "The _close_grouper performs several clusterings of the data points in the memory bank. Those data points which are part of the same cluster as the point of interest, v\u1d62, define that close neighbour set, C\u1d62. The authors of the LA paper motivate the use of multiple clustering runs with that clustering contains a random component, so by performing multiple ones, they smooth out the noise.", "To illustrate, the red point in the image below is the Code of interest in a sea of other Codes. Clustering of the current state of the memory bank puts the point of interest in a cluster of other points (green in middle image). Nearest neighbours defines another set of related data points (purple in the right-hand image). The _nearest_neighbours and _close_grouper create these two sets for each Code in the mini-batch, and represent the sets as boolean masks.", "With the two sets (B\u1d62 and B\u1d62 intersected with C\u1d62) for each Code v\u1d62 in the batch, it is time to compute the probability densities. This density should be differentiable with PyTorch methods as well.", "In lines 14\u201316 all the different dot-products are computed between the Codes of the mini-batch and the memory bank subset. The np.compress applies the mask to the memory bank vectors.", "The torch.matmul computes all the dot-products, taking the mini-batch dimension into account. Note also that the tensor codes contains a record of the mathematical operations of the Encoder. So as additional PyTorch operations are performed, this record is extended, and ultimately, this enables PyTorch\u2019s back-propagation machinery, autograd, to evaluate the gradients of the loss criterion with respect to all parameters of the Encoder.", "Conceptually the same operations take place in lines 25\u201327, however in this clause the mini-batch dimension is explicitly iterated over. This is needed when numpy arrays cannot be broadcast, which is the case for ragged arrays (at least presently).", "To put it all together, something like the code below gets the training going for a particular dataset, VGG Encoder and LA.", "I omit from the discussion how the data is prepared (operations I put in the fungidata file). Details can be found in the repo. For this discussion it is sufficient to view the dataloader as returning mini-batches of images of fungi, inputs['image'], and their corresponding indices within the larger dataset, inputs['idx']. The memory bank codes are initialized with normalized codes from the Encoder pre-trained as part of an Auto-Encoder.", "The training loop is functional, though abbreviated, see la_learner file for details, though nothing out of the ordinary is used.", "I use a slightly modified version of the Encoder, EncoderVGGMerged. It is a subclass of EncoderVGG .", "This class appends to the conclusion of the Encoder a merger layer that is applied to the Code, so it is a vector along one dimension.", "I illustrate the encoder model for clustering applied to one RGB 64x64 image as input.", "Next I illustrate the forward pass for one mini-batch of images of the model that creates the output and loss variables.", "The LALoss module in the illustration interacts with the memory bank, taking into account the indices of the images of the mini-batch within the total dataset of size N. It constructs clusters and nearest neighbours of the current state of the memory bank and relates the mini-batch of codes to these subsets.", "The backward pass performs the back-propagation, which begins at the loss output of the LA criterion, then follows the mathematical operations involving Codes backwards, and by the chain-rule, an approximate gradient of the LA objective function with respect to Encoder parameters is obtained.", "I will apply this method to images of fungi. My reasons:", "As an added bonus, the biology and culture of fungi is remarkable \u2014 one fun cultural component is how decision heuristics have evolved among mushroom foragers in order to navigate between the edible and the lethal. I can image some very interesting test-cases of machine learning on image data created from photos of fungi.", "Three images from the database are shown below.", "One downside of LA is that it involves several hyper-parameters. Sadly I do not have an abundance of GPUs standing by, so I must limit myself to very few of the many possible variations of hyper-parameters and fungi image selections.", "My focus in this article is on implementation from concept and equations (plus a plug for fungi image data). Therefore I pursue illustration and inspiration here, and I will keep further conclusions to high-level observations.", "I train the AE on chanterelles and agaric mushrooms cropped to 224x224. With a stochastic-gradient descent optimizer, the AE eventually converge, though for certain optimization parameters the training gets stuck in sub-optima. One example of the input and output of the trained AE is shown below.", "There is a clear loss of fidelity, especially in the surrounding grass, though the distinct red cap is roughly recovered in the decoded output.", "With the Encoder from the AE as starting point, the Encoder is further optimized with respect to the LA objective. The same set of mushroom images is used, a temperature of 0.07 and mixing rate of 0.5 (as in the original paper) and the number of clusters set about one tenth of the number of images to be clustered. Since my image data set is rather small, I set the background neighbours to include all images in the data set. The training of the Encoder with the LA objective converges eventually.", "One illustrative cluster of images is shown below:", "It is intuitive that the distinct white-dotted caps of fly agaric cluster. However, the cluster also contains images that are quite different in appearance. And inspecting other clusters, the white-dotted fly agaric caps appear occasionally in other clusters.", "Another illustrative cluster is shown below.", "The images have something in common that sets them apart from typical images: darker colours, mostly from brown leaves in the background, though the darker mushroom in the lower-right (black chanterelle or black trumpet) stands out.", "But again, images that meet that rough criterium appear in other clusters as well, suggesting there are additional non-linear relations encoded, which make the above images correspond to relatively close and distinct Codes, while others do not. Explainability is even harder than usual.", "I also note that many clusters contain just one image. Changing the number of cluster centroids that goes into the k-means clustering impacts this, but then very large clusters of images appear as well for which an intuitive explanation of shared features are hard to provide.", "These are illustrative results of what other runs generate as well. The minimization of LA at least in the few and limited runs I made here creates clusters of images in at best moderate correspondence with what at least to my eye is a natural grouping.", "Given the flexibility of deep neural networks, I expect there can be very many ways to compress images into crisp clusters, with no guarantee these ways embody a useful meaning as far as my eye can tell. Unlike the case with ground truth labels where the flexibility of the neural network is guided towards a goal we define as useful prior to optimization, the optimizer is here free to find features to exploit to make cluster quality high.", "Perhaps a different inductive bias is needed to better limit how the flexibility is deployed in order to minimize the LA objective function? Perhaps the LA objective function should be combined with an additional objective to keep it from deviating from some sensible range as far as my visual cognition is concerned? Perhaps I should use standardized images, like certain medical images, passport photographs, or a fixed perspective camera, to limit variations in the images to fewer high-level features, which the encoding can exploit in the clustering? Or maybe the real answer to my concerns is to throw more GPUs at the problem and figure out that perfect combination of hyper-parameters?", "All speculations of course. Thanks to PyTorch, though, the hurdles are lower on the path from concepts and equations to prototyping and creation beyond settled template solutions.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Quantitative if possible, towards first principles, pragmatic always. Innovation, biology, computation & complexity."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F587af1d14123&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----587af1d14123--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AJOhrn?source=post_page-----587af1d14123--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AJOhrn?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Anders Ohrn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F12f21dc7a56b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&user=Anders+Ohrn&userId=12f21dc7a56b&source=post_page-12f21dc7a56b----587af1d14123---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pubmed.ncbi.nlm.nih.gov/31926806/", "anchor_text": "this recent study"}, {"url": "https://pytorch.org/hub/pytorch_vision_inception_v3/", "anchor_text": "template Inception v3 model"}, {"url": "https://arxiv.org/abs/1903.12355", "anchor_text": "Local Aggregation by Zhuang et al."}, {"url": "https://arxiv.org/abs/1801.07648", "anchor_text": "many possible DCNN clustering techniques"}, {"url": "https://pytorch.org", "anchor_text": "PyTorch library"}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo"}, {"url": "https://science.sciencemag.org/content/313/5786/504.abstract", "anchor_text": "including dimensionality reduction"}, {"url": "https://analyticsindiamag.com/how-to-implement-convolutional-autoencoder-in-pytorch-with-cuda/", "anchor_text": "this"}, {"url": "https://afagarap.works/2020/01/26/implementing-autoencoder-in-pytorch.html", "anchor_text": "this"}, {"url": "https://arxiv.org/pdf/1511.00561.pdf", "anchor_text": "SegNet"}, {"url": "https://www.geeksforgeeks.org/vgg-16-cnn-model/", "anchor_text": "VGG template convolutional network"}, {"url": "https://pytorch.org/docs/stable/torchvision/models.html#classification", "anchor_text": "readily available in the PyTorch library"}, {"url": "https://naokishibuya.medium.com/up-sampling-with-transposed-convolution-9ae4f2df52d0", "anchor_text": "here"}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo"}, {"url": "https://arxiv.org/abs/1903.12355", "anchor_text": "Local Aggregation (LA) method"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "scikit-learn"}, {"url": "https://arxiv.org/pdf/1808.04699.pdf", "anchor_text": "paper by Wu et al"}, {"url": "https://mathworld.wolfram.com/HyperspherePointPicking.html", "anchor_text": "Marsaglia\u2019s method"}, {"url": "https://pytorch.org/docs/stable/notes/autograd.html", "anchor_text": "PyTorch\u2019s back-propagation machinery"}, {"url": "https://numpy.org/doc/stable/user/basics.broadcasting.html#module-numpy.doc.broadcasting", "anchor_text": "numpy arrays cannot be broadcast"}, {"url": "https://github.com/anderzzz/monkey_caput", "anchor_text": "repo"}, {"url": "https://svampe.databasen.org", "anchor_text": "annotated crowd-sourced open data"}, {"url": "http://www.svampeatlas.dk", "anchor_text": "www.svampeatlas.dk"}, {"url": "http://journal.sjdm.org/20/200330/jdm200330.pdf", "anchor_text": "decision heuristics have evolved"}, {"url": "https://medium.com/tag/clustering?source=post_page-----587af1d14123---------------clustering-----------------", "anchor_text": "Clustering"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----587af1d14123---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/mushrooms?source=post_page-----587af1d14123---------------mushrooms-----------------", "anchor_text": "Mushrooms"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----587af1d14123---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/tutorial?source=post_page-----587af1d14123---------------tutorial-----------------", "anchor_text": "Tutorial"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&user=Anders+Ohrn&userId=12f21dc7a56b&source=-----587af1d14123---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&user=Anders+Ohrn&userId=12f21dc7a56b&source=-----587af1d14123---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----587af1d14123--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F587af1d14123&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----587af1d14123---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----587af1d14123--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----587af1d14123--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----587af1d14123--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----587af1d14123--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----587af1d14123--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AJOhrn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AJOhrn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Anders Ohrn"}, {"url": "https://medium.com/@AJOhrn/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "329 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F12f21dc7a56b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&user=Anders+Ohrn&userId=12f21dc7a56b&source=post_page-12f21dc7a56b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fde626f3f3375&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-clustering-implementation-with-pytorch-587af1d14123&newsletterV3=12f21dc7a56b&newsletterV3Id=de626f3f3375&user=Anders+Ohrn&userId=12f21dc7a56b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}