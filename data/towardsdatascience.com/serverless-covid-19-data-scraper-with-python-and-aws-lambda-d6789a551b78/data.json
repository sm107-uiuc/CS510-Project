{"url": "https://towardsdatascience.com/serverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78", "time": 1683006999.980906, "path": "towardsdatascience.com/serverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78/", "webpage": {"metadata": {"title": "Serverless COVID-19 Data Scraper with Python and AWS Lambda | by Joe T. Santhanavanich | Towards Data Science", "h1": "Serverless COVID-19 Data Scraper with Python and AWS Lambda", "description": "In Data Science, getting the complete data source is one of the most important things. In several projects, data sources are dynamically changing, updating fast. For the COVID-19 pandemic, the number\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.worldometers.info/coronavirus/", "anchor_text": "Worldometer", "paragraph_index": 4}, {"url": "https://s3.console.aws.amazon.com/", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://console.aws.amazon.com/iam", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://gist.github.com/JoeThunyathep/663a580d09988303b385a224b523c177", "anchor_text": "gist", "paragraph_index": 13}, {"url": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html", "anchor_text": "here", "paragraph_index": 16}, {"url": "https://cyberduck.io/", "anchor_text": "Cyberduck", "paragraph_index": 17}], "all_paragraphs": ["In Data Science, getting the complete data source is one of the most important things. In several projects, data sources are dynamically changing, updating fast. For the COVID-19 pandemic, the number of cases changing all the time. Most available open COVID-19 sources are available only in daily intervals; however, the data in higher resolution seems to be important to find relations to other parameters such as air quality, environmental conditions, etc. Gathering data yourself by scraping them from the update real-time source is one of a solution to get data you desire for. Some articles had already shown examples of how to do this easily in Python. However, scheduling such a Python project needs a server machine that running all the time. For a small project, it may not worth renting/hosting a server yourself for this purpose.", "For this reason, I would like to introduce the AWS Lambda a compute service from Amazon where you can run or schedule any of your Python script (or other programming languages like Java, Go, Node.js, Ruby, C#, \u2026) without maintaining a server yourself. With the AWS Lambda, we can also work sync easily with files in the AWS S3 bucket.", "The best of all, the AWS Lambda is in the Always Free Tier service! (As of May 2020) It allows us to make a request up to 1 million requests per month! For example, if we scrape the dataset from internet every 1 minute, that is only 43200 requests per month (60 [requests /hour]* 24 [hour/day]* 30[day/month]).", "This article shows step-by-step instructions for scheduling a Python script for scraping COVID-19 data using AWS Lambda with AWS S3 bucket storage.", "First, we will prepare a Python script (covid19scraper.py) to scrape real-time global COVID-19 data from Worldometer using Requests and Beautiful Soup library. Overall, the Python script for scrape COVID-19 data looks like the following example:", "This technique has been shown several times already. So I would give only a short brief of this script. The requests is used to make a GET request to the URL and then the BeautifulSoup is used to query the specific class of the HTML body. In our case, the COVID-19 case data is in the class called \u201cmaincounter-number\u201d so the bsObj.find_all(\u2026) is called to find all values we interested in. By calling scrapeGlobalCase(), we would get the following result:", "To host our Python script on the AWS Lambda service, we need to prepare the Python modules with the script in the zip file. First, we have to install all modules locally with pip and -t ./ tag to specify saving in a local directory. In our example, we would need datetime beautifulsoup4 and request modules, you may run the following command to install them locally:", "Then, use the zip command to create a zip file of this python folder or do it with your preferred zip software (Winzip, 7zip, ..).", "As we will save our result to the AWS S3 bucket, let\u2019s create one by visiting your AWS console through the web browser (here). Click on create a bucket and assign a meaningful name for this project. You may select any region based on your preference. I named it as \u201chourlycovid19\u201d for saving COVID-19 case data hourly.", "We need to generate a role for our AWS Lambda to be able to access the S3 bucket we just created on the last step. Please do this by visit the AWS IAM console. (here) Select \u201cRole\u201d in the menu and click on \u201cCreate role\u201d then select on the \u201cLambda\u201d use case. Find a policy called \u201cAWSLambdaExecute\u201d which will allow Lambda to access the S3 bucket. After confirmation, you may name this role \u201clambda-s3-role\u201d.", "Now, everything is almost already, it is time to upload our zip Python package to the Lambda Layer to make our Python script executable on the Lambda. We can do this by browsing to the AWS Lambda Page and click on the \u201cLayers\u201d menu and click \u201cCreate Layer\u201d, give a name, select our zip file, and select Python runtime.", "Now, let\u2019s create a Lambda function to execute the script we prepared. Browse to the AWS Lambda Page and click on the \u201cFunctions\u201d menu and click \u201cCreate function\u201d as the figure above. Then, select \u201cAuthor from scratch\u201d with \u201cPython 3.x\u201d runtime. It is important to select the existing role \u201clambda-s3-role\u201d which you created on step 4 to allow this function to access the S3 bucket. You may follow the example setting as in the figure below.", "After the \u201ccovid19scrape\u201d function is created, then attach the \u201ccovidScraper\u201d layer we created from Step 5 to this function. This action will let our function able to read and call Python script we create at Step 1.", "Now, please head to the Function code part in the lambda function. Here, we will write a Python script that defines the Lambda handler that imports the \u201cscrapeGlobalCase\u201d function from the \u201ccovid19scrape\u201d Python script (as you named it in step 1) from the \u201ccovidScraper\u201d layer. We also import the \u201cboto3\u201d library for accessing the S3 service. Overall, the Python script in function code to scrape COVID-19 data and save to the S3 bucket would look like the figure below or you may check out the script at this gist. (**please change the BUCKET_NAME to match the S3 bucket you created from step 3)", "You may test it by clicking on the \u201cTEST\u201d button. Sometimes, the time out error may show up, the trick for solving this is to adjust the Basic settings for higher ram/ higher timeout time. For me, I set the ram at 3000 MB and 5-sec timeout.", "Congratulation!! \ud83c\udf89 If you follow until this step, now this Lambda function is ready to scrape COVID-19 data.", "As our function is ready, now let\u2019s schedule the function we created to run every hour (or with your preference) using CloudWatch. Please head to the AWS CloudWatch page and go to Events/Rules. From there, we can create a schedule rule using a fixed rate of time or using Cron expression to schedule the job at a specific time of day. If you are new to Cron expression, please read the documentation here on how to create one. In our case of 1-hour scheduling, you may use this expression: 0 * * * ? *", "All results are saved in the \u201chourlycovid19\u201d S3 bucket as separate JSON files. You may check them by going to the S3 bucket overview. You may connect download all JSON files from the S3 bucket to your local machine by AWS CLI. If you want to use easy GUI to download multiple files from S3, I recommend the Cyberduck \ud83e\udd86working pretty well.", "To show an example of how to use this dataset, you may use the example script below to read all JSON files in an output folder and add them to the dataframe.", "From this point, I believe you can easily find several tutorials to continue playing with the Python Pandas Dataframe to do some awesome data analysis or data visualization. Enjoy!! \u270c", "So, that\u2019s about it! If you are new to the cloud computing service, you may find this complex at first but I believe that you will love it once you make it run. I hope you like this article and able to apply this serverless Lambda service to run your workflow in the future.", "Please, feel free to left me a message if you have any questions or comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd6789a551b78&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://joets.medium.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": ""}, {"url": "https://joets.medium.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Joe T. Santhanavanich"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f7621d2a280&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&user=Joe+T.+Santhanavanich&userId=4f7621d2a280&source=post_page-4f7621d2a280----d6789a551b78---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://medium.com/@chaeyunkim", "anchor_text": "Chaeyun Kim"}, {"url": "https://aws.amazon.com/free/", "anchor_text": "AWS"}, {"url": "https://www.worldometers.info/coronavirus/", "anchor_text": "Worldometer"}, {"url": "https://gist.github.com/JoeThunyathep/9c0b4440f6d043d4653ae1e48eb2838d", "anchor_text": "covid19scraper.py"}, {"url": "https://s3.console.aws.amazon.com/", "anchor_text": "here"}, {"url": "https://console.aws.amazon.com/iam", "anchor_text": "here"}, {"url": "https://gist.github.com/JoeThunyathep/663a580d09988303b385a224b523c177", "anchor_text": "gist"}, {"url": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html", "anchor_text": "here"}, {"url": "https://cyberduck.io/", "anchor_text": "Cyberduck"}, {"url": "https://medium.com/tag/python?source=post_page-----d6789a551b78---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/covid-19?source=post_page-----d6789a551b78---------------covid_19-----------------", "anchor_text": "Covid-19"}, {"url": "https://medium.com/tag/aws-lambda?source=post_page-----d6789a551b78---------------aws_lambda-----------------", "anchor_text": "AWS Lambda"}, {"url": "https://medium.com/tag/programming?source=post_page-----d6789a551b78---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d6789a551b78---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&user=Joe+T.+Santhanavanich&userId=4f7621d2a280&source=-----d6789a551b78---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&user=Joe+T.+Santhanavanich&userId=4f7621d2a280&source=-----d6789a551b78---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd6789a551b78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d6789a551b78---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d6789a551b78--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d6789a551b78--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d6789a551b78--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d6789a551b78--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d6789a551b78--------------------------------", "anchor_text": ""}, {"url": "https://joets.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://joets.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Joe T. Santhanavanich"}, {"url": "https://joets.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "https://www.linkedin.com/in/thunyatheps/", "anchor_text": "https://www.linkedin.com/in/thunyatheps/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f7621d2a280&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&user=Joe+T.+Santhanavanich&userId=4f7621d2a280&source=post_page-4f7621d2a280--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbe1f3ef6d3d9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserverless-covid-19-data-scraper-with-python-and-aws-lambda-d6789a551b78&newsletterV3=4f7621d2a280&newsletterV3Id=be1f3ef6d3d9&user=Joe+T.+Santhanavanich&userId=4f7621d2a280&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}