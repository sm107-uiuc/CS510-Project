{"url": "https://towardsdatascience.com/practical-probability-theory-all-about-a-single-random-variable-8935cfa21a96", "time": 1683016990.711075, "path": "towardsdatascience.com/practical-probability-theory-all-about-a-single-random-variable-8935cfa21a96/", "webpage": {"metadata": {"title": "Practical Probability Theory: All About That Single Random Variable | by Shuai Guo | Towards Data Science", "h1": "Practical Probability Theory: All About That Single Random Variable", "description": "In this post, we will review some of the most useful probability concepts and important tools for exploratory data analysis. The table of content is given in the mind map above. Throughout the post\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/ShuaiGuo16/Univariate_probability_theory", "anchor_text": "Jupyter Notebook", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/List_of_the_verified_shortest_people", "anchor_text": "shortest man on earth", "paragraph_index": 4}, {"url": "https://time.com/3583663/worlds/", "anchor_text": "tallest man on earth", "paragraph_index": 4}, {"url": "http://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-ITM.pdf", "anchor_text": "here", "paragraph_index": 89}, {"url": "https://github.com/ShuaiGuo16/Univariate_probability_theory", "anchor_text": "Jupyter Notebook", "paragraph_index": 93}, {"url": "https://shuaiguo.medium.com/", "anchor_text": "Medium", "paragraph_index": 97}, {"url": "https://www.linkedin.com/in/shuaiguo16/", "anchor_text": "Linkedin", "paragraph_index": 97}], "all_paragraphs": ["In this post, we will review some of the most useful probability concepts and important tools for exploratory data analysis. The table of content is given in the mind map above. Throughout the post, I have created many illustrations to explain abstract concepts visually. Meanwhile, I\u2019ve used a dataset to show how the probability concepts are applied in practice. I hope those efforts could offer you a better reading experience.", "This post is all about understanding the underlying probability theories. To learn the code that realizes the probability calculations and visualizations discussed in the post, please check out the companion Jupyter Notebook I created.", "For now, we only consider one random variable (univariate). If you are interested in probability theories applied to multiple random variables (multivariate), check out the companion article I wrote:", "A random variable is defined as a variable whose value describes the outcome of a random event.", "This random event can be flipping a coin, where the corresponding random variable takes a value of either head or tail; Or, it can be measuring the height of an adult male, where the corresponding random variable takes a value anywhere between 0.54m (shortest man on earth) and 2.51m (tallest man on earth).", "Back to the height measurement example, say you\u2019ve been given a male height measurement dataset for further analysis, and you want to visualize the data first to gain a basic understanding. What would be the best way to do that? You may consider a histogram.", "Histogram works like this: first, divide the entire range of height values into a series of equal-sized intervals. This step creates the \u201cbins.\u201d Second, count how many height values fall into each interval. Finally, plot the counts of each interval. You\u2019ve created a histogram.", "Here is the histogram I plotted based on 1000 height measurements. A histogram is useful in exploratory data analysis (EDA) as it conveys insights regarding the distribution of the dataset.", "If you take a close look at the histogram shape, you may find it resembles a bell shape. Statisticians call that normal distribution. Not just people\u2019s height, blood pressure measurements, IQ scores, and student test scores all follow a normal distribution.", "So what does it mean by saying a random variable is \u201cnormally distributed\u201d? To understand that, we need to understand the concept of a probability density function.", "For a random variable, we are usually interested in the probability of observing its value within a certain range. If we make that range infinitely small, as in an infinitesimal interval [x, x+dx], we obtain the definition of the probability density function, or PDF, f(x): in this case, we can simply write the probability that a random variable\u2019s value falls within [x, x+dx] as f(x)dx.", "For a PDF, its name contains \u201cprobability density,\u201d as it resembles the concept of mass density in physics:", "Meanwhile, its name contains \u201cfunction,\u201d as the probability density values of a random variable will generally be different at different x locations.", "Equipped with the concept of PDF, we can now express the probability that a random variable falls within an interval [a,b] as an integral of this random variable\u2019s PDF over that range:", "Recall that a histogram also informs us about the probability of a random variable takes a value within a certain range. Are there any connections between a histogram and a PDF? Certainly, there is! In fact, a PDF can be conceived as the continuous version of the histogram.", "To see that better, let\u2019s try to turn the histogram we plotted earlier into a PDF. Here are the steps we take:", "In step 1, the probability value for each bin is calculated by dividing its counts by the sample size (1000 in our current case). In step 2, the probability density value for each bin is calculated by dividing its probability value by the bin width. This step is also known as normalization.", "Notice that the peak value of the PDF (around 4, which happens at around 1.8m height) we plotted above is greater than 1. So how come a probability value can be larger than 1? Wait a minute, that\u2019s just a common confusion people may have.", "To clear it up, remember that a PDF portrays the distribution of probability densities, not the probability itself. It is perfectly ok for probability density values to be greater than 1, cause they are calculated by dividing the probability values by the bin width. If the bin width is sufficiently small while the probability that the random variable falls into this bin is not negligible, we could get a probability density value bigger than 1, just as depicted in the figure above.", "When looking at Fig. 3(b), we don\u2019t see any bin taller than 1. This makes sense as it tells us the probability values in various bins.", "So exactly what has to be 1?", "PDF has an important property: An integral over its entire range equals 1. Mathematically, it writes as follows:", "This is easy to understand as the probability for the random variable to take a value within its possible range has to be one, i.e., it\u2019s bound to happen.", "In calculus, the integral in the above expression amounts to the area enclosed by the PDF curve and the x-axis. If that sounds abstract, let\u2019s use a histogram to connect the dots.", "We repeat the process of converting a histogram into a PDF (as shown below). Here, c\u1d62 denotes the number of data points that falls within the i-th bin, C is the total sample size, \u0394 represents the bin width.", "Say we have a total of N bins. If we sum up all the rectangle areas in Fig. 4(c), we get one:", "So why do we bother to calculate the area of a histogram with probability density? That\u2019s because we are actually calculating the area under a PDF curve! By using larger numbers of bins with smaller bin widths, we can eventually turn our histogram into a PDF (as shown below). However, the area sum of those tiny infinite bins remains one. Therefore, we conclude that the area enclosed by the PDF curve and the x-axis is 1.", "If we agree that the integral of a PDF amounts to the area under the PDF curve, we could then use that area to represent the probability:", "To see an example of the PDF, let\u2019s look at a normal distribution, the most important distribution in data science.", "As mentioned earlier, the male\u2019s height follows a normal distribution. Its distribution curve looks like a bell shape, which is the hallmark of a normal distribution. Mathematically, its PDF is written as follows:", "A normal distribution is governed by two parameters \u03bc and \u03c3. \u03bc is called mean. It describes the center location of the distribution. A normal distribution is symmetric about its mean. \u03c3 is called standard deviation. It measures how far the distribution spreads out. The square of standard deviation \u03c3\u00b2 is known as the variance.", "Since \u03bc and \u03c3 adequately determine a normal distribution, we commonly express a random variable X following a normal distribution as:", "Normal PDFs with various \u03bc-\u03c3 combinations are compared below. Notice that a PDF with a larger \u03c3 is wider but lower. This happens because the area under the PDF curve must be 1.", "You might have heard that a normal distribution has three magic numbers: 68, 95, and 99.7. Those numbers actually come from the so-called \u201c68\u201395\u201399.7 rule\u201d, which states that the probabilities for a normal random variable to lie within one, two, and three standard deviations around the mean are 68%, 95%, and 99.7%, respectively. The figure below illustrates this rule.", "The probability of observing a value outside the range [\u03bc-3\u03c3, \u03bc+ 3\u03c3] is tiny (<0.3%). If we have a data point that is more than 3\u03c3 away from the data mean, that data point may be considered an outlier. This is the so-called three-sigma rule of thumb in outlier detection.", "The standard normal distribution is a normal distribution with a mean value of 0 and a standard deviation value of 1. Here is the associated PDF expression:", "The practice of converting a normal random variable X~N(\u03bc,\u03c3\u00b2) into a standard normal random variable Z~N(0,1) is called standardization. The trick is to do the following transformation:", "Will that work? Let\u2019s test it on the male height dataset shown in Fig. 2 (Histogram). Our dataset has a mean value of 1.77m and a standard deviation value of 0.1m. After setting \u03bc=1.77 and \u03c3=0.1, we apply the above transformation on all our 1000 data. Subsequently, we plot a histogram of the transformed data in the probability density form, which is shown below. We can see that the obtained histogram matches perfectly with the standard normal distribution curve (red). Therefore, by applying the above transformation, we\u2019ve successfully converted the male height distribution into the standard normal distribution.", "Given the connection between Z~N(0,1) and X~N(\u03bc,\u03c3\u00b2), we can easily prove a useful property of the normal distribution, i.e., a linear transformation of a normal random variable is itself a normal random variable. Here is the proof:", "Say we have a random variable Y=aX+b, where X~N(\u03bc,\u03c3\u00b2). Our goal is to derive the distribution of Y. We can re-express Y as the following:", "By performing standardization, we are actually computing the z-score of each of our data points. In statistics, a z-score measures how many standard deviations a value is away from its population mean. It gives more context to the individual data as a data\u2019s z-score informs us where this data stands relative to the population this data comes from.", "Performing z-score standardization is a common data preprocessing technique in machine learning. This standardization process transforms features of the input dataset to comparable scales to facilitate better model training.", "For example, in clustering analysis, it is common to first standardize the features of the training data into their respective z-score forms before submitting to any clustering algorithms. This feature scaling step is crucial as clustering algorithms generally use distances between data points to determine their similarity. Standardization ensures that all the features contribute equally to the output.", "So we know we could use mean and standard deviation to characterize a normal distribution. But what about other distribution types? Which parameters should we use to characterize them?", "Expectation and variance are two important summary statistics to describe the distribution of a random variable. In this section, let\u2019s review their concepts and properties.", "The expectation is what you would expect the value taken by a random variable on average. It is also known as the mean or the expected value of the distribution. Given a random variable X and its PDF f(x), the expectation value of X is defined as:", "Recall that f(x)dx represents the probability that the random variable X falls within the interval [x, x+dx], i.e., f(x)dx = P(x<X<x+dx). Therefore, the above expression can be understood as a weighted sum of the possible values that X can take, where each value is weighted according to the probability of X falling within an infinitesimal interval associated with that value.", "The expectation is a linear operator, meaning that", "The prove of the above equation is rather straightforward:", "For a normal distribution, the mean \u03bc is the expectation. It is possible to prove the following equation. You can find detailed proof in the reference I attached at the end of this post.", "In statistical analysis, the variance is usually adopted as a measure of uncertainty. It describes the amount of variability of the random variable X around its expectation E[X]. We could adopt (X-E[X])\u00b2 as a measure of the deviation of X from its mean. By taking the expectation of this new measure, we obtain the definition of variance:", "Obviously, if X tends to take values that are close to E[X], the corresponding V[X] value will be small, and vice versa.", "The square root of the variance V[X] is called the standard deviation of X. It is often useful because it has the same unit as X.", "V[X] can also be expressed as the following:", "To prove the above equation, we start from the definition of the variance:", "Recall that E[X] is just a constant number. By using the linear property of the expectation operator, we have the following:", "Unlike expectation, the variance is not a linear operator.", "The proof of the above equation is given below:", "For a normal distribution, \u03c3\u00b2 is the variance. You could work out the following equation. Detailed proof can be found in the reference I attached at the end.", "Here is a summary of the important expressions related to expectation and variance:", "The cumulative distribution function (CDF) is another way to describe how a random variable's possible values are distributed. It is defined as the probability that X will take a value less than or equal to x:", "Equipped with this new concept, we can now express the probability P(a \u2264 X \u2264 b) in three equivalent ways: an integral of the PDF, an area under the PDF curve, as well as the difference between CDF values at two end locations:", "Previously we\u2019ve talked about using a histogram to visualize data distribution. Another useful tool to achieve a similar goal is the empirical cumulative distribution function, or ECDF in short. It is called \u201cempirical\u201d as it only estimates the underlying CDF based on the sample data.", "To see how to construct an ECDF, let\u2019s revisit the male height data we discussed earlier. Here is the procedure to generate the ECDF: first, we sort the height data in ascending order; second, for each sorted data value x\u1d62, we calculate the empirical probability P(X\u2264 x\u1d62), which equals to its sorted index divided by the total number of data (i.e., sample size); finally, we can plot the data points\u2019 values on the x-axis and plot their corresponding empirical probabilities on the y-axis, which gives us the ECDF.", "The plotted ECDF is shown below. Notice that ECDF is bounded in the range of [0, 1]. This makes sense as a probability value can only be within 0 and 1. Also, ECDF is a non-decreasing function, which reflects the fact that it shows cumulative probabilities. Finally, ECDF is handy as it directly shows us the percentage of the population having a value greater than or less than a certain threshold. This information is not readily available if we only have a PDF (which requires integrating first!).", "Recall that the male height data follows a normal distribution. As a result, Fig. 11 shows the typical look of a CDF coming from a normal distribution. Let\u2019s look more into that.", "Let\u2019s start with the standard normal distribution Z ~ N(0,1). We denote \u03a6(x) as the CDF of the standard normal distribution:", "Unfortunately, the above integral does not have a closed-form solution. Nevertheless, due to the importance of the normal distribution, many software packages have implemented functions to calculate \u03a6(x). In python, we could use scipy.stats.norm.cdf(x)to achieve that goal.", "Figure 12 shows the \u03a6(x) of the standard normal distribution. There are two properties associated with \u03a6(x):", "a. \u03a6(0)=0.5. This is because a standard normal random variable has an equal chance to land on either side of zero.", "Now, for a general normal distribution X~N(\u03bc,\u03c3\u00b2), we already knew by reversing the standardization operation, we can write X=\u03c3Z+\u03bc. Therefore, to find the CDF of X, we can write", "Therefore, we can write out the CDF of any normal distribution in the form of \u03a6(x). That basically explains why \u03a6(x) is so important that all statistical software packages have implemented this function.", "We can apply the above formula to the male height dataset to obtain its CDF. Given our dataset has a mean of 1.77 and a standard deviation of 0.1, we can directly express the required CDF as \u03a6 {(x-1.77)/0.1}, which is plotted below:", "We can see that the calculated CDF curve aligned nicely with the ECDF we\u2019ve obtained before.", "Normal CDFs with various \u03bc-\u03c3 combinations are compared in Fig. 14. Figure 14(a) shows that changing \u03bc merely shifts the CDF's relative location on the x-axis. Changing \u03c3, on the other hand, changes the slope of the CDF, as shown in Fig. 14(b). This is expected as \u03c3 controls the spread of the random variable. A larger \u03c3 means that the random variable distributes its probability more evenly over a larger range, which explains that the corresponding CDF slope is more gradual. On the contrary, a smaller \u03c3 means that the random variable focuses its probability in a small range near \u03bc. Therefore, the slope of the corresponding CDF will be steeper.", "Another important probability concept related to the CDF is the quantile function. Essentially, a quantile function is the inverse of the corresponding CDF. A CDF F(x) accepts a value x as its input and calculates the probability P(X\u2264x); A quantile function Q(\u03b1), on the other hand, accepts a probability value \u03b1 (0\u2264\u03b1\u22641) as the input and finds the value x\u03b1 such that P(X\u2264x\u03b1)=\u03b1. A visual demonstration of the relationship between a CDF and its corresponding quantile function is given in Fig. 15.", "To efficiently summarize a dataset, a data analyst tends to look at values of Q(0.25), Q(0.5), and Q(0.75). In fact, those values constitute the building block for the famous box plot, a powerful tool in EDA that enables a compact visualization of how the data are distributed.", "Here is a breakdown of the box plot. A box plot is built upon five numbers: median (the middle value of the dataset), first quartile Q\u2081, third quartile Q\u2083, maximum (the largest data point exclude any outliers), and minimum (the smallest data point exclude any outliers). In the context of a box plot, outliers are the data points outside 1.5 times the interquartile range (distance between Q\u2081 and Q\u2083) above Q\u2083 and below Q\u2081.", "The box plot for the previous male height dataset is shown in Fig. 17, along with its corresponding CDF on top. It is worth mentioning that the outliers identified by the box plot are not necessarily the \u201cwrong\u201d data. In Fig. 17, although all the male height data comes from the same normal distribution, several data points are classified as outliers by the standard of the box plot. For practical outlier detection, a box plot only provides a visual clue. You may need other statistics and sometimes domain knowledge to make the final decision.", "Nevertheless, a box plot is handy to answer if your data is symmetrical. If not, then how the data is skewed and how tightly the data is grouped. In Python, a box plot can be generated through Seaborn, Matplotlib, or directly Pandas.", "The Q-Q plot, or Quantile-Quantile plot, is an important tool to assess whether the sample data is normally distributed visually. It works by plotting the quantiles of the sample data and the standard normal distribution against each other. If the data came from a normal distribution, we should see the points forming a roughly straight line.", "Quantiles are cut points dividing the range of a probability distribution into intervals with equal probabilities. As we\u2019ve discussed earlier, Q\u2081, Q\u2082, and Q\u2083 are the quantiles which divide the distribution into four intervals, with each interval containing 25% of the probability.", "Similar to Q\u2081, Q\u2082, and Q\u2083 that create four equal-probable intervals, if our dataset contains N samples, we can create N+1 equal-probable intervals, where the N data points act as the quantiles. Subsequently, we can divide the standard normal distribution into N+1 equal-probable intervals, giving us the corresponding N quantiles. By plotting the re-ordered sample data on the y-axis and their corresponding quantiles of the standard normal distribution on the x-axis, we obtain the Q-Q plot.", "If we use the entire dataset, the corresponding Q-Q plot is shown in Fig. 19(a). We can clearly see that the points in the Q\u2013Q plot approximately lie on a line, indicating that the sample data is normally distributed.", "As a comparison, I\u2019ve generated another dataset containing uniformly distributed samples within the bounds of the minimum and maximum height values. Its Q-Q plot is shown in Fig. 19(b). For non-normal distributions, points in the Q\u2013Q plot exhibit large departures from the reference line. This observation gives us a visual clue to assess the normality of the data distribution.", "In this final section, let\u2019s review a simple algorithm to generate random samples from any given CDF \u2014 inverse transform sampling.", "This trick assumes that you know the CDF of the random variable. It doesn\u2019t have to normal, any CDF form is fine. Also, you need a random number generator that can generate random numbers within 0~1. Inverse transform sampling builds on a simple yet powerful theorem:", "For any random variable X, its CDF F(x) has a uniform distribution on [0 1].", "This theorem points out the direction for us: if we can generate random samples on [0 1], and for each sample u\u1d62, we apply the quantile function Q(u\u1d62) \u2014 which is the inverse of the specified CDF \u2014 to find the corresponding x\u1d62=Q(u\u1d62), then x\u1d62\u2019s would be the samples following our specified CDF.", "For interested readers, you can find the proof of the inverse transform sampling here. For now, let\u2019s focus on how this method works in practice.", "Our target is to generate samples from the standard normal distribution. Imagine that a standard normal random number generator is not readily available. However, we do have a uniform random number generator, and we do know the CDF of the standard normal distribution. In this situation, we could resort to inverse transform sampling to complete the task.", "The animation shown below illustrates the process of applying the inverse transform sampling. Random numbers are firstly generated uniformly on the y-axis. Subsequently, we transform those random numbers into samples through the inverse of CDF. By plotting a histogram of those transformed samples, we see that those samples form the standard normal distribution.", "This post discussed many practical probability theories and data visualization tools applied to a single random variable:", "To see how those probability calculations and visualizations are performed in Python, please check out the companion Jupyter Notebook I created.", "In the next post, we will switch gears and review probability theories applied to multiple random variables. See you there!", "[1] Walpole, Probability & Statistics for Engineers & Scientists, Pearson, 2016.", "[2] Glen Cowan, statistical data analysis, Oxford University Press, 1997.", "I\u2019m a Ph.D. researcher working on uncertainty quantification and reliability analysis for aerospace applications. Statistics and data science form the core of my daily work. I love sharing what I\u2019ve learned in the fascinating world of statistics. Check my previous posts to find out more and connect with me on Medium and Linkedin.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist, aerospace engineer, specialized in statistical modeling and uncertainty analysis for reliable system design."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8935cfa21a96&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://shuaiguo.medium.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": ""}, {"url": "https://shuaiguo.medium.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Shuai Guo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b08bf52bf9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&user=Shuai+Guo&userId=7b08bf52bf9c&source=post_page-7b08bf52bf9c----8935cfa21a96---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://github.com/ShuaiGuo16/Univariate_probability_theory", "anchor_text": "Jupyter Notebook"}, {"url": "https://towardsdatascience.com/multivariate-probability-theory-all-about-those-random-variables-ef921e099a6f", "anchor_text": "Multivariate Probability Theory: All About Those Random VariablesWondering how joint, marginal, conditional distributions and Bayes\u2019 rule are connected? Check this illustrative post to\u2026towardsdatascience.com"}, {"url": "https://en.wikipedia.org/wiki/List_of_the_verified_shortest_people", "anchor_text": "shortest man on earth"}, {"url": "https://time.com/3583663/worlds/", "anchor_text": "tallest man on earth"}, {"url": "http://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-ITM.pdf", "anchor_text": "here"}, {"url": "https://github.com/ShuaiGuo16/Univariate_probability_theory", "anchor_text": "Jupyter Notebook"}, {"url": "https://towardsdatascience.com/multivariate-probability-theory-all-about-those-random-variables-ef921e099a6f", "anchor_text": "Multivariate Probability Theory: All About Those Random VariablesWondering how joint, marginal, conditional distributions and Bayes\u2019 rule are connected? Check this illustrative post to\u2026towardsdatascience.com"}, {"url": "https://shuaiguo.medium.com/", "anchor_text": "Medium"}, {"url": "https://www.linkedin.com/in/shuaiguo16/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/statistics?source=post_page-----8935cfa21a96---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8935cfa21a96---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----8935cfa21a96---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----8935cfa21a96---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----8935cfa21a96---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&user=Shuai+Guo&userId=7b08bf52bf9c&source=-----8935cfa21a96---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&user=Shuai+Guo&userId=7b08bf52bf9c&source=-----8935cfa21a96---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8935cfa21a96&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8935cfa21a96---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8935cfa21a96--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8935cfa21a96--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8935cfa21a96--------------------------------", "anchor_text": ""}, {"url": "https://shuaiguo.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://shuaiguo.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shuai Guo"}, {"url": "https://shuaiguo.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "404 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b08bf52bf9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&user=Shuai+Guo&userId=7b08bf52bf9c&source=post_page-7b08bf52bf9c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F853a13978270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpractical-probability-theory-all-about-a-single-random-variable-8935cfa21a96&newsletterV3=7b08bf52bf9c&newsletterV3Id=853a13978270&user=Shuai+Guo&userId=7b08bf52bf9c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}