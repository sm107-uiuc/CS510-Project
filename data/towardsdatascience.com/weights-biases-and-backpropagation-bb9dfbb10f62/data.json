{"url": "https://towardsdatascience.com/weights-biases-and-backpropagation-bb9dfbb10f62", "time": 1683003487.627303, "path": "towardsdatascience.com/weights-biases-and-backpropagation-bb9dfbb10f62/", "webpage": {"metadata": {"title": "Weights, Biases, and Backpropagation | by Giovanni Rosati | Towards Data Science", "h1": "Weights, Biases, and Backpropagation", "description": "Neural networks are complex, powerful artificial intelligence (AI) systems that perform tasks such as identifying objects in a photograph or words in live or recorded speech. The name comes from how\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/", "anchor_text": "Towards Data Science", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/MNIST_database", "anchor_text": "MNIST", "paragraph_index": 1}, {"url": "https://youtu.be/aircAruvnKk", "anchor_text": "YouTube", "paragraph_index": 12}], "all_paragraphs": ["Neural networks are complex, powerful artificial intelligence (AI) systems that perform tasks such as identifying objects in a photograph or words in live or recorded speech. The name comes from how these systems mimic an aspect of the human brain \u2014 a system of interconnected neurons. Many excellent resources are available online to learn about neural networks, and artificial intelligence in general, particularly on YouTube and in publications like Towards Data Science. In this article, I will take a brief look at two essential components of a neural network: weights and biases.", "A neural network incorporates layers of \u201cnodes.\u201d If, for example, an image is composed of a 28 x 28-pixel grayscale grid, as in the commonly used MNIST training set of handwritten numbers, the first layer of the neural network would have 784 (28x28) nodes. Each initial layer node corresponds to a pixel in the image and has a value from zero to 1. A \u201c0\u201d would mean the pixel is white and, a \u201c1\u201d would mean the pixel is black. The second layer of nodes could have another 784 nodes, or it could have more or fewer nodes. For simplicity\u2019s sake, we\u2019ll assume that each node in the first layer is \u201cconnected\u201d to each node in the second layer. In a neural network, many subsequent \u201chidden\u201d connected layers can be used, and each node\u2019s value is called its \u201cactivation.\u201d The final layer, called the output layer, will have the number of nodes corresponding to the \u201clabels\u201d (categories, etc.) of the data used to train the network. In the MNIST example, the output layer would have ten nodes, one for each of the digits in a base 10 number system (0\u20139). The node in the output layer (0\u20139) with the highest value will be the system\u2019s guess of what number it just evaluated.", "Each \u201cconnection\u201d between a single node in one layer to each of the nodes in the next layer has a \u201cweight\u201d (positive or negative), which represents how strongly that source node influences any particular node it connects with. When the network is initialized, all these weights are chosen randomly.", "With the MNIST example, if the second layer had 16 nodes, there would be 12,544 weights connecting the input layer to the second layer (784 x 16). Each of the new 16 nodes would have 784 different connections, one to each node in the input layer.", "The first step in calculating the values of the nodes in the next layer is to multiply the source node\u2019s value times the weight of its connection to each node in the next layer. Next, a \u201cbias\u201d value (positive or negative) is assigned to each node in the new layer to allow further \u201ctweaking\u201d of that node\u2019s value. The final step involves taking the result of these two calculations and \u201csquishing\u201d it into the range of zero to one, and this gives us the activation (value) of each connected node. Different methods of \u201csquishing\u201d the value can be used, but that\u2019s beyond the scope of this article.", "All connected nodes in each subsequent layer are calculated in the same way:", "Step 2: \u201cSquishify\u201d (condense the result into the range of zero to 1)", "Step 3: Place that value in the connected node", "The network thus ends up with an activation value (0 to 1) in each of the output layer nodes. Then, based on the accuracy of these activations, a \u201ccost\u201d is computed. If for example, a handwritten number was a 7 in the MNIST dataset, but the output node for the \u201c7\u201d had a small activation (0.15), but higher activations for the \u201c1\u201d node (0.72) and the \u201c9\u201d node (0.68), this would create a high \u201ccost.\u201d The cost of that \u201cguess\u2019 is the sum of the squares of the differences between the correct values and the predicted values of each output node.", "Changes to the weights and biases that would make this particular prediction more accurate (to achieve lower activations for the incorrect output nodes and a higher activation for the correct output node) are calculated using calculus. This process is called backpropagation and is the essence of how a neural network \u201clearns.\u201d", "After the system evaluates \u201cenough\u201d images (for efficiency in training the network, it\u2019s usually best to split the data up into chunks), all of these individual backpropagation \u201cvotes\u201d for changes to the weights and biases are combined to come up with \u201cnudges\u201d that take into consideration all the different \u201cvotes.\u201d", "Repeating this process over and over, each time using the combined \u201cvotes\u201d to fine-tune the weights and biases, the network zeroes in on the optimum value for each weight and bias. Even in a simple network with only a few layers, this represents thousands and thousands of calculations.", "If you\u2019re new to neural networks, I hope this information was useful. If you want to dive deeper, one of my favorite resources is a series by 3Blue1Brown on YouTube.", "I\u2019m optimistic that AI will increasingly be used to make life better for all of us. Do you have a data science problem/challenge? I\u2019d love to help; let\u2019s connect!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbb9dfbb10f62&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@giorosati?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giorosati?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Giovanni Rosati"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f0d24cc1dc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&user=Giovanni+Rosati&userId=2f0d24cc1dc5&source=post_page-2f0d24cc1dc5----bb9dfbb10f62---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/", "anchor_text": "Towards Data Science"}, {"url": "https://en.wikipedia.org/wiki/MNIST_database", "anchor_text": "MNIST"}, {"url": "https://youtu.be/aircAruvnKk", "anchor_text": "YouTube"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bb9dfbb10f62---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----bb9dfbb10f62---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bb9dfbb10f62---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/backpropagation?source=post_page-----bb9dfbb10f62---------------backpropagation-----------------", "anchor_text": "Backpropagation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&user=Giovanni+Rosati&userId=2f0d24cc1dc5&source=-----bb9dfbb10f62---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&user=Giovanni+Rosati&userId=2f0d24cc1dc5&source=-----bb9dfbb10f62---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbb9dfbb10f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bb9dfbb10f62---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bb9dfbb10f62--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giorosati?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giorosati?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Giovanni Rosati"}, {"url": "https://medium.com/@giorosati/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "93 Followers"}, {"url": "http://linkedin.com/in/giorosati", "anchor_text": "http://linkedin.com/in/giorosati"}, {"url": "http://github.com/giorosati", "anchor_text": "http://github.com/giorosati"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2f0d24cc1dc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&user=Giovanni+Rosati&userId=2f0d24cc1dc5&source=post_page-2f0d24cc1dc5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F75a6602626f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweights-biases-and-backpropagation-bb9dfbb10f62&newsletterV3=2f0d24cc1dc5&newsletterV3Id=75a6602626f2&user=Giovanni+Rosati&userId=2f0d24cc1dc5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}