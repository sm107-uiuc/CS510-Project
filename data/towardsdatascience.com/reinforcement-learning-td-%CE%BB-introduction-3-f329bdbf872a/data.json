{"url": "https://towardsdatascience.com/reinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a", "time": 1683000429.237579, "path": "towardsdatascience.com/reinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a/", "webpage": {"metadata": {"title": "Reinforcement Learning \u2014 TD(\u03bb) Introduction(3) | by Jeremy Zhang | Towards Data Science", "h1": "Reinforcement Learning \u2014 TD(\u03bb) Introduction(3)", "description": "In last posts, we have learnt the idea of TD(\u03bb) with eligibility trace, which is a combination of n-step TD method, and have applied it on random walk example. In this post, let\u2019s extend the idea of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@zhangyue9306/reinforcement-learning-td-%CE%BB-introduction-2-f0ea427cd395", "anchor_text": "posts", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/reinforcement-learning-td-\u03bb-introduction-686a5e4f4e60", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://medium.com/@zhangyue9306/reinforcement-learning-td-%CE%BB-introduction-2-f0ea427cd395", "anchor_text": "eligibility trace", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b", "anchor_text": "tile coding", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/reinforcement-learning-on-policy-function-approximation-2f47576f772d", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/MountainCar(Lambda)/MountainCar.py", "anchor_text": "here", "paragraph_index": 20}], "all_paragraphs": ["In last posts, we have learnt the idea of TD(\u03bb) with eligibility trace, which is a combination of n-step TD method, and have applied it on random walk example. In this post, let\u2019s extend the idea of lambda to more general use cases \u2014 instead of learning a state-value function, a Q function of state, action value will be learnt. In this article, we will:", "Same as many extensions we have been elaborated on, it is quite natural to extend value function V(S) to Q function Q(S, A) , as all formulas and logic will be the same, only action will be taken into considerations when formulating the problem. Recall the TD(\u03bb) introduced here, the update process is similar:", "the only difference is the \u2207V is replaced by \u2207q , and the eligibility trace will be extended as:", "still here \u2207V is replaced by \u2207q .", "Consequently, we get the backup diagram of Sarsa(\u03bb):", "Note that here the algorithm is specifically designed for binary features representation, that is each state, action pair will be represented as binary features, for example (3.2, 1) may be represented as [1, 0, 0, 1] (more specifically, we have extensively talked about how to represent a continuous state into binary features in tile coding)", "At the first glance, you might think the algorithm is a bit complicated, but in fact it is the same as TD(\u03bb) , and let\u2019s try understand it in this way:", "First, let\u2019s focus on the bottom part. You should be familiar with this, as it looks almost the same as TD(\u03bb) \u2014 \u03b4 here is the temporal difference, and weight w is updated based on \u03b4 and eligibility trace z , where z keeps track of the previous state. z is provided with two updates:", "F(s, a) here you can think of it as tile coding function or any other function that gives a binary representation of state, action.", "That\u2019s all about this algorithm. Ignore other parts and connect it with what we learnt in previous lectures, and now let\u2019s get into implementation of an example.", "We have talked about mountain car in n-step Sarsa example here, the setting is (If you get any confusion on the implementation below, I strongly recommend you to read previous post to get a better understanding of the process):", "Consider the task of driving an underpowered car up a steep mountain road, as suggested by the diagram. The difficulty is that gravity is stronger than the car\u2019s engine, and even at full throttle the car cannot accelerate up the steep slope. The only solution is to first move away from the goal and up the opposite slope on the left.", "The reward in this problem is -1 on all time steps until the car moves past its goal position at the top of the mountain, which ends the episode. There are three possible actions: full throttle forward (+1), full throttle reverse (-1), and zero throttle (0). The car moves according to a simplified physics. Its position, x_t, and velocity, x_ \u0307t, are updated by:", "The following process will be mostly the same as we stated in n-step Sarsa, so I will mainly focus on explaining the differences.", "In the init function, the difference lies in the initialisation of self.z , which is the eligibility trace vector and is set to 0 at the beginning.", "value function returns the value given state, action pair. The major difference is in the update function, where we update self.z first before updating weights.", "The costToGo function is the same.", "The functions above are the same as prior implementation, so I will give a quick brief through. The reset function reset the agent to initial state when the agent either reaches the goal or the leftmost state; The takeAction function receives an action and returns the next state of the agent based on a pre-defined formula; chooseAction function chooses action based on current estimation with \u03f5-greedy policy; And giveReward gives reward to the agent based on its state.", "Lastly comes the play function, which kicks off the game playing. The logic is simple and straight forward \u2014 an agent starts at current state \u2192 takes an action \u2192 reaches next state \u2192 receives reward \u2192 takes next action \u2026 , and target = reward + Q(nextState, nextAction) , which is passed to value function we defined above to update eligibility trace z and weights w .", "The whole game setting is exactly the same as we introduced on n-step Sarsa, thus we compare the learning result between Sarsa(\u03bb) and n-step Sarsa:", "We used same number of tilings and other parameters. Referring to Sutton\u2019s book, the Sarsa(\u03bb) turns out to be more competitive than n-step Sarsa, as it learns faster to reach the goal(for more illustration, please refer to full implementation here).", "Hmm\u2026I am a data scientist looking to catch up the tide\u2026"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff329bdbf872a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://meatba11.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----f329bdbf872a---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff329bdbf872a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%25CE%25BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----f329bdbf872a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff329bdbf872a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=-----f329bdbf872a---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@zhangyue9306/reinforcement-learning-td-%CE%BB-introduction-2-f0ea427cd395", "anchor_text": "posts"}, {"url": "https://towardsdatascience.com/reinforcement-learning-td-\u03bb-introduction-686a5e4f4e60", "anchor_text": "here"}, {"url": "https://medium.com/@zhangyue9306/reinforcement-learning-td-%CE%BB-introduction-2-f0ea427cd395", "anchor_text": "eligibility trace"}, {"url": "https://towardsdatascience.com/reinforcement-learning-tile-coding-implementation-7974b600762b", "anchor_text": "tile coding"}, {"url": "https://towardsdatascience.com/reinforcement-learning-on-policy-function-approximation-2f47576f772d", "anchor_text": "here"}, {"url": "https://github.com/MJeremy2017/Reinforcement-Learning-Implementation/blob/master/MountainCar(Lambda)/MountainCar.py", "anchor_text": "here"}, {"url": "http://incompleteideas.net/book/the-book-2nd.html?source=post_page---------------------------", "anchor_text": "http://incompleteideas.net/book/the-book-2nd.html"}, {"url": "https://github.com/ShangtongZhang/reinforcement-learning-an-introduction", "anchor_text": "https://github.com/ShangtongZhang/reinforcement-learning-an-introduction"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f329bdbf872a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----f329bdbf872a---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----f329bdbf872a---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff329bdbf872a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%25CE%25BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----f329bdbf872a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff329bdbf872a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%25CE%25BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----f329bdbf872a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff329bdbf872a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----f329bdbf872a---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----f329bdbf872a---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Written by Jeremy Zhang"}, {"url": "https://meatba11.medium.com/followers?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----f329bdbf872a---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-td-%CE%BB-introduction-3-f329bdbf872a&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----f329bdbf872a---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/geekculture?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Using ChatGPT in PythonPractical Examples of Using ChatGPT SDK"}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "\u00b74 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Feeaed9847e72&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fusing-chatgpt-in-python-eeaed9847e72&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----eeaed9847e72----0-----------------clap_footer----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/using-chatgpt-in-python-eeaed9847e72?source=author_recirc-----f329bdbf872a----0---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feeaed9847e72&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fusing-chatgpt-in-python-eeaed9847e72&source=-----f329bdbf872a----0-----------------bookmark_preview----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----f329bdbf872a----1---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----f329bdbf872a----1-----------------bookmark_preview----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----f329bdbf872a----2---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----f329bdbf872a----2-----------------bookmark_preview----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Jeremy Zhang"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "UNet Line by Line ExplanationExample UNet Implementation"}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": "\u00b74 min read\u00b7Oct 18, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9b191c76baf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funet-line-by-line-explanation-9b191c76baf5&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----9b191c76baf5----3-----------------clap_footer----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5?source=author_recirc-----f329bdbf872a----3---------------------5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9b191c76baf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funet-line-by-line-explanation-9b191c76baf5&source=-----f329bdbf872a----3-----------------bookmark_preview----5fac1e2f_42ef_4d4f_9fae_439e9416d9a7-------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "See all from Jeremy Zhang"}, {"url": "https://towardsdatascience.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----0-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----f329bdbf872a----0-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----1-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----f329bdbf872a----1-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Anand Mishra"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Deep reinforcement learning \u2014 current state of artCurrent"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "5 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&user=Anand+Mishra&userId=86f86a9a5573&source=-----383190b14464----0-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----f329bdbf872a----0---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&source=-----f329bdbf872a----0-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----1-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----f329bdbf872a----1---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----f329bdbf872a----1-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://byfintech.medium.com/?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Bruce Yang ByFinTech"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement LearningNeurIPS 2022 Datasets and Benchmarks."}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "\u00b79 min read\u00b7Nov 13, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&user=Bruce+Yang+ByFinTech&userId=a878fc45fb3f&source=-----7af8e747c4bd----2-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/finrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd?source=read_next_recirc-----f329bdbf872a----2---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7af8e747c4bd&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2Ffinrl-meta-market-environments-and-benchmarks-for-data-driven-financial-reinforcement-learning-7af8e747c4bd&source=-----f329bdbf872a----2-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----3-----------------clap_footer----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----f329bdbf872a----3---------------------93473d7e_2ea4_4049_9531_9baf2f3619f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----f329bdbf872a----3-----------------bookmark_preview----93473d7e_2ea4_4049_9531_9baf2f3619f0-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----f329bdbf872a--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}