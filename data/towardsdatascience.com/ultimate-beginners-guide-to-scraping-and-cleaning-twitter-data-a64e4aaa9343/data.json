{"url": "https://towardsdatascience.com/ultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343", "time": 1683000418.167616, "path": "towardsdatascience.com/ultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343/", "webpage": {"metadata": {"title": "The Ultimate Beginner\u2019s Guide to Data Scraping, Cleaning, and Visualization | by Anne Bonner | Towards Data Science", "h1": "The Ultimate Beginner\u2019s Guide to Data Scraping, Cleaning, and Visualization", "description": "If you have a model that has acceptable results but isn\u2019t amazing, take a look at your data! Arguably the most important part of the process, getting your data ready can make your model a star."}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/kazanova/sentiment140", "anchor_text": "Sentiment140 dataset available on Kaggle", "paragraph_index": 5}, {"url": "https://www.kaggle.com/ywang311/twitter-sentiment/data", "anchor_text": "dataset which utilizes the Sentiment140 dataset", "paragraph_index": 5}, {"url": "https://github.com/twintproject/twint", "anchor_text": "TWINT", "paragraph_index": 6}, {"url": "https://contentsimplicity.com/articles/", "anchor_text": "reach out any time", "paragraph_index": 49}, {"url": "http://bit.ly/submissions2023", "anchor_text": "http://bit.ly/submissions2023", "paragraph_index": 51}], "all_paragraphs": ["If you have a model that has acceptable results but isn\u2019t amazing, take a look at your data! Taking the time to clean and preprocess your data the right way can make your model a star.", "In order to look at scraping and preprocessing in more detail, let\u2019s look at some of the work that went into \u201cYou Are What You Tweet: Detecting Depression in Social Media via Twitter Usage.\u201d That way, we can really examine the process of scraping Tweets and then cleaning and preprocessing them. We\u2019ll also do a little exploratory visualization, which is an awesome way to get a better sense of what your data looks like! We\u2019re going to do some of the most basic cleaning and preprocessing work here: it\u2019s up to you to really get these Tweets in order when you\u2019re building your model!", "More than 300 million people suffer from depression and only a fraction receive adequate treatment. Depression is the leading cause of disability worldwide and nearly 800,000 people every year die due to suicide. Suicide is the second leading cause of death in 15\u201329-year-olds. Diagnoses (and subsequent treatment) for depression are often delayed, imprecise, and/or missed entirely.", "It doesn\u2019t have to be this way! Social media provides an unprecedented opportunity to transform early depression intervention services, particularly in young adults.", "Every second, approximately 6,000 Tweets are tweeted on Twitter, which corresponds to over 350,000 tweets sent per minute, 500 million tweets per day and around 200 billion tweets per year. Pew Research Center states that currently, 72% of the public uses some type of social media. This project captures and analyses linguistic markers associated with the onset and persistence of depressive symptoms in order to build an algorithm that can effectively predict depression. By building an algorithm that can analyze Tweets exhibiting self-assessed depressive features, it will be possible for individuals, parents, caregivers, and medical professionals to analyze social media posts for linguistic clues that signal deteriorating mental health far before traditional approaches currently do. Analyzing linguistic markers in social media posts allows for a low-profile assessment that can complement traditional services and would allow for a much earlier awareness of depressive signs than traditional approaches.", "In order to build a depression detector, there were two kinds of tweets that were needed: random tweets that do not necessarily indicate depression and tweets that demonstrate that the user may have depression and/or depressive symptoms. A dataset of random tweets can be sourced from the Sentiment140 dataset available on Kaggle, but for this binary classification model, this dataset which utilizes the Sentiment140 dataset and offers a set of binary labels proved to be the most effective for building a robust model. There are no publicly available datasets of tweets indicating depression, so \u201cdepressive\u201d Tweets were retrieved using the Twitter scraping tool TWINT. The scraped Tweets were manually checked for relevance (for example, Tweets indicating emotional rather than economic or atmospheric depression) and Tweets were cleaned and processed. Tweets were collected by searching for terms specifically related to depression, specifically to lexical terms as identified in the unigram by De Choudhury, et. al.", "TWINT is a remarkably simple tool to use!", "You can download it right from the command line with:", "If you want to, for example, search for the term \u201cdepression\u201d on July 20, 2019 and store the data as a new csv named \u201cdepression,\u201d you would run a command like:", "Once you\u2019ve gathered the Tweets, you can start cleaning and preprocessing them. You\u2019ll probably wind up with a ton of information that you don\u2019t need, like conversation ids and so on. You may decide to create multiple CSVs that you want to combine. We\u2019ll get to all of that!", "At first? Not that impressively. After a basic cleaning and preprocessing of the data, the best results (even after spending time fine-tuning the model) hovered around 80%.", "The reason for that really made sense after I examined word frequency and bigrams. Explore your data! Once I looked at the words themselves, I realized that it was going to take a lot of work to clean and prepare the dataset the right way, and that doing so was an absolute necessity. Part of the cleaning process had to be done manually, so don\u2019t be afraid to get in there and get your hands dirty. It takes time, but it\u2019s worth it!", "In the end? The accuracy of the model was evaluated and compared to a binary classification baseline model using logistic regression. The models were analyzed for accuracy and a classification report was run to determine precision and recall scores. The data were split into training, testing, and validation sets and the accuracy for the model was determined based on the model\u2019s performance with the testing data, which were kept separate. While the performance of the benchmark logistic regression model was 64.32% using the same data, learning rate, and epochs, the LSTM model performed significantly better at 97.21%.", "So how did we get from the scraped Tweets to the results?", "Practice, practice, practice! (And some serious work.)", "(If you\u2019re new to data science, machine learning, and artificial intelligence, you might want to check out the ultimate beginner\u2019s guide to NumPy!)", "Let\u2019s say we scraped Twitter for the search terms \u201cdepression,\u201d \u201cdepressed,\u201d \u201chopeless,\u201d \u201clonely,\u201d \u201csuicide,\u201d and \u201cantidepressant\u201d and we saved those files of scraped Tweets as, for example, \u201cdepression\u201d in the file \u201ctweets.csv\u201d and so on.", "We\u2019ll start with a few imports", "We\u2019ll read one of our CSV files and take a look at the head.", "First of all, we should get rid of any of the information stored in the datasets that aren\u2019t necessary. We don\u2019t need names, ids, conversation ids, geolocations, and so on for this project. We can get those out of there with:", "Now we have this, which is much easier to deal with!", "Now just do that with all of the CSVs you created with your search terms and we can combine our separate datasets into one!", "Before we go any further, let\u2019s drop the duplicates", "And save our dataset as a new CSV!", "Before the data could be used in the model, it was necessary to expand contractions, remove links, hashtags, capitalization, and punctuation. Negations needed to be dealt with. That meant creating a dictionary of negations so that negated words could be effectively handled. Links and URLs needed to be removed along with whitespaces. Additionally, stop words beyond the standard NLTK stop words needed to be removed to make the model more robust. These words included days of the week and their abbreviations, month names, and the word \u201cTwitter,\u201d which surprisingly showed up as a prominently featured word when the word clouds were created. The tweets were then tokenized and PorterStemmer was utilized to stem the tweets.", "Let\u2019s take out all of the stuff that isn\u2019t going to help us!", "Turn it into a Pandas dataframe", "Now let\u2019s see if there are any null values. Let\u2019s clean it up!", "We\u2019ll quickly remove stopwords from the Tweets with", "If you want to, you can analyze the Tweets for VADER sentiment analysis scores!", "From there, you can also create labels. For a binary classification model, you may want a binary labelling system. However, be aware of your data! Sentiment scores alone do not indicate depression and it is far too simplistic to assume that a negative score indicates depression. In fact, anhedonia, or loss of pleasure, is an extremely common symptom of depression. Neutral, or flat, Tweets are at least as likely, if not more likely, to be an indicator of depression and should not be ignored.", "For the purposes of experimentation, you may want to set a sentiment analysis label like this. Feel free to play around with it!", "If you need to, drop what you don\u2019t need", "Go ahead and save a csv!", "Now let\u2019s make everything lowercase and split the Tweets.", "It\u2019s not fun and it\u2019s not pretty, but manual cleaning was critical. It took hours, but getting rid of references to things like tropical depressions and economic depressions improved the model. Removing Tweets that were movie titles improved the model (you can see \u201cSuicide Squad\u201d in the bigrams below). Removing quoted news headlines that included the search terms improved the model. It felt like it took an eternity to do, but this step made an enormous difference in the robustness of the model.", "Now let\u2019s look at character and word frequency!", "It\u2018s fairly easy to analyze the most common words found in the dataset. After removing the stop words, it was apparent that there were certain words that appeared much more frequently than other words.", "Let\u2019s count our most common words!", "And turn them into a dataframe.", "Hmmm. Too many stopwords. Let\u2019s deal with those.", "Better, but not great yet. Some of these words don\u2019t tell us much. Let\u2019s make a few more adjustments.", "Much better! Let\u2019s save this as a dataframe.", "What does that look like? Let\u2019s visualize it!", "Certain bigrams were also extremely common, including smile and wide, appearing 42,185 times, afraid and loneliness, appearing 4,641 times, and feel and lonely, appearing 3,541 times.", "This was just the beginning of cleaning, preprocessing, and visualizing the data. We can still do a lot from here before we build our model!", "Once the Tweets were cleaned, it was easy to see the difference between the two datasets by creating a word cloud with the cleaned Tweets. With only an abbreviated TWINT Twitter scraping, the differences between the two datasets were clear:", "Early in the process, it became clear that the most important part of refining the model to get more accurate results would be the data gathering, cleaning, and preprocessing stage. Until the Tweets were appropriately scraped and cleaned, the model had unimpressive accuracy. By cleaning and processing the Tweets with more care, the robustness of the model improved to 97%.", "If you\u2019re interested in learning about the absolute basics of data cleaning and preprocessing, take a look at this article!", "Thanks for reading! As always, if you do anything cool with this information, let everyone know about it in the comments below or reach out any time!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Building a community space at VentureBeat \ud83d\udcab Submit your articles here: http://bit.ly/submissions2023"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa64e4aaa9343&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@annebonner?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@annebonner?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Anne Bonner"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa71060a2ef24&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&user=Anne+Bonner&userId=a71060a2ef24&source=post_page-a71060a2ef24----a64e4aaa9343---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/@tasveerwala?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Nitin Sharma"}, {"url": "https://www.pexels.com/photo/grey-and-white-monkeys-sitting-near-tree-2861847/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://www.pexels.com/@burst?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Burst"}, {"url": "https://www.pexels.com/photo/adult-tan-and-white-french-bulldog-545063/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://towardsdatascience.com/you-are-what-you-tweet-7e23fb84f4ed", "anchor_text": "You Are What You TweetDetecting Depression in Social Media via Twitter Usagetowardsdatascience.com"}, {"url": "https://www.pexels.com/@quang-nguyen-vinh-222549?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Quang Nguyen Vinh"}, {"url": "https://www.pexels.com/photo/black-and-tan-smooth-chihuahua-in-blue-and-white-plastic-basket-2135383/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://www.kaggle.com/kazanova/sentiment140", "anchor_text": "Sentiment140 dataset available on Kaggle"}, {"url": "https://www.kaggle.com/ywang311/twitter-sentiment/data", "anchor_text": "dataset which utilizes the Sentiment140 dataset"}, {"url": "https://github.com/twintproject/twint", "anchor_text": "TWINT"}, {"url": "https://www.pexels.com/@dsd-143941?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "DSD"}, {"url": "https://www.pexels.com/photo/close-up-photo-of-monkey-on-tree-branch-1829979/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://towardsdatascience.com/the-ultimate-beginners-guide-to-numpy-f5a2f99aef54", "anchor_text": "The Ultimate Beginner\u2019s Guide to NumPyEverything you need to know to get started with NumPytowardsdatascience.com"}, {"url": "https://towardsdatascience.com/the-complete-beginners-guide-to-data-cleaning-and-preprocessing-2070b7d4c6d", "anchor_text": "The complete beginner\u2019s guide to data cleaning and preprocessingHow to successfully prepare your data for a machine learning model in minutestowardsdatascience.com"}, {"url": "https://contentsimplicity.com/articles/", "anchor_text": "reach out any time"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a64e4aaa9343---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----a64e4aaa9343---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----a64e4aaa9343---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----a64e4aaa9343---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----a64e4aaa9343---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&user=Anne+Bonner&userId=a71060a2ef24&source=-----a64e4aaa9343---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&user=Anne+Bonner&userId=a71060a2ef24&source=-----a64e4aaa9343---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa64e4aaa9343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a64e4aaa9343---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a64e4aaa9343--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@annebonner?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@annebonner?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Anne Bonner"}, {"url": "https://medium.com/@annebonner/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6.4K Followers"}, {"url": "http://bit.ly/submissions2023", "anchor_text": "http://bit.ly/submissions2023"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa71060a2ef24&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&user=Anne+Bonner&userId=a71060a2ef24&source=post_page-a71060a2ef24--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F29e21558a591&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-scraping-and-cleaning-twitter-data-a64e4aaa9343&newsletterV3=a71060a2ef24&newsletterV3Id=29e21558a591&user=Anne+Bonner&userId=a71060a2ef24&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}