{"url": "https://towardsdatascience.com/policy-gradient-step-by-step-ac34b629fd55", "time": 1682996669.66528, "path": "towardsdatascience.com/policy-gradient-step-by-step-ac34b629fd55/", "webpage": {"metadata": {"title": "Policy Gradient Step by Step. A comprehensive analysis on how Policy\u2026 | by Ziad SALLOUM | Towards Data Science", "h1": "Policy Gradient Step by Step", "description": "Update 1: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com Update 2: If you are new to the subject, it might be easier for you to start with\u2026"}, "outgoing_paragraph_urls": [{"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/revisiting-policy-in-reinforcement-learning-for-developers-43cd2b713182", "anchor_text": "Reinforcement Learning Policy for Developers", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083", "anchor_text": "Policy Based learning", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/introduction-to-actor-critic-7642bdb2b3d2", "anchor_text": "Actor-Critic", "paragraph_index": 16}], "all_paragraphs": ["Update 1: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com", "Update 2: If you are new to the subject, it might be easier for you to start with Reinforcement Learning Policy for Developers article.", "In a previous article we learned about Policy Based learning and explored what are the advantages and disadvantages of this methods. In this article we will delve into mathematical details in order to derive the right equation for policy gradient.", "But before we start let\u2019s have a quick reminder of why policy learning is useful:", "We need to always and always remind ourselves what is our objective, because it is very easy to forget about it.Keep saying to yourself that the aim is to maximize the rewards in every Reinforcement Learning problem.", "So starting from this fundamental principle we define J(\ud835\udf03) as the expected rewards R(s, a) that we get in every time step going from zero to the end of the episode T, following a policy \ud835\uded1(\ud835\udf03).If we define the episode as a trajectory \ud835\udfbd going from t=0 to T, then the expected rewards is the sum of all possible trajectories of the probability that \ud835\udfbd is selected according to \ud835\udf03, times the return of this trajectory R(\ud835\udfbd). This leads us to the following equation:", "Again our aim is to find the set of parameters \ud835\udf03 that will maximise J(\ud835\udf03)(which is the expected return).", "From calculus we know that in order to find the extremum (maximum or minimum) of a function we compute its derivative.Which we will do in the following set of equations:", "However, since we can\u2019t practically compute every possible trajectory \ud835\udfbd,we will fallback to get a reduced number of (m) trajectories. Here too we can see that P(\ud835\udfbd, \ud835\udf03 ) (the one before the log) magically vanishes. The reason is that when we have chosen the (m) trajectories there is no more probabilities of selecting them, because they are already selected.", "We end up with this equation:", "Notice that we moved from expected value (over all possible trajectories) to an average of (m) selected trajectories.", "Now let\u2019s focus on \ud835\udefblog P(\ud835\udfbd, \ud835\udf03 ) alone. The probability that a trajectory is followed, is equal to the the product of the probabilities that each step of this trajectory is reached when following a certain policy \ud835\uded1(\ud835\udf03).The following line shows that log P(\ud835\udfbd, \ud835\udf03 ) is transformed into the product of P(S(t+1)|St, At).\ud835\uded1(\ud835\udf03)", "Intuitively we say that we followed a trajectory, when we have passed through all of its steps. So the probability of following it to the end, is equal to the product of probabilities that we passed by every step of this trajectory.", "We know that the log of the product is equal to the sum of the logs:", "The second line of the set of equations above shows that we decomposed \u03a3log(P.\ud835\uded1) even further into \u03a3(log(P) + log(\ud835\uded1)), then \u03a3log(P) + \u03a3log(\ud835\uded1).When applying the derivative over \ud835\udf03 on the two terms the \ud835\udefb\u03a3log(P) disappears because P does not depend on \ud835\udf03.", "Now that we have found that \ud835\udefblog P(\ud835\udfbd, \ud835\udf03 ) = \ud835\udefb \u03a3log(\ud835\uded1(a|s,\ud835\udf03) we can place it back in the initial equation and retrieve the final result as shown below:", "As we have seen deriving the Policy Gradient is very elegant and intelligent procedure. It is essential to fully grasp the essence of this derivation since it is the basis of many well know policy based methods, such as Actor-Critic.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac34b629fd55&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://zsalloum.medium.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----ac34b629fd55---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@kylejglenn?utm_source=medium&utm_medium=referral", "anchor_text": "Kyle Glenn"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com"}, {"url": "https://towardsdatascience.com/revisiting-policy-in-reinforcement-learning-for-developers-43cd2b713182", "anchor_text": "Reinforcement Learning Policy for Developers"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083", "anchor_text": "Policy Based learning"}, {"url": "https://towardsdatascience.com/introduction-to-actor-critic-7642bdb2b3d2", "anchor_text": "Actor-Critic"}, {"url": "https://medium.com/@zsalloum/revisiting-policy-in-reinforcement-learning-for-developers-43cd2b713182", "anchor_text": "Reinforcement Learning Policy for Developers"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083", "anchor_text": "Policy Based Reinforcement Learning, the Easy Way"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566", "anchor_text": "Function Approximation in Reinforcement Learning"}, {"url": "https://towardsdatascience.com/introduction-to-actor-critic-7642bdb2b3d2", "anchor_text": "Introduction to Actor Critic in Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ac34b629fd55---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/policy-gradient?source=post_page-----ac34b629fd55---------------policy_gradient-----------------", "anchor_text": "Policy Gradient"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----ac34b629fd55---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ac34b629fd55---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data?source=post_page-----ac34b629fd55---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----ac34b629fd55---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----ac34b629fd55---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac34b629fd55&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac34b629fd55---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac34b629fd55--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac34b629fd55--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac34b629fd55--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://zsalloum.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "845 Followers"}, {"url": "https://rl-lab.com", "anchor_text": "https://rl-lab.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-gradient-step-by-step-ac34b629fd55&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}