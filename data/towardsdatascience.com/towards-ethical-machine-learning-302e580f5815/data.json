{"url": "https://towardsdatascience.com/towards-ethical-machine-learning-302e580f5815", "time": 1682994191.267724, "path": "towardsdatascience.com/towards-ethical-machine-learning-302e580f5815/", "webpage": {"metadata": {"title": "Towards Ethical Machine Learning. I quit my job to enter an intensive\u2026 | by Kayla Hartman | Towards Data Science", "h1": "Towards Ethical Machine Learning", "description": "I quit my job to enter an intensive data science bootcamp. I understand the value behind the vast amount of data available that enables us to create predictive machine learning algorithms. In\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["I quit my job to enter an intensive data science bootcamp. I understand the value behind the vast amount of data available that enables us to create predictive machine learning algorithms. In addition to recognizing its value on a professional level, I benefit from these technologies as a consumer. Whenever I find myself in a musical rut, I rely on Spotify\u2019s Discover Weekly. I\u2019m often amazed by how Spotify\u2019s algorithms and other machine learning models so accurately predict my behavior. In fact, when I first sat down to write this post, I took a break to watch one Youtube video. Twenty minutes later, I realized just how well Youtube\u2019s recommendation algorithm works. Although I so clearly see the benefits of machine learning, it is also essential to recognize and mitigate its potential dangers.", "While Spotify or Youtube recommending a song or video I dislike would not produce any devastating consequences, that\u2019s not the case for all machine learning algorithms. I first realized potential consequences of machine learning when I came across a collaboration between The Marshal Project and FiveThirtyEight, in which they discussed the use of machine learning in the criminal justice system. I assumed machine learning would be nothing but a benefit to the very broken criminal justice system. After all, the United States accounts for 5 percent of the world\u2019s total population, yet 25 percent of the world\u2019s incarcerated population. Beyond the disproportionate incarcerated population, the United States justice system is built on racist policing and prosecuting, skyrocketing recidivism rates, and excessively harsh punishments for nonviolent drug offenders. Wouldn\u2019t the introduction of machine learning do nothing but help a system so deep in crisis?", "While at first glance it seems that machine learning could do nothing but help the United States\u2019 broken criminal justice system, after reading more about some efforts being implemented, I realized that it is essential to proceed with caution. Determining a person\u2019s fate after arrest is one way in which machine learning is being introduced to the criminal justice system, and it exemplifies the risks of relying on machine learning to make a potentially life altering decision.", "Traditionally, shortly after an individual is arrested, a judge is tasked with the difficult decision to determine whether they must await their court date in jail, which could be for months or years, or if they can await their court date at home, with or without restrictions. In order to make this decision, a judge must analyze the defendant and essentially must predict whether they deem the individual to be a flight risk \u2014 one who would fail to appear at their trial or at risk of committing additional crimes if released to their home.", "The fact that a single person is granted the power to make a potentially life altering decision is unfair and makes room for biased decisions. With advances in machine learning, technologies have been introduced in attempt to remove judges\u2019 biases and make decisions based on data, rather than on an individual\u2019s sole judgement. These technologies are often referred to as risk assessment tools and have been developed by both non-profit organizations and for-profit companies. Amongst these risk assessment tools is the Public Safety Assessment (PSA) developed by the Laura and John Arnold Foundation (LJAF). The PSA uses historic data to flag those deemed high risk based on a score associated with their risk of failing to appear at court and their risk of committing another crime. It seems that utilizing an algorithm based on historic data would lead to reduced biases in deciding an individual\u2019s fate, rather than giving the full decision power to a single judge, but many are finding that these risk assessments are exacerbating the discriminatory practices they are trying to eliminate.", "These algorithms assign points to model features, such as age, gender, income, drug use, and previous convictions. Despite the PSA being used in 29 cities and states, as well as many other risk assessment tools being used nationwide, the comprehensive list of variables and weights used in these models remain proprietary, and are often referred to as a \u201cblack box\u201d. According to Christopher Slobogin, director Vanderbilt Law School\u2019s criminal justice program , \u201cRisk assessments should be impermissible unless both parties get to see all the data that go into them. It should be an open, full-court adversarial proceeding.\u201d If we want to ensure that these algorithms make efforts to reduce biases, it is important to understand the data on which they are based.", "Transparency in these risk assessments is invaluable so the general population, as well as the judges who rely on them to make decisions, can fully understand the pathway that leads to their recommendations, including the raw data from which these recommendations extend. After all, as noted on IBM Research, \u201cAI systems are only as good as the data we put into them. Bad data can contain implicit racial, gender, or ideological biases. Many AI systems will continue to be trained using bad data, making this an ongoing problem. But we believe that bias can be tamed and that the AI systems that will tackle bias will be the most successful.\u201d", "As data scientists, we must recognize our moral responsibility to train machine learning models with unbiased data. One of the starting points is to allow for transparency and a system of check and balances to ensure that the data on which a model is based is fair and unbiased. In regards to risk assessment tools, it is essential to understand the data used, especially given the historic problems, such as racism and overly harsh treatment of nonviolent drug offenses, that have plagued the United States criminal justice system. We must understand this data in order to digress from these biases, rather than perpetuating them.", "One step to reduce biases in machine learning algorithms is through Algorithmic Impact Assessments (AIAs), as proposed by New York University\u2019s AI Now Institute. AIAs extend from the idea that the \u201cblack box\u201d methodology leads to a vicious cycle, continuously moving further away from understanding these algorithms and diminishing the ability to address any issues that may arise from them. AI Now suggests the use of AIAs to handle the use of machine learning in the public realm, creating a set of standard requirements . Through AIAs, AI Now aims to provide clarity to the public by publicly listing and explaining algorithm systems used while allowing the public to dispute these systems, developing an audit and assessment processes, and increasing public agencies\u2019 internal capabilities to understand the systems they use.", "Similar to the use of AIAs to promote transparency in machine learning, the Defense Advanced Research Projects Agency (DARPA) suggests Explainable Artificial Intelligence (XAI) as a part of the solution. As expressed in the below graphic, XAI strives to produce more explainable models that users can understand and trust.", "Though there do not yet appear to be any clear, concise descriptions of XAI on DARPA\u2019s website, they say XAI prototypes are constantly tested, having had the goal for Phase 1 system evaluations to be completed this past November. On the website, they also state, \u201cAt the end of the program, the final delivery will be a toolkit library consisting of machine learning and human-computer interface software modules that could be used to develop future explainable AI systems\u201d", "AIAs and XAI are only two examples in which organizations are working towards more ethical, transparent machine learning models. As machine learning continues to grow at an exploding rate, there will certainly be more ideas introduced to ensure such regulation. Regardless of the specifics behind these ideas, it is important to maintain a system of transparency and comprehension surrounding machine learning models, during which the data is scrutinized throughout all stages of the machine learning process to ensure fair practices that do not perpetuate biases.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Analyst @ Alloy | enthused by the intersection of data, urban studies, and business"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F302e580f5815&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----302e580f5815--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kahartman95?source=post_page-----302e580f5815--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kahartman95?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Kayla Hartman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F889f1a67e6db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&user=Kayla+Hartman&userId=889f1a67e6db&source=post_page-889f1a67e6db----302e580f5815---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.themarshallproject.org/2015/08/04/the-new-science-of-sentencing", "anchor_text": "The New Science of SentencingInteractive graphics by Matthew Conlen, Reuben Fischer-Baum and Andy Rossback Additional research by Hayley Munguia\u2026www.themarshallproject.org"}, {"url": "https://fivethirtyeight.com/features/prison-reform-risk-assessment/", "anchor_text": "Should Prison Sentences Be Based On Crimes That Haven't Been Committed Yet?This story was produced in collaboration with The Marshall Project. Criminal sentencing has long been based on the\u2026fivethirtyeight.com"}, {"url": "https://www.washingtonpost.com/news/fact-checker/wp/2015/07/07/yes-u-s-locks-people-up-at-a-higher-rate-than-any-other-country/?utm_term=.9de388bf6ac6", "anchor_text": "Yes, U.S. locks people up at a higher rate than any other countryJuly 7, 2015 \"It's a stark fact that the United States has less than 5 percent of the world's population, yet we have\u2026www.washingtonpost.com"}, {"url": "https://hbr.org/2016/12/a-guide-to-solving-social-problems-with-machine-learning", "anchor_text": "A Guide to Solving Social Problems with Machine LearningIt's Sunday night. You're the deputy mayor of a big city. You sit down to watch a movie and ask Netflix for help\u2026hbr.org"}, {"url": "https://harvardlawreview.org/2018/02/bail-reform-and-risk-assessment-the-cautionary-tale-of-federal-sentencing/", "anchor_text": "Bail Reform and Risk Assessment: The Cautionary Tale of Federal SentencingAcross the country, from New Jersey to Texas to California, bail reform is being debated, implemented, and litigated at\u2026harvardlawreview.org"}, {"url": "http://www.arnoldfoundation.org/laura-and-john-arnold-foundation-makes-pretrial-risk-assessment-available-to-all-jurisdictions-announces-expert-panel-to-serve-as-pretrial-research-advisory-board/", "anchor_text": "Pretrial Risk Assessment Now Available to All Interested Jurisdictions; Research Advisory Board\u2026NEW YORK - The Laura and John Arnold Foundation (LJAF) is expanding access to a suite of resources that will help\u2026www.arnoldfoundation.org"}, {"url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3225350", "anchor_text": "Algorithmic Risk Assessments and the Double-Edged Sword of Youth by Megan T. Stevenson, Christopher\u2026At sentencing, youth can be considered both a mitigating circumstance because of its association with diminished\u2026papers.ssrn.com"}, {"url": "https://www.research.ibm.com/5-in-5/ai-and-bias/", "anchor_text": "AI and bias - IBM Research - USWithin five years, the number of biased AI systems and algorithms will increase. But we will deal with them accordingly\u2026www.research.ibm.com"}, {"url": "https://medium.com/@AINowInstitute/algorithmic-impact-assessments-toward-accountable-automation-in-public-agencies-bd9856e6fdde", "anchor_text": "Algorithmic Impact Assessments: Toward Accountable Automation in Public AgenciesUpdate 4/9/2018: We have released a new report describing our proposal for Algorithmic Impact Assessments in full\u2026medium.com"}, {"url": "https://ainowinstitute.org/", "anchor_text": "AI Now InstituteThe AI Now Institute at New York University is an interdisciplinary research center dedicated to understanding the\u2026ainowinstitute.org"}, {"url": "https://www.darpa.mil/program/explainable-artificial-intelligence", "anchor_text": "Explainable Artificial IntelligenceFigure 1. The Need for Explainable AI Dramatic success in machine learning has led to a torrent of Artificial\u2026www.darpa.mil"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----302e580f5815---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----302e580f5815---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/data-science?source=post_page-----302e580f5815---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ethics?source=post_page-----302e580f5815---------------ethics-----------------", "anchor_text": "Ethics"}, {"url": "https://medium.com/tag/criminal-justice?source=post_page-----302e580f5815---------------criminal_justice-----------------", "anchor_text": "Criminal Justice"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&user=Kayla+Hartman&userId=889f1a67e6db&source=-----302e580f5815---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&user=Kayla+Hartman&userId=889f1a67e6db&source=-----302e580f5815---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----302e580f5815--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F302e580f5815&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----302e580f5815---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----302e580f5815--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----302e580f5815--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----302e580f5815--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----302e580f5815--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----302e580f5815--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kahartman95?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kahartman95?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kayla Hartman"}, {"url": "https://medium.com/@kahartman95/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "148 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F889f1a67e6db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&user=Kayla+Hartman&userId=889f1a67e6db&source=post_page-889f1a67e6db--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6875f432cee7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftowards-ethical-machine-learning-302e580f5815&newsletterV3=889f1a67e6db&newsletterV3Id=6875f432cee7&user=Kayla+Hartman&userId=889f1a67e6db&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}