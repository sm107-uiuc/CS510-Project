{"url": "https://towardsdatascience.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c", "time": 1683001499.399025, "path": "towardsdatascience.com/how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c/", "webpage": {"metadata": {"title": "How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding Layers | by Michael Li | Towards Data Science", "h1": "How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding Layers", "description": "Introduced a different approach to tackle tabular data with deep learning and embedding layers to gain state of the art results."}, "outgoing_paragraph_urls": [{"url": "http://fast.ai", "anchor_text": "fast.ai", "paragraph_index": 1}, {"url": "https://www.kaggle.com/c/bluebook-for-bulldozers/overview", "anchor_text": "Blue Book Bulldozers Competition", "paragraph_index": 1}, {"url": "http://kaggle.com", "anchor_text": "Kaggle", "paragraph_index": 1}, {"url": "https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1604.06737", "anchor_text": "this paper", "paragraph_index": 31}, {"url": "https://www.kaggle.com/c/rossmann-store-sales/overview", "anchor_text": "Rossman", "paragraph_index": 31}, {"url": "https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------", "anchor_text": "Michael Li", "paragraph_index": 34}, {"url": "https://twitter.com/lymenlee", "anchor_text": "@lymenlee", "paragraph_index": 34}, {"url": "https://wayofnumbers.com/", "anchor_text": "wayofnumbers.com", "paragraph_index": 34}, {"url": "https://www.linkedin.com/in/michael-li-dfw", "anchor_text": "https://www.linkedin.com/in/michael-li-dfw", "paragraph_index": 36}], "all_paragraphs": ["Tree-based models like Random Forest and XGBoost have become very popular in solving tabular(structured) data problems and gained a lot of tractions in Kaggle competitions lately. It has its very deserving reasons. However, in this article, I want to introduce a different approach from fast.ai\u2019s Tabular module leveraging:", "This is a bit against industry consensus that Deep Learning is more for unstructured data like image, audio or NLP, and usually not suitable for handling tabular data. Yet, the introduction of embedding layers for the categorical data changed this perspective and we\u2019ll try to use fast.ai\u2019s tabular module on the Blue Book Bulldozers Competition on Kaggle and see how far this approach can go.", "You can find the Kaggle Notebook \ud83d\udcd4: here.", "First, let\u2019s import the necessary modules. The core one here is fastai.tabular:", "Then we\u2019ll read the data into a Pandas DataFrame. You can find the specific code in the Kaggle Notebook link on top of this article but for here, I\u2019ll only show necessary code snippets to keep things as concise as possible. We will read in the CSV file into train_df and this will be the DataFrame we\u2019ll be mainly working on. We will also read in test_df which is the test set.", "Let\u2019s take a brief look at the data we\u2019re dealing with:", "This is to create a good validation set. It cannot be emphasized enough how important a good validation set is in making a successful model. Since we are predicting sales price data in the future, we need to make a validation set that all of its data is collected in the \u2018future\u2019 of the training set. So we need to sort the training set first, then split the \u2018future\u2019 part as the validation set.", "The competition\u2019s evaluation methods use RMSLE (root mean squared log error). So if we take the log of our prediction, we can just use the good old RMSE as our loss function. It\u2019s just easier this way.", "For Feature Engineering, since we will be using deep learning to tackle the problem and it is very good at feature extraction, we\u2019ll only do it on the saledate. This is the advantage of using a Deep Learning approach, it requires way less feature engineering and less dependent on domain knowledge. We\u2019ll use the fast.ai\u2019s add_datepart function to for adding some more features related to the sale date.", "What add_datepart does is it takes the saledate column and added a bunch of other columns like day of week, day of month, whether it is the start or end of a month, quarter and year, etc. These added features will offer more insights into the date and are relevant to user purchasing behaviors. For example, at the end of the year, the company will usually run promotions and prices will usually decrease.", "Let\u2019s check whether all these date related features got added into our DataFrame:", "They did get added. Good. Now we need to do some data pre-processing since this DataFrame has quite some missing data and we also want to categorify and normalize the columns. With the fast.ai library, this is rather simple. We just specify the pre-processing methods we want into a Python list, like so:", "This variable procs will later be used to create the fast.ai DataBunch for training.", "Let\u2019s look at the data types of each column to decide which ones are categorical and which ones are continuous:", "Then we\u2019ll put all categorical columns into a list cat_vars and all continuous columns into a list cont_vars. These two variables will also be used to construct fast.ai DataBunch.", "We\u2019ll create another DataFrame df to feed into the DataBunch. We also specify the dependent variable as dep_var .", "Now is the time to create our validation set. We do this by cutting out a block of the most recent entries from the training set. How big the block should be? Well, the same size as the test set. Let\u2019s see the code:", "We first look at the time period of the test set and make sure it is more recent than all our training set. Then we calculate how many records we need to cut out.", "Finally, let\u2019s construct our DataBunch for training using fast.ai\u2019s datablock API:", "We will fire up a fast.ai tabular.learner from the DataBunch we just created. We want to limit the price range for our prediction to be within the history sale price range, so we need to calculate the y_range. Note that we multiplied the maximum of SalePrice by 1.2 so when we apply sigmoid, the upper limit will also be covered. This is a small trick to squeeze a bit more performance out of the model.", "Now we can create our learner:", "The single most important thing about fast.ai tabular_learner is the use of embedding layers for categorical data. This is the \u2018secret sauce\u2019 that enables Deep Learning to be competitive in handling tabular data. With one embedding layer for each categorical variable, we introduced good interaction for the categorical variables and leverage Deep Learning\u2019s biggest strength: Automatic Feature Extraction. We also used Drop Out for both the dense layers and embedding layers for better regularization. The metrics of the learner is RMSE since we\u2019ve already taken the log of SalePrice. Let\u2019s look at the model.", "As can be seen from the above, we have embedding layers for categorical columns, then followed by a drop out layer. We have a batch norm layer for the continuous columns, then we concatenate all of them (categorical embeddings + continuous variables) together and throw them into two fully connected layers with 1000 and 500 nodes, with Relu, BatchNorm, and Dropout in between. Quite standard stuff.", "Now that we have the model, let\u2019s use fast.ai\u2019s learning rate finder to find a good learning rate:", "We\u2019ll pick the learning rate at the end of the biggest learning rate curve slope: le-02", "Let\u2019s do some training using fast.ai\u2019s One-Cycle Training approach. Note that we added some weight decay (0.2) for regularization.", "We can train some more cycles with smaller learning rate:", "We\u2019ve reached a score of 0.223 on our validation set. Since the competition is not accepting submissions, we can only look at the leaderboard to get a rough idea of how well this model performs:", "The top place is 0.229. Compare to this model\u2019s 0.223. We don\u2019t know how well it works on the test set but overall I think the result we got isn\u2019t bad at all.", "What makes everything click here is the embedding layers. Embedding is just a fancy word of saying mapping something to a vector. Like the word embedding that is getting more popular in NLP, it means using a vector (the size is arbitrary though, depending on tasks) to represent words, and those vectors are weights and can be trained via back-prop.", "Similarly, for our case, we used embeddings on our categorical variables. Each column gets an embedding matrix that can be trained. And each unique column value gets a specific vector mapped to it. The beautiful thing about this is: with embedding, we can now develop \u2018semantics\u2019 to the variable, \u2018semantics\u2019 in the form of weights that matters to our sale price and can be extracted and trained via our deep neural network. The model will have the \u2018depth\u2019 it needs to fit a big data set well.", "But don\u2019t take my words for it, or just look at the results of my humble little project. In a more glory case, there was this paper by the folks who came 3rd in a Kaggle competition for something called Rossman (prediction future sales). Among the top teams in the leaderboard, everyone else used some kind of heavy feature engineering, but by using embedding layers, they managed to score 3rd place with way less feature engineering.", "What\u2019s more interesting is, with embedding layers, you can actually visualize the variable projection in the embedding matrix space. Take the Rossman project as an example. They took a two-dimensional projection of the embedding matrix for the German states.", "And if you circle some states on the embedding space and same states on the actual map. You\u2019ll find out that they are scarily similar. The embedding layer actually discovered geography.", "Found this article useful? Follow me (Michael Li) on Medium or you can find me on Twitter @lymenlee or my blog site wayofnumbers.com. You could also check out my most popular articles below!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Blogger | Product Manager | Developer | Pentester | https://www.linkedin.com/in/michael-li-dfw"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd1eb6b83c52c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://lymenlee.medium.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Michael Li"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c98619a048&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&user=Michael+Li&userId=72c98619a048&source=post_page-72c98619a048----d1eb6b83c52c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://fast.ai", "anchor_text": "fast.ai"}, {"url": "https://www.kaggle.com/c/bluebook-for-bulldozers/overview", "anchor_text": "Blue Book Bulldozers Competition"}, {"url": "http://kaggle.com", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/lymenlee/blue-book-bulldozer-fast-ai-deep-learning", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1604.06737", "anchor_text": "this paper"}, {"url": "https://www.kaggle.com/c/rossmann-store-sales/overview", "anchor_text": "Rossman"}, {"url": "https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------", "anchor_text": "Michael Li"}, {"url": "https://twitter.com/lymenlee", "anchor_text": "@lymenlee"}, {"url": "https://wayofnumbers.com/", "anchor_text": "wayofnumbers.com"}, {"url": "https://towardsdatascience.com/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a", "anchor_text": "\u201cThis is CS50\u201d: A Pleasant Way to Kick Off Your Data Science EducationWhy CS50 is especially good to solidify your software engineering foundationtowardsdatascience.com"}, {"url": "https://towardsdatascience.com/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133", "anchor_text": "Two Sides of the Same Coin: Jeremy Howard\u2019s fast.ai vs Andrew Ng\u2019s deeplearning.aiHow Not to \u2018Overfit\u2019 Your AI Learning by Taking Both fast.ai and deeplearning.ai coursestowardsdatascience.com"}, {"url": "https://towardsdatascience.com/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5", "anchor_text": "What You Need to Know About Netflix\u2019s \u2018Jupyter Killer\u2019: Polynote \ud83d\udcd6It\u2019s about time Jupyter Notebook has its worthy competitortowardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d1eb6b83c52c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d1eb6b83c52c---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----d1eb6b83c52c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d1eb6b83c52c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/embedding?source=post_page-----d1eb6b83c52c---------------embedding-----------------", "anchor_text": "Embedding"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&user=Michael+Li&userId=72c98619a048&source=-----d1eb6b83c52c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&user=Michael+Li&userId=72c98619a048&source=-----d1eb6b83c52c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd1eb6b83c52c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d1eb6b83c52c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d1eb6b83c52c--------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://lymenlee.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michael Li"}, {"url": "https://lymenlee.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.5K Followers"}, {"url": "https://www.linkedin.com/in/michael-li-dfw", "anchor_text": "https://www.linkedin.com/in/michael-li-dfw"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F72c98619a048&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&user=Michael+Li&userId=72c98619a048&source=post_page-72c98619a048--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F95661b899f04&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c&newsletterV3=72c98619a048&newsletterV3Id=95661b899f04&user=Michael+Li&userId=72c98619a048&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}