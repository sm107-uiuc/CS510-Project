{"url": "https://towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72", "time": 1683001754.514011, "path": "towardsdatascience.com/multi-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72/", "webpage": {"metadata": {"title": "Multi-Label Image Classification in TensorFlow 2.0 | by Ashref Maiza | Towards Data Science", "h1": "Multi-Label Image Classification in TensorFlow 2.0", "description": "Do you want to build amazing things with AI? There are many things you could learn. The newly released TensorFlow 2.0 has made deep learning development much easier by integrating more high level\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/ashrefm/multi-label-soft-f1", "anchor_text": "GitHub", "paragraph_index": 1}, {"url": "https://www.tensorflow.org/guide/estimator", "anchor_text": "Estimator API", "paragraph_index": 6}, {"url": "https://www.kaggle.com/neha1703/movie-genre-from-its-poster", "anchor_text": "Kaggle", "paragraph_index": 7}, {"url": "https://www.imdb.com/", "anchor_text": "IMDB Website", "paragraph_index": 7}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing", "anchor_text": "keras.preprocessing", "paragraph_index": 9}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator", "anchor_text": "ImageDataGenerator", "paragraph_index": 9}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator", "anchor_text": "DirectoryIterator", "paragraph_index": 9}, {"url": "https://www.tensorflow.org/guide/data", "anchor_text": "tf.data", "paragraph_index": 10}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data", "anchor_text": "tf.data.Dataset", "paragraph_index": 13}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet", "paragraph_index": 17}, {"url": "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub", "anchor_text": "transfer learning with hub", "paragraph_index": 18}, {"url": "https://www.tensorflow.org/tutorials/images/transfer_learning", "anchor_text": "transfer learning by Fran\u00e7ois Chollet", "paragraph_index": 18}, {"url": "https://www.tensorflow.org/hub/", "anchor_text": "TensorFlow Hub", "paragraph_index": 19}, {"url": "https://tfhub.dev/s?module-type=image-feature-vector&q=tf2", "anchor_text": "Tensorflow 2 compatible image feature vector URL", "paragraph_index": 20}, {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "anchor_text": "instance of MobileNet V2", "paragraph_index": 21}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regressions", "paragraph_index": 27}, {"url": "https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax", "anchor_text": "softmax layer", "paragraph_index": 28}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1-scores", "paragraph_index": 30}, {"url": "https://medium.com/@ashrefm/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d", "anchor_text": "\u201cThe Unknow Benefits of Using a Soft-F1 loss in Classification Sytems\u201d", "paragraph_index": 32}], "all_paragraphs": ["Do you want to build amazing things with AI? There are many things you could learn. The newly released TensorFlow 2.0 has made deep learning development much easier by integrating more high level APIs. If you are already an ML practioner and still did not join the TF world, you have no excuse anymore! The entry ticket is almost free.", "In this blog post, I will describe some concepts and tools that you could find interesting when training multi-label image classifiers. The complete code can be found on GitHub. So, you can take a seat and get your hands on!", "Machine learning has showed tremendous success these recent years in solving complex prediction tasks at a scale that we couldn\u2019t imagine before. The easiest way to start transforming a business with it, is to identify simple binary classification tasks, acquire a sufficient amount of historical data and train a good classifier to generalize well in the real world. There is always some way to frame a predictive business question into a Yes/No question. Is a customer going to churn? Will an ad impression generate a click? Will a click generate a conversion? All these binary questions can be addressed with supervised learning if you collect labeled data.", "We can also design more complex supervised learning systems to solve non-binary classification tasks:", "Multi-label classification is also very common in computer vision applications. We, humans, use our instinct and impressions to guess the content of a new movie when seing its poster (action? drama? comedy? etc.). You have probably been in such situation in a metro station where you wanted to guess the genre of a movie from a wall poster. If we assume that in your inference process, you are using the color information of the poster, saturation, hues, texture of the image, body or facial expression of the actors and any shape or design that makes a genre recognizable, then maybe there is a numerical way to extract those significant patterns from the poster and learn from them in a similar manner. How to build a deep learning model that learns to predict movie genres? Let\u2019s see some techniques you can use in TensorFlow 2.0!", "When TensorFlow was first released by Google in 2015, it rapidly became the world\u2019s most popular open-source machine learning library \u2014 \u201ca comprehensive ecosystem of tools for developers, enterprises, and researchers who want to push the state-of-the-art in machine learning and build scalable ML-powered applications.\u201d Google annouced the official release of TensorFlow 2.0 by the end of September this year. The new version adds major features and improvements:", "Personaly, I enjoyed building custom estimators in TensorFlow 1.x because they provide a high level of flexibility. So, I was happy to see the Estimator API being extended. We can now create estimators by converting existing Keras models.", "This dataset is hosted on Kaggle and contains movie posters from IMDB Website. A csv fileMovieGenre.csv can be downloaded. It contains the following information for each movie: IMDB Id, IMDB Link, Title, IMDB Score, Genre and a link to download the movie poster. In this dataset, each Movie poster can belong to at least one genre and can have at most 3 labels assigned to it. The total number of posters is around 40K.", "Something important to notice is that all movie genres are not represented in the same quantity. Some of them can be very infrequent which may represent a hard challenge for any ML algorithm. You can decide to ignore all labels with less than 1000 observations (Short, Western, Musical, Sport, Film-Noir, News, Talk-Show, Reality-TV, Game-Show). This means that the model will not be trained to predict those labels due to the lack of observations on them.", "If you are familiar with keras.preprocessing you may know the image data iterators (E.g., ImageDataGenerator, DirectoryIterator). These iterators are convenient for multi-class classfication where the image directory contains one subdirectory for each class. But, in the case of multi-label classification, having an image directory that respects this structure is not possible because one observation can belong to multiple classes at the same time.", "That is where the tf.data API has the upper hand.", "You first need to write some function to parse image files and generate a tensor representing the features and a tensor representing the labels.", "To train a model on our dataset you want the data to be:", "These features can be easily added using the tf.data.Dataset abstraction.", "AUTOTUNE will adapt the preprocessing and prefetching workload to model training and batch consumption. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. AUTOTUNE will prompt the tf.data runtime to tune the value dynamically at runtime.", "You can now create a function that generates training and validation datasets for TensorFlow.", "Each batch will be a pair of arrays (one that holds the features and another one that holds the labels). The features array will be of shape (BATCH_SIZE, IMG_SIZE, IMG_SIZE, CHANNELS) containing the scaled pixels. The labels array will be of shape (BATCH_SIZE, N_LABELS) where N_LABELS is the maximum number of target labels and each value represents wether a movie has a particular genre in it (0 or 1 value).", "Instead of building and training a new model from scratch, you can use a pre-trained model in a process called transfer learning. The majority of pre-trained models for vision applications were trained on ImageNet which is a large image database with more than 14 million images divided into more than 20 thousand categories. The idea behind transfer learning is that these models, because they were trained in a context of large and general classification tasks, can then be used to address a more specific task by extracting and transfering meaningful features that were previously learned. All you need to do is acquire a pre-trained model and simply add a new classfier on top of it. The new classification head will be trained from scratch so that you repurpose the objective to your multi-label classfication task.", "AknowledgementTensorFlow core team did a great job sharing pre-trained models and tutorials on how to use them with tf.keras API.transfer learning with hubtransfer learning by Fran\u00e7ois Chollet", "One concept that is essential in software development is the idea of reusing code that is made available through libraries. Libraries make the development faster and generate more efficiency. For machine learning engineers working on computer vision or NLP tasks, we know how long it takes to train complex neural network architectures from scratch. TensorFlow Hub is a library that allows to publish and reuse pre-made ML components. Using TF.Hub, it becomes simple to retrain the top layer of a pre-trained model to recognize the classes in a new dataset. TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning.", "Any Tensorflow 2 compatible image feature vector URL from tfhub.dev can be interesting for our dataset. The only condition is to insure that the shape of image features in our prepared dataset matches the expected input shape of the model you want to reuse.", "First, let\u2019s prepare the feature extractor. We will be using a pre-trained instance of MobileNet V2 with a depth multiplier of 1.0 and an input size of 224x224. MobileNet V2 is actually a large family of neural network architectures that were mainly designed to speed up on-device inference. They come in different sizes depending on the depth multiplier (number of features in hidden convolutional layers) and the size of input images.", "The feature extractor we are using here accepts images of shape (224, 224, 3) and returns a 1280-length vector for each image.", "You should freeze the variables in the feature extractor layer, so that the training only modifies the new classification layers. Usually, it is a good practice when working with datasets that are very small compared to the orginal dataset the feature extractor was trained on.", "Fine tuning the feature extractor is only recommended if the training dataset is large and very similar to the original ImageNet dataset.", "Now, you can wrap the feature extractor layer in a tf.keras.Sequential model and add new layers on top.", "Here is what the model summary looks like:", "The 2.2M parameters in MobileNet are frozen, but there are 1.3K trainable parameters in the dense layers. You need to apply the sigmoid activation function in the final neurons to ouput a probability score for each genre apart. By doing so, you are relying on multiple logistic regressions to train simultaneously inside the same model. Every final neuron will act as a seperate binary classifier for one single class, even though the features extracted are common to all final neurons.", "When generating predictions with this model, you should expect an independant probability score for each genre and that all probability scores do not necessarily sum up to 1. This is different from using a softmax layer in multi-class classification where the sum of probability scores in the output is equal to 1.", "After preparing the dataset and composing a model by attaching a multi-label neural network classifier on top of a pre-trained model, you can proceed to training and evaluation but first you need to define two major functions:", "Suppose you want to use the Macro F1-score @ threshold 0.5 to evaluate the performance of the model. It is the average of all F1-scores obtained when fixing a probability threshold of 0.5 for each label. Taking the average over all labels is very reasonable if they have the same importance in the multi-label classification task. I am providing here an implementation of this metric on a batch of observations in TensorFlow.", "This metric is not differentiable and thus cannot be used as a loss function. Instead, you can transform it into a differentiable version that can be minimized. We will call the resulting loss function the macro soft-F1 loss!", "Usually, it is fine to optimize the model by using the traditional binary cross-entropy but the macro soft-F1 loss brings very important benefits that I decided to exploit in some use cases. If you are interested in understanding in more details the motivation behind implementing this custom loss, you can read my blog post: \u201cThe Unknow Benefits of Using a Soft-F1 loss in Classification Sytems\u201d.", "Specify the learning rate and the number of training epochs (number of loops over the whole dataset).", "Compile the model to configure the training process.", "Now, you can pass the training dataset of (features, labels) to fit the model and indicate a seperate dataset for validation. The performance on the validation set will be measured after each epoch.", "After 30 epochs, you may observe a convergence on the validation set.", "Let\u2019s see what the predictions look like when using our model on posters of some known movies in the validation set.", "We notice that the model can get \u201cRomance\u201d right. Is it because of the red title on the poster of \u201cAn Affair of Love\u201d?", "What about the model suggesting new labels for \u201cClash of the Titans\u201d? The \u201cSci-Fi\u201d label seems very acurate and related to this film. Remember that in the original dataset a maximum of 3 labels are given for each poster. Probably, more useful labels could be recommended by using our model!", "After having trained and evaluated the model, you can export it as a TensorFlow saved model for future use.", "You can later reload the tf.keras model by specifying the path to the export directory containing the .pb file.", "Notice the \u2018KerasLayer\u2019 object in the custom_objects dictionary. This is the TF.Hub module that was used in composing the model.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7d4cf8a4bc72&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ashrefm?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Ashref Maiza"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80c2f1871537&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&user=Ashref+Maiza&userId=80c2f1871537&source=post_page-80c2f1871537----7d4cf8a4bc72---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/ashrefm/multi-label-soft-f1", "anchor_text": "GitHub"}, {"url": "https://www.tensorflow.org/guide/keras/overview", "anchor_text": "Full integration of Keras"}, {"url": "https://www.tensorflow.org/tutorials/customization/performance", "anchor_text": "tf.function"}, {"url": "https://www.tensorflow.org/guide/data", "anchor_text": "TensorFlow Datasets"}, {"url": "https://www.tensorflow.org/tfx/guide/serving", "anchor_text": "TensorFlow Serving"}, {"url": "https://www.tensorflow.org/lite", "anchor_text": "TensorFlow Lite"}, {"url": "https://www.tensorflow.org/js", "anchor_text": "TensorFlow.js"}, {"url": "https://www.tensorflow.org/guide/estimator", "anchor_text": "Estimator API"}, {"url": "https://medium.com/tensorflow/tensorflow-2-0-is-now-available-57d706c2a9ab", "anchor_text": "TensorFlow 2.0 is now available!"}, {"url": "https://www.kaggle.com/neha1703/movie-genre-from-its-poster", "anchor_text": "Kaggle"}, {"url": "https://www.imdb.com/", "anchor_text": "IMDB Website"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing", "anchor_text": "keras.preprocessing"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator", "anchor_text": "ImageDataGenerator"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator", "anchor_text": "DirectoryIterator"}, {"url": "https://www.tensorflow.org/guide/data", "anchor_text": "tf.data"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/data", "anchor_text": "tf.data.Dataset"}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet"}, {"url": "https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub", "anchor_text": "transfer learning with hub"}, {"url": "https://www.tensorflow.org/tutorials/images/transfer_learning", "anchor_text": "transfer learning by Fran\u00e7ois Chollet"}, {"url": "https://www.tensorflow.org/hub/", "anchor_text": "TensorFlow Hub"}, {"url": "https://tfhub.dev/s?module-type=image-feature-vector&q=tf2", "anchor_text": "Tensorflow 2 compatible image feature vector URL"}, {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "anchor_text": "instance of MobileNet V2"}, {"url": "https://en.wikipedia.org/wiki/Logistic_regression", "anchor_text": "logistic regressions"}, {"url": "https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax", "anchor_text": "softmax layer"}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "backpropagate"}, {"url": "https://en.wikipedia.org/wiki/F1_score", "anchor_text": "F1-scores"}, {"url": "https://medium.com/@ashrefm/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d", "anchor_text": "\u201cThe Unknow Benefits of Using a Soft-F1 loss in Classification Sytems\u201d"}, {"url": "https://medium.com/@ashrefm/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d", "anchor_text": "article"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7d4cf8a4bc72---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----7d4cf8a4bc72---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----7d4cf8a4bc72---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&user=Ashref+Maiza&userId=80c2f1871537&source=-----7d4cf8a4bc72---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&user=Ashref+Maiza&userId=80c2f1871537&source=-----7d4cf8a4bc72---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7d4cf8a4bc72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7d4cf8a4bc72---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7d4cf8a4bc72--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ashrefm?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ashref Maiza"}, {"url": "https://medium.com/@ashrefm/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "130 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80c2f1871537&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&user=Ashref+Maiza&userId=80c2f1871537&source=post_page-80c2f1871537--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3a2ae36b9258&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-image-classification-in-tensorflow-2-0-7d4cf8a4bc72&newsletterV3=80c2f1871537&newsletterV3Id=3a2ae36b9258&user=Ashref+Maiza&userId=80c2f1871537&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}