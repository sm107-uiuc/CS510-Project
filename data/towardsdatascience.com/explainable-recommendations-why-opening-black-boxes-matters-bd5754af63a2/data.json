{"url": "https://towardsdatascience.com/explainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2", "time": 1683007760.9882188, "path": "towardsdatascience.com/explainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2/", "webpage": {"metadata": {"title": "Explainable recommendations \u2014 why opening black boxes matters | by Ville Kuosmanen | Towards Data Science", "h1": "Explainable recommendations \u2014 why opening black boxes matters", "description": "This post is part 1 in my series of posts about explainable recommendations, based on my BSc dissertation. Part 2 shows the implementation of an explainable movie recommender system, while part 3\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/villekuosmanen/SHProject/raw/master/dissertation.pdf", "anchor_text": "BSc dissertation", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/how-i-implemented-explainable-movie-recommendations-using-python-7aa42a0af023", "anchor_text": "Part 2", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/what-is-the-radical-content-problem-and-does-your-recommender-system-suffer-from-it-7fe017f9a8b1", "anchor_text": "part 3", "paragraph_index": 0}], "all_paragraphs": ["This post is part 1 in my series of posts about explainable recommendations, based on my BSc dissertation. Part 2 shows the implementation of an explainable movie recommender system, while part 3 discusses the application of post-hoc explainability in data science.", "Recommender systems help users discover new items, and they have seen increased use in various applications including video streaming, e-commerce, and social media. Recommender systems can be built using several classes of techniques, but here I will focus on collaborative filtering with latent factor models (LFM). Collaborative filtering methods produce recommendations based on the users\u2019 previous ratings with the theory that if users A and B liked similar items in the past, it\u2019s likely that A will also like other items rated highly by B[1][2]. Explaining how LFMs work is out of scope for this blog post, but in a nutshell, they factorise the sparse matrix of known ratings to a set of common user and item factors with dimensionality d. These factors can then be treated as a vector with d dimensions, allowing us to predict the rating user u would give to item i by calculating the dot product of their vectors [3].", "LFMs can be generated by various matrix factorisation models, such as SVD. Since the factors are learned from numeric user ratings without any reference to the items themselves, they don\u2019t directly map to any interpretable factors or categories \u2014 for this reason LFMs are said to be uninterpretable, black-box models. Uninterpretable models are a problem for many reasons, perhaps most importantly due to lack of trust. If the system can\u2019t tell its user why it made a particular decision, why should the user trust that decision? Besides trust, Table 1 shows the seven explanatory criteria previously identified for explainability [4]. Justifying the decisions made by the model is especially important in areas like the medical industry, where incorrect decisions can have disastrous results. While recommender systems are often used in less serious applications such as online stores and social networks, making the recommendations explainable is still important since it\u2019s been shown that users prefer recommendations which they perceive as transparent [5].", "Research on explainable recommendations has focused on two main approaches, embedded and post-hoc explanations [6]. In embedded methods the explanation generation is integrated with the recommendations model itself, while in post-hoc methods the uninterpretable recommendations are made explainable after they\u2019ve been produced by the original model by a white-box explanation generator. An example of an embedded method is Explicit Matrix Factorization (EMF), where the factors in an LMF are not automatically learned but rather collected from textual user reviews. The system constructs matrices for how much users cared about each item feature, and how well each item was described by the feature. An LFM could then be built using these matrices. The system is easily interpretable and explained by simply checking which factors items and users score the highest, while maintaining good performance in prediction accuracy. [7]", "A post-hoc explainer can be built by extracting logical association rules from the recommendation model\u2019s inputs and outputs. The rules extracted were of form {X => Y}, where X is an item the user has experienced preference for, and Y is the recommendation. The association rule in question can be expressed in words as \u201cBecause you liked X, we recommend Y\u201d. The association rules are combined with the black box model by marking recommendations that are produced by both models as \u201cexplainable recommendations\u201d [8].", "Embedded explanations tend to naturally have good explainability because the explanations and recommendations models are not decoupled. Unlike post-hoc methods, embedded explanations are not model-agnostic and require a particular type of model (e.g. LFM) or domain (such as academic research papers, or textual reviews) to function, therefore making them less flexible.", "The explanations can be evaluated using both quantitative and qualitative approaches. Quantitative approaches evaluate objective, measurable characteristics of the system such as the time it takes to generate explanations, the accuracy of explainable recommendations, and the share of recommendations that can be made explainable. The last metric is known as model fidelity, and it\u2019s considered one of the key metrics for certain post-hoc explanations [8]. The explanations should also be evaluated qualitatively. This is often done through user studies or A/B tests by using one or more of the explanation criteria (Table 1) as metrics [4]. For example, if the goal of an explanation is to increase user trust in the system, a user study could compare whether a group of users that sees an explanation reports greater trust in the system than the control group that only saw a recommendation.", "Amazon has used a variety of explanations in their systems. Firstly, some recommendations are labelled with a sentence describing how it was found, such as \u201cCustomers who bought this item also bought\u2026\u201d. Amazon has also introduced the ability for users to influence how much a purchase should influence their recommendations, or if it should be filtered out altogether. This explanation improves the scrutability of the system and can be useful for filtering out items that were purchased as gifts. Users can also see which of their previous purchases or ratings influenced a recommendation. [9]", "Facebook has an explanation feature that tells users why they\u2019re seeing a post as well as indications on why the posts are ordered in the way they were. Users are also able to see detailed information on why an advertisement was shown to them, including a timeline on how the advert creator has interacted with their personal data. By releasing the feature Facebook wanted to increase transparency in its products, as well as help users control their own news feed, i.e. improve the scrutability of the product. [10] In addition, the Chinese e-commerce platform JingDong used word clouds of feature-opinion pairs as an explanation as part of a study on Explicit Matrix Factorization, which is a content-based explanation. The researchers found that the Click-Through Rate (CTR) of users who saw the new explanation was significantly higher than of those who received a generic \u201cPeople also viewed\u2026\u201d explanation or no explanation at all. [7]", "While explainable recommendations have seen increased attention in research over the last few years, few solutions have been deployed into production in industry. The next part of the series will cover my implementation of an explainable movie recommender system using two post-hoc explainers, it\u2019s evaluation both offline and through a user study, as well as a discussion on how the explanations could be deployed into real systems.", "The following references directly relate to the content of this post. A full reference list for the entire project is listed in my dissertation.", "[7]: Zhang, Y., Lai, G., Zhang, M., Zhang, Y., Liu, Y., & Ma, S. (2014, July). Explicit factor models for explainable recommendation based on phrase-level sentiment analysis. In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval (pp. 83\u201392). ACM.", "[8]: Peake, G., & Wang, J. (2018, July). Explanation mining: Post hoc interpretability of latent factor models for recommendation systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2060\u20132069). ACM.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I care about digital products that improve our lives. Software Engineer at a crypto startup."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbd5754af63a2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://villekuosmanen.medium.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": ""}, {"url": "https://villekuosmanen.medium.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Ville Kuosmanen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a700a66e281&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&user=Ville+Kuosmanen&userId=1a700a66e281&source=post_page-1a700a66e281----bd5754af63a2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@zariawright501?utm_source=medium&utm_medium=referral", "anchor_text": "Zaria Wright"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/villekuosmanen/SHProject/raw/master/dissertation.pdf", "anchor_text": "BSc dissertation"}, {"url": "https://towardsdatascience.com/how-i-implemented-explainable-movie-recommendations-using-python-7aa42a0af023", "anchor_text": "Part 2"}, {"url": "https://towardsdatascience.com/what-is-the-radical-content-problem-and-does-your-recommender-system-suffer-from-it-7fe017f9a8b1", "anchor_text": "part 3"}, {"url": "https://www.amazon.com/gp/help/customer/display.html/ref=hp_16465201_FAQ_recommendations?nodeId=13316081", "anchor_text": "https://www.amazon.com/gp/help/customer/display.html/ref=hp_16465201_FAQ_recommendations?nodeId=13316081"}, {"url": "https://newsroom.fb.com/news/2019/03/why-am-i-seeing-this/", "anchor_text": "https://newsroom.fb.com/news/2019/03/why-am-i-seeing-this/"}, {"url": "https://medium.com/tag/recommendation-system?source=post_page-----bd5754af63a2---------------recommendation_system-----------------", "anchor_text": "Recommendation System"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bd5754af63a2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bd5754af63a2---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/software-engineering?source=post_page-----bd5754af63a2---------------software_engineering-----------------", "anchor_text": "Software Engineering"}, {"url": "https://medium.com/tag/research?source=post_page-----bd5754af63a2---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&user=Ville+Kuosmanen&userId=1a700a66e281&source=-----bd5754af63a2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&user=Ville+Kuosmanen&userId=1a700a66e281&source=-----bd5754af63a2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbd5754af63a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bd5754af63a2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bd5754af63a2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bd5754af63a2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bd5754af63a2--------------------------------", "anchor_text": ""}, {"url": "https://villekuosmanen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://villekuosmanen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ville Kuosmanen"}, {"url": "https://villekuosmanen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "154 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a700a66e281&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&user=Ville+Kuosmanen&userId=1a700a66e281&source=post_page-1a700a66e281--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd789c40a43a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplainable-recommendations-why-opening-black-boxes-matters-bd5754af63a2&newsletterV3=1a700a66e281&newsletterV3Id=d789c40a43a2&user=Ville+Kuosmanen&userId=1a700a66e281&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}