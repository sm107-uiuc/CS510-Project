{"url": "https://towardsdatascience.com/nlp-deep-learning-for-relation-extraction-9c5d13110afa", "time": 1683009962.7623732, "path": "towardsdatascience.com/nlp-deep-learning-for-relation-extraction-9c5d13110afa/", "webpage": {"metadata": {"title": "NLP: Making sense of review data using relation extraction | by Oskar Handmark | Towards Data Science", "h1": "NLP: Making sense of review data using relation extraction", "description": "In this post, we will be focusing on text mining and review analysis. We\u2019ll roll our own deep learning implementation for relation extraction. Imagine you have a large pool of reviews about your\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)", "anchor_text": "BIO", "paragraph_index": 7}, {"url": "https://www.mturk.com/", "anchor_text": "Mech Turk", "paragraph_index": 8}, {"url": "https://spacy.io/", "anchor_text": "SpaCy", "paragraph_index": 10}, {"url": "https://www.textrazor.com/", "anchor_text": "TextRazor", "paragraph_index": 10}, {"url": "https://www.nltk.org/", "anchor_text": "NLTK", "paragraph_index": 10}, {"url": "https://stanfordnlp.github.io/CoreNLP/", "anchor_text": "Stanford CoreNLP", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Part_of_speech", "anchor_text": "part-of-speech", "paragraph_index": 11}, {"url": "http://universaldependencies.org/en/dep/index.html", "anchor_text": "Universal Dependencies", "paragraph_index": 11}, {"url": "https://github.com/OskarHandmark/nlp-deep-learning", "anchor_text": "Github", "paragraph_index": 31}, {"url": "https://backtick.se", "anchor_text": "https://backtick.se", "paragraph_index": 33}], "all_paragraphs": ["In this post, we will be focusing on text mining and review analysis. We\u2019ll roll our own deep learning implementation for relation extraction. Imagine you have a large pool of reviews about your company or your products and you want a quick overview of what descriptors or adjectives are mentioned about certain parts or features of your company or products. The end goal looks something like this:", "Performing this over thousands of reviews and aggregating this together builds a pretty powerful summarization tool that can be used to get a quick and thorough picture of what is said about a specific company or product. Moreover, we can zoom in on areas that we are specifically interested in, such as delivery times or the service quality. Since there exist so many good tools for sentiment analysis already, our focus will be on implementing relation extraction. Here are some examples of what we would like to extract, given the review sentence.", "\u201cX has the cheapest prices and super quick delivery\u201d", "\u201cI was impressed by the battery life\u201d", "We will use a few NLP techniques related to information extraction to solve this problem. Roughly, we\u2019ll give a few examples of how we want it to work along with data relevant to each word in our sentences, and let a neural network figure out what patterns may be hidden in there. I want to emphasize the fact that we will not include the actual word itself as a feature, which otherwise is a pretty common approach. This means that the model will generalize better to words it has not seen in its training set.", "Outlined below are the steps we\u2019ll take to implement this.", "The power of machine learning is when you\u2019re not sure how to algorithmically solve a problem, as long as you provide some examples of how you want it to work, and what\u2019s relevant in your data, you can get a pretty close estimate.", "We\u2019ll create some examples for our model. We\u2019ll use a chunking strategy to denote groups of entities or descriptors. For example, if the battery life was fantastically super amazing, we\u2019d want to make sure all of those words make it in there as a group. We\u2019ll use a version of the BIO (Begin, Inside, Outside) labelling standard to mark when word groups start and when they end:", "We\u2019d want to include as many examples as possible, and after writing a couple yourself, you realize that this is probably not what you were set out to do in life. Consider outsourcing this to Mech Turk.", "This step is manual, but do not be fooled by its trivial appearance. It is very important that labelling is done meticulously with persistent methodology. If you do not follow the same approach throughout your entire training set, you will confuse your model during training.", "Now that we have some labelled data, all we need is features for our model. A feature is a single measurable property about one of your training examples. For each of your training examples there are multiple features. In our case, a feature is information about each word, how they relate to other words, and what properties they have. There are quite a few libraries and services for extracting features from text, such as SpaCy , TextRazor and NLTK . We\u2019ll use Stanford CoreNLP because it has one of the best dependency parsers in the world.", "We can use dependency parse trees to extract the syntactic structure of our sentences. This will be helpful since it gives us information about the part-of-speech (POS) tags of the words. A POS-tag is a word category which describes the grammatical properties of the word, a few examples would be noun, verb and adjective. The dependency parse tree also gives us information about how the words structurally relate to other words. This is represented as in-and-out links to and from the words in the sentence. Stanford CoreNLP uses the Universal Dependencies standard to represent the dependencies.", "Dependency parse trees are internally a prediction process using a trained model, and even though the accuracy is high, there is a chance we get incorrect parse trees, depending on the sentence. We\u2019ll create a few features based on this tree. Each word will have the following features:", "Deliveries will have a feature vector as follows:", "In order to feed our feature vectors as input to our neural network, we\u2019ll need to transform our current feature vector into float values. Note that our current feature vector includes values of type string. How do you convert a string to a float? You don\u2019t.", "We\u2019ll use one of the standard approaches for this: One hot encoding. For every possible POS-tag, we\u2019ll create a new binary feature. We\u2019ll then mark the current feature\u2019s value by putting a 1 in the sub-feature that represents that tag. Like so:", "Why is it called one hot encoding? Because one of the features is hot, and marked as a one. You can think of this step as putting a word into a category bin, where the bin\u2019s name is the word itself, and not putting it in any other bins.", "This methodology is often used when you\u2019re working with actual words as features, but brings up the dimensionally of your feature to multiple thousand dimensions (this is usually fine, since the matrices are sparse). In our case, we don\u2019t include the actual word as a feature, but we still have to do this, since the POS-tags are strings.", "The observant reader might have noticed that we\u2019ve already done a slightly similar but different version of this step for the in and out-links features. Since we defined our features as binary, and named them \u2018in_nsubj\u2019 etc, we\u2019ve essentially created a similar encoding for our link features. We\u2019d put 1\u2019s in all bins where there is an in- or out link, respectively. The only difference here is that a word might have multiple in links, and multiple out links, hence the separation.", "Given our 27 training sentences, we have a total of 253 used features (after encoding), resulting in an input layer of size 253. We\u2019ll use a few hidden layers of different sizes, and an output layer of size 5, one for each category.", "Training the model is as simple as feeding the feature vectors and correct labels for all our training examples into the neural network model that we\u2019ve defined. We can then cross validate (or use a separate test set) to measure the performance of our model (my example code with 27 sentences of training has an accuracy of about 81%).", "Since we\u2019ve trained this model with a categorical output (our final layer has 5 outputs), we can get the probabilities assigned to each output for a given word during prediction:", "This is a post-prediction step in which we link the entities and descriptors together. After the model has made its predictions, we\u2019ll look at the dependency parse tree again, and follow the following simple heuristic:", "If there is a link between any of the words in the entity group, to any of the words in the descriptor group, we\u2019ll say they are connected. If there are more descriptors than entities, we allow multiple descriptors to be linked to the same entity, and vice versa.", "We\u2019ll also look for negations and transform words to their lemma-forms (i.e impressed \u2192 impressive). For example, imagine a sentence like:", "\u201cI was impressed by the battery life, but not by the design.\u201d", "And our classifier produced a correct classification of:", "Follow all original dependency parse tree links (for the predicted groups):", "impressed \u2192 [ nmod ] \u2192 life", "design \u2192 [conj ] \u2192 impressed", "When everything\u2019s in place. Running this for a lot of sentences and then aggregating the results is where things become useful. Sentiment analysis could be performed on the descriptors with ease. Imagine you had a few hundred or thousand reviews of one of your products (looking at you Amazon..), you\u2019ll have a summary of the pros and cons of that product, like the introductory image suggested:", "Somewhat incomplete source available on Github.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Entrepreneurship, investments, data engineering & ML. Co-Founder of Backtick - https://backtick.se"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c5d13110afa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ohandmark.medium.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": ""}, {"url": "https://ohandmark.medium.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Oskar Handmark"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffa4a9e525da2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&user=Oskar+Handmark&userId=fa4a9e525da2&source=post_page-fa4a9e525da2----9c5d13110afa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)", "anchor_text": "BIO"}, {"url": "https://www.mturk.com/", "anchor_text": "Mech Turk"}, {"url": "https://spacy.io/", "anchor_text": "SpaCy"}, {"url": "https://www.textrazor.com/", "anchor_text": "TextRazor"}, {"url": "https://www.nltk.org/", "anchor_text": "NLTK"}, {"url": "https://stanfordnlp.github.io/CoreNLP/", "anchor_text": "Stanford CoreNLP"}, {"url": "https://en.wikipedia.org/wiki/Part_of_speech", "anchor_text": "part-of-speech"}, {"url": "http://universaldependencies.org/en/dep/index.html", "anchor_text": "Universal Dependencies"}, {"url": "https://github.com/OskarHandmark/nlp-deep-learning", "anchor_text": "Github"}, {"url": "https://medium.com/tag/text-mining?source=post_page-----9c5d13110afa---------------text_mining-----------------", "anchor_text": "Text Mining"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9c5d13110afa---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9c5d13110afa---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9c5d13110afa---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----9c5d13110afa---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&user=Oskar+Handmark&userId=fa4a9e525da2&source=-----9c5d13110afa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&user=Oskar+Handmark&userId=fa4a9e525da2&source=-----9c5d13110afa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9c5d13110afa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9c5d13110afa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c5d13110afa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9c5d13110afa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9c5d13110afa--------------------------------", "anchor_text": ""}, {"url": "https://ohandmark.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ohandmark.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Oskar Handmark"}, {"url": "https://ohandmark.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "118 Followers"}, {"url": "https://backtick.se", "anchor_text": "https://backtick.se"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffa4a9e525da2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&user=Oskar+Handmark&userId=fa4a9e525da2&source=post_page-fa4a9e525da2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1292fd44033c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-deep-learning-for-relation-extraction-9c5d13110afa&newsletterV3=fa4a9e525da2&newsletterV3Id=1292fd44033c&user=Oskar+Handmark&userId=fa4a9e525da2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}