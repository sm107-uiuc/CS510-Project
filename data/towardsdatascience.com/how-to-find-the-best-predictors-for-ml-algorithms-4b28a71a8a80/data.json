{"url": "https://towardsdatascience.com/how-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80", "time": 1683011010.035511, "path": "towardsdatascience.com/how-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80/", "webpage": {"metadata": {"title": "How to Find the Best Predictors for ML Algorithms | Towards Data Science", "h1": "How to Find the Best Predictors for ML Algorithms", "description": "Understand Feature Selection and its various techniques to boost the predictive power of your machine learning algorithms and models."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/practical-guide-to-data-cleaning-in-python-f5334320e8e", "anchor_text": "data cleaned", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html", "anchor_text": "OrdinalEncoder", "paragraph_index": 10}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html", "anchor_text": "SelectKBest", "paragraph_index": 10}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html", "anchor_text": "chi2", "paragraph_index": 10}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html", "anchor_text": "mutual_info_classif", "paragraph_index": 10}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "one-hot encoded", "paragraph_index": 13}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html", "anchor_text": "dummy variables", "paragraph_index": 13}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html", "anchor_text": "chi2_contingency", "paragraph_index": 13}, {"url": "https://statisticsbyjim.com/anova/f-tests-anova/", "anchor_text": "this", "paragraph_index": 15}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html", "anchor_text": "f_classif", "paragraph_index": 16}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html", "anchor_text": "f_regression", "paragraph_index": 19}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html", "anchor_text": "Recursive Feature Elimination", "paragraph_index": 20}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html", "anchor_text": "RFECV", "paragraph_index": 27}, {"url": "http://www.finlyticshub.com", "anchor_text": "me", "paragraph_index": 33}, {"url": "http://www.machinelearningmastery.com", "anchor_text": "Machine Learning Mastery", "paragraph_index": 34}, {"url": "http://www.finltyicshub.com", "anchor_text": "www.finltyicshub.com", "paragraph_index": 36}], "all_paragraphs": ["So now, you have your data cleaned and are ready to feed it to machine learning (ML) algorithms. But what if you have a substantial number of input features? Are they all useful and predictive enough for model learning? Will it make your model less interpretive if you use all the features? Having a large number of predictors are also likely to increase the development and model training time, while at the same time utilizing a large amount of system memory.", "Feature selection techniques aim to systematically select the best subset of input features for model training to predict the target variable. Do not confuse feature selection with other dimensionality reduction techniques (e.g., PCA or use of information theory). Feature selection techniques do not amend the original semantics of the predictors, but simply select a subset of them, thereby resulting in a more interpretable model.", "According to Sayes et al.\u00b9: \u201cThe objectives of feature selection are manifold, the most important ones being:", "Although feature selection is applicable for both supervised and unsupervised learning, I will focus here on supervised feature selection, where the target variable is known beforehand.", "We can define three broad categories in the context of supervised feature selection:", "Filter feature selection techniques utilize various statistical tests and measures to infer the relationship between input and target variables before selecting the best subset of input features.", "Note that these statistical measures are univariate, and accordingly, the correlations between various pairs of input features are not accounted for. It might be a good idea to first start with a correlation matrix to weed out redundant correlated features. Alternatively, specific advanced multivariate filter techniques can be utilized, for example, Correlation-based Feature Selection (CFS), Markov Blanket Filter (MBF), and Fast Correlation-based Feature Selection (FCBF). However, there are currently no widely used and supported python packages out there that support these advanced multivariate feature selection techniques.", "Two conventional statistical feature techniques that can be used for categorical features in a classification problem are:", "The Chi-Squared test is used to determine the extent of relationship or dependence between two categorical variables \u2014 in our case, one categorical input feature, and the other, a categorical target variable.", "In probability and information theories, the Mutual Information of two random variables measures the level of independence between them. Higher values mean higher dependency.", "For categorical features encoded as integers (e.g., through OrdinalEncoder), scikit-learn\u2019s SelectKBest class is used in conjunction with either the chi2 or mutual_info_classif functions to identify and select the top k most relevant features. The higher the score returned by SelectKBest, the better that feature\u2019s predictive power will be. The shortlisted features are then fed into the ML algorithm for model development.", "A complete working example showing both chi2 and mutual_info_classif follows:", "Note that SelectKBest can also be used as part of a Pipeline for cross-validation purposes. However, depending upon the cardinality of your input features, using OrdinalEncoder in a Pipeline can sometimes not be feasible when the model comes across new value in the test set that was not available in the train set and was therefore not used for encoding. A workaround in such situations could be to run train_test_split multiple times with different test_size and random_state, and take an average of the selected validation metric.", "For object type categorical features that have not been numerically encoded (maybe because they will be one-hot encoded or converted to dummy variables at a later stage), SciPy\u2019s chi2_contingency class is used to calculate the chi statistic and p values of each pair of categorical features and the target variable. Features with the lowest p values are then shortlisted for modeling.", "Two conventional statistical feature techniques that can be used for numerical features in a classification problem are:", "The Analysis of Variance (ANOVA) F-statistic calculates the ratio of variances of the means of two or more samples of data. The higher this ratio between a numerical input feature and a categorical target feature, the lower the independence between the two and more likely to be useful for model training. Refer to this excellent article for details on the ANOVA F-statistic.", "ANOVA F-statistic for feature selection is similarly implemented in Python as a chi-squared test of independence through sci-kit learn\u2019s f_classif function. Given that we are dealing with numerical features this time around, we can easily implement cross-validation through pipelines as demonstrated below:", "Ah, this is the easiest type of feature selection: identifying the most suitable numeric input feature for a numerical target variable (regression problem). Possible techniques include:", "Correlation measures the degree of change in one variable as a result of another. Perhaps the best-known correlation measure is Pearson\u2019s correlation that assumes a Gaussian distribution of the data. Correlation coefficients range between -1 (perfect negative correlation) and 1 (perfect positive correlation) with 0 representing no relationship between the variables whatsoever.", "In addition to plotting the correlation matrix, automatic correlation-based feature selection can be implemented similar to a chi-squared test of independence or ANOVA F-statistic, using sci-kit learn\u2019s f_regression function in conjunction with the SelectKBest class. Further, just like the ANOVA F-statistic function, we can easily implement cross-validation through pipelines as demonstrated below:", "Recursive Feature Elimination (RFE) from scikit-learn is the most widely used wrapper feature selection method in practice. RFE is feature-type agnostic that iteratively selects the best number of features through a given supervised learning model (estimator).", "From scikit-learn documentation: \u201cFirst, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\u201d", "As evident from the above, RFE can only be used with an algorithm that has either a coef_ or feature_importances_ attribute to evaluate feature importance. Since RFE is a wrapper feature selection technique, it can use any given estimator (that can be different from the algorithm that is applied to the selected features) to identify the most suitable features.", "Given that RFE can be used for both categorical and numerical features; its implementation is similar in case of both classification and regression problems.", "The main parameter of RFE that requires tuning is n_features_to_select. A practical demonstration to identify the best number of features based on RFE using DecisionTreeClassifier for both feature selection and the classification algorithm is as below:", "The above code snippet will print out the mean and STD of Accuracy scores for each number of features utilized in RFE, something like below:", "Based purely on the Accuracy score, selecting six features appears to be ideal in this scenario.", "However, how do we know that DecisionTreeClassifier is the best algorithm to be used within RFE? What if we would like to evaluate various algorithms with RFE? RFECV comes to our help here.", "The primary purpose of RFECV is to select the best number of features through cross-validation automatically. Since the ideal number of features will be auto-selected by RFECV (therefore, not requiring the for loop in the last code snippet), we can efficiently train and assess multiple models for RFECV feature selection. The model with the best validation metric can then be used moving forward for making predictions.", "Let us look at a practical example now:", "The above code snippet will print out the mean and STD of Accuracy scores for each of the model utilized in RFECV, something like below:", "The simple logistic regression model wins for wrapper feature selection. We can then use this for making predictions:", "The majority of ML algorithms have a built-in attribute to view the relative importance of the features used during model learning. Some examples include:", "That is it from me this time. Feel free to reach out to me if you would like to discuss anything related to data analytics, traditional machine learning, or credit analysis.", "Inspired by Dr. Jason Brownlee of Machine Learning Mastery", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A finance professional by education with a keen interest in data analytics and machine learning. www.finltyicshub.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4b28a71a8a80&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@asad_mumtaz?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Asad Mumtaz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f9c6741ffa5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=post_page-1f9c6741ffa5----4b28a71a8a80---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.shutterstock.com/g/JrCasas", "anchor_text": "JrCasas"}, {"url": "http://www.shutterstock.com", "anchor_text": "Shutterstock"}, {"url": "https://towardsdatascience.com/practical-guide-to-data-cleaning-in-python-f5334320e8e", "anchor_text": "data cleaned"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html", "anchor_text": "Recursive Feature Elimination (RFE)"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html", "anchor_text": "OrdinalEncoder"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html", "anchor_text": "SelectKBest"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html", "anchor_text": "chi2"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html", "anchor_text": "mutual_info_classif"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html", "anchor_text": "one-hot encoded"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html", "anchor_text": "dummy variables"}, {"url": "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html", "anchor_text": "chi2_contingency"}, {"url": "https://statisticsbyjim.com/anova/f-tests-anova/", "anchor_text": "this"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html", "anchor_text": "f_classif"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html", "anchor_text": "f_regression"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html", "anchor_text": "Recursive Feature Elimination"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html", "anchor_text": "RFECV"}, {"url": "http://www.finlyticshub.com", "anchor_text": "me"}, {"url": "http://www.machinelearningmastery.com", "anchor_text": "Machine Learning Mastery"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4b28a71a8a80---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4b28a71a8a80---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----4b28a71a8a80---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/programming?source=post_page-----4b28a71a8a80---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----4b28a71a8a80---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=-----4b28a71a8a80---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=-----4b28a71a8a80---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4b28a71a8a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4b28a71a8a80---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4b28a71a8a80--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@asad_mumtaz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Asad Mumtaz"}, {"url": "https://medium.com/@asad_mumtaz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "457 Followers"}, {"url": "http://www.finltyicshub.com", "anchor_text": "www.finltyicshub.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f9c6741ffa5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=post_page-1f9c6741ffa5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F83025c62db23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-find-the-best-predictors-for-ml-algorithms-4b28a71a8a80&newsletterV3=1f9c6741ffa5&newsletterV3Id=83025c62db23&user=Asad+Mumtaz&userId=1f9c6741ffa5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}