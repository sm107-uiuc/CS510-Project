{"url": "https://towardsdatascience.com/reinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728", "time": 1683010149.390961, "path": "towardsdatascience.com/reinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728/", "webpage": {"metadata": {"title": "Reinforcement Learning with TensorFlow Agents \u2014 Tutorial | by Mauricio Fadel Argerich | Towards Data Science", "h1": "Reinforcement Learning with TensorFlow Agents \u2014 Tutorial", "description": "Some weeks ago, I wrote an article naming different frameworks you can use to implement Reinforcement Learning (RL) in your projects, showing the ups and downs of each of them and wondering if any of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/tensorflow/agents", "anchor_text": "TF Agents", "paragraph_index": 0}, {"url": "https://github.com/tensorflow/agents/tree/master/docs/tutorials", "anchor_text": "tutorials", "paragraph_index": 1}, {"url": "https://colab.research.google.com/drive/1Pd63OyiOnw4j401f3FN2tja4mH6EFMCc?usp=sharing", "anchor_text": "published all the code used here as a Google colab notebook", "paragraph_index": 1}, {"url": "https://github.com/tensorflow/agents", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://daiwk.github.io/assets/dqn.pdf", "anchor_text": "Mnih et al. 2015", "paragraph_index": 4}, {"url": "https://gym.openai.com/envs/#classic_control", "anchor_text": "all the available OpenAI environments", "paragraph_index": 4}, {"url": "https://github.com/tensorflow/agents/blob/master/tf_agents/environments/suite_gym.py", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf", "anchor_text": "DQN", "paragraph_index": 7}, {"url": "http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf", "anchor_text": "REINFORCE", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1509.02971.pdf", "anchor_text": "DDPG", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1802.09477.pdf", "anchor_text": "TD3", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1707.06347", "anchor_text": "PPO", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1801.01290", "anchor_text": "SAC", "paragraph_index": 7}, {"url": "https://github.com/tensorflow/agents/blob/master/tf_agents/networks/q_network.py", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://colab.research.google.com/drive/1Pd63OyiOnw4j401f3FN2tja4mH6EFMCc?usp=sharing", "anchor_text": "all the code in this article as a Google Colab notebook", "paragraph_index": 16}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/", "paragraph_index": 19}], "all_paragraphs": ["Some weeks ago, I wrote an article naming different frameworks you can use to implement Reinforcement Learning (RL) in your projects, showing the ups and downs of each of them and wondering if any of them would rule them all at some point. Since then, I\u2019ve come to know TF Agents, a library for RL based on TensorFlow and with the full support of its community (note that TF Agents is not an official Google product but it is published as a repository from the official TensorFlow account on Github).", "I am currently using TF Agents on a project and it has been easy to start with it, thanks to its good documentation including tutorials. It is updated regularly and has lots of contributors, which makes me think it is possible we will see TF Agents as the standard framework for implementing RL in the near future. Because of this, I\u2019ve decided to make this article to give you a quick introduction, so you can also benefit from this library. I have published all the code used here as a Google colab notebook, so you can easily run it online.", "You can find the Github with all the code and documentation for TF-Agents here. You won\u2019t need to clone their repository, but it\u2019s always useful to have the official Github for reference. I have implemented the following example following partially one of their tutorials (1_dqn_tutorial) but I have simplified it further and used it for playing Atari games in this article. Let\u2019s get hands on.", "As already said, TF-Agents runs on TensorFlow, more specifically TensorFlow 2.2.0. In addition you will need to install the following packages if you don\u2019t have them already:", "We will implement a DQN Agent (Mnih et al. 2015) and use it for CartPole, a classic control problem. If you would like to solve something more exciting like, say, an Atari game, you just need to change the environment name with the one you wish, choosing it from all the available OpenAI environments.", "We start by doing all of the necessary imports. As you can see below, we implement quite a few objects from TF-Agents. These are all things we can customize and switch for our implementation.", "Now, we head on to create our environment. In CartPole, we have a cart with a pole on top of it, the agent\u2019s mission is to learn to keep up the pole, moving the cart left and right. Note that we will use an e environment from suite_gym already included in TF-Agents, which is a slightly customized (and improved for its use with TF-Agents) version of OpenAI Gym environments (if you\u2019re interested, you can check the differences with OpenAI\u2019s implementation here). We will also use a wrapper for our environment called TFPyEnvironment \u2014 which converts the numpy arrays used for state observations, actions and rewards into TensorFlow tensors. When dealing with TensorFlow models, (i.e., neural networks) we use tensors, so by using this wrapper we save some effort we would need to convert these data.", "There are different agents in TF-Agents we can use: DQN, REINFORCE, DDPG, TD3, PPO and SAC. We will use DQN as said above. One of the main parameters of the agent is its Q (neural) network, which will be use to calculate the Q-values for the actions in each step. A q_network has two compulsory parameters: input_tensor_spec and action_spec defining the observation shape and the action shape. We can get this from our environment so we will define our q_network as follows:", "There are many more parameters we can customize for our q_network as you can see here, but for now, we will go with the default ones. The agent also requires an optimiser to find the values for the q_network parameter. Let\u2019s keep it classic and use Adam.", "Finally, we define and initialize our agent with the following parameters:", "We will also need some helper methods. The first one will iterate over the environment for a number of episodes, applying the policy to choose what actions to follow and return the average cumulative reward in these episodes. This will come in handy to evaluate the policy learned by our agent. Below, we also try the method in our environment for 10 episodes.", "We will also implement a method to collect data when training our agent. One of the breakthroughs of DQN was experience replay, in which we store the experiences of the agent (state, action, reward) and use it to train the Q network in batches in each step. This improves the learning by making it faster and more stable. In order to do this, TF-Agents includes the object TFUniformReplayBuffer, which stores these experiences to re-use them later, so we firstly create this object that we will need later on.", "In this method, we take an environment, a policy and a buffer, take the current time_step formed by its state observation and reward at that time_step, the action the policy chooses and then the next time_step. Then, we store this in the replay buffer. Note the replay buffer stores an object called Trajectory, so we create this object with the elements named before, and then save it to the buffer using the method add_batch.", "We can finally train our agent. We define the number of steps we will make in every iteration, after this number of steps, we will train our agent in every iteration, modifying it\u2019s policy. For now let\u2019s just use 1 step per iteration. We also define the batch size with which our Q network will be trained and an iterator so we iterate over the experienced of the agent.", "Then, we will just gather some experience for our buffer and start with the common RL loop. Get experience by acting on the environment, train policy and repeat. We additionally print the loss and evaluate the performance of the agent every 200 and 1000 steps respectively.", "We can now plot how the cumulative average reward varies as we train the agent. For this, we will use matplotlib to make a very simple plot.", "I have shared all the code in this article as a Google Colab notebook. You can directly run all the code as it is, if you would like to change it, you have to save it on your own Google drive account and then you can do whatever you like. You can also download it to run it locally on your computer, if you wish to.", "As usual, thank you for reading! Let me know in responses what you think about TF-Agents, and also if you have any question or you found any \ud83d\udc1b in the code.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist | Information Systems Engineer. Research Scientist of AI. More about me on https://www.linkedin.com/in/maufadel/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4ac7fa858728&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193----4ac7fa858728---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/tensorflow/agents", "anchor_text": "TF Agents"}, {"url": "https://github.com/tensorflow/agents/tree/master/docs/tutorials", "anchor_text": "tutorials"}, {"url": "https://colab.research.google.com/drive/1Pd63OyiOnw4j401f3FN2tja4mH6EFMCc?usp=sharing", "anchor_text": "published all the code used here as a Google colab notebook"}, {"url": "https://github.com/tensorflow/agents", "anchor_text": "here"}, {"url": "https://daiwk.github.io/assets/dqn.pdf", "anchor_text": "Mnih et al. 2015"}, {"url": "https://gym.openai.com/envs/#classic_control", "anchor_text": "all the available OpenAI environments"}, {"url": "https://github.com/jaekookang", "anchor_text": "jaekookang"}, {"url": "https://github.com/jaekookang/RL-cartpole", "anchor_text": "RL-cartpole"}, {"url": "https://github.com/tensorflow/agents/blob/master/tf_agents/environments/suite_gym.py", "anchor_text": "here"}, {"url": "https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf", "anchor_text": "DQN"}, {"url": "http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf", "anchor_text": "REINFORCE"}, {"url": "https://arxiv.org/pdf/1509.02971.pdf", "anchor_text": "DDPG"}, {"url": "https://arxiv.org/pdf/1802.09477.pdf", "anchor_text": "TD3"}, {"url": "https://arxiv.org/abs/1707.06347", "anchor_text": "PPO"}, {"url": "https://arxiv.org/abs/1801.01290", "anchor_text": "SAC"}, {"url": "https://github.com/tensorflow/agents/blob/master/tf_agents/networks/q_network.py", "anchor_text": "here"}, {"url": "https://colab.research.google.com/drive/1Pd63OyiOnw4j401f3FN2tja4mH6EFMCc?usp=sharing", "anchor_text": "all the code in this article as a Google Colab notebook"}, {"url": "https://github.com/tensorflow/agents/tree/master/docs/tutorials", "anchor_text": "tutorials included in the repository of TF-Agents on Github"}, {"url": "https://towardsdatascience.com/5-frameworks-for-reinforcement-learning-on-python-1447fede2f18", "anchor_text": "5 Frameworks for Reinforcement Learning on PythonProgramming your own Reinforcement Learning implementation from scratch can be a lot of work, but you don\u2019t need to do\u2026towardsdatascience.com"}, {"url": "https://medium.com/@mauriciofadelargerich/reinforcement-learning-environments-cff767bc241f", "anchor_text": "this other article"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----4ac7fa858728---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----4ac7fa858728---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4ac7fa858728---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----4ac7fa858728---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4ac7fa858728---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----4ac7fa858728---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=-----4ac7fa858728---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4ac7fa858728&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4ac7fa858728---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4ac7fa858728--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4ac7fa858728--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4ac7fa858728--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mauriciofadelargerich?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mauricio Fadel Argerich"}, {"url": "https://medium.com/@mauriciofadelargerich/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "298 Followers"}, {"url": "https://www.linkedin.com/in/maufadel/", "anchor_text": "https://www.linkedin.com/in/maufadel/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb3931df7d193&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=post_page-b3931df7d193--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9d5b675a4898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-with-tensorflow-agents-tutorial-4ac7fa858728&newsletterV3=b3931df7d193&newsletterV3Id=9d5b675a4898&user=Mauricio+Fadel+Argerich&userId=b3931df7d193&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}