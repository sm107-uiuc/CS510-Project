{"url": "https://towardsdatascience.com/how-to-analyze-time-series-data-with-pandas-4dea936fe012", "time": 1683017279.993186, "path": "towardsdatascience.com/how-to-analyze-time-series-data-with-pandas-4dea936fe012/", "webpage": {"metadata": {"title": "How to analyze time-series data with pandas | by Siddhartha Banerjee, PhD | Towards Data Science", "h1": "How to analyze time-series data with pandas", "description": "Time-series COVID data of confirmed infection and deaths from every single US county can be analyzed using pandas only. In this article, I will slice and dice the time-series data, plot them, compare\u2026"}, "outgoing_paragraph_urls": [{"url": "https://systems.jhu.edu/research/public-health/ncov/", "anchor_text": "Corona Virus Resource Center, John Hopkins University", "paragraph_index": 1}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter Notebook", "paragraph_index": 3}, {"url": "https://colab.research.google.com", "anchor_text": "Google Colab", "paragraph_index": 3}, {"url": "https://systems.jhu.edu/research/public-health/ncov/", "anchor_text": "Corona Virus Resource Center, John Hopkins University", "paragraph_index": 5}, {"url": "https://about.usps.com/who-we-are/postal-history/state-abbreviations.htm", "anchor_text": "USPS", "paragraph_index": 5}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 39}, {"url": "https://github.com/sidbannet", "anchor_text": "GitHub repositories", "paragraph_index": 41}], "all_paragraphs": ["\u201cLies, damned lies, and statistics\u201d \u2014 Unknown", "Time-series COVID data of confirmed infection and deaths from every single US county can be analyzed using pandas only. In this article, I will slice and dice the time-series data, plot them, compare them against each other, and present them for your interpretation. COVID data from Corona Virus Resource Center, John Hopkins University is used here for the purpose of demonstration.", "At the end of this article you will be able to get time-series statistics like nominal daily new COVID infections for all US counties, and compare COVID statistics of your county with your state and USA like the example plot shown here. I will demonstrate the use case of pandas and you can use some of these features for your own data-science projects.", "You can use any python analysis environment to follow along with this article. My favorite is Jupyter Notebook and especially that is natively available in Google Colab. You can use the freely available Colab notebook in your favorite browser and you don\u2019t need to configure anything. My favorite part is you can share your notebook with anyone you want just like you can share your Docs or Sheets in Google Drive.", "This is a very simple step to load the pandas package to your analysis environment.", "Import the COVID data from the Corona Virus Resource Center, John Hopkins University to your analysis environment. Also, get the two-letter abbreviation of US states and possessions from USPS.", "Fun fact, in 1831 Arkansas was abbreviated as Ar. T. Look at how many US states begin with A\u2019s, I\u2019s, M\u2019s, and N\u2019s and they changed Nebraska\u2019s abbreviation from NB to NE in 1969 (I wonder why did they do that?). To be clear, you don\u2019t need to abbreviate state names into two-letter for the purpose of the analysis, but I will take advantage of this to demonstrate map() function of pandas. The function read_csv() reads the data from the John Hopkins database in a pandas DataFrame in your analysis environment.", "In the DataFrame df_covid_conf we have here individual US county COVID infection data written out in individual rows. The first 11 columns in this DataFrame include county specific unique codes like UID, ISO, or FIPS as well as Combined Key. Another column field like US state (or administrative zones), county name, latitude, and longitude are also provided but they may or may not be unique to the county. For example, both Autauga and Baldwin counties belong to Alabama, but they have different unique FIPS codes. Latitude and longitude taken together will be unique to an individual county, but it is possible to have two or more counties having the same latitude or longitude. From the 12th column onwards it is date stamped cumulative confirmed COVID infection.", "Similar to the df_covid_conf we have COVID death statistics in df_covid_dead DataFrame. The only difference here is that it includes Population columns which state the number of people living in the county based on census data. I will later use the population in order to derive nominal COVID statistics like the number of infections per 100k people.", "I would only skim off those US counties with FIPS below 1000 or above 80000 and invalid population data. You may have to filter a valid dataset from larger data all the time and this is a small version of it for COVID data.", "To select counties with FIPS values greater than 1000, I use [df_covid_conf.FIPS > 1000]. Similarly [df_covid_conf.FIPS < 80000] selects only those rows with FIPS values less than 80000. Finally, to only select those counties with non-zero population data, I used [df_covid_dead.Population > 0] . You can use this technique to skim off data rows that are not valid for your analysis. But next, I used the map() method to change Province_State values from a full name like New York to its two-letter abbreviated form like NY. This is done by using {df}.map(two_letter_abbreviation), where two_letter_abbreviation is a python dict defined in the earlier section and {df} is an example DataFrame. For example, the newly defined DataFrame looks like this:", "This is the most important step. If you can organize your time-series DataFrame appropriately, then everything else becomes very simple. I will break it down into three sub-steps below.", "First I will use the drop() method to take out the columns that are not useful to the analysis. For example, I would drop off UID, Lat, Long_, and other columns because it is not needed for analysis. To do this, I will transpose with the T method and then use the drop() method. For example, this code snippet will remove UID, Lat, Lat_ and other unnecessary columns from the DataFrame us_conf. The transpose at the end makes the DataFrame structure similar to the one we started from.", "It is odd to have column names like Province_State or Admin2 floating around in your analysis environment. Personally, I like to rename them to State and County respectively. I will demonstrate the use of the rename() method like this:", "Hierarchical / Multi-level indexing is very exciting as it opens the door to some quite sophisticated data analysis and manipulation, especially for working with higher dimensional data. In essence, it enables you to store and manipulate data with an arbitrary number of dimensions in lower-dimensional data structures like Series (1d) and DataFrame (2d).", "We have a perfect use case of using hierarchical indexed DataFrame with the COVID data. For example, US State and County can be used as hierarchical indices where States are indexed as primary level and Counties are indexed as secondary level. This will allow grouping these 2d DataFrame into multiple 1d DataFrame for each individual States. I will come back to this in a later section.", "The multi-indexed time-series DataFrame shown here presents the data in a more intuitive manner. Now you can take this multi-indexed time-series and easily get a cumulative total of COVID infection or deaths for any US counties for a given date.", "Bringing together the steps mentioned in 4a, 4b, and 4c, I created two separate time-series DataFrame for confirmed cases and deaths into df_conf_ts and df_dead_ts respectively. Additionally, I organized all non-time series data like population and FIPS into a separate DataFrame df_stat.", "You can preview the last three day\u2019s worth of confirmed COVID data using:", "Preview the df_stat DataFrame and you get:", "The non-time-series DataFrame and time-series DataFrame should have exactly the same number of rows as these are made from the same dataset. It\u2019s worth checking the sizes of individual DataFrame using __len()__ function. Even better of checking the integrity of the DataFrame is to use {df_first_one}.index.equals(df_second_one). Like in this particular case:", "Finally, you are here and I promise this is where all the fun begins. Once you have the data organized well, potentially everything is possible with one line of coding. I will use pandas vectorized operations as those are both eloquent and efficient in analyzing time-series data in DataFrame. Here I will use groupby(), plot(), sum(), rolling(), mean(), diff() and transpose functions.", "First, let\u2019s get a plot of daily COVID infection in the whole of the USA. Here is your first one-liner to get a quick plot \u2192", "And you get a nice time plot of cumulative COVID infections in the USA \u2192", "Let\u2019s unpack this a little more. Using sum(axis='rows'), I summed up all the COVID infections in the US counties and the 2D multi-indexed DataFrame becomes a 1D series of infection numbers with date stamps in the index. And plot(grid=True) plots the number of all COVID infections from all US counties against dates. You can see the total number of COVID infections in the USA steadily grows and reaches 13.76 million by 12/2/2020.", "Now let\u2019s get the daily COVID infections in all of the USA and plot it against the date. Again a two-lines of code here:", "The trick here is to use the diff(periods=1) method with 1 day differencing. If you are looking at n days of infection you can replace it with diff(periods=n).", "The plot above is noisy because of substantial day-to-day variation. I am going to use rolling averaging with 7 days and superimpose it on the plot \u2192", "rolling(window=7).mean() is used to get rolling mean data and plot it with the same plotting figure. Notice that the plots produced here is a matplotlib.pyplot and ax contain all the matplotlib features.", "Now let\u2019s do some vector operations and get per county COVID statistics for", "In order to get the nominal daily infection one-line of code will be \u2192", "I used vector operation and divided daily new infection cases with the df_stat.Population and multiplied by 100,000. It was as simple as that. Notice that there is a couple of transformations done here. First I diff ed out against columns data to get daily new infection cases in every single US county. The transpose makes it vector divisible with the series DataFrame df_stat.Population, and hence the transpose operation. After the vector division is performed, I transformed it back to its original 2D data structure. Now you can plot these nominal new COVID infections in the last 2 weeks (14 days) from various US counties and compare them against one another easily. To get nominal daily deaths the operation is very similar to this except use df_dead_ts. Use your discretion on the number of days and multiplication factor (period of 14 days and per 1 million population for example).", "These time-series plots tell a meaningful chronological story in various US cities. Notice in these plots how different waves of COVID-19 affected different communities at very different times as well. For example per capita basis Madison, WI, and New York, NY were hit on early in the pandemic (March-April 2020) while you can observe a huge surge in COVID infections in Miami, FL in the second wave of infections in the summer, while New York and Madison suffered relatively less in summer. Los Angeles, CA is seeing a spike in recent days (late November 2020) like it hasn\u2019t seen in previous waves of COVID infections.", "Now instead of comparing different counties, let\u2019s compare new COVID infections per capita between counties and state and the US as a whole. To do this, I will use groupby() function that comes with DataFrame. So let\u2019s sum all COVID cases in counties and group by States only \u2192", "A very simple one-line of code gives you an aggregate of all COVID infections from counties within each US States and brings that up to a 2D DataFrame against date stamps on columns. Now you can appreciate the transform because that by itself gives you time-series of COVID infection in various states by simply add .T and the end of the expression \u2192", "This transformation gives you the power to easily enquire aggregate COVID infections in any US state to any date of your choice. For example, df_conf_groupby(\u2018State').sum()['12/2/20']['CA] right away gives you the fact that 1.265 million people have been affected with COVID in CA only till 12/2/2020. You can simply get to time-series plots of individual states with df_conf_ts.groupby('State').sum().T.plot() . It\u2019s that simple.", "Before we go, let\u2019s get the mortality rate as well. With the vectorized operation, it is again a simple one-liner \u2192", "This will give you a similar structured 2D DataFrame but with a mortality rate in % in every county in the US.", "One final plot. This will plot nominal new daily infections of Los Angeles county against states like CA, NY, TX as well as the USA \u2192", "The power of pandas is unleashed to analyze time series COVID statistics. All the code is available and can be directly opened and run in Google Colab platform.", "If you like this article, you may also like my other articles on similar topics,", "About me \u2014 I develop high-performance computation models to understand turbulence flow, multi-phase flow, and combustion flames. I apply data-science to accelerate design innovations in propulsion devices. I received a Ph.D. from the University of Wisconsin \u2014 Madison in 2011 with a major in Mechanical and Chemical Engineering and distributed minor in Mathematics, Statistics, and Computer Science. Feel free to check out my GitHub repositories and follow me on Linkedin.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Computational physicist | Propulsion scientist | Data science communicator | Author | Inventor | Introvert | Indian Classical Musician"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4dea936fe012&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@sidban", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sidban.medium.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": ""}, {"url": "https://sidban.medium.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Siddhartha Banerjee, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea0a552358c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&user=Siddhartha+Banerjee%2C+PhD&userId=ea0a552358c6&source=post_page-ea0a552358c6----4dea936fe012---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://systems.jhu.edu/research/public-health/ncov/", "anchor_text": "Corona Virus Resource Center, John Hopkins University"}, {"url": "https://jupyter.org/", "anchor_text": "Jupyter Notebook"}, {"url": "https://colab.research.google.com", "anchor_text": "Google Colab"}, {"url": "https://systems.jhu.edu/research/public-health/ncov/", "anchor_text": "Corona Virus Resource Center, John Hopkins University"}, {"url": "https://about.usps.com/who-we-are/postal-history/state-abbreviations.htm", "anchor_text": "USPS"}, {"url": "https://unsplash.com/@itookthose?utm_source=medium&utm_medium=referral", "anchor_text": "Sid Balachandran"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://towardsdatascience.com/how-to-build-plotly-choropleth-map-with-covid-data-using-pandas-in-google-colab-45951040b8e4", "anchor_text": "How to build Plotly Choropleth Map with COVID data using Pandas in Google ColabIn this project I am going to show how to build your own COVID dashboard in Google Colab using pandas and plotly.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/covid-19-trends-corona-virus-in-numbers-8725c25b636d", "anchor_text": "An open-source code to analyze COVID-19 trends \u2014 Part IA use case of GitHub and Google Colaboratory to track the spread of novel corona virus using John Hopkins University\u2019s\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/covid-19-dashboard-1910df63f14e", "anchor_text": "An open-source COVID-19 dashboard revealing the great American divideWhy region-based, data-driven decision is warranted to open the world\u2019s biggest economy\u2014 and why Decatur, IN is\u2026towardsdatascience.com"}, {"url": "https://github.com/sidbannet", "anchor_text": "GitHub repositories"}, {"url": "https://medium.com/@sidbannet/membership", "anchor_text": "Join Medium with my referral link - Siddhartha Banerjee, PhDAs a Medium member, a portion of your membership fee goes to writers you read, and you get full access to every story\u2026medium.com"}, {"url": "https://www.linkedin.com/in/sidban", "anchor_text": "Siddhartha Banerjee - Multi-dimensional &amp; Multi-physics modeling - Mainspring Energy | LinkedInAccomplished Mechanical Engineer with 13+ years experience in advanced vehicle powertrain systems. High Performance\u2026www.linkedin.com"}, {"url": "https://medium.com/tag/covid-19?source=post_page-----4dea936fe012---------------covid_19-----------------", "anchor_text": "Covid-19"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4dea936fe012---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/pandas?source=post_page-----4dea936fe012---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&user=Siddhartha+Banerjee%2C+PhD&userId=ea0a552358c6&source=-----4dea936fe012---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&user=Siddhartha+Banerjee%2C+PhD&userId=ea0a552358c6&source=-----4dea936fe012---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4dea936fe012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4dea936fe012---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4dea936fe012--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4dea936fe012--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4dea936fe012--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4dea936fe012--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4dea936fe012--------------------------------", "anchor_text": ""}, {"url": "https://sidban.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sidban.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Siddhartha Banerjee, PhD"}, {"url": "https://sidban.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "129 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fea0a552358c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&user=Siddhartha+Banerjee%2C+PhD&userId=ea0a552358c6&source=post_page-ea0a552358c6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe02ed4e40e0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-time-series-data-with-pandas-4dea936fe012&newsletterV3=ea0a552358c6&newsletterV3Id=e02ed4e40e0f&user=Siddhartha+Banerjee%2C+PhD&userId=ea0a552358c6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}