{"url": "https://towardsdatascience.com/variational-continual-learning-with-generative-replay-bfd43464d250", "time": 1683001793.7967832, "path": "towardsdatascience.com/variational-continual-learning-with-generative-replay-bfd43464d250/", "webpage": {"metadata": {"title": "Variational Continual Learning with Generative Replay | by Paul-Ambroise Duquenne | Towards Data Science", "h1": "Variational Continual Learning with Generative Replay", "description": "This blog post explains the approach presented in the paper \u201cVariational Continual Learning\u201d by Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, Richard E. Turner, published as a conference paper at ICLR\u2026"}, "outgoing_paragraph_urls": [{"url": "https://ml-research.fr/pa/", "anchor_text": "https://ml-research.fr/pa/", "paragraph_index": 32}], "all_paragraphs": ["This blog post explains the approach presented in the paper \u201cVariational Continual Learning\u201d by Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, Richard E. Turner, published as a conference paper at ICLR 2018. This paper is addressing continual learning with a bayesian approach using variational inference. In the second part, we present a new approach entitled \u201cVariational Generative Replay\u201d by Y. Gal and S. Farquhar, extending the first paper.", "1. Continual learning models are designed to learn from an incoming stream of data. The data arrives continually and the data distribution changes over time (non-stationarity). Two things may be handled for a successful continual learning:", "2. The bayesian approach is a probabilistic approach to machine learning formalizing a prior knowledge about the model parameters, and modelling distributions over weights of the model.", "Generally speaking, in machine learning, a discriminative model is defined in terms of probability as:", "With f belonging to a class of functions parameterized by \u03b8. For instance, a feed-forward neural network performing classification (softmax as last layer, \u03b8 as weights and biases).", "The classical bayesian approach models the weights by a distribution over the values the weights can take. It also uses Bayes rule to take advantage of a prior belief of the distribution of \u03b8.", "A natural idea, in the frame of continual learning, is to consider the last posterior as the best prior distribution for \u03b8 for the new task (new batch of data from a new distribution). Indeed, we notice that:", "This is a recursive formula for the posterior distributions over time. In the previous formula, we do not care about the computation of the normalization factor that is often intractable, as we are going to perform approximation of the posterior distribution. (hence the proportional sign)", "In most of cases, the posterior distribution is intractable. To overcome this issue, we may approximate the posterior distributions with simpler variational distributions", "To perform such an approximation, we consider:", "We are going to recursively approximate the posterior by a simpler distribution: given the approximation at time-step t-1, we can compute an approximation for time-step t following the previous formula. This method is called Variational Inference. We are searching for an approximate distribution (here a gaussian mean-field) defined by a set of parameters (\u03bcVI, \u03c3VI) that fits the target distribution. By fitting, we mean minimizing the difference between the 2 distributions. Typically, the Kullback-Leibler divergence is used to define the difference between two distributions.", "Therefore, to find the approximate variational posterior, we minimize the following Kullback-Leibler divergence.", "Therefore, we define the loss as:", "The KL term can be analytically computed as the Kullback-Leibler divergence between two gaussians. We can easily estimate the expected log likelihood with Monte Carlo method and the reparameterization trick:", "Therefore, a gradient of the loss function can be computed for the learnable parameters (\u03bcVI, \u03c3VI) and stochastic gradient descent can be performed.", "To refine the learning in the continual setting, we may consider a multi-head architecture. Indeed, single-head architecture are well suited for i.i.d instances or instances where only the input distribution changes overtime. The multihead architecture has the ability to take advantage of shared parameters between tasks and specific heads trained for each task.", "The recursive approximation of variational distributions may affect the model performance, and trigger catastrophic forgetting. To avoid such catastrophic forgetting, coresets are introduced: A sample of the training data is stored in a coreset (and removed from the training data), and is used to improve the posterior approximation before prediction. Different techniques may be chosen to select subsets of the training batches. Random sampling is the simplest choice. K-means clustering may be performed to keep a meaningful subset of the training data : centroids are selected to be put in the coreset. Theoritically, we notice that:", "We now focus on this new variational distribution that is only trained on non-coreset data. We can compute in a similar way a recursive formula for these variational distributions:", "In fact, in the implementation, they never remove any point from the coreset. Therefore, the formula becomes easier:", "It is interesting to notice that contrary to the theory developed here, the original implementation linked to the paper is not training on the whole coreset before doing predictions, but only on the subset of the coreset corresponding to the task tested. This is therefore a kind of last-minute training, which is not really satisfactory in the frame of Continual Learning.", "We sum up the Variational Continual Learning algorithm:", "In a previous paper, Deep Generative Replay (DGR) [Shin et al., 2017], the authors are addressing Continual Learning in a totally different way. They are training Generative Adversarial Networks (GAN) on each task to be able to use generated outputs of the GANs to make sure that the posterior fits the log likelihood of the previous tasks. This idea, called Likelihood-focused Continual Learning in the next paragraphs, can be integrated to Variational Continual Learning called Prior-focused Continual Learning (as it is focusing on the prior variational approximation). This hybrid method is called Variational Generative Replay in the recent paper written by S. Farquhar and Y. Gal, A Unifying Bayesian View of Continual Learning [2019]. Let\u2019s review the theory behind these methods:", "This is the approach developed in the paper Variational Continual Learning. This approach is focusing on transfer learning between tasks, thanks to a prior belief on weights learnt from previous tasks.", "It can be interpreted as an ensemble of models weighted with a probabilistic distribution that is regularized from a prior belief about it. The prior belief at time-step t being the posterior computed at time-step t-1.", "This is the approach developed in the paper Deep Generative Replay (DGR). This approach tries to make sure that the posterior fits the likelihood of all previously seen data, using generated data from GANs trained on previous tasks. Indeed, the idea is to fit the following intractable loss function (as we do not have direct access to the previously seen data):", "Therefore, the following approximation is done, introducing generative models pt\u2032(x,y) for previous tasks", "This approach is developed in the paper A Unifying Bayesian View of Continual Learning. It is mixing the prior-focused continual learning approach and the likelihood-focused continual learning approach:", "Basically, Variational Generative Replay replaces coresets in the implementation and is a new form of memory.", "To conclude, Variational Continual Learning with Generative Replay is a new way to approach continual learning using tools from Bayesian Deep Learning and Generative Adversarial Networks. It may be seen as a human-inspired approach, our prior knowledge built on previous tasks is used to perform new tasks. Moreover, deep generative replay is sometimes compared to dreams, when humans remind themselves of past actions to further learn. However, with this new method, the memory required grows linearly with the number of tasks which may not be satisfactory for a general continual learning model.", "S. Farquhar and Y. Gal. A Unifying Bayesian View of Continual Learning (2019).", "Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim Deep Generative Replay (DGR) (2017)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Research in Machine Learning at Uber \u2014 https://ml-research.fr/pa/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbfd43464d250&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bfd43464d250--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@duquenne.pa?source=post_page-----bfd43464d250--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duquenne.pa?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Paul-Ambroise Duquenne"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce2bebef7039&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&user=Paul-Ambroise+Duquenne&userId=ce2bebef7039&source=post_page-ce2bebef7039----bfd43464d250---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/pihey1995/VariationalContinualLearning.git", "anchor_text": "https://github.com/pihey1995/VariationalContinualLearning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bfd43464d250---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/continual-learning?source=post_page-----bfd43464d250---------------continual_learning-----------------", "anchor_text": "Continual Learning"}, {"url": "https://medium.com/tag/generative-adversarial?source=post_page-----bfd43464d250---------------generative_adversarial-----------------", "anchor_text": "Generative Adversarial"}, {"url": "https://medium.com/tag/bayesian-machine-learning?source=post_page-----bfd43464d250---------------bayesian_machine_learning-----------------", "anchor_text": "Bayesian Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----bfd43464d250---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&user=Paul-Ambroise+Duquenne&userId=ce2bebef7039&source=-----bfd43464d250---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&user=Paul-Ambroise+Duquenne&userId=ce2bebef7039&source=-----bfd43464d250---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbfd43464d250&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bfd43464d250---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bfd43464d250--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bfd43464d250--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bfd43464d250--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bfd43464d250--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bfd43464d250--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duquenne.pa?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@duquenne.pa?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Paul-Ambroise Duquenne"}, {"url": "https://medium.com/@duquenne.pa/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21 Followers"}, {"url": "https://ml-research.fr/pa/", "anchor_text": "https://ml-research.fr/pa/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce2bebef7039&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&user=Paul-Ambroise+Duquenne&userId=ce2bebef7039&source=post_page-ce2bebef7039--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fce2bebef7039%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvariational-continual-learning-with-generative-replay-bfd43464d250&user=Paul-Ambroise+Duquenne&userId=ce2bebef7039&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}