{"url": "https://towardsdatascience.com/downloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776", "time": 1683003900.351555, "path": "towardsdatascience.com/downloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776/", "webpage": {"metadata": {"title": "Downloading The Kinetics Dataset For Human Action Recognition in Deep Learning | by Mark Gituma | Towards Data Science", "h1": "Downloading The Kinetics Dataset For Human Action Recognition in Deep Learning", "description": "If you are interested in performing deep learning for human activity or action recognition, you are bound to come across the Kinetics dataset released by deep mind. There are 3 main versions of the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://deepmind.com/research/open-source/kinetics", "anchor_text": "Kinetics dataset", "paragraph_index": 0}, {"url": "https://deepmind.com/", "anchor_text": "deep mind", "paragraph_index": 0}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet", "paragraph_index": 4}, {"url": "http://kinetics-explorer.com/#/", "anchor_text": "http://kinetics-explorer.com/", "paragraph_index": 6}, {"url": "https://deepmind.com/research/open-source/kinetics", "anchor_text": "link", "paragraph_index": 9}, {"url": "https://github.com/Showmax/kinetics-downloader", "anchor_text": "showmax/kinetics-downloader", "paragraph_index": 17}, {"url": "https://github.com/dancelogue/kinetics-datasets-downloader", "anchor_text": "dancelogue/kinetics-datasets-downloader", "paragraph_index": 17}, {"url": "https://www.ffmpeg.org/", "anchor_text": "ffmpeg", "paragraph_index": 17}, {"url": "https://github.com/ytdl-org/youtube-dl", "anchor_text": "youtube-dl", "paragraph_index": 17}, {"url": "https://github.com/ytdl-org/youtube-dl", "anchor_text": "youtube-dl", "paragraph_index": 17}, {"url": "https://www.ffmpeg.org/", "anchor_text": "ffmpeg", "paragraph_index": 17}, {"url": "https://github.com/dancelogue/kinetics-datasets-downloader/blob/master/README.md", "anchor_text": "README.md", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Interquartile_range", "anchor_text": "interquartile range", "paragraph_index": 26}, {"url": "https://deepmind.com/", "anchor_text": "Deepmind", "paragraph_index": 45}, {"url": "https://deepmind.com/", "anchor_text": "Deepmind", "paragraph_index": 47}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark", "paragraph_index": 50}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark", "paragraph_index": 52}], "all_paragraphs": ["If you are interested in performing deep learning for human activity or action recognition, you are bound to come across the Kinetics dataset released by deep mind. There are 3 main versions of the dataset; Kinetics 400, Kinetics 600 and the Kinetics 700 version. Kinetics 700 is the latest version at the time of the writing of this blog.", "The Kinetics 700 dataset is described on the deep mind website as:", "A large-scale, high-quality dataset of URL links to approximately 650,000 video clips that covers 700 human action classes, including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands and hugging. Each action class has at least 600 video clips. Each clip is human annotated with a single action class and lasts around 10s.", "The URL links in the above context means YouTube URL links, therefore, the videos are YouTube videos.", "The dataset is becoming a standard for human activity recognition and is increasingly been used as a benchmark in several action recognition papers as well as a baseline for deep learning architectures designed to process video data. The main vision for the Kinetics dataset is that it become\u2019s the ImageNet equivalent of video data.", "This blog will go through the steps taken taken in downloading the videos from the annotations files as well as challenges faced and some strategies used to get around the challenges. It will highlight some basic statistics about the data which will hopefully help you make informed decisions if you choose to download it yourself. However, it won\u2019t go into too much detail about the annotations dataset e.g. how it was collected, the distribution of the different classes etc. This information can be found by reading the following papers:", "A kinetics dataset explorer was created to make it easy to visualize the data. The explorer can be found on http://kinetics-explorer.com/", "The biggest pain point when dealing with the Kinetics dataset as opposed to the ImageNet or COCO equivalents is that the actual videos are not available for download. In place, an annotations file is provided which contains a list of entries in json and csv format containing the YouTube URL links, action category and the start and end times of the action category within the video.", "The implications are that you have to download the videos yourself and crop them at the correct temporal range. There are about 650,000 videos, therefore this is not an easy task due to the various challenges we will cover later.", "The annotations file can be downloaded from the following link. Below is a screenshot of what you should see.", "Kinetics 700 is the dataset of focus for this blog. Clicking the \u201cDownload dataset\u201d link, downloads a 25 MB gzip file containing the annotation files. After extracting the contents of the gzip file, there are 3 folders which contain the train, val and test datasets in 2 file formats (csv and json). The structure of the csv file is:", "The items in the CSV file can be broken down as follows:", "The structure of the json file is as follows, which should be easy to follow from the csv context:", "The json files are much larger than the csv files, occupying 197.5 MB as opposed to 24.5 MB in memory, so might a bit faster to read data from csv as opposed to json. However, most open source software that are capable of downloading the kinetics dataset from the annotations file use the json format so might need to pre-process the csv data to the correct format. Personally I chose the JSON format due to the open source code base I ended up using.", "The data download was primarily on a desktop computer running Ubuntu 18.04 with consistent internet connection at about 60 Mb/s download speed with 16 GB of memory. However, some of the downloading occurred over my MacBook Pro when I was not using it.", "I did try to use AWS and Google Cloud however there were significant throttling issues from YouTube which will be addressed in the errors section.", "The next thing to consider is the codebase to download the data. There are two main options:", "The second option was chosen and the codebase selected was the showmax/kinetics-downloader and a fork of it was created in dancelogue/kinetics-datasets-downloader. The main requirements to use the codebase are python \u2265 3.4, ffmpeg and youtube-dl. Where youtube-dl is used to do the actual download while ffmpeg is used to crop the video at the required segment i.e. the time_start and time_end times.", "How to use the codebase is covered in the README.md file therefore we will not delve into the code. It is worth noting though that it uses the python multiprocessing module which I found to be necessary when downloading such a large dataset, and we will cover why in this blog.", "Some modifications were made based on issues encountered when downloading the dataset. The modifications to the codebase includes:", "The stats and failed logs were used to generate basic stats about the data and will hopefully help you make informed decisions if you choose to download the data yourself.", "YouTube is a dynamic platform which means videos are added and removed all the time. Therefore downloading the Kinetics dataset at different times will not have consistent results due due to videos being taken down. The following pie chart shows the downloaded and missing videos in my kinetics dataset.", "The total downloaded video count is 631604 while the failed videos is 15380, which means 2.37 % of the entire dataset could not be downloaded out of a total of 646984 videos. It is assumed this is within acceptable error margins.", "The following pie chart shows the split of the downloaded videos between the training, testing and validation set.", "As expected, majority of the videos consists of training set data, which makes up 83.94 % of the dataset. The test set makes up 10.13 % of the dataset while the validation set makes up 5.93 % of the dataset.", "In order to figure out how long it would take to download the entire dataset, the download time and the time it took to generate crop the videos (FFMPEG duration)was logged in seconds. As mentioned the stats for only 298651 videos were logged. The table below shows the mean and max of the individual processes.", "Full indicates the entire dataset while IQR indicates the data within the interquartile range. Getting the interquartile data was necessary to prevent extreme outliers as shown by the high max value for the download duration and the FFMPEG duration. The theoretical time to download 646984 videos sequentially was:", "This assumes the videos are downloaded synchronously without any interruptions. Luckily we have multiprocessing in our favour. I was running 16 separate processes using the python multiprocessing module.", "The pie chart below indicates the dominant process between download dominant and ffmpeg (cropping) dominant tasks.", "It can be seen that for most of the download process, the actual download process dominates, while the ffmpeg process dominates only 1.67 % of the time. Thus the main bottleneck in the entire process is actually downloading the videos from YouTube.", "One of the first mistakes I made when downloading the kinetics dataset was downloading videos at a higher quality than necessary (this could indicate why there were quite extreme outliers).", "Eventually I settled on videos with a max resolution of 360p, after all, these videos are meant to be consumed by machines and not people. Videos at this quality contain enough information to train the relevant deep learning algorithms, and are significantly faster to download and crop and take less space on disk during storage. It can be argued that a lower resolution could be tried as well i.e. 240p or 144p which will lead to significant space and time savings during download while maintaining the same baseline/benchmark accuracies.", "A quick calculation was conducted to figure out the space requirements and it was found that the entire cropped dataset occupied 628.43 GB on disk. In order to download the dataset you probably need about 20 GB extra (depending on number of concurrent downloads occurring) to account for the full un cropped videos which needs to be stored temporarily.", "The reasons 2.37 % of the videos failed to download were recorded and are shown in the following pie chart. The number next to the description in the legend was the total instances where the particular error occurred.", "Majority of the errors are based on YouTube\u2019s error messages and the description is an indicator of a group of errors. These are:", "Even though there were issues downloading the video, the failed videos formed only 2.37 % of the entire dataset which can be considered within acceptable error margins. However, it is worth noting though as time progresses the fraction of failed videos will increase as more videos get taken down over time.", "Even though these were the errors that prevented the videos from being downloaded, there was one error which proved to be the most frustrating experience in downloading the YouTube videos, the dreaded 429 too many requests error.", "It is by far is the biggest pain point of downloading the kinetics dataset and this is what it made me feel like for the duration of the download process.", "The primary reason for this error is caused by YouTube throttling requests which I assume is done by blacklisting the requesting ip address. It makes sense for YouTube to throttle requests where some of the reasons includes reducing the load to the server, preventing malicious parties from having access to the data etc. But it is a pain when downloading 650 000 video clips.", "What makes it especially challenging is the time it took for the requesting ip addresses to be allowed again i.e. the \u201ccooling off\u201d period. From experience it took anywhere from 12 hours to 5 days. I wasn\u2019t able to find a discernible pattern to get around it. The most amount of videos I was able to download in a single session before been throttled was 136963, the pie chart below shows the distributions between the runs (some of the runs were terminated manually as opposed to throttling).", "The throttling issues has been highlighted in different sources as a major hindrance when downloading data from YouTube.", "As far as I could tell the criteria by which an ip address is blacklisted is not clear. On my home desktop I could download over 50 000 videos before hitting the 429 error code, however moving to AWS or Google cloud I could maybe manage a 100 downloads before hitting the 429 error. Perhaps there is some criteria YouTube uses to immediately blacklist ip addresses from cloud VM vs personal machines.", "When the HTTP Error 429 was encountered it\u2019s best to stop the download and either try again at a later time or change IP addresses.", "The main viable option I was able to come up with was to change IP addresses by switching networks. Having 2 different OS (e.g. Windows and Ubuntu) on the same machine worked for sometime. If all else fails., wait for the cool off period.", "As downloading the dataset was not a huge priority at the time, when all the networking workaround options were encountering the HTTP Error 429 status, download of the dataset stopped and was attempted a few days later. I didn\u2019t explore other options such as using a VPN etc.", "One major topic that hasn\u2019t been covered so far is ethics i.e. scraping YouTube videos. On one hand the annotations file for the videos exist and was provided by Deepmind which is a subsidiary of Google, on the other hand, what are the rules in downloading the dataset especially for deep learning research. There are quite a few papers out there which make use of the data which shows that people are downloading it. It kind of feels like the head in the sand scenario is happening.", "This could possibly be the reason as to why the data has not been made publicly available, as such, anyone interested in deep learning must download it themselves. There are several issues with this approach which I believe are:", "Not sure what the workaround concerning the ethical situation can be in making the data public but hopefully Deepmind will make the video data easily accessible for non commercial use.", "Hopefully this blog has given you some insights when it comes to downloading the Kinetics dataset and the challenges faced should you attempt it yourself.", "The Kinetics dataset was necessary as I undertook a personal project for the whole of 2019 on building a Shazam for dance deep learning start-up. The Kinetics data was used to pre-train the dance algorithms as a proof of concept. I will soon be blogging about this process.", "If you have any questions or anything needs clarification, you can book a time with me on https://mbele.io/mark", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ask me anything or request a 10 minute video call on https://mbele.io/mark"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F500c3d50f776&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://markgituma.medium.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Mark Gituma"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe69ad71e0901&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&user=Mark+Gituma&userId=e69ad71e0901&source=post_page-e69ad71e0901----500c3d50f776---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://deepmind.com/research/open-source/kinetics", "anchor_text": "Kinetics dataset"}, {"url": "https://deepmind.com/", "anchor_text": "deep mind"}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet"}, {"url": "https://arxiv.org/pdf/1705.06950.pdf", "anchor_text": "https://arxiv.org/pdf/1705.06950.pdf"}, {"url": "https://arxiv.org/pdf/1907.06987.pdf", "anchor_text": "https://arxiv.org/pdf/1907.06987.pdf"}, {"url": "http://kinetics-explorer.com/#/", "anchor_text": "http://kinetics-explorer.com/"}, {"url": "https://deepmind.com/research/open-source/kinetics", "anchor_text": "link"}, {"url": "https://www.youtube.com/watch?v=", "anchor_text": "https://www.youtube.com/watch?v="}, {"url": "https://www.youtube.com/watch?v=---QUuC4vJs", "anchor_text": "video"}, {"url": "https://www.youtube.com/watch?v=---QUuC4vJs", "anchor_text": "https://www.youtube.com/watch?v=---QUuC4vJs"}, {"url": "https://www.youtube.com/watch?v=---QUuC4vJs", "anchor_text": "https://www.youtube.com/watch?v=---QUuC4vJs"}, {"url": "https://www.youtube.com/watch?v=--GkrdYZ9Tc", "anchor_text": "https://www.youtube.com/watch?v=--GkrdYZ9Tc"}, {"url": "https://github.com/Showmax/kinetics-downloader", "anchor_text": "showmax/kinetics-downloader"}, {"url": "https://github.com/dancelogue/kinetics-datasets-downloader", "anchor_text": "dancelogue/kinetics-datasets-downloader"}, {"url": "https://www.ffmpeg.org/", "anchor_text": "ffmpeg"}, {"url": "https://github.com/ytdl-org/youtube-dl", "anchor_text": "youtube-dl"}, {"url": "https://github.com/ytdl-org/youtube-dl", "anchor_text": "youtube-dl"}, {"url": "https://www.ffmpeg.org/", "anchor_text": "ffmpeg"}, {"url": "https://github.com/dancelogue/kinetics-datasets-downloader/blob/master/README.md", "anchor_text": "README.md"}, {"url": "https://en.wikipedia.org/wiki/Interquartile_range", "anchor_text": "interquartile range"}, {"url": "https://en.wikipedia.org/wiki/HTTP_404", "anchor_text": "404"}, {"url": "https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503", "anchor_text": "503"}, {"url": "https://imgflip.com/memetemplate/29364527/Luke-Skywalker-Crying", "anchor_text": "https://imgflip.com/memetemplate/29364527/Luke-Skywalker-Crying"}, {"url": "https://github.com/activitynet/ActivityNet/issues/51", "anchor_text": "https://github.com/activitynet/ActivityNet/issues/51"}, {"url": "https://github.com/activitynet/ActivityNet/issues/28", "anchor_text": "https://github.com/activitynet/ActivityNet/issues/28"}, {"url": "https://stackoverflow.com/questions/57488759/npmyoutube-dl-and-lamda-http-error-429-too-many-requests", "anchor_text": "https://stackoverflow.com/questions/57488759/npmyoutube-dl-and-lamda-http-error-429-too-many-requests"}, {"url": "https://github.com/ytdl-org/youtube-dl/issues/21729", "anchor_text": "https://github.com/ytdl-org/youtube-dl/issues/21729"}, {"url": "https://deepmind.com/", "anchor_text": "Deepmind"}, {"url": "https://deepmind.com/", "anchor_text": "Deepmind"}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----500c3d50f776---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/dataset?source=post_page-----500c3d50f776---------------dataset-----------------", "anchor_text": "Dataset"}, {"url": "https://medium.com/tag/deepmind?source=post_page-----500c3d50f776---------------deepmind-----------------", "anchor_text": "Deepmind"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&user=Mark+Gituma&userId=e69ad71e0901&source=-----500c3d50f776---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&user=Mark+Gituma&userId=e69ad71e0901&source=-----500c3d50f776---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F500c3d50f776&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----500c3d50f776---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----500c3d50f776--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----500c3d50f776--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----500c3d50f776--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----500c3d50f776--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----500c3d50f776--------------------------------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://markgituma.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mark Gituma"}, {"url": "https://markgituma.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "469 Followers"}, {"url": "https://mbele.io/mark", "anchor_text": "https://mbele.io/mark"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe69ad71e0901&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&user=Mark+Gituma&userId=e69ad71e0901&source=post_page-e69ad71e0901--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe0d223f0a4b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdownloading-the-kinetics-dataset-for-human-action-recognition-in-deep-learning-500c3d50f776&newsletterV3=e69ad71e0901&newsletterV3Id=e0d223f0a4b3&user=Mark+Gituma&userId=e69ad71e0901&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}