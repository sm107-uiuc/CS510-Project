{"url": "https://towardsdatascience.com/a-visual-primer-to-linear-regression-86adafa45e95", "time": 1683010016.361992, "path": "towardsdatascience.com/a-visual-primer-to-linear-regression-86adafa45e95/", "webpage": {"metadata": {"title": "A Visual Primer to Linear Regression | by David S. Fulford | Towards Data Science", "h1": "A Visual Primer to Linear Regression", "description": "Linear regression, or least squares regression, is the simplest application of machine learning, and arguably the most important. Many people apply the method every day without realization. Whenever\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Linear regression, or least squares regression, is the simplest application of machine learning, and arguably the most important. Many people apply the method every day without realization. Whenever you compute an arithmetic mean, we have a special case of linear regression \u2014 that is, that the best predictor of a response variable is the bias (or mean) of the response itself!", "At the core of the method of least squares lies the idea to minimize the sum of the squared \u201cerrors,\u201d that is, to adjust the unknown parameters such that the sum of the squares of the differences between observed and computed values is minimized.", "Linear regression has had quite a lot written about it on TowardsDataScience, so why author another article on it? My purpose is not to \u201cshow how it is done\u201d, but to illustrate linear regression as a convenient and practical example of a more fundamental concept \u2014 estimation \u2014 and to develop an intuition of the mechanisms for readers.", "The word \u201clinear\u201d in \u201clinear model\u201d does not refer to the individual terms of the model such as whether they are squared, or have a square root, etc. It is surprising to many to find out that predictor variables can have all kinds of non-linear transformations applied to them, and do often have applied in order to create a valid linear model. Rather, \u201clinear\u201d refers to the behavior of the model as a whole: A linear model is one in which a linear combination of the predictor variables yields a prediction of a response variable. This means that", "is a linear model, where x\u2081 could be (using some example \u201cmeasurement\u201d value from our data):", "I\u2019ve found that many people are resistant to the idea that we can manipulate our variables however we desire. But why do we accept that a linear combination of predictor variables is a valid method of making a prediction in the first place? The only rules of a least squares regression are that the residuals must have a mean of zero, be uncorrelated, and be homoscedastic (a fancy word to mean the variance of the residuals must be constant). We can do anything, and in fact must often do a lot of things, in order to satisfy these three rules!", "In order to generalize, we have to introduce some linear algebra. We can alternatively write our model in vector notation as:", "where the predictor variables are given as column vectors:", "In this form, we can begin to form a better understanding of the image of the geometric representation at the top of this article. It\u2019s quite obvious that we make a prediction as the sum of vectors X\u2081 and X\u2082, but what is \u00ea, the residual? It\u2019s the sum of all information that X\u2081 and X\u2082 do not contain, and is orthogonal to both of them! And here we have our intercept, or bias term, come into play. As we scale to higher dimensions, the concept of an \u201cintercept\u201d doesn\u2019t really make as much intuitive sense as we cannot visualize all variables on a single plot. Instead, consider this as a bias term we are adding in order to \u201cput our thumb on the scale\u201d, so to speak, to make our predictions more accurate than they would otherwise be if we just used the predictor variables. If we redraw the figure including a bias term, we get something like:", "And we see that the bias term, b, reduces the magnitude of the residual. (Note: This is not completely accurate as the residual should be orthogonal to X\u2081 and X\u2082, and b, but alas we are limited to three spatial dimensions). Of course, we are only looking at a single prediction corresponding to a single value of X\u2081 and X\u2082, whereas an actual linear model would be making a prediction for each value of X\u2081 and X\u2082. The bias term is calculated as the value that that sets the average of all residuals to zero.", "Let\u2019s go a bit further with our regression equations to illustrate just how we determine the coefficients. First, we can move from writing the model with vectors, to matrix notation. We first combine X\u2080, X\u2081 and X\u2082 into a matrix:", "And then simplify our regression equation:", "And here, since we\u2019ve discussed that the residuals are, we\u2019ve added the residual term as we know they must also be included to obtain the actual measured value of the response variable. Remember that the residuals are orthogonal to all predictor variables and the prediction of the response variable, meaning that they contain unexplained deviation that may exist in other predictor variables we do not have observations of.", "We won\u2019t go into the derivation of the solution, but if we solve for the values of \u03b2 that the equation, we obtain:", "And if you need some help with visualizing the matrix multiplication, we have:", "In the simplest case, \u2026 namely the estimation of a location parameter, \u2026 this is of course achieved by the sample mean.", "Now, let\u2019s consider a special case of linear regression, in which we only have X\u2080 \u2014 that is to say, we only have a unit column vector. This reduces the prior matrix multiplications to:", "And substituting into the regression equation, we have:", "And hopefully, you recognize this! It\u2019s saying that the best predictor of a linear model where we only have a response variable is the average of the response variable itself!", "Why is this significant? Well, this suggests that the required assumptions for least squares regression also apply to the calculation of averages. These are:", "Since we are only dealing with a single response variable, points two and three can be taken as speaking about the variable itself. If we have poor sampling such there is over-representation in a specific range of values as compared to other ranges, or if the samples are at all correlated (i.e. values are dependent upon one another), then an average is not the best estimator of a variable.", "As is now well known, if the true distribution deviates slightly from the assumed normal distribution, the sample mean may have catastrophically bad performance.", "If we invert back from averages to linear models, we can also say that least squares regression is not the best method of regression for problems that do not satisfy our rules.", "Least squares regression isn\u2019t always going to work, but there are a lot of other machine learning techniques we can try, right? Well, before we throw neural networks at a wall and see what sticks, let\u2019s consider what we can do about this shortcoming. I\u2019m not a statistician, so before I criticize much of the basis of the entire field of statistics (!), let me instead quote an actual statistician that investigated this problem back in 1964:", "It is interesting to look back at the very origin of the theory of estimation, namely to Gauss and his theory of least squares. Gauss was fully aware that his main reason for assuming an underlying normal distribution and a quadratic function was mathematical, i.e., computational, convenience. In later times, this was often forgotten, partly because of the central limit theorem. However, if one wants to be honest, the central limit theorem can at most explain why many distributions occurring in practice are approximately normal. The stress is on the word \u201capproximately.\u201d", "Huber is credited as one of the creators of the field of research of robust estimation, and is the source of the various quotes sprinkled throughout this article. His goal was to create alternative estimators to the least squares estimator that would be better able to handle outliers or other deviations from the rules of least squares estimation. As he points out, one of the primary motivations for choosing least squares among all other alternatives was for the convenience of an analytic solution. This was a BIG convenience for any period of history earlier than the late 20th century. Nowadays, however, numerical methods to solve regression problems are, to our human perception of time, often just as quick as analytic solutions. Better estimators exist.", "It is quite natural to ask whether one can obtain more robustness by minimization another function of the errors than the sum of their squares.", "Let\u2019s reduce the idea of an estimator to \u201ca measure of distance\u201d. We typically think of Euclidean distance, a\u00b2 + b\u00b2 + \u2026, but this is just one of infinite ways of measuring distance. If you were in Manhattan on the city grid, this is an almost useless measurement to determine the distance between you and that corner restaurant you\u2019re trying to reach.", "The green line, the Euclidean distance, is the shortest\u2026 but also impossible to achieve. And it turns out that the red, blue, and yellow lines, which are colloquially named \u201ctaxicab distance\u201d, are all identical in length. If you want to know how you should get somewhere based upon distance alone, a computer cannot calculate the shortest the route for you. However, this also means the solution for the shortest route is robust: It\u2019s easy to find an alternative route if something goes (in the words of Huber) catastrophically wrong. In the next article, we\u2019ll talk about these alternatives and learn about their properties, and in doing so, extend regression to handle cases of much greater complexity than least squares is capable of.", "This takes us closer to our goal of accurate estimation.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A reservoir engineer straddling the domains of physics-based workflows, data engineering, and machine learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F86adafa45e95&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----86adafa45e95--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@dsfulf?source=post_page-----86adafa45e95--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dsfulf?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "David S. Fulford"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6b03efa44f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&user=David+S.+Fulford&userId=e6b03efa44f2&source=post_page-e6b03efa44f2----86adafa45e95---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://doi.org/10.1214/aoms/1177703732", "anchor_text": "https://doi.org/10.1214/aoms/1177703732"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&user=David+S.+Fulford&userId=e6b03efa44f2&source=-----86adafa45e95---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&user=David+S.+Fulford&userId=e6b03efa44f2&source=-----86adafa45e95---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F86adafa45e95&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----86adafa45e95---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----86adafa45e95--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----86adafa45e95--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----86adafa45e95--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----86adafa45e95--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----86adafa45e95--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dsfulf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@dsfulf?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "David S. Fulford"}, {"url": "https://medium.com/@dsfulf/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "37 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe6b03efa44f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&user=David+S.+Fulford&userId=e6b03efa44f2&source=post_page-e6b03efa44f2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fe6b03efa44f2%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-visual-primer-to-linear-regression-86adafa45e95&user=David+S.+Fulford&userId=e6b03efa44f2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}