{"url": "https://towardsdatascience.com/a-comprehensive-python-implementation-of-glove-c94257c2813d", "time": 1683018772.529415, "path": "towardsdatascience.com/a-comprehensive-python-implementation-of-glove-c94257c2813d/", "webpage": {"metadata": {"title": "A Comprehensive Python Implementation of GloVe | by Peng Yan | Towards Data Science", "h1": "A Comprehensive Python Implementation of GloVe", "description": "As an NLP data scientist, I frequently read papers with topics varying from word vectors, RNNs, and transformers. Reading paper is fun, and give me the illusion that I have mastered a wide range of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/pengyan510/nlp-paper-implementation", "anchor_text": "a GitHub repository", "paragraph_index": 0}, {"url": "https://nlp.stanford.edu/pubs/glove.pdf", "anchor_text": "the original paper", "paragraph_index": 1}, {"url": "https://github.com/stanfordnlp/GloVe", "anchor_text": "released code", "paragraph_index": 2}, {"url": "https://github.com/pengyan510/nlp-paper-implementation/tree/master/glove", "anchor_text": "here", "paragraph_index": 2}, {"url": "http://mattmahoney.net/dc/textdata.html", "anchor_text": "Text8 Dataset", "paragraph_index": 3}, {"url": "https://docs.python.org/3/library/dataclasses.html", "anchor_text": "the official documentation", "paragraph_index": 13}, {"url": "https://docs.h5py.org/en/stable/", "anchor_text": "documentation", "paragraph_index": 24}, {"url": "https://github.com/pengyan510/nlp-paper-implementation/blob/master/glove/src/evaluate.py", "anchor_text": "here", "paragraph_index": 37}, {"url": "https://radimrehurek.com/gensim/models/keyedvectors.html#what-can-i-do-with-word-vectors", "anchor_text": "documentation", "paragraph_index": 37}], "all_paragraphs": ["As an NLP data scientist, I frequently read papers with topics varying from word vectors, RNNs, and transformers. Reading paper is fun, and give me the illusion that I have mastered a wide range of techniques. But when it comes to reproducing them, difficulties emerge. As far as I know, many NLP learners have run into the same situation as me. Thus I decided to start a series of posts focusing on implementing classical NLP papers. I also created a GitHub repository for this effort.", "This post is the first of this series, which reproduces the GloVe model based on the original paper. As stated before, the focus is purely on the implementation. For more information about the underlying theory, please refer to the original paper.", "According to the paper, the GloVe model was trained with a single machine. The released code was written in C, which can be somewhat unfamiliar for NLP learners. So I carried out a comprehensive Python implementation of the model, which aligns with the goal of training a huge vocabulary with only a single machine. The following sections walk through the implementation details step by step. The full code is here.", "For this project, I use the Text8 Dataset as the training data. To get it, we can use the gensim downloader:", "The dataset is a list of lists, where each sublist is a list of words representing a sentence. We only want a list of all the words, so flatten it with itertools:", "Okay, now we have the training corpus.", "When working on a machine learning model, there is always a wide range of parameters to configure, such as data file path, batch size, word embedding size, etc. These parameters can incur lots of overhead if you don\u2019t manage them well. Based on my experience, I find the best way is to store all of them in a single yaml file with the name config.yaml. In the code, also add a loading function to load configuration from the yaml file, like this:", "Then for the rest of the code, we can use the parameters as config.batch_size, config.learning_rate instead of hard coded values, which also makes the code nicer.", "And that\u2019s all the preparation work needed. Let\u2019s proceed with the actual two-step training of the GloVe model!", "For counting cooccurring pairs, we first need to determine the vocabulary. Here are some requirements for the vocabulary:", "To fulfill these requirements in a structured manner, a Vocabulary class is created. This class has four fields:", "It also defines the following methods:", "With this understanding in mind, we can now look at the code:", "For the class implementation, I make use of Python\u2019s dataclass feature. With this feature, I only need to define the fields with type annotation, and the __init__() method is automatically generated for me. I can also set default value for fields when defining them. For example, token2index is default to an empty dict by setting default_factory=dict. For more information about dataclass, please refer to the official documentation.", "Now we have the Vocabulary class, the remaining question is: how do we use it? There are basically two use cases:", "I create another class, Vectorizer, to coordinate these two use cases. It only has one field, vocab, which refers to the vocabulary created from the corpus. It has two methods:", "The full code is as below:", "Now we have the vectorizer to convert all words into indices, the remaining task is to scan all the context windows and count all possible cooccurring pairs. Since the cooccurrence matrix is sparse, it is reasonable to use a Counter to count the pairs. The key is (word i\u2019s index, word j\u2019s index), where word j appears in the context of word i. The value is a floating number representing the counts. However, two issues may occur if using this strategy.", "Issue 1: If we count all cooccurring pairs in one scan, we will likely run out of memory, as the number of distinct (word i\u2019s index, word j\u2019s index) can be enormous.", "Solution: Instead, we can count cooccurring pairs in multiple scans. In each scan, we limit word i\u2019s index to be in a small range, so that the number of distinct pairs is greatly reduced. Let\u2019s say the vocabulary has 100,000 distinct tokens. If we count all pairs in one scan, the number of distinct pairs can be as large as 10\u00b9\u2070. Instead, we can count all pairs in 10 scans. In the first scan, we limit word i\u2019s index to be in between 0 and 9999; in the second scan, we limit it to be in betweeen 10000 and 19999; in the third scan, we limit it to be in between 20000 and 29999, so on and so forth. And after each scan finishes, we save the counts to disk. Now in each scan, the number of distinct pairs can be as large as 10\u2079, which is one tenth of the original number.", "The idea behind this approach is that instead of calculating the whole cooccurrence matrix in one scan, we divide the matrix into 10 smaller rectangles and calculate them sequentially. The picture below visualizes the idea.", "This approach is scalable in the sense that as the vocabulary size increases, we can always increase the number of scans to reduce the memory usage. The main drawback is that the runtime will also increase if using a single machine. However, since there is no dependency between scans, they an be easily parallelized with Spark. But this is out of our scope.", "Also, at this point, the reason for shuffling the vocabulary can be uncovered. When we create the vocabulary with the most frequent tokens, the index of these tokens are ordered. Index 0 corresponds to the most frequent token, index 1 corresponds to the second most frequent token, so on and so forth. If we continue with the example of 100,000 tokens, in the first scan we would count pairs of the 10000 most frequent tokens, and the number of distinct pairs would be huge. While in the remaining scans, the number of distinct pairs would be much smaller. This leads to memory usage imbalance between scans. By shuffling the vocabulary, the distinct pairs are distributed evenly across scans and the memory usage is balanced.", "Issue 2: Continue from the solution to Issue 1, how do we save the counts of each scan to disk? The most obvious way is to write the (word i\u2019s index, word j\u2019s index, count) triplets into a shared text file between scans. But using this file later for training involves too much overhead.", "Solution: There is a python library, h5py, that provides Pythonic interface to the HDF5 binary format. It enables you to store huge amounts of numerical data, and easily manipulate them as if they were real NumPy arrays. For more detail about the library, check out its documentation.", "Same as before, I create a CooccurrenceEntries class that does the counting and saves the result to disk using the proposed solutions. The class has two fields:", "With the abstraction of Vocabulary, Vectorizer, CooccurrenceEntrie, the code for counting cooccurring pairs and saving to disk is simple:", "We first need to load data from the HDF5 dataset in batches. Since the data can be retrieved as if it is stored in a NumPy matrix, the easiest way is to use a PyTorch DataLoader. But then loading each batch involves many calls in the form of dataset[i], where the dataset is a h5py.Dataset instance. This involves many IO calls and can be extremely slow.", "The workaround is to load the h5py.Dataset into memory chunk by chunk. Each loaded chunk is a pure NumPy ndarray in the memory, so we can use PyTorch\u2019s Dataloader to iterate batches over it. Now the number of IO calls needed is equal to the number of chunks, which is significantly smaller.", "One drawback with this approach is that completely random shuffle is not possible, as batches containing data from different chunks will never be generated. So to get more randomness, we can load the chunks in random order, and set DataLoader\u2019s shuffle argument to be True.", "An HDF5DataLoader class is created for loading batches. It has five fields:", "The code is shown below. One thing to notice is that the CooccurrenceDataset is simply a subclass of PyTorch\u2019s Dataset for indexing the data. It is omitted as there is nothing special.", "Implementing GloVe model with PyTorch is straightforward. We define the two weight matrices and the two bias vectors in __init__(). Notice that we set sparse=True when creating the embeddings, as the gradient update is sparse by nature. In forward(), the average batch loss is returned.", "The model training follows the standard PyTorch training routine. The only difference is that instead of PyTorch\u2019s DataLoader, we use the customized HDF5Loader to generate batches. Here is the training code:", "Phew, we have walked through the full implementation. Congratulations!", "Next, let\u2019s train the model and look at the results!", "For the Text8 Dataset, training one epoch takes roughly 80 mins. I trained the model for 20 epochs and it takes more than one day to finish. The learning curve looks promising, and it seems like the loss would further decrease if the training continues.", "We can also do some word similarity task to see how the word vectors behave. Here I make use of the KeyedVectors class from gensim, which allows you to do this without writing nearest neighbor or cosine similarity code. The similarity evaluation code is here. For details about KeyedVectors, please refer to the documentation.", "Running some simple similarity task shows the following result:", "As we can see, some of them make sense, like \u201ccomputer\u201d and \u201cgame\u201d, \u201cunited\u201d and \u201cstates\u201d; and some of them not. But that\u2019s enough to make the point. Training on a larger dataset for more epochs should improve the result.", "The GloVe paper is well written and easy to follow. Yet when it comes to implementation, there are plenty of pitfalls and difficulties along the way, especially when you take memory issues into consideration. With a decent amount of effort, we end up with a satisfying solution for training on a single machine.", "As I said at the beginning, I will continue implementing more NLP papers and share my first-hand experience with you. Hope you enjoy the GloVe implementaion and see you in the next post!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc94257c2813d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mlpractitioner.medium.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": ""}, {"url": "https://mlpractitioner.medium.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Peng Yan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F90bafa597f29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&user=Peng+Yan&userId=90bafa597f29&source=post_page-90bafa597f29----c94257c2813d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@cookiethepom?utm_source=medium&utm_medium=referral", "anchor_text": "Cookie the Pom"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/pengyan510/nlp-paper-implementation", "anchor_text": "a GitHub repository"}, {"url": "https://nlp.stanford.edu/pubs/glove.pdf", "anchor_text": "the original paper"}, {"url": "https://github.com/stanfordnlp/GloVe", "anchor_text": "released code"}, {"url": "https://github.com/pengyan510/nlp-paper-implementation/tree/master/glove", "anchor_text": "here"}, {"url": "http://mattmahoney.net/dc/textdata.html", "anchor_text": "Text8 Dataset"}, {"url": "https://docs.python.org/3/library/dataclasses.html", "anchor_text": "the official documentation"}, {"url": "https://docs.h5py.org/en/stable/", "anchor_text": "documentation"}, {"url": "https://github.com/pengyan510/nlp-paper-implementation/blob/master/glove/src/evaluate.py", "anchor_text": "here"}, {"url": "https://radimrehurek.com/gensim/models/keyedvectors.html#what-can-i-do-with-word-vectors", "anchor_text": "documentation"}, {"url": "https://medium.com/tag/nlp?source=post_page-----c94257c2813d---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----c94257c2813d---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/word-embeddings?source=post_page-----c94257c2813d---------------word_embeddings-----------------", "anchor_text": "Word Embeddings"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c94257c2813d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----c94257c2813d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&user=Peng+Yan&userId=90bafa597f29&source=-----c94257c2813d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&user=Peng+Yan&userId=90bafa597f29&source=-----c94257c2813d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc94257c2813d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c94257c2813d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c94257c2813d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c94257c2813d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c94257c2813d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c94257c2813d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c94257c2813d--------------------------------", "anchor_text": ""}, {"url": "https://mlpractitioner.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mlpractitioner.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Peng Yan"}, {"url": "https://mlpractitioner.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "33 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F90bafa597f29&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&user=Peng+Yan&userId=90bafa597f29&source=post_page-90bafa597f29--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F41d0367cc93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-python-implementation-of-glove-c94257c2813d&newsletterV3=90bafa597f29&newsletterV3Id=41d0367cc93b&user=Peng+Yan&userId=90bafa597f29&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}