{"url": "https://towardsdatascience.com/in-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319", "time": 1682996702.256927, "path": "towardsdatascience.com/in-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319/", "webpage": {"metadata": {"title": "In 10 minutes: Web Scraping with Beautiful Soup and Selenium for Data Professionals | by Vincent Tatan | Towards Data Science", "h1": "In 10 minutes: Web Scraping with Beautiful Soup and Selenium for Data Professionals", "description": "Web Scraping is a process to extract valuable information from websites and online contents. It is a free method to extract information and receive datasets for further analysis. In this era where\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.mathworks.com/matlabcentral/answers/155126-how-does-the-vision-cascadeobjectdetector-detect-left-and-right-eyes-separately-it-is-constantly-de", "anchor_text": "B", "paragraph_index": 36}, {"url": "https://bit.ly/2I8jkWV.", "anchor_text": ".", "paragraph_index": 43}, {"url": "http://www.linkedin.com/in/vincenttatan/", "anchor_text": "LinkedIn", "paragraph_index": 46}, {"url": "https://medium.com/@vincentkernn", "anchor_text": "Medium", "paragraph_index": 46}, {"url": "https://www.youtube.com/user/vincelance1/videos", "anchor_text": "Youtube Channel", "paragraph_index": 46}], "all_paragraphs": ["Web Scraping is a process to extract valuable information from websites and online contents. It is a free method to extract information and receive datasets for further analysis. In this era where information is practically highly related to each other, I believe that the need for Web Scraping to extract alternative data is enormous especially for me as a data professional.", "The objective for this publication is for you to understand several ways on scraping any publicly available information using quick and dirty Python Code. Just spend 10 minutes to read this article \u2014 or even better, contribute. Then you could get a quick glimpse to code your first Web Scraping tool.", "In this article, we are going to learn how to scrape data from Wikipedia and e-commerce (Lazada). We will clean up, process, and save the data into .csv file. We will use Beautiful Soup and Selenium as our main Web Scraping Libraries.", "Beautiful Soup parses HTML into an easy machine readable tree format to extract DOM Elements quickly. It allows extraction of a certain paragraph and table elements with certain HTML ID/Class/XPATH.", "Whenever I need a quick and dirty way approach to extract information online. I will always use BS as my first approach. Usually it would take me in less than 10 minutes within 15 lines of codes to extract.", "Selenium is a tool designed to automate Web Browser. It is commonly used by Quality Assurance (QA) engineers to automate their testings Selenium Browser application.", "Additionally, it is very useful to web scrape because of these automation capabilities:", "(Github is available at the end of this article)", "Imagine you were UN ambassadors, aiming to make visits on cities all around the world to discuss about the Kyoto Protocol status on Climate Changes. You need to plan your travel, but you do not know the capital city for each of the country. Therefore, you googled and found this link on Wikipedia.", "Inside this link, there is a table which maps each country to the capital city. You find this is good, but you do not stop there. As a data scientist and UN ambassador, you want to extract the table from Wikipedia and dump it into your data application. You took up the challenge to write some scripts with Python and BeautifulSoup.", "We will leverage on the following steps:", "4. Add header and url into your requests. This will create a request into the wikipedia link. The header would be useful to spoof your request so that it looks like it comes from a legitimate browser.", "For Wikipedia, it might not matter as all the information is open sourced and publicly available. But for some other sites such as Financial Trading Site (SGX), it might block the requests which do not have legitimate headers.", "5.Initiate BS and list element to extract all the rows in the table", "6. Iterate through all of the rows in table and get through each of the cell to append it into rows and row_list", "7. Create Pandas Dataframe and export data into csv.", "Congratulations! You have become a web scraper professional in only 7 steps and within 15 lines of code", "So far BS has been really successful to web scrape for us. But I discovered there are some limitations depending on the problems:", "If we run Beautiful Soup in e commerce websites such as Lazada and Amazon, we will run to this Connection Error which is caused by their anti scraping software to deter bots from making http requests.", "One way to fix it is to use client browsers and automate our browsing behavior. We can achieve this by using Selenium.", "Imagine you were creating price fluctuation model to analyze e-Commerce providers such as Lazada and Amazon. Without Web Scraping tool, you would need to hire somebody to manually browse through numerous product pages and copy paste the pricing one by one into Excelsheet. This process would be very repetitive, especially if you\u2019d like to collect the data point every day/every hour. This would also be a very time consuming process as it involves many manual clicks and browses to duplicate the information.", "What if I tell you, you can automate this process:", "By having Selenium doing the exploration of products and clicking for you.", "By having Selenium opening your Google Chrome Browser to mimic legitimate user browsing behaviors.", "By having Selenium pump all of the information into lists and csv files for you.", "Well you\u2019re in luck, because all you need to do is write a simple Selenium script and you can now run the web scraping program while having a good night sleep.", "4. Drive Selenium Chrome Browser by inserting the executable path and url. In my case, I used the relative path to find the chromedriver.exe located in the same directory as my script.", "5.Wait page to load and find the element. This is how Selenium could be different from Requests and BS. You could instruct the page to wait until a certain DOM element is renderred. After that, it would continue running its web scraping logic.", "You can stop the wait until Expected Conditions (EC) is met to find by ID \u201cLevel_1_Category_No1\u201d. If 30 seconds already passed without finding such element, then pass TimeoutException to shut the browser.", "Congrats. We have setup Selenium to use our Chrome Browser. Now we are ready to automate the Information Extraction.", "Let us identify several attributes from our Lazada Websites and extract their DOM Elements.", "2. Get the unordered list xpath (ul) and extract the values for each list item (li). You could inspect the element, right click, and select copy>XPATH to easily generate the relevant XPATH. Feel free to open the following link for further detail.", "2. Extract the product title, pack size, price, and rating. We will open several lists to contain every item and dump them into a Dataframe.", "3. Dump the information into a Pandas Dataframe and csv", "Congrats! You have effectively expanded your skills to extract any information found online!", "The purpose for this Proof Of Concepts (POC) was created as a part of my own side project. The goal of this application is to use web scraping tool to extract any publicly available information without much cost and manpower.", "In this POC, I used Python as the scripting language, Beautiful Soup and Selenium library to extract the necessary information.", "The Github Python Code is located below.", "Feel free to clone the repository and contribute whenever you have time.", "In lieu with today\u2019s topics about python and web scraping. You could also visit another of my publication regarding web scraping for aspiring investors. You should try this walk through to guide you to code quick and dirty Python to scrape, analyze, and visualize stocks.", "Hopefully from this relevant publication, you could learn how to scrape critical information and develop an useful application. Please read and reach out to me if you like it.", "Whew\u2026 That\u2019s it, about my idea which I formulated into writings. I really hope this has been a great read for you guys. With that, I hope my idea could be a source of inspiration for you to develop and innovate.", "Please Comment out below to suggest and feedback.", "Vincent Tatan is a Data and Technology enthusiast with relevant working experiences from Visa Inc. and Lazada to implement microservice architectures, data engineering, and analytics pipeline projects.", "Vincent is a native Indonesian with a record of accomplishments in problem solving with strengths in Full Stack Development, Data Analytics, and Strategic Planning.", "He has been actively consulting SMU BI & Analytics Club, guiding aspiring data scientists and engineers from various backgrounds, and opening up his expertise for businesses to develop their products .", "Please reach out to Vincent via LinkedIn , Medium or Youtube Channel", "This disclaimer informs readers that the views, thoughts, and opinions expressed in the text belong solely to the author, and not necessarily to the author\u2019s employer, organization, committee or other group or individual. References are picked up from the list and any similarities with other works are purely coincidental", "This article was made purely as the author\u2019s side project and in no way driven by any other hidden agenda.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I fight phishing with ML @ Google. I use advanced ML algorithms and MLOps to protect Chrome, Gmail and Android users. Please reach out to me on Linkedin."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8de169d36319&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8de169d36319--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@vincentkernn?source=post_page-----8de169d36319--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vincentkernn?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Vincent Tatan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9848578f8495&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&user=Vincent+Tatan&userId=9848578f8495&source=post_page-9848578f8495----8de169d36319---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "anchor_text": "Beautiful Soup Documentation - Beautiful Soup 4.4.0 documentationBeautiful Soup 4 is published through PyPi, so if you can't install it with the system packager, you can install it\u2026www.crummy.com"}, {"url": "https://www.seleniumhq.org/", "anchor_text": "Selenium - Web Browser AutomationSelenium has the support of some of the largest browser vendors who have taken (or are taking) steps to make Selenium a\u2026www.seleniumhq.org"}, {"url": "https://en.wikipedia.org/wiki/List_of_national_capitals", "anchor_text": "List of national capitals - WikipediaThis is a list of national capitals, including capitals of territories and dependencies, non-sovereign states including\u2026en.wikipedia.org"}, {"url": "https://pypi.org/project/beautifulsoup4/", "anchor_text": "beautifulsoup"}, {"url": "http://www.amazon.com'", "anchor_text": "www.amazon.com'"}, {"url": "https://www.softwaretestinghelp.com/locate-elements-in-chrome-ie-selenium-tutorial-7/", "anchor_text": "How to Locate Elements in Chrome and IE Browsers for Building Selenium Scripts - Selenium Tutorial\u2026This is tutorial #7 in our Selenium Online Training Series. If you want to check all Selenium tutorials in this series\u2026www.softwaretestinghelp.com"}, {"url": "https://www.mathworks.com/matlabcentral/answers/155126-how-does-the-vision-cascadeobjectdetector-detect-left-and-right-eyes-separately-it-is-constantly-de", "anchor_text": "B"}, {"url": "https://github.com/VincentTatan/Web-Scraping", "anchor_text": "VincentTatan/Web-ScrapingWeb Scraping with Beautiful Soup and Selenium. Contribute to VincentTatan/Web-Scraping development by creating an\u2026github.com"}, {"url": "https://towardsdatascience.com/value-investing-dashboard-with-python-beautiful-soup-and-dash-python-43002f6a97ca", "anchor_text": "Value Investing Dashboard with Python Beautiful Soup and Dash PythonAn Overview of Web Scraping with a Quick Dash Visualization for Value Investingtowardsdatascience.com"}, {"url": "https://bit.ly/2I8jkWV.", "anchor_text": "."}, {"url": "http://www.linkedin.com/in/vincenttatan/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/@vincentkernn", "anchor_text": "Medium"}, {"url": "https://www.youtube.com/user/vincelance1/videos", "anchor_text": "Youtube Channel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&user=Vincent+Tatan&userId=9848578f8495&source=-----8de169d36319---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&user=Vincent+Tatan&userId=9848578f8495&source=-----8de169d36319---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8de169d36319--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8de169d36319&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8de169d36319---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8de169d36319--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8de169d36319--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8de169d36319--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8de169d36319--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8de169d36319--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vincentkernn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vincentkernn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vincent Tatan"}, {"url": "https://medium.com/@vincentkernn/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.9K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9848578f8495&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&user=Vincent+Tatan&userId=9848578f8495&source=post_page-9848578f8495--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fba9496ed2fd5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fin-10-minutes-web-scraping-with-beautiful-soup-and-selenium-for-data-professionals-8de169d36319&newsletterV3=9848578f8495&newsletterV3Id=ba9496ed2fd5&user=Vincent+Tatan&userId=9848578f8495&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}