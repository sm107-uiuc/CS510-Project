{"url": "https://towardsdatascience.com/how-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65", "time": 1683015627.214779, "path": "towardsdatascience.com/how-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65/", "webpage": {"metadata": {"title": "How to build a Dask distributed cluster for AutoML pipeline search with TPOT | by John Goudouras | Towards Data Science", "h1": "How to build a Dask distributed cluster for AutoML pipeline search with TPOT", "description": "An in-depth tutorial, guiding you through all the steps required to set up a scalable, automated machine learning model pipeline search with open-source python libraries, namely Dask and TPOT."}, "outgoing_paragraph_urls": [{"url": "https://dask.org/", "anchor_text": "Dask", "paragraph_index": 0}, {"url": "https://distributed.dask.org/en/latest/", "anchor_text": "library", "paragraph_index": 0}, {"url": "https://github.com/dask/dask-tutorial", "anchor_text": "Dask", "paragraph_index": 1}, {"url": "https://numpy.org/", "anchor_text": "NumPy", "paragraph_index": 1}, {"url": "https://pandas.pydata.org/", "anchor_text": "pandas", "paragraph_index": 1}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn", "paragraph_index": 1}, {"url": "https://www.vmware.com/products/esxi-and-esx.html", "anchor_text": "VMware ESXi", "paragraph_index": 5}, {"url": "https://jupyter.org/", "anchor_text": "jupyter notebook", "paragraph_index": 5}, {"url": "https://kubernetes.dask.org/en/latest/", "anchor_text": "Dask Kubernetes", "paragraph_index": 5}, {"url": "https://releases.ubuntu.com/20.04/ubuntu-20.04.1-live-server-amd64.iso", "anchor_text": "Ubuntu 20.04.1 live server", "paragraph_index": 7}, {"url": "https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/", "anchor_text": "set up swap memory", "paragraph_index": 7}, {"url": "https://docs.dask.org/en/latest/dataframe.html#dataframe", "anchor_text": "DataFrame", "paragraph_index": 8}, {"url": "https://github.com/duncs/clusterssh", "anchor_text": "ClusterSSH", "paragraph_index": 10}, {"url": "https://www.anaconda.com/", "anchor_text": "Anaconda3", "paragraph_index": 13}, {"url": "https://github.com/EpistasisLab/tpot", "anchor_text": "TPOT", "paragraph_index": 13}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch", "paragraph_index": 13}, {"url": "https://linux.die.net/man/1/screen", "anchor_text": "screen", "paragraph_index": 15}, {"url": "https://docs.dask.org/en/latest/diagnostics-distributed.html", "anchor_text": "dashboard", "paragraph_index": 17}, {"url": "https://wiki.python.org/moin/GlobalInterpreterLock", "anchor_text": "Global Interpreter Lock", "paragraph_index": 22}, {"url": "https://stackoverflow.com/questions/49406987/how-do-we-choose-nthreads-and-nprocs-per-worker-in-dask-distributed/49407253", "anchor_text": "StackOverflow", "paragraph_index": 22}, {"url": "http://epistasislab.github.io/tpot/", "anchor_text": "TPOT", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Imputation_(statistics)", "anchor_text": "imputing", "paragraph_index": 24}, {"url": "http://proceedings.mlr.press/v64/olson_tpot_2016.pdf", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://coiled.io/", "anchor_text": "coiled", "paragraph_index": 27}], "all_paragraphs": ["Were you ever in a spot where you knew you did your best cleaning and wrangling with your dataset but couldn\u2019t pick the best model? Do you have a lot of CPUs lying around but they are in separate hosts? Then this is the guide for you! We will explore Dask, in particular, Dask\u2019s distributed library to not only parallelize our TPOT pipeline searches but also distribute them across different machines.", "Dask is an Open Source parallel computing library that scales the existing Python ecosystem. It integrates well with the common data science stack; NumPy, pandas, and scikit-learn. With Dask, we can natively scale huge computations from laptops to whole clusters. We will be focusing on the latter.", "Dask.distributed: is a lightweight and open-source library for distributed computing in Python.", "Architecture: Dask.distributed is a centrally managed, distributed, dynamic task scheduler. It has three main processes:", "Steps to set up scheduler and workers:", "For this example, we will be using VMware ESXi to create 3 virtual machines in a single host machine. One will be the scheduler that will also run a jupyter notebook and the other two will be the workers. This is just a proof of concept setup. It is not, admittedly, the most efficient way to spin up cluster workers. In spite of that, this will present a more general process that can then be adapted with cloud solutions and/or Dask Kubernetes.", "We will start with the scheduler instance. First click on Create/Register VM > Create a new virtual machine > Next", "You can select any name but I would recommend assigning an easily recognizable name like cluster-master. For this example, I am using Ubuntu 20.04.1 live server on all machines. It is not mandatory but it is highly recommended to use the same distribution in all machines. The machines will be used to perform computations on large datasets\u00b9. Thus, it is also highly recommended to assign a lot of RAM to each machine, and if not possible to at least set up swap memory. For this example, we will be using 24 Gb of RAM and 8 vCPUs on each machine.", "\u00b9On this tutorial we will be using Pandas DataFrames. For particurarly large datasets we can use Dask\u2019s DataFrame object. Dask.DataFrame is a large parallel DataFrame composed of many smaller Pandas DataFrames, split along the index. These Pandas DataFrames may live on disk for larger-than-memory computing on a single machine, or on many different machines in a cluster.", "Here is a snapshot of our VM specs. You can change these according to your needs.", "Repeat the process for the worker machines. We choose the same specs but that\u2019s not mandatory. After installing the OS on each machine we will install the necessary software through\u00a0SSH. For small clusters like these, we choose ClusterSSH. ClusterSSH is a Tk/Perl wrapper around standard Linux tools like XTerm and SSH. We will use it to replicate commands to all machines simultaneously. Without further ado, let\u2019s get down to business.", "Run the following command to install ClusterSSH in your local machine. In this tutorial, we will be managing the cluster via SSH from our personal computer. We will not configure ClusterSSH. We will just connect to the machines by passing the usernames and IP addresses in the CLI. For bigger or multiple clusters, it is recommended to edit the configuration file located at ~/.csshrc.", "In the above picture, anything you type in the CLUSTERSSH grey window will be replicated across all machines. You can type individual shell commands on each of the windows separately too. We want to replicate the following commands to all machines:", "Then we will have to restart the shell, which is very simple, we can just disconnect and reconnect through ClusterSSH. If you installed Anaconda3 to a different location just export the path and run ./anaconda3/condabin/conda init. After reconnecting run the following commands to install the necessary prerequisites for TPOT and Dask. Do note that we are also installing all the optional dependencies, except PyTorch, for the extra functionalities of TPOT.", "Steps to set up the distributed cluster:", "First, we need to set up the scheduler so we can later connect the rest of the machines. Although all of these machines reside in the same host, just to cover the general case we will not connect them via LAN. Let\u2019s get started! We will use a terminal multiplexer called screen to manage multiple shells in one ssh session. Here is a quick cheat sheet of the options you will need:", "Great! Now we are ready to set up the scheduler inside a screen! Click on the master/scheduler VM instance SSH window and type the following:", "The Scheduler IP address will, of course, be different. The scheduler itself is located at the 8786 port and this is where we will be pointing all our workers. The 8787 port hosts the dask dashboard. We will get back to this later after we connect all the workers. For now, press Ctrl+a d to detach the screen. Now let\u2019s set up our jupyter notebook:", "Save the token, detach the screen and close off the SSH connection. Do not close the SSH connections to the other machines. We now have to forward the port from the remote notebook in our Master VM instance to a local port so that we can access it from our browser. We can achieve this with the following command:", "Go to your localhost on the port specified(we chose 8003), enter the token you saved, and voila! The notebook is running on the remote machine while we edit it from our local machine.", "Now we can proceed to set up all the workers to point to the scheduler. This is pretty simple. We create a screen via the grey ClusterSSH terminal, this time in all the workers, and point them to the scheduler in our master VM instance.", "Detach the screens and you\u2019re all set. The clients are connected, the scheduler is up and running and you also have a dashboard to check everything! Use the nprocs and nthreads parameters to choose the number of processes and threads per worker respectively. This choice depends on the workload. Dask\u2019s main contributor Matthew Rocklin recommends the following:", "Using few processes and many threads per process is good if you are doing mostly numeric workloads, such as are common in Numpy, Pandas, and Scikit-Learn code, which is not affected by Python\u2019s Global Interpreter Lock (GIL). However, if you are spending most of your compute time manipulating Pure Python objects like strings or dictionaries then you may want to avoid GIL issues by having more processes with fewer threads each. Using more processes avoids GIL issues, but adds costs due to inter-process communication. You would want to avoid many processes if your computations require a lot of inter-worker communication. source: MRocklin - StackOverflow", "TPOT is a Python Automated Machine Learning (AutoML) tool that optimizes machine learning pipelines using genetic programming. TPOT is built on the scikit-learn library and just like Dask, it uses existing Python APIs and data structures. This means its usage should be pretty intuitive for scikit-learn users. It also integrates quite nicely with Dask!", "TPOT uses an evolutionary algorithm to find the best pipeline. But what is a pipeline? In machine learning projects you seldom have the ideal format of data to create a performant model. There are many transformations you can perform such as imputing, feature scaling and normalization or categorical variables encoding\u2014 which in and of itself has more than one way of being implemented, i.e. one-hot or target encoding. Then you could create an ensemble by bagging, boosting or stacking models. The final model will use a combination of some or all of the above. This is called a pipeline. TPOT tries out various pipelines, and lets them \u201crandomly mutate\u201d, just like living organisms do (or viruses and extrachromosomal DNA if you want to be pedantic about it) until it finds a better performing one. You can read the full TPOT paper here.", "Finally, let\u2019s use our cluster to find the best pipeline for a dataset. The following notebook is taken mostly from the docs, with some slight changes.", "While TPOT is running, you can check the dashboard at localhost:8787 of your scheduler. If you are not in the remote scheduler, you can check it at IP-of-scheduler:8787 from your local machine. The dashboard provides things like insights on the progress of each generation, a basic system monitor of the workers and the whole cluster, the logs and Call Stacks of each worker, and a very, very cool graph. Here is what the dask dashboard should look like when running:", "Closing off, I would like to mention that the main contributors of Dask founded a company called coiled providing cloud and enterprise solutions for managed Dask clusters and python scaling in general. They are currently in beta and offer up to 100 free CPUs in the cloud to demo their platform.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist Intern at University Housing B.V. Data Science, Machine Learning and Mathematics enthusiast. BSc, Math major, CS minor, Computational Math minor."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F34ab6cf6bf65&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@johngoudouras?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johngoudouras?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "John Goudouras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F12363bbabca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&user=John+Goudouras&userId=12363bbabca8&source=post_page-12363bbabca8----34ab6cf6bf65---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://unsplash.com/@fabioha?utm_source=medium&utm_medium=referral", "anchor_text": "fabio"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://dask.org/", "anchor_text": "Dask"}, {"url": "https://distributed.dask.org/en/latest/", "anchor_text": "library"}, {"url": "https://github.com/dask/dask-tutorial", "anchor_text": "Dask"}, {"url": "https://numpy.org/", "anchor_text": "NumPy"}, {"url": "https://pandas.pydata.org/", "anchor_text": "pandas"}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn"}, {"url": "https://www.vmware.com/products/esxi-and-esx.html", "anchor_text": "VMware ESXi"}, {"url": "https://jupyter.org/", "anchor_text": "jupyter notebook"}, {"url": "https://kubernetes.dask.org/en/latest/", "anchor_text": "Dask Kubernetes"}, {"url": "https://releases.ubuntu.com/20.04/ubuntu-20.04.1-live-server-amd64.iso", "anchor_text": "Ubuntu 20.04.1 live server"}, {"url": "https://linuxize.com/post/how-to-add-swap-space-on-ubuntu-18-04/", "anchor_text": "set up swap memory"}, {"url": "https://docs.dask.org/en/latest/dataframe.html#dataframe", "anchor_text": "DataFrame"}, {"url": "https://github.com/duncs/clusterssh", "anchor_text": "ClusterSSH"}, {"url": "https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh", "anchor_text": "https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh"}, {"url": "https://www.anaconda.com/", "anchor_text": "Anaconda3"}, {"url": "https://github.com/EpistasisLab/tpot", "anchor_text": "TPOT"}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch"}, {"url": "https://linux.die.net/man/1/screen", "anchor_text": "screen"}, {"url": "https://docs.dask.org/en/latest/diagnostics-distributed.html", "anchor_text": "dashboard"}, {"url": "https://wiki.python.org/moin/GlobalInterpreterLock", "anchor_text": "Global Interpreter Lock"}, {"url": "https://stackoverflow.com/questions/49406987/how-do-we-choose-nthreads-and-nprocs-per-worker-in-dask-distributed/49407253", "anchor_text": "StackOverflow"}, {"url": "http://epistasislab.github.io/tpot/", "anchor_text": "TPOT"}, {"url": "http://epistasislab.github.io/tpot/", "anchor_text": "Docs"}, {"url": "https://en.wikipedia.org/wiki/Imputation_(statistics)", "anchor_text": "imputing"}, {"url": "http://proceedings.mlr.press/v64/olson_tpot_2016.pdf", "anchor_text": "here"}, {"url": "http://epistasislab.github.io/tpot/", "anchor_text": "Docs"}, {"url": "https://coiled.io/", "anchor_text": "coiled"}, {"url": "https://medium.com/tag/automl?source=post_page-----34ab6cf6bf65---------------automl-----------------", "anchor_text": "Automl"}, {"url": "https://medium.com/tag/dask?source=post_page-----34ab6cf6bf65---------------dask-----------------", "anchor_text": "Dask"}, {"url": "https://medium.com/tag/tpot?source=post_page-----34ab6cf6bf65---------------tpot-----------------", "anchor_text": "Tpot"}, {"url": "https://medium.com/tag/distributed-systems?source=post_page-----34ab6cf6bf65---------------distributed_systems-----------------", "anchor_text": "Distributed Systems"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----34ab6cf6bf65---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&user=John+Goudouras&userId=12363bbabca8&source=-----34ab6cf6bf65---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&user=John+Goudouras&userId=12363bbabca8&source=-----34ab6cf6bf65---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F34ab6cf6bf65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----34ab6cf6bf65---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----34ab6cf6bf65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johngoudouras?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johngoudouras?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "John Goudouras"}, {"url": "https://medium.com/@johngoudouras/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "15 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F12363bbabca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&user=John+Goudouras&userId=12363bbabca8&source=post_page-12363bbabca8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F12363bbabca8%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-a-dask-distributed-cluster-for-automl-pipeline-search-with-tpot-34ab6cf6bf65&user=John+Goudouras&userId=12363bbabca8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}