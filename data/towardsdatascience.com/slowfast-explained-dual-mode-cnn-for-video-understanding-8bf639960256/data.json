{"url": "https://towardsdatascience.com/slowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256", "time": 1682994398.875903, "path": "towardsdatascience.com/slowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256/", "webpage": {"metadata": {"title": "SlowFast Explained: Dual-mode CNN for Video Understanding | by Rani Horev | Towards Data Science", "h1": "SlowFast Explained: Dual-mode CNN for Video Understanding", "description": "Detecting objects in images and categorizing them is one of the more well-known Computer Vision tasks, popularized by the 2010 ImageNet dataset and challenge. While much progress has been achieved on\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1812.03982.pdf", "anchor_text": "paper", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1506.01497.pdf", "anchor_text": "Faster R-CNN", "paragraph_index": 11}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "mAP", "paragraph_index": 11}, {"url": "https://www.lyrn.ai", "anchor_text": "LyrnAI", "paragraph_index": 17}], "all_paragraphs": ["Detecting objects in images and categorizing them is one of the more well-known Computer Vision tasks, popularized by the 2010 ImageNet dataset and challenge. While much progress has been achieved on ImageNet, a still vexing task is video understanding \u2014 analyzing a video segment and explaining what\u2019s happening inside of it. Despite some recent progress on solving video understanding, contemporary algorithms are still far from human-level results.", "A new paper from Facebook AI Research, SlowFast, presents a novel method to analyze the contents of a video segment, achieving state-of-the-art results on two popular video understanding benchmarks \u2014 Kinetics-400 and AVA. At the heart of the method is the use of two parallel convolution neural networks (CNNs) on the same video segment \u2014 a Slow pathway and a Fast pathway.", "The authors observe that frames in video scenes usually contain two distinct parts \u2014 static areas in the frame which don\u2019t change at all or change slowly, and dynamic areas which indicate something important that is currently going on. For instance, a video of a plane lifting off will include a relatively static airport with a dynamic object (the plane) moving quickly in the scene. In an everyday scenario of two people meeting, the handshake is usually fast and dynamic while the rest of the scene is static.", "Accordingly, SlowFast uses a slow, high-definition CNN (Fast pathway) to analyze the static content of a video while running in parallel a fast, low-definition CNN (Slow pathway) whose goal is to analyze the dynamic content of a video. The technique is partially inspired by the retinal ganglion in primates, in which 80% of the cells (P-cells) operate at low temporal frequency and recognize fine details, and ~20% of the cells (M-cells) operate at high temporal frequency and are responsive to swift changes. Similarly, in SlowFast the compute cost of the Slow pathway is 4x larger than that of the Fast pathway.", "Both the Slow and Fast pathways use a 3D ResNet model, capturing several frames at once and running 3D convolution operations on them.", "The Slow pathway uses a large temporal stride (i.e. number of frames skipped per second) \u03c4, typically set at 16, allowing for approximately 2 sampled frames per second. The Fast pathway uses a much smaller temporal stride \u03c4/\u03b1, with \u03b1 typically set at 8, allowing for 15 frames per second. The Fast pathway is kept lightweight by using a significantly smaller channel size (i.e. convolution width; number of filters used), typically set at \u215b of the Slow channel size. The channel size of the Fast pathway is marked as \u03b2. The consequence of the smaller channel size is that the Fast pathway requires 4x less compute than the Slow pathway despite having a higher temporal frequency.", "Lateral ConnectionsAs shown in the visual illustration, data from the Fast pathway is fed into the Slow pathway via lateral connections throughout the network, allowing the Slow pathway to become aware of the results from the Fast pathway. The shape of a single data sample is different between the two pathways (Fast is {\u03b1T, S\u00b2, \u03b2C} while Slow is {T, S\u00b2, \u03b1\u03b2C}), requiring SlowFast to perform data transformation on the results of the Fast pathway, which is then fused into the Slow pathway by summation or concatenation.", "The paper suggests three techniques for data transformation, with the third one proving in practice to be the most effective:", "Interestingly, the researchers found that bidirectional lateral connections, i.e. also feeding the Slow pathway into the Fast pathway, do not improve performance.", "Combining the pathwaysAt the end of each pathway, SlowFast performs Global Average Pooling, a standard operation intended to reduce dimensionality. It then concatenates the results of the two pathways and inserts the concatenated result into a fully connected classification layer which uses Softmax to classify which action is taking place in the image.", "SlowFast was tested on two major datasets \u2014 Kinetics-400, created by DeepMind, and AVA, created by Google. While both datasets include annotations for video scenes, they differ slightly:", "For AVA testing, the SlowFast researchers first used a version of the Faster R-CNN object detection algorithm, combined with an off-the-shelf person detector, providing a set of regions-of-interest. They then pre-trained the SlowFast network on the Kinetics dataset, and finally ran it on the regions-of-interest. The result was 28.3 mAP (median average precision) a dramatic improvement on the AVA state-of-the-art of 21.9 mAP. It\u2019s worth noting that the compared results also pre-trained on Kinetics-400 and Kinetics-600, providing no special advantage to SlowFast vs previous results.", "Interestingly, the paper compares the results of the Slow-only and Fast-only networks to the combined network. In Kinetics-400, Slow-only achieves a top-1 result of 72.6% and a 90.3% top-5 score while Fast-only achieves a top-1 result of 51.7% and a top-5 result of 78.5%.", "This shows that despite both pathways achieving significantly below state-of-the-art scores, the combination of Slow and Fast pathways allows for increased insight into the occurrence on screen. Similar results were observed on the AVA dataset.", "SlowFast is lighter in compute compared to standard ResNet implementations, requiring 20.9 GFLOPs to reach convergence in the Slow network and 4.9 GFLOPs in the Fast network, compared to 28.1 to 44.9 GFLOPs in common 3D ResNet-50 baselines on the same dataset.", "SlowFast is implemented in PyTorch and will be open-sourced.", "SlowFast presents a novel and interesting approach to video understanding, taking advantage of the intuitive structure of real-world scenes and getting some inspiration from biological mechanisms. The paper shows that further optimizations of the model, such as using a deeper ResNet or applying additional established Computer Vision techniques, can achieve even better results and further our ability to use software to understand real-world situations.", "To stay updated with the latest Deep Learning research, subscribe to my newsletter on LyrnAI", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Learn something new every day. Currently Deep Learning :)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8bf639960256&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8bf639960256--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ranihorev?source=post_page-----8bf639960256--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Rani Horev"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8----8bf639960256---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/pdf/1812.03982.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1812.03982.pdf", "anchor_text": "SlowFast"}, {"url": "https://arxiv.org/pdf/1812.03982.pdf", "anchor_text": "SlowFast"}, {"url": "https://arxiv.org/pdf/1812.03982.pdf", "anchor_text": "SlowFast"}, {"url": "https://arxiv.org/abs/1506.01497.pdf", "anchor_text": "Faster R-CNN"}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "mAP"}, {"url": "https://www.lyrn.ai", "anchor_text": "LyrnAI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8bf639960256---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/lyrnai?source=post_page-----8bf639960256---------------lyrnai-----------------", "anchor_text": "Lyrnai"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8bf639960256---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----8bf639960256---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&user=Rani+Horev&userId=53f9e9fdd8d8&source=-----8bf639960256---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8bf639960256--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8bf639960256&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8bf639960256---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8bf639960256--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8bf639960256--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8bf639960256--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8bf639960256--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8bf639960256--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ranihorev?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rani Horev"}, {"url": "https://medium.com/@ranihorev/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.7K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F53f9e9fdd8d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&user=Rani+Horev&userId=53f9e9fdd8d8&source=post_page-53f9e9fdd8d8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9bc3579798b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslowfast-explained-dual-mode-cnn-for-video-understanding-8bf639960256&newsletterV3=53f9e9fdd8d8&newsletterV3Id=9bc3579798b7&user=Rani+Horev&userId=53f9e9fdd8d8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}