{"url": "https://towardsdatascience.com/assumptions-of-linear-regression-5d87c347140", "time": 1683012092.129463, "path": "towardsdatascience.com/assumptions-of-linear-regression-5d87c347140/", "webpage": {"metadata": {"title": "Assumptions of Linear Regression. And how to test them using Python. | by Sachin Date | Towards Data Science", "h1": "Assumptions of Linear Regression", "description": "The four assumptions of the Linear Regression Model, how to test them, and what happens when are violated."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/the-intuition-behind-correlation-62ca11a3c4a", "anchor_text": "The Intuition Behind Correlation", "paragraph_index": 21}, {"url": "https://patsy.readthedocs.io/en/latest/quickstart.html", "anchor_text": "using the Patsy", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression analysis", "paragraph_index": 46}, {"url": "https://towardsdatascience.com/testing-for-normality-using-skewness-and-kurtosis-afd61be860", "anchor_text": "Testing for Normality using Skewness and Kurtosis", "paragraph_index": 72}, {"url": "https://towardsdatascience.com/when-your-regression-models-errors-contain-two-peaks-13d835686ca", "anchor_text": "When Your Regression Model\u2019s Errors Contain Two Peaks", "paragraph_index": 73}, {"url": "https://towardsdatascience.com/3-conditionals-every-data-scientist-should-know-1916d48b078a", "anchor_text": "Three Conditionals Every Data Scientist Should Know:", "paragraph_index": 79}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression analysis", "paragraph_index": 81}, {"url": "https://towardsdatascience.com/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f", "anchor_text": "Heteroscedasticity is nothing to be afraid of", "paragraph_index": 96}, {"url": "https://towardsdatascience.com/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f", "anchor_text": "Robust Linear Regression Models for Nonlinear, Heteroscedastic Data", "paragraph_index": 97}, {"url": "https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant", "anchor_text": "UCI Machine Learning Repository", "paragraph_index": 101}, {"url": "https://timeseriesreasoning.medium.com", "anchor_text": "follow me", "paragraph_index": 102}], "all_paragraphs": ["Linear Regression is the bicycle of regression models. It\u2019s simple yet incredibly useful. It can be used in a variety of domains. It has a nice closed formed solution, which makes model training a super-fast non-iterative process.", "A Linear Regression model\u2019s performance characteristics are well understood and backed by decades of rigorous research. The model\u2019s predictions are easy to understand, easy to explain and easy to defend.", "If there only one regression model that you have time to learn inside-out, it should be the Linear Regression model.", "If your data satisfies the assumptions that the Linear Regression model, specifically the Ordinary Least Squares Regression (OLSR) model makes, in most cases you need look no further.", "Which brings us to the following four assumptions that the OLSR model makes:", "Let\u2019s look at the four assumptions in detail and how to test them.", "Linearity requires little explanation. After all, if you have chosen to do Linear Regression, you are assuming that the underlying data exhibits linear relationships, specifically the following linear relationship:", "Where y is the dependent variable vector, X is the matrix of explanatory variables which includes the intercept, \u03b2 is the vector of regression coefficients and \u03f5 is the vector of error terms i.e. the portion of y that X is unable to explain.", "How to test the linearity assumption using Python", "This can be done in two ways:", "Note that Pearson\u2019s \u2018r\u2019 should be used only when the the relation between y and X is known to be linear.", "Let\u2019s test the linearity assumption on the following data set of 9568 observations of 4 operating parameters of a combined cycle power plant taken over 6 years:", "The explanatory variables x_j are as the following 4 power plant parameters:", "Ambient_Temp in CelsiusExhaust_Volume in column height of Mercury in centimetersAmbient_Pressure in millibars of MercuryRelative_Humidity expressed as a percentage", "The response variable y is Power_Output of the power plant in MW.", "Let\u2019s load the data set into a Pandas DataFrame.", "Plot the scatter plots of each explanatory variable against the response variable Power_Output.", "Here is a collage of the four plots:", "You can see that Ambient_Temp and Exhaust_Volume seem to be most linearly related to the power plant\u2019s Power_Output, followed by Ambient_Pressure and Relative_Humidity in that order.", "Let\u2019s also print out the Pearson\u2019s \u2018r\u2019:", "We get the following output, which backs up our visual intuition:", "Related read: The Intuition Behind Correlation, for an in-depth explanation of the Pearson\u2019s correlation coefficient.", "The second assumption that one makes while fitting OLSR models is that the residual errors left over from fitting the model to the data are independent, identically distributed random variables.", "We break this assumption into three parts:", "After we train a Linear Regression model on a data set, if we run the training data through the same model, the model will generate predictions. Let\u2019s call them y_pred. For each predicted value y_pred in the vector y_pred, there is a corresponding actual value y from the response variable vector y. The difference (y \u2014 y_pred) is the residual error \u2018\u03b5\u2019. There are as many of these \u03b5 as the number of rows in the training set and together they form the residual errors vector \u03b5.", "Each residual error \u03b5 is a random variable. To understand why, recollect that our training set (y_train, X_train) is just a sample of n values drawn from some very large population of values.", "If we had drawn a different sample (y_train\u2019, X_train\u2019) from the same population, the model would have fitted somewhat differently on this second sample, thereby producing a different set of predictions y_pred\u2019, and therefore a different set of residual errors \u03b5 = (y\u2019 \u2014 y_pred\u2019).", "A third training sample drawn from the population would have, after training the model on it, generated a third set of residual errors \u03b5 = (y\u2019\u2019 \u2014 y_pred\u2019\u2019), and so on.", "One can now see how each residual error in the vector \u03b5 can take a random value from as many set of values as the number of sample training data sets one is willing to train the model on, thereby making each residual error \u03b5 a random variable.", "Why do residual errors need to be independent?", "Two random variables are independent if the probability of one of them taking up some value doesn\u2019t depend on what value the other variable has taken. When you roll a die twice, the probability of its coming up as one, two,\u2026,six in the second throw does not depend on the value it came up on the first throw. So the two throws are independent random variables that can each take a value of 1 thru 6 independent of the other throw.", "In the context of regression, we have seen why the residual errors of the regression model are random variables. If the residual errors are not independent, they will likely demonstrate some sort of a pattern (which is not always obvious to the naked eye). There is information in this pattern that the regression model wasn\u2019t able to capture during its training on the training set, thereby making the model sub-optimal.", "If the residual errors aren\u2019t independent, it may mean a number of things:", "How to test for independence of residual errors?", "It\u2019s not easy to verify independence. But sometimes one can detect patterns in the plot of residual errors versus the predicted values or the plot of residual errors versus actual values.", "Another common technique is to use the Dubin-Watson test which measures the degree of correlation of each residual error with the \u2018previous\u2019 residual error. This is known as lag-1 auto-correlation and it is a useful technique to find out if residual errors of a time series regression model are independent.", "Let\u2019s fit a linear regression model to the Power Plant data and inspect the residual errors of regression.", "We\u2019ll start by creating the model expression using the Patsy library as follows:", "In the above model expression, we are telling Patsy that Power_Output is the response variable while Ambient_Temp, Exhaust_Volume, Ambient_Pressure and Relative_Humidity are the explanatory variables. Patsy will add the regression intercept by default.", "We\u2019ll use patsy to carve out the y and X matrices as follows:", "Let\u2019s also carve out the train and test data sets. The training data set will be 80% of the size of the overall (y, X) and the rest will be the testing data set:", "Finally, build and train an Ordinary Least Squares Regression Model on the training data and print the model summary:", "Next, let\u2019s get the predictions of the model on test data set and get its predictions:", "Let\u2019s calculate the residual errors of regression \u03b5 = (y_test \u2014 y_pred):", "Finally, let\u2019s plot resid against the predicted value y_pred=prediction_summary_frame[\u2018mean\u2019]:", "One can see that the residuals are more or less pattern-less for smaller values of Power Output, but they seem to be showing a linear pattern at the higher end of the Power Output scale. It indicates that the model\u2019s predictions at the higher end of the power output scale are less reliable than at the lower end of the scale.", "What identically distributed means is that residual error \u03b5_i corresponding to the prediction for each data row, has the same probability distribution. If the distribution of errors is not identical, one cannot reliably use tests of significance such as the F-test for regression analysis or perform confidence interval testing on the predictions. Many of these tests depend on the residual errors being identically, and normally distributed. This brings us to the next assumption.", "In the previous section, we saw how and why the residual errors of the regression are assumed to be independent, identically distributed (i.i.d.) random variables. Assumption 3 imposes an additional constraint. The errors should all have a normal distribution with a mean of zero. In statistical language:", "This notation is read as follows:", "For all i in the data set of length n rows, the ith residual error of regression is a random variable that is normally distributed (that\u2019s why the N() notation). This distribution has a mean of zero and a variance of \u03c3\u00b2. Furthermore, all \u03b5_i have the same variance \u03c3\u00b2, i.e. they are identically distributed.", "It is a common misconception that linear regression models require the explanatory variables and the response variable to be normally distributed.", "More often than not, x_j and y will not even be identically distributed, leave alone normally distributed.", "In Linear Regression, Normality is required only from the residual errors of the regression.", "In fact, normality of residual errors is not even strictly required. Nothing will go horribly wrong with your regression model if the residual errors ate not normally distributed. Normality is only a desirable property.", "What\u2019s normally is telling you is that most of the prediction errors from your model are zero or close to zero and large errors are much less frequent than the small errors.", "If the residual errors of regression are not N(0, \u03c3\u00b2), then statistical tests of significance that depend on the errors having an N(0, \u03c3\u00b2) distribution, simply stop working.", "A special case of non-normality: bimodally distributed residual errors", "Sometimes, one finds that the model\u2019s residual errors have a bimodal distribution i.e. they have two peaks. This may point to a badly specified model or a crucial explanatory variable that is missing from the model.", "For example, consider the following situation:", "Your dependent variable is a binary variable such as Won (encoded as 1.0) or Lost (encoded as 0.0). But your linear regression model is giong to generate predictions on the continuous real number scale. If the model generates most of its predictions along a narrow range of this scale around 0.5, for e.g. 0.55, 0.58, 0.6, 0.61, etc. the regression errors will peak either on one side of zero (when the true value is 0), or on the other side of zero (when the true value is 1). This is a sign that your model is not able to decide whether the output should be 1 or 0, so it\u2019s predicting a value that is around the average of 1 and 0.", "This can happen if you are missing a key binary variable, known as an indicator variable, which influences the output value in the following way:", "When the variable\u2019s value is 0, the output ranges within a certain range, say close to 0.", "When the variable\u2019s value is 1, the output takes on a whole new range of values that are not there in the earlier range, say around 1.0.", "If this variable is missing in your model, the predicted value will average out between the two ranges, leading to two peaks in the regression errors. Once this variable is added, the model is well specified, and it will correctly differentiate between the two possible ranges of the explanatory variable.", "There are number of tests of normality available. The easiest way to check for normality is to measure the Skewness and the Kurtosis of the distribution of residual errors.", "The Skewness of a perfectly normal distribution is 0 and its kurtosis is 3.0.", "Any departures, positive or negative from these values indicates a departure from normality. It is of course impossible to get a perfectly normal distribution. Some departure from normality is expected. But how much is a \u2018little\u2019 departure? How to judge if the departure is significant?", "Whether the departure is significant is answered by statistical tests of normality such as the Jarque Bera Test and the Omnibus Test. A p-value of \u2264 0.05 on these tests indicates that the distribution is normal at a confidence level of \u2265 95%.", "Let\u2019s run the Jarque-Bera normality test on the linear regression model that we have trained on the Power Plant data set. Recollect that the residual errors were stored in the variable resid and they were obtained by running the model on the test data and by subtracting the predicted value y_pred from the observed value y_test.", "The skewness of the residual errors is -0.23 and their Kurtosis is 5.38. The Jarque-Bera test has yielded a p-value that is < 0.01 and thus it has judged them to be respectively different than 0.0 and 3.0 at a greater than 99% confidence level thereby implying that the residuals of the linear regression model are for all practical purposes not normally distributed.", "Let\u2019s plot the frequency distribution of the residual errors:", "We get the following histogram showing us that the residual errors do seem to be normally distributed (but the JB has shown that they are in fact not so):", "Related read: Testing for Normality using Skewness and Kurtosis, for an in-depth explanation of Normality and statistical tests of normality.", "Related read: When Your Regression Model\u2019s Errors Contain Two Peaks: A Python tutorial on dealing with bimodal residuals.", "In the previous section we saw why the residual errors should be N(0, \u03c3\u00b2) distributed, i.e. normally distributed with mean zero and variance \u03c3\u00b2. In this section we impose an additional constraint on them: the variance \u03c3\u00b2 should be constant. Particularly, \u03c3\u00b2 should not be a function of the response variable y, and thereby indirectly the explanatory variables X.", "The property of a data set to have constant variance is called homoscedasticity. And it\u2019s opposite, where the variance is a function of explanatory variables X is called heteroscedasticity.", "Here is an illustration of a data set showing homoscedastic variance:", "And here\u2019s one that displays a heteroscedastic variance:", "While talking about homoscedastistic or heteroscedastic variances, we always consider the conditional variance: Var(y|X=x_i), or Var(\u03b5|X=x_i). This is read as variance of y or variance of residual errors \u03b5 for a certain value of X=x_i.", "Related read:Three Conditionals Every Data Scientist Should Know: Conditional expectation, conditional probability & conditional variance: practical insights for regression modelers", "The immediate consequence of residual errors having a variance that is a function of y (and so X) is that the residual errors are no longer identically distributed. The variance of \u03b5 for each X=x_i will be different, thereby leading to non-identical probability distributions for each \u03b5_i in \u03b5.", "We have seen that if the residual errors are not identically distributed, we cannot use tests of significance such as the F-test for regression analysis or perform confidence interval checking on the regression model\u2019s coefficients or the model\u2019s predictions. Many of these tests depend on the residual errors being independent, identically distributed random variables.", "Heteroscedastic errors frequently occur when a linear model is fitted to data in which the fluctuation in the response variable y is some function of the current value y, for e.g. it is a percentage of the current value of y. Such data sets commonly occur in the monetary domain. An example is where the absolute amount of variation in a company\u2019s stock price is proportional to the current stock price. Another example is of seasonal variations in the sales of some product being proportional to the sales level.", "Heteroscedasticity can also be introduced by errors in the data gathering process. For example, if the measuring instrument introduces a noise in the measured value that is proportional to the measured value, the measurements will contain heteroscedastic variance.", "Another reason heteroscedasticity is introduced in the model\u2019s errors is by simply using the wrong kind of model for the data set or by leaving out important explanatory variables.", "There are three main approaches to dealing with heteroscedastic errors:", "There are several tests of homoscedasticity available. Here are a few:", "Testing for heteroscedastic variance using Python", "Let\u2019s test the model\u2019s residual errors for heteroscedastic variance by using the White test. We\u2019ll use the errors from the linear model we built earlier for predicting the power plant\u2019s output.", "The White test for heteroscedasticity uses the following line of reasoning to detect heteroscedatsicity:", "Let\u2019s run the White test on the residual errors that we got earlier from running the fitted Power Plant Output model on the test data set. These residual errors are stored in the variable resid.", "You can see that the F-test for regression has returned a p-value of 2.25e-06 which is much smaller than even 0.01.", "So with 99% confidence, we can say that the auxiliary model used by the White test was able to explain a meaningful relationship between the residual errors residof the primary model and the primary model\u2019s explanatory variables (in this case X_test).", "So we reject the null hypothesis of the F-test that the residuals errors of the Power Plant Output model are homoscedastic and accept the alternate hypothesis that the residual errors of the model are heteroscedastic.", "Recollect that we had seen the following linear pattern of sorts in the plot of residual errors versus the predicted value y_pred:", "From this plot, we should have expected the residual errors of our linear model to be heteroscedastic. The White test just confirmed this expectation!", "Related Read: Heteroscedasticity is nothing to be afraid of for an in-depth look at Heteroscedasticity and its consequences.", "Further reading: Robust Linear Regression Models for Nonlinear, Heteroscedastic Data: A step-by-step tutorial in Python", "The Ordinary Least Squares regression model (a.k.a. the linear regression model) is a simple and powerful model that can be used on many real world data sets.", "The OLSR model is based on strong theoretical foundations. It\u2019s predictions are explainable and defensible.", "To get the most out of an OLSR model, we need to make and verify the following four assumptions:", "Combined Cycle Power Plant Data Set: downloaded from UCI Machine Learning Repository used under the following citation requests:", "Thanks for reading! If you liked this article, please follow me to receive tips, how-tos and programming advice on regression and time series analysis.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "In-depth explanations of regression and time series models. Get the intuition behind the equations."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5d87c347140&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://timeseriesreasoning.medium.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": ""}, {"url": "https://timeseriesreasoning.medium.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Sachin Date"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb75b5b1730f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&user=Sachin+Date&userId=b75b5b1730f3&source=post_page-b75b5b1730f3----5d87c347140---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant", "anchor_text": "UCI Machine Learning Repository"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://towardsdatascience.com/the-intuition-behind-correlation-62ca11a3c4a", "anchor_text": "The Intuition Behind Correlation"}, {"url": "https://patsy.readthedocs.io/en/latest/quickstart.html", "anchor_text": "using the Patsy"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression analysis"}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression analysis"}, {"url": "https://en.wikipedia.org/wiki/Confidence_interval#Significance_of_t-tables_and_z-tables", "anchor_text": "t-values and confidence intervals"}, {"url": "https://towardsdatascience.com/when-your-regression-models-errors-contain-two-peaks-13d835686ca", "anchor_text": "When Your Regression Model\u2019s Errors Contain Two Peaks"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://towardsdatascience.com/testing-for-normality-using-skewness-and-kurtosis-afd61be860", "anchor_text": "Testing for Normality using Skewness and Kurtosis"}, {"url": "https://towardsdatascience.com/when-your-regression-models-errors-contain-two-peaks-13d835686ca", "anchor_text": "When Your Regression Model\u2019s Errors Contain Two Peaks"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://towardsdatascience.com/3-conditionals-every-data-scientist-should-know-1916d48b078a", "anchor_text": "Three Conditionals Every Data Scientist Should Know:"}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression analysis"}, {"url": "https://en.wikipedia.org/wiki/Park_test", "anchor_text": "The Park test"}, {"url": "https://en.wikipedia.org/wiki/Glejser_test", "anchor_text": "The Glejser test"}, {"url": "https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test", "anchor_text": "The Breusch\u2013Pagan test"}, {"url": "https://en.wikipedia.org/wiki/White_test", "anchor_text": "The White test"}, {"url": "https://en.wikipedia.org/wiki/Goldfeld%E2%80%93Quandt_test", "anchor_text": "The Goldfeld\u2013Quandt tes"}, {"url": "https://towardsdatascience.com/fisher-test-for-regression-analysis-1e1687867259", "anchor_text": "F-test for regression"}, {"url": "https://sachin-date.medium.com/", "anchor_text": "Author"}, {"url": "https://towardsdatascience.com/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f", "anchor_text": "Heteroscedasticity is nothing to be afraid of"}, {"url": "https://towardsdatascience.com/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f", "anchor_text": "Robust Linear Regression Models for Nonlinear, Heteroscedastic Data"}, {"url": "https://towardsdatascience.com/robust-linear-regression-models-for-nonlinear-heteroscedastic-data-14b1a87c1952", "anchor_text": "Robust Linear Regression Models for Nonlinear, Heteroscedastic DataA step-by-step tutorial in Pythontowardsdatascience.com"}, {"url": "https://towardsdatascience.com/the-intuition-behind-correlation-62ca11a3c4a", "anchor_text": "The Intuition Behind CorrelationWhat does it really mean for two variables to be correlated? We\u2019ll answer that question in this article. We\u2019ll also\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f", "anchor_text": "Heteroscedasticity is nothing to be afraid ofCauses, effects, tests, and solutions using Pythontowardsdatascience.com"}, {"url": "https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant", "anchor_text": "UCI Machine Learning Repository"}, {"url": "http://dx.doi.org/10.1016/j.ijepes.2014.02.027", "anchor_text": "[Web Link],"}, {"url": "http://www.sciencedirect.com/science/article/pii/S0142061514000908", "anchor_text": "[Web Link]"}, {"url": "https://timeseriesreasoning.medium.com", "anchor_text": "follow me"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5d87c347140---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----5d87c347140---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/programming?source=post_page-----5d87c347140---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----5d87c347140---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/residual?source=post_page-----5d87c347140---------------residual-----------------", "anchor_text": "Residual"}, {"url": "https://creativecommons.org/licenses/by-sa/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&user=Sachin+Date&userId=b75b5b1730f3&source=-----5d87c347140---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&user=Sachin+Date&userId=b75b5b1730f3&source=-----5d87c347140---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5d87c347140&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5d87c347140---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5d87c347140--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5d87c347140--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5d87c347140--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5d87c347140--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5d87c347140--------------------------------", "anchor_text": ""}, {"url": "https://timeseriesreasoning.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://timeseriesreasoning.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sachin Date"}, {"url": "https://timeseriesreasoning.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb75b5b1730f3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&user=Sachin+Date&userId=b75b5b1730f3&source=post_page-b75b5b1730f3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fab0c6502600b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fassumptions-of-linear-regression-5d87c347140&newsletterV3=b75b5b1730f3&newsletterV3Id=ab0c6502600b&user=Sachin+Date&userId=b75b5b1730f3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.amazon.com/dp/1508496129", "anchor_text": "An Illustrated Guide to Mobile Technology2015"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}