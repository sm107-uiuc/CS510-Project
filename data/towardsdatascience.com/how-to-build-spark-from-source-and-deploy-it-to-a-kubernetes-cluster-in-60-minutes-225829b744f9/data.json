{"url": "https://towardsdatascience.com/how-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9", "time": 1683004978.016762, "path": "towardsdatascience.com/how-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9/", "webpage": {"metadata": {"title": "How to build Spark from source and deploy it to a Kubernetes cluster in 60 minutes | by Nikolay Dimolarov | Towards Data Science", "h1": "How to build Spark from source and deploy it to a Kubernetes cluster in 60 minutes", "description": "In my last article I explained the broad strokes of the Hadoop ecosystem and you can read about it here. What is important about that article is the end, which I will blatantly plagiarise from my\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/making-big-moves-in-big-data-with-hadoop-hive-parquet-hue-and-docker-320a52ca175", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://techcrunch.com/2019/01/03/cloudera-and-hortonworks-finalize-their-merger/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAFdWl96BCgH521hvgxIYTl5hVRxsg-B6Nj6_q5C9nY3_SVtz7qmGHpnGmuLxoZhv7_OXLaYSmtuQlD2BcGGKqyaT_Vz_mgfpTaE7JZZ241vBM43dLmYQsoSiqK8lidE-92bDNI69PaxqA1Z6tnjx-kUAGfvrD9zL3Bvt6j4uufAo", "anchor_text": "merged around a year ago", "paragraph_index": 1}, {"url": "https://github.com/apache/spark", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/latest/running-on-kubernetes.html", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://issues.apache.org/jira/browse/SPARK-31165", "anchor_text": "this issue", "paragraph_index": 9}, {"url": "https://www.dimolarov.com/", "anchor_text": "https://www.dimolarov.com/", "paragraph_index": 29}], "all_paragraphs": ["In my last article I explained the broad strokes of the Hadoop ecosystem and you can read about it here. What is important about that article is the end, which I will blatantly plagiarise from my other article as it serves as the beginning of this one too:", "Now, if you have been sort of listening in on Hadoop\u2019s ecosystem over the last few years you would have seen that the two biggest players on the market \u2014 Cloudera and Hortonworks \u2014 merged around a year ago amid a slow down of the Hadoop big data market. Add the fact that people seem way more interested in Kubernetes than in older Hadoop specific technologies like YARN for resource management and orchestration, the fast adoption of DL frameworks like PyTorch and you sort of have a perfect storm forming for the ageing Hadoop stack. Nonetheless projects like Apache Spark are chugging along by e.g. introducing Kubernetes as an alternative to YARN. Exciting times for the ecosystem!", "The goal of this article is to show you what some of the cool kids are doing in 2020 in the Big Data ecosystem; which is trying to cram stuff into Kubernetes (which is a good thing!). More specifically using Spark\u2019s experimental implementation of a native Spark Driver and Executor where Kubernetes is the resource manager (instead of e.g. YARN)", "\u2026 and let us do this in 60 minutes:", "If it is that simple why do we need this article?! Read along to find out how this took me days to figure out the first time around.", "Disclaimer: your mileage on the 60 minutes might vary but it is really doable under the assumption that you generally know how do the things on a computer including setting up a local k8s cluster and running bash scripts and the likes. Furthermore, building Spark might take a while if you have a slowish computer ;)", "Now that everyone is on board, let\u2019s deploy Spark on Kubernetes. For this you can use your laptop\u2019s run of the mill minikube setup instead of renting a server in a public cloud just for this exercise. Unless you want to go all in on this, in which case you have just been saluted.", "Steps 1\u20133 (clone repo, build Spark, build Docker image):", "This is actually where the fun starts \u2014 on the \u201ceasiest\u201d steps. Well, put on your seatbelt and check this out (pun intended):", "If you clone the official Spark repository here and innocently follow the official Spark guide on running Spark in k8s here, you will run into this issue that I opened in Spark\u2019s Jira backlog a few days ago.", "Namely, that there are multiple wrong references in the Dockerfile and because of that simply running a docker build command as described in the Dockerfile comments will not work.", "Update: Well, it turns out that you can in fact run things as described in the documentation but only if you pay really close attention.", "which creates a Spark distribution instead of just the normal assembly bits and pieces but I guess I skipped on the fine-print in their tutorial, so I updated this article accordingly.", "tl;dr to complete steps 1\u20133 simply do this:", "At this point you should have an image of Spark in your local Docker registry!", "Step 4: Run Spark Pi job with multiple executor replicas in Kubernetes:", "What the Spark article I linked above mentions but does not quite explain as a showstopper is the fact that due to Kubernetes\u2019 RBAC (role-based access control), you cannot simply deploy Spark into your cluster as Spark needs some additional rights to your Kubernetes cluster to manage pods. This is due to Spark\u2019s architecture \u2014 you deploy a Spark Driver, which can then create the Spark Executors in pods and then clean them up once the job is done:", "tl;dr we need to create a service account with kubectl for Spark:", "Next up is to run Spark Pi with our locally built Docker image:", "Ok, but what is actually happening here. Well, this is how you deploy your Spark Driver into your Kubernetes cluster! Let us go through the parameters, so you can actually start working with this on your own afterwards:", "Should now return a list of the running pods! And do not worry when they get terminated in the end \u2014 that is the default setting for this implementation.", "Step 5: Use port forwarding to show Spark UI", "Then you should be able to access the Spark UI with the localhost:4040 from the first command from above in your browser like so:", "You can also check out your logs like this:", "Doing this exact setup with the config and the Dockerfile can be either super straightforward if you know Spark and Kubernetes really well or a little bit of a nightmare if you do not. I hope that this will help you to do this in minutes instead!", "Where do you go from here? Anywhere you want. The goal of this article was to quickly get you up and running with a new fancy resource manager for Spark. I suggest you play around with this setup with other Spark apps as the next steps \u2014 I might just write an article on some more complicated examples in the future (let me know if I should).", "This is an update from 20th April 2020 \u2014 one can also use Google\u2019s native Kubernetes operator, which seems very promising and can remove the manual deployment steps into your cluster:", "It is currently being used by e.g. Salesforce and Microsoft in production and is being evaluated for production by Uber and Lyft. Something to look out for in the future!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I solve problems with software. I am a CTO, software engineer and product guy. https://www.dimolarov.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F225829b744f9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----225829b744f9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nikolaydimolarov?source=post_page-----225829b744f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nikolaydimolarov?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Nikolay Dimolarov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc95ce91e6201&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&user=Nikolay+Dimolarov&userId=c95ce91e6201&source=post_page-c95ce91e6201----225829b744f9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://commons.wikimedia.org/wiki/File:Apache_Spark_logo.svg,", "anchor_text": "Spark Logo"}, {"url": "https://en.wikipedia.org/wiki/Kubernetes", "anchor_text": "k8s Logo"}, {"url": "https://emojipedia.org/unicorn/", "anchor_text": "Emoji"}, {"url": "https://towardsdatascience.com/making-big-moves-in-big-data-with-hadoop-hive-parquet-hue-and-docker-320a52ca175", "anchor_text": "here"}, {"url": "https://techcrunch.com/2019/01/03/cloudera-and-hortonworks-finalize-their-merger/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAFdWl96BCgH521hvgxIYTl5hVRxsg-B6Nj6_q5C9nY3_SVtz7qmGHpnGmuLxoZhv7_OXLaYSmtuQlD2BcGGKqyaT_Vz_mgfpTaE7JZZ241vBM43dLmYQsoSiqK8lidE-92bDNI69PaxqA1Z6tnjx-kUAGfvrD9zL3Bvt6j4uufAo", "anchor_text": "merged around a year ago"}, {"url": "https://github.com/apache/spark", "anchor_text": "here"}, {"url": "https://spark.apache.org/docs/latest/running-on-kubernetes.html", "anchor_text": "here"}, {"url": "https://issues.apache.org/jira/browse/SPARK-31165", "anchor_text": "this issue"}, {"url": "https://spark.apache.org/docs/latest/running-on-kubernetes.html", "anchor_text": "documentation"}, {"url": "https://github.com/GoogleCloudPlatform/spark-on-k8s-operator", "anchor_text": "GoogleCloudPlatform/spark-on-k8s-operatorThis is not an officially supported Google product. If you are currently using the v1beta1 version of the APIs in your\u2026github.com"}, {"url": "https://medium.com/tag/spark?source=post_page-----225829b744f9---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/kubernetes?source=post_page-----225829b744f9---------------kubernetes-----------------", "anchor_text": "Kubernetes"}, {"url": "https://medium.com/tag/docker?source=post_page-----225829b744f9---------------docker-----------------", "anchor_text": "Docker"}, {"url": "https://medium.com/tag/big-data?source=post_page-----225829b744f9---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/hadoop?source=post_page-----225829b744f9---------------hadoop-----------------", "anchor_text": "Hadoop"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&user=Nikolay+Dimolarov&userId=c95ce91e6201&source=-----225829b744f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&user=Nikolay+Dimolarov&userId=c95ce91e6201&source=-----225829b744f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----225829b744f9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F225829b744f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----225829b744f9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----225829b744f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----225829b744f9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----225829b744f9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----225829b744f9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----225829b744f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nikolaydimolarov?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nikolaydimolarov?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nikolay Dimolarov"}, {"url": "https://medium.com/@nikolaydimolarov/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "159 Followers"}, {"url": "https://www.dimolarov.com/", "anchor_text": "https://www.dimolarov.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc95ce91e6201&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&user=Nikolay+Dimolarov&userId=c95ce91e6201&source=post_page-c95ce91e6201--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff5762ed32e7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9&newsletterV3=c95ce91e6201&newsletterV3Id=f5762ed32e7&user=Nikolay+Dimolarov&userId=c95ce91e6201&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}