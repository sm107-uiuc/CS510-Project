{"url": "https://towardsdatascience.com/solving-ais-cassandra-problem-8edb1bc29876", "time": 1683013707.554469, "path": "towardsdatascience.com/solving-ais-cassandra-problem-8edb1bc29876/", "webpage": {"metadata": {"title": "Solving AI\u2019s Cassandra Problem. Use Explainable AI to Persuade Your\u2026 | by Alon Bochman | Towards Data Science", "h1": "Solving AI\u2019s Cassandra Problem", "description": "The AI community has a serious problem: 87% of our projects never make it to production. If another field had that kind of failure rate, we might not call it science at all. What exactly are we\u2026"}, "outgoing_paragraph_urls": [{"url": "https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/", "anchor_text": "87% of our projects never make it to production", "paragraph_index": 0}, {"url": "https://hostingtribunal.com/blog/big-data-stats/#:~:text=The%20amount%20of%20data%20created,that's%2044%20trillion%20gigabytes)!", "anchor_text": "1.7 MB", "paragraph_index": 1}, {"url": "https://arxiv.org/list/cs.AI/pastweek?skip=0&show=25", "anchor_text": "31", "paragraph_index": 2}, {"url": "https://outsideinsight.com/insights/global-ai-investment-150-billion-2025/", "anchor_text": "\u00a3150 billion by 2025", "paragraph_index": 3}, {"url": "https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf", "anchor_text": "doubling every 3.4 months", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Cassandra", "anchor_text": "Cassandra", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "anchor_text": "Explainable AI", "paragraph_index": 6}, {"url": "https://www.amazon.com/Start-Why-Leaders-Inspire-Everyone/dp/1591846447", "anchor_text": "at the expense of the why", "paragraph_index": 7}, {"url": "https://www.kaggle.com/c/home-credit-default-risk", "anchor_text": "Kaggle Home Credit", "paragraph_index": 8}, {"url": "https://blog.dataiku.com/tree-based-models-how-they-work-in-plain-english#:~:text=Tree%2Dbased%20models%20use%20a,classification%20(predicting%20categorical%20values).", "anchor_text": "tree-based", "paragraph_index": 8}, {"url": "https://www.genpact.com/digital-transformation/artificial-intelligence-ai", "anchor_text": "Genpact", "paragraph_index": 9}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP", "paragraph_index": 22}, {"url": "https://www.actuaries.digital/2019/06/18/analytics-snippet-feature-importance-and-the-shap-approach-to-machine-learning-models/", "anchor_text": "SHAP order is more accurate", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Violin_plot#:~:text=A%20violin%20plot%20is%20a,by%20a%20kernel%20density%20estimator.", "anchor_text": "violin", "paragraph_index": 27}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable ML Book by Chris Molnar (WIP)", "paragraph_index": 88}, {"url": "https://www.uxai.design/design-strategy", "anchor_text": "UXAI", "paragraph_index": 89}, {"url": "https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/", "anchor_text": "Microsoft", "paragraph_index": 89}, {"url": "https://medium.com/@tonyxu_71807/ensuring-fairness-and-explainability-in-credit-default-risk-modeling-shap-ibm-tool-kit-aix-360-bfc519c191bf", "anchor_text": "Ensuring fairness and explainability in credit default risk modeling", "paragraph_index": 90}], "all_paragraphs": ["The AI community has a serious problem: 87% of our projects never make it to production. If another field had that kind of failure rate, we might not call it science at all. What exactly are we missing?", "\u00b7 We are not short on data: We generate 1.7 MB per person per second in 2020", "\u00b7 We are not short on theoretical advances: 31 new AI papers were published on Arxiv just today", "\u00b7 We are not short on investment: It\u2019s expected to top \u00a3150 billion by 2025", "\u00b7 We are not short on performance: AI compute performance has been doubling every 3.4 months", "What we are short on is trust. Modern AI/ML techniques such as deep learning and tree-based methods can deliver great accuracy but are also harder to interpret than older regression-based methods. Our model might tell the future with perfect accuracy, but if the experts we serve see it as a black box, it will not make it beyond the lab. If end users don\u2019t trust our model, they will ignore it, just as the ancient Greeks ignored Cassandra\u2019s accurate prophesies.", "Explainable AI (XAI) is a set of technologies that seek to make complex models understandable and trustworthy. Interest has been growing rapidly over the past two years:", "You can find lots of articles introducing XAI. I\u2019ve included some of my favorites in the footnotes below. However, they mostly focus on the how at the expense of the why, and are light on realistic data and domain expertise.", "This article will illustrate how XAI fits into the AI/ML workflow with a case study: A credit model I developed as part of the Kaggle Home Credit competition. The training dataset consists of 397,511 loan applications from prospective borrowers. The model seeks to predict which borrowers will default. It was built with LightGBM, a tree-based algorithm.", "In our consulting practice at Genpact, we see three major XAI uses cases. Let\u2019s go through each one.", "A model developer would like to use XAI to", "\u00b7 Eliminate features that do not add much value, making the model lighter, faster to train and less likely to overfit", "\u00b7 Ensure the model is relying on features that make sense from a domain perspective. For example, we don\u2019t want the model to use the borrower\u2019s first name to predict loan defaults", "Most tree-based libraries include a basic feature importance report that can help with these tasks. Here it is for our credit model:", "How should we read this chart?", "\u00b7 The most important features are on top", "\u00b7 Feature importance is defined by how frequently it is used by the model\u2019s trees (by split) or by how much signal it adds (by gain)", "\u00b7 The most important feature is NEW_EXT_SOURCES_MEAN. This represents the borrower\u2019s credit score, similar to a FICO score in the US. Technically, it is the average of three scores from external credit bureaus", "\u00b7 The average credit score is more important than any of the individual scores (EXT_SOURCE_1, 2, 3)", "\u00b7 The second most important feature is the applicant\u2019s age, DAYS_BIRTH, etc.", "\u00b7 We can use this to improve model performance. For example, we see all three credit scores are important (EXT_SOURCE 1, 2, and 3) but the mean is the most important. Therefore, there is some difference between scores that the model is trying to learn. We can make that explicit by engineering features for that difference, e.g. EXT_SOURCE_1 \u2014 EXT_SOURCE_2.", "\u00b7 We can use this to validate model logic, to a limited degree. For example, are we comfortable relying on the borrower age this much? This is hard to answer because we still don\u2019t know just how the model is using borrower age.", "Compare this against a similar report generated by an XAI package called SHAP:", "Both charts show the model\u2019s most \u201cimportant\u201d features on top, though they don\u2019t quite agree on the order. Many believe the SHAP order is more accurate. In any event, the SHAP chart provides a lot more detail.", "How should we read this chart?", "Let\u2019s zoom in on the top feature:", "\u00b7 Top-Down Position: This is the feature that \u201cmoves the needle\u201d the most for the model\u2019s output. It is the most impactful.", "\u00b7 Color: To the right of the feature label, we see a violin-shaped dot plot. Each dot represents a borrower in our dataset. Blue dots represent borrowers with low credit scores (risky). Red dots are high credit scores (safe). The same blue-red scale applies to all quantitative features.", "\u00b7 Left-Right Position: Dots to the left of the center-line represent borrowers whose credit scores decrease the model output, i.e. reduce the predicted probability of default. Dots to the right are those for whom the credit score increases the model output.", "\u00b7 The dots on the left are mostly red, meaning that high credit scores (red) tend to decrease the probability of default (left).", "\u00b7 We can use this to debug the model. For example, if one of the credit bureaus reported a score where high values are risky and low values safe, or if we had mixed up the probability of default with the probability of repayment, this chart would show the problem and allow us to fix it. This happens more often than one might think.", "Let\u2019s zoom in further on that last point. Here is a chart that shows how credit scores affect the predicted probability of default.", "How should we read this chart?", "\u00b7 As before, each dot represents a borrower.", "\u00b7 The horizontal axis is the credit score, scaled from zero to one.", "\u00b7 The vertical axis is not the predicted probability of default, but the contribution of the credit score to that probability. It is scaled as log-odds rather than probability units, same as the raw output from our logistic model. See footnotes for the formula to convert log-odds to probability.", "\u00b7 This scatterplot slopes from top left to the bottom right because low credit scores (left) increase the predicted probability of default (top) and high credit scores (right) decrease it (bottom).", "\u00b7 If our model was linear, the dots would slope down in a perfect line.", "\u00b7 We see a thicker scatterplot instead because our model includes feature interactions. The same credit score (vertical line) can affect two borrowers differently, depending on the value of another feature.", "Let\u2019s add some interaction data to the chart:", "How should we read this chart?", "\u00b7 Note that the axes haven\u2019t changed, and the dots haven\u2019t moved.", "\u00b7 We have only added a color scale based on a second (interaction) feature, NEW_CREDIT_TO_ANNUITY_RATIO. This is the ratio between the requested loan amount and the annual loan payment. The lower that ratio (blue) the safer the loan is considered because it should take less time to pay off.", "\u00b7 Unfortunately, the color doesn\u2019t tell us much: the blue and red dots seem randomly dispersed. This means there is no clear interaction between the two features we plotted. However, consider the following interaction plot:", "How should we read this chart?", "\u00b7 The color scale represents the same feature as before, but now we\u2019ve switched the horizontal axis from credit score to the borrower\u2019s age, expressed as the number of days from today counting back to their birth, hence a negative number.", "\u00b7 The vertical axis, shows the impact of the borrower\u2019s age on the predicted default probability, expressed as log-odds.", "What is this chart telling us?", "\u00b7 The big picture is that older borrowers are generally safer (lower) than younger borrowers. This is true up until you hit age 65 or so (-23,000 days). Past that age, there is a wide dispersion. Senior citizen credit quality is all over the place, but the new credit to annuity ratio plays a big role, the lower the better.", "\u00b7 More subtly: Something interesting happens around age 45 (-16,250 days). For borrowers younger than 45 (right), blue dots are generally higher than red dots. In credit terms, younger borrowers asking for short term loans (low credit to annual payment = blue) are riskier. For older borrowers (left), the relationship is reversed, with long term loans becoming riskier.", "\u00b7 I\u2019m not sure why the Home Credit dataset exhibits this pattern. It might be the result of a lending policy, a product characteristic or it could be accidental. If this were a real credit model, I would discuss this pattern with a domain expert (an underwriter in this case).", "\u00b7 If we determined the pattern had a basis in credit fundamentals, I would engineer some features so the model could to take advantage of it. For example, one such feature might be abs(age \u2014 45 years).", "As mentioned earlier, one of the biggest reasons ML models don\u2019t make it out of the lab and into production is that end users do not trust them. Suppose our end user, a loan officer, is running our model on a single borrower (borrower #4 in our dataset). The model predicts this borrower is 94.9% likely to default. Very risky. Before denying the application, the loan officer would like to know why the model dislikes this borrower so much. Using XAI, we can decompose the prediction into its components. There are several ways to visualize these components. My favorite is the decision plot, also from the SHAP package:", "How should we read this chart?", "\u00b7 In this plot, we show the impact of the top 20 most important features on the model\u2019s prediction for borrower #4.", "\u00b7 The prediction is the red line. The model\u2019s output is where the line meets the color band at the top of the chart, 94.9% likely to default.", "\u00b7 Features that mark the borrower as riskier-than-average move the line to the right. Features that mark the borrower as safer-than-average move the line to the left.", "\u00b7 Feature values for borrower #4 are in gray, next to the line.", "\u00b7 Although it might be hard to see from the chart, not all features move the line to the same degree. Features on top move it more.", "\u00b7 The borrower\u2019s credit score is about average for our cohort, but", "\u00b7 Almost everything else about this borrower is a red flag. It\u2019s not one thing: It\u2019s everything.", "\u00b7 This should give the loan officer some confidence in the prediction. Even if the model is wrong about one or two features, the conclusion shouldn\u2019t change much.", "If this were a production model, feature labels would be more user-friendly and the loan officer would be able to click on them to get additional information, such as how borrower #4 compares with the rest on any given feature, or the feature dependency plot shown earlier.", "The only problem is that this plot doesn\u2019t show our full model, only the top 20 features. Here is the underlying data:", "How should we read this chart?", "\u00b7 Each row represents a model feature, 704 in total.", "\u00b7 The middle column shows the feature\u2019s value for borrower #4.", "\u00b7 The right column shows the feature\u2019s contribution to the model\u2019s prediction for borrower #4, denominated in log-odds units. The data is sorted by the absolute value of this column. This puts the most important features on top, just like in previous plots.", "\u00b7 If we add up the right column to the model\u2019s average prediction across all borrowers, we get the model\u2019s prediction for borrower #4. Here\u2019s the math:", "\u00b7 Reading down the right column, this borrower\u2019s credit score is significant, but almost every other feature contributes a little to the risky label. Lots of risk factors, no mitigants.", "\u00b7 Looking at the bottom of the list, 336 of our 704 features have zero contribution, which means they do not affect our model\u2019s prediction for borrower #4 at all.", "\u00b7 If this were a common pattern across borrowers (and not just for borrower #4), we would want to prune these zero-impact features from the model.", "Before a model goes to production, it will typically need to be validated by a separate team. Organizations call these teams by different names: model validation, model risk, AI governance or something similar. For simplicity, let\u2019s call them the auditor.", "The auditor is not concerned with a single prediction as above. They care about the model as a whole. For example, they may want to confirm that our (candidate) model is not biased against protected groups, which would be a violation of the Equal Credit Opportunity Act (if this model served US borrowers). Take gender, for example:", "Our dataset includes about as many women as men and shows that women default less often. We would want to make sure that our model does not treat women unfairly by predicting they are more likely to default than men. This is simple to do: We simply compare predictions for men and women and use the t-test to see if the difference is significant.", "This chart shows the model tends to predict women will default less often, and the group difference is significant. This is consistent with our training data, summarized above. We can go further and test each feature separately:", "How should we read this chart?", "\u00b7 We once again look at the top 10 most important features.", "\u00b7 Features stretching to the left of the vertical line \u201cfavor\u201d women and those to the right \u201cfavor\u201d men.", "\u00b7 The plot also shows confidence intervals.", "What is this chart telling us?", "\u00b7 Most features favor women, consistent with the underlying distribution. This is good, since our model is not distorting things.", "\u00b7 Some features still favor men, such as the ratio between the annual loan payment and income. Possibly this is because men in our dataset have a higher income.", "\u00b7 We built this chart on a sample. We could probably get better (tighter) confidence intervals if we used a larger sample.", "\u00b7 At this point, the auditor will consider this evidence to determine whether a model should move forward to production. Different lenders will react to the evidence in different ways. Some may kick out features that favor men, even though they may make the model less accurate. Others will accept all features provided they do not cross a certain significance threshold. Yet others may only look at the aggregate prediction.", "The same analysis would be repeated for other protected groups \u2014 by race, age, sexual orientation, disability status, etc.", "Explainable AI (XAI) is one of the most exciting areas of development in AI because it can facilitate conversations between modelers and domain experts that would otherwise not happen. These conversations are highly valuable because they get technical and business stakeholders on the same page. Together, we can make sure the model is \u201cright for the right reasons\u201d and maybe even solve our Cassandra problem.", "We have only scratched the surface of what\u2019s possible with XAI. I hope I piqued your appetite. Here are some additional resources", "\u00b7 Interpretable ML Book by Chris Molnar (WIP)", "\u00b7 Designing user experience (UX) for XAI, from UXAI and Microsoft", "\u00b7 Ensuring fairness and explainability in credit default risk modeling", "Here is the formula to convert log-odds to probability:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8edb1bc29876&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@alon.bochman?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alon.bochman?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Alon Bochman"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa37d685642da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&user=Alon+Bochman&userId=a37d685642da&source=post_page-a37d685642da----8edb1bc29876---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Evelyn_De_Morgan", "anchor_text": "Evelyn De Morgan"}, {"url": "https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/", "anchor_text": "87% of our projects never make it to production"}, {"url": "https://hostingtribunal.com/blog/big-data-stats/#:~:text=The%20amount%20of%20data%20created,that's%2044%20trillion%20gigabytes)!", "anchor_text": "1.7 MB"}, {"url": "https://arxiv.org/list/cs.AI/pastweek?skip=0&show=25", "anchor_text": "31"}, {"url": "https://outsideinsight.com/insights/global-ai-investment-150-billion-2025/", "anchor_text": "\u00a3150 billion by 2025"}, {"url": "https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf", "anchor_text": "doubling every 3.4 months"}, {"url": "https://en.wikipedia.org/wiki/Cassandra", "anchor_text": "Cassandra"}, {"url": "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence", "anchor_text": "Explainable AI"}, {"url": "https://www.amazon.com/Start-Why-Leaders-Inspire-Everyone/dp/1591846447", "anchor_text": "at the expense of the why"}, {"url": "https://www.kaggle.com/c/home-credit-default-risk", "anchor_text": "Kaggle Home Credit"}, {"url": "https://blog.dataiku.com/tree-based-models-how-they-work-in-plain-english#:~:text=Tree%2Dbased%20models%20use%20a,classification%20(predicting%20categorical%20values).", "anchor_text": "tree-based"}, {"url": "https://www.genpact.com/digital-transformation/artificial-intelligence-ai", "anchor_text": "Genpact"}, {"url": "https://unsplash.com/@spacex?utm_source=medium&utm_medium=referral", "anchor_text": "SpaceX"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "SHAP"}, {"url": "https://www.actuaries.digital/2019/06/18/analytics-snippet-feature-importance-and-the-shap-approach-to-machine-learning-models/", "anchor_text": "SHAP order is more accurate"}, {"url": "https://en.wikipedia.org/wiki/Violin_plot#:~:text=A%20violin%20plot%20is%20a,by%20a%20kernel%20density%20estimator.", "anchor_text": "violin"}, {"url": "https://unsplash.com/@mrthetrain?utm_source=medium&utm_medium=referral", "anchor_text": "Joshua Hoehne"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&utm_medium=referral", "anchor_text": "Tingey Injury Law Firm"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@theexplorerdad?utm_source=medium&utm_medium=referral", "anchor_text": "Joshua Ness"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/watch?v=rPSiEDYcXr4&feature=emb_logo", "anchor_text": "XAI Overview Video"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "Interpretable ML Book by Chris Molnar (WIP)"}, {"url": "https://www.uxai.design/design-strategy", "anchor_text": "UXAI"}, {"url": "https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/", "anchor_text": "Microsoft"}, {"url": "https://www.researchgate.net/publication/338184751_Explainable_Artificial_Intelligence_XAI_Concepts_Taxonomies_Opportunities_and_Challenges_toward_Responsible_AI", "anchor_text": "Taxonomy of XAI methods"}, {"url": "https://cloud.google.com/explainable-ai", "anchor_text": "XAI offering from Google"}, {"url": "https://medium.com/@tonyxu_71807/ensuring-fairness-and-explainability-in-credit-default-risk-modeling-shap-ibm-tool-kit-aix-360-bfc519c191bf", "anchor_text": "Ensuring fairness and explainability in credit default risk modeling"}, {"url": "https://medium.com/tag/ai?source=post_page-----8edb1bc29876---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/interpretability?source=post_page-----8edb1bc29876---------------interpretability-----------------", "anchor_text": "Interpretability"}, {"url": "https://medium.com/tag/visualization?source=post_page-----8edb1bc29876---------------visualization-----------------", "anchor_text": "Visualization"}, {"url": "https://medium.com/tag/ux?source=post_page-----8edb1bc29876---------------ux-----------------", "anchor_text": "UX"}, {"url": "https://medium.com/tag/explanation?source=post_page-----8edb1bc29876---------------explanation-----------------", "anchor_text": "Explanation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&user=Alon+Bochman&userId=a37d685642da&source=-----8edb1bc29876---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&user=Alon+Bochman&userId=a37d685642da&source=-----8edb1bc29876---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8edb1bc29876&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8edb1bc29876---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8edb1bc29876--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8edb1bc29876--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8edb1bc29876--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alon.bochman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@alon.bochman?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Alon Bochman"}, {"url": "https://medium.com/@alon.bochman/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "30 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa37d685642da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&user=Alon+Bochman&userId=a37d685642da&source=post_page-a37d685642da--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fae35d729716e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-ais-cassandra-problem-8edb1bc29876&newsletterV3=a37d685642da&newsletterV3Id=ae35d729716e&user=Alon+Bochman&userId=a37d685642da&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}