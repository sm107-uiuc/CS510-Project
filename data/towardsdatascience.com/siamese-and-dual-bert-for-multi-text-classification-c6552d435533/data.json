{"url": "https://towardsdatascience.com/siamese-and-dual-bert-for-multi-text-classification-c6552d435533", "time": 1683007355.619286, "path": "towardsdatascience.com/siamese-and-dual-bert-for-multi-text-classification-c6552d435533/", "webpage": {"metadata": {"title": "Siamese and Dual BERT for Multi Text Classification | by Marco Cerliani | Towards Data Science", "h1": "Siamese and Dual BERT for Multi Text Classification", "description": "Constant research in NLP produces the development of various kinds of pre-trained models. It\u2019s typical to register increasing improvements in state-of-the-art results for various tasks, such as text\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/129978", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://www.kaggle.com/rmisra/news-category-dataset", "anchor_text": "News Category Dataset", "paragraph_index": 3}, {"url": "https://www.huffingtonpost.com/", "anchor_text": "HuffPost", "paragraph_index": 3}, {"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/129978", "anchor_text": "Two BERTs are better than one", "paragraph_index": 15}], "all_paragraphs": ["Constant research in NLP produces the development of various kinds of pre-trained models. It\u2019s typical to register increasing improvements in state-of-the-art results for various tasks, such as text classification, unsupervised topic modeling, and question-answering.", "One of the greatest discoveries was the adoption of the attention mechanics in neural network structures. This technique is the basis of all networks called transformers. They apply attention mechanisms to extract information about the context of a given word, and then encode it in a learned vector.", "There are a lot of transformers architectures that we, as data scientists, can evoke and use to make predictions or fine-tune on our task. In this post, we enjoy ourselves with the classical BERT, but the same reasoning can be applied to every other transformer structure. Our scope is to play with BERT using it in dual and siamese structures instead of using it as a single feature extractor for multi-textural input classification. What presented in this post is inspired by here.", "We collect a dataset from Kaggle. The News Category Dataset contains around 200k news headlines from the year 2012 to 2018 obtained from HuffPost. Our scope is to categorize news articles based on two different text sources: headlines and short descriptions. In total, we have more than 40 different types of news. For simplicity, considering the computation time of our workflow, we use only a subgroup of 8 classes.", "We don\u2019t apply any sort of preprocessing cleaning; we let our BERTs do all the magic. Our working framework is Tensorflow with the great Huggingface transformers library. More in detail, we utilize the bare Bert Model transformer which outputs raw hidden-states without any specific head on top. It\u2019s accessible like a Tensorflow model sub-class and can be easily pulled in our network architecture for fine-tuning.", "As the first competitor, we introduce a single BERT structure. It receives only one text input, which is the result of the concatenation of our two textual sources. This is the normality: any model can receive input of concatenated features. For transformers, this process is exalted combining the input with special tokens.", "BERT expects input data in a specific format: there are special tokens to mark the beginning ([CLS]) and the end of sentences/textual sources ([SEP]). At the same time, the tokenization involves splitting the input text into lists of tokens that are available in the vocabulary. The out of vocabulary words are processed with the word-piece technique; where a word is progressively split into subwords which are part of the vocabulary. This process can be carried out easily by the pre-trained Tokenizer of Huggingface; we have only to take care of padding.", "We end with three matrices (token, mask, sequence ids) for each text source. They are the inputs of our transformers. In the case of single BERT, we have only a single tuple of matrices. This is because we pass simultaneously to our tokenizer the two text sequences, which are automatically concatenated (with [SEP] token).", "The structure of our model is very simple: the transformer is directly fed with the matrices we\u2019ve built above. In the end, the final hidden-state of the transformer is reduced with an average-pooling operation. The probability scores are calculated by a final dense layer.", "Our simple BERT achieves 83% accuracy on our test data. The performances are reported in the confusion matrix below.", "Our second structure can be defined as dual BERT because it uses two different transformers. They have the same composition but are trained with different inputs. The first one receives news headlines while the other the short textual descriptions. Inputs are encoded as always producing two tuples of matrices (token, mask, sequence ids), one for each input. The final hidden-states of our transformers, for both the data sources, are reduced with average pooling. They are concatenated and passed through a fully connected layer.", "With these settings, we can achieve 84% accuracy on our test data.", "Our last model is a kind of Siamese architecture. It can be defined in this way because the two different data sources are passed simultaneously in the same trainable transformer structure. The input matrices are the same as in the case of dual BERT. The final hidden state of our transformer, for both data sources, is pooled with an average operation. The resulting concatenation is passed in a fully connected layer that combines them and produces probabilities.", "Our siamese structure achieves 82% accuracy on our test data.", "In this post, we applied the BERT structure to carry out a multiclass classification task. The added value of our experiments was to use the transformers in various ways to deal with multiple input sources. We started with the classic concatenation of all the inputs in only one source, and we ended feeding our models maintaining the text inputs separated. The dual and siamese variants presented were able to achieve good performances. For this reason, they can be considered good alternatives to the classical single transformer structure.", "Kaggle: Two BERTs are better than one"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc6552d435533&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@cerlymarco?source=post_page-----c6552d435533--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Marco Cerliani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc843902314c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=post_page-c843902314c7----c6552d435533---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc6552d435533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=-----c6552d435533---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6552d435533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=-----c6552d435533---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@junglerolf?utm_source=medium&utm_medium=referral", "anchor_text": "rolf neumann"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/129978", "anchor_text": "here"}, {"url": "https://www.kaggle.com/rmisra/news-category-dataset", "anchor_text": "News Category Dataset"}, {"url": "https://www.huffingtonpost.com/", "anchor_text": "HuffPost"}, {"url": "https://github.com/cerlymarco/MEDIUM_NoteBook", "anchor_text": "CHECK MY GITHUB REPO"}, {"url": "https://www.linkedin.com/in/marco-cerliani-b0bba714b/", "anchor_text": "Linkedin"}, {"url": "https://www.kaggle.com/c/google-quest-challenge/discussion/129978", "anchor_text": "Two BERTs are better than one"}, {"url": "https://www.kaggle.com/akensert/bert-base-tf2-0-now-huggingface-transformer", "anchor_text": "Bert-base TF2.0"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c6552d435533---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c6552d435533---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----c6552d435533---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/transformers?source=post_page-----c6552d435533---------------transformers-----------------", "anchor_text": "Transformers"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----c6552d435533---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc6552d435533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=-----c6552d435533---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc6552d435533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=-----c6552d435533---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6552d435533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=post_page-----c6552d435533--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc843902314c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=post_page-c843902314c7----c6552d435533---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe2412974851a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&newsletterV3=c843902314c7&newsletterV3Id=e2412974851a&user=Marco+Cerliani&userId=c843902314c7&source=-----c6552d435533---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Written by Marco Cerliani"}, {"url": "https://medium.com/@cerlymarco/followers?source=post_page-----c6552d435533--------------------------------", "anchor_text": "6K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc843902314c7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&user=Marco+Cerliani&userId=c843902314c7&source=post_page-c843902314c7----c6552d435533---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe2412974851a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsiamese-and-dual-bert-for-multi-text-classification-c6552d435533&newsletterV3=c843902314c7&newsletterV3Id=e2412974851a&user=Marco+Cerliani&userId=c843902314c7&source=-----c6552d435533---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/forecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Marco Cerliani"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/forecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Forecasting with Granger Causality: Checking for Time Series Spurious CorrelationsHacking Granger Causality Test with ML Approaches"}, {"url": "https://towardsdatascience.com/forecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "\u00b76 min read\u00b7Apr 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5faed62c3604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604&user=Marco+Cerliani&userId=c843902314c7&source=-----5faed62c3604----0-----------------clap_footer----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/forecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604?source=author_recirc-----c6552d435533----0---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5faed62c3604&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-granger-causality-checking-for-time-series-spurious-correlations-5faed62c3604&source=-----c6552d435533----0-----------------bookmark_preview----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c6552d435533----1---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----c6552d435533----1-----------------bookmark_preview----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----c6552d435533----2---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----c6552d435533----2-----------------bookmark_preview----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Marco Cerliani"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "Time2Vec for Time Series features encodingLearn a valuable representation of time for your Machine Learning Model"}, {"url": "https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": "\u00b75 min read\u00b7Sep 25, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa03a4f3f937e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime2vec-for-time-series-features-encoding-a03a4f3f937e&user=Marco+Cerliani&userId=c843902314c7&source=-----a03a4f3f937e----3-----------------clap_footer----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e?source=author_recirc-----c6552d435533----3---------------------a6d5716e_3419_4dad_9d64_110a9fbdccb5-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa03a4f3f937e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime2vec-for-time-series-features-encoding-a03a4f3f937e&source=-----c6552d435533----3-----------------bookmark_preview----a6d5716e_3419_4dad_9d64_110a9fbdccb5-------", "anchor_text": ""}, {"url": "https://medium.com/@cerlymarco?source=post_page-----c6552d435533--------------------------------", "anchor_text": "See all from Marco Cerliani"}, {"url": "https://towardsdatascience.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://skanda-vivek.medium.com/?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Skanda Vivek"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Fine-Tune Transformer Models For Question Answering On Custom DataA tutorial on fine-tuning the Hugging Face RoBERTa QA Model on custom data and obtaining significant performance boosts"}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b75 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&user=Skanda+Vivek&userId=220d9bbb8014&source=-----513eaac37a80----0-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/fine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513eaac37a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tune-transformer-models-for-question-answering-on-custom-data-513eaac37a80&source=-----c6552d435533----0-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Babar M Bhatti"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Essential Guide to Foundation Models and Large Language ModelsThe term Foundation Model (FM) was coined by Stanford researchers to introduce a new category of ML models. They defined FMs as models\u2026"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b714 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&user=Babar+M+Bhatti&userId=10dee34829b&source=-----27dab58f7404----1-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&source=-----c6552d435533----1-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "The Ultimate Guide to Evaluating Your Recommendation SystemUnderstand the key metrics to measure the performance of your recommender engine"}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b720 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2Fd4fc8d4423cc&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fthe-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----d4fc8d4423cc----0-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc?source=read_next_recirc-----c6552d435533----0---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd4fc8d4423cc&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fthe-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc&source=-----c6552d435533----0-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----c6552d435533----1---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----c6552d435533----1-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://tmmtt.medium.com/?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://tmmtt.medium.com/?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Teemu Maatta"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "OpenAI\u2019s Embedding Model With Vector DatabaseThe updated Embedding model offers State-of-the-Art performance with 4x longer context window. Thew new model is 90% cheaper. The smaller\u2026"}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b712 min read\u00b7Jan 10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2Fb69014f04433&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fopenais-embedding-model-with-vector-database-b69014f04433&user=Teemu+Maatta&userId=a536c637e472&source=-----b69014f04433----2-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/openais-embedding-model-with-vector-database-b69014f04433?source=read_next_recirc-----c6552d435533----2---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69014f04433&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fopenais-embedding-model-with-vector-database-b69014f04433&source=-----c6552d435533----2-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/@bnjmn_marie?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/@bnjmn_marie?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Benjamin Marie"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "Run Very Large Language Models on Your ComputerWith PyTorch and Hugging Face\u2019s device_map"}, {"url": "https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": "\u00b75 min read\u00b7Dec 22, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F390dd33838bb&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Frun-very-large-language-models-on-your-computer-390dd33838bb&user=Benjamin+Marie&userId=ad2a414578b3&source=-----390dd33838bb----3-----------------clap_footer----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/run-very-large-language-models-on-your-computer-390dd33838bb?source=read_next_recirc-----c6552d435533----3---------------------07be785d_b452_40a7_a31b_05c9ff6b35a2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F390dd33838bb&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Frun-very-large-language-models-on-your-computer-390dd33838bb&source=-----c6552d435533----3-----------------bookmark_preview----07be785d_b452_40a7_a31b_05c9ff6b35a2-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c6552d435533--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----c6552d435533--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}