{"url": "https://towardsdatascience.com/using-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9", "time": 1683008401.7990642, "path": "towardsdatascience.com/using-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9/", "webpage": {"metadata": {"title": "Using Skip Connections To Enhance Denoising Autoencoder Algorithms | by Metika Sikka | Towards Data Science", "h1": "Using Skip Connections To Enhance Denoising Autoencoder Algorithms", "description": "The official Keras blog, calls autoencoders an example of \u2018self-supervised\u2019 algorithms as their targets are generated from the input data. Hence, they are used for tasks of image reconstruction. The\u2026"}, "outgoing_paragraph_urls": [{"url": "https://blog.keras.io/building-autoencoders-in-keras.html", "anchor_text": "Keras", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "degradation problem", "paragraph_index": 3}, {"url": "https://www.kaggle.com/hsankesara/flickr-image-dataset", "anchor_text": "this", "paragraph_index": 5}, {"url": "https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/", "anchor_text": "Deconvolutional layers", "paragraph_index": 7}, {"url": "https://github.com/philipperemy/keract", "anchor_text": "keract", "paragraph_index": 10}, {"url": "https://www.worldsciencefestival.com/venues/columbia-university/", "anchor_text": "image", "paragraph_index": 11}, {"url": "https://github.com/MS1997/Autoencoders-with-skip-connections", "anchor_text": "here", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1611.09119.pdf", "anchor_text": "Learning Deep Representations Using Convolutional Auto-encoders with Symmetric Skip Connections", "paragraph_index": 22}], "all_paragraphs": ["The official Keras blog, calls autoencoders an example of \u2018self-supervised\u2019 algorithms as their targets are generated from the input data. Hence, they are used for tasks of image reconstruction.", "The main parts of an autoencoder are: Encoder, Bottleneck and Decoder. The Encoder is extracts image features at each step and in the process compresses the input data. The bottleneck constrains the input to its lowest dimensions known as compressed representations of the input data. The Decoder comes after this bottleneck and is used to reconstruct the input data. A loss measure is used to compare how close the generated or reconstructed date is to the input data.", "Data denoising images is a common application of autoencoders. Noise in images can be understood as a random variation in color or brightness of images, degrading their quality. Removing this noise is often a pre-processing step in various use-cases of image data. Convolutional autoencoders can be used for this purpose. The encoder learns to extract the features separating them from the noise in the image. Thereby compressing the image. The final compressed representations from the bottleneck are passed over to the decoder. The decoder finally decompresses the image minimizing the noise.", "We know that deep neural networks suffer from the degradation problem. Since Autoencoders have multiple convolutional and deconvolutional layers, they also suffer in performance when reconstructing images due to this information loss. Residual networks comprising of skip connections are a known solution to this problem. Hence, to improve the performance of the autoencoders such \u2018skip connections\u2019 can be added from the encoder to the decoder, i.e. across the bottleneck. These additional connections can directly send the feature maps from the an earlier layer of the encoder to a later layer of the decoder. This helps the decoder form more clearly defined decompressions of the input image.", "To see the advantage of these residual networks, let\u2019s see the activation outputs at various stages of a convolutional autoencoder model. First we trained an autoencoder model without skip-connections across the bottleneck. Then we added them and train the model again on the same sample of images.", "A sample of 10K RGB images were taken from this data set of Flickr images on Kaggle. All the analysis was done using Google Colab\u2019s GPU.", "We have used the Functional API of Keras to form the autoencoder model. The input images were resized to a smaller size (128,128,3) because of computational limitations. The image pixels were also standardized by a factor of 1/255. Further, the images were corrupted on purpose by applying a Gaussian noise matrix. These corrupted images formed the input of the autoencoder whereas the original images were used as targets while training the model. When building convolutional networks it is important to remember that, as we go deeper, the number of channels or filters increases whereas the size (height and width) of the input decreases.", "Below is code for the decoder. Transposed convolution or deconvolutional layers were used to build this decoder. Deconvolutional layers work roughly like a combination of convolutional and upsampling layers. Initially, we trained the model without the first and second skip connections. Then these connections were added from an earlier layer of the encoder to the later layer of the decoder using Add() from the layers API in Keras. The lrelu_bn() helper function was used to apply activations to these additions and pass the result through a batch normalization layer.", "Since the input images were standardized, their resulting pixel values were between 0 and 1. To get a comparable reconstructed image, \u201csigmoid\u201d activation was used in the final layer. Out of the training set, 1k images were used as the validation set. Binary cross entropy was used as the loss function. Finally, both models were trained for 200 epochs with a mini-batch size of 32. The Adam optimizer with a learning rate of 0.001 gave the least training and validation loss at convergence.", "Let\u2019s look at the activation outputs at various layers of the model for a test image. This will help us clearly see the encoder-decoder in action!", "The activation outputs were created using the keract package.", "We take a test image of the Columbia University campus. The test image was resized for the model and random noise was added. The \u2018noisy\u2019 image was used as the input for the model.", "Since the encoder was same for both the models, the activation outputs were also the same for this part. On examining the activation outputs of the first three convolutional layers, it can be seen that most of the image information is retained. This could also imply that the noise in the image is also retained at this stage of the model. However, as we go deeper in the model (see activation outputs of layers after the third convolutional layer), the information retained is quite abstract. The model starts to extract higher level features such as borders, corners & angles.", "It is interesting to note that the activation outputs of the decoder are in the exact opposite sequence as the encoder above.", "After the third de-convolutional layer, we still do not see any edges of the image being formed again.", "There is no clearly defined decompression of the image in the final layer of the decoder as seen below!", "As seen in the activation outputs of the encoder, its earlier layers retain the noise but the later layers extract higher representations of the image. Hence, skip connections are made from the third and fifth convolutional layers of the encoder to third and fifth deconvolutional layers of the decoder. The activation outputs of the first, second and third de-convolutional layers for this decoder are the same as the previous version of the decoder. However, after the third layer we see a difference in the activation outputs from those of the previous decoder. Below we can clearly see the image being formed again in the activation output of the sixth deconvolutional layer.", "The final layer of this decoder has given a clearly defined decompressed version of the test input image.", "Denoised image output from the first model:", "Denoised image output of the second model with skip connections across the bottleneck:", "We can clearly see the better performance the autoencoder model with skip connections across the bottleneck!", "This approach can be used for any image reconstruction application of autoencoders apart from denoising images. While the skip connections improve the performance of the autoencoder, the positions and number of these connections can be experimented with. The model can also be trained with different levels of noise factor for better generalization of results. The full code can be accessed here!", "J. Dong , XJ. Mao , C. Shen , YB. Yang, Learning Deep Representations Using Convolutional Auto-encoders with Symmetric Skip Connections (2017)", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F849e049c0ac9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://metika.medium.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": ""}, {"url": "https://metika.medium.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Metika Sikka"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F127625b11501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&user=Metika+Sikka&userId=127625b11501&source=post_page-127625b11501----849e049c0ac9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://blog.keras.io/building-autoencoders-in-keras.html", "anchor_text": "Keras"}, {"url": "https://giphy.com/gifs/color-colour-FkUyGd7FDh1gk", "anchor_text": "GIPHY"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "degradation problem"}, {"url": "https://www.kaggle.com/hsankesara/flickr-image-dataset", "anchor_text": "this"}, {"url": "https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/", "anchor_text": "Deconvolutional layers"}, {"url": "https://github.com/philipperemy/keract", "anchor_text": "keract"}, {"url": "https://www.worldsciencefestival.com/venues/columbia-university/", "anchor_text": "image"}, {"url": "https://github.com/MS1997/Autoencoders-with-skip-connections", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1611.09119.pdf", "anchor_text": "Learning Deep Representations Using Convolutional Auto-encoders with Symmetric Skip Connections"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----849e049c0ac9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/autoencoder?source=post_page-----849e049c0ac9---------------autoencoder-----------------", "anchor_text": "Autoencoder"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----849e049c0ac9---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/image-denoising?source=post_page-----849e049c0ac9---------------image_denoising-----------------", "anchor_text": "Image Denoising"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----849e049c0ac9---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&user=Metika+Sikka&userId=127625b11501&source=-----849e049c0ac9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&user=Metika+Sikka&userId=127625b11501&source=-----849e049c0ac9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F849e049c0ac9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----849e049c0ac9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----849e049c0ac9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----849e049c0ac9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----849e049c0ac9--------------------------------", "anchor_text": ""}, {"url": "https://metika.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://metika.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Metika Sikka"}, {"url": "https://metika.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "61 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F127625b11501&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&user=Metika+Sikka&userId=127625b11501&source=post_page-127625b11501--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Facd64ae209a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-skip-connections-to-enhance-denoising-autoencoder-algorithms-849e049c0ac9&newsletterV3=127625b11501&newsletterV3Id=acd64ae209a2&user=Metika+Sikka&userId=127625b11501&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}