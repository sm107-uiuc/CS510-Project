{"url": "https://towardsdatascience.com/road-surface-semantic-segmentation-4d65b045245", "time": 1683012276.904804, "path": "towardsdatascience.com/road-surface-semantic-segmentation-4d65b045245/", "webpage": {"metadata": {"title": "Road Surface Semantic Segmentation | by Thiago Rateke | Towards Data Science", "h1": "Road Surface Semantic Segmentation", "description": "Hello There! This post is about a road surface semantic segmentation approach. So the focus here is on the road surface patterns, like: what kind of pavement the vehicle is driving on or if there is\u2026"}, "outgoing_paragraph_urls": [{"url": "https://rdcu.be/cdpxi", "anchor_text": "Autonomous Robots", "paragraph_index": 1}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/datasets/?lang=en", "anchor_text": "RTK dataset", "paragraph_index": 1}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/datasets/?lang=en#gtSegmentacao", "anchor_text": "This GT is available on the dataset page", "paragraph_index": 6}, {"url": "https://www.fast.ai/", "anchor_text": "fastai", "paragraph_index": 7}, {"url": "https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb", "anchor_text": "lesson3-camvid", "paragraph_index": 7}, {"url": "https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb", "anchor_text": "lesson3-camvid", "paragraph_index": 23}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/?lang=en", "anchor_text": "project", "paragraph_index": 48}, {"url": "http://www.lapix.ufsc.br/?lang=en", "anchor_text": "LAPiX", "paragraph_index": 48}, {"url": "https://www.researchgate.net/publication/337682194_Road_Surface_Classification_with_Images_Captured_From_Low-cost_Camera_-_Road_Traversing_Knowledge_RTK_Dataset", "anchor_text": "approach", "paragraph_index": 49}, {"url": "https://rdcu.be/cdpxi", "anchor_text": "Road surface detection and differentiation considering surface damages", "paragraph_index": 50}, {"url": "https://www.researchgate.net/publication/337682194_Road_Surface_Classification_with_Images_Captured_From_Low-cost_Camera_-_Road_Traversing_Knowledge_RTK_Dataset", "anchor_text": "Road Surface Classification with Images Captured From Low-cost Cameras \u2014 Road Traversing Knowledge (RTK) Dataset", "paragraph_index": 51}, {"url": "https://arxiv.org/abs/1505.04597", "anchor_text": "U-net: Convolutional networks for biomedical image segmentation", "paragraph_index": 52}, {"url": "https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28", "anchor_text": "MICCAI 2015. Cham: Springer International Publishing", "paragraph_index": 52}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Deep residual learning for image recognition", "paragraph_index": 53}, {"url": "https://ieeexplore.ieee.org/document/7780459/authors#authors", "anchor_text": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "paragraph_index": 53}], "all_paragraphs": ["Hello There! This post is about a road surface semantic segmentation approach. So the focus here is on the road surface patterns, like: what kind of pavement the vehicle is driving on or if there is any damage on the road, also the road markings and speed-bumps as well and other things that can be relevant for a vehicular navigation task.", "Here I will show you the step-by-step approach based on the paper available at Autonomous Robots (Springer) [1]. The Ground Truth and the experiments were made using the RTK dataset [2], with images captured with a low-cost camera, containing images of roads with different types of pavement and different conditions of pavement quality.", "It was fun to work on it and I\u2019m excited to share it, I hope you enjoy it too. \ud83e\udd17", "The purpose of this approach is to verify the effectiveness of using passive vision (camera) to detect different patterns on the road. For example, to identify if the road surface is an asphalt or cobblestone or an unpaved (dirt) road? This may be relevant for an intelligent vehicle, whether it is an autonomous vehicle or an Advanced Driver-Assistance System (ADAS). Depending on the type of pavement it may be necessary to adapt the way the vehicle is driven, whether for the safety of users or the conservation of the vehicle or even for the comfort of people inside the vehicle.", "Another relevant factor of this approach is related to the detection of potholes and water-puddles, which could generate accidents, damage the vehicles and can be quite common in developing countries. This approach can also be useful for departments or organizations responsible for maintaining highways and roads.", "To achieve these objectives, Convolutional Neural Networks (CNN) were used for the semantic segmentation of the road surface, I\u2019ll talk more about that in next sections.", "To train the neural network and to test and validate the results, a Ground Truth (GT) was created with 701 images from the RTK dataset. This GT is available on the dataset page and is composed by the following classes:", "Everything done here was done using Google Colab. Which is a free Jupyter notebook environment and give us free access to GPUs and is super easy to use, also very helpful for organization and configuration. It was also used the fastai [3], the amazing deep learning library. To be more precise, the step-by-step that I will present was very much based on one of the lessons given by Jeremy Howard on one the courses about deep learning, in this case lesson3-camvid.", "The CNN architecture used was the U-NET [4], which is an architecture designed to perform the task of semantic segmentation in medical images, but successfully applied to many other approaches. In addition, ResNet [5] based encoder and a decoder are used. The experiments for this approach were done with resnet34 and resnet50.", "For the data augmentation step, standard options from the fastai library were used, with horizontal rotations and perspective distortion being applied. With fastai it is possible to take care to make the same variations made in the data augmentation step for both the original and mask (GT) images.", "A relevant point, which was of great importance for the definition of this approach, is that the classes of the GT are quite unbalanced, having much larger pixels of background or surface types (eg.: asphalt, paved or unpaved) than the other classes. Unlike an image classification problem, where perhaps replicating certain images from the dataset could help to balance the classes, in this case, replicating an image would imply further increasing the difference between the number of pixels from the largest to the smallest classes. Then, in the defined approach weights were used in the classes for balancing. \ud83e\udd14", "Based on different experiments, it was realized that just applying the weights is not enough, because when improving the accuracy of the classes that contain a smaller amount of pixels, the classes that contain a larger amount of pixels (eg.: asphalt, paved and unpaved) lost quality in the accuracy results.", "The best accuracy values, considering all classes, without losing much quality for the detection of surface types, was with the following configuration: first training a model without using weights, generating a model with good accuracy for the types of surface, then, use that previously trained model as a basis for the next model that uses the proportional weights for the classes. And that\u2019s it!", "You can check the complete code, that I will comment on throughout this post, on GitHub:", "Cool, so we start by our initial settings, importing the fastai library and the pathlib module. Let\u2019s call this as Step 1.", "As we\u2019ll use our dataset from google drive, we need to mount it, so in the next cell type:", "You\u2019ll see something like the next image, click on the link and you\u2019ll get an authorization code, so just copy and paste the authorization code in the expected field.", "Now just access your Google Drive as a file system. This is the start of Step 2, loading our data.", "Where \u201cimage\u201d is the folder containing the original images. The \u201clabels\u201d is the folder containing the masks that we\u2019ll use for our training and validation, these images are 8-bit pixels after a colormap removal process. In \u201ccolorLabels\u201d I\u2019ve put the original colored masks, which we can use later for visual comparison. The \u201cvalid.txt\u201d file contains a list of images names randomly selected for validation. Finally, the \u201ccodes.txt\u201d file contains a list with classes names.", "Now, we define the paths for the original images and for the GT mask images, enabling access to all images in each folder to be used later.", "We can see an example, image 139 from the dataset.", "Next, as shown in fastai lesson, we use a function to infer the mask filename from the original image, responsible for the color coding of each pixel.", "Here we are at the Step 3. Let\u2019s create the DataBunch for training our first model using data block API. Defining where our images come from, which images will be used for validation and and the masks corresponding to each original image. For the data augmentation, the fastai library also gives options, but here we\u2019ll use only the default options with get_transforms(), which consists of randomly horizontal rotations and the perspective warping. Remember to set tfm_y=True in the transform call to ensure that the transformations for the data augmentation in the dataset are the same for each mask and its original image. Imagine if we rotated the original image, but the mask corresponding to that image was not rotated, what a mess it would be! \ud83d\ude35", "We continue using the lesson3-camvid example from the fastai course, to define the accuracy metric and the weight decay. I\u2019ve used the resnet34 model since I didn\u2019t have much of a difference using resnet50 in this approach with this dataset. We can find the learning rate using lr_find(learn), which in my case I\u2019ve defined as 1e-4.", "Next we run the fit_one_cycle() for 10 times to check how our model is doing.", "Using the confusion matrix we can see how good (or bad) the model is for each class until now\u2026", "Don\u2019t forget to save the model we\u2019ve trained until now.", "Now we just train the model over more epochs to improve the learning, and remember to save our final model. The slice keyword is used to take a start and a stop value, so in the first layers begin the training with the start value and this will change until the stop value when reaching the end of the training process.", "This is our first model, without weights, which works fine for road surfaces but doesn\u2019t work for the small classes.", "We\u2019ll use the first model in our next Step. This part is almost exactly the same as the Step 3, since the databunch, we just need to remember to load our previous model.", "And, before we start the training process, we need to put weight in the classes. I defined these weights in order to try to be proportional to how much each class appears in the dataset (number of pixels). * I ran a python code with OpenCV just to count the number of pixels in each class over the GT\u2019s 701 images, to get a sense of the proportion of each class\u2026 \ud83d\ude13", "The remainder is exactly like step three presented before. What changes are the results obtained. \ud83d\ude2c", "Now, it looks like we have a more reasonable result for all classes. Remember to save it!", "Finally, let\u2019s see our images, right? Before anything, it will be better to save our results, or our test images.", "But, wait! The images all look completely black, where are my results??? \ud83d\ude31 Calm down, these are the results, just without color map, if you open one of these images on the entire screen, with high brightness, you can see the small variations, \u201cEleven Shades of Grey\u201d \ud83d\ude43. So let\u2019s color our results to be more presentable? Now we\u2019ll use OpenCV and create a new folder to save our colored results.", "So we create a function to identify each variation and to colorize each pixel.", "Next, we read each image, call the function and save our final result.", "But, this process could take more time than necessary, using the %timeit we achieve a performance as:", "Imagine if we need to test with more images? We can speed up this step using Cython. So, let\u2019s put a pinch of Cython on that!", "So, we edit our function to identify each variation and to colorize each pixel, but this time, using Cython.", "And we just read each image and call the function and save our final result as we did before.", "And voila! Now we have a performance as:", "In the image below are some results. In the left column are the original images, in the middle column the GT and in the right column the result with this approach.", "Identifying road surface conditions is important in any scenario, based on this the vehicle or driver can adapt and make a decision that can make the driving safer, more comfortable and more efficient. This is particularly relevant in developing countries that may have even more situations of road maintenance problems or a reasonable number of unpaved roads.", "This approach looks promising for dealing with environments with variations in the road surface. This can also be useful for highway analysis and maintenance departments, in order to automate part of their work in assessing road quality and identifying where maintenance is needed.", "However, some points were identified and analyzed as subject to improvement.", "For the segmentation GT, it may be interesting to divide some classes into more specific classes, such as the Cracks class, used for different damages regardless of the type of road. Thus having variations of Cracks for each type of surface, because different surfaces have different types of damage. Also divide this class into different classes, categorizing different damage in each new class.", "That\u2019s all for now. Feel free to reach out to me. \ud83e\udd18", "This experiment is part of a project on visual perception for vehicular navigation from LAPiX (Image Processing and Computer Graphics Lab).", "If you are going to talk about this approach, please cite as:", "[1] T. Rateke, A. von Wangenheim. Road surface detection and differentiation considering surface damages, (2020), Autonomous Robots (Springer).", "[2] T. Rateke, K. A. Justen and A. von Wangenheim. Road Surface Classification with Images Captured From Low-cost Cameras \u2014 Road Traversing Knowledge (RTK) Dataset, (2019), Revista de Inform\u00e1tica Te\u00f3rica e Aplicada (RITA).", "[4] O. Ronneberger, P. Fischer, T. Brox. U-net: Convolutional networks for biomedical image segmentation, (2015), NAVAB, N. et al. (Ed.). Medical Image Computing and Computer-Assisted Intervention \u2014 MICCAI 2015. Cham: Springer International Publishing.", "[5] K. He, et al. Deep residual learning for image recognition, (2016), IEEE Conference on Computer Vision and Pattern Recognition (CVPR)."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4d65b045245&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@thiagortk?source=post_page-----4d65b045245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Thiago Rateke"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1ce9b89b9a0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=post_page-1ce9b89b9a0f----4d65b045245---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d65b045245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----4d65b045245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d65b045245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=-----4d65b045245---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://rdcu.be/cdpxi", "anchor_text": "Autonomous Robots"}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/datasets/?lang=en", "anchor_text": "RTK dataset"}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/datasets/?lang=en#gtSegmentacao", "anchor_text": "This GT is available on the dataset page"}, {"url": "https://www.fast.ai/", "anchor_text": "fastai"}, {"url": "https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb", "anchor_text": "lesson3-camvid"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages", "anchor_text": "thiagortk/Road-surface-detection-and-differentiation-considering-surface-damagesThe semantic segmentation GT for road surfaces contains 701 frames from RTK dataset.github.com"}, {"url": "https://giphy.com/", "anchor_text": "https://giphy.com/"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb", "anchor_text": "lesson3-camvid"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://giphy.com/", "anchor_text": "https://giphy.com/"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "https://github.com/thiagortk/Road-surface-detection-and-differentiation-considering-surface-damages/blob/master/RoadSurfaceSegmentation.ipynb", "anchor_text": "Road Surface Semantic Segmentation.ipynb"}, {"url": "http://www.lapix.ufsc.br/pesquisas/projeto-veiculo-autonomo/?lang=en", "anchor_text": "project"}, {"url": "http://www.lapix.ufsc.br/?lang=en", "anchor_text": "LAPiX"}, {"url": "https://www.researchgate.net/publication/337682194_Road_Surface_Classification_with_Images_Captured_From_Low-cost_Camera_-_Road_Traversing_Knowledge_RTK_Dataset", "anchor_text": "approach"}, {"url": "https://rdcu.be/cdpxi", "anchor_text": "Road surface detection and differentiation considering surface damages"}, {"url": "https://www.researchgate.net/publication/337682194_Road_Surface_Classification_with_Images_Captured_From_Low-cost_Camera_-_Road_Traversing_Knowledge_RTK_Dataset", "anchor_text": "Road Surface Classification with Images Captured From Low-cost Cameras \u2014 Road Traversing Knowledge (RTK) Dataset"}, {"url": "https://www.fast.ai/", "anchor_text": "fastai"}, {"url": "https://github.com/fastai/fastai", "anchor_text": "https://github.com/fastai/fastai"}, {"url": "https://arxiv.org/abs/1505.04597", "anchor_text": "U-net: Convolutional networks for biomedical image segmentation"}, {"url": "https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28", "anchor_text": "MICCAI 2015. Cham: Springer International Publishing"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Deep residual learning for image recognition"}, {"url": "https://ieeexplore.ieee.org/document/7780459/authors#authors", "anchor_text": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"}, {"url": "https://towardsdatascience.com/road-surface-classification-150f9874faef", "anchor_text": "Road Surface ClassificationAn approach for road surface type and quality classificationtowardsdatascience.com"}, {"url": "https://medium.com/analytics-vidhya/visual-depth-estimation-by-two-different-sensors-36f756d1575a", "anchor_text": "Visual depth estimation by two different sensorsStereo disparity map and point cloud from Passive and Active vision low-cost sensorsmedium.com"}, {"url": "https://medium.com/tag/road-surface?source=post_page-----4d65b045245---------------road_surface-----------------", "anchor_text": "Road Surface"}, {"url": "https://medium.com/tag/semantic-segmentation?source=post_page-----4d65b045245---------------semantic_segmentation-----------------", "anchor_text": "Semantic Segmentation"}, {"url": "https://medium.com/tag/potholes?source=post_page-----4d65b045245---------------potholes-----------------", "anchor_text": "Potholes"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----4d65b045245---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----4d65b045245---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d65b045245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----4d65b045245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4d65b045245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----4d65b045245---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4d65b045245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=post_page-----4d65b045245--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1ce9b89b9a0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=post_page-1ce9b89b9a0f----4d65b045245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc7836133181f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&newsletterV3=1ce9b89b9a0f&newsletterV3Id=c7836133181f&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----4d65b045245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Written by Thiago Rateke"}, {"url": "https://medium.com/@thiagortk/followers?source=post_page-----4d65b045245--------------------------------", "anchor_text": "33 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://www.linkedin.com/in/thiagortk/", "anchor_text": "https://www.linkedin.com/in/thiagortk/"}, {"url": "https://www.researchgate.net/profile/Thiago_Rateke", "anchor_text": "https://www.researchgate.net/profile/Thiago_Rateke"}, {"url": "https://github.com/thiagortk", "anchor_text": "https://github.com/thiagortk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1ce9b89b9a0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=post_page-1ce9b89b9a0f----4d65b045245---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc7836133181f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-semantic-segmentation-4d65b045245&newsletterV3=1ce9b89b9a0f&newsletterV3Id=c7836133181f&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----4d65b045245---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/road-surface-classification-150f9874faef?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Thiago Rateke"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/road-surface-classification-150f9874faef?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Road Surface ClassificationAn approach for road surface type and quality classification"}, {"url": "https://towardsdatascience.com/road-surface-classification-150f9874faef?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "\u00b77 min read\u00b7Jun 9, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F150f9874faef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-classification-150f9874faef&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----150f9874faef----0-----------------clap_footer----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/road-surface-classification-150f9874faef?source=author_recirc-----4d65b045245----0---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F150f9874faef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Froad-surface-classification-150f9874faef&source=-----4d65b045245----0-----------------bookmark_preview----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----4d65b045245----1---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----4d65b045245----1-----------------bookmark_preview----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----4d65b045245----2---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----4d65b045245----2-----------------bookmark_preview----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/visual-depth-estimation-by-two-different-sensors-36f756d1575a?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Thiago Rateke"}, {"url": "https://medium.com/analytics-vidhya?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Analytics Vidhya"}, {"url": "https://medium.com/analytics-vidhya/visual-depth-estimation-by-two-different-sensors-36f756d1575a?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "Visual depth estimation by two different sensorsStereo disparity map and point cloud from Passive and Active vision low-cost sensors"}, {"url": "https://medium.com/analytics-vidhya/visual-depth-estimation-by-two-different-sensors-36f756d1575a?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": "\u00b79 min read\u00b7Jul 25, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fanalytics-vidhya%2F36f756d1575a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fvisual-depth-estimation-by-two-different-sensors-36f756d1575a&user=Thiago+Rateke&userId=1ce9b89b9a0f&source=-----36f756d1575a----3-----------------clap_footer----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/visual-depth-estimation-by-two-different-sensors-36f756d1575a?source=author_recirc-----4d65b045245----3---------------------fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F36f756d1575a&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fvisual-depth-estimation-by-two-different-sensors-36f756d1575a&source=-----4d65b045245----3-----------------bookmark_preview----fcdd03fe_3d92_43bd_83c5_73f615e9e0f8-------", "anchor_text": ""}, {"url": "https://medium.com/@thiagortk?source=post_page-----4d65b045245--------------------------------", "anchor_text": "See all from Thiago Rateke"}, {"url": "https://towardsdatascience.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://aaweg-i.medium.com/?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Aaweg-I"}, {"url": "https://medium.com/aaweg-i-nterview?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Aaweg Interview"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Can you explain Jaccard\u2019s Index? How does it differ from Dice Coefficient?In object detection, there are two distinct tasks to measure:"}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b76 min read\u00b7Nov 27, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Faaweg-i-nterview%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&user=Aaweg-I&userId=5a024f90bf10&source=-----861c4a496b2b----0-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://medium.com/aaweg-i-nterview/computer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F861c4a496b2b&operation=register&redirect=https%3A%2F%2Fmedium.com%2Faaweg-i-nterview%2Fcomputer-vision-iou-jaccards-index-dice-score-coefficient-861c4a496b2b&source=-----4d65b045245----0-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----4d65b045245----1-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----4d65b045245----0---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----4d65b045245----0-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----1-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----4d65b045245----1---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----4d65b045245----1-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----2-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----4d65b045245----2---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----4d65b045245----2-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/extracting-gps-data-from-photos-using-python-e8be352acf15?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://nathanthandoko.medium.com/?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://nathanthandoko.medium.com/?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Nathan Timothy Handoko"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/extracting-gps-data-from-photos-using-python-e8be352acf15?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "Extracting GPS Data from Photos using PythonA very simple and straight-forward guide to extract metadata"}, {"url": "https://towardsdatascience.com/extracting-gps-data-from-photos-using-python-e8be352acf15?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": "\u00b74 min read\u00b7Dec 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe8be352acf15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-gps-data-from-photos-using-python-e8be352acf15&user=Nathan+Timothy+Handoko&userId=dac8f7cc03cf&source=-----e8be352acf15----3-----------------clap_footer----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/extracting-gps-data-from-photos-using-python-e8be352acf15?source=read_next_recirc-----4d65b045245----3---------------------489635b6_8d46_4779_ae30_14b0819711b9-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe8be352acf15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-gps-data-from-photos-using-python-e8be352acf15&source=-----4d65b045245----3-----------------bookmark_preview----489635b6_8d46_4779_ae30_14b0819711b9-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4d65b045245--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----4d65b045245--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}