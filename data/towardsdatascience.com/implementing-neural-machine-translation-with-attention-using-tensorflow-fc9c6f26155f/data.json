{"url": "https://towardsdatascience.com/implementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f", "time": 1683003981.061216, "path": "towardsdatascience.com/implementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f/", "webpage": {"metadata": {"title": "Implementing Neural Machine Translation with Attention mechanism using Tensorflow | by Renu Khandelwal | Towards Data Science", "h1": "Implementing Neural Machine Translation with Attention mechanism using Tensorflow", "description": "In this article, you will learn how to implement sequence to sequence(seq2seq) neural machine translation(NMT) using Bahdanau\u2019s Attention mechanism. We will implement the code in Tensorflow 2.0 using\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a", "anchor_text": "Sequence to Sequence Model using Attention Mechanism", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/intuitive-explanation-of-neural-machine-translation-129789e3c59f", "anchor_text": "An Intuitive explanation of Neural Machine Translation", "paragraph_index": 2}, {"url": "http://www.manythings.org/anki/.", "anchor_text": "here", "paragraph_index": 7}, {"url": "http://www.manythings.org/anki/", "anchor_text": "here", "paragraph_index": 9}], "all_paragraphs": ["In this article, you will learn how to implement sequence to sequence(seq2seq) neural machine translation(NMT) using Bahdanau\u2019s Attention mechanism. We will implement the code in Tensorflow 2.0 using Gated Recurrent Unit(GRU).", "Sequence to Sequence Model using Attention Mechanism", "An Intuitive explanation of Neural Machine Translation", "Neural Machine Translation(NMT) is the task of converting a sequence of words from a source language, like English, to a sequence of words to a target language like Hindi or Spanish using deep neural networks.", "NMT is implemented using a sequence to sequence(seq2seq) model consisting of Encoder and Decoder. The Encoder encodes the complete information of the source sequence into a single real-valued vector, also known as the context vector, which is passed to the Decoder to produce an output sequence, which is the target language like Hindi or Spanish.", "The context vector has the responsibility to summarize the entire input sequence into a single vector, which is inefficient, so we use the Attention mechanism.", "The basic idea of the Attention mechanism is to avoid attempting to learning a single vector representation for each sentence; instead, it pays attention to specific input vectors of the input sequence based on the attention weights.", "For implementation purposes, we will use English as the source language and Spanish as the target language. The code will be implemented using TensorFlow 2.0, and data can be downloaded from here.", "Steps for implementing NMT with an Attention mechanism", "Read the file for English-Spanish translations that can be downloaded from here.", "I have stored the file in \u201cspa.txt.\u201d", "We apply the following text cleaning", "Let\u2019s take one of the sentences in English and preprocess them", "Preprocessing the source and target sentences to have word pairs in the format: [ENGLISH, SPANISH]", "We need to vectorize the text corpus where the text is converted into a sequence of integers.", "We first create the tokenizer and then apply the tokenizer on the source sentences", "We now transform each word in the source sentences into a sequence of integers by replacing the word with its corresponding integer value.", "Only words known by the tokenizer will be taken into account", "We need to create the sequences with the same length, so we post pad sequences that are shorter in length with \u201c0.\u201d", "Tokenize the target sentences in a similar way", "Split the dataset into a test and train. 80% of data is used for training and 20% for testing the model", "When the dataset is big, we want to create the dataset in memory to be efficient. We will use tf.data.Dataset.from_tensor_slices() method to get slices of the array in the form of an object.", "Dataset is created in batches of 64.", "We iterate through all the elements in the dataset. The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode", "Each batch of source data will be of the size (BATCH_SIZE, max_source_length), and a batch size of target data will be (BATCH_SIZE, max_target_length). In our case the max-source_length is 11 and max_target_length is 16", "Difference between seq2seq model with attention and seq2seq model without attention", "setting a few parameters for the model", "The Encoder takes the input as the source tokens, passes them to an embedding layer for the dense representation of the vector, which is then passed to GRU.", "Set return_sequences and return_state as True for the GRU. By default, return_sequneces are set to False. When return_sequences are set to true, then it returns the entire sequence of outputs from all the units in the Encoder. When return_sequences are set to False, then we only return the hidden state of the last encoder unit.", "seq2seq without Attention will have return_sequences of the Encoder set to False. Seq2seq with Attention will have return_sequences set to True for the Encoder.", "To return the internal state of GRU, we set the retrun_state to True", "Testing the Encoder class and printing the dimensions of the Encoder\u2019s output and hidden state", "We will implement these simplified equations in the Attention layer", "Test the Bahdanau attention layer with ten units", "The Decoder has an embedding layer, a GRU layer, and a fully connected layer.", "To predict the target word Decoder uses", "We use Adam optimizer here; you can try Rmsprop too", "Use SparseCategoricalCrossentropy to compute the loss between the actual and the predicted output.", "If the output is a one-hot encoded vector, then use categorical_crossentropy. Use SparseCategoricalCrossentropy loss for word2index vector containing integers.", "SparseCategoricalCrossentropy is computationally and memory-efficient as it uses a single integer rather like [3] than the whole vector [0 0 0 1]", "To train the dataset using the Encoder-Decoder model", "Tensorflow keeps track of every gradient for every computation on every tf.Variable. To train, we use gradient tape as we need to control the areas of code where we need gradient information. For seq2seq with the Attention mechanism, we calculate the gradient for the Decoder\u2019s output only.", "Training the Encoder-Decoder model with attention using multiple epochs", "Making inferences is similar to training except that we do not know the actual word that is used in Teacher Forcing, so we pass the predicted word from the previous time step as an input to the Decoder.", "We calculate the Attention weights at each time step as it helps to pay attention to the most relevant information in the source sequence that is used to make the prediction.", "We stop predicting the words either when we have reached the max target sentence length, or we have encountered the \u201cstop_\u201d tag.", "Function to plot the Attention weights between the source words and target words. The plot will help us understand which source word was given greater attention to predict the target word", "To translate the source sentence to the target language, we make a call to the evaluate function which creates the Encoder, Decoder and Attention layer", "The attention plot for the translated sentence", "During translation, we see that \u201c going\u201d was given greater attention to predict \u201cvoy\u201d, similarly \u201cwork\u201d was given higher attention to predict \u201ctrabajar\u201d", "A Technology Enthusiast who constantly seeks out new challenges by exploring cutting-edge technologies to make the world a better place!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffc9c6f26155f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://arshren.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Renu Khandelwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31b07253bc35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=post_page-31b07253bc35----fc9c6f26155f---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9c6f26155f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=-----fc9c6f26155f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc9c6f26155f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=-----fc9c6f26155f---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@aaronburden?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Aaron Burden"}, {"url": "https://unsplash.com/s/photos/diiferent-language?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a", "anchor_text": "Sequence to Sequence Model using Attention Mechanism"}, {"url": "https://towardsdatascience.com/intuitive-explanation-of-neural-machine-translation-129789e3c59f", "anchor_text": "An Intuitive explanation of Neural Machine Translation"}, {"url": "http://www.manythings.org/anki/.", "anchor_text": "here"}, {"url": "http://www.manythings.org/anki/", "anchor_text": "here"}, {"url": "https://github.com/arshren/NMT-with-Attention/blob/master/NMT%20with%20Attention%20trained%20with%2020%20epochs.ipynb", "anchor_text": "Github"}, {"url": "https://arxiv.org/pdf/1409.0473.pdf", "anchor_text": "https://arxiv.org/pdf/1409.0473.pdf"}, {"url": "https://www.tensorflow.org/tutorials/text/nmt_with_attention", "anchor_text": "https://www.tensorflow.org/tutorials/text/nmt_with_attention"}, {"url": "https://www.tensorflow.org/guide/keras/rnn", "anchor_text": "https://www.tensorflow.org/guide/keras/rnn"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----fc9c6f26155f---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----fc9c6f26155f---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-translation?source=post_page-----fc9c6f26155f---------------machine_translation-----------------", "anchor_text": "Machine Translation"}, {"url": "https://medium.com/tag/attention-mechanism?source=post_page-----fc9c6f26155f---------------attention_mechanism-----------------", "anchor_text": "Attention Mechanism"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----fc9c6f26155f---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9c6f26155f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=-----fc9c6f26155f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc9c6f26155f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=-----fc9c6f26155f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc9c6f26155f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31b07253bc35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=post_page-31b07253bc35----fc9c6f26155f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1cb44d62203&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&newsletterV3=31b07253bc35&newsletterV3Id=b1cb44d62203&user=Renu+Khandelwal&userId=31b07253bc35&source=-----fc9c6f26155f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Written by Renu Khandelwal"}, {"url": "https://arshren.medium.com/followers?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "5.9K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F31b07253bc35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&user=Renu+Khandelwal&userId=31b07253bc35&source=post_page-31b07253bc35----fc9c6f26155f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1cb44d62203&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f&newsletterV3=31b07253bc35&newsletterV3Id=b1cb44d62203&user=Renu+Khandelwal&userId=31b07253bc35&source=-----fc9c6f26155f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Renu Khandelwal"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Convolutional Neural Network: Feature Map and Filter VisualizationLearn how Convolutional Neural Networks understand images."}, {"url": "https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "\u00b78 min read\u00b7May 18, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff75012a5a49c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c&user=Renu+Khandelwal&userId=31b07253bc35&source=-----f75012a5a49c----0-----------------clap_footer----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c?source=author_recirc-----fc9c6f26155f----0---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff75012a5a49c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c&source=-----fc9c6f26155f----0-----------------bookmark_preview----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----fc9c6f26155f----1---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----fc9c6f26155f----1-----------------bookmark_preview----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----fc9c6f26155f----2---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----fc9c6f26155f----2-----------------bookmark_preview----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/unleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Renu Khandelwal"}, {"url": "https://arshren.medium.com/unleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "Unleashing an End-to-End Predictive Model Pipeline: A Step-by-Step GuideA Detailed ML Ops Pipeline for an End-to-End Predictive Model for Tabular Data"}, {"url": "https://arshren.medium.com/unleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": "\u00b712 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F2515a65cd8f6&operation=register&redirect=https%3A%2F%2Farshren.medium.com%2Funleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6&user=Renu+Khandelwal&userId=31b07253bc35&source=-----2515a65cd8f6----3-----------------clap_footer----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/unleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6?source=author_recirc-----fc9c6f26155f----3---------------------d4830131_3a5f_402c_97a1_1958dc3fdc64-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2515a65cd8f6&operation=register&redirect=https%3A%2F%2Farshren.medium.com%2Funleashing-an-end-to-end-predictive-model-pipeline-a-step-by-step-guide-2515a65cd8f6&source=-----fc9c6f26155f----3-----------------bookmark_preview----d4830131_3a5f_402c_97a1_1958dc3fdc64-------", "anchor_text": ""}, {"url": "https://arshren.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "See all from Renu Khandelwal"}, {"url": "https://towardsdatascience.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----0-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----fc9c6f26155f----0-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----fc9c6f26155f----1-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Building An LSTM Model From Scratch In PythonHow to build a basic LSTM using Basic Python libraries"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b717 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&user=Youssef+Hosni&userId=859af34925b7&source=-----1dedd89de8fe----0-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----fc9c6f26155f----0---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&source=-----fc9c6f26155f----0-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@weiyunna91?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "YUNNA WEI"}, {"url": "https://medium.com/trigger-ai?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Efficient Data+AI Stack"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "MLOps in Practice \u2014 Machine Learning (ML) model deployment patterns (Part 1)Machine Learning (ML) model serving and deployment is one of the most critical components of any solid ML solution architecture. This\u2026"}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b711 min read\u00b7Jan 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftrigger-ai%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&user=YUNNA+WEI&userId=4b47aa84fc4&source=-----ce7cb575feda----1-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/trigger-ai/mlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda?source=read_next_recirc-----fc9c6f26155f----1---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce7cb575feda&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ftrigger-ai%2Fmlops-in-practice-machine-learning-ml-model-deployment-patterns-part-1-ce7cb575feda&source=-----fc9c6f26155f----1-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----fc9c6f26155f----2---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----fc9c6f26155f----2-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Yujian Tang"}, {"url": "https://medium.com/plain-simple-software?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Plain Simple Software"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "Long Short Term Memory in KerasHow to create an LSTM model with Tensorflow Keras"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": "\u00b76 min read\u00b7Dec 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplain-simple-software%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&user=Yujian+Tang&userId=1c4e6640433f&source=-----acdf61c056da----3-----------------clap_footer----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----fc9c6f26155f----3---------------------5aff6068_51fc_4106_98c5_5aa4a2f0309d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&source=-----fc9c6f26155f----3-----------------bookmark_preview----5aff6068_51fc_4106_98c5_5aa4a2f0309d-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----fc9c6f26155f--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}