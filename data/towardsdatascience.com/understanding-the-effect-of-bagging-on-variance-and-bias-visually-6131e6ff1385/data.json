{"url": "https://towardsdatascience.com/understanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385", "time": 1683002271.302343, "path": "towardsdatascience.com/understanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385/", "webpage": {"metadata": {"title": "Understanding the Effect of Bagging on Variance and Bias visually | by Dr. Robert K\u00fcbler | Towards Data Science", "h1": "Understanding the Effect of Bagging on Variance and Bias visually", "description": "Giving an intuition on why Bagging algorithms like Random Forests actually work and displaying the effects of them in an easy and approachable way."}, "outgoing_paragraph_urls": [{"url": "http://www.cs.huji.ac.il/~shais", "anchor_text": "Shai Shalev-Shwartz", "paragraph_index": 21}, {"url": "https://cs.uwaterloo.ca/~shai", "anchor_text": "Shai Ben-David", "paragraph_index": 21}, {"url": "https://arxiv.org/abs/1407.7502", "anchor_text": "Understanding Random Forests \u2014 From Theory to Practice", "paragraph_index": 55}, {"url": "https://www.cse.huji.ac.il/~shais/UnderstandingMachineLearning/", "anchor_text": "Understanding Machine Learning: From Theory to Algorithm", "paragraph_index": 56}, {"url": "https://www.latex-project.org/", "anchor_text": "LaTeX", "paragraph_index": 57}, {"url": "https://www.python.org/", "anchor_text": "Python", "paragraph_index": 57}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib", "paragraph_index": 57}, {"url": "https://numpy.org/", "anchor_text": "numpy", "paragraph_index": 57}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn", "paragraph_index": 57}, {"url": "https://www.researchgate.net/profile/Patrick_Bormann2", "anchor_text": "Dr. Patrick Bormann", "paragraph_index": 58}, {"url": "https://dr-robert-kuebler.medium.com/membership", "anchor_text": "via this link", "paragraph_index": 62}, {"url": "https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/", "anchor_text": "LinkedIn", "paragraph_index": 65}], "all_paragraphs": ["There exist a vast amount of great articles describing how Bagging methods like random forests work on an algorithmic level and why Bagging is a good thing to do. Usually, the essence is the following:", "\u201cYou train a lot of decision trees on different parts of the training set and average their predictions into a final prediction. The prediction gets better, because the variance of the random forest is smaller compared to the variance of a single decision tree. (dartboard.png)\u201d", "Of course, I am paraphrasing here. The articles include great pictures, code, and many more thoughts. But what I often miss is a good intuition on why Bagging is a good idea and how to see the variance reduction in action, using a real dataset.", "Thus, in this article, I want to address both of these shortcomings and give intuitive reasoning why the random forest algorithm works and how you can see the improvement in the variance graphically. You can consider this article an exploration of these two topics that goes deeper than the average article about the Bias-Variance Dilemma while being not as deep as a fully-fledged research paper. Still, I will provide links to resources that I find helpful, so you can go into greater depth whenever desired.", "I try to keep the math level quite understandable to allow people without a mathematics major to follow along, while also giving some high-level ideas and illustrations that also mathematically involved people can enjoy.", "Still, I will not explain how decision trees, random forests, and all the other models mentioned work in detail since this has been covered numerous times already, as described. I will only explain the very high-level ideas, starting with decision trees.", "Disclaimer: I will only talk about vanilla decision trees here. We do not consider pruning in the rest of this article. The trees can grow arbitrarily deep.", "A decision tree with k leaves is a model of the form", "meaning that a decision tree is a piecewise constant function with a real value w in a region R of the feature space. Here x is from a feature space X and y is the corresponding label from an output space Y. The constraints on the R\u2019s are that", "Now, that we have established that, let us examine why a decision tree is called a high-variance algorithm, while for example linear regression is considered low-variance.", "For a quick recap, linear regression models have the following form:", "where the weights w are real numbers and d is the dimension of the samples, i.e. the number of features.", "For comparing the variance of these models, we have to take one step back and think about what a learning problem actually is.", "Usually, we are given a fixed amount of samples (learning set, training samples), let our algorithm do some magic and fit all the necessary parameters and in the end, we can predict values for unseen samples. However, this is a quite rigid view of things.", "In Learning Theory, we model the training set as coming from a distribution D over the space X\u00d7Y, where X is the feature space and Y is the output space. We sample a training set L (and also a validation and test set) of size n from the distribution:", "Imagine a distribution to be a black box with a button; if you hit the button once, you get a random sample (x\u2081, y\u2081) from the distribution. Hit it again and you get another sample (x\u2082, y\u2082), independent of the one(s) before. Repeat, until you have enough samples to work with.", "Then we can use the n data points from L to train our model. This outputs a function f with f(x\u1d62)\u2248y\u1d62 for all (x\u1d62, y\u1d62) in the sample L (if our model is any good). This approach ensures that the performance of the model is okay on the training set.", "But now imagine that we query n new samples from the distribution D and use these as a training set L\u2019. Let us call the model resulting from the training on this new set g. This new model g will also meet the condition g(x\u1d62\u2019)\u2248y\u1d62\u2019 for all (x\u1d62\u2019, y\u1d62\u2019) in L\u2019.", "Now, since L\u2019 consists of different points (x\u1d62\u2019, y\u1d62\u2019), the new model g will have a different output shape than f. The models f and g might or might not differ a lot, depending on how different L and L\u2019 were, how the models were created and which randomness the algorithms used internally.", "If for a fixed algorithm (e.g. \u201cdecision tree\u201d) the models for different training sets L and L\u2019 tend to differ a lot, we call this algorithm a high-variance one.", "Of course, this is no precise definition, but this is also unnecessary for this article. In the following, we will use graphics to determine if an algorithm has a higher variance than another algorithm.", "If you are interested in the mathematics (cheers!), I can recommend the dissertation of Gilles Louppe [1], and the book of Shai Shalev-Shwartz and Shai Ben-David [2] which explains the theoretical foundations of machine learning in great detail.", "Let us get back to our comparison of decision trees and linear regression. We will use the following running example: X=[0, 10] and Y=\u211d, i.e. the feature space is of dimension 1 and this one feature can take real values between 0 and 10, while the labels can take any real value.", "In our example, we define a distribution D doing the following: the feature x is chosen uniformly from 0 to 10 and the label y is computed explicitly via the hidden function", "The function h describes the underlying structure of the labels, it is the truth that we want to learn about the labels. We call it hidden since we will not give this information to the algorithms. They have to figure it out on their own. :)", "Following the reasoning above, if we query our distribution D three times for 10 samples each time we might end up with the following three training sets:", "Let us use the rightmost training set and plot the results after applying decision trees and linear regression.", "Let us conduct the same experiment 3000 times for 3000 independently sampled training sets, each of size 10 again. On the left side, we see the results of the decision trees and on the right side, there are the linear regression results stacked on top of each other.", "Here we can see that the decision trees (left side) fit the data quite well on average. People also refer to this property as decision trees having a low bias. Meanwhile, for linear regression on the right side, the model clearly can not capture the complex pattern of the underlying label structure. We say that linear regression has high bias, in this case, it is not able to learn the truth.", "Yet, if you consider the vertical width of these black tubes, the ones stemming from the decision trees are wider than the linear regression ones on the right. This means that the decision tree predictions wiggle around more extremely than the linear regression predictions when re-sampling the training dataset, which we refer to as decision trees having a high variance and linear regression having a low variance.", "What we actually want are algorithms with a low bias (they hit the truth on average) and low variance (they do not wiggle around the truth too much). Luckily, there are numerous ways to lower the bias (e.g. with a technique called Boosting) and also other ways to lower the variance. The latter can be achieved with the so-called Bagging. The good thing about Bagging is, that it also does not increase the bias again, which we will motivate in the following section.", "That is why the effect of using Bagging together with linear regression is low: You can not decrease the bias via Bagging, but with Boosting. The funny thing is that it has proven useful to choose decision trees together with Boosting, too. In this case, heavily pruned decision trees, which also have a lower bias, are used.", "In this section, we will see what Bagging does, why it works, and how to see the decrease in variance.", "Imagine we have access to the standard normal distribution, in particular, the mean of an observed value is 0 and the variance is 1. Let us assume that we love to see values around 0 (just as we love to see prediction functions around 3sin(x)+x). But the variance of 1 is too large for our taste (just like the width of the black tubes) and we search for a way to decrease it. An easy way to do it is to sample more values from the standard normal distribution and take the average of them. The following result is well-known and easy to verify:", "Thus, by averaging, we simulate drawing from another normal distribution with the same mean, but with a smaller variance, if \u03c1 is not too big. This is great because we get values closer to zero with a higher probability than before!", "In the special case of independent random variables (\u03c1=0) and b=100, the variance drops from 1 to 0.01, for example. The result is the following:", "Attention: If the random variables X are all correlated with value 1, this implies that \u03c1=(b-1)/b, i.e. the variance of the average will be 1 again. This corresponds to the case where each sample is, in fact, the same number. Averaging over a lot of the same numbers does not give us any new information, so this is as good as drawing only a single value.", "In the best case, we can average independent samples. The more correlated they are, the more useless they become in the averaging process.", "Now, the useful insight is that we can do the same with prediction models. Running a decision tree algorithm on a randomly drawn training dataset gives us a model, which is essentially sampling a function from a distribution. Averaging these models gives us another model (e.g. a random forest) with the same bias, but with lower variance. This ensemble model is closer to the truth than a single decision tree on average.", "But the question is: How badly are these functions correlated? Consider the following: If we come across a dataset, we can fit a single decision tree on it. So far, so good. But, if we do it again, the result will (nearly) be the same in the case of decision trees. This means that the functions that we sample this way are highly correlated (\u03c1\u22481) and do not improve upon a single decision tree.", "It is not necessarily exactly 1 since the decision tree algorithms occasionally have to break ties which can be done in a random manner, but since this is the only source of randomness it does not produce trees that are fundamentally different from each other.", "Somehow we have to decorrelate these trees, and we will see how to do this in the next section.", "Random forests were invented by Leo Breiman [3]. The idea here is to fit numerous decision trees on the training set in a special way, giving an equally large number of tree models (=functions). Afterward, these trees are combined into a single model, e.g. by averaging their outputs for any given input x, making it a special Bagging method. This results in a model with lower variance, similar to what we have seen before with normally distributed random variables.", "The idea behind getting many and not maximally correlated trees is the following:", "Having two sources of randomization helps to reduce the correlation between different trees even more than using only one of them. Feel free to add more, if you happen to design a new Bagging algorithm! There are various other methods to combine single decision trees, for example Extremely Randomized Trees by Geurts et al. [4].", "Let us draw 10 samples from our distribution again and fit a decision tree and a random forest containing 100 decision trees. We repeat this procedure 1000 times and get the following picture:", "We see that the vertical width of the red tube, formed by the random forests is smaller than the decision trees\u2019 black tube. So, random forests have a lower variance than decision trees, as expected. Furthermore, it seems that the averages (the middle) of the two tubes are the same which means that the process of averaging did not change the bias. We still hit the underlying true function 3sin(x)+x quite well.", "Note that the random forest algorithm could not show its full potential here since we have used a dataset with only one feature that every single decision tree has to use. So the 100 decision trees inside the random forest can only differ among the training samples that were chosen to grow each tree. In this case, the random forest algorithm collapses into an easier Bagging algorithm that only uses different training samples for each tree.", "If we want to widen the gap in variances while still being able to interpret the results visually, we have to move to a 2-dimensional feature space. This allows the random forest algorithm to choose exactly one of the two features available at random at each step within the algorithm.", "A random dataset comprising 50 points can look like this:", "Now, let us look at how the variance behaves for decision trees and random forests in this context. Enjoy the results!", "Let us first start with the case of decision trees. We use 9 different training datasets for growing 9 different trees.", "Now, let us do the same with random forests. Here, we train 100 decision trees per random forests again on a different subset of samples and use only one of the two given features at random! Each model is trained on 50 random sample points.", "It has become evident that high-variance algorithms change their outcome (the model) rapidly when the training set changes. This is bad since we can never know how far away our concrete model is from the truth, even if the bias of our model is zero.", "But we learned how to increase our chance of getting a good model using Bagging. We have also gotten an intuition on why Bagging lowers the variance while leaving the bias unchanged, and we have seen these results in a lot of illustrations.", "[1] G. Louppe, Understanding Random Forests \u2014 From Theory to Practice (2014), Dissertation", "[2] S. Shalev-Shwartz and S. Ben-David, Understanding Machine Learning: From Theory to Algorithm (2014), Cambridge University Press", "I created all formulas using LaTeX. For the other graphics, I used the Python library matplotlib together with numpy. For the model training, I used the scikit-learn.", "My thanks go to Dr. Patrick Bormann for proofreading and for giving a lot of helpful advice on improving my article. Also thanks to Andre Esser for his help!", "Please think of me when you are starting to generate money with this decision tree mosaic art. \ud83d\ude00", "I hope that you learned something new, interesting, and useful today. Thanks for reading!", "As the last point, if you", "why not do it via this link? This would help me a lot! \ud83d\ude0a", "To be transparent, the price for you does not change, but about half of the subscription fees go directly to me.", "Thanks a lot, if you consider supporting me!", "If you have any questions, write me on LinkedIn!", "Studied Mathematics, graduated in Cryptanalysis, working as a Senior Data Scientist. Interested in algorithms, probability theory, and machine learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6131e6ff1385&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@robertkuebler", "anchor_text": "Mastodon"}, {"url": "https://kuebler.ai/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Dr. Robert K\u00fcbler"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d6b5fb431bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=post_page-6d6b5fb431bf----6131e6ff1385---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6131e6ff1385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----6131e6ff1385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6131e6ff1385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=-----6131e6ff1385---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://dribbble.com/tinati", "anchor_text": "Tinati K\u00fcbler"}, {"url": "http://www.cs.huji.ac.il/~shais", "anchor_text": "Shai Shalev-Shwartz"}, {"url": "https://cs.uwaterloo.ca/~shai", "anchor_text": "Shai Ben-David"}, {"url": "https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables", "anchor_text": "also normally distributed"}, {"url": "https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_(Bienaym%C3%A9_formula)", "anchor_text": "Bienaym\u00e9 Formula"}, {"url": "https://en.wikipedia.org/wiki/Covariance", "anchor_text": "covariances"}, {"url": "https://arxiv.org/abs/1407.7502", "anchor_text": "Understanding Random Forests \u2014 From Theory to Practice"}, {"url": "https://www.cse.huji.ac.il/~shais/UnderstandingMachineLearning/", "anchor_text": "Understanding Machine Learning: From Theory to Algorithm"}, {"url": "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf", "anchor_text": "Random Forests"}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.7485&rep=rep1&type=pdf", "anchor_text": "Extremely Randomized Trees"}, {"url": "https://www.latex-project.org/", "anchor_text": "LaTeX"}, {"url": "https://www.python.org/", "anchor_text": "Python"}, {"url": "https://matplotlib.org/", "anchor_text": "matplotlib"}, {"url": "https://numpy.org/", "anchor_text": "numpy"}, {"url": "https://scikit-learn.org/", "anchor_text": "scikit-learn"}, {"url": "https://www.researchgate.net/profile/Patrick_Bormann2", "anchor_text": "Dr. Patrick Bormann"}, {"url": "https://dr-robert-kuebler.medium.com/membership", "anchor_text": "via this link"}, {"url": "https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6131e6ff1385---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/random-forest?source=post_page-----6131e6ff1385---------------random_forest-----------------", "anchor_text": "Random Forest"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----6131e6ff1385---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/bias-variance-tradeoff?source=post_page-----6131e6ff1385---------------bias_variance_tradeoff-----------------", "anchor_text": "Bias Variance Tradeoff"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6131e6ff1385---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6131e6ff1385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----6131e6ff1385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6131e6ff1385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----6131e6ff1385---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6131e6ff1385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d6b5fb431bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=post_page-6d6b5fb431bf----6131e6ff1385---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F11fae4bef4b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&newsletterV3=6d6b5fb431bf&newsletterV3Id=11fae4bef4b2&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----6131e6ff1385---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Written by Dr. Robert K\u00fcbler"}, {"url": "https://kuebler.ai/followers?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "3K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6d6b5fb431bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=post_page-6d6b5fb431bf----6131e6ff1385---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F11fae4bef4b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-effect-of-bagging-on-variance-and-bias-visually-6131e6ff1385&newsletterV3=6d6b5fb431bf&newsletterV3Id=11fae4bef4b2&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----6131e6ff1385---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/convenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Dr. Robert K\u00fcbler"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/convenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Convenient Bayesian Marketing Mix Modeling with PyMC MarketingA new and shiny library from the PyMC team worth trying out"}, {"url": "https://towardsdatascience.com/convenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "\u00b76 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8b02a9a9c4aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----8b02a9a9c4aa----0-----------------clap_footer----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/convenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa?source=author_recirc-----6131e6ff1385----0---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8b02a9a9c4aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fconvenient-bayesian-marketing-mix-modeling-with-pymc-marketing-8b02a9a9c4aa&source=-----6131e6ff1385----0-----------------bookmark_preview----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6131e6ff1385----1---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----6131e6ff1385----1-----------------bookmark_preview----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6131e6ff1385----2---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6131e6ff1385----2-----------------bookmark_preview----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Dr. Robert K\u00fcbler"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "How to Build Popularity-Based Recommenders with PolarsBasic recommenders that are easy to understand and implement, as well as fast to train"}, {"url": "https://towardsdatascience.com/how-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": "\u00b77 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcc7920ad3f68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68&user=Dr.+Robert+K%C3%BCbler&userId=6d6b5fb431bf&source=-----cc7920ad3f68----3-----------------clap_footer----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68?source=author_recirc-----6131e6ff1385----3---------------------d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc7920ad3f68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-popularity-based-recommenders-with-polars-cc7920ad3f68&source=-----6131e6ff1385----3-----------------bookmark_preview----d3e64de8_85cf_4f47_b7f8_a95c1a9d5801-------", "anchor_text": ""}, {"url": "https://kuebler.ai/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "See all from Dr. Robert K\u00fcbler"}, {"url": "https://towardsdatascience.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----6131e6ff1385----0-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@theDrewDag?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Andrea D'Agostino"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "How to prepare data for K-fold cross-validation in Machine LearningCross-validation is the first technique to use to avoid overfitting and data leakage when we want to train a predictive model on our data."}, {"url": "https://towardsdatascience.com/how-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b74 min read\u00b7Dec 19, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F924a44ec322c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c&user=Andrea+D%27Agostino&userId=4e8f67b0b09b&source=-----924a44ec322c----1-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F924a44ec322c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-prepare-data-for-k-fold-cross-validation-in-machine-learning-924a44ec322c&source=-----6131e6ff1385----1-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6131e6ff1385----0---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----6131e6ff1385----0-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://rukshanpramoditha.medium.com/?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Rukshan Pramoditha"}, {"url": "https://medium.com/data-science-365?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Data Science 365"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Determining the Right Batch Size for a Neural Network to Get Better and Faster ResultsGuidelines for choosing the right batch size to maintain optimal training speed and accuracy while saving computer resources"}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b74 min read\u00b7Sep 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdata-science-365%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----7a8662830f15----1-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/data-science-365/determining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15?source=read_next_recirc-----6131e6ff1385----1---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a8662830f15&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdata-science-365%2Fdetermining-the-right-batch-size-for-a-neural-network-to-get-better-and-faster-results-7a8662830f15&source=-----6131e6ff1385----1-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@samuel.flender?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@samuel.flender?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Samuel Flender"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Class Imbalance in Machine Learning Problems: A Practical GuideFive lessons from the trenches of applied data science"}, {"url": "https://towardsdatascience.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b78 min read\u00b7Oct 3, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fb81eee0041&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041&user=Samuel+Flender&userId=ce56d9dcd568&source=-----4fb81eee0041----2-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/class-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041?source=read_next_recirc-----6131e6ff1385----2---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fb81eee0041&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-in-machine-learning-problems-a-practical-guide-4fb81eee0041&source=-----6131e6ff1385----2-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----3-----------------clap_footer----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6131e6ff1385----3---------------------93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6131e6ff1385----3-----------------bookmark_preview----93f52bd7_5cb8_4cdb_82ad_e2b5634c7b25-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----6131e6ff1385--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}