{"url": "https://towardsdatascience.com/top-down-view-at-reinforcement-learning-f4a8b35ebf9a", "time": 1682999812.284766, "path": "towardsdatascience.com/top-down-view-at-reinforcement-learning-f4a8b35ebf9a/", "webpage": {"metadata": {"title": "Top Down View at Reinforcement Learning | by Ziad SALLOUM | Towards Data Science", "h1": "Top Down View at Reinforcement Learning", "description": "Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com When you are new to Reinforcement Learning you will no doubt be bombarded with weird terms\u2026"}, "outgoing_paragraph_urls": [{"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com", "paragraph_index": 0}, {"url": "https://medium.com/@zsalloum/basics-of-reinforcement-learning-the-easy-way-fb3a0a44f30e", "anchor_text": "Markov Decision Process", "paragraph_index": 13}, {"url": "https://medium.com/@zsalloum/q-vs-v-in-reinforcement-learning-the-easy-way-9350e1523031", "anchor_text": "State and Action Value functions", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566", "anchor_text": "Function Approximation", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/revisiting-policy-in-reinforcement-learning-for-developers-43cd2b713182", "anchor_text": "Reinforcement Learning Policy for Developers", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/exploration-in-reinforcement-learning-e59ec7eeaa75", "anchor_text": "much to explore", "paragraph_index": 18}, {"url": "https://towardsdatascience.com/model-based-reinforcement-learning-cb9e41ff1f0d", "anchor_text": "Model based Reinforcement Learning", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/monte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f", "anchor_text": "Monte Carlo Tree Search", "paragraph_index": 20}, {"url": "https://en.wikipedia.org/wiki/AlphaZero", "anchor_text": "AlphaZero", "paragraph_index": 20}, {"url": "https://medium.com/@zsalloum/dynamic-programming-in-reinforcement-learning-the-easy-way-359c7791d0ac", "anchor_text": "Dynamic Programming", "paragraph_index": 21}, {"url": "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511", "anchor_text": "Monte Carlo", "paragraph_index": 22}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "Temporal Difference (TD)", "paragraph_index": 22}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "TD learning", "paragraph_index": 23}], "all_paragraphs": ["Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com", "When you are new to Reinforcement Learning you will no doubt be bombarded with weird terms, like Model-Based, Model-Free, On Policy, Off Policy etc\u2026", "Soon you will find it exhausting to keep track of this terminology that seem to appear all over the place, without obvious link between its terms.", "This article will try to put all these terms into perspective so that beginners don\u2019t feel overwhelmed.", "Disclaimer: this article assumes that you already know what is Reinforcement Learning and some of the existing algorithms. It does not introduce or explain any particular algorithm, but it will try to put together the different branches so that you get a comprehensive big picture, and how those branches fit in.", "As already established Reinforcement Learning is a framework that lets agent learn decision making from experience. It consists of an agent interacting with an environment, where the it takes actions and collects rewards. The goal of the agent is to collect the maximum rewards.", "For this we need to set up the following definitions.", "The state is the collection of elements or features that describe a situation at a certain moment or time step. Example of state could be the position of a robot, its orientation, as well as the landscape around it, the wind speed, the temperature, etc\u2026", "The Environment State is the state that describes the environment at one moment or a time step. The state of the environment might contain so much details that might not be possible, nor interesting to include in any computation. For example the state of the atoms in robot movement problem is not interesting to take into account.", "The Agent State is the state as it is perceived by the agent. The agent might not be able to detect the full state of the environment, for example a robot with a fixed camera can\u2019t see 360\u00b0 view. In poker game, the agent has only knowledge of the opponent public cards.Generally the agent state differs from the environment state, but in the simplest cases, they are the same, such as in some board games.", "In fully observable environment, the agent sees the full environment state, so in this manner the observation is the environment state.The agent is said to be in Markov Decision Process (MDP).", "Partially observable environment, the agent gets partial info. This is called Partially Observable MDP (POMDP), the env can still be MDP but the agent does not know it.", "The history is a sequence of observations , actions and rewards.", "Markov Decision Process (MDP) is a mathematical framework for modeling decision making in situations.A process is Markov if the next state is dependent only on the current state, any past state is irrelevant.", "State and Action Value functions, are functions that give a value to a certain state s, or an action a performed on state s. The idea is to assess the importance of being at a certain state and/or perform a certain action relative to other states or actions. In short they tell how valuable is to be at that state and how good is to take that action.Imagine a game of chess where the white has an opportunity for a checkmate. Being in such position is a very valuable state, and among all possible actions at that position, performing the move to checkmate is the best action to be taken.In problems with limited number of states, it is easy to compute the exact value of states and action. However when the number of states becomes extremely large, the need to approximate will be more urgent in order to save time and resources. For those kind of problems Function Approximation is used.", "A policy \ud835\udf0b(s) is a function that maps a state to an action. It is like being in some situation and you ask yourself \u201cwhat should I do now?\u201d. The policy tells you what action to take.Policy can be deterministic which means the same state leads the same action, or it can be stochastic in which the same state leads to different actions according to some probability distribution.A gentle introduction to policy can be found in the article \u201cReinforcement Learning Policy for Developers\u201d", "A model predicts what the environment will do next. For example a transition probability predicts what will be the next state, a reward function predicts the next reward.A model does not automatically gives us a good policy we still need to plan.", "Prediction is the evaluation of the future given a policy, while Control is the optimisation of the future, by finding the best policy that maximizes the cumulative reward.", "Exploration is about finding more information about the environment.Exploitation is about getting advantage of the acquired info to maximize rewards.It is important to know how much to explore and how much to exploit.", "Model based Reinforcement Learning is the knowledge of the environment dynamics, for instance the transition probabilities between states, as well as the rewards. This can be known for board games but it will be very difficult to have it in real life problems.", "Model can be given or can be learned, then it can be subject to planning, or a study in a way that does not require to take real actions. Planning phase uses specialized algorithms such as Monte Carlo Tree Search that is used in AlphaZero.It goes without saying that the model MUST be accurate enough to represent the real problem, otherwise it would be a waste of time and resources to plan actions based on inaccurate model, which will lead to poor performance in the real environment.", "Dynamic Programming is one of the model based algorithms.", "On the other hand Model Free algorithms do not rely on models to learn, they learn through direct experience, meaning they take actions in the real environment. Among such algorithms we can find Monte Carlo and Temporal Difference (TD).", "In TD learning we compute the action value Q(s,a) at sate s, by also taking into consideration the action value at the next state Q(s\u2019, a\u2019).", "Q at next state is subject to On/Off policies methods.", "On Policy consists of computing the Q(s, a) value based on a certain policy \ud835\udf0b, meaning Q(s, a) needs the value Q(s\u2019, a\u2019). To get the value of Q(s\u2019, a\u2019) we need action a\u2019 which is gotten using the same policy \ud835\udf0b that brought action a . When moving to state s\u2019 we still follow the action a\u2019 that has been previously determined. The algorithm using On Policy is called SARSA.", "In contrast, Off Policy computes Q(s, a) by using the max Q(s\u2019) over all available actions at s\u2019. This means that we don\u2019t have to chose a specific action a\u2019 according to policy \ud835\udf0b, we simply choose the Q(s\u2019, a\u2019) that have the highest value, then when moving to state s\u2019, we don\u2019t necessarily follow the action that brought the maximum Q value. The algorithm using this technique is called Q-Learning.", "Agents can be categorized in different ways following the types of components their algorithms uses to learn and make decisions:", "Orthogonally to the above categories, each type of the above agents can be :", "The following picture summarizes the categories of agents that are commonly used in Reinforcement Learning", "This picture gives a glimpse of some RL algorithms and their categories:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff4a8b35ebf9a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://zsalloum.medium.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----f4a8b35ebf9a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@joshwp?utm_source=medium&utm_medium=referral", "anchor_text": "Josh Power"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com"}, {"url": "https://medium.com/@zsalloum/basics-of-reinforcement-learning-the-easy-way-fb3a0a44f30e", "anchor_text": "Markov Decision Process"}, {"url": "https://medium.com/@zsalloum/q-vs-v-in-reinforcement-learning-the-easy-way-9350e1523031", "anchor_text": "State and Action Value functions"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566", "anchor_text": "Function Approximation"}, {"url": "https://towardsdatascience.com/revisiting-policy-in-reinforcement-learning-for-developers-43cd2b713182", "anchor_text": "Reinforcement Learning Policy for Developers"}, {"url": "https://towardsdatascience.com/exploration-in-reinforcement-learning-e59ec7eeaa75", "anchor_text": "much to explore"}, {"url": "https://towardsdatascience.com/model-based-reinforcement-learning-cb9e41ff1f0d", "anchor_text": "Model based Reinforcement Learning"}, {"url": "https://towardsdatascience.com/monte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f", "anchor_text": "Monte Carlo Tree Search"}, {"url": "https://en.wikipedia.org/wiki/AlphaZero", "anchor_text": "AlphaZero"}, {"url": "https://medium.com/@zsalloum/dynamic-programming-in-reinforcement-learning-the-easy-way-359c7791d0ac", "anchor_text": "Dynamic Programming"}, {"url": "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511", "anchor_text": "Monte Carlo"}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "Temporal Difference (TD)"}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "TD learning"}, {"url": "https://towardsdatascience.com/math-behind-reinforcement-learning-the-easy-way-1b7ed0c030f4", "anchor_text": "Value based"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083", "anchor_text": "Policy Based"}, {"url": "https://towardsdatascience.com/introduction-to-actor-critic-7642bdb2b3d2", "anchor_text": "Actor Critic"}, {"url": "https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms", "anchor_text": "https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f4a8b35ebf9a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----f4a8b35ebf9a---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f4a8b35ebf9a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----f4a8b35ebf9a---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----f4a8b35ebf9a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----f4a8b35ebf9a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff4a8b35ebf9a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f4a8b35ebf9a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f4a8b35ebf9a--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://zsalloum.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "845 Followers"}, {"url": "https://rl-lab.com", "anchor_text": "https://rl-lab.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftop-down-view-at-reinforcement-learning-f4a8b35ebf9a&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}