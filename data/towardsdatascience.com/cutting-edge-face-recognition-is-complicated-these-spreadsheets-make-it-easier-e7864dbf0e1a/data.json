{"url": "https://towardsdatascience.com/cutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a", "time": 1682993538.635234, "path": "towardsdatascience.com/cutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a/", "webpage": {"metadata": {"title": "Cutting-Edge Face Recognition is Complicated. These Spreadsheets Make it Easier. | by Dave Smith | Towards Data Science", "h1": "Cutting-Edge Face Recognition is Complicated. These Spreadsheets Make it Easier.", "description": "9 steps to building a deep convolutional neural net in spreadsheets for beginners. Learn the intuition behind convolutions and filters and see the simplicity of learning in Excel."}, "outgoing_paragraph_urls": [{"url": "https://www.nytimes.com/2018/07/08/business/china-surveillance-technology.html", "anchor_text": "China\u2019s Orwellian mass surveillance", "paragraph_index": 5}, {"url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b", "anchor_text": "part 1", "paragraph_index": 16}, {"url": "https://www.youtube.com/watch?v=0mxNQA95mYE", "anchor_text": "introduction", "paragraph_index": 40}, {"url": "http://cs231n.github.io/neural-networks-1/#commonly-used-activation-functions", "anchor_text": "overview on non-linear activation functions", "paragraph_index": 63}, {"url": "https://www.ExcelwithML.com", "anchor_text": "https://www.ExcelwithML.com", "paragraph_index": 109}, {"url": "https://mastermind.fyi/", "anchor_text": "https://mastermind.fyi/", "paragraph_index": 109}], "all_paragraphs": ["Machine learning can be complicated\u2026and intimidating to learn when you\u2019re starting out. Spreadsheets on the other hand are simple. They aren\u2019t sexy, but they strip away the distractions and help you visualize what happens behind the code in an intuitive way.", "Using step-by-spreadsheets (which you can view or download using the link below), I\u2019ll show you how the convolutional neural nets (\u201cCNNs\u201d) used in computer vision work. There\u2019s a bit of math, but you can follow all formulas in the spreadsheets:", "The spreadsheet model looks at a picture, analyzes its pixels, and predicts if it is Elon Musk, Jeff Bezos, orrrrr Jon Snow\u2026obviously 3 of Skynet\u2019s greatest threats.", "This post will cover the 9 steps above and use an analogy for each step to help supercharge your intuition.", "The goal is to give you a simple path to getting started in machine learning and show curious minds how cutting-edge AI works \u201cunder the hood\u201d with easy-to-follow spreadsheets. If this helps you, consider signing up for my email list by clicking below and I\u2019ll send you more spreadsheets that help you get started in machine learning.", "Computer vision is the foundation behind Facebook facial recognition system, China\u2019s Orwellian mass surveillance, and pretty soon, your car:", "Let\u2019s start by pretending that inside the mind of Terminator lives a special detective called \u2018Sherlock Convolution Holmes.\u2019 His job is to carefully look at the evidence (the input image) and using his keen eye and deduction abilities (feature detection), he predicts who\u2019s in the picture and cracks the case (correctly classify the image).", "Each of the 9 steps below will be part of this big picture analogy.", "When I look at this picture, I see a visionary. A guy who is simultaneously improving planet earth AND building a rocket to escape it in case Terminator tries to blow it up. Unlike a computer, I don\u2019t see pixel values and I can\u2019t tell a picture is just a stacked combination of red, green, and blue light:", "A computer (i.e. Skynet) on the other hand, is blind\u2026it just sees numbers.", "Think of a digital photograph as 3 spreadsheets (1 red, 1 green, 1 blue) stacked on top of each other and each spreadsheet is a matrix of numbers. When you take a photo, your camera measures the amount of red, green, and blue light hitting each pixel. It then ranks each pixel on a scale of 0\u2013255 and records them on a spreadsheet:", "In the 28x28 image above, each pixel is represented by 3 rows (1 red, 1 blue, and 1 green) and has a value of 0\u2013255. The pixels have been conditionally formatted based on their value.", "If we split each color into a separate matrix, we have 3 28x28 matrices and each matrix is an input that we\u2019ll use to train our neural net:", "*Sidebar: If you want to learn how to convert any picture into a conditionally-formatted Excel file in about 30 seconds, head over to:", "You\u2019ll learn how to take an \u201cEx-celfie\u201d that your fellow spreadsheet-slinging colleagues will love\u2026trust me, they\u2019ll get a good laugh at seeing your mug (or theirs) in a spreadsheet \ud83e\udd33 (small images work best).", "When you were born, did you know what a dog was? No, of course not. But over time, your parents showed you pictures of dogs in books, in cartoons, in real life and eventually\u2026you could point at those 4-legged furry animals and say \u201cdog.\u201d The connections between the billions of neurons in your brain became strong enough that you could recognize dogs.", "The Terminator learned to see Elon in the same manner. Through a process called supervised training, it was shown thousands of pictures of Elon Musk, Jeff Bezos, and Jon Snow. At first, it had a 1 in 3 chance of guessing who it was\u2026but like a child\u2026it improved over time as it saw more images during training. The connections or \u201cweights/biases\u201d of the network were updated over time such that it could predict image outputs based on pixel inputs. This is the process of learning (gradient descent) discussed in part 1.", "Yeah\u2026that means nothing to me either. Let\u2019s de-construct:", "For computer vision, this means that regardless of where an object is moved in an image (translation), it doesn\u2019t change what that object is (invariance).", "The convolutional neural net has to be trained to recognize Elon\u2019s features no matter where he\u2019s at in the image (translation) and no matter his size (scale invariance).", "CNNs excel at recognizing patterns in any part of an image and then stacking these patterns on top of one another to build more complex patterns\u2026like a human.", "In a normal neural net, we would treat each individual pixel as an input (not 3 matrices) to our model, but this ignores the fact that pixels close together have special meaning and structure. With CNNs, we look at groups of pixels next to one another which allows the model to learn local patterns like shapes, lines, etc. For example \u2014 if the CNN saw lots of white pixels around a black circle, it would recognize this pattern as an eye.", "To get CNNs to accomplish translation variance, they rely on the services of its\u2019 feature detective, Sherlock Convolution Holmes.", "Sherlock lives inside the mind of Terminator. Using his magnifying glass, he scrutinizes 1 patch of an image at a time and finds the important features or \u201cclues\u201d of that image. As he collects clues like simple lines and shapes, he stacks them on top of one another and starts to see facial features like an eye or a nose.", "Each convolutional layer holds a stack of feature maps or \u201cclues\u201d that build on one another. At the end of the case, he puts all of these clues together and he\u2019s able to crack the case and correctly identify his target.", "Each convolutional layer of the network has a set of feature maps that can recognize increasingly complex patterns/shapes in a hierarchal manner like below.", "The CNN uses pattern recognition of numbers to figure out the most important features of any image. As it stacks these patterns on top of each other with more layers, it can build very complex feature maps.", "Real-life CNNs do the exact same thing as Sherlock:", "What makes CNNs so amazing is that they learn these features on their own\u2026an engineer doesn\u2019t write code that says look for a set of 2 eyes, 1 nose, a mouth, etc.", "In this way, the engineer is more like an architect. They tell Sherlock, \u201cI\u2019m giving you 2 stacks (\u201cconvolutional layers\u201d) of blank feature maps (\u201cclues\u201d) and it\u2019s your job to analyze the picture and find the most important clues. The first stack has 16 feature maps (\u201cclues\u201d), the 2nd stack has 64 features maps\u2026.now go put your detective skills to use and solve the case!\u201d", "For Sherlock to find the \u201cclues\u201d in the case (i.e. \u201ccalculate a feature map\u201d), he relies on several tools in his detective kit and we\u2019ll cover each:", "Sherlock\u2019s undoubtedly very sharp and has astute observation skills, but he couldn\u2019t do his job without his collection of special magnifying glasses or \u201cfilters.\u201d He uses a different magnifying glass to help him fill in the details of each blank feature map. So, if he had 16 feature maps\u2026he\u2019d have 16 magnifying glasses.", "Each magnifying glass is made up of multiple layers of glass and each layer of glass is made up of different weights. The number of layers of glass, our \u201cfilter depth\u201d, always matches the layer depth from the input layer he\u2019s looking at.", "At first, Sherlock is looking at our input image which has 3 layers \u2014 red, green, and blue. So\u2026our magnifying glass would also have 3 layers.", "As we build the CNN, our layer depth increases so our magnifying glass would also get thicker.", "In order for Sherlock to build 1 feature map or \u201cclue\u201d, he starts by taking out 1 of his magnifying glasses and places it in the top left section of an input image. The red layer of glass can only see the red input image, the green glass sees the green image, and the blue glass sees the blue image.", "Each pixel in our feature map is 1 part of a clue. And to calculate each pixel, Sherlock has to do perform some basic multiplication and addition.", "In our example below using a 5x5x3 input image and a 3x3x3 filter, there are 27 multiplications required for 1 pixel:", "Let\u2019s zoom in and look at the math. A pixel is made up of 27 multiplications (3 layers x 9 multiplications per layer) and the screenshot below shows 9 of the 27 multiplications:", "In terms of the bias, you can think of it as the handle of each magnifying glass. Like the weights, it\u2019s another parameter of the model that is tweaked each training run to improve the model\u2019s accuracy and update the feature map details.", "Filter weights \u2014 In the example above, I kept the weights to 1s and 0s to make the math easier; however, in a normal neural net, you would initialize your starting weights with random lower values\u2026like values between (.01) and 0.1 using a bell-curve or normal distribution type approach. To learn more about weight initialization, check out this introduction.", "After calculating the 1st pixel in the feature map, where does Sherlock move his magnifying glass next?", "The answer depends on the striding parameter. As the architect/engineer, we have to tell Sherlock how many pixels he should move or \u201cstride\u201d his magnifying glass to the right before he calculates the next pixel in his feature map. A stride of 2 or 3 is most common in practice, but we\u2019ll stick with 1 here to keep it simple. This means that Sherlock moves his glass 1 pixel to the right and then he\u2019ll perform the same convolution calcs as before.", "When his glass reaches the far-right edge of the input image, he then moves his magnifying glass 1 pixel down and all the way to the left.", "Why would you stride more than 1?", "A stride of 2 or 3 usually makes sense because pixels immediately next to one another typically have similar values, but if they are 2\u20133 pixels apart, there\u2019s more likely to be variations in pixel values that are important for the feature map/pattern.", "In order for Sherlock to crack his case, he needs a lot of clues at the beginning of a case. In the example above, we took a 5x5x3 image, or 75 pixels of information (75 = 5 x 5 x 3), and we only ended up with a 3x3x2 image, or 18 pixels (18 = 3 x 3 x 2) after our first convolutional layer. This means we lost evidence and this makes his partner, John Watson, very upset.", "In the first couple layers of a CNN, Sherlock likes to see lot of tiny patterns (more clues). In the later layers, it\u2019s ok to \u201cdown-sample\u201d and decrease our total volume of pixels (less clues) as Sherlock stacks the tiny clues and looks at larger patterns.", "So how do we prevent this information loss at the beginning of a CNN?", "In our example, we could only move the filter 3 times before we hit the right edge\u2026and the same from top-to-bottom. This means our resulting output height/width was 3x3 and we lost 2 pixels from left-to-right and another 2 pixels from moving our filter top-to-bottom.", "To prevent this information loss, it\u2019s common to \u201cpad\u201d the original image with zeros (referred to as \u201czero padding\u201d or \u201csame padding\u201d)\u2026kinda like crime scene tape to ensure nobody tampers with the clues like this:", "After padding, if Sherlock used his same magnifying glasses again, his 2 feature maps would both be 5x5 instead of 3x3.", "This means we\u2019d be left with 50 pixels of information since our new output from this convolution is 5x5x2 = 50.", "50 pixels is better than 18. But remember\u2026we started with 75 pixels so we\u2019re still missing some clues.", "So what else can we do to make Sherlock and John Watson happy?", "There\u2019s no limit to the # of feature maps or \u201cclues\u201d our model has\u2026this is a parameter that we control.", "If we increase our feature maps from 2 to at least 3 (5x5x2\u2026to\u20265x5x3) then our total output pixels (75) matches our input pixels (75) and we ensure we don\u2019t have information loss. If we increase the maps to 10, then we\u2018d have even more information for Sherlock to sort through (250 pixels = 5 x 5 x 10) as he finds his clues.", "In summary, the total pixel information in the first few layers is generally higher than our input image because we want to give Sherlock as many tiny clues/patterns as possible. In the last several layers of our network, it\u2019s common to downsample and have fewer pixels because these layers are recognizing larger patterns of the image.", "Giving Sherlock enough information in a case is important, but now comes time for true detective work \u2014 NON-linear pattern recognition! Like the curvature of an ear or the nostril of a nose.", "Thus far, Sherlock has done a bunch of math to build his feature maps, but each calculation has been linear (takes input pixels and performs same multiplication/addition on each pixel) and therefore, he can only identify linear patterns of pixels.", "To introduce non-linearity in CNNs, we use an activation function called a Rectified Linear Unit or \u201cReLU\u201d for short. After we calculate our feature maps from the first convolution, each value is ran through this function to see if it lights up or is \u201cactivated.\u201d", "If the input value is negative, then the output turns into a zero. If the input is positive, then the output value remains unchanged. The ReLU acts like an on/off switch and after you run each value of your feature map through the ReLU, you create non-linear pattern recognition.", "Coming back to our original CNN example, we would apply the ReLU right after the convolution:", "While there are a number of non-linear activation functions you can use to introduce non-linearity into a neural net (sigmoids, tanh, leaky ReLU, etc.), ReLUs are the most popular used in CNNs today because they are computationally efficient and result in faster learning. Check out Andrej Karpathy\u2019s overview on non-linear activation functions to learn about the pros/cons for each function.", "Now that Sherlock has some feature maps, or \u201cclues\u201d, to start looking at, how does he determine which information is critical vs. irrelevant details? Max Pooling.", "Sherlock thinks of the human brain like an empty attic. The fool will store all sorts of furniture and items up there such that the useful information ends up getting lost in all the clutter. The wise person only stores the most important info which allows them to make quick decisions when called upon. In this way, max pooling is Sherlock\u2019s version of the brain attic. In order for him to make decisions quickly, he only keeps the most important info.", "With max pooling, he looks at a neighborhood of pixels and only keeps the \u201cmaximum\u201d value or \u201cmost important\u201d pieces of evidence.", "For example, if he\u2019s looking at a 2x2 area (4 pixels), he only keeps the pixel with the highest value and discards the other 3. This technique allows him to learn fast and also helps him generalize (as opposed to \u2018memorize\u2019) clues that he can store and remember for future images.", "Similar to our magnifying glass filter earlier, we also control the stride of max pooling and the pooling size. In our example below, we\u2019ll assume a stride of 1 and a 2x2 pooling size:", "After max pooling, we\u2019ve completed 1 round of convolution/ReLU/max pooling.", "In a typical CNN, there would be several rounds of convolution/ReLU/pooling until we got to our classifier. With each round, we would be squeezing the height/width while adding depth so that we don\u2019t lose pieces of evidence along the way.", "Steps 1\u20135 were focused on gathering the evidence and now it\u2019s time for Sherlock to look at all the clues and solve the case:", "Now that we have the evidence, let\u2019s start to make sense of it all..", "When Sherlock gets to the end of a training loop, he has a mountain of clues scattered all over the place and needs a way to look at all of them at once. Each clue is a simple 2-dimensional matrix of values, but we have thousands of them piled on top of one another.", "As a private detective, Sherlock thrives in this type of chaos, but he has to bring his evidence to the courtroom and organize them for a jury.", "He does this by using a simple transformation technique called flattening:", "Here\u2019s what a transformation would look like to the human eye\u2026", "Coming back to our example, here\u2019s what the computer sees\u2026", "Now that Sherlock has organized his evidence, it\u2019s time for him to convince the jury that the evidence clearly points to 1 suspect.", "In a fully connected layer, we connect the evidence to each suspect. In a sense, we are \u201cconnecting the dots\u201d for the jury by showing them the link between the evidence and each suspect:", "Here\u2019s what the computer would see using our numerical example:", "In between each piece of evidence in the flatten layer and the 3 outputs are a bunch of weights and biases. Like the other weights in the network, these would be initialized at random values when we first start training the CNN and over-time, the CNN would \u201clearn\u201d how to adjust these weights/biases to result in increasingly accurate predictions.", "Now it\u2019s time for Sherlock to crack the case!", "In the image classifier stage of the CNN, the model\u2019s prediction is the output with the highest score. The goal is to have a high score for the correct output and low scores for the incorrect outputs.", "There are 2 parts of this scoring function:", "The logit score for each output is a basic linear function:", "Logit Score = (Evidence x Weights) + Bias", "Each piece of evidence is multiplied by the weight that connects the evidence to the output. All of these multiplications are added together and we add a bias term at the end and the highest score is the model\u2019s guess.", "So why don\u2019t we stop here? 2 intuitive reasons:", "Sherlock\u2019s goal is have his prediction be as close to 1 as possible for the correct output.", "To find Sherlock\u2019s level of confidence, we take the letter e (which equals 2.71828\u2026) and raise or \u201cexponentiate\u201d it by the logit score. A high score becomes really high confidence and a low score becomes really low confidence.", "This exponentiation calculation also ensures we don\u2019t have any negative scores. Since our logit scores \u201ccould\u201d be negative, here\u2019s what what happen to hypothetical logit scores after the exponentiation:", "To find the confidence-weighted probability, we divide each output\u2019s confidence measure by the sum of all confidence scores and this gives a probability for each output image which all add up to 1. Using our Excel example:", "This softmax classifier is intuitive. Sherlock thinks there\u2019s a 97% (confidence-weighted) chance that the picture Terminator\u2019s looking at is Elon Musk.", "The final step in our model is computing our loss. The loss tells us how good (or bad) of a detective Sherlock really is.", "Every neural net has a loss function where we compare predictions to actuals. As we train the CNN, our predictions improve (Sherlock\u2019s detective skills get better) as we adjust the weights/biases of the network.", "The most commonly used loss function for CNNs is cross-entropy loss. A Google search on cross-entropy turns up several interpretations with lots of Greek letters so it\u2019s easy to get confused. Despite the varying descriptions, they all mean the same thing in the context of machine learning so we\u2019ll cover the 3 most common below so it will \u201cclick\u201d for you.", "Before tackling each formula variation, here is what they each do:", "Distance captures the intuition that if our prediction is close to 1 for the correct label, our cost is nearly 0. If our prediction is close to 0 for the correct label, then we are heavily penalized. The goal is to minimize the \u201cdistance\u201d between the correct class\u2019s prediction (Elon, 0.97) and the actual probability of the correct class (1.00).", "The intuition behind the reward/penalty \u201clog\u201d formula is discussed in interpretation #2.", "In CNNs, \u201clog\u201d actually means \u201cnatural log (ln)\u201d and it is the inverse of the \u201cexponentiation/confidence\u201d done in step 1 of softmax.", "Instead of taking the actual probability (1.00) and subtracting the predicted probability (0.97) to calculate cost, the log calculation exponentially penalizes Sherlock the farther away his prediction is from 1.00.", "KL (Kullback-Leibler) Divergence measures how much our predicted probability (softmax score) diverges from the actual probability.", "The formula is split into 2 parts:", "With the help of our special convolution detective, Sherlock Holmes, we\u2019ve given Terminator a set of eyes so he now has the ability to seek and destroy the protector of the free world\u2026Elon Musk (sorry Elon!).", "Although, we only trained terminator to distinguish between Elon, Jeff, and Jon\u2026Skynet has infinitely more resources and training images at its disposal so it can leverage what we\u2019ve built and train Terminator to see any human or thing.", "If you liked this and want to get more excellerated learnings and cheat sheets sent straight to your inbox, click below and enter your email (they\u2019re all free).", "Our future fate is in your hands in the war against machines \ud83d\ude1c", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Merging mankind with machine, 1 spreadsheet at a time https://www.ExcelwithML.com | Get AI-generated advice at https://mastermind.fyi/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe7864dbf0e1a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ExcelwithML?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ExcelwithML?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Dave Smith"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d60cc4d4a12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&user=Dave+Smith&userId=5d60cc4d4a12&source=post_page-5d60cc4d4a12----e7864dbf0e1a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://drive.google.com/open?id=1TJXPPQ6Cz-4kVRXTSrbj4u4orcaamtpGvY58yuJbzHk", "anchor_text": "https://drive.google.com/open?id=1TJXPPQ6Cz-4kVRXTSrbj4u4orcaamtpGvY58yuJbzHk"}, {"url": "http://bit.ly/2uNrJuc", "anchor_text": ""}, {"url": "https://www.nytimes.com/2018/07/08/business/china-surveillance-technology.html", "anchor_text": "China\u2019s Orwellian mass surveillance"}, {"url": "http://think-maths.co.uk/spreadsheet", "anchor_text": "http://think-maths.co.uk/spreadsheet"}, {"url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b", "anchor_text": "part 1"}, {"url": "https://www.youtube.com/watch?v=0mxNQA95mYE", "anchor_text": "introduction"}, {"url": "http://cs231n.github.io/neural-networks-1/#commonly-used-activation-functions", "anchor_text": "overview on non-linear activation functions"}, {"url": "https://medium.com/excel-with-ml/machine-learning-with-spreadsheets-part-1-gradient-descent-f9316676db9b#53c4", "anchor_text": "one-hot encoding"}, {"url": "http://bit.ly/2Louz37", "anchor_text": ""}, {"url": "https://www.facebook.com/sharer/sharer.php?u=https%3A//towardsdatascience.com/cutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a", "anchor_text": ""}, {"url": "https://twitter.com/home?status=Learn%20Neural%20Nets%20in%20Excel!%20%22Cutting-edge%20face%20recognition%20is%20complicated.%20%20These%20spreadsheets%20make%20it%20easier.%22%20%40ExcelwithML%20https%3A//towardsdatascience.com/cutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a", "anchor_text": ""}, {"url": "https://twitter.com/@ExcelwithML", "anchor_text": ""}, {"url": "http://scs.ryerson.ca/~aharley/vis/conv/flat.html", "anchor_text": "Draw a number and watch the CNN predict it"}, {"url": "https://experiments.withgoogle.com/teachable-machine", "anchor_text": "Train your own CNN with Google + your webcam (or just watch)"}, {"url": "https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html", "anchor_text": "Andreij Karpathy\u2019s real-time image classification model"}, {"url": "https://www.youtube.com/watch?time_continue=2548&v=9C06ZPF8Uuc", "anchor_text": "YouTube video"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----e7864dbf0e1a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e7864dbf0e1a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e7864dbf0e1a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----e7864dbf0e1a---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/excel?source=post_page-----e7864dbf0e1a---------------excel-----------------", "anchor_text": "Excel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&user=Dave+Smith&userId=5d60cc4d4a12&source=-----e7864dbf0e1a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&user=Dave+Smith&userId=5d60cc4d4a12&source=-----e7864dbf0e1a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe7864dbf0e1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e7864dbf0e1a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e7864dbf0e1a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ExcelwithML?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ExcelwithML?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dave Smith"}, {"url": "https://medium.com/@ExcelwithML/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "982 Followers"}, {"url": "https://www.ExcelwithML.com", "anchor_text": "https://www.ExcelwithML.com"}, {"url": "https://mastermind.fyi/", "anchor_text": "https://mastermind.fyi/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d60cc4d4a12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&user=Dave+Smith&userId=5d60cc4d4a12&source=post_page-5d60cc4d4a12--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F266d38268676&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcutting-edge-face-recognition-is-complicated-these-spreadsheets-make-it-easier-e7864dbf0e1a&newsletterV3=5d60cc4d4a12&newsletterV3Id=266d38268676&user=Dave+Smith&userId=5d60cc4d4a12&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}