{"url": "https://towardsdatascience.com/an-intuitive-explanation-of-self-attention-4f72709638e1", "time": 1683014805.256563, "path": "towardsdatascience.com/an-intuitive-explanation-of-self-attention-4f72709638e1/", "webpage": {"metadata": {"title": "An intuitive explanation of Self Attention | by Saketh Kotamraju | Towards Data Science", "h1": "An intuitive explanation of Self Attention", "description": "What do transformer neural networks contain that make them so much more powerful and better performing than regular recurrent neural networks? Answer: They use the Multi-headed Self Attention block\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention is all you need", "paragraph_index": 5}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention Is All You Need", "paragraph_index": 36}], "all_paragraphs": ["In this article, I am going to explain everything you need to know about self-attention.", "What do transformer neural networks contain that make them so much more powerful and better performing than regular recurrent neural networks?", "Answer: They use the Multi-headed Self Attention block to give the word embedding inputs more contextual information. But what exactly does the self-attention block do to the word embeddings that make these transformer models so much more powerful?", "That is the focus of this article. The main purpose of this post is to describe both the intuition behind each part of the self-attention block and the mathematical operations involved in it.", "This article does not aim to explain the overall structure of transformer neural networks. It also does not also describe the difference between self-attention and regular attention.", "We know that word embeddings are vectors that represent the semantic meaning of a word. Words with similar meanings may have similar embeddings. However, in a sentence, the individual meanings of the words do not represent their meanings in the sentence. For example, if I had the phrase, Bank of a river, the embeddings of Bank and river individually mean completely different things, but they have a strong correlation in the sentence. Word embeddings without self-attention do not possess this sense of contextual information, so given the phrase above, a language model would have a low chance of predicting river. In order to address this problem, the self-attention block was proposed in the paper Attention is all you need as part of the original transformer architecture.", "A self-attention module works by comparing every word in the sentence to every other word in the sentence, including itself, and reweighing the word embeddings of each word to include contextual relevance. It takes in n word embeddings without context and returns n word embeddings with contextual information. For example, in the phrase, Bank of the river, Bank would be compared with Bank, of, the, and river, and as Bank is compared with those four words, its word embedding would be reweighted to include the relevance of the words to its own meaning in the sentence accordingly.", "The Self-attention block is comprised of three steps/parts:", "When the input word embeddings are passed into the self-attention module and find out who they should pay attention to, they need a function to find how similar they are to the other words in the sentence. This is where dot product similarity comes into play.", "For the following explanation, I will use the following example:", "where v1, v2, v3, and v4 are the word embeddings of words in a sentence.", "In our example, we will give self-attention to v3, and compare it with v1, v2, v3, and v4. The reason why we also have to compare each word to itself (e.g. v3 to v3), is so that the model can learn which parts of the semantic meaning of a word it should pay attention to. It may seem unusual that a word may have to pay attention to itself. However, sometimes a word can have more than one meaning represented in its embedding (like the example with Bank), and unless we also include itself in the dot product similarity, the model won\u2019t be able to learn which parts of the word\u2019s meaning it should pay attention to. Simply put, words usually have more than one meaning, and in order for the model to recognize which meaning of the word it should pay attention to, we must compare words to themselves by including them in the dot product similarity. In our example, where v3 is compared to every other word and itself, that looks like this:", "We will take the dot product of v1 and v3, v2 and v3, v3 and v3, and v4 and v3 to determine the alignment score of each pair of embeddings. The alignment scores, S31, S32, S33, and S34, will tell us how similar the semantic meanings of v3 and each of the four compared words. The higher the alignment score, the more similar the semantic meanings of the words, and the more attention v3 will have to pay attention to the other word in the pair. Note that each of the alignment scores is a single number, not a vector or matrix of numbers.", "I\u2019ve only done this process for one word: v3. In reality, this process will be done simultaneously for all four words using vectorization and linear algebra.", "Take the word embedding of King and Queen.", "The alignment score of this pair would be:", "Now take the word embeddings of King and Dog", "The alignment score of this pair would be", "Note that these word embeddings are made up and that the real word embeddings of dog, king, and queen are likely much larger in size. Also note that the first index, where king and queen had a high number, represents the royalty of the particular word.", "As you can see the alignment score of King and Queen is much greater than King and Dog. This is because the semantic meaning of the king and dog are dissimilar so they are not important to each other in a sentence. Index 1 represents the royalty of the word, so King and Queen are similar in that regard.", "In short, if the semantic meaning of both words differs, then the alignment score won\u2019t be high, the words will have a low correspondence, and each word will pay low attention to each other so the original word embeddings of each word won\u2019t change too much. If the semantic meaning of two words is similar in any regard, then the alignment score will be high, the words will have a high correspondence, and the two words will pay a high amount of attention to each other so the original word embeddings of each word will undergo a significant change.", "Normalizing the values of the outputs of any Neural Network through an activation function is a common procedure. We will normalize the alignment scores using a SoftMax activation function to obtain the weights that we will apply to the original word embeddings. The SoftMax function will make each of the alignment scores a probabilistic distribution so they all add up to one. In our example,", "all four alignment scores will be SoftMaxed to obtain the final weights that have to be applied to the original word embeddings in order to create the final contextualized embedding.", "Note that when I say \u2018weights\u2019 in the paragraph above, I am not referring to the parameters that the model will learn.", "Now the final reweighing process occurs. In order to determine the total amount of attention the word(v3) should pay to the other words, we multiply the weights with their respective original word embeddings and then add all of these values together to get the final word embedding for the word being compared(v3); in this case,", "Y3 is the final reweighted word embedding vector of v3. Remember that Y31, Y32, Y33, and Y34 are all individually vectors, so we must add them together to get one final vector.", "Remember that the process described above will be done for every other word in the sentence as well.", "Intuitively, all of the processes above make sense except for one thing: the fact that because there are no weights to learn, so the alignment scores and self-attention weights will essentially be pre-determined and the model won\u2019t be able to learn any deeper connections between two words. This is why we will introduce weights in the self-attention block. But where? In order for the model to learn the deepest connections between words, we will introduce the weights at three locations: the input word embeddings, the dot product similarity comparison, and the final step of reweighing the word embeddings. In addition, one more benefit of introducing the words at these locations is that the shapes/dimensions of the vectors multiplied do not change. Remember that if we have a vector of 1 x k shape, and we multiply it by a matrix of k x k shape, this should result in a vector of 1 x k shape. Therefore, even if we introduce weights in the locations described, nothing should change in dimensionality or shape.", "This is why we must introduce weights at the places where we have the original word embedding vectors, v1, v2, v3, and v4, because the shape of these vectors is all the same, and even if we introduce a k x k matrix of weights, the shapes of these will still be 1 x k. The three locations where we use the original embedding vectors is the input word embeddings, the dot product similarity when we compare each word to other words, and during the final reweighing process when we multiply the normalized weights times the original word embeddings. With weights, our calculations will look as follows:", "As you can see, wherever we use the original word embeddings v1, v2, v3, and v4, we multiply those vectors with the corresponding weight Matrixes. Mk, Mq, and Mv are simply the key, query, and value matrices/weights that the model will learn. Remember that in the calculations above, I only did the self-attention operation for one word, v3. In reality, this will happen to all of the words simultaneously through vectorization and some linear algebra.", "Note that in the diagram above, when I multiply the key, query, and value matrices with their respective embedding vectors, I do a matrix multiplication, not a dot product.", "Although it may seem reasonable that one self-attention block is enough for a word to obtain contextual relevance, this is not the case. Often, a word will have to pay attention to multiple other words, and only one self-attention block may not be enough attention for multiple words. This is especially evident in examples where the input text is very large (e.g. for a text summarization task). A pair of words that have contextual relevance, therefore, will sometimes not get enough attention that will make an observable change in their respective embeddings.", "In order to fix this problem, we will use a multi-headed attention block. The Multi headed attention block expands the model\u2019s ability to focus on different positions in the input text.", "A multi-headed attention block is essentially the same thing as a regular self-attention block, but instead of just one attention block, the multi-headed attention block will contain multiple self-attention blocks that operate in parallel. These self-attention blocks will not share any weights; the only thing they will share is the same input word embeddings. The number of self-attention blocks in a multi-headed attention block is a hyperparameter of the model. Suppose that we choose to have n self-attention blocks. The consequence of this is that after all the individual calculations are done by each of the self-attention blocks, we will have n embeddings for each word. In order to fix this problem, the multi-headed attention block concatenates these embeddings and finally passes them through a dense layer. Remember that we want the shape and number of the inputs to equal the shape and number of the outputs. Because we concatenated the embeddings, we keep the number of inputs equal to the number of outputs. Because we passed the concatenated outputs through a dense layer, we were able to control their shape, making sure that it\u2019s the same as the shape of the inputs.", "The self-attention block takes in word embeddings of words in a sentence as an input, and returns the same number of word embeddings but with context. It accomplishes this through a series of key, query, and value weight matrices. The multi-headed attention block consists of multiple self-attention blocks that operate in parallel and share no weights. After each of the self-attention blocks return new contextualized word embeddings, the multi-headed attention block concatenates these new embeddings together and passes them through a dense layer in order to control the shape of the output. This allows for a word embedding to receive enough attention that will make an observable change in its embedding.", "I hope you found this content easy and intuitive to understand. If you think that I need to elaborate further or clarify, drop a comment below.", "Attention Is All You Need (arxiv.org)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "My name is Saketh Kotamraju. I am a highschooler who is very interested in Natural Language processing. I write articles to share what I\u2019ve learned!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4f72709638e1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4f72709638e1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@saketh.kotamraju?source=post_page-----4f72709638e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketh.kotamraju?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Saketh Kotamraju"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b581e538e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&user=Saketh+Kotamraju&userId=e0b581e538e6&source=post_page-e0b581e538e6----4f72709638e1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention is All you need"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention is all you need"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention Is All You Need"}, {"url": "https://www.youtube.com/watch?v=yGTUuEx3GkA", "anchor_text": "Rasa"}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a", "anchor_text": "Illustrated: Self-Attention"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----4f72709638e1---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----4f72709638e1---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----4f72709638e1---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4f72709638e1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----4f72709638e1---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&user=Saketh+Kotamraju&userId=e0b581e538e6&source=-----4f72709638e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&user=Saketh+Kotamraju&userId=e0b581e538e6&source=-----4f72709638e1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4f72709638e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4f72709638e1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4f72709638e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4f72709638e1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4f72709638e1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4f72709638e1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4f72709638e1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketh.kotamraju?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@saketh.kotamraju?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Saketh Kotamraju"}, {"url": "https://medium.com/@saketh.kotamraju/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "204 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b581e538e6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&user=Saketh+Kotamraju&userId=e0b581e538e6&source=post_page-e0b581e538e6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff82e8c84099d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-intuitive-explanation-of-self-attention-4f72709638e1&newsletterV3=e0b581e538e6&newsletterV3Id=f82e8c84099d&user=Saketh+Kotamraju&userId=e0b581e538e6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}