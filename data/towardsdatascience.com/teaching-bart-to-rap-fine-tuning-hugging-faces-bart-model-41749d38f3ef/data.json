{"url": "https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef", "time": 1683015341.2297862, "path": "towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef/", "webpage": {"metadata": {"title": "Teaching BART to Rap: Fine-tuning Hugging Face\u2019s BART Model | by Neil Sinclair | Towards Data Science", "h1": "Teaching BART to Rap: Fine-tuning Hugging Face\u2019s BART Model", "description": "Transfer learning has provided an unimaginable boon to artificial intelligence over the past few years, making waves in the computer vision space and more recently in the NLP space with researchers\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/", "anchor_text": "Arvix", "paragraph_index": 0}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Hugging Face", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1910.13461", "anchor_text": "BART model", "paragraph_index": 1}, {"url": "https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://colab.research.google.com/drive/1n45bHMFw5dSTEUxcGYrQxhApPaltqGsS", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://pytorch-lightning.readthedocs.io/en/latest/", "anchor_text": "PyTorch Lightning", "paragraph_index": 3}, {"url": "http://www.github.com/fpaupier/RapLyrics-Scraper", "anchor_text": "this GitHub repo", "paragraph_index": 6}, {"url": "https://colab.research.google.com/drive/1n45bHMFw5dSTEUxcGYrQxhApPaltqGsS", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1", "anchor_text": "here", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1910.13461", "anchor_text": "original BART paper", "paragraph_index": 18}], "all_paragraphs": ["Transfer learning has provided an unimaginable boon to artificial intelligence over the past few years, making waves in the computer vision space and more recently in the NLP space with researchers discovering that a model trained on a language modelling task can easily (quickly and cheaply) be adapted for other tasks. From a practitioner\u2019s perspective, aside from the deluge of new discoveries \u2014 easily accessible on Arvix \u2014 Hugging Face have developed unbelievably easy-to-use APIs that allow anyone to access these latest developments with a few lines of code.", "In spite of the ease with which one can use the Hugging Face APIs both for on-the-fly inference and for fine tuning through command line style arguments, I got a little stuck trying to fine-tune the BART model. I\u2019m aiming to use it for my Masters thesis and it took me an inordinate amount of time to write the code to fine tune the model because I got stuck in the process. However, once I\u2019d managed to get past this, I\u2019ve been amazed at the power of this model.", "TL; DR: Check out the fine tuning code here and the noising code here.", "This article will give a brief overview of how to fine-tune the BART model, with code rather liberally borrowed from Hugging Face\u2019s finetuning.py script. However, this will allow a bit more control over how one can experiment with the model. I\u2019ve used PyTorch Lightning to handle the training, and if you\u2019re new to it, I encourage you to get familiar with it. The implementation is incredibly straightforward and may be able to streamline some of your projects going forward. Although I\u2019ve taught BART to rap here, it\u2019s really just a convenient (and fun!) seq2seq example as to how one can fine-tune the model.", "Just a quick overview of where I got stuck in the training process. The loss on my model was declining at a rapid pace over each batch, however the model was learning to generate blank sentences. For a long time, I couldn\u2019t figure out why this was happening. It turns out that you need to manually shift the tokens to the right before you feed them to the decoder, but that you must pass the unshifted tokens to the loss function.", "So, without further ado, this is how to teach BART to rap.", "I found a great set of lyrics from this GitHub repo. The author explains how they scraped the lyrics using the Genius python API, but I just downloaded the lyrics that had already been scraped. I then spun up a quick notebook (here) where I created a set of line, next-line pairs of lyrics, such that:", "Here L(n) represents line \u201cn\u201d, L(n+1) represents the following line and -> indicates the lines are paired in the training data. I also did a small amount of additional processing to ensure that songs wouldn\u2019t bleed into each other and that a verse line wouldn\u2019t be followed by a chorus line in the training pairs and vice versa. I also removed a lot of duplicate lines as failing to do this led to a model that often just generated the same lines, repeated, over and over again (due to the significant portion of line -> repeated-line pairs in the data).", "From here, I noised the data. Because BART is trained as a denoising autoencoder I thought it best to pass noised data into the model for training. I\u2019m not sure if this is necessary though. I replaced 25% of the data with the <mask> token, however, I excluded the final word of the lyric line from being added to the replacement pool as this word plays a crucial role in supporting a rhyming scheme.", "I also tried to set up the training set in such a way that a line could be predicted by more than just the previous line. This was done in the hope that during generation the model would be able to have greater coherence across a four-line verse. Concretely, as above if L(n) represents the nth line in the training set, it was set up such that:", "However, when doing this I found that although the number of training examples grew significantly (obviously), the model was learning to copy output lines from the dataset. I thus abandoned this version of the training data.", "The training was relatively straight forward (after I solved the plummeting loss issue). I used PyTorch Lightning to simplify the process of training, loading and saving the model. I also used \u2018bart-base\u2019 as the pre-trained model because I had previously had some GPU memory issues on Google Colab using \u2018bart-large\u2019. I trained the model for around 10 epochs. The code is available here.", "When generating the text, I did two things. First, I fed a seed line into the generate_text() method (which used the BartForConditionalGeneration generate() method) and auto-regressively generated k new lines; secondly, I noised each line with 25% \u2014 35% noised tokens. I found that noising the tokens like this generally gave more variation in the outputs of the model. In the end, I was pretty amazed with the results that I was able to get. It\u2019s quite addictive playing with it. Here\u2019s one 4 line piece I thought could be in a song (it\u2019s no Bukowski, but hey) \u2014 first line is mine:", "You and me forever cruising city lights", "I hope you and your homies don\u2019t ever see these flashing lights", "And me forever shining in the city lights", "But you can\u2019t ever change the way you shine", "Adding a longer range of lyrics for generation \u2014 although my experiment with creating more training data with longer lead-in lyrics (two and three lines leading to the target line) weren\u2019t successful, there might be a way to improve this, by for example, adding <sep> tokens to the sentences.", "I think it would also be interesting to see how BART works with a different genre of music, such as Country or Punk Rock. I also think it would be interesting to see what happens if one doesn\u2019t noise the source lines when training the model. Although, as I recall, from the original BART paper all of the data was noised when training the model, I\u2019m not sure if not noising the data would work.", "Finally, every now and then when a really great line would pop up, I\u2019d manually go search through the training data to see if the model was just copying it or if it was generating the text. Most of the time it was generating the text, however adding in a BLEU-like metric to get a sense of whether the model is copying or being \u201coriginal\u201d would be helpful.", "There are a lot of options that one has available now when utilising pre-tuned models, especially with the great work that Hugging Face is doing with democratising access to the latest and greatest ones. BART shows a lot of promise for a wide-range of seq2seq tasks and having spent some time getting to know the model better, I\u2019m very keen to see what else is possible.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F41749d38f3ef&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://neil-ian-sinclair.medium.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": ""}, {"url": "https://neil-ian-sinclair.medium.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Neil Sinclair"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc2f5bfff9f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&user=Neil+Sinclair&userId=c2f5bfff9f14&source=post_page-c2f5bfff9f14----41749d38f3ef---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/", "anchor_text": "Arvix"}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Hugging Face"}, {"url": "https://arxiv.org/abs/1910.13461", "anchor_text": "BART model"}, {"url": "https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1", "anchor_text": "here"}, {"url": "https://colab.research.google.com/drive/1n45bHMFw5dSTEUxcGYrQxhApPaltqGsS", "anchor_text": "here"}, {"url": "https://pytorch-lightning.readthedocs.io/en/latest/", "anchor_text": "PyTorch Lightning"}, {"url": "http://www.github.com/fpaupier/RapLyrics-Scraper", "anchor_text": "this GitHub repo"}, {"url": "https://colab.research.google.com/drive/1n45bHMFw5dSTEUxcGYrQxhApPaltqGsS", "anchor_text": "here"}, {"url": "https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1910.13461", "anchor_text": "original BART paper"}, {"url": "https://medium.com/tag/nlp?source=post_page-----41749d38f3ef---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----41749d38f3ef---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/hugging-face?source=post_page-----41749d38f3ef---------------hugging_face-----------------", "anchor_text": "Hugging Face"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----41749d38f3ef---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&user=Neil+Sinclair&userId=c2f5bfff9f14&source=-----41749d38f3ef---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&user=Neil+Sinclair&userId=c2f5bfff9f14&source=-----41749d38f3ef---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F41749d38f3ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----41749d38f3ef---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----41749d38f3ef--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----41749d38f3ef--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----41749d38f3ef--------------------------------", "anchor_text": ""}, {"url": "https://neil-ian-sinclair.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://neil-ian-sinclair.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Neil Sinclair"}, {"url": "https://neil-ian-sinclair.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "86 Followers"}, {"url": "https://www.linkedin.com/in/neil-sinclair-64854555/", "anchor_text": "https://www.linkedin.com/in/neil-sinclair-64854555/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc2f5bfff9f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&user=Neil+Sinclair&userId=c2f5bfff9f14&source=post_page-c2f5bfff9f14--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F97356644d0b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fteaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef&newsletterV3=c2f5bfff9f14&newsletterV3Id=97356644d0b4&user=Neil+Sinclair&userId=c2f5bfff9f14&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}