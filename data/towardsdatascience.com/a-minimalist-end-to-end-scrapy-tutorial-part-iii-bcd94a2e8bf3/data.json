{"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3", "time": 1683000381.507599, "path": "towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3/", "webpage": {"metadata": {"title": "A Minimalist End-to-End Scrapy Tutorial (Part III) | by Harry Wang | Towards Data Science", "h1": "A Minimalist End-to-End Scrapy Tutorial (Part III)", "description": "In Part II, you have extracted all the required data from the website and stored them in Items. In Part III, I will introduce Item Pipelines to save the extracted data into a database using ORM\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III", "paragraph_index": 0}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV", "paragraph_index": 0}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V", "paragraph_index": 0}, {"url": "https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a", "anchor_text": "ORM", "paragraph_index": 1}, {"url": "https://www.sqlalchemy.org", "anchor_text": "SQLAlchemy", "paragraph_index": 5}, {"url": "https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a", "anchor_text": "this article", "paragraph_index": 5}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III", "paragraph_index": 24}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV", "paragraph_index": 24}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V", "paragraph_index": 24}], "all_paragraphs": ["Part I, Part II, Part III, Part IV, Part V", "In Part II, you have extracted all the required data from the website and stored them in Items. In Part III, I will introduce Item Pipelines to save the extracted data into a database using ORM (SQLAlchemy) and handle the duplicate data issue.", "Each item returned by the spider is sent to Item Pipelines (if any) sequentially for additional processing, such as saving items to the database, data validation, removing duplicates, etc. Item pipelines are defined as classes in the pipelines.py file, open this autogenerated file, you can see one empty pipeline has been defined named \u201cTutorialPipeline\u201d:", "You need to specify which pipeline is enabled and the sequence of pipelines in settings.py file \u2014 by default, no pipeline is enabled. To enable the empty pipeline above, comment out the following part in settings.py :", "The integer values (normally ranging from 0 to 1000), such as 300 as shown above, determine the execution order of the pipelines (lower valued pipeline runs first).", "Next, let\u2019s develop a pipeline to save the items to a database. Here, I use Object-Relational Mapping (ORM) to query and manipulate data from the database using the object-oriented paradigm. In particular, I use SQLAlchemy. I won\u2019t cover the details of ORM and please refer to this article for some Pros and Cons.", "First, let\u2019s design the database schema. Note that there are 6 fields in the item, e.g., quote_content, tags, author_name, author_birthday, author_bornlocation, and bio. I am going to use three tables to store these data, i.e., quote, tag, author. There is a many-to-many relationship between quote and tag (one quote can one or more tags and one tag can associate with one or more quotes) and a one-to-many relationship between author and quote (one author can have one or more quotes but one quote belongs to only one author).", "To define this schema using ORM via SQLAlchemy, you need to:", "db_connect() function use create_engine(get_project_settings().get(\u201cCONNECTION_STRING\u201d)) to connect to a database. CONNECTION_STRING is specified in settings.py file. You can change the connection string to connect to different database systems, such as SQLite, MySQL, Postgres without changing your code. In this tutorial, I use SQLite, which essentially is a local file named scrapy_quotes.db created in the root folder when the first time the spider runs.", "I also provide an example to connect to MySQL (commented out):", "Now, let\u2019s create the pipeline to save items to the database. Open pipelines.py file and add the following class (pipeline):", "Make sure you also import the required packages and functions:", "The init function below uses the functions in models.py to connect to the database (db_connect) and create tables (create_table) if not existed yet (otherwise ignored).", "in process_item function, I first create instances for the database session and three tables. Then, I assign the author info and quote text values to corresponding table columns.", "Next, we need to check whether the author and tags of the current item already exist in the database or not and only create new author/tag if they don\u2019t exist so far:", "In the end, I add the quote to the database:", "Note that you don\u2019t need to add author and tag explicitly due to the relationships you specified in ORM (quote.author and quote.tags) \u2014 the new author/tags (if any) will be created and inserted automatically by SQLAlchemy.", "Now, run the spider scrapy crawl quotes , you should see a SQLite file named scrapy_quotes.db created. You can open the file to see the extracted content using SQLite command line:", "Note, that we have 50 quotes extracted. Assume the website may add additional quotes and you would like to run the spider once a week to collect the new ones if any. So, let\u2019s run the spider scrapy crawl quotes again and you may notice a problem: we now have 100 quotes in the database \u2014 the same 50 quotes are extracted and stored again!", "Next, let\u2019s add another pipeline to check the item to see whether the item is a duplicate, if yes, drop the item so that the item won\u2019t go through the rest of the pipelines.", "Open pipelines.py file and add the following class (pipeline):", "Make sure to import the DropItem exception: from scrapy.exceptions import DropItem . The logic is simple: do a database query to see whether the current item\u2019s quote text already exists, if yes, drop the item. Now, you need to enable this pipeline in settings.py and make sure the duplicates pipeline is executed before the save to database pipeline:", "You can delete the SQLite file first and run the spider a few times, you will see that only the first time the database is populated with 50 quotes. After that, you can see the warning information indicating the duplicate items have been dropped.", "You have finished Part III!! Cheers. In Part IV, I will show you how to deploy the spider to do periodic crawling and monitoring, e.g., run the spider automatically every 10 minutes.", "Part I, Part II, Part III, Part IV, Part V", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbcd94a2e8bf3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://harrywang.medium.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Harry Wang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17a1fba2e2cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&user=Harry+Wang&userId=17a1fba2e2cb&source=post_page-17a1fba2e2cb----bcd94a2e8bf3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@sarahdorweiler?utm_source=medium&utm_medium=referral", "anchor_text": "Sarah Dorweiler"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V"}, {"url": "https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a", "anchor_text": "ORM"}, {"url": "https://www.sqlalchemy.org", "anchor_text": "SQLAlchemy"}, {"url": "https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a", "anchor_text": "this article"}, {"url": "https://sqlitebrowser.org", "anchor_text": "DB Browser for SQLite"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V"}, {"url": "https://medium.com/tag/python?source=post_page-----bcd94a2e8bf3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----bcd94a2e8bf3---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/tag/scrapy?source=post_page-----bcd94a2e8bf3---------------scrapy-----------------", "anchor_text": "Scrapy"}, {"url": "https://medium.com/tag/web-crawler?source=post_page-----bcd94a2e8bf3---------------web_crawler-----------------", "anchor_text": "Web Crawler"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bcd94a2e8bf3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&user=Harry+Wang&userId=17a1fba2e2cb&source=-----bcd94a2e8bf3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&user=Harry+Wang&userId=17a1fba2e2cb&source=-----bcd94a2e8bf3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbcd94a2e8bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bcd94a2e8bf3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bcd94a2e8bf3--------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harry Wang"}, {"url": "https://harrywang.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "152 Followers"}, {"url": "http://harrywang.me", "anchor_text": "harrywang.me"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17a1fba2e2cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&user=Harry+Wang&userId=17a1fba2e2cb&source=post_page-17a1fba2e2cb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb98b5ed4151&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3&newsletterV3=17a1fba2e2cb&newsletterV3Id=b98b5ed4151&user=Harry+Wang&userId=17a1fba2e2cb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}