{"url": "https://towardsdatascience.com/generating-eminem-lyrics-using-neural-networks-96e7f9c45e8a", "time": 1683006920.496107, "path": "towardsdatascience.com/generating-eminem-lyrics-using-neural-networks-96e7f9c45e8a/", "webpage": {"metadata": {"title": "Generating Eminem Lyrics using Neural Networks | by Rohan Jagtap | Towards Data Science", "h1": "Generating Eminem Lyrics using Neural Networks", "description": "It\u2019s no secret that Deep Learning is much much more than just classifying Cats and Dogs or predicting if a Titanic passenger survived. Be it translating text from one language to another while\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s Blog", "paragraph_index": 7}, {"url": "https://github.com/rojagtap/eminem_lyrics_generator", "anchor_text": "Here", "paragraph_index": 26}], "all_paragraphs": ["It\u2019s no secret that Deep Learning is much much more than just classifying Cats and Dogs or predicting if a Titanic passenger survived. Be it translating text from one language to another while preserving the semantics (like a human would) or recognizing human faces more accurately than ever, Deep Learning has achieved numerous wonders.", "This post is a step-by-step guide on implementing a Eminem lyrics generator (more formally, Unsupervised Text Generator) using TensorFlow. Let\u2019s peek at the main contents:", "In this section, we go through a very high-level overview of RNNs and several flavors of it.", "The fundamental operation of a neural network is mapping the inputs (independent variables) to the outputs (dependent variables) by means of a very complex mathematical function consisting of many nested weighted sums. This is great, but in case of sequential or series data, the value of a dependent variable at any given point in the sequence or series (widely known as a timestep) is not only a function of the independent variables defining it, but also the previous values of the dependent variable in that sequence. This can be best explained with the example of any particular piece of text, where any given word is dependent on the meaning it adds to the sentence as well as the previous words in the context, this adds a grammatical sense to the text (yep, exactly how we\u2019re going to generate text).", "This kind of modeling is achieved by Recurrent Neural Networks. Here the outputs, along with the weighted sum of the inputs, also have an extra memory element that comes from the previous outputs. The aforementioned diagram clearly delineates the architecture of a RNN. At any given timestep, the inputs undergo the hidden layers, the output of which is calculated by combining the previous hidden layer values with the current output. This calculated value is also preserved to be combined in the next timestep, hence \u2018memory element\u2019.", "RNNs work fine, however there are issues,", "Explanation to these is out of the scope for this post but in short, Vanishing Gradient means that while calculating gradients for weight correction, as we go back through the timesteps, the gradients tend to diminish and finally, \u2018vanish\u2019. While long-term dependency is a limitation of the vanilla (plain) RNNs of not being able to remember longer sequences. These issues are addressed by \u2018descendants\u2019 of RNNs \u2014 Long Short-Term Memory Networks or LSTMs. These essentially have a more complex cell with a gated architecture which ensures the preservation of longer sequences and addresses the Vanishing Gradient problem. One of the well-known flavors of LSTM is the Gated Recurrent Unit (GRU) which is an enhancement to LSTM for faster computation.", "Colah\u2019s Blog is by far, one of the best explanations to RNNs (in my opinion). Consider giving it a read if you\u2019re interested in knowing the math behind RNNs.", "In this section, we discuss how exactly are we going to use the RNNs in our text generation problem and get a superficial notion of how things actually work.", "The training inputs to the model are words from a given lyric and the target is the next word from the lyric. Following is the pictorial depiction of the same:", "Neural Nets are known to learn generic patterns between inputs and outputs. By this I mean that when I train a neural net to predict \u201cI\u201d for \u201clook\u201d, \u201ceasy\u201d for \u201cgo\u201d + the memory element of RNNs for many different songs, the neural net tends to learn patterns that are similar among these lyrics. This pattern is none other than the way Eminem writes i.e his style of writing songs, which is if you notice closely, unique (and we too, have a unique style of our own). Now after training if we let the model predict words on its own, it will generate text consisting words from his lyrics and also follow his style of writing songs (might as well drop its own Eminem hit who knows!). This summarizes the main idea of the model.", "We finally get to the real deal; the code!", "I have manually collected Eminem\u2019s 15 songs into text files and we consider each song as an individual sample for training", "First, we read the files and clean the data to make it feasible to be processed by the model:", "As explained in the previous section, we train the model to predict the next word in the lyrics, given previous word and some context from the recent past. There are 2 approaches for implementing this:", "We\u2019ll proceed with Teacher forcing for better and faster convergence. For this we take the original lyric as the input and take the offset 1 of the original lyric at the target. This means that if the input is \u201clook I was gonna go\u201d then the target will be \u201cI was gonna go easy\u201d (offset by 1).", "Next, we will perform generic NLP steps to make sure our input to the model is numeric. We tokenize the words into integers, then we pad or truncate the sequences to a fixed length as all the inputs to a model should be fixed in length.", "As a utility for feasibility, we have a vocabulary for interchangeably switching between the token and the corresponding word. Additionally, we define a few constants which may be tuned in accordance with the model and availability of hardware resources (I have considered minimal values).", "Now, we will finally build the model", "I have trained a minimalist model to demonstrate the concept, it may be tuned according to requirements. Model tuning is again, out of the scope of this post. However, I\u2019ll describe the basic components.", "These are a few verbose from the model training:", "Pretty good for a minimalist model! Now let\u2019s test the results.", "Since we have used Teacher Forcing for training, for predicting on unknown outputs we need to use the first approach as we don\u2019t know the \u2018actual\u2019 outputs and all we have is the next predicted word. We call this the \u2018Inference Step\u2019.", "Passing \u201cslim\u201d as an input to the generator, I got the following output:", "As I\u2019ve mentioned earlier, the model is trained on minimal parameters and with just 15 songs. There is a strong chance that a model may overfit with such a little amount of data and it shows; some phrases are repeated multiple times. This can be fixed with proper tuning and a larger corpus of data.", "The main takeaway from this post is the concept of text generation. The model is generic and may be trained over any type of corpus (say a book) to generate text of desired genre or pattern.", "Here is a link to the github repository of the code. Feel free to fork it, fine-tune the model, train on more data, make pull requests (if you may).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Immensely interested in AI Research | I read papers and post my notes on Medium"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F96e7f9c45e8a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rojagtap.medium.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": ""}, {"url": "https://rojagtap.medium.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Rohan Jagtap"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39646f947a4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&user=Rohan+Jagtap&userId=39646f947a4c&source=post_page-39646f947a4c----96e7f9c45e8a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.facebook.com/eminem/photos/a.84897990078/10151927547475079/?type=3&theater", "anchor_text": "Eminem"}, {"url": "https://www.facebook.com/", "anchor_text": "Facebook"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s blog"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s blog"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "Colah\u2019s Blog"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/losses", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/keras/losses"}, {"url": "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23", "anchor_text": "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"}, {"url": "https://arxiv.org/abs/1412.6980", "anchor_text": "https://arxiv.org/abs/1412.6980"}, {"url": "https://ruder.io/optimizing-gradient-descent/", "anchor_text": "https://ruder.io/optimizing-gradient-descent/"}, {"url": "https://github.com/rojagtap/eminem_lyrics_generator", "anchor_text": "Here"}, {"url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "anchor_text": "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/keras"}, {"url": "https://ruder.io/optimizing-gradient-descent/", "anchor_text": "https://ruder.io/optimizing-gradient-descent/"}, {"url": "https://arxiv.org/abs/1412.6980", "anchor_text": "https://arxiv.org/abs/1412.6980"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----96e7f9c45e8a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----96e7f9c45e8a---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/lstm?source=post_page-----96e7f9c45e8a---------------lstm-----------------", "anchor_text": "Lstm"}, {"url": "https://medium.com/tag/generative-model?source=post_page-----96e7f9c45e8a---------------generative_model-----------------", "anchor_text": "Generative Model"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----96e7f9c45e8a---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&user=Rohan+Jagtap&userId=39646f947a4c&source=-----96e7f9c45e8a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&user=Rohan+Jagtap&userId=39646f947a4c&source=-----96e7f9c45e8a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F96e7f9c45e8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----96e7f9c45e8a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----96e7f9c45e8a--------------------------------", "anchor_text": ""}, {"url": "https://rojagtap.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://rojagtap.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rohan Jagtap"}, {"url": "https://rojagtap.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "465 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39646f947a4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&user=Rohan+Jagtap&userId=39646f947a4c&source=post_page-39646f947a4c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe51e2b6202c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-eminem-lyrics-using-neural-networks-96e7f9c45e8a&newsletterV3=39646f947a4c&newsletterV3Id=e51e2b6202c5&user=Rohan+Jagtap&userId=39646f947a4c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}