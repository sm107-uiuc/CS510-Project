{"url": "https://towardsdatascience.com/ai-the-end-of-the-world-9277ab8bd765", "time": 1682995084.91358, "path": "towardsdatascience.com/ai-the-end-of-the-world-9277ab8bd765/", "webpage": {"metadata": {"title": "AI \u2014 The End of the WoRLd?. \u2014 Teaching virtual agents to learn just\u2026 | by Aadil A. | Towards Data Science", "h1": "AI \u2014 The End of the WoRLd?", "description": "But is that fear really justified? Is there really any cause for concern? If one of the smartest people in the world is terrified by recent exponential developments in the field, should you be as\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=MuWWZ91-G6w", "anchor_text": "Deepmind\u2019s AlphaGo", "paragraph_index": 3}, {"url": "https://openai.com/about/", "anchor_text": "OpenAI", "paragraph_index": 3}, {"url": "https://www.youtube.com/watch?v=gLoI9hAX9dw", "anchor_text": "DeepFake algorithm", "paragraph_index": 31}, {"url": "https://blog.openai.com/better-language-models/", "anchor_text": "OpenAI\u2019s text-generation model", "paragraph_index": 31}, {"url": "https://www.linkedin.com/in/aadillpickles/", "anchor_text": "LinkedIn", "paragraph_index": 34}, {"url": "https://aadilali.com", "anchor_text": "website", "paragraph_index": 34}, {"url": "https://aadilali.us19.list-manage.com/subscribe?u=b1a0190d700080e749848161b&id=75ee2a93f6", "anchor_text": "newsletter", "paragraph_index": 34}, {"url": "http://aadilali.com", "anchor_text": "aadilali.com", "paragraph_index": 36}], "all_paragraphs": ["Elon Musk is terrified of AI taking over the world.", "But is that fear really justified? Is there really any cause for concern? If one of the smartest people in the world is terrified by recent exponential developments in the field, should you be as well?", "If AI systems are just based on some clever math and programming principles, do we really have anything to worry about?", "When Mr. Musk talks about the machines winning, he\u2019s most likely referring to systems that have learned to operate using Reinforcement Learning (RL) models. He\u2019s already warned us about the potential dangers of Deepmind\u2019s AlphaGo and established OpenAI to create a safe path to Artificial General Intelligence (AGI) who also primarily focus on Reinforcement Learning research.", "These developments are a big deal. Most common AI systems right now are only programmed with the ability to do one specific task like detect objects or generate pictures of cats. They\u2019re narrow systems that use supervised learning techniques. We can predict what output they should ideally spit out because we know what the right answer looks like. We know that the object it\u2019s trying to classify is a dog or that the system will always generate a picture of a cat if it\u2019s being trained that way.", "But what about when we don\u2019t know what the right answer is?", "Here, we learn only through trial and error. As in, we give an agent a task to do and let it figure out how to do it with \u2014 but we don\u2019t even know the right way to do it.", "This is the way most researchers think we\u2019ll get to creating general purpose AI (AGI) systems that can figure out how to do any task. Including taking over the human race.", "So can RL really end humanity? No, not yet at least. General intelligence is complicated and took humans millions of years of evolution to develop. Lots more research is needed before SkyNet becomes a reality.", "For now, the most it can do reliably is play video games. Let\u2019s break that process down a little and figure out what actually goes into building an RL agent.", "Let\u2019s say you picked up your first ever arcade game with no idea how to play it. No one really reads instructions so your learning process is basically button-mashing and seeing what happens to your character on the screen. You figure out what to do without any prior knowledge or intended goal other than getting your score as high as possible.", "That\u2019s pretty much what RL agents do to play video games as well except we describe their process with more jargon (jargon is italicized for your reading pleasure).", "An RL agent is basically the player in the game \u2014 the little green spaceship shooting enemies.", "Its environment is everything around it \u2014 the game or map including enemies and barriers.", "It can take actions in order to interact with its environment. In a video game like Space Invaders, the possible actions are move left, move right, shoot or do nothing.", "When it takes an action (inaction is still an action), the environment gives the agent a reward which can be either positive or negative depending on the quality of the action and how much reward it can get in the future. It\u2019s like feedback for whatever actions the agent takes \u2014 positive ones eventually result in a higher score and negative ones result in losing lives.", "Every time the agent completes this cycle, it transitions to a new state. This is like the agent\u2019s position \u2014 depending on its state it can access different parts of the environment. Like if we move left and all the enemies are on the left, we can shoot more enemies. Ideally, we\u2019d like the agent to maximize long-term reward (score).", "But how does the agent actually figure out what to do? How does it know what actions to take from different scenarios to get the highest score possible?", "RL agents learn a policy to determine their behaviour in different scenarios. They learn Q-values to figure out how good it is to take a certain action from a certain state. The \u2018Q\u2019-uality of that action is based on how much reward we expect to get from the state we get to after we take that action.", "Here, taking the action of moving to the right would correspond with a high Q-value since it puts the agent in a position to shoot more enemies that aren\u2019t firing back at it to get a higher score. But moving to the left wouldn't make sense and wouldn\u2019t improve the agent's capability to get more long-term reward since there wouldn\u2019t be any enemies to shoot.", "So, from this game state where the agent is in the middle and the enemies are on the right, the agent most likely takes the action of moving right. That state-action pair would get stored in a Q-table and the next time the agent encounters the same situation, it would know what to do.", "Realistically, running through the billions of possible state-action pair combinations would be nearly impossible for any really serious task (like playing a video game) so we throw some deep learning along with the classic Q-learning model to get the coolest RL buzzword so far \u2014 Deep Q-Networks.", "We use a CNN \u2014 a supervised learning model to allow the agent to see what\u2019s happening in the game. It looks at different spatial and texture features like shapes and edges with 3 convolutional layers and doing some processing in 2 fully-connected layers to figure out what decision it should make.", "This allows the agent to learn the correlation between certain scenarios so its behaviour can generalize across them and isn\u2019t limited to an exact state-action pair.", "So how does the model actually learn and improve?", "This actually isn\u2019t super hard to understand if we break it down.", "Our target network and actual network are pretty much the same \u2014 the only real difference is that the target network is more confident. It knows the right thing to do based on a certain policy (the brain that figures out what action to do given a state) and is always 100% sure what the right thing action is. Our Q-network is a little bit less sure of itself. It will output a probability of doing an action\u2014 if it\u2019s the correct action then we use an optimizer to get the network to learn to take more of those actions. If it\u2019s wrong, it\u2019ll take less.", "As our Q-network trains and gets better, its Q-value for each state-action pair gets higher. So as our network improves, the loss gets lower which makes sense since the loss is a measure of how badly the network is doing. Less loss = less bad = our network plays better!", "Whenever our network goes through a sequence of 1) starting from a state, 2) doing an action, 3) getting a reward, and 4) transitioning to the next state, we remember that sequence and learn from it in the future in a process called experience replay. Those stored experiences get picked out randomly and are tossed into the loss function as parameters (s, a, r, s`) to update the network.", "We choose experiences randomly to make sure the network doesn\u2019t get too comfortable with learning about a specific scenario. For example, if we train our agent that plays Space Invaders in scenes where all of the enemies are on the left side of the screen, it will usually learn how to move left and shoot. But if we do that too often, when it sees the enemies on the right, it won\u2019t know what to do because it\u2019s never seen that before. It\u2019ll just do what it knows \u2014 move left and shoot. But if it learns from random past experiences, we can 1) train the network multiple times on the same data and 2) it\u2019ll learn how to behave in all kinds of situations.", "The thing is, RL models can probably do anything that humans can \u2014 it\u2019s only a question of how fast can we advance the field in order to make them do all the same tasks as us. Once we get there, it\u2019ll be a question of making an AI system that can potentially learn to do all those tasks at the same time.", "There are some incredibly smart people in the AI space right now arguing over precisely what direction advancements in RL are going to be put to use for. Ethical debates are popping up not just about Artificial General Intelligence (AI agents that can learn to do any task) which many believe will be achieved through RL tactics but also the DeepFake algorithm and OpenAI\u2019s text-generation model that have implications that could genuinely disrupt the nature of our world if used immorally.", "Nothing is certain in such a delicate situation like this. Just remember Murphy\u2019s law:", "\u201cAnything that can go wrong, will go wrong\u201d", "Thanks for reading and I hope you learned something interesting about RL! Reach out on LinkedIn and visit my website where you can sign up for my newsletter to get monthly updates on my progress!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Youthful ML Dev. || Twitter: @aadillpickle || Website: aadilali.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9277ab8bd765&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@aliaadil2002?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aliaadil2002?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Aadil A."}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe01c41f9630c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&user=Aadil+A.&userId=e01c41f9630c&source=post_page-e01c41f9630c----9277ab8bd765---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=MuWWZ91-G6w", "anchor_text": "Deepmind\u2019s AlphaGo"}, {"url": "https://openai.com/about/", "anchor_text": "OpenAI"}, {"url": "https://www.youtube.com/watch?v=gLoI9hAX9dw", "anchor_text": "DeepFake algorithm"}, {"url": "https://blog.openai.com/better-language-models/", "anchor_text": "OpenAI\u2019s text-generation model"}, {"url": "https://www.linkedin.com/in/aadillpickles/", "anchor_text": "LinkedIn"}, {"url": "https://aadilali.com", "anchor_text": "website"}, {"url": "https://aadilali.us19.list-manage.com/subscribe?u=b1a0190d700080e749848161b&id=75ee2a93f6", "anchor_text": "newsletter"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9277ab8bd765---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----9277ab8bd765---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/skynet?source=post_page-----9277ab8bd765---------------skynet-----------------", "anchor_text": "Skynet"}, {"url": "https://medium.com/tag/elon-musk?source=post_page-----9277ab8bd765---------------elon_musk-----------------", "anchor_text": "Elon Musk"}, {"url": "https://medium.com/tag/space-invaders?source=post_page-----9277ab8bd765---------------space_invaders-----------------", "anchor_text": "Space Invaders"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&user=Aadil+A.&userId=e01c41f9630c&source=-----9277ab8bd765---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&user=Aadil+A.&userId=e01c41f9630c&source=-----9277ab8bd765---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9277ab8bd765&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9277ab8bd765---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9277ab8bd765--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9277ab8bd765--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9277ab8bd765--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aliaadil2002?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@aliaadil2002?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aadil A."}, {"url": "https://medium.com/@aliaadil2002/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "184 Followers"}, {"url": "http://aadilali.com", "anchor_text": "aadilali.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe01c41f9630c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&user=Aadil+A.&userId=e01c41f9630c&source=post_page-e01c41f9630c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F581c701a254f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-the-end-of-the-world-9277ab8bd765&newsletterV3=e01c41f9630c&newsletterV3Id=581c701a254f&user=Aadil+A.&userId=e01c41f9630c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}