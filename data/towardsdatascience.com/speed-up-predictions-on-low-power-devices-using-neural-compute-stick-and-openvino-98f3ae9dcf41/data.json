{"url": "https://towardsdatascience.com/speed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41", "time": 1682995383.768808, "path": "towardsdatascience.com/speed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41/", "webpage": {"metadata": {"title": "Speed up predictions on low-power devices using Neural Compute Stick and OpenVINO | by Mattia Varile | Towards Data Science", "h1": "Speed up predictions on low-power devices using Neural Compute Stick and OpenVINO", "description": "First, suppose that we want to convert an already trained Tensorflow object detection model. For the purpose of this article, we will use an already trained one, developed by the Tensorflow team, on\u2026"}, "outgoing_paragraph_urls": [{"url": "http://cocodataset.org/#home", "anchor_text": "COCO objects dataset", "paragraph_index": 1}, {"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://software.intel.com/en-us/openvino-toolkit", "anchor_text": "OpenVINO Toolkit", "paragraph_index": 2}, {"url": "https://www.movidius.com/solutions/vision-processing-unit", "anchor_text": "Myriad chip", "paragraph_index": 5}, {"url": "https://software.seek.intel.com/openvino-toolkit", "anchor_text": "download page", "paragraph_index": 7}, {"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "Model Zoo", "paragraph_index": 24}, {"url": "https://download.01.org/openvinotoolkit/2018_R5/packages/l_openvino_toolkit_ie_p_2018.5.445.tgz", "anchor_text": "download", "paragraph_index": 33}, {"url": "https://www.aikospace.com/", "anchor_text": "satellites", "paragraph_index": 48}, {"url": "https://www.intel.ai/ai-at-ces/#gs.0zw5zg", "anchor_text": "Intel Nervana", "paragraph_index": 49}], "all_paragraphs": ["In this article, we will explore the procedure required to:", "First, suppose that we want to convert an already trained Tensorflow object detection model. For the purpose of this article, we will use an already trained one, developed by the Tensorflow team, on the COCO objects dataset (here a full list of the models).", "We need to convert this model to an NCS compatible version, called Intermediate Representation (or IR), using OpenVINO Toolkit.", "After the conversion, we get two files capable of being deployed on Raspberry Pi with NCS hardware attached.", "A more detailed scheme of the process is the following:", "The Neural Compute Stick is equipped with a Myriad chip (also called Vision Processing Unit or VPU).", "As the first step, is required to install OpenVINO Toolkit on the main machine.", "Firstly connect to the download page. Then, register yourself and choose the Ubuntu version of OpenVINO, selecting the Full Package button. After that, download the file, placing it inside Downloads .", "Once finished it\u2019s time to install the package.", "Let\u2019s open a new terminal (CTRL + ALT + T). Navigate to Downloads folder, unzip files, install dependencies and execute GUI installation, as follows:", "Follow the onscreen instructions, proceeding with a full installation", "Wait a few minutes, until the installation process is finished.", "It\u2019s now required to set environmental variables. Run the following script to temporarily set your environment variables:", "OpenVINO toolkit environment variables are removed when you close the shell. As an option, it is possible to permanently set the environment variables as follows (strongly suggested):", "Let\u2019s open .bashrc file, by issuing:", "Append this line at the end of the file:", "Save the file and close the editor (CTRL + X).", "To be sure everything works fine, let\u2019s open a new terminal. Once opened you should now be able to see :", "It is now necessary to update udev rules in order to let OpenVINO being able to communicate with the Neural Compute Stick.", "To do that, let\u2019s open a new terminal (CTRL + ALT + T) and issue the following commands:", "We can now test the installation by making a prediction on an image classifier. Let\u2019s plug the stick into a USB port of the main machine (it\u2019s suggested a USB 3.0 port). Open a new terminal and then run the following commands:", "At the end of the execution you will be able to see the following output:", "It means that you successfully made a prediction using SqueezeNet network loaded on Neural Compute Stick.", "As previously described, we want to use a Tensorflow model to inference using OpenVINO Toolkit.", "Let\u2019s download an SSD MobileNet v1 detector model from Tensorflow ODAPI Model Zoo. To do that, let\u2019s open a new terminal and issue the commands:", "We converted the Tensorflow model, using half-precision floating-point format (or FP16), in order to halve the model size but substantially improving performances at the cost of negligible lower accuracies.", "On the Download folder you should now be able to see the newly generated files, with extension respectively:", "That files will be used for predictions on Raspberry board.", "Before uploading the previous files into Raspberry, let\u2019s first check if everything works fine, inferencing the generated model.", "Plug the camera and the Neural Compute Stick on your main machine. Let\u2019s open a new terminal and issue:", "Your main machine should now open a new window, showing your camera detections!", "Let\u2019s set your Raspberry Pi board. We will first proceed by installing a lighter version of OpenVINO for Raspberry. Then, we will set all the files necessary to run SSDMobileNet V1 on the board.", "Is required to have Raspian OS installed and working (it\u2019s suggested to install Raspian OS from scratch).", "First, We need to download OpenVINO. This version is different from the previous one. Save the file within Download.", "Let\u2019s open a new terminal. Issue the following commands:", "Is required to update several environment variables, before getting OpenVINO Toolkit up and running. Let\u2019s run the following command, within Downloads folder to temporarily set the environment variables:", "Similarly to the procedure on the main machine, is now suggested to permanently set the environment variables by opening .bashrc file a", "and adding the following line at the end:", "To test the installation, let\u2019s open a new terminal. You should see:", "Log out and then log in (or alternatively turn off and on Raspberry) for it to take effect.", "It\u2019s now time to copy the model files to Raspberry. To run a demo app we need the following files:", "If you correctly followed previous steps, these files should be located inside Download folder of the main machine.", "You can both proceed by copying these files to a USB drive and then to Raspberry, or via SSH.", "On Raspberry, create a new folder: mkdir ~/NCS-demo. Put all the previous files inside it.", "Finally, we can execute the demo app, for detections, on Raspberry. In order to do that:", "Tip: Increase or decrease the -pt flag value. It will affect the confidence in the detection.", "As previously experienced on the host machine, a new window should pop-up showing inferences at almost 10FPS speed for this network!", "The Neural Compute Stick is a powerful piece of hardware, useful for executing Convolutional Neural Networks on low-powered systems. Our tests showed almost 10x increasing in speed, compared to inferences executed on vanilla Raspberry board.", "This is only the starting point on the hardware side. We will see in the future, more and more specialized hardware onboard of low-powered devices, such as mobiles, tablets, PCs, cars, drones, and even satellites.", "Intel is undoubtedly one of the main players in this environment, deeply investing in AI on the edge acquiring Movidius company, but also exploring, together with Facebook, other solutions such as Intel Nervana.", "However, competition is also heavily working on this field.", "Xilinx is adapting his ZINQ FPGAs for accelerating neural networks performances on the edge on the hardware side, but also by developing a software tool called Deephi DNNDK for optimizing Neural Networks for low powered systems.", "Google is also moving on this side, by developing the brand new Edge TPU, specially designed for running .tflite models capable of improving, even more, the prediction speed at very little power (stay tuned we will soon explore this solution, comparing performances with NCS).", "It\u2019s an exciting time for AI-powered embedded devices.", "Please feel free to comment on this article in order to improve his quality and effectiveness.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F98f3ae9dcf41&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mattiavarile?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mattiavarile?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Mattia Varile"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff9c50f3928cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&user=Mattia+Varile&userId=f9c50f3928cb&source=post_page-f9c50f3928cb----98f3ae9dcf41---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://software.intel.com/en-us/movidius-ncs", "anchor_text": "NCS1"}, {"url": "https://software.intel.com/en-us/neural-compute-stick", "anchor_text": "NCS2"}, {"url": "http://cocodataset.org/#home", "anchor_text": "COCO objects dataset"}, {"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "here"}, {"url": "https://software.intel.com/en-us/openvino-toolkit", "anchor_text": "OpenVINO Toolkit"}, {"url": "https://www.movidius.com/solutions/vision-processing-unit", "anchor_text": "Myriad chip"}, {"url": "https://software.seek.intel.com/openvino-toolkit", "anchor_text": "download page"}, {"url": "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md", "anchor_text": "Model Zoo"}, {"url": "https://download.01.org/openvinotoolkit/2018_R5/packages/l_openvino_toolkit_ie_p_2018.5.445.tgz", "anchor_text": "download"}, {"url": "https://www.aikospace.com/", "anchor_text": "satellites"}, {"url": "https://www.intel.ai/ai-at-ces/#gs.0zw5zg", "anchor_text": "Intel Nervana"}, {"url": "http://www.linkedin.com/in/mattia-varile", "anchor_text": "Mattia Varile"}, {"url": "https://software.intel.com/en-us/articles/OpenVINO-Install-Linux", "anchor_text": "Detailed install on Linux"}, {"url": "https://software.intel.com/en-us/articles/OpenVINO-Using-TensorFlow#converting-tf-object-detection-api-models", "anchor_text": "Tensorflow ODAPI conversion guide"}, {"url": "https://software.intel.com/en-us/articles/OpenVINO-IE-Samples", "anchor_text": "Object detection SSD demo"}, {"url": "https://software.intel.com/en-us/articles/OpenVINO-Install-RaspberryPI", "anchor_text": "Install OpenVINO on Raspberry P"}, {"url": "https://medium.com/tag/raspberry-pi?source=post_page-----98f3ae9dcf41---------------raspberry_pi-----------------", "anchor_text": "Raspberry Pi"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----98f3ae9dcf41---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----98f3ae9dcf41---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----98f3ae9dcf41---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/intel?source=post_page-----98f3ae9dcf41---------------intel-----------------", "anchor_text": "Intel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&user=Mattia+Varile&userId=f9c50f3928cb&source=-----98f3ae9dcf41---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&user=Mattia+Varile&userId=f9c50f3928cb&source=-----98f3ae9dcf41---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F98f3ae9dcf41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----98f3ae9dcf41---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----98f3ae9dcf41--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mattiavarile?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mattiavarile?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mattia Varile"}, {"url": "https://medium.com/@mattiavarile/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "126 Followers"}, {"url": "https://www.linkedin.com/in/mattia-varile/", "anchor_text": "https://www.linkedin.com/in/mattia-varile/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff9c50f3928cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&user=Mattia+Varile&userId=f9c50f3928cb&source=post_page-f9c50f3928cb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F18b61a60c3a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-predictions-on-low-power-devices-using-neural-compute-stick-and-openvino-98f3ae9dcf41&newsletterV3=f9c50f3928cb&newsletterV3Id=18b61a60c3a9&user=Mattia+Varile&userId=f9c50f3928cb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}