{"url": "https://towardsdatascience.com/evaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3", "time": 1682995382.937216, "path": "towardsdatascience.com/evaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3/", "webpage": {"metadata": {"title": "Evaluating Machine Learning Models Fairness and Bias. | by Will Badr | Towards Data Science", "h1": "Evaluating Machine Learning Models Fairness and Bias.", "description": "Evaluating machine learning models for bias is becoming an increasingly common focus for different industries and data researchers. Model Fairness is a relatively new subfield in Machine Learning. In\u2026"}, "outgoing_paragraph_urls": [{"url": "http://aif360.mybluemix.net/data", "anchor_text": "nteractive Experience", "paragraph_index": 12}, {"url": "http://aif360.mybluemix.net/resources#guidance", "anchor_text": "uidance Material", "paragraph_index": 13}], "all_paragraphs": ["Evaluating machine learning models for bias is becoming an increasingly common focus for different industries and data researchers. Model Fairness is a relatively new subfield in Machine Learning. In the past, the study of discrimination emerged from analyzing human-driven decisions and the rationale behind those decisions. Since we started to rely on predictive ML models to make decisions for different industries such as insurance and banking, we need to implement strategies to ensure the fairness of those models and detect any discriminative behaviour during predictions.", "As ML models get more complex, it becomes much harder to interpret them. Predictive models are usually a black-box function that takes a certain input (x) and outputs a prediction (y). Let\u2019s say an insurance company wants to use a predictive model to measure the risk of taking a client on-board. The input (x) can consist of features or attributes such as race, age, gender, ethnicity, education level and income. They can also decide whether or not a person should be asked to pay a higher premium based on the model predictions that look into the same attributes I just mentioned. In the banking and financial industry in the United States, this may have some legal implications as it violates the Equal Credit Opportunity Act (fair lending) by not approving credit request of right applicants.", "As the use of predictive models rapidly grows and deployed to make informative decisions to access some services such a bank loan, creditworthiness or employment, it is now important to audit and interpret the output decisions of those models and design for fairness in the early stages. In this article, I will discuss 5 tools that can be used to explore and audit the predictive model fairness.", "FairML is a toolbox written in python to audit machine learning models for fairness and bias. It\u2019s an easy way to quantify the significance of the model\u2019s inputs. It uses four input ranking algorithms to quantify a model\u2019s relative predictive dependence on model\u2019s inputs.", "For installation and demo code, you can refer to the main Github repo for the library.", "Lime is an open source project that aims at explaining and interpreting how machine learning models work. The great thing about Lime is the broad range of the Machine Learning or Deep Learning models it supports. I can interpret text classification, multi-class classification, image classification and regression models.", "Here is a quick demonstration of using Lime to understand and explore the decision criteria for making predictive decisions. In this example, I trained a text classifier that uses the 20 categories newsgroup dataset. The below text is being classified as comp.windows.x category.", "Now, let\u2019s use Lime to explore what specific words in this text has the most weight to come up with this decision.", "As you can see, the words client, application have the most weight. Let\u2019s try a little experiment. I am going to remove those two words from the above text and place another word and try again to predict.", "You can see that the word space introduced bias and completely changed the prediction although the context of the text is still the same.", "To understand how the code works, you can refer to the code repository and the example code in the link below:", "AI Fairness 360 is an open-source library that detects and mitigate bias in machine learning models using a bunch of bias mitigation algorithms. This library is very comprehensive and full of metrics to evaluate bias.", "They created an Interactive Experience in which you can see the metrics and test the capabilities.", "They have also created a Guidance Material that can guide through which metrics can be used for which use case.", "This library relies on a bunch of Bias mitigation algorithms such as:", "SHAP can explain the output of any machine learning model by connecting game theory with a local explanation. It uses some beautiful JS visualization to explain the models.", "For detailed explanation and guidance on how it works, refer to the link below", "Google What-If Tool (WIF) is a tensorboard plugin to understand a black-box classification or regression ML model. It has multiple demos, interactive experience and comprehensive documentation.", "In Conclusion, any bias in ML models is due to some kind of bias present in the people working on annotating the data or it lies in the data itself due to skewness or missing features or any other reason that needs to be picked up and investigated. Failing to capture those features and generalize the data to train the models can result in model bias. Biased Machine Learning models may result in making unfair/biased decisions which would, consequently, impact the end users. Therefore, it is really important that all stakeholders should focus on detecting any presence of bias in their developed models.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Principal AI/ML Specialist @ Amazon Web Service"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4ec82512f7c3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@will.badr?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@will.badr?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Will Badr"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F551ba3f6b67d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&user=Will+Badr&userId=551ba3f6b67d&source=post_page-551ba3f6b67d----4ec82512f7c3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/adebayoj/fairml", "anchor_text": "https://github.com/adebayoj/fairml"}, {"url": "https://github.com/adebayoj/fairml", "anchor_text": "adebayoj/fairmlContribute to adebayoj/fairml development by creating an account on GitHub.github.com"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "marcotcr/limeLime: Explaining the predictions of any machine learning classifier \u2014 marcotcr/limegithub.com"}, {"url": "http://aif360.mybluemix.net/data", "anchor_text": "nteractive Experience"}, {"url": "http://aif360.mybluemix.net/resources#guidance", "anchor_text": "uidance Material"}, {"url": "https://github.com/IBM/AIF360", "anchor_text": "IBM/AIF360A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and\u2026github.com"}, {"url": "http://papers.nips.cc/paper/6988-optimized-pre-processing-for-discrimination-prevention", "anchor_text": "Calmon et al., 2017"}, {"url": "https://doi.org/10.1145/2783258.2783311", "anchor_text": "Feldman et al., 2015"}, {"url": "https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning", "anchor_text": "Hardt et al., 2016"}, {"url": "https://github.com/slundberg/shap", "anchor_text": "slundberg/shapA unified approach to explain the output of any machine learning model. \u2014 slundberg/shapgithub.com"}, {"url": "https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/interactive_inference", "anchor_text": "tensorflow/tensorboardTensorFlow\u2019s Visualization Toolkit. Contribute to tensorflow/tensorboard development by creating an account on GitHub.github.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4ec82512f7c3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----4ec82512f7c3---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4ec82512f7c3---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----4ec82512f7c3---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/analytics?source=post_page-----4ec82512f7c3---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&user=Will+Badr&userId=551ba3f6b67d&source=-----4ec82512f7c3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&user=Will+Badr&userId=551ba3f6b67d&source=-----4ec82512f7c3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4ec82512f7c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4ec82512f7c3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4ec82512f7c3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@will.badr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@will.badr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Will Badr"}, {"url": "https://medium.com/@will.badr/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F551ba3f6b67d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&user=Will+Badr&userId=551ba3f6b67d&source=post_page-551ba3f6b67d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F811aaedd70bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fevaluating-machine-learning-models-fairness-and-bias-4ec82512f7c3&newsletterV3=551ba3f6b67d&newsletterV3Id=811aaedd70bd&user=Will+Badr&userId=551ba3f6b67d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}