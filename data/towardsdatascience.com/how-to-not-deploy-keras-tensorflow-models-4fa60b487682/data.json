{"url": "https://towardsdatascience.com/how-to-not-deploy-keras-tensorflow-models-4fa60b487682", "time": 1683011949.642692, "path": "towardsdatascience.com/how-to-not-deploy-keras-tensorflow-models-4fa60b487682/", "webpage": {"metadata": {"title": "How to not deploy Keras/TensorFlow models | by Christian Freischlag | Towards Data Science", "h1": "How to not deploy Keras/TensorFlow models", "description": "While the most articles about deep learning are focusing at the modeling part, there are also few about how to deploy such models to production. Some of them say \u201cproduction\u201d, but they often simply\u2026"}, "outgoing_paragraph_urls": [{"url": "https://flask.palletsprojects.com/en/1.1.x/deploying/", "anchor_text": "the official website", "paragraph_index": 7}, {"url": "https://www.tensorflow.org/guide/saved_model", "anchor_text": "tutorial", "paragraph_index": 15}, {"url": "https://www.tensorflow.org/model_optimization/guide/pruning/", "anchor_text": "pruning", "paragraph_index": 15}, {"url": "https://www.tensorflow.org/model_optimization/guide/quantization/post_training", "anchor_text": "quantization", "paragraph_index": 15}, {"url": "http://digital-thinking.de/how-to-deploy-keras-cnns-with-tensorflow-serve-including-jpeg-decoding/", "anchor_text": "tensorflow model server", "paragraph_index": 16}, {"url": "https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/architecture.md", "anchor_text": "TensorFlow model server", "paragraph_index": 17}, {"url": "https://aws.amazon.com/de/machine-learning/elastic-inference/", "anchor_text": "Elastic Inference", "paragraph_index": 19}, {"url": "http://digital-thinking.de", "anchor_text": "digital-thinking.de", "paragraph_index": 21}], "all_paragraphs": ["While the most articles about deep learning are focusing at the modeling part, there are also few about how to deploy such models to production. Some of them say \u201cproduction\u201d, but they often simply use the un-optimized model and embed it into a Flask web server. In this post, I will explain why using this approach is not scaling well and wasting resources.", "If you search for how to deploy TensorFlow, Keras or Pytorch models into production there are a lot of good tutorials, but sometimes you come across very simple simple examples, claiming production ready. These examples often use the raw keras model, a Flask web server and containerize it into a docker container. These examples use Python to serve predictions. The code for these \u201cproduction\u201d Flask webservers look like this:", "Furthermore, they often show how to containerize the Flask server and bundle it with your model into docker. These approaches also claim that they can easily scale by increasing the number of docker instances.", "Now let us recap what happens here and why it is not \u201cproduction\u201d grade.", "First usually the model is used as it is, which means the Keras model from the example was simply exported by model.save(). The model includes all the parameters and gradients, which are necessary to train the model, but not required for inference. Also, the model is neither pruned nor quantized. As an effect using not optimized models have a higher latency, need more compute and are larger in terms of file size.", "The next problem is that plain Python and Flask is used to load the model and serve predictions. Here are a lot of problems.", "First let\u2019s look at the worst thing you can do: loading the model for each request. In the code example from above, the model is used when the script is called, but in other tutorials they moved this part into the predict function. What that does is loading the model every single time you make a prediction. Please do not do that. (The comparison here does not compare with that approach)", "That being said, let\u2019s look at Flask. Flask includes a powerful and easy-to-use web server for development. On the official website, you can read the following:", "While lightweight and easy to use, Flask\u2019s built-in server is not suitable for production as it doesn\u2019t scale well.", "That said, you can use Flask as a WSGI app in e.g. Google App Engine. However, many tutorials are not using Google App Engine or NGIX, they just use it as it is and put it into a docker container. But even when they use NGIX or any other web servers, they usually turn off multi threading completely.", "Let\u2019s look a bit deeper into the problem here. If you use a TensorFlow, it handles compute resources (CPU, GPU) for you. If you load a model and call predict, TensorFlow uses the compute resources to make these predictions. While this happens, the resource is in-use aka locked. When your web server only serves one single request at the time, you are fine, as the model was loaded in this thread and predict is called from this thread. But once you allow more than one requests at the time, your web server stops working, because you can simply not access a TensorFlow model from different threads. That being said, in this setup you can not process more than one request at once. Doesn\u2019t really sound like scalable, right?", "Ok, the web server does not scale, but what about scaling the number of web servers? In a lot of examples this approach is the solution to the scaling problem of single instances. There is not much to say about it, it works sure. But scaling this way wastes money, resources and energy. It\u2019s like having a truck and putting in one single parcel and once there are more parcels, you get another truck, instead of using the existing truck smarter.", "GPUs made deep learning possible as they can do operations massively in parallel. When using docker containers to deploy deep learning models to production, the most examples do NOT utilize GPUs, they don\u2019t even use GPU instances. The prediction time for each request is magnitudes slower on CPU machines, so latency is a big problem. Even with powerful CPU instances you will not achieve comparable results to the small GPU instances.", "Just a side note: In general it is possible to use GPUs in docker, if the host has the correct driver installed. Docker is completely fine for scaling up instances, but scale up the correct instances.", "As you can see, loading trained model and putting it into Flask docker containers is not an elegant solution. If you want deep learning in production, start from the model, then think about servers and finally about scaling instances.", "Unfortunately optimizing a model for inference is not that straight forward as it should be. However, it can easily reduce inference time by multiples, so it\u2019s worth it without doubts. The first step is freezing the weights and removing all the trainings overhead. This can be achieved with TensorFlow directly but requires you to convert your model into either an estimator or into a Tensorflow graph (SavedModel format), if you came from a Keras model. TensorFlow itself has a tutorial for this. To further optimize, the next step is to apply model pruning and quantization, where insignificant weights are removed and model size is reduced.", "When you have an optimized model, you can look at different model servers, meant for deep learning models in production. For TensorFlow and Keras TensorFlowX offers the tensorflow model server. There are also others like TensorRT, Clipper, MLFlow, DeepDetect.", "TensorFlow model server offers several features. Serving multiple models at the same time, while reducing the overhead to a minimum. It allows you to version your models, without downtime when deploying a new version, while still being able to use the old version. It also has an optional REST API endpoint additionally to the gRPC API. The throughput is magnitudes higher than using a Flask API, as it is written in C++ and uses multi-threading. Additionally, you can even enable batching, where the server batches multiple single predictions into a batch for very high load settings. And finally, you can put it into a docker container and scale even more.", "Hint: tensorflow_model_server is available on every AWS-EC2 Deep learning AMI image, with TensorFlow 2 it\u2019s called tensorflow2_model_server.", "And lastly, I would recommend using GPUs or TPUs for inference environments. The latency and throughput are much higher with such accelerators, while saving energy and money. Note that it is only being utilized if your software stack can utilize the power of GPUs (optimized model + model server). In AWS you can look into Elastic Inference or just use a GPU instance with Tesla M60 (g3s.xlarge).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML/Data and Tech enthusiast | digital-thinking.de | Lead Machine Learning Engineer @Chrono24"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4fa60b487682&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa60b487682--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@christian.freischlag?source=post_page-----4fa60b487682--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christian.freischlag?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Christian Freischlag"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7bf9b5093a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&user=Christian+Freischlag&userId=b7bf9b5093a4&source=post_page-b7bf9b5093a4----4fa60b487682---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.pikist.com", "anchor_text": "www.pikist.com"}, {"url": "https://flask.palletsprojects.com/en/1.1.x/deploying/", "anchor_text": "the official website"}, {"url": "https://www.tensorflow.org/guide/saved_model", "anchor_text": "tutorial"}, {"url": "https://www.tensorflow.org/model_optimization/guide/pruning/", "anchor_text": "pruning"}, {"url": "https://www.tensorflow.org/model_optimization/guide/quantization/post_training", "anchor_text": "quantization"}, {"url": "http://digital-thinking.de/how-to-deploy-keras-cnns-with-tensorflow-serve-including-jpeg-decoding/", "anchor_text": "tensorflow model server"}, {"url": "https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/architecture.md", "anchor_text": "TensorFlow model server"}, {"url": "https://aws.amazon.com/de/machine-learning/elastic-inference/", "anchor_text": "Elastic Inference"}, {"url": "http://digital-thinking.de/how-to-not-deploy-tensorflow-models-and-how-do-it-better/", "anchor_text": "digital-thnking.de"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4fa60b487682---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/software-development?source=post_page-----4fa60b487682---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----4fa60b487682---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----4fa60b487682---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/deployment?source=post_page-----4fa60b487682---------------deployment-----------------", "anchor_text": "Deployment"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&user=Christian+Freischlag&userId=b7bf9b5093a4&source=-----4fa60b487682---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&user=Christian+Freischlag&userId=b7bf9b5093a4&source=-----4fa60b487682---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4fa60b487682&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4fa60b487682---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4fa60b487682--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4fa60b487682--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4fa60b487682--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4fa60b487682--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4fa60b487682--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christian.freischlag?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@christian.freischlag?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Christian Freischlag"}, {"url": "https://medium.com/@christian.freischlag/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "192 Followers"}, {"url": "http://digital-thinking.de", "anchor_text": "digital-thinking.de"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb7bf9b5093a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&user=Christian+Freischlag&userId=b7bf9b5093a4&source=post_page-b7bf9b5093a4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2f0157628cac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-not-deploy-keras-tensorflow-models-4fa60b487682&newsletterV3=b7bf9b5093a4&newsletterV3Id=2f0157628cac&user=Christian+Freischlag&userId=b7bf9b5093a4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}