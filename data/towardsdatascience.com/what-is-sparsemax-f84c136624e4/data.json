{"url": "https://towardsdatascience.com/what-is-sparsemax-f84c136624e4", "time": 1683003964.860262, "path": "towardsdatascience.com/what-is-sparsemax-f84c136624e4/", "webpage": {"metadata": {"title": "What is Sparsemax?. A useful variation of softmax | by Michael Larionov, PhD | Towards Data Science", "h1": "What is Sparsemax?", "description": "In machine learning, there are several very useful functions, for example, sigmoid, relu, softmax. The latter is widely used in multi-class classification problems as an output layer of the Neural\u2026"}, "outgoing_paragraph_urls": [{"url": "http://proceedings.mlr.press/v48/martins16.pdf", "anchor_text": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification", "paragraph_index": 2}, {"url": "https://github.com/mlarionov/machine_learning_POC/blob/master/sparsemax/Sparsemax.ipynb", "anchor_text": "my github repository", "paragraph_index": 11}], "all_paragraphs": ["In machine learning, there are several very useful functions, for example, sigmoid, relu, softmax. The latter is widely used in multi-class classification problems as an output layer of the Neural networks:", "This function has a useful property: the sum of its elements is one, which makes it very useful to model probabilities. It is also differentiable everywhere and the derivative is never zero, which make it useful in the backpropagation algorithms. in contrast, the derivative of the argmax function, that softmax is called to replace, is always zero. Another useful property is that this function preserves the support of the posterior probability distribution because the output probabilities are never zero, however small values they may be.", "But sometimes you want to have a sparse output, only preserving several values with non-zero probability. For this scenario, Andr\u00e9 F. T. Martins and Ram\u00f3n F. Astudillo proposed a new function called sparsemax in their paper From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification.", "The idea is to set the probabilities of the smallest values of z to zero and keep only probabilities of the highest values of z, but still keep the function differentiable to ensure successful application of backpropagation algorithm. This function is defined as:", "Here \u03c4(z) is called threshold function and it defines the support function S(z) that contains all non-zero indices of p. A python implementation of sparsemax function is below:", "Running it and softmax on the same values we can indeed see that it does set some of the probabilities to zero, where softmax keeps them non-zero:", "It is also interesting to see how the two functions are different in the two-dimensional case. In this case softmax becomes a sigmoid function, and sparsemax can be represented in this form:", "The picture below illustrates how they are different:", "Note, that the sparsemax function is not differentiable everywhere (but neither is relu), but where it is is an easy computation:", "Here |S(z)| is the number of elements in the support S(z).", "The obvious problem with sparsemax is vanishing gradient. You can see that the derivative turns to zero once z becomes large. The authors acknowledged the problem and even proposed a new loss function in place of cross-entropy loss. However I believe the main advantage of sparsemax is not in the output layer, but in the middle of the neural network, for example, in the attention mechanism.", "You can find the code for this article in my github repository.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff84c136624e4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@michaellarionov", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://michaellarionov.medium.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": ""}, {"url": "https://michaellarionov.medium.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Michael Larionov, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff9158ca11a43&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&user=Michael+Larionov%2C+PhD&userId=f9158ca11a43&source=post_page-f9158ca11a43----f84c136624e4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@greg_rosenke?utm_source=medium&utm_medium=referral", "anchor_text": "Greg Rosenke"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://proceedings.mlr.press/v48/martins16.pdf", "anchor_text": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"}, {"url": "https://github.com/mlarionov/machine_learning_POC/blob/master/sparsemax/Sparsemax.ipynb", "anchor_text": "my github repository"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f84c136624e4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f84c136624e4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----f84c136624e4---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----f84c136624e4---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&user=Michael+Larionov%2C+PhD&userId=f9158ca11a43&source=-----f84c136624e4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&user=Michael+Larionov%2C+PhD&userId=f9158ca11a43&source=-----f84c136624e4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff84c136624e4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f84c136624e4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f84c136624e4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f84c136624e4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f84c136624e4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f84c136624e4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f84c136624e4--------------------------------", "anchor_text": ""}, {"url": "https://michaellarionov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://michaellarionov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Michael Larionov, PhD"}, {"url": "https://michaellarionov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "611 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff9158ca11a43&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&user=Michael+Larionov%2C+PhD&userId=f9158ca11a43&source=post_page-f9158ca11a43--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcf000f0c5fdd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-sparsemax-f84c136624e4&newsletterV3=f9158ca11a43&newsletterV3Id=cf000f0c5fdd&user=Michael+Larionov%2C+PhD&userId=f9158ca11a43&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}