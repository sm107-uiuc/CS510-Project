{"url": "https://towardsdatascience.com/spacex-falcon-9-landing-with-rl-7dde2374eb71", "time": 1683010094.732613, "path": "towardsdatascience.com/spacex-falcon-9-landing-with-rl-7dde2374eb71/", "webpage": {"metadata": {"title": "SpaceX Falcon 9 Landing with RL. Reinforcement Learning with SpaceX\u2026 | by Ugurkan Ates | Towards Data Science", "h1": "SpaceX Falcon 9 Landing with RL", "description": "The Falcon 9, developed by aerospace company SpaceX, means it is now possible to reuse the first-stage of the rocket, by flying it safely back to Earth. An achievement once seemed so impossible that\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Motion_planning", "anchor_text": "path planning", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Reinforcement_learning", "anchor_text": "Reinforcement Learning", "paragraph_index": 3}], "all_paragraphs": ["The Falcon 9, developed by aerospace company SpaceX, means it is now possible to reuse the first-stage of the rocket, by flying it safely back to Earth.", "An achievement once seemed so impossible that it lead creation of multiple \u201cfake SpaceX landing videos-explanations\u201d now is widely agreed upon about how amazing behind the tech related to it.", "While today I\u2019m not here nor capable of you giving rocket engineering course just wanted to show this quick little diagram from SpaceX to understand a little bit more.", "While none of AI techniques have been deployed to any of SpaceX tech pipeline (they are using classic-robotics/control theory way of path planning algorithms) it would be nice to see what would happen if we tried to solve the problem with state of the art Reinforcement Learning algorithms.", "If you are new to RL I urge you to checkout other tutorials,books and resources for beginners relating to learning more about fundamentals of RL and the math about it.", "Dear Sven Niederberger(@EmbersArc on GitHub) created this tough Reinforcement Learning environment some time ago. While in creation it\u2019s main purpose was to create a nice attractive/hype GYM like environment using ideas from LunarLander envs , it quickly has been realized it\u2019s way harder to solve in terms of RL than what was inspired for it.", "LunarLander has 2 versions. One designed for discrete action space", "Action is two real values vector from -1 to +1.", "While discrete action one easily can be solved with Value based methods plus non linear functional approximation such as DQN,Rainbow DQN or Gorilla DQN , continuous action problem requires somekind of actor-critic based algorithm to work due sparse rewards, hard exploration and unstable nature of vanilla DQN methods.", "PPO+LSTM + paralel train(on policy,cluster style training), Soft Actor Critic(SAC,off policy), DDPG and D4PG(off policy- hybrid actor critic methods) can be used for solving this problem. Especially if you are going for a on policy methods I would urge to you take a look on parallelization and LSTMs(or Attention mechanisms for being SOTA?) with RL in general but that\u2019s a topic for another day.", "Our Rocket gym also uses most of things from LunarLander setup and it\u2019s highly customizable structure.It uses Box2D as physics backend and openGL for light rendering of environment(images aren\u2019t used in observations just there for checking your progress)", "The state consists of the following variables:", "If VEL_STATE(in code) is set to true, the velocities are included:", "Observations are very useful extracted features from physics simulation as such you wouldn\u2019t waste most of your computing power on CNN\u2019s to extract them hence our purpose to create a meaningful robotics/control algorithm replacement rather than full blown system.", "I have tried both options while there\u2019s is no big difference I would suggest you to turn on Velocity States for more information , it helps with agent learning , hence more relevant info better mentality. Be note all values has been normalized for smooth training process.", "Reward calculation is explained in this little snippet code. Basically takes fuel cost and your relative position to ground and rocket of weight to understand how correct your landing was done in terms of control mechanics and physics. Because you might not get a easy situation due random spawning but if you still recovered from that state you should get a decent reward signal", "I have tried 3 algorithms for this problem. D4PG,SAC and PPO with some modifications. I will talk briefly about each experience and results from them , you will able to find full codes for all 3 in repository. All of my agents done with continuous control inputs , feel free to check discrete case as well", "For all agents I have used PTAN a pyTorch based RL library that eases setting up agents handling process such as logging,network creation,setting & collecting up trajectories and more. I encourage to you to check out because most of time wasting time with boilerplate code is waste of time and prone to buggy code.While PTan isn\u2019t plug&train helps for what it\u2019s set out to do.", "One minor difference between DDPG and D4PG comes from action exploration. Instead of Ornstein-Uhlenbeck Process noise we just use a more simple random noise from normal(Gaussian) distribution . Calculating OU noise doesn\u2019t seems to provide much yet it complefiy the code so I mostly prefer D4PG.", "While I accidentally deleted TensorBoard logs of this run , I practically trained D4PG for 1 million steps and it seemed wasn\u2019t converging from losses and stuck on some local optima. Still I have some video from it. I still included code for it maybe with different batch sizes and random seeds you can train more efficiently.", "SAC is still one of SOTA algorithms in model free RL.In a nutshell it\u2019s differences can be stated as", "Entropy Regularization = Getting more bonus reward at each time stamp proportional to entropy of policy at current step", "Double Q Trick = You have 2 networks predicting Q values , choosing minimum of them for Bellman approximation results you with more smooth training process.", "This algorithm still builds up on conservative policy iteration ( TRPO,PPO etc). Instead of just maximizing lifetime awards it also tries to maximize entropy ( uncertainty in layman terms). So you can get best of both worlds , ability to learn efficiently from past experiences (experience replays) and more stable policy learning setup from on-policy methods.", "Rocket Environment is very complex compared to real world situation due randomized nature , at each time step rocket can spawn in a state that\u2019s very hard to recover even in real life. So you should always keep that in mind when evaluating this environment.You can modify environment to be more \u201crealistic\u201d aka a similar landing process to real life where it wouldn\u2019t do a rush emergency landing but I used default ones.After a while rewards started to pick up and agent stuck itself mostly fine on most cases. This training took 1 million steps with TESLA P100 (16GB VRAM and 21 TFlops of 16bit performance).", "PPO while outdone by some SOTA(state of the art) is still very useful algorithm to try on continuous control problems due easy to implement nature and very few hyperparams to change compared to other algorithms.", "I have went for a bigger trajectory this time and wanted to push my compute capabilities as much as possible in relative terms. I trained this network for 6 million steps.", "I suggest you get familiar with PTan for very easy experiments on different algorithms, it allows you to keep track of rewards(handles terminal states etc fairly easy even on multiple env setups) since code heavily uses them. Of course you can use your own code with my hyper params as well.", "This was a fun experience , it\u2019s really hard and dynamic problem with randomization factor added in you can modify it to be less random and easier to solve obviously you also can make it harder. I found PPO most stable during training but SAC got good results way before PPO while D4PG failed on me, it might be due my parameter choices feel free to try your own version and write results.", "You can access my repository which contains ready to train Google Colab notebooks , local train codes and saved models/logs. I also urge you to check Colab Pro which lets you train 24h on fast machines. In repository README you can find more about how to run code.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Reinforcement Learning , GAN & CNN. Occasionally embedded software development stuff"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7dde2374eb71&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ugurkanates.medium.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": ""}, {"url": "https://ugurkanates.medium.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Ugurkan Ates"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F49f8ecb2420a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&user=Ugurkan+Ates&userId=49f8ecb2420a&source=post_page-49f8ecb2420a----7dde2374eb71---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cosmosmagazine.com/space/launch-land-repeat-reusable-rockets-explained/#:~:text=The%20Falcon%209%20first%2Dstage,Fuel%20tanks%3A&text=These%20engines%20fire%20again%20as%20the%20rocket%20nears%20the%20landing%20platform.", "anchor_text": "cosmosmagazine.com"}, {"url": "https://www.inverse.com/article/33904-how-spacex-lands-a-falcon-9-rocket-in-6-steps", "anchor_text": "You can check more about in video form here"}, {"url": "https://www.youtube.com/watch?v=Wn5HxXKQOjw", "anchor_text": "https://www.youtube.com/watch?v=Wn5HxXKQOjw"}, {"url": "https://en.wikipedia.org/wiki/Motion_planning", "anchor_text": "path planning"}, {"url": "https://en.wikipedia.org/wiki/Reinforcement_learning", "anchor_text": "Reinforcement Learning"}, {"url": "https://mc.ai/solving-lunar-lander-openaigym-reinforcement-learning/", "anchor_text": "ref mc.ai"}, {"url": "https://github.com/Shmuma/ptan", "anchor_text": "https://github.com/Shmuma/ptan"}, {"url": "https://github.com/ugurkanates/SpaceXReinforcementLearning", "anchor_text": "ugurkanates/SpaceXReinforcementLearningSince this seems to be getting some more attention I've updated it to the latest version of Gym. I hope everything\u2026github.com"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----7dde2374eb71---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7dde2374eb71---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/spacex?source=post_page-----7dde2374eb71---------------spacex-----------------", "anchor_text": "Spacex"}, {"url": "https://medium.com/tag/control?source=post_page-----7dde2374eb71---------------control-----------------", "anchor_text": "Control"}, {"url": "https://medium.com/tag/rockets?source=post_page-----7dde2374eb71---------------rockets-----------------", "anchor_text": "Rockets"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&user=Ugurkan+Ates&userId=49f8ecb2420a&source=-----7dde2374eb71---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&user=Ugurkan+Ates&userId=49f8ecb2420a&source=-----7dde2374eb71---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7dde2374eb71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7dde2374eb71---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7dde2374eb71--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7dde2374eb71--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7dde2374eb71--------------------------------", "anchor_text": ""}, {"url": "https://ugurkanates.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ugurkanates.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ugurkan Ates"}, {"url": "https://ugurkanates.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "65 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F49f8ecb2420a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&user=Ugurkan+Ates&userId=49f8ecb2420a&source=post_page-49f8ecb2420a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F49f8ecb2420a%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspacex-falcon-9-landing-with-rl-7dde2374eb71&user=Ugurkan+Ates&userId=49f8ecb2420a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}