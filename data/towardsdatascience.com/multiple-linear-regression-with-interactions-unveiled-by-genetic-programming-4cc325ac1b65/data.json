{"url": "https://towardsdatascience.com/multiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65", "time": 1683012043.2841458, "path": "towardsdatascience.com/multiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65/", "webpage": {"metadata": {"title": "Multiple linear regression with interactions. | Towards Data Science", "h1": "Multiple linear regression with interactions unveiled by genetic programming", "description": "How to deal with linear regression when there are more variables and interactions among them with a new approach based on genetic programming."}, "outgoing_paragraph_urls": [{"url": "https://medium.com/analytics-vidhya/linear-regression-in-python-from-scratch-with-scipy-statsmodels-sklearn-da8e373cc89b", "anchor_text": "brief introduction with coding", "paragraph_index": 2}, {"url": "https://gplearn.readthedocs.io/en/stable/", "anchor_text": "gplearn", "paragraph_index": 2}, {"url": "https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271", "anchor_text": "genetic programming", "paragraph_index": 12}, {"url": "https://www.statsmodels.org/stable/index.html", "anchor_text": "statsmodels", "paragraph_index": 26}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html", "anchor_text": "sklearn polynomial features", "paragraph_index": 26}, {"url": "https://gplearn.readthedocs.io/en/stable/", "anchor_text": "gplearn", "paragraph_index": 26}, {"url": "https://www.linkedin.com/in/andrea-castiglioni314/", "anchor_text": "https://www.linkedin.com/in/andrea-castiglioni314/", "paragraph_index": 28}], "all_paragraphs": ["We all had some sort of experience with linear regression. It\u2019s one of the most used regression techniques used. Why? Because it is simple to explain and it is easy to implement. But what happens when you have more than one variable? How can you deal with this increased complexity and still use an easy to understand regression like this? And what happen if the system is even more complicated? Let\u2019s imagine when you have an interaction between two variables.", "Here is where multiple linear regression kicks in and we will see how to deal with interactions using some handy libraries in python. Finally we will try to deal with the same problem also with symbolic regression and we will enjoy the benefits that come with it!", "If you want to have a refresh on linear regression there are plenty of resources available and I also wrote a brief introduction with coding. What about symbolic regression? In this article we will be using gplearn. See its documentation for more informations or, if you like, see my other article about how to use it with complex functions in python here.", "We will explore two use cases of regression. In in the first case we will just have four variables (x1 to x4) which adds up plus some predetermined interactions: x1*x2, x3*x2 and x4*x2.", "Note that in our dataset \u201cout_df\u201d we don\u2019t have the interactions terms. What we will be doing will try to discover those relationships with our tools. This is how the variables look like when we plot them with seaborn, using x4 as hue (figure 1):", "The y of the second case (figure 2) is given by:", "The first step is to have a better understanding of the relationships so we will try our standard approach and fit a multiple linear regression to this dataset. We will be using statsmodels for that. In figure 3 we have the OLS regressions results.", "Ouch, this is clearly not the result we were hoping for. R\u00b2 is just 0.567 and moreover I am surprised to see that P value for x1 and x4 is incredibly high. We need some different strategy.", "What we can do is to import a python library called PolynomialFeatures from sklearn which will generate polynomial and interaction features. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a\u00b2, ab, b\u00b2].", "With \u201cinteraction_only=True\u201d only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.). The default degree parameter is 2.", "With the same code as before, but using Xt now, yields the results below.", "Now R\u00b2 in Figure 4 is 1 which is perfect. Too perfect to be good? In fact there are a lot of interaction terms in the summary statistics. Some that we did not even be aware of. Our equation is of the kind of: y = x\u2081+05*x\u2082+2*x\u2083+x\u2084+ x\u2081*x\u2082 \u2014 x\u2083*x\u2082 + x\u2084*x\u2082 So our fit introduces interactions that we didn\u2019t explicitly use in our function. Even if we remove those with high p-value (x\u2081 x\u2084), we are left with a complex scenario. This might be a problem for generalization. We can exploit genetic programming to give us some advice here.", "With genetic programming we are basically telling the system to do its best to find relationships in our data in an analytical form. If you read the other tutorial some functions I will call here will be clearer. However what we basically want to do is to import SymbolicRegressor from gplearn.genetic and we will use sympy to pretty formatting our equations. Since we are at it, we will also import RandomForest and DecisionTree regressors to compare the results between all those tools later on. Below the code to get it working:", "The converter dictionary is there to help us map the equation with its corrispondent python function to let simpy do its work. We also do train_test split of our data so that we will compare our predictions on the test data alone. We defined a function set in which we use standard functions from gplearn\u2019s set. At the 40th generation the code stops and we see that R\u00b2 is almost 1, while the formula generated is now pretty easy to read.", "If you compare it with the formula we actually used you will see that its a close match, refactoring our formula becomes:", "All algorithms performed good on this work: here are the R\u00b2.", "In this case the relationship is more complex as the interaction order is increased:", "We do basically the same steps as in the first case, but here we already start with polynomial features:", "In this scenario our approach is not rewarding anymore. It is clear that we don\u2019t have the correct predictors in our dataset. We could use polynomialfeatures to investigate higher orders of interactions but the dimensionality will likely increase too much and we will be left with no much more knowledge then before. Besides, if you had a real dataset and you did not know the formula of the target, would you increase the interactions order? I guess not!", "In the code below we again fit and predict our dataset with decision tree and random forest algorithms but also employ gplearn.", "The result is incredible: again after 40 generations we are left with an incredibly high R\u00b2 and even better a simple analytical equation.", "The original formula is like this:", "So we see that there are indeed differences on the terms which involves x1 and its interactions. While the terms which don\u2019t depend on it are perfectly there. Neverthless, if compared with the polynomialfeatures approach, we\u2019re dealing with a much less complicated formula here.", "What is the error of the different systems? Well for gplearn it is incredibly low if compared with other. In figure 8 the error in the y-coordinate versus the actual y is reported. While the x axis is shared, you can notice how different the y axis become. The maximum error with GPlearn is around 4 while other methods can show spikes up to 1000.", "In the first part of this article we saw how to deal with multiple linear regression in the presence of interactions. We used statsmodels OLS for multiple linear regression and sklearn polynomialfeatures to generate interactions. We then approached the same problem with a different class of algorithm, namely genetic programming, which is easy to import and implement and gives an analytical expression.", "In the second part we saw that when things get messy, we are left with some uncertainty using standard tools, even those from traditional machine learning. However, this class of problems is easier to face with the use of gplearn. With this library we were given an analytical formula for our problem directly.", "[1] statsmodels[2] sklearn polynomial features[3] gplearn", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m a physicist with a PhD in polymer physics working as a Data Scientist. https://www.linkedin.com/in/andrea-castiglioni314/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4cc325ac1b65&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@andrea.castiglioni?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.castiglioni?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Andrea Castiglioni"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17db10ba741b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&user=Andrea+Castiglioni&userId=17db10ba741b&source=post_page-17db10ba741b----4cc325ac1b65---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@johnmoeses?utm_source=medium&utm_medium=referral", "anchor_text": "John Moeses Bauan"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/analytics-vidhya/linear-regression-in-python-from-scratch-with-scipy-statsmodels-sklearn-da8e373cc89b", "anchor_text": "brief introduction with coding"}, {"url": "https://gplearn.readthedocs.io/en/stable/", "anchor_text": "gplearn"}, {"url": "https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271", "anchor_text": "here"}, {"url": "https://medium.com/analytics-vidhya/python-symbolic-regression-with-gplearn-cbc24dbbc271", "anchor_text": "genetic programming"}, {"url": "https://www.statsmodels.org/stable/index.html", "anchor_text": "statsmodels"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html", "anchor_text": "sklearn polynomial features"}, {"url": "https://gplearn.readthedocs.io/en/stable/", "anchor_text": "gplearn"}, {"url": "https://medium.com/tag/data-science?source=post_page-----4cc325ac1b65---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/analytics?source=post_page-----4cc325ac1b65---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----4cc325ac1b65---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4cc325ac1b65---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/genetic-algorithm?source=post_page-----4cc325ac1b65---------------genetic_algorithm-----------------", "anchor_text": "Genetic Algorithm"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&user=Andrea+Castiglioni&userId=17db10ba741b&source=-----4cc325ac1b65---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&user=Andrea+Castiglioni&userId=17db10ba741b&source=-----4cc325ac1b65---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4cc325ac1b65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4cc325ac1b65---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4cc325ac1b65--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.castiglioni?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.castiglioni?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andrea Castiglioni"}, {"url": "https://medium.com/@andrea.castiglioni/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "224 Followers"}, {"url": "https://www.linkedin.com/in/andrea-castiglioni314/", "anchor_text": "https://www.linkedin.com/in/andrea-castiglioni314/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17db10ba741b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&user=Andrea+Castiglioni&userId=17db10ba741b&source=post_page-17db10ba741b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4d46beefe5b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultiple-linear-regression-with-interactions-unveiled-by-genetic-programming-4cc325ac1b65&newsletterV3=17db10ba741b&newsletterV3Id=4d46beefe5b6&user=Andrea+Castiglioni&userId=17db10ba741b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}