{"url": "https://towardsdatascience.com/spark-vs-pandas-part-4-recommendations-35fc554573d5", "time": 1683016455.9930172, "path": "towardsdatascience.com/spark-vs-pandas-part-4-recommendations-35fc554573d5/", "webpage": {"metadata": {"title": "Spark vs Pandas, part 4\u2014 Recommendations | by Kaya Kupferschmidt | Towards Data Science", "h1": "Spark vs Pandas, part 4\u2014 Recommendations", "description": "Originally I wanted to write a single article for a fair comparison of Pandas and Spark, but it continued to grow until I decided to split this up. This is the second part of the small series. This\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/ml", "anchor_text": "implementation of the ML algorithms in Spark", "paragraph_index": 14}, {"url": "https://spark.apache.org/docs/3.0.1/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs", "anchor_text": "Pandas User Defined Functions", "paragraph_index": 22}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow", "paragraph_index": 24}], "all_paragraphs": ["Originally I wanted to write a single article for a fair comparison of Pandas and Spark, but it continued to grow until I decided to split this up. This is the second part of the small series.", "This last part of the series will give you some advice how to chose between both technologies for implementing a given task.", "After a detailed analysis of the two contenders Pandas and Spark, we can now summarize the strengths and weakness of both and provide indications when to use what.", "Pandas is simple to use and you find lots of valuable information and online resources. Pandas performs all it operations reasonably quick, as long as the amount of data is not too huge. It is well integrated into a whole ecosystem of numerical, statistical and machine learning libraries like SciKit Learn, Tensorflow and many more.", "Pandas does not scale at all. It cannot make use of multiple CPUs and the whole data set needs to fit into the RAM of your local machine. Some projects like Dask try to address these shortcomings, but that\u2019s a different story.", "Python as a language is a little bit weak due to being dynamically typed. Writing robust code is harder than with a statically and compiled language.", "Because of its simplicity, flexibility and availability I would always use Pandas for data exploration and for experiments \u2014 as long as the data fits into memory. Specifically for ML projects, I don\u2019t think twice and start with Pandas because of all the powerful libraries, which are well integrated with Pandas. Even if the final amount of data might be too large, Pandas and its friends still is a tool simple and flexible enough for first experiments with a subset of the full data set.", "On the other hand, nowadays I think twice before using Pandas for production workloads, because of the weaker correctness guarantees of Python as a dynamically typed language. But due to the availability of many important ML libraries, Python and Pandas also have their place in production. (Unfortunately).", "Spark shines in many areas where Pandas has some weaknesses, as we will see below.", "Spark scales very well \u2014 with number of CPUs, number of machines and probably most importantly with the amount of data. There is no real limit except time for how much data you can process with a limited amount of resources.", "Due to the availability of a vast number of connectors for all kinds of data sources and sinks, Spark is very well suited for integrating data from different origins.", "Finally by relying on Scala as a statically typed and compiled language, Spark code often has a higher inherent robustness than Python code. This makes Spark with Scala a very good candidate for production.", "Spark is made for huge amounts of data \u2014 although it is much faster than its old ancestor Hadoop, it is still often slower on small data sets, for which Pandas takes less than one second.", "Spark provides some ML algorithms, but you probably will never get a universe as rich as for Python.", "One thing to keep in mind is that Spark was designed as a relational algebra running in a cluster of machines \u2014 but the processing atoms of a relational algebra (joins, projections, filtering, aggregations, simple transformations etc) are distinct from the processing atoms of a matrix algebra (matrix multiplication, decomposition etc), which would be required by most ML algorithms. When you time some time and look at the implementation of the ML algorithms in Spark you will see that the developers had to transform numerical problems into a map/reduce problems for distributed processing. While this is possible, it is of course much harder than using a distributed matrix algebra, which in turn also explains the slow development of new features Spark in the ML area.", "Spark is perfect for typical ETL/ELT workloads, but only my second choice for machine learning projects due to the limited amount of available algorithms. If you have really huge amounts of data, where subsampling won\u2019t work, Spark is still a good candidate.", "So far I took the perspective of using either Pandas or Spark for a given task, but not combining them in a single application. But sometimes the world has some gifts for you, and this time it is PySpark. Although PySpark primarily is a Python wrapper around Spark, it includes a growing support for integrating Pandas code within Spark.", "The main driver supporting Pandas directly from within Spark is that even the Spark developers understood that Spark cannot and probably should not try to replace Pandas in certain scenarios, most notably in the ML part of projects. Instead Spark puts its development focus on integrating frameworks like Pandas and even Tensorflow.", "Spark basically offers two levels of integration of Pandas:", "The first, most simple and straight forward integration of Pandas is the ability to convert between Spark DataFrames and Pandas DataFrames. This allows a developer to use both frameworks and switch between them. But beware that Spark does not magically remove the limitations of Pandas: When converting a Spark DataFrame into a Pandas DataFrame, the whole data set again needs to fit into the RAM of your local machine.", "While this limitation can be a deal-breaker for some scenarios, it is acceptable in other scenarios where you use Spark to reduce the amount of data (by sampling or aggregations) and then use Pandas with its friends (SciKit Learn etc) to continue with the smaller data set.", "As we saw, simply switching back and forth between Spark DataFrames and Pandas DataFrames is not advisable, but fortunately there is a better way for using Pandas within a PySpark application:", "With version 2.3.0, Apache Spark introduced the so called Pandas User Defined Functions (UDFs) in addition to the already existing Python UDFs. Before version 2.3.0 the only way to write custom Python code which should be executed in parallel by Apache Spark on all executors was to write a small Python function containing the desired logic and wrapping that function into a Python UDF. Spark then would execute that UDF for every record.", "As nice as this sounds, that approach was notoriously slow. Python UDFs in Spark are implemented by exchanging data between Spark (which lives inside a JVM process) and multiple Python processes and then by calling the user defined Python function for every individual record. This approach contains two significant bottlenecks: First the data exchange involves CPU intensive data serialization and deserialization steps and second calling a Python function for every individual record is really slow.", "In order to improve the situation, Spark implemented a new API for creating Pandas UDFs to offer a significant performance boost. With Pandas UDFs, you now provide Python functions which don\u2019t work on individual records any more, but which transform either Pandas DataFrames or Series containing batches of multiple records to transform. Moreover by using Apache Arrow Spark does not need to perform the expensive serialization/deserialization any more. Instead Spark uses shared memory or directly passes memory blocks without any conversion to exchange data between the JVM and Python.", "This combination will bring features from both worlds into a single application: By using Pandas, you have a greater degree of flexibility, and by embedded your Pandas code in Spark, it is executed in parallel on multiple machines in the cluster.", "Do not try to replace Pandas with Spark, they are complementary to each other and have each their pros and cons.", "Whether to use Pandas or Spark depends on your use case. For most Machine Learning tasks, you probably will eventually use Pandas, even if you do your preprocessing with Spark. But for complex Data Engineering tasks which often also need to scale to huge amounts of data, I highly recommend to use Spark with Scala (don\u2019t be afraid of Scala \u2014investing into Scala will pay off from a projects point of view).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance Big Data and Machine Learning expert at dimajix."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F35fc554573d5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@kupferk", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kupferk.medium.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Kaya Kupferschmidt"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa1b1c406b9d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=post_page-a1b1c406b9d0----35fc554573d5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@carlevarino?utm_source=medium&utm_medium=referral", "anchor_text": "Cesar Carlevarino Aragon"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/spark-vs-pandas-part-1-pandas-10d768b979f5", "anchor_text": "Spark vs Pandas, part 1 \u2014 Pandas"}, {"url": "https://towardsdatascience.com/spark-vs-pandas-part-2-spark-c57f8ea3a781", "anchor_text": "Spark vs Pandas, part 2 \u2014 Spark"}, {"url": "https://towardsdatascience.com/spark-vs-pandas-part-3-scala-vs-python-7b267b130158", "anchor_text": "Spark vs Pandas, part 3 \u2014 Languages"}, {"url": "https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/ml", "anchor_text": "implementation of the ML algorithms in Spark"}, {"url": "https://spark.apache.org/docs/3.0.1/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs", "anchor_text": "Pandas User Defined Functions"}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "https://medium.com/tag/spark?source=post_page-----35fc554573d5---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----35fc554573d5---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/pandas?source=post_page-----35fc554573d5---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/big-data-analytics?source=post_page-----35fc554573d5---------------big_data_analytics-----------------", "anchor_text": "Big Data Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=-----35fc554573d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=-----35fc554573d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F35fc554573d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----35fc554573d5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----35fc554573d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----35fc554573d5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----35fc554573d5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----35fc554573d5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----35fc554573d5--------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kaya Kupferschmidt"}, {"url": "https://kupferk.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "223 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa1b1c406b9d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=post_page-a1b1c406b9d0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F874fa4e516b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspark-vs-pandas-part-4-recommendations-35fc554573d5&newsletterV3=a1b1c406b9d0&newsletterV3Id=874fa4e516b6&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}