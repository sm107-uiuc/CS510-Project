{"url": "https://towardsdatascience.com/understanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278", "time": 1682995403.127666, "path": "towardsdatascience.com/understanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278/", "webpage": {"metadata": {"title": "Understanding AlphaGo: how AI thinks and learns (Fundamentals) | by Shen Huang | Towards Data Science", "h1": "Understanding AlphaGo: how AI thinks and learns (Fundamentals)", "description": "Join me in an adventure of learning how game AI works\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.forbes.com/sites/cognitiveworld/2019/02/24/ai-plays-games/#27fe5ce94a49", "anchor_text": "2016", "paragraph_index": 1}, {"url": "https://oeis.org/A008937", "anchor_text": "177", "paragraph_index": 16}, {"url": "https://sscaitournament.com/index.php?action=botDetails&bot=SAIDA", "anchor_text": "SSCAIT 2018", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Finite-state_machine#Mathematical_model", "anchor_text": "here", "paragraph_index": 32}, {"url": "https://medium.freecodecamp.org/how-to-drop-leprechaun-hats-into-your-website-with-computer-vision-b0d115a0f1ad", "anchor_text": "here", "paragraph_index": 35}, {"url": "http://www.gatsby.ucl.ac.uk/~dayan/papers/cjch.pdf", "anchor_text": "here", "paragraph_index": 46}, {"url": "https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#Exploration_and_exploitation", "anchor_text": "here", "paragraph_index": 49}, {"url": "https://towardsdatascience.com/understanding-alphago-how-ai-thinks-and-learns-advanced-d70780744dae", "anchor_text": "second part", "paragraph_index": 53}], "all_paragraphs": ["\u201cI visualize a time when we will be to robots what dogs are to humans, and I\u2019m rooting for the machines.\u201d", "Developed by DeepMind, AlphaGo has gained the world\u2019s attention after defeating the top human players of the world in a game of go in the year 2016. The more powerful version, named AlphaZero, continues to thrive in games such as Go and Chess. A variation called AlphaStar, had an increasingly good performance playing real-time strategy games against professional human players. We are in the age where machines are taking over our tasks, and in some particular field, they are doing better jobs than us humans.", "But how do those AI work exactly? In this article, we will go over how these game AI works starting from the basics. We will start with the old school adversarial search and state machines. Then we will explore a bit in the field of machine learning, from reinforcement learning to Monte Carlo tree search we will understand how modern AI learn by themselves (with Pok\u00e9mon \u03de\u03de(\u0e51\u2688 \u2024\u032b \u2688\u0e51)\u2229 as examples).", "Then we will go into part 2, where we will dive deeper into deep learning, mainly focusing on artificial neural networks and convolutional neural networks. After that, we should be able to understand the policy networks and value networks for AlphaGo.", "Do not get scared away by those terminologies, as you will understand them like a pro by the end of this article. I hope this article can dispel some of the myths towards artificial intelligence, answer the doubts and encourage more interest in this field of study. If you are ready, let our journey begin!", "\u201cOur intelligence is what makes us human, and AI is an extension of that quality.\u201d", "The first concept of artificial intelligence can go as far back into the ancient Greek mythologies. Hephaestus \u2014 the Greek god of blacksmiths, metalworking, carpenters, craftsmen, artisans, sculptors, metallurgy, fire, and volcanoes, crafted Talos \u2014 a bronze automaton, at the request of his father \u2014 Zeus, to protect Zeus\u2019s consort Europa from being kidnaped. Hephaestus was also known to be the creator of Pandora \u2014 a perfect woman as a gift to mankind, holding the \u201cPandora\u2019s Box\u201d \u2014 an evil jar that released all the wicked sins to humanity while having \u201chope\u201d under the lip of the jar.", "Back around 350 BC, the great philosopher Aristotle described a method of formal, mechanical thought through deductive reasoning known as \u201csyllogism\u201d. In the year 1206, the Ismail al-Jazari created a programmable automaton known as the \u201cmusical robot band\u201d. Many other brilliant people were inspired throughout the centuries. A famous one being Alan Turing, who invented an algorithm in the year 1950 to play chess with his friends before the computers were invented. (He lost that game by the way) And of-course, Turing was also famous for his \u201cTuring test\u201d which we will go through more in detail later.", "During the summer of the year 1956, the field of research of artificial intelligence formally started inside a workshop at Dartmouth College, Hanover, New Hampshire. The term \u201cartificial intelligence\u201d describes human-invented machines that are cognitively capable. There are many sub-fields of this research, such as computer vision, natural language processing, machine learning, expert systems, and the topic that we will be discussing today \u2014 game AI.", "We are going to start with two fundamental algorithms used in-game artificial intelligence \u2014 the adversarial search, and the state machine. From these building blocks, we can then go deeper into more advanced algorithms.", "Adversarial search, sometimes known as minimax search, is an algorithm often used in games involving adversarial relationships between the players. The game can generally be optimized with alpha-beta pruning, which will be covered later in this section.", "The algorithm can be applied to games such as Tic-Tac-Toe or Nim, which I have attached the games below along with the rules. You can try playing with the computer in the game \u2014 Hint: You will never win, and we will see why in a moment.", "Tic-Tac-Toe is a game where both players trying to put their \u201cX\u201d or \u201cO\u201d symbol inside a 3 by 3 board. The player wins by having their symbol forming a connection with the length of 3. The connection can be either horizontal, vertical or diagonal.", "Nim is a game where the players trying to take a certain number of chips from a set of chips, the players will have to take at least 1 chip every turn. The player who took the last chip(s) from the game wins the game.", "Now let us get to the serious topics today \u2014 adversarial search. The adversarial search creates a tree of all the possible game states, branched by the available choices. In a game of Nim with 3 maximum chip takes, for example, each player can take either 1, 2, or 3 chips, that makes 3 branches for each tree node as shown below.", "The tree ends when no more chips are remaining. The player who took the last chip(s) wins the game.", "The tree contains all the possible game states, in this case, 177 states. By searching through all the game states the computer will know the outcome of the game before making any moves.", "\u2014 Futurama S2E02 Brannigan, Begin Again", "In the field of computer science, we also value the efficiency of the algorithms. Less amount of computation and memory consumption means a lighter load on the hardware and electricity consumption, resulting in a reduced cost running the algorithm. And thus, rather than going over every possible state, there are many ways to simplify the problem.", "For example, the 8 states of tic-tac-toe shown below are rotationally equivalent, and thus we can consider them as 2 states instead. These types of translational and rotational equivalencies will be discussed in more detail as we dive into convolutional neural networks in a later section.", "By eliminating the extra states, the size of the search tree can be greatly reduced. There are over 3500 states in the first 4 layers of the search tree if such a reduction is not applied. Searching through 3500 states is not much of a task for a modern computer, but the number grows exponentially and can go to the scale of microseconds of the age of our universe when it goes to a bigger board such as chess.", "Eliminating the identical states in the first layer cuts 2/3 of the extra states, but can we do better? There is a little trick called alpha-beta pruning which we will discuss in the next section.", "\u201cI never underestimate my opponent, but I never underestimate my talents.\u201d", "Imagine when you are playing a game of tic-tac-toe, when your opponent already had 2 pieces that are connected, you will always want to block him on the other end. Why? Because you can assume that he will win in the next turn if you don\u2019t. That is the idea of alpha-beta pruning, you always expect your opponent trying their best to win.", "For a game of tic-tac-toe, the outcome is usually evaluated as binary. For some more complicated games such as chess, however, the board can be evaluated with a score. For example, the sum of the score of white pieces minus the sum of the score of the black pieces. And this is when alpha-beta pruning can become helpful for eliminating the branches. Here is a video below explaining alpha-beta pruning with chess.", "Algorithms Explained \u2014 minimax and alpha-beta pruning", "As for the Nim game, the AI uses a much simpler rule base. We went over the search tree just because it is easier to explain search trees with Nim. The AI will divide the chips into chucks with a size of 1 chip greater than the maximum allowed pick, and make sure each time one entire chunk gets picked by picking the difference between chunk size and player\u2019s pick. If the chuck is not divisible, the AI will move first and pick the remainder. This way, there is no way for the player to win.", "For a game such as chess, all the possible states cannot be searched easily like in tic-tac-toe or nim. But a computer that can search over 30 layers deep is already insanely difficult to beat, as most players cannot foresee that many moves.", "\u201cSimple can be harder than complex: You have to work hard to get your thinking clean to make it simple.\u201d", "The state machine, usually referring to a Finite State Machine, is an often-underestimated concept in-game AI nowadays especially after machine learning gained huge popularity over the years. However, such old-school design dominated with a win rate of 96.15% in the SSCAIT 2018 challenge playing against other StarCraft AI using machine learning.", "Outside the field of game AI, state machines are also applied widely into fields such as this cool phone assistant AI from Google. In this section, we will go into the theory behind all such wonders.", "A finite state machine, sometimes called a finite state automaton, is usually represented by a group of connected nodes, formally called a \u201cgraph\u201d. The graph below demonstrates how typical readers interact with my article.", "Inside the circles are what we call the \u201cstates\u201d, and the arrows are called the \u201cstate-transition function\u201d. The state-transition function is usually described by a condition. For example, when my reader is at \u201creader liked my article\u201d state, they might transition to \u201creader claps my article\u201d state if \u201cI ask for claps\u201d or \u201creader remembered to clap\u201d. A more formal mathematical definition of the finite state machine can be found here.", "There are many interesting theories developed around it which eventually leads to two of the big topics in computer science, the NP vs. P problem and the Turing Machine. Machine learning algorithms such as Markov Chain also shares some of the concepts in the state machine. We will go over the Markov Decision Process in the next section when we learn about Reinforcement Learning.", "\u201cA computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\u201d", "As a widely used quote, Tom M. Mitchell formally defined the concept of machine learning as a computer program that incrementally improves performance with accumulated experiences. Driven by a machine learning algorithm, the machines will incrementally advance themselves with the new information they received. Related algorithms are vastly applied in many fields that are changing our life nowadays, such as Snapchat filters that detect our face, or Google translator helping us understanding others who speak foreign languages. If you are interested in some of those applications, I have also written a tutorial relating to facial detection which can be found here.", "In this section, we will learn about a popular area of machine learning for game AI \u2014 Reinforcement Learning. The popular neural network will be gone over in the deep learning section afterward.", "\u201cFailure is simply the opportunity to begin again, this time more intelligently.\u201d", "\u201cReinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.\u201d", "To understand, the following diagram is an example illustrating the fundamental concept of reinforcement learning.", "There are several concepts of reinforcement learning, which we can understand from the above example where claps encourage the writer to write better articles (and ask for more claps).", "The agent will attempt to optimize the outcome evaluated by the interpreter, and there are several approaches. In this section we will go over 2 popular approaches used in-game AI \u2014 Q-Learning and Monte Carlo Tree Search. Once we understand those two, we should be able to understand Deep Q-Learning in the later sections.", "Q-Learning is the simplest form of Reinforcement Learning. The goal of Q-Learning is to learn a policy that optimizes the evaluated outcome of the agent. The flow-diagram below explains how it works for a player trying to find the best Pok\u00e9mon to use.", "The policies are usually defined by matrices recording the chances of each action at each state. The agent will perform the action based on the policies, and then update the policies based on the outcome of the action. For example, if the opponent summoned Squirtle, the agent will randomly pick a Pok\u00e9mon. If the agent picked Pikachu and found out to be very effective against Squirtle, the agent will then update the policies, so it is more likely for it to counter Squirtle with Pikachu in the future. There are two other notable concepts we should go over, the learning rate and the Markov decision process.", "Learning describes how fast the model learns. For example, the percentage can increase by 1% for a low learning rate or 15% for a high learning rate for the same outcome of \u201cvery effective\u201d.", "Markov decision process is a state diagram describing the states and actions of the agents and the environment. It also describes the probability of transition between each state and reward for each state.", "For more information on the serious math definition and proof of convergence of Q-learning, you can read them here.", "Monte Carlo Tree Search (MCTS) works similar to Adversarial Search covered in the previous section. The main difference is MCTS randomly chooses a branch to go down rather than trying to iterate through all the branches. The algorithm then establishes a profile from the outcome from that branch.", "Formally, the Monte Carlo Tree Search has the following 4 states:", "This algorithm is especially useful in games where the number of states is large, as it would be almost impossible to go through all the states. By learning from the experiences generated from previous game plays, more intelligent decisions can be made in the future. More readings on deciding the nodes between exploration and exploitation can be found here.", "Below is a video on how an AI plays Super Mario with the algorithm.", "AI Playing Mario with Monte Carlo Tree Search", "Reinforcement learning is an interesting field of study with many different branches. The two we have covered in this section will surely aid us in understanding the more advanced material in the sections afterward.", "Congratulations for making it this far, we are halfway through our journey understanding how modern game AI think and learn. In the second part of this article, we will go over deep learning and neural networks, then we can finally go into the architecture of those DeepMind AI.", "Also, let me know which kind of writing style you liked the most, I can do the classic documentary, serious thesis, or those flashy Pok\u00e9mon examples. Your feedback is what allows me to learn the best policy matrix \ud83e\udd16.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fda07d3ec5278&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@shenhuang_21425?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shenhuang_21425?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Shen Huang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F75d92e349c1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&user=Shen+Huang&userId=75d92e349c1c&source=post_page-75d92e349c1c----da07d3ec5278---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.forbes.com/sites/cognitiveworld/2019/02/24/ai-plays-games/#27fe5ce94a49", "anchor_text": "2016"}, {"url": "https://www.smithsonianmag.com/innovation/google-ai-deepminds-alphazero-games-chess-and-go-180970981/", "anchor_text": "Smithsonian.com"}, {"url": "http://greekmythology.wikia.com/wiki/Talos", "anchor_text": "FANDOM"}, {"url": "https://en.wikipedia.org/wiki/Ismail_al-Jazari", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Dartmouth_College", "anchor_text": "Wikipedia"}, {"url": "https://oeis.org/A008937", "anchor_text": "177"}, {"url": "https://www.youtube.com/watch?v=XtgZKwK6C3U", "anchor_text": "Futurama S2E02"}, {"url": "https://sscaitournament.com/index.php?action=botDetails&bot=SAIDA", "anchor_text": "SSCAIT 2018"}, {"url": "https://sscaitournament.com/", "anchor_text": "SSCAIT"}, {"url": "https://en.wikipedia.org/wiki/Finite-state_machine#Mathematical_model", "anchor_text": "here"}, {"url": "http://www.cs.cmu.edu/~tom/", "anchor_text": "Tom M. Mitchell"}, {"url": "https://medium.freecodecamp.org/how-to-drop-leprechaun-hats-into-your-website-with-computer-vision-b0d115a0f1ad", "anchor_text": "here"}, {"url": "http://www.gatsby.ucl.ac.uk/~dayan/papers/cjch.pdf", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#Exploration_and_exploitation", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/understanding-alphago-how-ai-thinks-and-learns-advanced-d70780744dae", "anchor_text": "second part"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----da07d3ec5278---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/technology?source=post_page-----da07d3ec5278---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/alphago?source=post_page-----da07d3ec5278---------------alphago-----------------", "anchor_text": "Alphago"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----da07d3ec5278---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/games?source=post_page-----da07d3ec5278---------------games-----------------", "anchor_text": "Games"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&user=Shen+Huang&userId=75d92e349c1c&source=-----da07d3ec5278---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&user=Shen+Huang&userId=75d92e349c1c&source=-----da07d3ec5278---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fda07d3ec5278&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----da07d3ec5278---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----da07d3ec5278--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----da07d3ec5278--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----da07d3ec5278--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shenhuang_21425?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@shenhuang_21425?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Shen Huang"}, {"url": "https://medium.com/@shenhuang_21425/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "367 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F75d92e349c1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&user=Shen+Huang&userId=75d92e349c1c&source=post_page-75d92e349c1c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2b688ff06a54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278&newsletterV3=75d92e349c1c&newsletterV3Id=2b688ff06a54&user=Shen+Huang&userId=75d92e349c1c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}