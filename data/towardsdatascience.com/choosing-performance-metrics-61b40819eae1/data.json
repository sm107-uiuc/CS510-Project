{"url": "https://towardsdatascience.com/choosing-performance-metrics-61b40819eae1", "time": 1683015685.6194391, "path": "towardsdatascience.com/choosing-performance-metrics-61b40819eae1/", "webpage": {"metadata": {"title": "Choosing Performance Metrics. Accuracy, recall, precision, F1 score \u2014\u2026 | by S. T. Lanier | Towards Data Science", "h1": "Choosing Performance Metrics", "description": "Accuracy, recall, precision, F1 score\u2013\u2013how do you choose a metric for judging model performance? And once you choose, do you want the macro average? Weighted average? For each of these metrics, I\u2019ll\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity#cite_note-1", "anchor_text": "healthcare, where the distinction between specificity and sensitivity originated", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Harmonic_mean", "anchor_text": "harmonic mean", "paragraph_index": 18}, {"url": "https://www.youtube.com/watch?v=kfEuqcA6vYw", "anchor_text": "Here\u2019s a good video", "paragraph_index": 18}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report", "paragraph_index": 22}], "all_paragraphs": ["Accuracy, recall, precision, F1 score\u2013\u2013how do you choose a metric for judging model performance? And once you choose, do you want the macro average? Weighted average? For each of these metrics, I\u2019ll look more closely at what it is and what its best use cases are. I\u2019ll also walk through how to read the output table from scikit-learn\u2019s classification_report, pictured above.", "I\u2019m starting with accuracy because I think, by its name, we feel we have an intuitive understanding of it without ever having seen any mathematical formulae. \u201cWe want a more accurate model.\u201d Always, and we haven\u2019t even defined it in a rigorous sense yet. I certainly did (and still do) start with accuracy in a project because it feels familiar and unspecialized.", "Abstractly, accuracy is just the percentage of predictions that were made correctly, expressed as a decimal number between 0 (0% of predictions correct) and 1 (100% of predictions correct).", "And because looking ahead TP (true positive), FP (false positive), TN (true negative), and FN (false negative) will be important for later metrics, let\u2019s go ahead and talk about their connection to accuracy too.", "To take an example, if we\u2019re trying to classify images into two categories, dogs and not-dogs, our model is going to predict only 1) that the image is of a dog, in which case it can be correct, and the image really is of a dog (TP), or incorrect, and the image is not of a dog, though the model thinks it is (FP); or 2) the model can predict that the image is NOT of a dog, in which case it can again be correct, and the image really is not of a dog (TN), or incorrect, and the image is in fact of a dog, though the model thinks it is not (FN).", "Looking above then, we can tell that no matter which definition for accuracy we use, we\u2019re just dividing the number of predictions the model got right against its total number of predictions.", "Meeting with intuition, accuracy really is a sort of goldilocks for most generic, uncomplicated datasets you run up against. As long as classes are more or less balanced (equal numbers of dog and not-dog images in the previous example), accuracy does a pretty good job of blending specificity and sensitivity, recall and precision. Specificity and sensitivity are themselves pretty specific words in this case, as are recall and precision, and we should talk about them next.", "Like accuracy, I think we already have a pretty intuitive understanding of specificity and sensitivity, or at least feel we do, but the reality is they come with some pretty specific definitions in the world of statistics.", "Sensitivity, which, spoiler, is the same thing as recall, is also called the true positive rate (TPR), and is, in common English, the fraction of all the real YESes that got put in the right bin; in the earlier example, of the images that really are of dogs, what fraction of them did the model get right and call dogs? How good is the model at catching YESes? That\u2019s what sensitivity/recall/TPR answers.", "You\u2019ll notice something interesting here: we haven\u2019t included anything about the not-dog images. In fact, if you really think about that equation above, you realize those not-dog, or NO, images, and the model\u2019s success or failure to predict or classify them (TN and FP), don\u2019t affect sensitivity/recall at all. In fact, again taking the earlier example, a model that predicted \u201cyes, dog\u201d for every single image given to it would have perfect sensitivity/recall/TPR.", "This gives sensitivity/recall/TPR a pretty specific use case, and it boils down to this: use it when when every instance of what you\u2019re looking for is too precious to let slip by. Examples include detecting terrorist attacks, detecting illnesses, detecting fraud, etc. In every case, a sensitivity-focused model will catch all real terrorist attacks, all true cases of heart disease, and all really fraudulent credit card purchases with the caveat that it will also pull some instances that are false positives: there will be some innocent travelers, some healthy people, some normal Target purchases pinged.", "Specificity, also called the true negative rate (TNR), is the other side of the coin from sensitivity. It cares about everything sensitivity does, but for the NO cases (the really not-dogs).", "A model that calls \u201cnot a dog\u201d for every single image given to it would have perfect specificity (and, consequently, a 0 for sensitivity). It\u2019s the inverse of sensitivity/recall, and often the choice between the two comes down to which you\u2019re focusing on, the YESes or the NOs. In an ideal world, you get a model that excels at both, but sometimes we\u2019re forced to choose, especially in healthcare, where the distinction between specificity and sensitivity originated.", "Recall we\u2019ve already talked about\u2013\u2013it\u2019s sensitivity\u2013\u2013 and precision, on the third hand \u2014 happy Halloween, everybody \u2014 is this: of all the stuff the model pinged as YESes (dogs), what fraction of them are correct (really dogs)?", "Like sensitivity and specificity, there\u2019s an element of the model\u2019s performance that\u2019s ignored when calculating precision, but this time it\u2019s everything the model pinged as a NO that\u2019s ignored. If there were 1,000 pictures, 500 of dogs, 500 of not-dogs, and the model only classified 5 of the dogs correctly, and called everything else not-dogs, that would be perfect, 1.0 precision (even though 495 of the dog pictures were missed by the classifier).", "Precision, then, has a pretty specific use case too. Focus on it when you want to be confident in the YESes the model gives you. Sure, it\u2019s going to miss some YESes, but what it does ping, if the model has good precision, you can be confident in.", "Short answer, F1 score is the harmonic average of recall and precision, taking values between 0 and 1.", "When you replace recall and precision with their TP/FP/TN/FN definitions, you get this definition for F1 score:", "Maybe, like me, you\u2019ve never heard of harmonic mean. Here\u2019s a good video explaining it with an example, but the quick and dirty is that its most common use case is to average rates, for which our familiar arithmetic mean won\u2019t suffice.", "If you go back up to that first equation for F1 score, you can tell by looking at the second definition, the one with recall MULTIPLIED by precision in the numerator, that if either recall or precision is 0 then so is F1 score. This makes it a great compromise between recall and precision so that you don\u2019t get extreme cases like the examples I\u2019ve been giving. In that most recent example, with only 5 correctly classified pictures of dogs, precision is 1.0, but recall is 5/500 = 0.01, so F1 score is similarly held back at (approximately) 0.02. Accuracy, for the record, is 0.51.", "Both accuracy and F1 (0.51 and 0.02 respectively) are reflecting poor overall performance in this case, but that\u2019s because this is a balanced dataset. In an imbalanced dataset, F1 score but not accuracy will capture a poor balance between recall and precision. That\u2019s F1 score\u2019s use case.", "An example: 5 pictures of dog, 995 pictures of anything else (imbalanced). We get a classifier running, and it correctly gets one of those dog pictures classified, but calls everything else not-a-dog. That means there are 4 incorrectly classified pictures of dogs. Recall is 0.2 (pretty bad) and precision is 1.0 (perfect), but accuracy, clocking in at 0.999, isn\u2019t reflecting how badly the model did at catching those dog pictures; F1 score, equal to 0.33, is capturing the poor balance between recall and precision.", "classification_report from scikit-learn was surprisingly difficult for me to read the first time I saw it, so much so that I put off choosing a metric for the project because I couldn\u2019t figure out where any of them were on this report. I wish someone had given me the cheatsheet above.", "I think part of what made it so hard to read is that it prints out accuracy, and then macro avg and weighted avg, which my brain attributed to accuracy; but that\u2019s wrong, they belong to precision, recall, and f1-score. There\u2019s exactly one number that belongs to accuracy, and I drew a dotted box around it in red above.", "Precision, recall, and F1 score, each in its own green box above, are all broken down by class, and then a macro average and weighted average are given for each. Macro average is the usual average we\u2019re used to seeing. Just add them all up and divide by how many there were. Weighted average considers how many of each class there were in its calculation, so fewer of one class means that it\u2019s precision/recall/F1 score has less of an impact on the weighted average for each of those things. support, boxed in orange, tells how many of each class there were: 1 of class 0, 1 of class 1, 3 of class 2.", "To read the chart above, for example, might go like this: precision was 0.5, 0, and 1 for class 0, class 1, and class 2, respectively. That means that of the things the model classified as class 0, only 50% of them really were; of the things the model classified as class 1, 0% of them really were; and of the things the model classified as class 2, 100% of them really were. The macro average precision is 0.5, and the weighted average is 0.7. The weighted average is higher for this model because the place where precision fell down was for class 1, but it\u2019s underrepresented in this dataset (only 1/5), so accounted for less in the weighted average.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Student of data science. Translator (\u65e5\u672c\u8a9e). Tutor. Bicyclist. Stoic. Tea pot. Seattle."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F61b40819eae1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://stlanier.medium.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": ""}, {"url": "https://stlanier.medium.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "S. T. Lanier"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d41f0a85642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&user=S.+T.+Lanier&userId=5d41f0a85642&source=post_page-5d41f0a85642----61b40819eae1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report"}, {"url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity#cite_note-1", "anchor_text": "healthcare, where the distinction between specificity and sensitivity originated"}, {"url": "https://en.wikipedia.org/wiki/Harmonic_mean", "anchor_text": "harmonic mean"}, {"url": "https://www.youtube.com/watch?v=kfEuqcA6vYw", "anchor_text": "Here\u2019s a good video"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "classification_report"}, {"url": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity", "anchor_text": "https://en.wikipedia.org/wiki/Sensitivity_and_specificity"}, {"url": "https://en.wikipedia.org/wiki/Precision_and_recall", "anchor_text": "https://en.wikipedia.org/wiki/Precision_and_recall"}, {"url": "https://en.wikipedia.org/wiki/F-score", "anchor_text": "https://en.wikipedia.org/wiki/F-score"}, {"url": "https://sebastianraschka.com/faq/docs/computing-the-f1-score.html", "anchor_text": "https://sebastianraschka.com/faq/docs/computing-the-f1-score.html"}, {"url": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c", "anchor_text": "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html", "anchor_text": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"}, {"url": "https://medium.com/tag/recall?source=post_page-----61b40819eae1---------------recall-----------------", "anchor_text": "Recall"}, {"url": "https://medium.com/tag/precision?source=post_page-----61b40819eae1---------------precision-----------------", "anchor_text": "Precision"}, {"url": "https://medium.com/tag/f1?source=post_page-----61b40819eae1---------------f1-----------------", "anchor_text": "F1"}, {"url": "https://medium.com/tag/imbalanced-data?source=post_page-----61b40819eae1---------------imbalanced_data-----------------", "anchor_text": "Imbalanced Data"}, {"url": "https://medium.com/tag/metrics?source=post_page-----61b40819eae1---------------metrics-----------------", "anchor_text": "Metrics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&user=S.+T.+Lanier&userId=5d41f0a85642&source=-----61b40819eae1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&user=S.+T.+Lanier&userId=5d41f0a85642&source=-----61b40819eae1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F61b40819eae1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----61b40819eae1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----61b40819eae1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----61b40819eae1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----61b40819eae1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----61b40819eae1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----61b40819eae1--------------------------------", "anchor_text": ""}, {"url": "https://stlanier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://stlanier.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "S. T. Lanier"}, {"url": "https://stlanier.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "70 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d41f0a85642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&user=S.+T.+Lanier&userId=5d41f0a85642&source=post_page-5d41f0a85642--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe8e65edd7262&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-performance-metrics-61b40819eae1&newsletterV3=5d41f0a85642&newsletterV3Id=e8e65edd7262&user=S.+T.+Lanier&userId=5d41f0a85642&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}