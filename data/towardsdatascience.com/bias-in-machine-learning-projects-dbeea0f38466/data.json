{"url": "https://towardsdatascience.com/bias-in-machine-learning-projects-dbeea0f38466", "time": 1683016218.000382, "path": "towardsdatascience.com/bias-in-machine-learning-projects-dbeea0f38466/", "webpage": {"metadata": {"title": "Bias in Machine Learning Projects | by Luigi Saetta | Towards Data Science", "h1": "Bias in Machine Learning Projects", "description": "I was preparing a webinar and I was thinking about what subjects could be interesting for it, between the many different subjects that come out in my mind. I thought that to be successful in\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Bias", "anchor_text": "Wikipedia", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Closed-minded", "anchor_text": "closed-minded", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Prejudice", "anchor_text": "prejudicial", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Systematic_error", "anchor_text": "systematic error", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Melanoma", "anchor_text": "melanoma", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1901.10002.pdf", "anchor_text": "A framework for understanding unintended consequences of Machine Learning Models", "paragraph_index": 26}, {"url": "https://www.nytimes.com/2019/02/19/technology/youtube-conspiracy-stars.html", "anchor_text": "YouTube unleashed a conspiracy theory boom. Can it be contained?", "paragraph_index": 37}, {"url": "https://arxiv.org/pdf/2007.13019.pdf#:~:text=Recommendation%20algorithms%20are%20known%20to,known%20as%20a%20feedback%20loop.", "anchor_text": "arXiv", "paragraph_index": 38}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "https://christophm.github.io/interpretable-ml-book/lime.html", "paragraph_index": 44}, {"url": "https://luigisaetta.it/index.php/machine-learning/52-bias-in-machine-learning-projects", "anchor_text": "https://luigisaetta.it", "paragraph_index": 58}], "all_paragraphs": ["I was preparing a webinar and I was thinking about what subjects could be interesting for it, between the many different subjects that come out in my mind.", "I thought that to be successful in realizing a Machine Learning project, one should be really aware of what are the pitfalls, what are the points, during the project, where you can do important mistakes.", "One area of concern for sure is regarding BIAS. For this reason, I decided to devote some of my time and prepared the following notes.", "Well, let\u2019s start with a definition. And I will take the one coming from Wikipedia: \u201c Bias is a disproportionate weight in favor of or against an idea or thing, usually in a way that is closed-minded, prejudicial, or unfair. \u2026People may develop biases for or against an individual, a group, or a belief. In science and engineering, a bias is a systematic error\u201d.", "So, we could start by saying that bias is a systematic error in our Machine Learning (ML) model.", "When we develop a supervised model (for now, let us limit our discussion on this type of model), given a set of inputs X = (x1, \u2026 xn) we want to be able to predict the most probable value for a related y. We think there is a meaningful relationship between X and y", "and we want to train a model, starting from a large set of examples, where for each sample we give the input values (X) and the corresponding expected value y.", "The model uses some very general algorithm (for example a Neural Network) but it learns all his knowledge from the data used during the training.", "Usually, during the development of the model, one part of the available data is taken apart (held-out) for validating the model. During this phase normally one wants to verify if the model has learned a generalizable knowledge. In other words, if it performs well on data unseen during the training phase. But, before being ready to use the model in production, on real-world data, many tests should be done to verify that the model is correct.", "We might discover that our model tends to give favorable predictions to some samples (that could be related to people) and less favorable to others, in a systematic and unjustified way. Good if we discover this issue before using the model in production.", "One example: let\u2019s imagine that we have developed a Deep Learning model that could help us in diagnosis melanoma, using as input a picture of a portion of the skin.", "Based on our validation set, it seems that our model has a nice accuracy (90%?), but then we start a field evaluation study and we discover that the model doesn\u2019t work well on people with dark skin. It tends to have a higher rate of errors in this group of people, systematically. We have discovered a bias in our model.", "Definitively it is a mistake we have done somewhere. But it is a mistake that produces errors systematically, not randomly.", "We do a careful analysis of the data collection process and we discover that our dataset contains a higher percentage of people with fair-skinned people. Simply, because it is well known that those people have higher risks coming from exposition to the sun (that is one of the risk factors). Adding more examples of lesions from people with dark skin helps to improve the accuracy in this sub-population and reduce the bias in our model.", "Is it something that has necessarily to do with ethics, with what we think is fair or unfair?", "Well, this is probably one of the big questions we would like to answer. But it is not the only one. For now, we can say yes and no.", "Let me try to express my first idea: every time we develop a rule that in some way treats differently several groups of people we should ask ourselves if it is fair. And the answer is not easy, because there is no universally accepted definition of what is fair and what is not.", "Fairness cannot be mathematically measured (this doesn\u2019t mean that we shouldn\u2019t make the question, which means that the answer is not easy).", "But, here the problem is always seen bigger because we have an ancestral fear that Computers, sooner or later, will take decisions instead of us. And, at the end of the story, an ML model is something that makes decisions.", "As in every field of Science, before getting to any conclusions, we should gather all the relevant information (and in this process, we should be unbiased!).", "So, we should first try to understand where bias could come from.", "The development of an ML model is almost always a long process, with a series of steps. Let\u2019s try to make a summary:", "Well, probably this is not the only way to summarize the development process. But I think it is a good one to support our discussion.", "As we look at the steps detailed above, we should think that in every one of these steps we can make mistakes. And, some of these mistakes could condition our model to give systematical errors on one or more of the sub-population of the samples.", "Therefore, without any deliberate intent, we can introduce bias in our model.", "As we said, we can introduce bias in different steps of the development of an ML model and therefore we can have different types of bias. Having a classification can be useful to guide us in the process of identification of possible sources of bias in our model.", "One useful classification has been proposed, by two researchers, in this article: \u201c A framework for understanding unintended consequences of Machine Learning Models\u201d (H. Suresh, J. V. Guttag, MIT, Feb. 2020).", "In the article, they identify these six categories:", "The first three are involved in data generation and collection. The last three in the model development.", "They also provide a nice diagram that helps us to link the different categories to the different steps in the development of an ML model:", "I would add some considerations to the above picture.", "To sum it up, we must carefully check the entire process to avoid bias. Multiple tests and testing more and more data is helpful and, as my personal suggestion, having a team of people with different areas of expertise and background is also helpful.", "Another problem, related to bias, is that ML models can create Feedback Loop.", "What is a feedback loop? a feedback loop arises when the model wrongly produces the \u201cnext generation of input data\u201d, amplifying a bias, or some incorrect predictions produced by the model itself.", "Let\u2019s try to explain using a (somewhat real) example: imagine that a group of people wants to publicize a \u201cfake theory\u201d. They produce a nice and well-crafted video where they explain their theory. Then, they publish this video on one Social Media, with a Recommendation System based only on ratings from users. All the people from this group give very high ratings to the Video.", "The Recommender Engine, based on these ratings, will start to recommend this video to other people and, if these people will give some more positive ratings, there is the chance that starts a positive loop where more and more people will see the video.", "Well, this problem is not unreal. For example, there have been articles in the past suggesting that the YouTube engine has created something of this sort. And, we all know the debate regarding if some other Social Media can produce, for example, an increase in spreading fake news or hate speech.", "One example is coming from the New York Times article: \u201c YouTube unleashed a conspiracy theory boom. Can it be contained?\u201d.", "An interesting paper, titled \u201c Feedback Loop and Bias Amplification in Recommender Systems\u201d can be found on arXiv. In this case, the bias created can be called \u201c popularity bias\u201d: the model tends to push items based on popularity and not on the intrinsic quality, and this bias can be amplified by such algorithms as Collaborative Filtering, as analyzed in the article.", "One of the reasons why bias can be difficult to identify is the fact that sometimes ML models are used as (magic) Black Box. You verify that the model has enough high accuracy on the validation and test set and that\u2019s OK. Then, you ignore that you\u2019re not able to explain why the model produces some predictions instead of others (why, for example, the model decides that it is a high risk to give a loan to one customer).", "It could happen, especially if you\u2019re using large neural networks, with many layers.", "But, even if it is complicated to explain, we shouldn\u2019t accept such a situation. First of all, because there is a real risk that the model contains bugs and maybe bias. Second, because this is unacceptable if the usage of the model has social consequences. Third, because there may be some regulations on the subject.", "One area of active research in ML is the Model exPlainability and, in the last years, many techniques have been developed that can be employed even to support the explanation of complex models.", "From a general point of view, we talk about:", "One technique used to explain even complex, non-linear models is LiMe: Local Interpretable Model-agnostic Explanation, where we locally approximate (locally means: around the specific sample) the model with a linear one to identify the effects, on the prediction, of varying the features. See, for example, https://christophm.github.io/interpretable-ml-book/lime.html", "One last remark, interesting for people living in the EU: some people tend to incorrectly assert that GDPR defines a \u201cright to explanation\u201d. It is not true and it is a matter that couldn\u2019t be ruled simply.", "In general, there is an article (n. 22) in GDPR regarding the possibility to have Completely Automated Decisions. This article applies if three conditions are fulfilled:", "In this case, GDPR forbids a completely automated decision process if it produces juridical effects or if it has significant effects on the personality of the user.", "It doesn\u2019t mean that you can\u2019t use an ML model but, in the scenario depicted above, the process requires a human intervention (the decision process cannot be entirely made by a machine).", "Also, the GDPR does not mandate a \u201cright to explanation\u201d. It would be rather difficult, and probably in the majority of cases ineffective, to try to explain to the people the inner workings of an ML model. But it mandates a \u201cright to information\u201d and a \u201cright to object\u201d.", "Finally, if we are talking between people working on the development of ML models, we have the knowledge and the tools to understand why a model produce some decisions and therefore we shouldn\u2019t accept that a model is used as \u201ca black box\u201d, without any comprehension of how it works.", "As probably you clearly understand now, the risk of Bias in ML models is a problem that can be analyzed and, if not removed, reduced greatly.", "There is a great concern regarding the adoption of models for \u201cautomated decisions\u201d, especially because most people don\u2019t understand how these models work, and they fear the risk that those decisions are biased and can be unfair.", "But, I think that first of all, we should consider bias as a systematic error: As Data Scientists and ML Engineers we should try to do our best to avoid or reduce these kinds of errors. Then, we should never treat a model as a \u201cback box\u201d and always try to explain decisions and outcomes, to see if they make sense.", "Obviously, we shouldn\u2019t forget that the outcomes of an ML model can have social and ethical consequences.", "However, these kinds of problems should not prevent us from seriously considering the great benefits that can be realized, even in the social field, from the adoption of AI.", "If you want more information I would suggest the articles listed in the section \u201cReferences\u201d, from which I have taken some information and pictures.", "One book that I would greatly recommend is the one in ref. n. 3. Chapter n. 3 from the book has been authored by dr. R. Thomas and contains a rather extensive examination of bias, feedback loop, and other subjects linked to data ethics.", "Originally published at https://luigisaetta.it on November 9, 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Born in the wonderful city of Naples, but living in Rome. Always curious about new technologies and new things., especially in the AI field."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdbeea0f38466&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://luigi-saetta.medium.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": ""}, {"url": "https://luigi-saetta.medium.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Luigi Saetta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4b663f74558a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&user=Luigi+Saetta&userId=4b663f74558a&source=post_page-4b663f74558a----dbeea0f38466---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@deonblack?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Deon Black"}, {"url": "https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Bias", "anchor_text": "Wikipedia"}, {"url": "https://en.wikipedia.org/wiki/Closed-minded", "anchor_text": "closed-minded"}, {"url": "https://en.wikipedia.org/wiki/Prejudice", "anchor_text": "prejudicial"}, {"url": "https://en.wikipedia.org/wiki/Systematic_error", "anchor_text": "systematic error"}, {"url": "https://en.wikipedia.org/wiki/Melanoma", "anchor_text": "melanoma"}, {"url": "https://arxiv.org/pdf/1901.10002.pdf", "anchor_text": "A framework for understanding unintended consequences of Machine Learning Models"}, {"url": "https://arxiv.org/pdf/1901.10002.pdf", "anchor_text": "https://arxiv.org/pdf/1901.10002.pdf"}, {"url": "https://www.nytimes.com/2019/02/19/technology/youtube-conspiracy-stars.html", "anchor_text": "YouTube unleashed a conspiracy theory boom. Can it be contained?"}, {"url": "https://arxiv.org/pdf/2007.13019.pdf#:~:text=Recommendation%20algorithms%20are%20known%20to,known%20as%20a%20feedback%20loop.", "anchor_text": "arXiv"}, {"url": "https://christophm.github.io/interpretable-ml-book/lime.html", "anchor_text": "https://christophm.github.io/interpretable-ml-book/lime.html"}, {"url": "https://arxiv.org/pdf/1901.10002.pdf", "anchor_text": "https://arxiv.org/pdf/1901.10002.pd"}, {"url": "https://arxiv.org/pdf/2007.13019.pdf#:~:text=Recommendation%20algorithms%20are%20known%20to,known%20as%20a%20feedback%20loop", "anchor_text": "https://arxiv.org/pdf/2007.13019.pdf#:~:text=Recommendation%20algorithms%20are%20known%20to,known%20as%20a%20feedback%20loop"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "https://christophm.github.io/interpretable-ml-book/"}, {"url": "https://luigisaetta.it/index.php/machine-learning/52-bias-in-machine-learning-projects", "anchor_text": "https://luigisaetta.it"}, {"url": "https://medium.com/tag/ai?source=post_page-----dbeea0f38466---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/bias?source=post_page-----dbeea0f38466---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dbeea0f38466---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&user=Luigi+Saetta&userId=4b663f74558a&source=-----dbeea0f38466---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&user=Luigi+Saetta&userId=4b663f74558a&source=-----dbeea0f38466---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdbeea0f38466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dbeea0f38466---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dbeea0f38466--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dbeea0f38466--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dbeea0f38466--------------------------------", "anchor_text": ""}, {"url": "https://luigi-saetta.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://luigi-saetta.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Luigi Saetta"}, {"url": "https://luigi-saetta.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "127 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4b663f74558a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&user=Luigi+Saetta&userId=4b663f74558a&source=post_page-4b663f74558a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbf5991d56a16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-in-machine-learning-projects-dbeea0f38466&newsletterV3=4b663f74558a&newsletterV3Id=bf5991d56a16&user=Luigi+Saetta&userId=4b663f74558a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}