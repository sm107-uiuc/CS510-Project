{"url": "https://towardsdatascience.com/monte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f", "time": 1682995046.296253, "path": "towardsdatascience.com/monte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f/", "webpage": {"metadata": {"title": "Monte Carlo Tree Search in Reinforcement Learning | by Ziad SALLOUM | Towards Data Science", "h1": "Monte Carlo Tree Search in Reinforcement Learning", "description": "Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com Monte Carlo tree search (MCTS) algorithm consists of four phases: Selection, Expansion\u2026"}, "outgoing_paragraph_urls": [{"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com", "paragraph_index": 0}, {"url": "https://deepmind.com/research/publications/general-reinforcement-learning-algorithm-masters-chess-shogi-and-go-through-self-play/", "anchor_text": "view source", "paragraph_index": 1}], "all_paragraphs": ["Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com", "Instead of an alpha-beta search with domain-specific enhancements, AlphaZero uses a general purpose Monte Carlo tree search (MCTS) algorithm. Each search consists of a series of simulated games of self-play that traverse a tree from root state root until a leaf state is reached. (view source )", "Monte Carlo tree search (MCTS) algorithm consists of four phases: Selection, Expansion, Rollout/Simulation, Backpropagation.", "1. SelectionAlgorithm starts at root node R, then moves down the tree by selecting optimal child node until a leaf node L(no known children so far) is reached.", "2. ExpansionIf L is a not a terminal node (it does not terminate the game) then create one or more child nodes according to available actions at the current state (node), then and select the first of these new nodes M.", "3. SimulationRun a simulated rollout from M until a terminal state is found. The terminal state contains a result (value) that will be returned to upwards in the is backpropagation phase. NB. The states or nodes in which the rollout passes through are not considered visited.", "4. BackpropagationAfter the simulation phase, a result is returned. All nodes from M up to R will be updated by adding the result to their value and increase the count of visits at each node.", "The algorithm starts at a node or state that is considered the root, then selects a child node to move to.The selection is based on the Upper Confidence Bounds (UCB1) formula:", "where v\u1d62 is the value at state Si, n\u1d62 is number of visits at state Si, N is the total number of visits of the nodes at the same level (or in other words the number of visits at the parent of Si), C is a constant used for fine tuning.After computing the UCB1 for every child of the current node, the one with the highest value is chosen.", "If the selected node is new, meaning it is not visited yet, Rollout is called to find a terminal state with value. Otherwise, if it is visited, then create child nodes for all actions available at the current node, the move to the first of the child nodes and begin a Rollout.", "The Rollout or Simulation is the phase in which random actions are taken, retrieve the landing state then take another random action in order to land in a new state. This process is iterated until a terminal state is reached, at that point the value of the terminal stated is returned.", "the back propagation gets the value of the Rollout and updates the nodes from the start of the Rollout till the root node. The update consists of adding the Rollout result to the current value of each node, and to increase by one the count of visits at each of these nodes.", "The following is an example that unrolls all the different phases of the MCTS algorithm.", "Let\u2019s start with root node S0.We assume that it has been visited before, so it is not new. So we need to expand it. We assume that there are 2 actions (A1, A2) at this state.We expand the tree by adding two states S1 and S2 resulting from the actions A1, A2.Since the UCB1 for both S1 and S2 is infinity (since N1=0 and N2=0) we choose to go at first with A1.", "Now S1 is new because it has not been visited yet (N1 = 0). The algorithm says that in this case we should rollout until we reach a terminal state.Let\u2019s assume that we did just that and found a terminal node with value 20. We propagate this value from S1 upwards to S0 (text in blue). So S1 and S0 will have both values equal 20 and the number of visits equals 1.", "Now in the second iteration, UCB1(S1) = 20 and UCB1(S2) = infinity, so we take action A2.Also we notice that S2 is new (N2=0) so we rollout until we find a terminal state.We assume that the terminal state has a value 10. We backpropagate it from S2 up to S0 (text in blue).At the end we get S2 (V2=10, N2=1) and S0(V0 = 30, N0=2)", "In the third iteration, UCB1(S1) = 20 and UCB1(S2) = 10, so we choose to go to S1. Since now it is not new anymore (N1 > 0) we expand it by adding the available actions and their landing states. We suppose that there are 2 actions A3, A4 with the respective states S3 and S4.Since both S3 and S4 have UCB1 infinity we choose S3 by following actin A3. S3 is new so we rollout until we find terminal state with value 15. We backpropagate this value to node S3, S1, S0. The updated values can be seen in the blue text."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb97d3e743d0f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://zsalloum.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----b97d3e743d0f---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb97d3e743d0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----b97d3e743d0f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb97d3e743d0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=-----b97d3e743d0f---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/photos/waAAaeC9hns", "anchor_text": "https://unsplash.com/photos/waAAaeC9hns"}, {"url": "http://rl-lab.com/", "anchor_text": "http://rl-lab.com"}, {"url": "https://deepmind.com/research/publications/general-reinforcement-learning-algorithm-masters-chess-shogi-and-go-through-self-play/", "anchor_text": "view source"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----b97d3e743d0f---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b97d3e743d0f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/monte-carlo-tree-search?source=post_page-----b97d3e743d0f---------------monte_carlo_tree_search-----------------", "anchor_text": "Monte Carlo Tree Search"}, {"url": "https://medium.com/tag/mcts?source=post_page-----b97d3e743d0f---------------mcts-----------------", "anchor_text": "Mcts"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b97d3e743d0f---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb97d3e743d0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----b97d3e743d0f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb97d3e743d0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----b97d3e743d0f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb97d3e743d0f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----b97d3e743d0f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----b97d3e743d0f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Written by Ziad SALLOUM"}, {"url": "https://zsalloum.medium.com/followers?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "845 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rl-lab.com", "anchor_text": "https://rl-lab.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----b97d3e743d0f---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonte-carlo-tree-search-in-reinforcement-learning-b97d3e743d0f&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----b97d3e743d0f---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Policy Based Reinforcement Learning, the Easy WayStep by step approach to understanding Policy Based methods in Reinforcement Learning"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "8 min read\u00b7Feb 8, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8de9a3356083&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-based-reinforcement-learning-the-easy-way-8de9a3356083&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----8de9a3356083----0-----------------clap_footer----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----b97d3e743d0f----0---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8de9a3356083&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-based-reinforcement-learning-the-easy-way-8de9a3356083&source=-----b97d3e743d0f----0-----------------bookmark_preview----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----b97d3e743d0f----1---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----b97d3e743d0f----1-----------------bookmark_preview----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----b97d3e743d0f----2---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----b97d3e743d0f----2-----------------bookmark_preview----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "Function Approximation in Reinforcement LearningWhat to do when state and action spaces explode\u2026 literally ?"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": "\u00b77 min read\u00b7May 21, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F85a4864d566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffunction-approximation-in-reinforcement-learning-85a4864d566&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----85a4864d566----3-----------------clap_footer----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----b97d3e743d0f----3---------------------68bfc65d_69a0_4836_adb8_070ddb6d628b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F85a4864d566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffunction-approximation-in-reinforcement-learning-85a4864d566&source=-----b97d3e743d0f----3-----------------bookmark_preview----68bfc65d_69a0_4836_adb8_070ddb6d628b-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "See all from Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@artem.a.arutyunov?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@artem.a.arutyunov?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Artem Arutyunov"}, {"url": "https://medium.com/the-power-of-ai?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "The Power of AI"}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Win at Blackjack with Reinforcement LearningAs a popular casino card game, many have studied Blackjack closely in order to devise strategies for improving their likelihood of winning."}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "13 min read\u00b7Dec 30, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fthe-power-of-ai%2F95f588dd670c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-power-of-ai%2Fblackjack-with-reinforcement-learning-95f588dd670c&user=Artem+Arutyunov&userId=8d26b20a79d4&source=-----95f588dd670c----0-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/the-power-of-ai/blackjack-with-reinforcement-learning-95f588dd670c?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95f588dd670c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fthe-power-of-ai%2Fblackjack-with-reinforcement-learning-95f588dd670c&source=-----b97d3e743d0f----0-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----b97d3e743d0f----1-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://aniruddhamukh.medium.com/?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Aniruddha Mukherjee"}, {"url": "https://medium.com/dsckiit?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "GDSC KIIT"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Reinforcement Learning: An Introduction and Guide to its FundamentalsPolicies, Rewards, the Bellman Equation, and the Markov Decision Process (MDP)"}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "5 min read\u00b7Apr 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdsckiit%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&user=Aniruddha+Mukherjee&userId=68f97387c191&source=-----467c6a2ed25e----0-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/dsckiit/reinforcement-learning-guide-and-introduction-467c6a2ed25e?source=read_next_recirc-----b97d3e743d0f----0---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F467c6a2ed25e&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fdsckiit%2Freinforcement-learning-guide-and-introduction-467c6a2ed25e&source=-----b97d3e743d0f----0-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Anand Mishra"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Deep reinforcement learning \u2014 current state of artCurrent"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "5 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&user=Anand+Mishra&userId=86f86a9a5573&source=-----383190b14464----1-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----b97d3e743d0f----1---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&source=-----b97d3e743d0f----1-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----2-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----b97d3e743d0f----2---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----b97d3e743d0f----2-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----3-----------------clap_footer----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----b97d3e743d0f----3---------------------9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----b97d3e743d0f----3-----------------bookmark_preview----9f4068c2_9607_4ceb_82e1_84b2ea6b40a7-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----b97d3e743d0f--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}