{"url": "https://towardsdatascience.com/summary-of-tabular-methods-in-reinforcement-learning-39d653e904af", "time": 1682994243.518775, "path": "towardsdatascience.com/summary-of-tabular-methods-in-reinforcement-learning-39d653e904af/", "webpage": {"metadata": {"title": "Summary of Tabular Methods in Reinforcement Learning | by Ziad SALLOUM | Towards Data Science", "h1": "Summary of Tabular Methods in Reinforcement Learning", "description": "Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com Tabular methods refer to problems in which the state and actions spaces are small enough for\u2026"}, "outgoing_paragraph_urls": [{"url": "http://rl-lab.com", "anchor_text": "http://rl-lab.com", "paragraph_index": 0}, {"url": "https://medium.com/@zsalloum/dynamic-programming-in-reinforcement-learning-the-easy-way-359c7791d0ac", "anchor_text": "Dynamic Programming in Reinforcement Learning, the Easy Way", "paragraph_index": 7}, {"url": "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511", "anchor_text": "Monte Carlo in Reinforcement Learning, the Easy Way", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "TD in Reinforcement Learning, the Easy Way", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3", "anchor_text": "Double Q-Learning the Easy Way", "paragraph_index": 27}], "all_paragraphs": ["Update: The best way of learning and practicing Reinforcement Learning is by going to http://rl-lab.com", "Tabular methods refer to problems in which the state and actions spaces are small enough for approximate value functions to be represented as arrays and tables.", "The aim of reinforcement learning is to find a solution to the following equation, called Bellman equation:", "What we mean by solving the Bellman equation is to find the optimal policy that maximizes the State Value function.", "Since an analytical solution is hard to get, we use iterative methods in order to compute the optimal policy. The optimal State and Action value functions are denoted as the following:", "Dynamic programming is a method in which each value at a state is computed by taking as input the values of surrounding states (disregarding if those values are accurate or not). Once a value of one state is computed, we move to another state and we repeat the same process (taking into account any new value computed in previous states).", "This process is iterated enough times until changes in every state is less than a certain limit that we have defined.", "More on DP Learning can be found in the article \u201cDynamic Programming in Reinforcement Learning, the Easy Way\u201d", "DP is efficient, it finds optimal policies in polynomial time for most cases.", "DP is guaranteed to find optimal policy.", "DP is not suitable for large problems, with millions or more of states.", "DP requires the knowledge of the transition probability matrix, however this is an unrealistic requirement for many problems.", "In Monte Carlo (MC) we play an episode of the game, move epsilon-greedly through out the states till the end, record the states, actions and rewards that we encountered then compute the V(s) and Q(s) for each state we passed through.We repeat this process by playing more episodes and after each episode we get the states, actions, and rewards and we average the values of the discovered V(s) and Q(s).", "MC prediction algorithm consists of playing as many episodes as possible and after each episode compute the values of the states that we have passed through, then average those results with the current values of those states.", "The On-policy first-visit MC control is meant to find the optimal policy. It plays the episode but keeps track of every action used at each state. In this way it is possible to know what action resulted in the best Q-value.At the end add the action with maximum Q-value to the optimal policy.", "Detailed explanation of Monte Carlo can be found in the article \u201cMonte Carlo in Reinforcement Learning, the Easy Way\u201d", "MC can be used to learn optimal behavior directly from interaction with the environment. It does not require a model of the environment\u2019s dynamics.", "MC can be used with simulation or sample models.", "MC can be used to focus on one region of special interest and be accurately evaluated without having to evaluate the rest of the state set.", "MC only works for episodic (terminating) environments. It does not work with environment with no terminating states.", "MC must have a complete episodes, it does not have bootstrapping, meaning it does not give an estimates of the other states.", "MC must wait until the end of an episode before return is known. For problems with very long episodes this will become too slow.", "TD can be seen as the fusion between DP and MC methods. It plays episodes but does not have to wait until the end to know the return. It computes the value of the current state based on estimates of other states.TD(0) refers to the fact of looking ahead only one step, then compute the current state value.", "In order to find the optimal policy TD offers different methods, one of them is SARSA.SARSA consists of taking action A on state S, note the reward and the next state S\u2019, then choose an action A\u2019 from state S\u2019 then use all these info to update Q(S, A), then move to S\u2019 and execute action A\u2019 which has been chosen earlier.", "The Q-learning is another way for finding optimal policy.Like SARSA it takes action A on state S, note the reward and the next state S\u2019, then unlike SARSA it chooses the max Q-Value in state S\u2019 then use all these info to update Q(S, A), then move to S\u2019 and execute epsilon greedy action which does not necessarily result in taking action that has the max Q-Value in state S\u2019.", "Double Q-Learning is an algorithm that solves particular issues in Q-Learning, especially when Q-Learning can be tricked to take the bad action based on some positive rewards, while the expected reward of this action is guaranteed to be negative.It does that by maintaining two Q-Value lists each updating itself from the other. In short it finds the action that maximizes the Q-Value in one list, but instead of using this Q-Value, it uses the action to get a Q-Value from the other list.", "To learn more details about TD learning check the article \u201cTD in Reinforcement Learning, the Easy Way\u201d.", "While more details on Double Q-Learning can be found in \u201cDouble Q-Learning the Easy Way\u201d", "TD does not need to know the transition probability matrix like in DP.", "TD does not need to wait until the end of the episode to know the return, it updates the state value and the action value incrementally.", "SARSA might be stuck in local minima.", "Q-Learning can behave poorly in some stochastic environments.", "Algorithms are taken from R.S. Sutton and A.G. Barto. Reinforcement Learning: An Introduction."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F39d653e904af&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://zsalloum.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----39d653e904af---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F39d653e904af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----39d653e904af---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F39d653e904af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=-----39d653e904af---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://rl-lab.com", "anchor_text": "http://rl-lab.com"}, {"url": "https://medium.com/@zsalloum/dynamic-programming-in-reinforcement-learning-the-easy-way-359c7791d0ac", "anchor_text": "Dynamic Programming in Reinforcement Learning, the Easy Way"}, {"url": "https://medium.com/@zsalloum/monte-carlo-in-reinforcement-learning-the-easy-way-564c53010511", "anchor_text": "Monte Carlo in Reinforcement Learning, the Easy Way"}, {"url": "https://towardsdatascience.com/td-in-reinforcement-learning-the-easy-way-f92ecfa9f3ce", "anchor_text": "TD in Reinforcement Learning, the Easy Way"}, {"url": "https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3", "anchor_text": "Double Q-Learning the Easy Way"}, {"url": "https://medium.com/tag/dynamic-programming?source=post_page-----39d653e904af---------------dynamic_programming-----------------", "anchor_text": "Dynamic Programming"}, {"url": "https://medium.com/tag/monte-carlo?source=post_page-----39d653e904af---------------monte_carlo-----------------", "anchor_text": "Monte Carlo"}, {"url": "https://medium.com/tag/temporal-difference?source=post_page-----39d653e904af---------------temporal_difference-----------------", "anchor_text": "Temporal Difference"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----39d653e904af---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----39d653e904af---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F39d653e904af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----39d653e904af---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F39d653e904af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----39d653e904af---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F39d653e904af&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----39d653e904af---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----39d653e904af---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Written by Ziad SALLOUM"}, {"url": "https://zsalloum.medium.com/followers?source=post_page-----39d653e904af--------------------------------", "anchor_text": "845 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://rl-lab.com", "anchor_text": "https://rl-lab.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f2b933522e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&user=Ziad+SALLOUM&userId=1f2b933522e2&source=post_page-1f2b933522e2----39d653e904af---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408fc441c93b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsummary-of-tabular-methods-in-reinforcement-learning-39d653e904af&newsletterV3=1f2b933522e2&newsletterV3Id=408fc441c93b&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----39d653e904af---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Policy Based Reinforcement Learning, the Easy WayStep by step approach to understanding Policy Based methods in Reinforcement Learning"}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "8 min read\u00b7Feb 8, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8de9a3356083&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-based-reinforcement-learning-the-easy-way-8de9a3356083&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----8de9a3356083----0-----------------clap_footer----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/policy-based-reinforcement-learning-the-easy-way-8de9a3356083?source=author_recirc-----39d653e904af----0---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8de9a3356083&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpolicy-based-reinforcement-learning-the-easy-way-8de9a3356083&source=-----39d653e904af----0-----------------bookmark_preview----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----39d653e904af----1---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----39d653e904af----1-----------------bookmark_preview----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----39d653e904af----2---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----39d653e904af----2-----------------bookmark_preview----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "Function Approximation in Reinforcement LearningWhat to do when state and action spaces explode\u2026 literally ?"}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": "\u00b77 min read\u00b7May 21, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F85a4864d566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffunction-approximation-in-reinforcement-learning-85a4864d566&user=Ziad+SALLOUM&userId=1f2b933522e2&source=-----85a4864d566----3-----------------clap_footer----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/function-approximation-in-reinforcement-learning-85a4864d566?source=author_recirc-----39d653e904af----3---------------------62ab043e_27c9_478a_9083_c78e0b6b01da-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F85a4864d566&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffunction-approximation-in-reinforcement-learning-85a4864d566&source=-----39d653e904af----3-----------------bookmark_preview----62ab043e_27c9_478a_9083_c78e0b6b01da-------", "anchor_text": ""}, {"url": "https://zsalloum.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "See all from Ziad SALLOUM"}, {"url": "https://towardsdatascience.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----39d653e904af----0-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----39d653e904af----1-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Trust Region Policy Optimization (TRPO) ExplainedThe Reinforcement Learning algorithm TRPO builds upon natural policy gradient algorithms, ensuring updates remain within \u2018trustworthy\u2019\u2026"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "\u00b712 min read\u00b7Oct 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----4b56bd206fc2----0-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----39d653e904af----0---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&source=-----39d653e904af----0-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----1-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----39d653e904af----1---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----39d653e904af----1-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----39d653e904af----2---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----39d653e904af----2-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Anand Mishra"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "Deep reinforcement learning \u2014 current state of artCurrent"}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": "5 min read\u00b7Dec 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&user=Anand+Mishra&userId=86f86a9a5573&source=-----383190b14464----3-----------------clap_footer----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/@anandmishra.kanha/deep-reinforcement-learning-current-state-of-art-383190b14464?source=read_next_recirc-----39d653e904af----3---------------------6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F383190b14464&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40anandmishra.kanha%2Fdeep-reinforcement-learning-current-state-of-art-383190b14464&source=-----39d653e904af----3-----------------bookmark_preview----6009d0b8_afb2_4fd8_bd1e_58b4a6b20874-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----39d653e904af--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----39d653e904af--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}