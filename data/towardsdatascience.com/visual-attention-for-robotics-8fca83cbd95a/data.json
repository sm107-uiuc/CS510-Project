{"url": "https://towardsdatascience.com/visual-attention-for-robotics-8fca83cbd95a", "time": 1683001780.176123, "path": "towardsdatascience.com/visual-attention-for-robotics-8fca83cbd95a/", "webpage": {"metadata": {"title": "Visual Attention for Robotics. Robustifying a visuomotor policy using\u2026 | by Amir Mazaheri | Towards Data Science", "h1": "Visual Attention for Robotics", "description": "Object manipulation is one of the main tasks of robotics research. Training a policy neural network by demonstrations is one way to design a visuomotor policy. However, recoding demonstrations is\u2026"}, "outgoing_paragraph_urls": [{"url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Abolghasemi_Pay_Attention_-_Robustifying_a_Deep_Visuomotor_Policy_Through_Task-Focused_CVPR_2019_paper.pdf", "anchor_text": "paper", "paragraph_index": 5}, {"url": "https://www.crcv.ucf.edu/research/projects/pay-attention/", "anchor_text": "project page", "paragraph_index": 6}], "all_paragraphs": ["Object manipulation is one of the main tasks of robotics research. Training a policy neural network by demonstrations is one way to design a visuomotor policy. However, recoding demonstrations is expensive and time-consuming. Also, the environment may change after recording the training demonstration samples. For example, during test time, an unknown object might enter the visual scene of the robot. In such scenarios, most of the visuomotor policies will fail, since they encounter an unseen state. Also, a disturbance can be physical or visual, meaning that, something can interfere or touch the object for a moment, and prevent the robot from finishing the job (physical disturbance) or just some unexpected visual pattern in the input stream of the robot camera (visual disturbance). Since there are infinite scenarios of disturbance, it is impractical to gather training samples for every possible physical disturbance.", "We investigate an approach to train the policy neural network in a benign condition, meaning zero disturbance during training, while it is robust against physical/visual disturbance in test time.", "We design a Teacher-Student system, to extract rich features that are robust against unseen disturbances from the input frames. Our teacher network is a simple text (the task of the robot) to frame grounding (as an attention map) network. We call it Task-Focused visual Attention (TFA).", "The student network which is a Variational Auto-Encoder (VAE)-GAN, tries to not only reconstruct the input frame but also mimic the attention that the teacher network is producing. This is a form of knowledge distillation. While the teacher network can capture the task (which comes as a natural language sentence in our experiments) to frame knowledge, the student network can get the same knowledge by mimicking the teacher's behavior and supply the motor network that moves the robot.", "We show that the student network can not only learn the attention, it can also produce features that are robust against disturbance. Knowing that the disturbance will be ignored in the attention process.", "Please read our paper for more details.", "Also, the code and data are available on our project page.", "Please do not hesitate to ask your questions.", "You can also watch my YouTube presentation, for more details and discussions:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a PhD candidate at the University of Central Florida. My main research interests include Computer Vision and Machine Learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8fca83cbd95a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@AmirMazaheriii?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AmirMazaheriii?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Amir Mazaheri"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7444fab509bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&user=Amir+Mazaheri&userId=7444fab509bb&source=post_page-7444fab509bb----8fca83cbd95a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Abolghasemi_Pay_Attention_-_Robustifying_a_Deep_Visuomotor_Policy_Through_Task-Focused_CVPR_2019_paper.pdf", "anchor_text": "paper"}, {"url": "https://www.crcv.ucf.edu/research/projects/pay-attention/", "anchor_text": "project page"}, {"url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Abolghasemi_Pay_Attention_-_Robustifying_a_Deep_Visuomotor_Policy_Through_Task-Focused_CVPR_2019_paper.pdf", "anchor_text": "paper"}, {"url": "https://www.crcv.ucf.edu/research/projects/pay-attention/", "anchor_text": "project page"}, {"url": "https://medium.com/tag/robotics?source=post_page-----8fca83cbd95a---------------robotics-----------------", "anchor_text": "Robotics"}, {"url": "https://medium.com/tag/attention-network?source=post_page-----8fca83cbd95a---------------attention_network-----------------", "anchor_text": "Attention Network"}, {"url": "https://medium.com/tag/visual-attention?source=post_page-----8fca83cbd95a---------------visual_attention-----------------", "anchor_text": "Visual Attention"}, {"url": "https://medium.com/tag/knowledge-distillation?source=post_page-----8fca83cbd95a---------------knowledge_distillation-----------------", "anchor_text": "Knowledge Distillation"}, {"url": "https://medium.com/tag/disturbance?source=post_page-----8fca83cbd95a---------------disturbance-----------------", "anchor_text": "Disturbance"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&user=Amir+Mazaheri&userId=7444fab509bb&source=-----8fca83cbd95a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&user=Amir+Mazaheri&userId=7444fab509bb&source=-----8fca83cbd95a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8fca83cbd95a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8fca83cbd95a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8fca83cbd95a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AmirMazaheriii?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@AmirMazaheriii?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Amir Mazaheri"}, {"url": "https://medium.com/@AmirMazaheriii/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "11 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7444fab509bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&user=Amir+Mazaheri&userId=7444fab509bb&source=post_page-7444fab509bb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F7444fab509bb%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisual-attention-for-robotics-8fca83cbd95a&user=Amir+Mazaheri&userId=7444fab509bb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}