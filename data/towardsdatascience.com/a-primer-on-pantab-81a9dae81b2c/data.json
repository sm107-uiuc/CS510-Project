{"url": "https://towardsdatascience.com/a-primer-on-pantab-81a9dae81b2c", "time": 1683007298.577815, "path": "towardsdatascience.com/a-primer-on-pantab-81a9dae81b2c/", "webpage": {"metadata": {"title": "A Primer on pantab. How to combine pandas and Tableau in a\u2026 | by Chris Nguyen | Towards Data Science", "h1": "A Primer on pantab", "description": "The pandas library in Python is an essential tool for data analysis, but did you know you can combine it with the Tableau Hyper API to make your pipeline from raw data records to visualizations\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pandas.pydata.org/", "anchor_text": "pandas", "paragraph_index": 0}, {"url": "https://pantab.readthedocs.io/en/latest/index.html", "anchor_text": "pantab", "paragraph_index": 0}, {"url": "https://help.tableau.com/current/api/hyper_api/en-us/index.html", "anchor_text": "Hyper API", "paragraph_index": 0}, {"url": "https://pantab.readthedocs.io/en/latest/api.html", "anchor_text": "pantab API", "paragraph_index": 6}, {"url": "https://help.tableau.com/current/api/hyper_api/en-us/docs/hyper_api_create_update.html", "anchor_text": "Hyper API reference", "paragraph_index": 10}], "all_paragraphs": ["The pandas library in Python is an essential tool for data analysis, but did you know you can combine it with the Tableau Hyper API to make your pipeline from raw data records to visualizations easier? This is the exact purpose for the pantab library developed by Will Ayd at innobi, which is a Python wrapper around Tableau\u2019s Hyper API. Here, I will go through a guided example of how to use pantab in a data workflow.", "Before we even get started, why should we even use pantab and the Hyper API in the first place? The Hyper API allows you to create functions to automate your data processing with Tableau Hyper extract files. Hyper is Tableau\u2019s in-memory data engine technology and the extracts are represented with the \u201c.hyper\u201d extension. So basically, the Hyper API allows you to create \u201c.hyper\u201d files for use with Tableau. You\u2019ll be able to create and update extracts using a language like Python, Java, or C++. However, it can get a little hairy working with the API at times. For example, here is a Python code snippet to transform data from a CSV to a Hyper file:", "That\u2019s a lot of effort for including just 3 rows of data in a Hyper file! (in fact, it took me more time and effort to write and debug this code than the entire rest of the code in this article combined)", "The good news is that pantab makes this process much easier by combining it with pandas and abstracting the Hyper API to simplify it. If you are already a pandas practitioner, this is even better as this will provide you with a familiar framework to work with data and generate your Hyper files.", "An example use case of this is something that I run into from time to time in my current position: sometimes running extracts take a very long time, potentially hours overnight, but if there\u2019s something wrong with it then I want to investigate that. However, I want to investigate an exact version of the extract by connecting to the extract as a data source and doing EDA on it to check some assumptions before the data is overwritten the next day. This would be easiest using tools like Python/pandas as Tableau itself is primarily a data visualization tool but I want to check certain groupings or aggregations in my investigation in a more programmatic way.", "pantab would also be a useful tool in an ETL data pipeline to pipe out Hyper files when the data you need has to be transformed from one or more sources. Sort of like an alternative to Tableau Prep (or a replacement should you not have access to it).", "At the time of this article, there are only 4 functions you can call in the pantab API:", "Let\u2019s go through each of these as examples using the data from my repo.", "The frame_to_hyper function simply converts pandas DataFrames to tables within a Hyper file. After importing required libraries, you just need to read in the data as a pandas DataFrame and then use frame_to_hyper to write the DataFrame to a specified Hyper file as shown below:", "That is two lines of code to do the exact same thing as the code using the Hyper API directly does. Quite a reduction in code! And now you can use pandas to directly transform the data or do any checks with it before writing it to a Hyper file.", "Note that I actually created two DataFrames above. I did this to demonstrate that you can save tables in Hyper files in different schemas (for more background info on this, consult the Hyper API reference). The default schema is the \u201cpublic\u201d schema but you can be explicit and name a schema, just as I did with the \u201cExtract\u201d schema above. To do this, you must import the \u201cTableName\u201d object from the tableauhyperapi library (so you can\u2019t really100% avoid the Hyper API after all, but you can certainly reduce how much you need to use it directly!).", "Why did I bother to save my data twice but in different schemas? I did it to demonstrate that not all tables in Hyper extract files will be in the public schema so you will need to check where they are sometimes. (In particular, if the Tableau version used to create the extract was before version 10.5, it may be in the Extract schema by default instead of the public schema.) To demonstrate this, take the pokemon_extract.hyper file and try to read it into a pandas DataFrame using the frame_from_hyper function with default table location. It errors out with message \u201cHyperException: Specified table does not exist: pokemon.\u201d because the \u201cpokemon\u201d table is not in the default location for Tableau 10.5 and above. You need to specify the schema using the TableName object like the second code line in the below code snippet:", "You can easily check that the default schema when writing a DataFrame to Hyper is the public schema because these lines have the exact same resulting file:", "For an existing Hyper file, there might be tables in existing schemas already. How do we check for these existing tables and schemas? We can use the frames_from_hyper function to help us with that. The frames_from_hyper function returns a dictionary object where the schema/tables are stored as dictionary keys and the pandas DataFrames are the values. Looking at the keys will reveal any pre-existing schemas and tables.", "Here, we can see that public.pokemon exists in the pokemon_public.hyper file while Extract.pokemon exists in the pokemon_extract.hyper file.", "Finally, we can write multiple pandas DataFrames to a Hyper file by using the frames_to_hyper function. It takes a dictionary of DataFrames as input to write out each of them out to a table in a Hyper extract like so:", "Note however that this will create three separate tables in the Hyper file, with no way to combine or union them into a single table:", "But what if we do want to combine all of the tables into one? Here, all of our tables have the same shape and fields so we do want to combine them in the end. We can do this in two ways: either combine them as a single pandas DataFrame before writing out to a Hyper file or use the append mode (table_mode = \u2018a\u2019) in frame_to_hyper:", "The pandas library can make many things easier, including working with Tableau workflows. I hope this primer helped you learn more about how to use pantab and generate some use cases for your data projects!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F81a9dae81b2c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://datadissectiondr.medium.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": ""}, {"url": "https://datadissectiondr.medium.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Chris Nguyen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3d5f673bb08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&user=Chris+Nguyen&userId=a3d5f673bb08&source=post_page-a3d5f673bb08----81a9dae81b2c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pandas.pydata.org/", "anchor_text": "pandas"}, {"url": "https://pantab.readthedocs.io/en/latest/index.html", "anchor_text": "pantab"}, {"url": "https://help.tableau.com/current/api/hyper_api/en-us/index.html", "anchor_text": "Hyper API"}, {"url": "https://github.com/c-l-nguyen/pantab-pokemon", "anchor_text": "repo from Github"}, {"url": "https://pantab.readthedocs.io/en/latest/api.html", "anchor_text": "pantab API"}, {"url": "https://help.tableau.com/current/api/hyper_api/en-us/docs/hyper_api_create_update.html", "anchor_text": "Hyper API reference"}, {"url": "https://medium.com/tag/data?source=post_page-----81a9dae81b2c---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/data-visualization?source=post_page-----81a9dae81b2c---------------data_visualization-----------------", "anchor_text": "Data Visualization"}, {"url": "https://medium.com/tag/pandas?source=post_page-----81a9dae81b2c---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/tableau?source=post_page-----81a9dae81b2c---------------tableau-----------------", "anchor_text": "Tableau"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----81a9dae81b2c---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&user=Chris+Nguyen&userId=a3d5f673bb08&source=-----81a9dae81b2c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&user=Chris+Nguyen&userId=a3d5f673bb08&source=-----81a9dae81b2c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F81a9dae81b2c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----81a9dae81b2c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----81a9dae81b2c--------------------------------", "anchor_text": ""}, {"url": "https://datadissectiondr.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://datadissectiondr.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chris Nguyen"}, {"url": "https://datadissectiondr.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "52 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3d5f673bb08&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&user=Chris+Nguyen&userId=a3d5f673bb08&source=post_page-a3d5f673bb08--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fa3d5f673bb08%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-primer-on-pantab-81a9dae81b2c&user=Chris+Nguyen&userId=a3d5f673bb08&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}