{"url": "https://towardsdatascience.com/machine-learning-models-compression-and-quantization-simplified-a302ddf326f2", "time": 1682996812.2677171, "path": "towardsdatascience.com/machine-learning-models-compression-and-quantization-simplified-a302ddf326f2/", "webpage": {"metadata": {"title": "Deep Learning \u2014 Model Optimization and Compression: Simplified | by Prakhar Ganesh | Towards Data Science", "h1": "Deep Learning \u2014 Model Optimization and Compression: Simplified", "description": "The world around us is filled with Neural Networks and Deep Learning models doing wonders!! But these models are both computationally expensive and energy intensive. So expensive that people have\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["The world around us is filled with Neural Networks and Deep Learning models doing wonders!! But these models are both computationally expensive and energy intensive. So expensive that people have actually started holding AI/ML accountable for their carbon emission and the numbers are not pretty!!", "Another major reason why more researchers have turned towards Model compression is the difficulty in deploying these models on systems with limited hardware resources. While these models have been successful in making headlines and achieving extraordinary performances, they require the support of expensive, high speed GPUs to get them working, which limits their applications.", "Being able to compress these highly complex models, transfer them to hardware devices and end their dependence on huge computational resources is one of the major goals of this domain. These kind of advances can help us incorporate AI into every small embedded system around us.", "Yes offcourse!! With the internet giants like Google and Amazon offering computational services online, one does wonder if doing remote computations is the way to go. While people have started using these cloud services like a crutch for heavy computations, it does come with it\u2019s own set of problems.", "One of the major issues with cloud computing is network connectivity. The system needs to be online at all times to work smoothly. But that cannot be always guaranteed and thus doing the computations locally is of extreme importance to systems that cannot afford any network delays.", "Another issue with using these cloud services is sacrificing the \u201cair gap\u201d. The air gap is a technical term used to represent systems that are not connected to the internet and thus cannot be breached remotely. Getting access to the data present in these configurations needs to be done physically, Mission Impossible style!! :P", "For systems which are extremely protective regarding their privacy and security, giving up this \u201cair gap\u201d is not ideal and so they prefer local computations over cloud services.", "That\u2019s what the majority of ML community believes but is not true!! If you are a beginner in ML looking to develop state-of-the-art models and are not bound by processing capacities, you might think that highly complex and Deep models are always the way to go.", "But that\u2019s a huge misconception. Highly complex and Deep models does not guarantee performance. Not to mention, these models can take hours or sometimes even days to train (even on GPUs). Research into pruning and quantization has shown that the connections that actually matter in the model are only a small percentage of the whole spider web!!", "For example, famous ImageNet models like AlexNet and VGG-16 have been compressed to 40\u201350 times their original size, without any loss of (and actually a slight gain of) accuracy. This dramatically increases their inference speed and the ease with which they can adapted across various devices.", "Model compression can be divided into two broad categories,", "Pruning : Removing redundant connections present in the architecture. Pruning involves cutting out unimportant weights (which are usually defined as weights with small absolute value).", "Obviously the new model formed will have lower accuracy since the model was actually trained for the original connections. That is why the model is fine tuned after pruning to regain the accuracy. It is noted that fully connected layers and CNNs can usually go upto 90% sparsity without losing any accuracy.", "Quantization : Quantization involves bundling weights together by clustering them or rounding them off so that the same number of connections can be represented using lesser amount of memory.", "Quantization by doing clustering/bundling and thus using lesser number of distinct float values to represent more number of features is one of the most common techniques. Another common technique that forms the skeleton for a lot of quantization methods is converting floating point weights to fixed point representation by rounding off.", "Again, as it was with pruning, we need to fine tune the model after quantization. The important point here is that the property that was given to the weights while quantization should be maintained through the fine tuning too. That is why specific ways of fine tuning are used which are tailored to match the quantization method.", "Look at the image above for an example of quantization by clustering. Weights of same color are clustered together and represented by their centroid. This decreases the amount of data required to represent these weights. Earlier it required 32bits*16 = 512 bits to represent them. Now it will only take 32bits*4 + 2bits*16 = 160 bits to represent them. During the fine tuning, the gradient for all the weights which belong to the same color are summed and then subtracted from the centroid. This makes sure that the clustering made during quantization is maintained through the fine tuning.", "Deep Learning model pruning and quantization are relatively new fields. While there have been significant success in this field, it still has a long way to go. The next focus of the domain should be creating open source and easily accessible pipelines for transferring common Deep Learning models to embedded systems like FPGAs.", "This blog is a part of an effort to create simplified introductions to the field of Machine Learning. Follow the complete series here", "Or simply read the next blog in the series", "[1] Han, Song, Huizi Mao, and William J. Dally. \u201cDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding.\u201d arXiv preprint arXiv:1510.00149 (2015).[2] Jia, Haipeng, et al. \u201cDropPruning for Model Compression.\u201d arXiv preprint arXiv:1812.02035 (2018).[3] Wang, Shuo, et al. \u201cC-lstm: Enabling efficient lstm using structured compression techniques on fpgas.\u201d Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, 2018.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Computer Vision and Deep Learning enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa302ddf326f2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@prakhargannu?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@prakhargannu?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Prakhar Ganesh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F318f2765b461&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&user=Prakhar+Ganesh&userId=318f2765b461&source=post_page-318f2765b461----a302ddf326f2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.technologyreview.com/s/613630/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/?utm_medium=tr_social&utm_source=facebook&utm_campaign=site_visitor.unpaid.engagement&fbclid=IwAR04gQbmXY7OxR3vx8BRb52-pYhlqhXhxorXGSkgGkygu8jUVgbF_CJxYwI", "anchor_text": "Training a single AI model can emit as much carbon as five cars in their lifetimesThe artificial-intelligence industry is often compared to the oil industry: once mined and refined, data, like oil, can\u2026www.technologyreview.com"}, {"url": "https://towardsdatascience.com/machine-learning-simplified-1fe22fec0fac", "anchor_text": "Machine Learning : SimplifiedKnow it before you dive intowardsdatascience.com"}, {"url": "https://towardsdatascience.com/high-frequency-trading-hft-with-ai-simplified-a24c00da72e0", "anchor_text": "High Frequency Trading (HFT) with AI : SimplifiedTake a peek into the ever-competing world of HFTs and how is AI becoming a part of it.towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a302ddf326f2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a302ddf326f2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----a302ddf326f2---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a302ddf326f2---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/surveys?source=post_page-----a302ddf326f2---------------surveys-----------------", "anchor_text": "Surveys"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&user=Prakhar+Ganesh&userId=318f2765b461&source=-----a302ddf326f2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&user=Prakhar+Ganesh&userId=318f2765b461&source=-----a302ddf326f2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa302ddf326f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a302ddf326f2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a302ddf326f2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a302ddf326f2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a302ddf326f2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@prakhargannu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@prakhargannu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Prakhar Ganesh"}, {"url": "https://medium.com/@prakhargannu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "649 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F318f2765b461&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&user=Prakhar+Ganesh&userId=318f2765b461&source=post_page-318f2765b461--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6fd6e4d21dc5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-models-compression-and-quantization-simplified-a302ddf326f2&newsletterV3=318f2765b461&newsletterV3Id=6fd6e4d21dc5&user=Prakhar+Ganesh&userId=318f2765b461&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}