{"url": "https://towardsdatascience.com/machine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c", "time": 1683011030.022142, "path": "towardsdatascience.com/machine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c/", "webpage": {"metadata": {"title": "Machine Learning\u2019s Obsession with Kids\u2019 TV Show Characters | by Catherine Yeo | Towards Data Science", "h1": "Machine Learning\u2019s Obsession with Kids\u2019 TV Show Characters", "description": "Elmo, Bert, and Marge (Simpson) aren\u2019t just your favorite TV characters growing up - they\u2019re also machine learning and NLP models. This article gives an overview on all of these models and, of course, their character inspirations."}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1802.05365.pdf", "anchor_text": "ELMo", "paragraph_index": 2}, {"url": "https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie", "anchor_text": "\u201cwhimsical but memorable\u201d", "paragraph_index": 2}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1906.01604.pdf", "anchor_text": "KERMIT", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1910.13461.pdf", "anchor_text": "BART", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1905.12616.pdf", "anchor_text": "GROVER", "paragraph_index": 4}, {"url": "https://twitter.com/jackclarkSF/status/1187824098916753408", "anchor_text": "almost", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/2006.15020.pdf", "anchor_text": "MARGE", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1802.05365.pdf", "anchor_text": "ELMo", "paragraph_index": 6}, {"url": "http://jalammar.github.io/illustrated-bert/", "anchor_text": "resource", "paragraph_index": 9}, {"url": "https://lifestyle.howstuffworks.com/family/activities/how-elmo-works.htm", "anchor_text": "won the longest giggle award on the Golden Grover Awards", "paragraph_index": 10}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "introducing", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1905.07129.pdf", "anchor_text": "ERNIE", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1907.12412", "anchor_text": "ERNIE 2.0", "paragraph_index": 15}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE", "paragraph_index": 16}, {"url": "https://arxiv.org/pdf/1905.07129.pdf", "anchor_text": "ERNIE", "paragraph_index": 17}, {"url": "https://arxiv.org/pdf/1906.01604.pdf", "anchor_text": "KERMIT", "paragraph_index": 19}, {"url": "https://www.12news.com/article/news/year-in-review/here-are-the-top-memes-of-the-2010s/75-cc27ea6b-4a22-475b-b382-4d9f5547f056", "anchor_text": "But That\u2019s None of My Business", "paragraph_index": 21}, {"url": "https://www.theguardian.com/technology/2016/nov/30/evil-kermit-perfect-meme-terrible-times", "anchor_text": "Evil Kermit", "paragraph_index": 21}, {"url": "https://arxiv.org/pdf/1910.13461.pdf", "anchor_text": "BART", "paragraph_index": 22}, {"url": "https://arxiv.org/pdf/1905.12616.pdf", "anchor_text": "GROVER", "paragraph_index": 28}, {"url": "https://arxiv.org/abs/2006.15020", "anchor_text": "MARGE", "paragraph_index": 31}, {"url": "https://en.wikipedia.org/wiki/BLEU", "anchor_text": "BLEU", "paragraph_index": 33}, {"url": "https://twitter.com/catyeo18", "anchor_text": "let me know", "paragraph_index": 37}, {"url": "https://medium.com/fair-bytes", "anchor_text": "Subscribe", "paragraph_index": 38}, {"url": "https://twitter.com/catherinehyeo", "anchor_text": "@catherinehyeo", "paragraph_index": 39}, {"url": "http://catherinehyeo.com", "anchor_text": "catherinehyeo.com", "paragraph_index": 41}], "all_paragraphs": ["Bart. Elmo. Bert. Kermit. Marge. What do they have in common?", "They\u2019re all beloved fictional characters from TV shows many of us watched when we were young. But that\u2019s not all \u2014 they\u2019re also all AI models.", "In 2018, researchers at the Allen Institute published the language model ELMo. The lead author, Matt Peters, said the team brainstormed many acronyms for their model, and ELMo instantly stuck as a \u201cwhimsical but memorable\u201d choice.", "What started out as an inside joke has become a full-blown trend.", "Google AI followed with BERT, an incredibly powerful and now widely used Transformer-based language model. Then, many more: ERNIE, KERMIT, BART, GROVER, etc. OpenAI almost named GPT-2 \u201cSnuffleupagus, or Snuffy for short.\u201d Just last month, Facebook AI published MARGE.", "This article gives an overview on all of these models and, of course, their character inspirations below:", "The one that started this trend, ELMo is a deep contextualized word representation approach that is able to capture more characteristics about words (syntax, semantics, and more).", "A big challenge in representing words as vectors (\u201cword embeddings\u201d) was that a word would be represented by the same vector no matter what context it was used in. However, \u201ccurrent\u201d has different meanings in \u201cwhat\u2019s your current job?\u201d versus \u201cthat is a strong river current\u201d \u2014 we can\u2019t just use one fixed representation for both \u201ccurrent\u201ds!", "Thus, contextualized word embeddings were created to capture a word\u2019s context in its representation as well. Rather than only reading a word at a time, ELMo reads the entire sentence for context before assigning every word its embedding, which is done using a bi-directional LSTM.", "ELMo was a great step forward in natural language processing (NLP) research using language modeling. For an illustrated explanation of ELMo, I would highly recommend this resource.", "Outside machine learning and NLP, Elmo is an adorable furry red Muppet on the children\u2019s show Sesame Street. Elmo likes surprises, pizza, and bubble baths and won the longest giggle award on the Golden Grover Awards. It first appeared on screen in 1980.", "Google further transformed pre-training in NLP by introducing BERT, a new Transformer-based language model that was the first to allow deeply bidirectional and unsupervised representation.", "Deeply bidirectional means in capturing contextual embeddings, BERT represents each word using both its previous and next context. (In comparison, ELMo is shallowly bidirectional.) Simply conditioning each word on its previous and next words can be problematic, so BERT randomly masks some of the words and conditions each word bidirectionally to predict the masked words.", "In its initial release, BERT already achieved impressive results in question-and-answering and natural language understanding tasks. BERT and other Transformer-based architectures have been a cornerstone of NLP research in the past year.", "Outside machine learning and NLP, Bert is a friendly yellow character on Sesame Street. In his free time, he likes to read Boring Stories, eat oatmeal, and study pigeons.", "You can\u2019t have Bert without his best buddy Ernie \u2014 good thing researchers developed ERNIE (Sun et al.), ERNIE (Zhang et al.), and even ERNIE 2.0!", "The first ERNIE (Enhanced Representation through Knowledge Integration) presented a language model that extended BERT\u2019s word masking strategy to entity-level and phrase-level masking. In doing so, this ERNIE can implicitly learn the prior knowledge of phrases, entities, and relationships between them during the training process.", "Less than two months later, a second ERNIE (Enhanced Language Representation with Informative Entities) was published. This ERNIE presented a language model that incorporated knowledge graphs to optimize for having as much information as possible. Knowledge graphs are a powerful way to represent data points and relations that link them together.", "Outside machine learning and NLP, Ernie is a troublemaker whose life mission is to annoy Bert on Sesame Street. He is extremely fond of his rubber duckie and once famously said \u201cI can\u2019t hear you, I have a banana in my ear!\u201d", "KERMIT is an insertion-based generative architecture that models the joint distribution, decompositions (i.e. its marginals), and conditionals together. The researchers found that KERMIT worked well for a few select tasks, including machine translation.", "In case you were wondering like I was, \u201ckontextuell\u201d is Swedish for \u201ccontextual\u201d. We know the researchers were quite intentional on this naming because later in the paper, they write \u201cThen, like its friends ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), and ERNIE (Sun et al., 2019), we can also use KERMIT\u2026\u201d", "Outside machine learning and NLP, Kermit is an iconic singing frog that has graced many Muppet productions (Sam and Friends, Sesame Street, The Muppet Show, etc.) and memes (But That\u2019s None of My Business, Evil Kermit, etc.). Introduced in 1955, Kermit is the oldest TV character on this list.", "Facebook AI built on BERT, GPT, and previous NLP pre-training work to create BART, a new pretrained model for text generation and comprehension that combines both bidirectional and auto-regressive Transformers.", "BERT used masking in its bidirectional encoder, which meant that masked/missing words were predicted independently. As a result, BERT can\u2019t be used for text generation.", "In contrast, GPT is auto-regressive, which means that it predicts a future word from a set of words given a context in a forward direction. As a result, GPT can\u2019t learn bidirectional interactions.", "BART combines these fundamental ideas together: 1) a document with random spans of text replaced with masks is encoded bidirectionally, then 2) the likelihood of the unmodified document is predicted with an autoregressive decoder.", "Outside machine learning and NLP, Bart is one of TV\u2019s most well-known young rebels. You can find Bart and his endless prank calls on The Simpsons.", "The NLP field has progressed very quickly in recent years to achieve highly believable summarization and translation. However, these technologies can also be used for less-than-positive purposes, such as AI-generated fake news and propaganda.", "To combat this, researchers created GROVER, a publicly available generator that can write realistic and controlled fake news. GROVER\u2019s purpose is so others could practice against it to develop better techniques for classifying AI-generated fake news from real, human-written news. At the time, the best discriminator could only distinguish AI-generated fake news from real news with 73% accuracy.", "(In a baffling naming decision, there\u2019s no acronym here \u2014 it\u2019s called GROVER just because.)", "Outside machine learning and NLP, Grover is a furry, blue Sesame Street character who loves to help (or tries to help) others. Hopefully GROVER can help the AI world in addressing disinformation as much as Grover helps his friends.", "Published very recently by Facebook AI, MARGE is a new \u201ca pre-trained sequence-to-sequence model learned with an unsupervised multilingual multi-document paraphrasing objective.\u201d", "In simpler words, it\u2019s a pre-trained language model that generates text by 1) retrieving related text in other languages, 2) reconstructing the original text by finding patterns within them.", "The researchers found that MARGE can successfully perform paraphrasing, translation, multi-document summarization, and information retrieval tasks all without any fine tuning. MARGE scored up to 35.8 on BLEU (Bilingual Evaluation Understudy), a metric for language translations, which is considered quite high for a model without fine tuning.", "Outside machine learning and NLP, Marge is a fictional character on The Simpsons. Mother of three kids (including Bart), Marge is also well-known for her tall, blue (bleu? \ud83d\udc40) hair.", "(With both BART and MARGE, perhaps Facebook AI likes the Simpsons a lot?)", "It\u2019s pretty cool that researchers pay homage to previous works in this funny, harmless way. Perhaps future state-of-the-art machine learning models will be named HERMiONE or ZUKo \u2014 I eagerly await the day for AI researchers to expand to other fiction realms.", "If there are any other AI models named after fictional characters, let me know!", "Thank you for reading! Subscribe to read more about research, resources, and issues related to AI.", "Catherine Yeo is a CS undergraduate at Harvard interested in AI/ML/NLP, fairness and ethics, and everything related. Feel free to suggest ideas or say hi to her on Twitter @catherinehyeo.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Harvard | Book Author | AI/ML writing in @fairbytes @towardsdatascience | More at catherinehyeo.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F728edfb43b3c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@catyeo18?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@catyeo18?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Catherine Yeo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F297181e56116&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&user=Catherine+Yeo&userId=297181e56116&source=post_page-297181e56116----728edfb43b3c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@stefangrage?utm_source=medium&utm_medium=referral", "anchor_text": "Stefan Grage"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1802.05365.pdf", "anchor_text": "ELMo"}, {"url": "https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie", "anchor_text": "\u201cwhimsical but memorable\u201d"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT"}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/pdf/1906.01604.pdf", "anchor_text": "KERMIT"}, {"url": "https://arxiv.org/pdf/1910.13461.pdf", "anchor_text": "BART"}, {"url": "https://arxiv.org/pdf/1905.12616.pdf", "anchor_text": "GROVER"}, {"url": "https://twitter.com/jackclarkSF/status/1187824098916753408", "anchor_text": "almost"}, {"url": "https://arxiv.org/pdf/2006.15020.pdf", "anchor_text": "MARGE"}, {"url": "https://arxiv.org/pdf/1802.05365.pdf", "anchor_text": "ELMo"}, {"url": "http://jalammar.github.io/illustrated-bert/", "anchor_text": "resource"}, {"url": "https://lifestyle.howstuffworks.com/family/activities/how-elmo-works.htm", "anchor_text": "won the longest giggle award on the Golden Grover Awards"}, {"url": "https://arxiv.org/pdf/1802.05365.pdf", "anchor_text": "ELMo"}, {"url": "https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html", "anchor_text": "introducing"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT"}, {"url": "https://arxiv.org/pdf/1810.04805.pdf", "anchor_text": "BERT"}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/pdf/1905.07129.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/abs/1907.12412", "anchor_text": "ERNIE 2.0"}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/pdf/1905.07129.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/pdf/1904.09223.pdf", "anchor_text": "ERNIE"}, {"url": "https://arxiv.org/pdf/1906.01604.pdf", "anchor_text": "KERMIT"}, {"url": "https://www.12news.com/article/news/year-in-review/here-are-the-top-memes-of-the-2010s/75-cc27ea6b-4a22-475b-b382-4d9f5547f056", "anchor_text": "But That\u2019s None of My Business"}, {"url": "https://www.theguardian.com/technology/2016/nov/30/evil-kermit-perfect-meme-terrible-times", "anchor_text": "Evil Kermit"}, {"url": "https://arxiv.org/pdf/1906.01604.pdf", "anchor_text": "KERMIT"}, {"url": "https://arxiv.org/pdf/1910.13461.pdf", "anchor_text": "BART"}, {"url": "https://arxiv.org/pdf/1910.13461.pdf", "anchor_text": "BART"}, {"url": "https://arxiv.org/pdf/1905.12616.pdf", "anchor_text": "GROVER"}, {"url": "https://arxiv.org/pdf/1905.12616.pdf", "anchor_text": "GROVER"}, {"url": "https://arxiv.org/abs/2006.15020", "anchor_text": "MARGE"}, {"url": "https://en.wikipedia.org/wiki/BLEU", "anchor_text": "BLEU"}, {"url": "https://arxiv.org/abs/2006.15020", "anchor_text": "MARGE"}, {"url": "https://twitter.com/catyeo18", "anchor_text": "let me know"}, {"url": "https://medium.com/fair-bytes", "anchor_text": "Subscribe"}, {"url": "https://medium.com/fair-bytes/how-biased-is-gpt-3-5b2b91f1177", "anchor_text": "How Biased is GPT-3?Despite its impressive performance, the world\u2019s newest language model reflects societal biases in gender, race, and\u2026medium.com"}, {"url": "https://medium.com/fair-bytes/we-need-to-change-how-image-datasets-are-curated-b325642394df", "anchor_text": "We Need to Change How Image Datasets are CuratedWhy many gold-standard computer vision datasets, such as ImageNet, are flawedmedium.com"}, {"url": "https://twitter.com/catherinehyeo", "anchor_text": "@catherinehyeo"}, {"url": "https://medium.com/tag/ai?source=post_page-----728edfb43b3c---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----728edfb43b3c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----728edfb43b3c---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----728edfb43b3c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/tds-narrated?source=post_page-----728edfb43b3c---------------tds_narrated-----------------", "anchor_text": "Tds Narrated"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&user=Catherine+Yeo&userId=297181e56116&source=-----728edfb43b3c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&user=Catherine+Yeo&userId=297181e56116&source=-----728edfb43b3c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F728edfb43b3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----728edfb43b3c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----728edfb43b3c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----728edfb43b3c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----728edfb43b3c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@catyeo18?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@catyeo18?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Catherine Yeo"}, {"url": "https://medium.com/@catyeo18/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "254 Followers"}, {"url": "http://catherinehyeo.com", "anchor_text": "catherinehyeo.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F297181e56116&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&user=Catherine+Yeo&userId=297181e56116&source=post_page-297181e56116--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd11afe16c8d7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c&newsletterV3=297181e56116&newsletterV3Id=d11afe16c8d7&user=Catherine+Yeo&userId=297181e56116&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}