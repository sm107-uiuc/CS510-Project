{"url": "https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030", "time": 1682994721.019839, "path": "towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030/", "webpage": {"metadata": {"title": "How to visualize convolutional features in 40 lines of code | by Fabio M. Graetz | Towards Data Science", "h1": "How to visualize convolutional features in 40 lines of code", "description": "Recently, while reading Jeremy Rifkin\u2019s book \u201cThe End of Work\u201d, I came across an interesting definition of AI. Rifkin writes: \u201ctoday when scientists talk of artificial intelligence, they generally\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network", "anchor_text": "Erhan et al. 2009", "paragraph_index": 2}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf", "anchor_text": "neural style transfer", "paragraph_index": 33}, {"url": "https://arxiv.org/pdf/1312.6199.pdf", "anchor_text": "adversarial examples", "paragraph_index": 46}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/filter_visualizer.ipynb", "anchor_text": "notebook", "paragraph_index": 54}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/README.md", "anchor_text": "readme", "paragraph_index": 54}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/Calculate_mean_activation_per_filter_in_specific_layer_given_an_image.ipynb", "anchor_text": "notebook", "paragraph_index": 55}, {"url": "https://openreview.net/pdf?id=Bygh9j09KX", "anchor_text": "paper", "paragraph_index": 57}], "all_paragraphs": ["Recently, while reading Jeremy Rifkin\u2019s book \u201cThe End of Work\u201d, I came across an interesting definition of AI. Rifkin writes: \u201ctoday when scientists talk of artificial intelligence, they generally mean \u2018the art of creating machines that perform functions which require intelligence when performed by people.\u2019 (taken from Kurzweil, Raymond, The Age of Intelligent Machines (Cambridge, MA: MIT Press, 1990), p. 14.)\u201d. I like this definition because it avoids the hyped discussion whether AI is truly intelligent in the sense of our intelligence. As a scientist, the thought of unveiling the functional principles of our brain and creating a truly intelligent machine excites me but I think it is important to realize that Deep Learning models are not models of the brain (Fran\u00e7ois Chollet, Deep Learning with Python (Shelter Island, NY: Manning Publications, 2018), p. 8). Deep Learning research is aimed at learning rules from data to automize processes that until now were not automizable. While that may sound less exciting, it truly is a great thing. Just one example: the emergence of deep convolutional neural networks revolutionized computer vision and pattern recognition and will allow us to introduce a vast amount of automation in fields such as medical diagnosis. This could allow humanity to quickly bring top medical diagnosis to people in poor countries that are not able to educate the many doctors and experts they would otherwise require.", "Despite all the exciting news about Deep Learning, the exact way neural networks see and interpret the world remains a black box. A better understanding of how exactly they recognize specific patterns or objects and why they work so well might allow us to 1) improve them even further and would 2) also solve legal problems since in many cases the decisions a machine takes have to be interpretable to humans.", "There are two main ways to try to understand how a neural network recognizes a certain pattern. If you want to know what kind of pattern significantly activates a certain feature map you could 1) either try to find images in a dataset that result in a high average activation of this feature map or you could 2) try to generate such a pattern by optimizing the pixel values in a random image. The latter idea was proposed by Erhan et al. 2009. In this article, I am going to explain to you how you can generate feature visualizations for a convolutional neural network as shown in the cover picture by optimizing pixel values of a random image with only ~40 lines of Python code.", "The article is structured as follows: First, I will show you visualizations of convolutional features in several layers of a VGG-16 network, then we will try to understand some of those visualizations and I will show you how to quickly test a hypothesis of what kind of pattern a certain filter might detect. Finally, I will explain the code that is necessary to create the patterns presented in this article.", "Neural networks learn to transform input data such as images into successive layers of increasingly meaningful and complex representations.", "You can think of a deep network as a multistage information-distillation operation, where information goes through successive filters and comes out increasingly purified. (Fran\u00e7ois Chollet, Deep Learning with Python (Shelter Island, NY: Manning Publications, 2018), p. 9)", "After reading his article, you will know how you can generate patterns that maximize the mean activation of a chosen feature map in a certain layer of those hierarchical representations, how you might be able to interpret some of those visualizations, and finally how to test a hypothesis of what kind of pattern or texture the chosen filter might respond to. Below you find feature visualizations for filters in several layers of a VGG-16 network. While looking at them, I would like you to observe how the complexity of the generated patterns increases the deeper we get into the network.", "Those patterns really blow my mind! Partly, because I think that some of them are stunningly beautiful (so much that I\u2019d immediately frame them and put them on my wall) but mostly because of the thought that they were created simply by maximizing a certain value produced by a complicated, parameterized mathematical function that was trained on thousands of images. And while scanning through the 512 patterns obtained by maximizing the average activations of the feature maps in the last convolutional layer, I came across several ones that made me think \u201cwait, this is a chicken!\u201d or \u201cdoesn\u2019t this look like feathers?\u201d", "Let\u2019s try to interpret some of those feature visualizations!", "Starting with this one, does this remind you of something?", "The picture immediately reminded me of the round arches of a vaulted ceiling you would find in churches.", "So how could we test this hypothesis? The picture of the artificial arches was created by maximizing the mean activation of the 286th feature map in the 40th layer. We, therefore, simply apply the network to the picture and plot the average activations of the feature maps in the 40th layer.", "What do we see? A strong spike at feature map 286, as expected! So does this mean that filter 286 in layer 40 is the filter responsible for detecting vaulted ceilings? Well, I\u2019d be a little careful here. Filter 286 apparently responds to arch like structures in images but keep in mind that such arch-like structures might play an important role for several different categories.", "Note: while I used layer 40, which is a convolutional layer, to generate the images we are currently looking at, I used layer 42 to generate the plots showing the mean activation per feature map. Layer 41 and 42 are batch-norm and ReLU. The ReLU activation function removes all negative values and the only reason for choosing layer 42 instead of 40 is that otherwise, the plot would show a large amount of negative noise that made it hard to see the positive spikes we are interested in.", "On to the next example. I could swear those are chicken heads (or at least bird heads)! Do you see the pointy beaks and dark eyes?", "And voil\u00e0, feature map 256 shows a strong spike.", "Could it be that filter 462 responds to feathers?", "Yes, filter 462 responds to feathers:", "However, there are some other large peaks! Let\u2019s take a look at feature visualizations generated for two of the respective filters:", "While quickly scanning through the patterns generated for the 512 filters of the 40th layer, neither of both pictures rang a bell. But now that the network spoke? Maybe a little bit chain-like, what would you say?", "I believe to see lots of feather-like structures, something that reminds me of bird legs and at the bottom left there might be something similar to a bird head with a dark eye and a long beaky. Longer than the beaks in the \u201cchicken feature visualization\u201d. I\u2019m really not a bird expert, but what about those two here? They have got long legs and beaks.", "Ok, there clearly is a spike at feature map 64 but there are more and even larger ones! Let\u2019s take a look at patterns generated for four of the other filters whose feature maps show a spike:", "More bird legs and some more eyes and beaks in the top row? Regarding the bottom row, however, I have no clue. Maybe those patterns are associated with the background of the image or simply represent something the network needs for detecting birds that I don\u2019t understand. I suppose this will remain part of the black box for now\u2026", "A final cute one and then we jump straight to the code, I promise. Any guesses what this could be?", "I had two cats for many years and I recognize a kitten ear when I see one :D Do you see them? Look for a big one in the top left corner!", "Yes, there is a spike for feature map 277 but what caused the strong spike directly to the right of it?", "Let\u2019s quickly generate a picture that maximizes the mean activation of feature map 281 in layer 40:", "I had a lot of fun trying to pry a few secrets out of the network. The truth, however, is that most filters even in the final convolutional layer remained absolutely abstract to me.", "A more rigorous approach to this would be to apply the network to an entire dataset of many different kinds of images and keep track of the ones that excite a certain filter in a certain layer the most.", "There is one additional thing that I found very interesting. While scanning through the generated patterns I discovered that many patterns seemed to occur in different orientations (sometimes even the same orientation).", "This makes sense! Convolutions are translationally invariant because the filters slide over the image horizontally and vertically. But they are not rotationally invariant because the filters don\u2019t rotate. The network, thus, seems to need several similar filters in different orientations to detect objects and patterns that are differently oriented.", "The idea is the following: we start with a picture containing random pixels. We apply the network in evaluation mode to this random image, calculate the average activation of a certain feature map in a certain layer from which we then compute the gradients with respect to the input image pixel values. Knowing the gradients for the pixel values we then proceed to update the pixel values in a way that maximizes the average activation of the chosen feature map.", "I know that this might sound confusing so let\u2019s explain it again in different words: The network weights are fixed, the network will not be trained, and we try to find an image that maximizes the average activation of a certain feature map by performing gradient descent optimization on the pixel values.", "This technique is also used for neural style transfer.", "In order to implement this we will need:", "Let\u2019s start with generating a noisy image as input. We can do this i.e. the following way: img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255 where sz is the height and width of the image, 3 is the number of color channels, and we divide by 255 because it is the maximum value a variable of type uint8 can store. Play with the numbers 150 and 180 if you want more or less noise. We then convert this to a PyTorch variable that requires gradients using img_var = V(img[None], requires_grad=True)(this is fastai syntax). The pixel values require gradients as we want to optimize them using backpropagation.", "Next, we need a pre-trained network in evaluation mode (which means that the weights are fixed). This can be done with model = vgg16(pre=True).eval() and set_trainable(model, False).", "Now, we need a way to access the features from one of the hidden layers. We could truncate the network after the hidden layer we are interested in so that it would become the output layer. There is, however, a nicer way to solve this problem in PyTorch called a hook which can be registered on a PyTorch Module or a Tensor. To understand this, you have to know:", "When we apply our network to our noisy image the forward method of the first layer takes the image as input and calculates its output. This output is the input to the forward method of the second layer and so on. When you register a forward hook on a certain layer the hook is executed when the forward method of that layer is called. Ok, I know this sounds confusing. What I want you to take from this is the following: when you apply your network to an input image the first layer calculates its output, then the second, and so on. When we reach a layer for which we registered a hook, it not only calculates its output but also executes the hook.", "So what is this good for? Let\u2019s say we are interested in the feature maps of layer i. We register a forward hook on layer i that, once the forward method of layer i is called, saves the features of layer i in a variable.", "When the hook is executed, it calls the method hook_fn (see constructor). The method hook_fn saves the layers output in self.features. Note, that this tensor requires gradients because we want to perform backpropagation on the pixel values.", "How would you use a SaveFeatures object?", "Register your hook for layer i with activations = SaveFeatures(list(self.model.children())[i]) and after you applied your model to the image with model(img_var) you can access the features the hook saved for us in activations.features. Remember to call the method close to free up used memory.", "Great, we can now access the feature maps of layer i! The feature maps could i.e. have the shape [1, 512, 7, 7] where 1 is the batch dimension, 512 the number of filters/feature maps and 7 the height and width of the feature maps. The goal is to maximize the average activation of a chosen feature map j. We, therefore, define the following loss function: loss = -activations.features[0, j].mean() and an optimizer optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6) that optimizes the pixel values. Optimizers by default minimize losses so instead of telling the optimizer to maximize the loss we simply multiply the mean activation by -1. Reset the gradients with optimizer.zero_grad(), calculate the gradients of the pixel values with loss.backward(), and change the pixel values with optimizer.step().", "We now have everything that we need: we started with a random image, defined a pre-trained network in evaluation mode, registered a forward hook to access the features of layer i, and defined an optimizer and a loss function that allows us to change the pixel values in a way that maximizes the mean activation of feature map j in layer i.", "Great, let\u2019s look at an example of what this gives us:", "Wait, this is not what we wanted right? This was supposed to result in the chain pattern I showed you before. If you pinch your eyes you might be able to guess where \u201cthe chains\u201d might be. However, we must have ended up in a very poor local minimum and have to find a way to guide our optimizer towards a better minimum/better-looking pattern. In contrast to the generated patterns I showed you before, this picture is dominated by a high-frequency pattern that resembles adversarial examples. So, what could we do to fix this? I experimented with different optimizers, learning rates, and regularizations but nothing appeared to reduce the high-frequency patterns.", "Next, I varied the size of the noisy input image.", "Can you observe that the frequency of the \u201cchain pattern\u201d appears to increase with the image size? I know that it might be hard to see what I mean. However, somehow it does make sense to me that the frequency of the generated pattern increases with the image size because the convolutional filters have a fixed size but their relative size compared to the image decreases with increasing image resolution. In other words: Assume that the pattern that is created always has roughly the same size measured in pixels. If we increase the image size, the relative size of the generated pattern will reduce and the pattern frequency increases.", "If my assumptions are true, what we want is the low-frequency pattern of a low-resolution example (even lower than the ones shown above) but with a high resolution. Does this make sense? And how could we do this?", "I tried to start with a very low-resolution image of i.e. 56 by 56 pixels, optimized the pixel values for a few steps, and then increased the image size by a certain factor. After upscaling the image I then optimized the pixel values for a few more steps and then again, upscaled the image\u2026", "We now have a low-frequency pattern in a much better resolution and not too much noise. Why does this work? I have the following idea: when we start with a low resolution, we get a low-frequency pattern. After upscaling, the upscaled pattern has a lower frequency than what the optimizer would have generated if we had started at that larger image size with a random image. So when optimizing the pixel values in the next iteration we are at a better starting point and appear to avoid poor local minima. Does this make sense? To further reduce high-frequency patterns, I slightly blurred the image after upscaling which affects high-frequency patterns more than low-frequency patterns.", "I found that scaling up 12 times by a factor of 1.2 gives nice results.", "Take a look at the code below. You will find that we already discussed most significant lines such as the creation of the random image, registering the hook, defining the optimizer and loss, and optimizing the pixel values. The only important new aspects are, that 1) I wrapped the code together in a class and 2) that we scale-up the image several times after optimizing the pixel values for a few steps.", "If you want to play with this, feel free to use and change the notebook. If you didn\u2019t understand every line, don\u2019t worry, for a start you can simply change the layer and filter indices and run the notebook top to bottom. Follow the instructions in the readme file to create a conda environment with fastai==0.7.0 installed.", "Can you find other feature maps in which you are able to recognize patterns? In case you want to test your hypothesis with a picture as I did in this article, feel free to use this notebook. If you discover something cool, let me now! :)", "I hope that you enjoyed the beauty of the visualized features as much as I did and that I was able to teach you something interesting. If any part is unclear or you need additional explanations, please leave a comment, I\u2019d love to help you understand :)", "Update: a reader pointed me to this exciting new paper that suggests that neural networks might not recognize shapes but rather respond to textures. Check it out!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior MLOps engineer at Recogni | Machine Learning | Kubernetes | Theoretical Astrophysicist | Bespoke Shoemaking | Berlin"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F70b7d87b0030&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@fabiograetz?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiograetz?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Fabio M. Graetz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffb820388a7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&user=Fabio+M.+Graetz&userId=fb820388a7e9&source=post_page-fb820388a7e9----70b7d87b0030---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network", "anchor_text": "Erhan et al. 2009"}, {"url": "https://de.wikipedia.org/wiki/Romanik#/media/File:Gadebusch_Hallenschiff441.JPG", "anchor_text": "Source"}, {"url": "https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Orpington_chicken_head.jpg/320px-Orpington_chicken_head.jpg", "anchor_text": "Source"}, {"url": "https://commons.wikimedia.org/wiki/Feather#/media/File:Handschwingen_auswahl_2.jpg", "anchor_text": "Source"}, {"url": "https://commons.wikimedia.org/wiki/Chain#/media/File:Broad_chain_closeup.jpg", "anchor_text": "Source"}, {"url": "https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Wattledcranethumb.jpg/206px-Wattledcranethumb.jpg", "anchor_text": "Source"}, {"url": "https://commons.wikimedia.org/wiki/Category:Cat_ears#/media/File:Daisy-jan13.jpg", "anchor_text": "Source"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf", "anchor_text": "neural style transfer"}, {"url": "https://arxiv.org/pdf/1312.6199.pdf", "anchor_text": "adversarial examples"}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/filter_visualizer.ipynb", "anchor_text": "notebook"}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/README.md", "anchor_text": "readme"}, {"url": "https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/Calculate_mean_activation_per_filter_in_specific_layer_given_an_image.ipynb", "anchor_text": "notebook"}, {"url": "https://openreview.net/pdf?id=Bygh9j09KX", "anchor_text": "paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----70b7d87b0030---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----70b7d87b0030---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----70b7d87b0030---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----70b7d87b0030---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----70b7d87b0030---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&user=Fabio+M.+Graetz&userId=fb820388a7e9&source=-----70b7d87b0030---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&user=Fabio+M.+Graetz&userId=fb820388a7e9&source=-----70b7d87b0030---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F70b7d87b0030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----70b7d87b0030---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----70b7d87b0030--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----70b7d87b0030--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----70b7d87b0030--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiograetz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabiograetz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fabio M. Graetz"}, {"url": "https://medium.com/@fabiograetz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "849 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffb820388a7e9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&user=Fabio+M.+Graetz&userId=fb820388a7e9&source=post_page-fb820388a7e9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc88e15df57a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030&newsletterV3=fb820388a7e9&newsletterV3Id=c88e15df57a4&user=Fabio+M.+Graetz&userId=fb820388a7e9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}