{"url": "https://towardsdatascience.com/understand-logistic-regression-from-scratch-430aedf5edb9", "time": 1683013687.009131, "path": "towardsdatascience.com/understand-logistic-regression-from-scratch-430aedf5edb9/", "webpage": {"metadata": {"title": "Understand the Logistic Regression from Scratch \u2014 Kaggle Notebook | by Narendra Prasath | Towards Data Science", "h1": "Understand the Logistic Regression from Scratch \u2014 Kaggle Notebook", "description": "The goal of this kernel is to implement logistic regression from scratch for sentiment analysis using the twitter dataset. We will be mainly focusing on building blocks of logistic regression on our\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pypi.org/project/jupyter-to-medium/", "anchor_text": "JupytertoMedium", "paragraph_index": 2}, {"url": "https://www.kaggle.com/narendrageek/understand-the-logistic-regression-from-scratch", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "Wiki", "paragraph_index": 13}, {"url": "https://www.linkedin.com/in/narendra-prasath/", "anchor_text": "LinkedIn", "paragraph_index": 47}], "all_paragraphs": ["7. Test with Scikit learn logistic regression", "Let\u2019s import all the necessary modules in Python.", "The goal of this kernel is to implement logistic regression from scratch for sentiment analysis using the twitter dataset. We will be mainly focusing on building blocks of logistic regression on our own. This kernel can provide an in-depth understanding of how logistic regression works internally. The notebook is converted to a medium article using the JupytertoMedium python library. The Kaggle notebook is available from here.", "Given a tweet, it will be classified if it has positive sentiment \ud83d\udc4d or negative sentiment \ud83d\udc4e. It is very useful for beginners and others as well.", "Preprocessing is one of the important steps in the pipeline. It includes cleaning and removing unnecessary data before building a machine learning model.", "Let\u2019s see how we can implement this.", "Let\u2019s take a look at what output got after preprocessing tweets. It\u2019s good that we were able to process the tweets successfully.", "BOW represents the word and its frequency for each class. We will create a dict for storing the frequency of positive and negative classes for each word.Let\u2019s indicate a positive tweet is 1 and the negative tweet is 0. The dict key is a tuple containing the(word, y) pair. The word is processed word and y indicates the label of the class. The dict value represents the frequency of the word for class y.", "Now, we have various methods to represent features for our twitter corpus. Some of the basic and powerful techniques are,", "The count vectorizer indicates the sparse matrix and the value can be the frequency of the word. Each column is a unique token in our corpus.", "The sparse matrix dimension would be no of unique tokens in the corpus * no of sample tweets.", "Example: corpus = [ 'This is the first document.', 'This document is the second document.', 'And this is the third one.', 'Is this the first document?', ] and the CountVectorizer representation is", "TF-IDF statistical measure that evaluates how relevant a word is to a document in a collection of documents. TF-IDF is computed as follows:", "Term Frequency: term frequency tf(t,d), the simplest choice is to use the frequency of a term (word) in a document. Inverse Document Frequency: idf(t,D) a measure of how much information the word provides, i.e., if it\u2019s common or rare across all documents. It is the logarithmic scale of the inverse fraction of the document that contains the word. The definition is as per Wiki.", "This seems to be simple, isn\u2019t it? Perhaps yes. We are not representing our features to the sparse matrix. Will use the simplest features for our analysis.", "Shuffle the corpus and will split the train and test set.", "Let\u2019s keep the 80% data for training and 20% data samples for testing.", "Take a look at sample train features.", "Now, Let\u2019s see how logistic regression works and gets implemented.", "Most of the time, when you hear about logistic regression you may think, it is a regression problem. No, it is not, Logistic regression is a classification problem and it is a non-linear model.", "As shown in the above picture, there are 4 stages for most of the ML algorithms,", "Step 3. Calculate the cost (objective of the algorithm)", "Logistic regression takes a linear regression and applies a sigmoid to the output of the linear regression. So, It produces the probability of each class and it sums up to 1.", "Regression: Single linear regression equation as follows:", "You may think of how complicated the equation it is. We need to multiply all the weighs with each feature at the ith position then sums up all.", "Fortunately, Linear algebra brings this equation with ease of operation. Yes, It is a matrix dot product. You can apply the dot product of features and weights to find the z.", "It maps the input \u2018z\u2019 to a value that ranges between 0 and 1, and so it can be treated as a probability.", "The cost function used in logistic regression is:", "This is the Log loss of binary classification. The average of the log loss across all training samples is calculated in logistic regression, the equation 3 modified for all the training samples as follows:", "The loss function for a single training example is,", "Gradient Descent is an algorithm used for updating the weights theta iteratively to minimize the objective function (cost). We need to update the weights iteratively because,", "At initial random weights, the model doesn\u2019t learn anything much. To improve the prediction we need to learn from the data with multiple iterations and tune the random weights accordingly.", "The gradient of the cost function J for one of the weights theta_j is:", "Regularization is a technique to solve the problem of overfitting in a machine learning algorithm by penalizing the cost function. There will be an additional penalty term in the cost function. There are two types of regularization techniques:", "Lasso Regression (L1) L1-norm loss function is also known as the least absolute errors (LAE). $\u03bb*\u2211 |w| $ is a regularization term. It is a product of $\u03bb$ regularization term with an absolute sum of weights. The smaller values indicate stronger regularization.", "Ridge Regression (L2) L2-norm loss function is also known as the least squares error (LSE). $\u03bb*\u2211 (w)\u00b2$ is a regularization term. It is a product of $\u03bb$ regularization term with the squared sum of weights. The smaller values indicate stronger regularization.", "You could notice, that it makes a huge difference. Yes, it does well. The main difference is what type of regularization term you are adding in the cost function to minimize the error.", "L2 (Ridge) shrinks all the coefficient by the same proportions but it doesn\u2019t eliminate any features, while L1 (Lasso) can shrink some coefficients to zero, and also performs feature selection.", "In the following code will add L2 regularization", "Let\u2019s train the gradient descent function for optimizing the randomly initialized weights. The brief explanation has given in section 4.", "It is time to test our logistic regression function on test data that the model has not seen before.", "Predict whether a tweet is positive or negative.", "As of now, we have seen how to implement the logistic regression on our own. Got the accuracy of 94.45. Let\u2019s see the results from the popular Machine Learning (ML) Python library.", "Here, we are going to train the logistic regression from the in-build Python library to check the results.", "Great!!!. The results are pretty much close.", "Finally, we implemented the logistic regression on our own and also tried with in-build Scikit learn logistic regression getting similar accuracy. But, this approach of feature extraction is very simple and intuitive.", "I am learning by doing it. Kindly leave your thoughts or any suggestions in the comments. Your feedback is highly appreciated to boost my confidence.", "\ud83d\ude4fThanks for reading! You can reach me via LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Product Engineer\u2014 Aditya Birla Group | Passionate about Data Science field"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F430aedf5edb9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@narendren.jbk?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@narendren.jbk?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Narendra Prasath"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8a7fd0a8af09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&user=Narendra+Prasath&userId=8a7fd0a8af09&source=post_page-8a7fd0a8af09----430aedf5edb9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pypi.org/project/jupyter-to-medium/", "anchor_text": "JupytertoMedium"}, {"url": "https://www.kaggle.com/narendrageek/understand-the-logistic-regression-from-scratch", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "Wiki"}, {"url": "https://en.wikipedia.org/wiki/Sigmoid_function", "anchor_text": "Sigmoid function"}, {"url": "https://www.linkedin.com/in/narendra-prasath/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----430aedf5edb9---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/python?source=post_page-----430aedf5edb9---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----430aedf5edb9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/twitter?source=post_page-----430aedf5edb9---------------twitter-----------------", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/nlp?source=post_page-----430aedf5edb9---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&user=Narendra+Prasath&userId=8a7fd0a8af09&source=-----430aedf5edb9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&user=Narendra+Prasath&userId=8a7fd0a8af09&source=-----430aedf5edb9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F430aedf5edb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----430aedf5edb9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----430aedf5edb9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----430aedf5edb9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----430aedf5edb9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@narendren.jbk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@narendren.jbk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Narendra Prasath"}, {"url": "https://medium.com/@narendren.jbk/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "25 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8a7fd0a8af09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&user=Narendra+Prasath&userId=8a7fd0a8af09&source=post_page-8a7fd0a8af09--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbef9ea1222c1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstand-logistic-regression-from-scratch-430aedf5edb9&newsletterV3=8a7fd0a8af09&newsletterV3Id=bef9ea1222c1&user=Narendra+Prasath&userId=8a7fd0a8af09&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}