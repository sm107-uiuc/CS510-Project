{"url": "https://towardsdatascience.com/recurrent-neural-networks-explained-ffb9f94c5e09", "time": 1683003965.645626, "path": "towardsdatascience.com/recurrent-neural-networks-explained-ffb9f94c5e09/", "webpage": {"metadata": {"title": "Recurrent Neural Networks for Dummies | Towards Data Science", "h1": "Recurrent Neural Networks (RNNs) for Dummies", "description": "This article gently introduces recurrent units with illustrations, how their memory works and how they are used to handle sequence data such as text."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/why-deep-learning-works-289f17cab01a", "anchor_text": "Why Deep Learning Works", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Concentration_(card_game)", "anchor_text": "Pexeso", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/why-deep-learning-works-289f17cab01a", "anchor_text": "other article", "paragraph_index": 27}, {"url": "https://towardsdatascience.com/sentiment-analysis-a-benchmark-903279cab44a", "anchor_text": "practical experimentation with classifying real-world customer reviews", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/an-introduction-to-recurrent-neural-networks-for-beginners-664d717adbd", "anchor_text": "this excellent article", "paragraph_index": 33}], "all_paragraphs": ["This article gently introduces recurrent units, how their memory works and how they are used to handle sequence data such as text and time series. Have you ever thought of recurrent neural network as a time machine?", "We want a machine learning model to understand sequences, not isolatedsamples. This is particularly important for time series data, where data is intrinsically linked to the notion of time.", "Sequences are also found in natural language, where sentences are sequence of words. A natural language processing model requires contextual information to understand the subject (he) and the direct object (it) in the sentence below. After providing sequential information, the model would understand the subject (Joe\u2019s brother) and the direct object (sweater) in the sentence.", "In our previous article Why Deep Learning Works, we showcased few artificial neural networks for predicting the harvesting quantity that a farmer is likely to produce on a given year. The models would increase predictive power by looking at not only one year (e.g. 2019), but at a sequence of years (e.g. 2017, 2018, 2019) at once.", "As illustrated below, the models would predict the fourth value given three consecutive values. The first vertical column shows the full sequence of values. The next columns show examples what the prediction would be (colored in blue).", "This is called overlapping windowed dataset, since we\u2019re windowing observations to create new. We can imagine building a fully connected neural network with three layers and ReLU activation functions for predicting the next number when given three consecutive numbers.", "There are several problems with this approaches. If we rearrange the input sequence, the network will predict the same result. A fully connected network will not distinguish the order and therefore missing some information.", "Moreover, a fully connected network requires fixed input and output size. If we decide to look at 5 consecutive number to make our prediction, we will have to build another model.", "Another drawback of fully connected networks is, it can\u2019t classify inputs in multiple places. We cannot, for example, predict the next 4 values at once, when the network was designed to predict 3 values.", "The order of inputs matters. This is true for most sequential data.", "In the previous section, we came up with the idea of using context, history and also future for better prediction. How can we make a neural network remember?", "We probably all experienced once being beaten by kids in the game of Pexeso, a game of concentration and memory.", "When playing Pexeso, the goal is, with least as possible moves, to find all pairs of identical cards. Somehow, kids are excellent at remembering things. Why don\u2019t we give this same super-human capability to a neuron in an artificial neural network?", "Basically, we need to update the neuron into a new computational unit that is able to remember what it has seen before. We\u2019ll call this the unit\u2019s state or hidden state or memory.", "How can build a unit that remembers the past? The memory or state can be written to a file but better, we keep it inside the unit, in an array or in a vector. When the unit reads an input, it also reads the content of the memory. Using both information it makes a prediction and more importantly, it updates the memory.", "We can find this principle in the Pexeso game as well. A kid would open a card, would try to recall the location of the pair card, that was previously opened in the past, and would then decide on which card to open next. After opening that card, if it is not a match, the kid would update his memory by recording the position of the pair he has just discovered. In the next round of the game, the kid will repeat this process as represented graphically in the image below.", "In mathematics, the type of dependence of the current value (event or word) on the previous event(s) is called recurrence and is expressed using recurrent equations.", "A recurrent neural network can be thought of as multiple copies of the same node, each passing a message to a successor. One way to represent the above mentioned recursive relationships is to use the diagram below. The little black square indicates that the state used is obtained from a previous timestamp, aka a loop where previous state gets fed into the current state.", "Each unit has three sets of weights: one for the inputs \ud835\udc99(\ud835\udc61), another for the outputs of the previous time step \ud835\udc9a(\ud835\udc61\u20131) and the other for the output of the current time step \ud835\udc9a(\ud835\udc61). Those weights are just like any other weights that we dealt with in normal artificial neural networks and eventually they would be determined by the training process.", "The schematic below shows the inside of a unit that turns 3 numbers into 4 numbers. The input is a 3-numbers vector. The hidden state or memory is a 5-numbers vector. The unit will use an internal network of 5 neurons (A1\u20135) to turn the input into a 5-numbers vector, combine it with the current state and pass the result through an activation function. The resulting 5-number vector will pass through another internal network of 5 neurons (B1\u20135) to produce the new state. It will simultaneously go through another network of 4 neurons (C1\u20134) to produce a 4-numbers output vector.", "By combining the current input with the previous state and passing this through an activation function, the network will not just remember the previous inputs. The state will always be a bigger picture of things that have already been seen by the network.", "In the Pexeso game, instead of recording the (x, y) coordinates of the cards on the table, a kid would vaguely remember which cards are next to one another, which ones are close to the center, which ones are rather on the left part of the board, which ones have more colors, etc.", "Similarly, a unit would not just remember the last 2 or 3 words of a sentence, but it will find how many words and which words, especially which representation of those words, to remember in order to achieve the best prediction.", "This is a very basic simple illustration of how we, humans, also choose to remember something (e.g. our mum anniversary) and to forget the other (our boss anniversary).", "The whole unit in our previous example will have 5+5+4=14 weights and 14 bias to learn during training. How do we find those weights? Will typical gradient descent and back propagation also work here?", "Let\u2019s have some ugly mathematics now. First, we will call V the weights applied to the input, U the weights applied to the state and W the weights applied to the output. Let\u2019s call h the state. We have two activation functions, g_h which serves as the activation for the hidden state and \ud835\udc54_y which is the activation of the output.", "The recurrent unit is perfectly described by the following two equations, where b and b\u2019 represent the bias in the output neurons and state neurons respectively.", "In order to find the weights by applying stochastic gradient descent, as we covered in our other article, we need to calculate the loss function and its derivative with respect to the weights.", "Below you can see how this is done for W, the output weights. The loss for the whole network is the sum of individual losses in recurrent units.", "Similarly we can calculate the derivative of the loss function with respect to state weights U as follows.", "That wasn\u2019t so bad. We now know how to train a recurrent neural network. But there is a problem.", "In the component of the loss function which is highlighted above, you can see a huge product of numbers. The resulting quantity is known to become very large or very small, causing exploding or vanishing gradients.", "Gradients may overshoot the minimum and undo a lot of the work that was already done. Therefore, it\u2019s a common practice to clip the gradients to be in an acceptable interval and to choose an activation function that does not allow too small gradients.", "Practically, RNNs cannot learn long dependencies because of this problem, as we will demonstrate in our practical experimentation with classifying real-world customer reviews. If you want to implement your own RNN from scratch in Python, check this excellent article from Victor Zhou.", "Now, we know how a single recurrent unit works. By chaining several units one after another, we are able to process a sequence of inputs.", "Below, we illustrate how a recurrent neural network would take a sequence of observations and predict if it will rain or not.", "At time t, the network is presented with the information \u2018dog barking\u2019 and its memory is empty. The prediction is therefore with probability 0.3 that it will rain. The network stores a representation of \u2018dog barking\u2019 in its memory for the next step.", "At time t+1, it receives a new information \u2018white shirt\u2019, which decreases the likelihood of raining to 0.1. Now the memory has a representation of both \u2018dog barking\u2019 and \u2018white shirt\u2019.", "Next, at time t+2, the network receives \u2018apple pie\u2019 as information. This does not change its prediction, but the memory is updated by pushing out \u2018white shirt\u2019.", "At time t+3, the input \u2018knee hurts\u2019 increases the prediction to 0.6 and overwrites \u2018apple pie\u2019 in the memory. The final input of the sequence is \u2018get dark\u2019, which pushes the final prediction to 0.9.", "The example intuitively illustrates how the network intentionally keep and forget certain information in its memory when learning from the inputs\u2019 sequence. This is a typical many-to-one scenario.", "Recurrent neural networks are also found in the different flavors depicted below. The many-to-many architecture is typically used to translate a text from one language to another.", "In this article we demonstrated how neural networks unfold to process sequence data. If you are interested in learning how recurrent neural networks can be implemented and benchmark against fully connected neural networks or convolutional neural networks, just read through our next article below. Hands-on practical Python code is included.", "Husband & Dad. Mental health advocate. Top Medium Writer. 20 years in IT. AI Expert @Harvard. Empowering human-centered organizations with high-tech."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fffb9f94c5e09&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://michel-kana.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Michel Kana, Ph.D"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb0b01fe20d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=post_page-cb0b01fe20d2----ffb9f94c5e09---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffb9f94c5e09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----ffb9f94c5e09---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffb9f94c5e09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=-----ffb9f94c5e09---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://sciencevibe.com/2017/04/05/astronomer-light-is-a-cosmic-time-machine-2/", "anchor_text": "source"}, {"url": "https://towardsdatascience.com/why-deep-learning-works-289f17cab01a", "anchor_text": "Why Deep Learning Works"}, {"url": "https://en.wikipedia.org/wiki/Concentration_(card_game)", "anchor_text": "Pexeso"}, {"url": "https://towardsdatascience.com/why-deep-learning-works-289f17cab01a", "anchor_text": "other article"}, {"url": "https://towardsdatascience.com/sentiment-analysis-a-benchmark-903279cab44a", "anchor_text": "practical experimentation with classifying real-world customer reviews"}, {"url": "https://towardsdatascience.com/an-introduction-to-recurrent-neural-networks-for-beginners-664d717adbd", "anchor_text": "this excellent article"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "source"}, {"url": "https://towardsdatascience.com/sentiment-analysis-a-benchmark-903279cab44a", "anchor_text": "Sentiment Analysis: a benchmarkRecurrent neural networks explained. Classifying Customer Reviews using FCNNs, CNNs, RNNs and Embeddings.towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ffb9f94c5e09---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ffb9f94c5e09---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ffb9f94c5e09---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/recurrent-neural-network?source=post_page-----ffb9f94c5e09---------------recurrent_neural_network-----------------", "anchor_text": "Recurrent Neural Network"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----ffb9f94c5e09---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffb9f94c5e09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----ffb9f94c5e09---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffb9f94c5e09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----ffb9f94c5e09---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffb9f94c5e09&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb0b01fe20d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=post_page-cb0b01fe20d2----ffb9f94c5e09---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F69e95067d2a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&newsletterV3=cb0b01fe20d2&newsletterV3Id=69e95067d2a1&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----ffb9f94c5e09---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Written by Michel Kana, Ph.D"}, {"url": "https://michel-kana.medium.com/followers?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "5.4K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb0b01fe20d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=post_page-cb0b01fe20d2----ffb9f94c5e09---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F69e95067d2a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-explained-ffb9f94c5e09&newsletterV3=cb0b01fe20d2&newsletterV3Id=69e95067d2a1&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----ffb9f94c5e09---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Michel Kana, Ph.D"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "BERT for dummies \u2014 Step by Step TutorialDIY Practical guide on Transformer. Hands-on proven PyTorch code for Intent Classification with BERT fine-tuned."}, {"url": "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "\u00b711 min read\u00b7Sep 15, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb90890ffe03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-for-dummies-step-by-step-tutorial-fb90890ffe03&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----fb90890ffe03----0-----------------clap_footer----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03?source=author_recirc-----ffb9f94c5e09----0---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb90890ffe03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbert-for-dummies-step-by-step-tutorial-fb90890ffe03&source=-----ffb9f94c5e09----0-----------------bookmark_preview----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ffb9f94c5e09----1---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----ffb9f94c5e09----1-----------------bookmark_preview----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ffb9f94c5e09----2---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ffb9f94c5e09----2-----------------bookmark_preview----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Michel Kana, Ph.D"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "Generative Adversarial Network (GAN) for Dummies \u2014 A Step By Step TutorialThe ultimate beginner guide for understanding, building and training GANs with bulletproof Python code."}, {"url": "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": "\u00b710 min read\u00b7Apr 20, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffdefff170391&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391&user=Michel+Kana%2C+Ph.D&userId=cb0b01fe20d2&source=-----fdefff170391----3-----------------clap_footer----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=author_recirc-----ffb9f94c5e09----3---------------------9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdefff170391&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391&source=-----ffb9f94c5e09----3-----------------bookmark_preview----9e4f95c1_43b5_4bb4_a444_8a6ad9c7deaa-------", "anchor_text": ""}, {"url": "https://michel-kana.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "See all from Michel Kana, Ph.D"}, {"url": "https://towardsdatascience.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Prateek Gaurav"}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "NLP: Zero To Hero [Part 2: Vanilla RNN, LSTM, GRU & Bi-Directional LSTM]Link to Part 1of this article: NLP: Zero To Hero [Part 1: Introduction, BOW, TF-IDF & Word2Vec] Link to Part 3 of this article: NLP: Zero\u2026"}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b78 min read\u00b7Mar 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F77fd60fc0b44&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40prateekgaurav%2Fnlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44&user=Prateek+Gaurav&userId=966fe9bb6729&source=-----77fd60fc0b44----0-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@prateekgaurav/nlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77fd60fc0b44&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40prateekgaurav%2Fnlp-zero-to-hero-part-2-vanilla-rnn-lstm-gru-bi-directional-lstm-77fd60fc0b44&source=-----ffb9f94c5e09----0-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Building An LSTM Model From Scratch In PythonHow to build a basic LSTM using Basic Python libraries"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b717 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&user=Youssef+Hosni&userId=859af34925b7&source=-----1dedd89de8fe----1-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&source=-----ffb9f94c5e09----1-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@coucoucamille?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Coucou Camille"}, {"url": "https://medium.com/codex?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Time Series Prediction Using LSTM in PythonImplementation of Machine Learning Algorithm for Time Series Data Prediction."}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b76 min read\u00b7Feb 10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&user=Coucou+Camille&userId=d796c2fbb274&source=-----19b1187f580f----0-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/codex/time-series-prediction-using-lstm-in-python-19b1187f580f?source=read_next_recirc-----ffb9f94c5e09----0---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F19b1187f580f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Ftime-series-prediction-using-lstm-in-python-19b1187f580f&source=-----ffb9f94c5e09----0-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@ytang07?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Yujian Tang"}, {"url": "https://medium.com/plain-simple-software?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Plain Simple Software"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Long Short Term Memory in KerasHow to create an LSTM model with Tensorflow Keras"}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b76 min read\u00b7Dec 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fplain-simple-software%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&user=Yujian+Tang&userId=1c4e6640433f&source=-----acdf61c056da----1-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/plain-simple-software/long-short-term-memory-in-keras-acdf61c056da?source=read_next_recirc-----ffb9f94c5e09----1---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Facdf61c056da&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fplain-simple-software%2Flong-short-term-memory-in-keras-acdf61c056da&source=-----ffb9f94c5e09----1-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ffb9f94c5e09----2---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ffb9f94c5e09----2-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Zain Baquar"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "Time Series Forecasting with Deep Learning in PyTorch (LSTM-RNN)An in depth tutorial on forecasting a univariate time series using deep learning with PyTorch"}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": "\u00b712 min read\u00b7Feb 9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1ba339885f0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c&user=Zain+Baquar&userId=d16fc4a70186&source=-----1ba339885f0c----3-----------------clap_footer----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/time-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c?source=read_next_recirc-----ffb9f94c5e09----3---------------------d16b3daa_acc7_44bb_a178_f535c4bb6728-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ba339885f0c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-forecasting-with-deep-learning-in-pytorch-lstm-rnn-1ba339885f0c&source=-----ffb9f94c5e09----3-----------------bookmark_preview----d16b3daa_acc7_44bb_a178_f535c4bb6728-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----ffb9f94c5e09--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}