{"url": "https://towardsdatascience.com/the-cox-proportional-hazards-model-35e60e554d8f", "time": 1683011421.0838442, "path": "towardsdatascience.com/the-cox-proportional-hazards-model-35e60e554d8f/", "webpage": {"metadata": {"title": "The Cox Proportional Hazards Model | by Ravi Charan | Towards Data Science", "h1": "The Cox Proportional Hazards Model", "description": "The Cox Proportional Hazards Model is a semi-parametric survival model allowing one to estimate the effect of covariates on the hazard rate."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/visualizing-time-series-survival-data-36029652a393", "anchor_text": "Kaplan\u2013Meier", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/visualizing-time-series-survival-data-36029652a393", "anchor_text": "estimator", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Dirac_delta_function", "anchor_text": "delta functions", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Weibull_distribution", "anchor_text": "Weibull", "paragraph_index": 17}, {"url": "https://en.wikipedia.org/wiki/Exponential_distribution", "anchor_text": "exponential", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Statistical_model_specification#Detection_of_misspecification", "anchor_text": "misspecification", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/Compound_interest", "anchor_text": "compounding", "paragraph_index": 26}, {"url": "https://en.wikipedia.org/wiki/David_Cox_(statistician)", "anchor_text": "David Cox", "paragraph_index": 30}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Partial_likelihood", "anchor_text": "partial likelihood", "paragraph_index": 35}, {"url": "https://www.statsmodels.org/stable/duration.html", "anchor_text": "statsmodels", "paragraph_index": 38}, {"url": "https://en.wikipedia.org/wiki/Fisher_information", "anchor_text": "Fisher Information Matrix", "paragraph_index": 38}, {"url": "http://Kaplan\u2013Meier", "anchor_text": "Kaplan\u2013Meier", "paragraph_index": 39}, {"url": "https://en.wikipedia.org/wiki/Omitted-variable_bias#:~:text=(Learn%20how%20and%20when%20to%20remove%20this%20template%20message),to%20those%20that%20were%20included.", "anchor_text": "omitted variable bias", "paragraph_index": 50}, {"url": "https://towardsdatascience.com/understanding-logistic-regression-coefficients-7a719ebebd35", "anchor_text": "logistic regression coefficients", "paragraph_index": 51}, {"url": "https://towardsdatascience.com/the-relationship-between-perplexity-and-entropy-in-nlp-f81888775ccc", "anchor_text": "perplexity", "paragraph_index": 51}, {"url": "https://towardsdatascience.com/why-is-the-normal-distribution-so-normal-e644b0a50587", "anchor_text": "central limit theorem", "paragraph_index": 51}, {"url": "https://towardsdatascience.com/expectation-maximization-explained-c82f5ed438e5", "anchor_text": "expectation maximization", "paragraph_index": 51}, {"url": "https://medium.com/@rmcharan/regression-geometry-61fdd5515ab7", "anchor_text": "regression", "paragraph_index": 52}, {"url": "https://towardsdatascience.com/the-singular-value-decomposition-without-algebra-ae10147aab4c", "anchor_text": "singular value decomposition", "paragraph_index": 52}, {"url": "https://towardsdatascience.com/build-intuition-for-the-fourier-transform-b0bd338c6d4f", "anchor_text": "Fourier transform", "paragraph_index": 52}, {"url": "https://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/microeconometrics-methods-and-applications?format=HB&isbn=9780521848053", "anchor_text": "Cameron and Trivendi", "paragraph_index": 53}], "all_paragraphs": ["I previously wrote about how to compute the Kaplan\u2013Meier curve for survival data. As a non-parametric estimator, it does a good job of giving a quick look at the survival curve for a dataset. However, what it doesn\u2019t let you do is model the impact of covariates on survival. In this article, we\u2019ll focus on the Cox Proportional Hazards model, one of the most used models for survival data.", "We\u2019ll go into some depth on how to compute the estimates. This is valuable because we will see that the estimates depend only on the ordering of failures and not their actual times. We will also briefly discuss some tricky issues about causal inference that are special to survival analysis.", "We typically think about survival data in terms of survival curves like the one below.", "On the x-axis, we have the time in days. On the y-axis, we have (an estimator for) the percentage (technically, proportion) of subjects in the population that \u201csurvive\u201d to that time. Survive can be figurative or literal. It could be whether people live to a certain age, whether a machine makes it a certain amount of time without breaking down, or it could be whether someone remains unemployed a certain amount of time after losing their job.", "Crucially, the complication in survivorship analysis is that some subjects do not have their \u201cdeath\u201d observed. They might still be alive, a machine may still be functioning, or someone may still be unemployed at the time the data is collected. Such observations are called \u201cright-censored\u201d and dealing with censorship means that survival analysis requires different statistical tools.", "We denote the survivor function as S, a function of time. Its output is the percentage of subjects surviving at time t. (Again, it is technically a proportion between 0 and 1, but I will use the two words interchangeably). For simplicity we will make the technical assumption that if we wait long enough all subjects will \u201cdie.\u201d", "We will index the subjects with a subscript like i or j. The failure times of the whole population will be indicated with a similar subscript on the time variable t.", "Another subtlety to consider is whether we are treating time as discrete (week by week, say) or continuous. Philosophically speaking, we only ever measure time in discrete increments (to the nearest second, say). Commonly our data will only tell us if someone died in a given year or if a machine failed on a given day. I will go back and forth between the discrete and continuous cases in the interests of keeping the exposition as clear as possible.", "When we are trying to model the effects of covariates (e.g. age, gender, race, machine manufacturer) we will typically be interested in understanding the effect of the covariate on the Hazard Rate. The hazard rate is the instantaneous probability of failure/death/state transition at a given time t, conditional on already having survived that long. We will denote it \u03bb(t). Treating time as discrete:", "Where f is the overall probability density of failing at time t. We can unify the discrete and continuous cases by allowing delta functions in the probability density \u201cfunction\u201d. Thus the result \u03bb = f/S is the same for the continuous case.", "Let\u2019s fix an example. Let\u2019s consider the context of a clinical trial where a drug initially causes a disease to go into remission. We will say the drug \u201cfails\u201d for a subject when the disease begins to progress for a subject. Finally, suppose that subjects\u2019 disease statuses are measured every week. Then if \u03bb(3) = 0.1, that means that there is a 10% chance that, for a given subject, if they are still in remission before week 3, their disease will begin to progress at week 3. The other 90% will remain in remission.", "Next, the overall probability density function f is just the derivative of S with respect to time. (Again, if time is discrete, f is just the sum of some delta functions). This means that", "This means that if we know the Hazard function, we can solve this differential equation for S:", "If time is discrete, the integral of a sum of delta functions just turns into a sum of the hazards at each discrete time.", "Okay, that sums up the notation and basic concepts that we will need. Let\u2019s move on to discussing models.", "As I said earlier, we are typically interested in modeling the Hazard Rate \u03bb.", "In a non-parametric model, we make no assumptions about the functional form of \u03bb. The Kaplan\u2013Meier Curve is the Maximum Likelihood Estimator in this case. The downside is that this makes it hard to model any effects of covariates. It is a little bit like using a scatter plot to understand the effect of a covariate. Not necessarily as helpful as a fully parametric model like a linear regression.", "In a fully parametric model, we make an assumption for the precise functional form of \u03bb. A discussion of the fully parametric models is a full article in its own right, but it\u2019s worth a very brief discussion. The table below shows three of the most common fully-parametric models. Each is generalized by the next, going from 1 to 2 to 3 parameters. The functional form for the hazard function is shown in the middle column. The logarithm of the hazard function is also shown in the last column. All parameters (\u0263, \u03b1, \u03bc) are assumed to be positive except that \u03bc could be 0 in the generalized Weibull distribution (reproducing the Weibull distribution).", "Looking at the logarithm shows us that the exponential model assumes that the hazard function is constant. The Weibull model assumes that is increasing if \u03b1>1, constant if \u03b1=1, and decreasing if \u03b1<1. The Generalized Weibull model starts out the same way as the Weibull model (at the beginning ln S = 0). After that, an extra term \u03bc kicks in.", "The problem with these models is that they make strong assumptions about the data. In certain contexts, there may be reasons to believe these models are a good fit. But with these and several other options available, there is a strong risk of drawing incorrect conclusions due to misspecification of the model.", "This is why the Cox Proportional Hazards, a semi-parametric model is so popular. No functional assumptions are made about the shape of the Hazard Function; instead, functional-form assumptions are made about the effects of the covariates alone.", "The Cox Proportional Hazards Model is usually given in terms of the time t, covariate vector x, and coefficient vector \u03b2 as", "where the \u03bb\u2092 is an arbitrary function of time, the baseline hazard. The dot product of X and \u03b2 is taken in the exponent just like in standard linear regression. Regardless of the values covariates, all subjects share the same baseline hazard \u03bb\u2092. Thereafter, adjustments are made based on the covariates.", "Suppose for the minute that we have fit a Cox Proportional Hazards model to our data, which consisted of", "After the fit, we will get values for \u03b2. For example, suppose for simplicity that there is a single covariate. A value of \u03b2=0.1 means that an increase in the covariate by an amount of 1 leads to an approximately 10% high chance of disease progression at any given time. The exact value is in fact", "For small values of \u03b2, the value of \u03b2 itself is a pretty good approximation of the exact increase in hazard. For larger values of \u03b2, the exact amount must be computed.", "Another way to express \u03b2=0.1 is that, as x increases, the hazard increases at a rate of 10% per increase of x by 1. The larger 10.52% arises from (continuous) compounding, just like with compound interest.", "Also, \u03b2=0 means no effect, and \u03b2 negative means that there is less risk as the covariate increases. Note that, unlike in standard regressions, there is no intercept term. Instead the intercept is absorbed into the baseline hazard \u03bb\u2092, which can also be estimated (see below).", "Finally, assuming we have estimated the baseline hazard function, we can construct the survivor function.", "The baseline function is raised to the power of the exp(x\u02b9\u03b2) factor coming from the covariates. Some care should be taken in interpreting the baseline survivor function, which roughly plays the role of the intercept term in a regular linear regression. If the covariates have been centered (mean 0) then it represents the survivor function for the \u201caverage\u201d subject.", "In the 1970s, David Cox, a British mathematician, proposed a way to estimate \u03b2 without having to estimate the baseline hazard \u03bb\u2092. Again, the baseline hazard can be estimated afterwards. As mentioned earlier, we will see that is is the ordering of the observed failures that matters, not the times themselves.", "Before jumping into the estimation, it is worth discussing ties. Since we are typically only observing data in discrete increments, it is possible that two failures could occur at the same time. For example, two machines might fail in the same week, and the recording is only made on a weekly basis. These ties make the analysis of the situation rather complicated without adding much insight. Consequently, I will derive the estimates in the case of no ties.", "Recall that our data consists of observations of some number failures at discrete time. Let R(t) denote the population \u201cat risk\u201d at time t. If a subject in our study has failed (disease progressed, for example) before time t, they are not \u201cat risk.\u201d Also, if a subject in our study has had their observation censored at a time before time t, they are also not \u201cat risk.\u201d", "In the usual fashion, we want to construct a likelihood function (what is the probability we would have observed the data we did, given the covariates and coefficients) and then optimize that to get a maximum-likelihood estimator.", "For each discrete time when we observed a failure of subject j, the probability of that occurring, given that a failure occurred, is below. The sum is taken over all subjects at risk at time j.", "Notice that the baseline hazard \u03bb\u2092 has dropped out! Very convenient. For this reason, the likelihood we construct is only a partial likelihood. Notice also that the times don\u2019t appear at all. The term for subject j depends only on which subjects are still alive at time j, which in turn depends only on the order in which the subjects are censored or observed to fail.", "The partial likelihood is of course just the product of these terms, one for each failure we observe (no terms for censored observations).", "The log partial likelihood is then", "The fit is done with standard numerical methods, for example in the python package statsmodels and the variance-covariance matrix for the estimates is given by the (inverse of the) Fisher Information Matrix. Nothing exciting here.", "Now that we have estimated the coefficients, we can estimate the survivor function. This ends up being very similar to estimating a Kaplan\u2013Meier curve.", "We postulate terms \u03b1 indexed by i. At time i, the baseline survivor curve should decrease by a fraction \u03b1 representing the proportion of subjects at risk that fail at time i. In other words", "To compute the maximum likelihood estimator for \u03b1, we consider the likelihood contribution from subject i which fails at time i and separately the contribution from those that are censored at time i.", "For a subject that fails at time i, the probability is given by the probability they are alive at time i less the probability they are alive at the next time i+1. (We temporarily assume the times are ordered).", "If instead they are censored at time i, the contribution is just the probability they are alive at the time after i, i.e. that they haven\u2019t died yet. This is just", "There is an extra term from the subjects that were observed (i.e. observed to fail instead of censored). The log likelihood becomes", "I have been a bit sloppy about keeping track of endpoints (i vs. i+1), but it will all work out.", "There are only \u03b1 terms for subjects we observed to fail. Differentiating with respect to \u03b1-j and assuming no ties, we get a contribution from the sum on the left only for subjects alive at time j, and a single contribution from the term on the right.", "Setting this equal to 0 means that we can obtain the maximum likelihood estimates for \u03b1 using our estimates for \u03b2 as the solution to the several equations, one for each subject that was observed to fail:", "There\u2019s plenty more to say about Cox Proportional Hazards models, but I will try to keep things brief and just mention a few things.", "For example, one may want to consider time-varying regressors, and this is possible.", "The other crucial thing to keep in mind is omitted variable bias. In standard linear regression, omitted variables uncorrelated with the regressors aren\u2019t a big problem. This is not true in survival analysis. Suppose we have two equally sized and sampled sub-populations in our data each with a constant hazard rate, one is 0.1 and the other is 0.5. Initially, we will see a high hazard rate (the average, just 0.3). As time goes on, the population with a high hazard rate will leave the population and we will observe a hazard rate that declines towards 0.1. If we omitted the variable representing these two populations, our baseline hazard rate will be all messed up.", "I aim to write (relatively) accessible explanations of data science concepts without shying away from the sometimes complicated mathematics involved. If you liked this, you I have similarly styled explanations of logistic regression coefficients, perplexity, the central limit theorem, or expectation maximization.", "If you didn\u2019t like this, consider more geometric explanations of regression, the singular value decomposition, or the Fourier transform.", "For a more detailed discussion, see Cameron and Trivendi", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist, Mathematician. Formerly @MIT, @McKinsey, currently teaching computers to read"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F35e60e554d8f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rmcharan?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rmcharan?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Ravi Charan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F393ce2bbf82c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&user=Ravi+Charan&userId=393ce2bbf82c&source=post_page-393ce2bbf82c----35e60e554d8f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@shlomo99?utm_source=medium&utm_medium=referral", "anchor_text": "Shlomo Shalev"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/visualizing-time-series-survival-data-36029652a393", "anchor_text": "Kaplan\u2013Meier"}, {"url": "https://towardsdatascience.com/visualizing-time-series-survival-data-36029652a393", "anchor_text": "estimator"}, {"url": "https://en.wikipedia.org/wiki/Dirac_delta_function", "anchor_text": "delta functions"}, {"url": "https://en.wikipedia.org/wiki/Weibull_distribution", "anchor_text": "Weibull"}, {"url": "https://en.wikipedia.org/wiki/Exponential_distribution", "anchor_text": "exponential"}, {"url": "https://en.wikipedia.org/wiki/Statistical_model_specification#Detection_of_misspecification", "anchor_text": "misspecification"}, {"url": "https://en.wikipedia.org/wiki/Compound_interest", "anchor_text": "compounding"}, {"url": "https://en.wikipedia.org/wiki/David_Cox_(statistician)", "anchor_text": "David Cox"}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Partial_likelihood", "anchor_text": "partial likelihood"}, {"url": "https://www.statsmodels.org/stable/duration.html", "anchor_text": "statsmodels"}, {"url": "https://en.wikipedia.org/wiki/Fisher_information", "anchor_text": "Fisher Information Matrix"}, {"url": "http://Kaplan\u2013Meier", "anchor_text": "Kaplan\u2013Meier"}, {"url": "https://en.wikipedia.org/wiki/Omitted-variable_bias#:~:text=(Learn%20how%20and%20when%20to%20remove%20this%20template%20message),to%20those%20that%20were%20included.", "anchor_text": "omitted variable bias"}, {"url": "https://towardsdatascience.com/understanding-logistic-regression-coefficients-7a719ebebd35", "anchor_text": "logistic regression coefficients"}, {"url": "https://towardsdatascience.com/the-relationship-between-perplexity-and-entropy-in-nlp-f81888775ccc", "anchor_text": "perplexity"}, {"url": "https://towardsdatascience.com/why-is-the-normal-distribution-so-normal-e644b0a50587", "anchor_text": "central limit theorem"}, {"url": "https://towardsdatascience.com/expectation-maximization-explained-c82f5ed438e5", "anchor_text": "expectation maximization"}, {"url": "https://medium.com/@rmcharan/regression-geometry-61fdd5515ab7", "anchor_text": "regression"}, {"url": "https://towardsdatascience.com/the-singular-value-decomposition-without-algebra-ae10147aab4c", "anchor_text": "singular value decomposition"}, {"url": "https://towardsdatascience.com/build-intuition-for-the-fourier-transform-b0bd338c6d4f", "anchor_text": "Fourier transform"}, {"url": "https://www.cambridge.org/us/academic/subjects/economics/econometrics-statistics-and-mathematical-economics/microeconometrics-methods-and-applications?format=HB&isbn=9780521848053", "anchor_text": "Cameron and Trivendi"}, {"url": "https://medium.com/tag/data-science?source=post_page-----35e60e554d8f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----35e60e554d8f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----35e60e554d8f---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----35e60e554d8f---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----35e60e554d8f---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&user=Ravi+Charan&userId=393ce2bbf82c&source=-----35e60e554d8f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&user=Ravi+Charan&userId=393ce2bbf82c&source=-----35e60e554d8f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F35e60e554d8f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----35e60e554d8f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----35e60e554d8f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----35e60e554d8f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----35e60e554d8f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rmcharan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rmcharan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ravi Charan"}, {"url": "https://medium.com/@rmcharan/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "599 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F393ce2bbf82c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&user=Ravi+Charan&userId=393ce2bbf82c&source=post_page-393ce2bbf82c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6bca6dd641ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-cox-proportional-hazards-model-35e60e554d8f&newsletterV3=393ce2bbf82c&newsletterV3Id=6bca6dd641ca&user=Ravi+Charan&userId=393ce2bbf82c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}