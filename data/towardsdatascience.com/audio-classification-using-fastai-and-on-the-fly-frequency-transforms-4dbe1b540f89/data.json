{"url": "https://towardsdatascience.com/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89", "time": 1682994026.77562, "path": "towardsdatascience.com/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89/", "webpage": {"metadata": {"title": "Audio Classification using FastAI and On-the-Fly Frequency Transforms | by John Hartquist | Towards Data Science", "h1": "Audio Classification using FastAI and On-the-Fly Frequency Transforms", "description": "While deep learning models are able to help tackle many different types of problems, image classification is the most prevalent example for courses and frameworks, often acting as the \u201chello, world\u201d\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/fastai/fastai", "anchor_text": "FastAI", "paragraph_index": 0}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch", "paragraph_index": 0}, {"url": "https://docs.fast.ai/", "anchor_text": "only four lines of code", "paragraph_index": 0}, {"url": "https://docs.fast.ai/data_block.html", "anchor_text": "data_block", "paragraph_index": 0}, {"url": "https://www.kaggle.com/c/freesound-audio-tagging", "anchor_text": "Freesound General-Purpose Audio Tagging Kaggle competition", "paragraph_index": 0}, {"url": "https://github.com/sevenfx/fastai_audio", "anchor_text": "this repository", "paragraph_index": 1}, {"url": "https://librosa.github.io/", "anchor_text": "librosa", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Fast_Fourier_transform", "anchor_text": "Fast Fourier Transform", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Mel_scale", "anchor_text": "mel scale", "paragraph_index": 7}, {"url": "https://cloud.google.com/", "anchor_text": "GCP instance", "paragraph_index": 9}, {"url": "https://magenta.tensorflow.org/datasets/nsynth", "anchor_text": "NSynth Dataset", "paragraph_index": 10}, {"url": "https://magenta.tensorflow.org/", "anchor_text": "Magenta", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "anchor_text": "Convolutional Neural Network", "paragraph_index": 12}, {"url": "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py", "anchor_text": "resnet18", "paragraph_index": 12}, {"url": "https://docs.fast.ai/", "anchor_text": "great new fastai documentation", "paragraph_index": 17}, {"url": "https://forums.fast.ai/t/black-and-white-images-on-vgg16/2479/2", "anchor_text": "thanks to David Gutman on the fastai forums", "paragraph_index": 19}, {"url": "https://github.com/sevenfx/fastai_audio", "anchor_text": "https://github.com/jhartquist/fastai_audio", "paragraph_index": 23}, {"url": "https://johnhartquist.com", "anchor_text": "https://johnhartquist.com", "paragraph_index": 25}], "all_paragraphs": ["While deep learning models are able to help tackle many different types of problems, image classification is the most prevalent example for courses and frameworks, often acting as the \u201chello, world\u201d introduction. FastAI is a high-level library built on top of PyTorch that makes it extremely easy to get started classifying images, with an example showing how train an accurate model in only four lines of code. With the new v1 release of the library, an API called data_block allows users a flexible way to simplify the data loading process. After competing in the Freesound General-Purpose Audio Tagging Kaggle competition over the summer, I decided to repurpose some of my code to take advantage of fastai\u2019s benefits for audio classification as well. This article will give a quick introduction to working with audio files in Python, give some background around creating spectrogram images, and then show how to leverage pretrained image models without actually having to generate images beforehand.", "All the code used to generate the content of this post will be available in this repository, complete with example notebooks.", "At first, it may seem a little strange to classify audio files as images. Images are 2-dimensional after all (with a possible 3rd dimension for RGBA channels), and audio files have a single time dimension (with a possible 2nd dimension for channels, for example stereo vs mono). In this post, we\u2019ll only be looking at audio files with a single channel. Every audio file also has an associated sample rate, which is the number of samples per second of audio. If a 3 second audio clip has a sample rate of 44,100 Hz, that means it is made up of 3*44,100 = 132,300 consecutive numbers representing changes in air pressure. One of the best libraries for manipulating audio in Python is called librosa.", "While this representation does give us a sense of how loud or quiet a clip is at any point in time, it gives us very little information about which frequencies are present. A very common solution to this problem is to take small overlapping chunks of the signal, and run them through a Fast Fourier Transform (FFT) to convert them from the time domain to the frequency domain. After running each section through an FFT, we can convert the result to polar coordinates, giving us magnitudes and phases of different frequencies. While the phases information can be useful in some contexts, we mostly use the magnitudes, and convert them to decibel units because our ears percieve sound on a logarithmic scale.", "Taking an FFT of size 1024 will result in a frequency spectrum with 1024 frequency bins. The second half of the spectrum is redundant however, so in practice we only use the first (N/2)+1 bins, which is 513 in this case.", "To generate information about the whole file, we can take an FFT of a 1024 sample window, and slide it by 512 samples (hop length) so that the windows overlap with each other. For this three second file, that will give us 259 frequency spectrums, which we can then view as a 2-dimensional image. This is called a short-time Fourier Transform (STFT), and it allows us to see how different frequencies change over time.", "In this example, we can see that almost all of the interesting frequency data is below 12,500 Hz. In addition to there being a lot of wasted bins, this does not accurately display how humans perceive frequencies. Along with loudness, we also hear frequencies on a logarithmic scale. We would hear the same \u201cdistance\u201d of frequencies from 50 Hz to 100 Hz as we would between 400 Hz and 800 Hz.", "These are some of the reasons why many people use melspectrograms which transform the frequency bins into the mel scale. Librosa allows us to easily convert a regular spectrogram into a melspectrogram, and lets us define how many \u201cbins\u201d we want to have. We can also specify a minimum and maximum frequency that we want our bins to be divided into.", "In each of these melspectrograms, I used 64 frequency bins (n_mels). The only difference is that on the right, I specified that I only care about frequencies between 20Hz and 8000Hz. This greatly reduces the size of each transform from the original 513 bins per time step.", "While it is possible to classify raw audio waveform data, it is very popular to use image classifiers to classify melspectrograms, and it works pretty well. In order to do this we have to convert our whole dataset to image files using similar code as above. This took me about 10 minutes of processing time using all the CPUs on my GCP instance. I used the following parameters for generating the melspectrogram images:", "For the rest of this post, I\u2019ve used the NSynth Dataset by the Magenta team at Google. It is an interesting dataset composed of 305,979 musical notes, each 4 seconds long. I trimmed the dataset down to only the acoustically generated notes to make things a little more manageable. The goal was to classify which instrument family each note was generated with out of 10 possible instrument families.", "Using fastai\u2019s new data_block API, it becomes very easy to build a DataBunch object with all the spectrogram image data along with their labels \u2014 in this example I grabbed all of the labels using a regex over the filenames.", "Once I had my data loaded, I instantiated a pretrained Convolutional Neural Network (CNN) called resnet18, and fine-tuned it on the spectrograms.", "In only 2 minutes and 14 seconds I was left with a model that scored 84% accuracy on the validation set (a completely separate set of instruments from the training set). While this model is definitely overfitting, this is without data augmentation or regularization of any kind, a pretty good start!", "By utilizing fastai\u2019s ClassificationInterpretation class, we can take a look at where the mistakes are coming from.", "It looks like mallets are getting confused with guitars, and reeds are being confused with brass instruments the most. Using this information, we could look more closely at the spectrograms of those instruments, and try to decide if there are better parameters we could use to differentiate between them.", "If classifying audio from images works so well, you might ask why it would be beneficial to generate spectrograms during training (as opposed to before). There are a few good reasons for this:", "Over the past few days I\u2019ve been experimenting with an idea to create a new fastai module for audio files. After reading the great new fastai documentation, I was able to write some basic classes to load raw audio files and generate the spectrograms as batches on the GPU using PyTorch. I also wrote a custom create_cnn function that would take pretrained image classifiers, and modify them to work on a single channel (spectrogram) instead of the 3 channels they were originally trained for. To my surprise, the code runs almost as fast as the image classification equivalent, with no extra step of generating actual images. Setting up my data now looks like this:", "The fastai library supports a nice way to preview batches as well:", "Fine-tuning on a pretrained model is exactly the same as before, only this time the first convolutional layer is being modified to accept a single input channel (thanks to David Gutman on the fastai forums).", "This time the training takes only 30 seconds longer, and has only slightly lower accuracy after 3 epochs with 80% on the validation set! Generating images on the CPU before took over 10 minutes when doing it one at time. This opens up the possibility for much more rapid experimentation with tuning spectrogram parameters and as well as computing spectrograms from augmented audio files.", "Now that its possible to generate different spectral representations on the fly, I\u2019m very interested in trying to get data augmentation working for raw audio files. From pitch shifting, to time stretching (methods available in librosa), to simply taking random segments of audio clips, there is a lot to experiment with.", "I am also interested in how much better the results would be the pretrained models used here had actually been trained on audio files and not image files.", "Thanks for taking the time to read my first blog post! Please let me know if you have any corrections or comments. Once again, you can view all the code and full notebooks over at https://github.com/jhartquist/fastai_audio.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "https://johnhartquist.com \u2014 Seattle, WA based software engineer focusing on ML/DL and audio programming."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4dbe1b540f89&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@johnhartquist?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johnhartquist?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "John Hartquist"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F598c5512bf7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&user=John+Hartquist&userId=598c5512bf7f&source=post_page-598c5512bf7f----4dbe1b540f89---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/fastai/fastai", "anchor_text": "FastAI"}, {"url": "https://pytorch.org/", "anchor_text": "PyTorch"}, {"url": "https://docs.fast.ai/", "anchor_text": "only four lines of code"}, {"url": "https://docs.fast.ai/data_block.html", "anchor_text": "data_block"}, {"url": "https://www.kaggle.com/c/freesound-audio-tagging", "anchor_text": "Freesound General-Purpose Audio Tagging Kaggle competition"}, {"url": "https://github.com/sevenfx/fastai_audio", "anchor_text": "this repository"}, {"url": "https://librosa.github.io/", "anchor_text": "librosa"}, {"url": "https://en.wikipedia.org/wiki/Fast_Fourier_transform", "anchor_text": "Fast Fourier Transform"}, {"url": "https://en.wikipedia.org/wiki/Mel_scale", "anchor_text": "mel scale"}, {"url": "https://cloud.google.com/", "anchor_text": "GCP instance"}, {"url": "https://magenta.tensorflow.org/datasets/nsynth", "anchor_text": "NSynth Dataset"}, {"url": "https://magenta.tensorflow.org/", "anchor_text": "Magenta"}, {"url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "anchor_text": "Convolutional Neural Network"}, {"url": "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py", "anchor_text": "resnet18"}, {"url": "https://librosa.github.io/librosa/", "anchor_text": "librosa"}, {"url": "https://pytorch.org/docs/master/torch.html#torch.stft", "anchor_text": "PyTorch\u2019s"}, {"url": "https://pytorch.org/docs/master/torch.html#torch.stft", "anchor_text": "stft"}, {"url": "https://docs.fast.ai/", "anchor_text": "great new fastai documentation"}, {"url": "https://forums.fast.ai/t/black-and-white-images-on-vgg16/2479/2", "anchor_text": "thanks to David Gutman on the fastai forums"}, {"url": "https://github.com/sevenfx/fastai_audio", "anchor_text": "https://github.com/jhartquist/fastai_audio"}, {"url": "https://docs.fast.ai/", "anchor_text": "FastAI docs"}, {"url": "https://pytorch.org/docs/master/", "anchor_text": "PyTorch v1.0 docs"}, {"url": "http://pytorch.org/audio/", "anchor_text": "torchaudio"}, {"url": "https://jackschaedler.github.io/circles-sines-signals/dft_introduction.html", "anchor_text": "https://jackschaedler.github.io/circles-sines-signals/dft_introduction.html"}, {"url": "http://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html", "anchor_text": "Speech Processing for Machine Learning: Filter banks, Mel-Frequency Cepstral Coefficients (MFCCs) and What\u2019s In Between"}, {"url": "https://www.coursera.org/learn/audio-signal-processing", "anchor_text": "Audio Signal Processing for Musical Applications"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4dbe1b540f89---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----4dbe1b540f89---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/image-classification?source=post_page-----4dbe1b540f89---------------image_classification-----------------", "anchor_text": "Image Classification"}, {"url": "https://medium.com/tag/audio-classification?source=post_page-----4dbe1b540f89---------------audio_classification-----------------", "anchor_text": "Audio Classification"}, {"url": "https://medium.com/tag/fastai?source=post_page-----4dbe1b540f89---------------fastai-----------------", "anchor_text": "Fastai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&user=John+Hartquist&userId=598c5512bf7f&source=-----4dbe1b540f89---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&user=John+Hartquist&userId=598c5512bf7f&source=-----4dbe1b540f89---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4dbe1b540f89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4dbe1b540f89---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4dbe1b540f89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johnhartquist?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@johnhartquist?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "John Hartquist"}, {"url": "https://medium.com/@johnhartquist/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "253 Followers"}, {"url": "https://johnhartquist.com", "anchor_text": "https://johnhartquist.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F598c5512bf7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&user=John+Hartquist&userId=598c5512bf7f&source=post_page-598c5512bf7f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F598c5512bf7f%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faudio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89&user=John+Hartquist&userId=598c5512bf7f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}