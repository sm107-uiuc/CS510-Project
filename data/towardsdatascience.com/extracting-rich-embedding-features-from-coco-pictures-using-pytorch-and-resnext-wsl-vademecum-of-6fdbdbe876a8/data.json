{"url": "https://towardsdatascience.com/extracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8", "time": 1683017213.8513181, "path": "towardsdatascience.com/extracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8/", "webpage": {"metadata": {"title": "Extracting rich embedding features from COCO pictures using PyTorch and ResNeXt-WSL | Towards Data Science", "h1": "Extracting rich embedding features from COCO pictures using PyTorch and ResNeXt-WSL", "description": "In this tutorial, I will show you how to leverage a powerful pre-trained convolution neural network to extract embedding vectors that can accurately describe any kind of picture in an abstract latent\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1805.00932https://arxiv.org/pdf/1611.05431.pdf", "anchor_text": "ResNeXt", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "ResNet", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac", "anchor_text": "beat the benchmark of ILSVRC classification task with a 15% improvement", "paragraph_index": 1}, {"url": "https://paperswithcode.com/sota/image-classification-on-imagenet", "anchor_text": "top leaderboard of the ImageNet task", "paragraph_index": 1}, {"url": "https://medium.com/syncedreview/facebook-model-pretrained-on-billions-of-instagram-hashtags-achieves-sota-results-on-top-1-imagenet-ae8113bb3145", "anchor_text": "source", "paragraph_index": 3}, {"url": "https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/", "anchor_text": "PyTorch hub", "paragraph_index": 6}, {"url": "https://cocodataset.org/", "anchor_text": "COCO", "paragraph_index": 7}, {"url": "https://cocodataset.org/#detection-2017", "anchor_text": "Detection 2017", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29", "anchor_text": "Dimensionality Reduction for Data Visualization: PCA vs TSNE vs UMAP vs LDA", "paragraph_index": 27}, {"url": "https://github.com/gm-spacagna/docem", "anchor_text": "https://github.com/gm-spacagna/docem", "paragraph_index": 35}, {"url": "https://datasciencevademecum.com/2020/05/21/embedding-billions-of-text-documents-using-tensorflow-universal-sentence-encoder-on-top-of-spark-emr/", "anchor_text": "Embedding billions of text documents using Tensorflow Universal Sentence Encoder and Spark EMR", "paragraph_index": 36}, {"url": "https://datasciencevademecum.com/2020/12/02/extracting-rich-embedding-features-from-pictures-using-pytorch-and-resnext-wsl/", "anchor_text": "https://datasciencevademecum.com", "paragraph_index": 37}], "all_paragraphs": ["In this tutorial, I will show you how to leverage a powerful pre-trained convolution neural network to extract embedding vectors that can accurately describe any kind of picture in an abstract latent feature space.I will show some examples of using ResNext-WSL on the COCO dataset using the library PyTorch and other conventional tools from the PyData stack.", "ResNeXt is the evolution of the well famous ResNet model that adds an additional dimension on top of it called the \u201ccardinality\u201d dimension. Through this improvement, the authors managed to beat the benchmark of ILSVRC classification task with a 15% improvement. Although better models were developed in the last couple of years, it still stands on the top leaderboard of the ImageNet task, with 85.4% top-1 accuracy.", "The weakly supervised learning (WSL) version was developed by the Facebook AI Research (FAIR) group, but it was trained on 3.5 billion public Instagram pictures in order to predict around 8000 hashtags sourced by the users. This novel approach made ResNeXt-WSL my favorite choice among many other publicly available. I believe that a model trained on a broader variety of pictures can encapsulate many different topics of real-world scenarios while other pre-trained models were mostly optimized solely for their benchmark task.", "Below are some facts about the training of this massive model (source):", "The model was trained with different capacities in order to reduce its size and inference time.", "After training the model on the Instagram hashtag classification task, the last layer was replaced with the ImageNet classes and fine-tuned on that task. Clearly training those models is not something every organization can afford.", "Luckily for us, a simplified version was released in the PyTorch hub, trained on \u201conly\u201d 940 million public images and 1.5k hashtags. For this tutorial, we choose the smallest version of ResNext-WSL (32x8d) since it is still accurate enough on the public benchmarks but it is less memory and computationally expensive.", "Common Objects in COntext ( COCO) is a large-scale object detection, segmentation, and captioning dataset, widely used as a benchmark for many machine learning tasks.", "For this tutorial, we would focus on the Detection 2017 dataset (validation fold) consisting of 5000 annotated pictures. The dataset satisfies a few desired properties:", "The 5000 pictures are annotated with 80 categories grouped in 12 supercategories:", "And below are a sample of random pictures with their annotations:", "As we can see the pictures in the COCO dataset do represent different real-world scenarios, even though they are skewed with a lot of pictures containing people.", "The ResNeXt traditional 32x4d architecture is composed by stacking multiple convolutional blocks each composed by multiple layers with 32 groups and a bottleneck width equal to 4. That is the first convolution layer with 64 filters is parallelized in 32 independent convolutions with only 4 filters each.", "The smallest WSL model in the PyTorch hub uses a 32x8d architecture (bottleneck width = 8) instead. Regardless of those architecture details, what matters for us is the last average pool layer that would concatenate all of those filters into a single dimensional array of size 2048.", "The concatenated features are then supposed to be fed to the output softmax layer predicting the 1000 classes of ImageNet. Since we are not interested in the class predictions, we will drop the softmax layer and use the array of the average pool as the embedding features for our pictures.", "The embedding-only model will have the following size:", "The first thing to do in order to be usable is to pre-process the input pictures in the format the model would expect. The preprocessing consists of:", "I have used a Google Colab environment with GPU runtime to perform the loading, preprocessing, and inference on the 5000 pictures in around 10 minutes.", "Let\u2019s dive into the feature space and extract some insights.For example, if we consider a sample picture with a dog:", "It would be embedded with the following values:", "We can notice that by the design of the neural network we only get non-negative values without any upper bound.", "We can derive a couple of properties:", "The measure the first point we can count what percentage of the dimensions are used by each picture (value > 0.01):", "Only 40% of dimensions are used in average by each picture, where we can assume the higher the value the more the topics embedded in the picture.", "In order to confirm the exponential distribution hypothesis we can plot the mean of each dimension against its standard deviation across the dataset:", "The proportionality between mean and standard deviation gives us a hint that the dimensions tend to follow an exponential-like distribution on our dataset.", "We can apply a few dimensionality reduction techniques to reduce the embedding space into 3 dimensions and use the supercategory to highlight the pictures that belong to the same taxonomy.", "We will focus on 3 unsupervised techniques: PCA, t-SNE, and UMAP. For a more exhaustive comparison of their differences, I recommend the following reading: Dimensionality Reduction for Data Visualization: PCA vs TSNE vs UMAP vs LDA.", "To make the exploration more fun I have deployed a TensorBoard using a sample of pictures in a sprite image:", "And the TSNE projection looked like this:", "The interactive projector of the TensorBoard is a powerful tool for exploring the embedding space and spot correlations and interesting manifolds of points.", "What can we actually do now with this embedding space? A relevant application would be to find similar pictures. Thus, I have selected a few random pictures and plotted the 15 closest ones based on the cosine similarity in the 2048-dimensional embedding space.", "Not just the embedding space is able to accurately group pictures that do are very similar in terms of objects and context, but it can also correctly discriminate the entropy on each kind of picture based on the cosine distance. For instance, the neighborhoods of \u201ctennis players\u201d and \u201cpeople skiing\u201d have a much lower distance from the query picture compared to the other more entropic neighborhoods.", "In this tutorial, we have seen how easily, and without having to train any model, we can leverage the state-of-the-art to extract rich embedding features from pictures of different natures. We have proven the ability of the embedding space to capture a lot of fine details including both the objects and the surrounding context. The most salient part was showing that the embedding features can accurately find similar pictures. The measure of similarity and the latent manifold structures can enable a lot of downstream applications.", "In the next articles, we will see how to discover and define those latent topics represented by the manifolds in the embedding space, to learn how to cluster those pictures, and to learn advanced averaging techniques for document embedding. Stay tuned!", "You can find the code and the notebooks at https://github.com/gm-spacagna/docem.", "If you are interested in extracting embedding features from text data, you can check out this other article: Embedding billions of text documents using Tensorflow Universal Sentence Encoder and Spark EMR.", "Originally published at https://datasciencevademecum.com on December 2, 2020.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Director of Artificial Intelligence at Brainly"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6fdbdbe876a8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gm-spacagna.medium.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": ""}, {"url": "https://gm-spacagna.medium.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Gianmario Spacagna"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb66d34d8e1ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&user=Gianmario+Spacagna&userId=b66d34d8e1ba&source=post_page-b66d34d8e1ba----6fdbdbe876a8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@cosmictimetraveler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Cosmic Timetraveler"}, {"url": "https://unsplash.com/s/photos/painted-ladies?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/abs/1805.00932https://arxiv.org/pdf/1611.05431.pdf", "anchor_text": "ResNeXt"}, {"url": "https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8", "anchor_text": "ResNet"}, {"url": "https://towardsdatascience.com/review-resnext-1st-runner-up-of-ilsvrc-2016-image-classification-15d7f17b42ac", "anchor_text": "beat the benchmark of ILSVRC classification task with a 15% improvement"}, {"url": "https://paperswithcode.com/sota/image-classification-on-imagenet", "anchor_text": "top leaderboard of the ImageNet task"}, {"url": "https://paperswithcode.com/method/resnext-block#", "anchor_text": "paperswithcode"}, {"url": "https://medium.com/syncedreview/facebook-model-pretrained-on-billions-of-instagram-hashtags-achieves-sota-results-on-top-1-imagenet-ae8113bb3145", "anchor_text": "source"}, {"url": "https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/", "anchor_text": "PyTorch Hub"}, {"url": "https://pytorch.org/hub/facebookresearch_WSL-Images_resnext/", "anchor_text": "PyTorch hub"}, {"url": "https://cocodataset.org/", "anchor_text": "COCO"}, {"url": "https://cocodataset.org/#home", "anchor_text": "COCO website"}, {"url": "https://cocodataset.org/#detection-2017", "anchor_text": "Detection 2017"}, {"url": "https://pytorch.org/hub/pytorch_vision_resnext/", "anchor_text": "PyTorch Hub"}, {"url": "https://github.com/pytorch/hub/raw/master/images/dog.jpg", "anchor_text": "pytorch github repository"}, {"url": "https://towardsdatascience.com/dimensionality-reduction-for-data-visualization-pca-vs-tsne-vs-umap-be4aa7b1cb29", "anchor_text": "Dimensionality Reduction for Data Visualization: PCA vs TSNE vs UMAP vs LDA"}, {"url": "https://github.com/gm-spacagna/docem", "anchor_text": "https://github.com/gm-spacagna/docem"}, {"url": "https://datasciencevademecum.com/2020/05/21/embedding-billions-of-text-documents-using-tensorflow-universal-sentence-encoder-on-top-of-spark-emr/", "anchor_text": "Embedding billions of text documents using Tensorflow Universal Sentence Encoder and Spark EMR"}, {"url": "https://datasciencevademecum.com/2020/12/02/extracting-rich-embedding-features-from-pictures-using-pytorch-and-resnext-wsl/", "anchor_text": "https://datasciencevademecum.com"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----6fdbdbe876a8---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----6fdbdbe876a8---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/embeddings?source=post_page-----6fdbdbe876a8---------------embeddings-----------------", "anchor_text": "Embeddings"}, {"url": "https://medium.com/tag/resnext?source=post_page-----6fdbdbe876a8---------------resnext-----------------", "anchor_text": "Resnext"}, {"url": "https://medium.com/tag/k-neighbors?source=post_page-----6fdbdbe876a8---------------k_neighbors-----------------", "anchor_text": "K Neighbors"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&user=Gianmario+Spacagna&userId=b66d34d8e1ba&source=-----6fdbdbe876a8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&user=Gianmario+Spacagna&userId=b66d34d8e1ba&source=-----6fdbdbe876a8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6fdbdbe876a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6fdbdbe876a8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6fdbdbe876a8--------------------------------", "anchor_text": ""}, {"url": "https://gm-spacagna.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gm-spacagna.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gianmario Spacagna"}, {"url": "https://gm-spacagna.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "134 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb66d34d8e1ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&user=Gianmario+Spacagna&userId=b66d34d8e1ba&source=post_page-b66d34d8e1ba--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd208a609588c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-rich-embedding-features-from-coco-pictures-using-pytorch-and-resnext-wsl-vademecum-of-6fdbdbe876a8&newsletterV3=b66d34d8e1ba&newsletterV3Id=d208a609588c&user=Gianmario+Spacagna&userId=b66d34d8e1ba&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}