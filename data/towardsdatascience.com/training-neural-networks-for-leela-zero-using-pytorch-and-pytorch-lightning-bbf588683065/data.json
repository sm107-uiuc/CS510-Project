{"url": "https://towardsdatascience.com/training-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065", "time": 1683005105.7711308, "path": "towardsdatascience.com/training-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065/", "webpage": {"metadata": {"title": "Training Neural Networks for Leela Zero With PyTorch | by Peter Yu | Towards Data Science", "h1": "Training Neural Networks for Leela Zero With PyTorch", "description": "Recently, I have been looking into ways to speed up my research and manage my experiments, especially around writing training pipelines and managing experiment configurations, and I discovered these\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "PyTorch Lightning", "paragraph_index": 0}, {"url": "https://hydra.cc/", "anchor_text": "Hydra", "paragraph_index": 0}, {"url": "https://github.com/leela-zero/leela-zero", "anchor_text": "Leela Zero", "paragraph_index": 1}, {"url": "https://medium.com/@peterkeunwoo/beating-my-brother-in-chess-cb17739ffe2", "anchor_text": "a smaller version of AlphaGo for chess", "paragraph_index": 1}, {"url": "https://github.com/yukw777/leela-zero-pytorch", "anchor_text": "https://github.com/yukw777/leela-zero-pytorch", "paragraph_index": 2}, {"url": "https://github.com/leela-zero/leela-zero/tree/next/training/tf", "anchor_text": "Tensorflow training pipeline", "paragraph_index": 3}, {"url": "https://deepmind.com/blog/article/alphago-zero-starting-scratch", "anchor_text": "AlphaGo Zero paper", "paragraph_index": 4}, {"url": "https://github.com/mattheww/gomill", "anchor_text": "GoMill", "paragraph_index": 22}, {"url": "https://github.com/yukw777/leela-zero-pytorch/blob/master/eval/bg-vs-sm.ctl", "anchor_text": "here", "paragraph_index": 22}, {"url": "https://github.com/yukw777/leela-zero-pytorch", "anchor_text": "https://github.com/yukw777/leela-zero-pytorch", "paragraph_index": 23}], "all_paragraphs": ["Recently, I have been looking into ways to speed up my research and manage my experiments, especially around writing training pipelines and managing experiment configurations, and I discovered these two new projects called PyTorch Lightning and Hydra. PyTorch Lightning helps you write training pipelines quickly, while Hydra helps you manage configurations in a clean way.", "In order to practice using them in a more realistic setting, I decided to write a training pipeline for Leela Zero, a Go engine. I chose to do this because it is a well-scoped project with interesting technical challenges related to training huge networks on big data sets using multiple GPUs. Also, I previously had fun implementing a smaller version of AlphaGo for chess, so I thought this would be a fun side project.", "In this blog, I will explain the major details of the project so that you can understand what I did easily. You can read my code here: https://github.com/yukw777/leela-zero-pytorch", "The first step was to figure out the inner-workings of Leela Zero\u2019s neural network. I referenced Leela Zero\u2019s documentation and its Tensorflow training pipeline heavily.", "Leela Zero\u2019s neural network is composed of a ResNet \u201ctower\u201d with two \u201cheads\u201d, the policy head and the value head, as described in the AlphaGo Zero paper. All convolution filters are 3x3 except for the ones at the start of the policy and value head, which are 1x1, as in the paper. The game and board features are encoded as tensors of shape [batch size, board width, board height, number of features] and fed through the ResNet tower first. The tower then extracts abstract features and feeds them through each of the heads to calculate the policy probability distribution for the next move and the value of the game to predict the winner of the game.", "You can find the implementation details of the network in the code snippet below.", "Leela Zero uses a simple text file to save and load network weights. Each row in the text file has a series of numbers that represent weights of each layer of the network. The residual tower is first, followed by the policy head, and then the value head.", "Convolutional layers have 2 weight rows:", "Batchnorm layers have 2 weight rows:", "Innerproduct (fully connected) layers have 2 weight rows:", "I wrote unit tests to make sure my weight files are correct. An additional simple sanity check I used was to calculate the number of layers and compare it to what Leela Zero says after loading my weight files. The equation for the number of layers is:", "So far, this seems simple enough, but there is a quirky implementation detail you need to be aware of. Leela Zero actually uses the bias for the convolutional layer to represent the learnable parameters (gamma and beta) of the following batch norm layer. This was done so that the format of the weights file, which only has one line for the layer weights and another for the bias, didn\u2019t have to change when batch norm layers were added.", "Currently, Leela Zero only uses the beta term of batch norm, and sets gamma to 1. Then, how do you actually use the convolutional bias to produce the same results as applying the learnable parameters in batch norm? Let\u2019s first take a look at the equation for batch norm:", "Since Leela Zero sets gamma to 1, the equation becomes:", "Now, let x_conv be the output of a convolutional layer without the bias. Then, we want to add some bias to x_conv, so that when you run it through batch norm without beta, the result is the same as running x_conv through the batch norm equation with only beta mentioned above. In an equation form:", "So if we set the convolutional bias to beta * sqrt(var \u2014 eps) in the weight file, we get the desired output, and this is what LeelaZero does.", "Then, how do we actually implement this? In Tensorflow, you can tell the batch norm layer to ignore just the gamma term by calling tf.layers.batch_normalization(scale=False) and be done with it. Unfortunately, in PyTorch you can\u2019t set batch normalization layers to ignore only gamma; you can only ignore both gamma and beta by setting the affine parameter to False: BatchNorm2d(out_channels, affine=False). So, I set batch normalization to ignore both, then simply added a tensor after, which represents beta. Then, I used the equation bias = beta * sqrt(var \u2014 eps) to calculate the convolutional bias for the weight file.", "After figuring out the details of Leela Zeros\u2019s neural network, it was time to tackle the training pipeline. As I mentioned, I wanted to practice using two tools \u2014 PyTorch Lightning and Hydra \u2014 to speed up writing training pipelines and cleanly manage experiment configurations. Let\u2019s dive into the details on how I used them.", "Writing the training pipeline is by far my least favorite part of research: it involves a lot of repetitive boilerplate code, and is hard to debug. Because of this, PyTorch Lightning was like a breath of fresh air to me. It is a lightweight library without many auxiliary abstractions on top of PyTorch that takes care of most of the boilerplate code in writing training pipelines. It allows you to focus on the more interesting parts of your training pipelines, like the model architecture, and to make your research code more modular and debuggable. Furthermore, it supports multi-GPU and TPU training out of the box!", "In order to use PyTorch Lightning for my training pipeline, the most coding I had to do was to write a class, which I called NetworkLightningModule, that inherits from LightningModule to specify the details of my training pipeline, and pass it to the Trainer. You can follow the official PyTorch Lightning documentation for details on how to write your own LightningModule.", "Another part of research that I have been searching for a good solution is experiment management. When you conduct research, it\u2019s unavoidable that you run a myriad of variants of your experiment to test your hypothesis, and it\u2019s extremely important to keep track of them in a scalable way. So far, I have relied on configuration files to manage my experiment variants, but using flat configuration files quickly becomes unmanageable. Templates are one solution to this problem. However, I have found that templates eventually become messy as well, because as you overlay multiple layers of value files to render your configuration files, it becomes difficult to keep track of which value came from which value file.", "Hydra, on the other hand, is a composition-based configuration management system. Instead of having separate templates and value files to render the final configuration, you combine multiple smaller configuration files to compose the final configuration. It is not as flexible as a template-based configuration management system, but I find that composition-based systems strike a good balance between flexibility and maintainability. Hydra is one such system that is specifically tailored for research scripts. It is a bit heavy-handed in its invocation as it requires that you use it as a decorator to the main entry point function of your script, but I actually think this design choice makes it easy to integrate with your training scripts. Furthermore, it allows you to manually override configurations via command line, which is very useful when running different variations of your experiment. I used Hydra to manage different sizes of the network architecture and training pipeline configurations.", "To evaluate my trained networks, I used GoMill to run Go tournaments. It is a library to run tournaments between Go Text Protocol (GTP) engines, of which Leela Zero is one. You can find a tournament configuration I used here.", "By using PyTorch-Lightning and Hydra, I was able to drastically speed up writing training pipelines and efficiently manage experiment configurations. I hope this project and blog post will help you with your research also. You can check out the code here: https://github.com/yukw777/leela-zero-pytorch", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD Student at UMich Researching NLP and Cognitive Architectures \u2022 Perviously Real-time Distributed System Engineer turned NLP Research Engineer at ASAPP"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbbf588683065&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://peterkeunwoo.medium.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": ""}, {"url": "https://peterkeunwoo.medium.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Peter Yu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F96d3b6e1e5c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&user=Peter+Yu&userId=96d3b6e1e5c6&source=post_page-96d3b6e1e5c6----bbf588683065---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/M4biGF0pN5s", "anchor_text": "Source"}, {"url": "https://github.com/PyTorchLightning/pytorch-lightning", "anchor_text": "PyTorch Lightning"}, {"url": "https://hydra.cc/", "anchor_text": "Hydra"}, {"url": "https://github.com/leela-zero/leela-zero", "anchor_text": "Leela Zero"}, {"url": "https://medium.com/@peterkeunwoo/beating-my-brother-in-chess-cb17739ffe2", "anchor_text": "a smaller version of AlphaGo for chess"}, {"url": "https://github.com/yukw777/leela-zero-pytorch", "anchor_text": "https://github.com/yukw777/leela-zero-pytorch"}, {"url": "https://github.com/leela-zero/leela-zero/tree/next/training/tf", "anchor_text": "Tensorflow training pipeline"}, {"url": "https://deepmind.com/blog/article/alphago-zero-starting-scratch", "anchor_text": "AlphaGo Zero paper"}, {"url": "https://github.com/yukw777/leela-zero-pytorch/blob/master/leela_zero_pytorch/network.py#L90", "anchor_text": ""}, {"url": "https://github.com/mattheww/gomill", "anchor_text": "GoMill"}, {"url": "https://github.com/yukw777/leela-zero-pytorch/blob/master/eval/bg-vs-sm.ctl", "anchor_text": "here"}, {"url": "https://github.com/yukw777/leela-zero-pytorch", "anchor_text": "https://github.com/yukw777/leela-zero-pytorch"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bbf588683065---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bbf588683065---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----bbf588683065---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bbf588683065---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----bbf588683065---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&user=Peter+Yu&userId=96d3b6e1e5c6&source=-----bbf588683065---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&user=Peter+Yu&userId=96d3b6e1e5c6&source=-----bbf588683065---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbbf588683065&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bbf588683065---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bbf588683065--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bbf588683065--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bbf588683065--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bbf588683065--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bbf588683065--------------------------------", "anchor_text": ""}, {"url": "https://peterkeunwoo.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://peterkeunwoo.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Peter Yu"}, {"url": "https://peterkeunwoo.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "86 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F96d3b6e1e5c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&user=Peter+Yu&userId=96d3b6e1e5c6&source=post_page-96d3b6e1e5c6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fedffe1da419f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftraining-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065&newsletterV3=96d3b6e1e5c6&newsletterV3Id=edffe1da419f&user=Peter+Yu&userId=96d3b6e1e5c6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}