{"url": "https://towardsdatascience.com/the-video-search-engine-my-journey-into-computer-vision-9789824e76bb", "time": 1683002337.379317, "path": "towardsdatascience.com/the-video-search-engine-my-journey-into-computer-vision-9789824e76bb/", "webpage": {"metadata": {"title": "The Video Search Engine \u2014 My Journey Into Computer Vision | by Rod Fuentes | Towards Data Science", "h1": "The Video Search Engine \u2014 My Journey Into Computer Vision", "description": "Creating video content has been my lifelong hobby. I remember making stop animation movies in middle school, graduating to 30-min. short films through high school and college. My \u2018films\u2019 are more\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.npr.org/2019/08/09/749938354/episode-932-deep-learning-with-the-elephants", "anchor_text": "quintessential modern problem", "paragraph_index": 2}, {"url": "https://projects.raspberrypi.org/en/projects/getting-started-with-picamera", "anchor_text": "portable video capture", "paragraph_index": 10}, {"url": "https://www.pyimagesearch.com/2019/04/15/live-video-streaming-over-network-with-opencv-and-imagezmq/", "anchor_text": "there are many options", "paragraph_index": 10}, {"url": "https://aws.amazon.com/blogs/aws/launch-welcoming-amazon-rekognition-video-service/", "anchor_text": "AWS Rekognition", "paragraph_index": 15}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html", "anchor_text": "SageMaker object detection API", "paragraph_index": 19}, {"url": "https://en.wikipedia.org/wiki/FFmpeg", "anchor_text": "FFmpeg library", "paragraph_index": 21}, {"url": "https://thehive.ai/hive-data?gclid=EAIaIQobChMIwrbin5m45gIV4oNaBR39agSjEAAYAyAAEgLNqfD_BwE", "anchor_text": "many services", "paragraph_index": 23}, {"url": "https://www.linkedin.com/in/paulblankley/", "anchor_text": "Paul Blankley", "paragraph_index": 25}, {"url": "https://www.quora.com/How-should-I-label-image-data-for-machine-learning", "anchor_text": "consulting the interwebs", "paragraph_index": 25}, {"url": "https://stackoverflow.com/questions/58592206/understanding-the-output-of-sagemaker-object-detection-prediction", "anchor_text": "Ryo Kawamura", "paragraph_index": 29}, {"url": "https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624", "anchor_text": "using the \u2018resnet-50\u2019 algorithm", "paragraph_index": 32}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "mean average precision (mAP)", "paragraph_index": 42}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-api-config.html", "anchor_text": "change deep learning topologies", "paragraph_index": 46}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/algo-object-detection-tech-notes.html", "anchor_text": "transfer learning", "paragraph_index": 46}, {"url": "https://www.linkedin.com/in/sandeeparneja/", "anchor_text": "Sandeep Arneja", "paragraph_index": 50}, {"url": "https://www.linkedin.com/in/paulblankley/", "anchor_text": "Paul Blankley", "paragraph_index": 50}, {"url": "https://www.linkedin.com/in/ryo-kawamura-91a11a52/?locale=en_US", "anchor_text": "Ryo Kawamura", "paragraph_index": 50}, {"url": "https://angel.co/thea-zimnicki", "anchor_text": "Thea Zimnicki", "paragraph_index": 50}], "all_paragraphs": ["Creating video content has been my lifelong hobby. I remember making stop animation movies in middle school, graduating to 30-min. short films through high school and college. My \u2018films\u2019 are more family-oriented these days thanks to my kids, but I\u2019m always pondering new projects.", "As I reflect on projects I\u2019d love to do, I keep returning to the same problem: recording footage is far easier than making sense of it. Just think about your phone\u2019s camera roll. It\u2019s likely filled with hundreds, if not thousands, of videos that are unedited, too long, and unwatchable.", "This imbalance between creating and consuming video is part of the \u201cquintessential modern problem\u201d, resulting from cheap recording devices and even cheaper digital storage. Quickly summarized, the problem is that we can point 15 cameras from 15 different angles at the same sporting event for two hours and produce 30 hours of unedited video. But no human has 30 hours to watch that content.", "What\u2019s needed is a way to extract the interesting moments from video content.", "Let\u2019s consider a more practical example. Your local retailer likely records thousands of hours of video per month to identify shoplifters. Yet that video is unedited, lengthy, and terribly unwatchable despite the obvious business value. What\u2019s needed is a \u201csearch engine\u201d for video. A system that takes image or video \u201ckey moments\u201d as search term inputs and outputs relevant video segments as search results.", "This problem reminded me of my 2004 summer internship at one of our nation\u2019s premier R&D labs, IBM T.J. Watson Research Center. There, I saw early applications of computer vision projects, such as drawing bounding boxes on cars entering and exiting a parking lot.", "It\u2019s been 15 years since my time at IBM, but I\u2019ve never forgotten that magic feeling \u2014 watching the screen flicker with boxes around cars and people. Back then, such output was a breakthrough in machine learning and compute power. I can now explore whether general purpose video search engine can be built.", "My objective is to build a prototype of the video search engine described above. The system will video record a table tennis match, extract the video clips when the ball is in play, and show just the relevant clips to a user. The first key result is to video record a ping pong match using a portable device and send the video to cloud storage for analysis. The second key result is to train an objection detection model that finds a ping pong ball in play. The third key result is to output the extracted video clips to a web UI.", "I imposed various limitations on this project to keep it within the scope of nights and weekends. For instance, I don\u2019t intend to build a fully contained object detection system on a Raspberry Pi. Instead, I will use AWS to retrieve stored video clips, process them through the object detector, and return the results to a web UI. Real-time processing of the video is also beyond the scope of this project. That said, these limitations present exciting future opportunities for this project.", "So far, I\u2019ve accomplished 70% of the first key result by video recording content using a Raspberry Pi and sending that video to AWS S3 for future analysis.", "From the start, I imagined a Raspberry Pi (with the Pi Camera module) would be ideal for exploring portable video capture. I\u2019ve learned that there are many options, including IP cameras, webcams, and more. But in hindsight I\u2019m glad I chose the Raspberry Pi thanks to its form factor, well-documented code, and ardent community.", "Once I had the Raspberry Pi booted, I configured an SSH environment so I could execute code from my laptop to capture images and video.", "Then I had to send that video to AWS S3. I started with a simple design using Python: (1) open a video stream from the Pi Camera and (2) send one frame every two seconds to S3.", "Images started appearing in my S3 bucket, so I began designing the database for the project.", "My design stores each image, its timestamp, and a prediction result for each image in a NoSQL table. Later, I will query that database for the predictions and fetch the corresponding timestamps to trim the video into relevant clips.", "For now, I set up a stub for the predictions, relying on AWS Rekognition API to detect objects. Here is how I saved the data to a DynamoDB table:", "Success! I have a NoSQL table that references an S3 image, a timestamp, and its corresponding prediction:", "With the camera pointed at me, AWS Rekognition detected a \u2018person\u2019 with 99.13% confidence. But could Rekognition detect a ping pong ball in play to help me achieve my second key result?", "Sadly, no. After testing many ping pong images, I found that Rekognition performs admirably with respect to detecting scenes \u2014 such as labeling images pertaining to \u201cPing Pong\u201d. But when it comes to finding a ping pong ball, Rekognition did not perform well. In most cases, it did not distinguish the ball as an identifiable object at all. When it did find the ball, it labeled it as the \u201cMoon\u201d \ud83d\ude0e", "Using the Rekognition API was convenient but limiting with respect to my project. Fortunately, Amazon offers the SageMaker object detection API if you want to customize your own model.", "I began with a video feed of a table tennis match. Here are some sample frames:", "My first task was to label video frames with the ping pong ball in play to build a train, validate, test data set. The FFmpeg library was useful to convert the video into images that I could label:", "The snippet above generated thousands of images on my machine. The next step was to add \u2018bounding boxes\u2019 to the ping pong balls in play.", "There are many services that perform this arduous task for you, but I opted to personally label the images to get a deeper understanding and appreciation for computer vision. I turned to RectLabel, an image annotation tool to label images for bounding box object detection and segmentation:", "I spent about four hours on this task, averaging 8.3 labels per minute, to get 2000 labeled images. It was mind-numbing work.", "About half-way through my labeling work, I wondered whether tight or loose bounding boxes would be better to balance model accuracy versus model generalization given JPEG compression artifacts and motion blur on the ping pong ball. After phoning a friend, Paul Blankley, and consulting the interwebs, I learned that \u201cbounding boxes are usually drawn tightly around every [object] in an image\u201d because:", "Without accurately drawn bounding boxes, an entire algorithm can be affected causing it to inaccurately identify [objects]. This is why quality checking and ensuring a high level of attention is paid to the accuracy of every bounding box, resulting in a strong AI engine.", "If I had to do this project again, I would use lossless image format (*.png) and draw tighter bounding boxes to improve my training data. Yet I recognize this optimization is not free. My average labeling speed decreased by ~50% when I started labeling images with tighter bounding boxes.", "Once I finished labeling images, RectLabel output the data in a JSON file suitable for computer vision tasks. Here\u2019s a sample of the output:", "Then I created a function to separate the annotations into train and validate folders, as expected by Amazon SageMaker\u2019s input channels. Note this important tip from Ryo Kawamura if you\u2019re following my code:", "Though \u2018category_id\u2019 in the COCO JSON file starts from 1, \u2018class_id\u2019 in the Amazon SageMaker JSON file starts from 0.", "Next, I moved the files into an Amazon S3 bucket with four folders as required by the SageMaker endpoint: /train, /validation, /train_annotation, and /validation_annotation. I used a 70% split on the train vs. validation files and shuffled the data:", "In the next step, I created a SageMaker object detector with certain hyperparameters, such as using the \u2018resnet-50\u2019 algorithm with one class (my ping pong ball) and images sized 512x512 pixels.", "I then set the train/validate location for the object-detector, called the .fit function, and deployed the model to an endpoint:", "Given that I had only 2000 images, my Amazon box (ml.p3.2xlarge) took about ~10 minutes to train the model. Deploying the endpoint often took even longer, and the anticipation of testing a model was agonizing!", "Finally, the moment of truth. I invoked my model by passing it a PNG file it had never seen in bytes:", "Here\u2019s how to interpret this output according to AWS SageMaker:", "Each of these object arrays consists of a list of six numbers. The first number is the predicted class label. The second number is the associated confidence score for the detection. The last four numbers represent the bounding box coordinates [xmin, ymin, xmax, ymax]. These output bounding box corner indices are normalized by the overall image size. Note that this encoding is different than that use by the input .json format. For example, in the first entry of the detection result, 0.3088374733924866 is the left coordinate (x-coordinate of upper-left corner) of the bounding box as a ratio of the overall image width, 0.07030484080314636 is the top coordinate (y-coordinate of upper-left corner) of the bounding box as a ratio of the overall image height, 0.7110607028007507 is the right coordinate (x-coordinate of lower-right corner) of the bounding box as a ratio of the overall image width, and 0.9345266819000244 is the bottom coordinate (y-coordinate of lower-right corner) of the bounding box as a ratio of the overall image height.", "Frankly, I needed something more tangible to appreciate the results. So I used this function to visualize each prediction:", "I shuddered in excitement and relief when I saw this output:", "I spent an hour hitting the model with various test images it had never seen. Some were great predictions. Others were plain goofy, such as the model confusing white spots on a player\u2019s uniform for a ping pong ball \ud83d\ude44", "Fortunately, I was able to remove most of the false positives by raising the confidence threshold to 0.40.", "I am quite happy with my results so far, but future work is required to evaluate and optimize my model. For example, I intend to calculate the mean average precision (mAP) as a performance metric. That mAP metric will help me evaluate different optimizations, such as adding more training images, experimenting with transfer learning, and trying other deep learning topologies. I\u2019ll leave those tasks for my 2020 roadmap (and future posts).", "I\u2019m also excited to tackle my third key result in 2020 \u2014 showing the relevant video clips to a user via a web UI. When that key result is complete, I will test the entire setup in a real-world environment:", "Stay tuned for more learning and development in this direction.", "It is common wisdom among data scientists that", "This project has given me deep appreciation for this truism. Indeed, the ability to change deep learning topologies was trivial on AWS SageMaker. Yet the results did not change significantly. I also leveraged transfer learning in another model with minimal effort. Again, the results were not much better. Then I remembered the difficult, painstaking work of collecting and labeling images for my project\u2026", "I\u2019m boggled when I compare model-related work against data-related work with respect to the level of effort and cross-project applicability. For instance, switching between deep learning topologies is relatively easy, and many projects can leverage those topologies in a variety of computer vision tasks. In contrast, my image labeling work required significant effort and will likely benefit my project only.", "Facing this reality, I\u2019m feeling a tad pessimistic about the viability of a general purpose video search engine that can produce results from a user\u2019s arbitrary input of (1) video and (2) images-as-search-terms. To be sure, a specific purpose video search engine is within grasp. But significant, non-trivial work lies ahead to explore how a model can generalize to detect whatever a user wants to find based on a few image examples.", "Here\u2019s to a fun year of learning ahead on that front!", "Many thanks to Sandeep Arneja, Paul Blankley, Ryo Kawamura, and Thea Zimnicki for their feedback and contributions to this project.", "Authentic, exited startup founder. Exploring Web3, DeFi, NFTs. Co-founder @AlphaBack_xyz. Loves: coding, cooking, climbing, and CoLab machine learning \ud83d\ude1c"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9789824e76bb&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://paperhunt.net/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Rod Fuentes"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3720040b14ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=post_page-3720040b14ff----9789824e76bb---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9789824e76bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=-----9789824e76bb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9789824e76bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=-----9789824e76bb---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.npr.org/2019/08/09/749938354/episode-932-deep-learning-with-the-elephants", "anchor_text": "quintessential modern problem"}, {"url": "https://projects.raspberrypi.org/en/projects/getting-started-with-picamera", "anchor_text": "portable video capture"}, {"url": "https://www.pyimagesearch.com/2019/04/15/live-video-streaming-over-network-with-opencv-and-imagezmq/", "anchor_text": "there are many options"}, {"url": "https://aws.amazon.com/blogs/aws/launch-welcoming-amazon-rekognition-video-service/", "anchor_text": "AWS Rekognition"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html", "anchor_text": "SageMaker object detection API"}, {"url": "https://en.wikipedia.org/wiki/FFmpeg", "anchor_text": "FFmpeg library"}, {"url": "https://thehive.ai/hive-data?gclid=EAIaIQobChMIwrbin5m45gIV4oNaBR39agSjEAAYAyAAEgLNqfD_BwE", "anchor_text": "many services"}, {"url": "https://www.linkedin.com/in/paulblankley/", "anchor_text": "Paul Blankley"}, {"url": "https://www.quora.com/How-should-I-label-image-data-for-machine-learning", "anchor_text": "consulting the interwebs"}, {"url": "https://stackoverflow.com/questions/58592206/understanding-the-output-of-sagemaker-object-detection-prediction", "anchor_text": "Ryo Kawamura"}, {"url": "https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624", "anchor_text": "using the \u2018resnet-50\u2019 algorithm"}, {"url": "https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173", "anchor_text": "mean average precision (mAP)"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-api-config.html", "anchor_text": "change deep learning topologies"}, {"url": "https://docs.aws.amazon.com/sagemaker/latest/dg/algo-object-detection-tech-notes.html", "anchor_text": "transfer learning"}, {"url": "https://www.linkedin.com/in/sandeeparneja/", "anchor_text": "Sandeep Arneja"}, {"url": "https://www.linkedin.com/in/paulblankley/", "anchor_text": "Paul Blankley"}, {"url": "https://www.linkedin.com/in/ryo-kawamura-91a11a52/?locale=en_US", "anchor_text": "Ryo Kawamura"}, {"url": "https://angel.co/thea-zimnicki", "anchor_text": "Thea Zimnicki"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9789824e76bb---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----9789824e76bb---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/python?source=post_page-----9789824e76bb---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9789824e76bb---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/videos?source=post_page-----9789824e76bb---------------videos-----------------", "anchor_text": "Videos"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9789824e76bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=-----9789824e76bb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9789824e76bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=-----9789824e76bb---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9789824e76bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3720040b14ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=post_page-3720040b14ff----9789824e76bb---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd74fdf79fdea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&newsletterV3=3720040b14ff&newsletterV3Id=d74fdf79fdea&user=Rod+Fuentes&userId=3720040b14ff&source=-----9789824e76bb---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Written by Rod Fuentes"}, {"url": "https://paperhunt.net/followers?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "438 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3720040b14ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&user=Rod+Fuentes&userId=3720040b14ff&source=post_page-3720040b14ff----9789824e76bb---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd74fdf79fdea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-video-search-engine-my-journey-into-computer-vision-9789824e76bb&newsletterV3=3720040b14ff&newsletterV3Id=d74fdf79fdea&user=Rod+Fuentes&userId=3720040b14ff&source=-----9789824e76bb---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Rod Fuentes"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Garbage Route Optimization Using Computer Vision Object DetectionCo-written by my 10 year-old daughter, Isabella, whose science fair project turned into her first, hands-on machine learning project \u2764"}, {"url": "https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "9 min read\u00b7Jan 4, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F17a217d5582d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgarbage-route-optimization-using-computer-vision-object-detection-17a217d5582d&user=Rod+Fuentes&userId=3720040b14ff&source=-----17a217d5582d----0-----------------clap_footer----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d?source=author_recirc-----9789824e76bb----0---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F17a217d5582d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgarbage-route-optimization-using-computer-vision-object-detection-17a217d5582d&source=-----9789824e76bb----0-----------------bookmark_preview----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----9789824e76bb----1---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----9789824e76bb----1-----------------bookmark_preview----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----9789824e76bb----2---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----9789824e76bb----2-----------------bookmark_preview----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/setting-up-your-local-environment-2e629d5e37ea?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Rod Fuentes"}, {"url": "https://medium.com/coinmonks?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Coinmonks"}, {"url": "https://medium.com/coinmonks/setting-up-your-local-environment-2e629d5e37ea?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "Setting Up Your Local EnvironmentIntro to Solidity: An Ethereum Developer Tutorial for Beginners"}, {"url": "https://medium.com/coinmonks/setting-up-your-local-environment-2e629d5e37ea?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": "5 min read\u00b7Dec 19, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcoinmonks%2F2e629d5e37ea&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2Fsetting-up-your-local-environment-2e629d5e37ea&user=Rod+Fuentes&userId=3720040b14ff&source=-----2e629d5e37ea----3-----------------clap_footer----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/setting-up-your-local-environment-2e629d5e37ea?source=author_recirc-----9789824e76bb----3---------------------b5c2078c_51cc_4020_b7e3_f67b844667ca-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e629d5e37ea&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2Fsetting-up-your-local-environment-2e629d5e37ea&source=-----9789824e76bb----3-----------------bookmark_preview----b5c2078c_51cc_4020_b7e3_f67b844667ca-------", "anchor_text": ""}, {"url": "https://paperhunt.net/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "See all from Rod Fuentes"}, {"url": "https://towardsdatascience.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://salvatore-raieli.medium.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Salvatore Raieli"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "META\u2019S SAM: A Unique Model to Segment AnythingSegmentation needs a foundation model: why is it important?"}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "\u00b714 min read\u00b7Apr 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&user=Salvatore+Raieli&userId=f1a08d9452cd&source=-----c3a956bf5d62----0-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/metas-sam-a-unique-model-to-segment-anything-c3a956bf5d62?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc3a956bf5d62&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fmetas-sam-a-unique-model-to-segment-anything-c3a956bf5d62&source=-----9789824e76bb----0-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----9789824e76bb----1-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----9789824e76bb----0---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----9789824e76bb----0-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://medium.com/@amaster_37400?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Aaron Master"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Please Stop Drawing Neural Networks WrongThe Case for GOOD Diagrams"}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "12 min read\u00b7Mar 21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&user=Aaron+Master&userId=31905cfe67ce&source=-----ffd02b67ad77----1-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/please-stop-drawing-neural-networks-wrong-ffd02b67ad77?source=read_next_recirc-----9789824e76bb----1---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "33"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffd02b67ad77&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplease-stop-drawing-neural-networks-wrong-ffd02b67ad77&source=-----9789824e76bb----1-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://mark-riedl.medium.com/?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://mark-riedl.medium.com/?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Mark Riedl"}, {"url": "https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "A Very Gentle Introduction to Large Language Models without the Hype[This is a work in progress]"}, {"url": "https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "38 min read\u00b7Apr 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F5f67941fa59e&operation=register&redirect=https%3A%2F%2Fmark-riedl.medium.com%2Fa-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e&user=Mark+Riedl&userId=7247bdeb9655&source=-----5f67941fa59e----2-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e?source=read_next_recirc-----9789824e76bb----2---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "53"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f67941fa59e&operation=register&redirect=https%3A%2F%2Fmark-riedl.medium.com%2Fa-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e&source=-----9789824e76bb----2-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----3-----------------clap_footer----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----9789824e76bb----3---------------------122b88b5_fcee_4ca3_9e71_7961f79d86e0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----9789824e76bb----3-----------------bookmark_preview----122b88b5_fcee_4ca3_9e71_7961f79d86e0-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9789824e76bb--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----9789824e76bb--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}