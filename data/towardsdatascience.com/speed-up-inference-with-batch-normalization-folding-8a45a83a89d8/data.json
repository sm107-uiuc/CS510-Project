{"url": "https://towardsdatascience.com/speed-up-inference-with-batch-normalization-folding-8a45a83a89d8", "time": 1683006110.998639, "path": "towardsdatascience.com/speed-up-inference-with-batch-normalization-folding-8a45a83a89d8/", "webpage": {"metadata": {"title": "Speed-up inference with Batch Normalization Folding | by Nathan Hubens | Towards Data Science", "h1": "Speed-up inference with Batch Normalization Folding", "description": "Batch Normalization is a technique which takes care of normalizing the input of each layer to make the training process faster and more stable. In practice, it is an extra layer that we generally add\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/fastai/imagenette", "anchor_text": "ImageNette dataset", "paragraph_index": 11}, {"url": "http://nathanhubens.github.io", "anchor_text": "nathanhubens.github.io", "paragraph_index": 24}], "all_paragraphs": ["Batch Normalization is a technique which takes care of normalizing the input of each layer to make the training process faster and more stable. In practice, it is an extra layer that we generally add after the computation layer and before the non-linearity.", "Due to its efficiency for training neural networks, batch normalization is now widely used. But how useful is it at inference time?", "Once the training has ended, each batch normalization layer possesses a specific set of \u03b3 and \u03b2, but also \u03bc and \u03c3, the latter being computed using an exponentially weighted average during training. It means that during inference, the batch normalization acts as a simple linear transformation of what comes out of the previous layer, often a convolution.", "As a convolution is also a linear transformation, it also means that both operations can be merged into a single linear transformation!", "This would remove some unnecessary parameters but also reduce the number of operations to be performed at inference time.", "With a little bit of math, we can easily rearrange the terms of the convolution to take the batch normalization into account.", "As a little reminder, the convolution operation followed by the batch normalization operation can be expressed, for an input x, as:", "So, if we re-arrange the W and b of the convolution to take the parameters of the batch normalization into account, as such:", "We can remove the batch normalization layer and still have the same results!", "Note: Usually, you don\u2019t have a bias in a layer preceding a batch normalization layer. It is useless and a waste of parameters as any constant will be canceled out by the batch normalization.", "We will try for 2 common architectures:", "Just for the demonstration, we will use ImageNette dataset and PyTorch. Both networks will be trained for 5 epochs and what changes in terms of parameter number and inference time.", "Let\u2019s start by training VGG16 for 5 epochs (the final accuracy doesn\u2019t matter):", "Then show its number of parameters:", "The initial inference time for a single image is:", "So now if we apply batch normalization folding, we have:", "So 8448 parameters removed and even better, almost 0.4 ms faster inference! Most importantly, this is completely lossless, there is absolutely no change in terms of performance:", "Let\u2019s see how it behaves in the case of Resnet50!", "Same, we start by training it for 5 epochs:", "The initial amount of parameters is:", "After using batch normalization folding, we have:", "So now, we have 26,560 parameters removed and even more impressive, an inference time reduce by 1.5ms! And still without any drop in performance.", "So if we can reduce the inference time and the number of parameters of our models without enduring any drop in performance, why shouldn\u2019t we always do it?", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD Student interested in Machine Learning, Deep Learning and Data Science | @HubensN | nathanhubens.github.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8a45a83a89d8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nathan.hubens?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathan.hubens?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Nathan Hubens"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4438540a27bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&user=Nathan+Hubens&userId=4438540a27bf&source=post_page-4438540a27bf----8a45a83a89d8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/fastai/imagenette", "anchor_text": "ImageNette dataset"}, {"url": "https://github.com/nathanhubens/fasterai", "anchor_text": "nathanhubens/fasteraiFasterAI: A repository for making smaller and faster models with the FastAI library. - nathanhubens/fasteraigithub.com"}, {"url": "https://arxiv.org/pdf/1502.03167.pdf", "anchor_text": "The Batch Normalization paper"}, {"url": "https://www.youtube.com/watch?v=tNIpEZLv_eg&t=1s", "anchor_text": "DeepLearning.ai Batch Normalization Lesson"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8a45a83a89d8---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----8a45a83a89d8---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&user=Nathan+Hubens&userId=4438540a27bf&source=-----8a45a83a89d8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&user=Nathan+Hubens&userId=4438540a27bf&source=-----8a45a83a89d8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8a45a83a89d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8a45a83a89d8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8a45a83a89d8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathan.hubens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nathan.hubens?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nathan Hubens"}, {"url": "https://medium.com/@nathan.hubens/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "445 Followers"}, {"url": "http://nathanhubens.github.io", "anchor_text": "nathanhubens.github.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4438540a27bf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&user=Nathan+Hubens&userId=4438540a27bf&source=post_page-4438540a27bf--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71441112cb70&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fspeed-up-inference-with-batch-normalization-folding-8a45a83a89d8&newsletterV3=4438540a27bf&newsletterV3Id=71441112cb70&user=Nathan+Hubens&userId=4438540a27bf&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}