{"url": "https://towardsdatascience.com/15-minutes-to-spark-89cca49993f0", "time": 1683014176.2196548, "path": "towardsdatascience.com/15-minutes-to-spark-89cca49993f0/", "webpage": {"metadata": {"title": "15 Minutes to Learn Spark. From configuration to UDFs | by Andrea Ialenti | Towards Data Science", "h1": "15 Minutes to Spark", "description": "A quick-start introduction to Spark for those impatient of writing their first query. The idea of this post is to cover the major features of Spark SQL"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@andrea.ialenti", "anchor_text": "all my articles", "paragraph_index": 0}, {"url": "https://drive.google.com/file/d/1kCXnIeoPT6p9kS_ANJ0mmpxlfDwK1yio/view", "anchor_text": "this dataset", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?utm_source=tr.im&utm_medium=no_referer&utm_campaign=tr.im%2F1Triu&utm_content=direct_input", "anchor_text": "Six Spark Exercises to Rule Them All", "paragraph_index": 3}, {"url": "https://spark.apache.org/docs/3.0.0-preview/web-ui.html", "anchor_text": "Spark UI", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c", "anchor_text": "I wrote an entire article about this topic", "paragraph_index": 29}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions", "anchor_text": "I would refer to the documentation", "paragraph_index": 34}, {"url": "https://spark.apache.org/docs/2.4.0/api/sql/index.html#array_except", "anchor_text": "the reference", "paragraph_index": 41}, {"url": "https://databricks.com/glossary/catalyst-optimizer", "anchor_text": "Catalyst", "paragraph_index": 42}, {"url": "https://medium.com/@andrea.ialenti", "anchor_text": "follow me on Medium", "paragraph_index": 48}, {"url": "https://www.jetbrains.com/pycharm/download/#section=mac", "anchor_text": "their website", "paragraph_index": 50}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "from the official Spark website", "paragraph_index": 51}], "all_paragraphs": ["As I wrote in pretty much all my articles about this tool, Spark is super easy to use, as much as SQL. But it doesn\u2019t matter how many hours I spend in writing code, I am just not able to permanently store Spark APIs in my brain (someone would say that my memory is like RAM, small and volatile (: ).", "Whether you want a quick-start introduction to Spark SQL and you are impatient of writing your first query, or you are just like me and you need a cheat-sheet, I believe that you\u2019ll find this article useful.", "The idea of this post is to cover all the major functions/features of Spark SQL, and in the snippets you\u2019ll always have the original SQL query and its translation in PySpark.", "I will be executing my code on this dataset: I\u2019ve created it a few months ago for another Medium article \u2014 Six Spark Exercises to Rule Them All \u2014 and it consists of three simple tables:", "Apache Spark is an engine for large scale, parallel data processing. One of the amazing characteristics of this framework is that it exposes APIs in multiple languages: I usually interact with it using Scala, but many others use SQL, Python, or even Java and R.", "The first thing to know when we write a Spark program is that, as we execute the code, we are not necessarily performing any operation on data. Indeed the tool has two types of API calls: Transformations and Actions. The paradigm behind Spark Transformations is known as \u201cLazy Evaluation\u201d, meaning that the actual data crunch won\u2019t start until we call for an Action. To understand this concept, imagine the case in which you need to do a SELECT and a renaming of a column: without a call to an Action (such as a collect or a count), your code is simply defining what is known as the Spark Execution Plan, i.e. the set of operations that will be executed once an Action is triggered.", "Spark organizes the Execution Plan in a Directed Acyclic Graph (the very well known DAG). This structure describes the exact operations that will be performed, and enables the Scheduler to decide which task to execute at a given time.", "Great, where do we start? There are multiple ways to work with Spark:", "The code below is pretty much intended for an IDE.", "Before writing any query, we need to import some libraries and start a Spark Session (the entry point to programming Spark with the Dataset and DataFrame API)*. The following PySpark and Scala snippets will load all you need (assuming that you already configured your system). Afterward, we are only going to see PySpark code, for simplicity. Scala APIs are pretty much the same, besides some nuances.", "*explaining differences among Datasets, DataFrames and RDDs won\u2019t fit in the 15 minutes I promised, so I\u2019ll skip this part and pretend it doesn\u2019t exist.", "The simplest queries you can write is probably the most important you\u2019ll ever use. Let\u2019s see how to do basic operations using the Sales table.", "The first thing we did in the snippets was defining the execution plan; this is executed only when we income the show Action.", "Other examples of Actions we can invoke on Spark plans include:", "Another interesting thing to notice is that columns are identified by col objects. In this case, we are letting Spark infer what Dataframe those columns belong to.", "We can use the syntax execution_plan_variable[\"column_name\"] to specify from which execution plan the column is coming. Using this alternative syntax, we obtain:", "It is particularly important to qualify the source table of a field when we deal with joins (e.g. two tables could have two fields with the same name, hence using only the col objects won\u2019t be enough to disambiguate). The syntax is slightly different in Scala:", "Sometimes we simply want to rename a column, or we want to add a new one with some calculation (e.g. a CASE WHEN):", "Spark supports all major aggregation functions. The example below only refers to the \u201csimple\u201d ones (e.g. Average, Sum, Count, etc.). Aggregations for arrays are described later.", "Displaying the \u201ctable\u201d schema is kind of a misleading wording; a more precise definition would be \u201cshowing the execution plan\u2019s output schema\u201d. With the Spark APIs, we can pipe multiple operations one after the other; with the printSchema API, we output how the final table would look like if we\u2019d write the result of the execution plan on disk.", "In the following example, we rename a few columns, do an aggregation, and add yet another column.", "The output of the printSchema is:", "Note that printSchema does not trigger an Action; what happens instead, is that Spark evaluates the execution plan to understand where the DAG is leading to in terms of output columns. For this reason, this operation is much faster than show, which, instead, triggers the execution of the DAG.", "A more detailed explanation of what the engine will be doing doing when an Action is triggered, can be obtained through the explain API. In this case, we will not get as output the mere schema of the final DAG node, but we\u2019ll obtain a detailed explanation of the operations that will be performed by Spark. Let\u2019s call the explain on the previous query:", "To be honest, I\u2019ve never found the explain API too useful, especially when the DAG starts to be big and complex. A much better view can be found in the Spark UI, that exposes a graphical representation of the same information.", "The CASE WHEN operation is very nicely implemented in Spark (without the need of ad-hoc UDFs); let\u2019s simply take the sales_table to insert each row in a different bucket, depending on num_pieces_sold:", "Sometimes we need to split our flows in multiple parts, to then merge everything back together in a single table; in SQL this is expressed with the UNION ALL. In Spark 2.1, columns had to be sorted before doing a UNION ALL operation. Luckily, Spark 2.3 does the UNION ALL using column names to align the execution plans that are being merged. In the following example, we first split in two our table, then we merge the pieces back together (totally unnecessary, but it will show how to use the API):", "Let\u2019s look at the explain to see what happens behind the scenes:", "The two lines in bold, are the tables that are being merged together.", "Joins are usually the first place where we want to look when we are having performance issues with our code. The Spark engine is quite good in parallelizing non-join operations, while it may need tuning when it comes to join tasks. I wrote an entire article about this topic, so I won\u2019t go any deeper than this: if you want to know more, or you are encountering some issues with joins performance, I definitely suggest have a look!", "In the meantime, here\u2019s the syntax for joining. In the examples, we are going to join the Sales and Sellers tables.", "Besides the traditional join types (left, right, inner, cross, etc.), Spark also supports semi and anti joins; these two are basically one way to express IN and NOT IN operations in Spark:", "A window function performs a calculation on a specific subset of rows, defined as frame or window. The classical example is the ranking of subgroups. In our toy dataset, imagine we want to know, for each seller, what is the product that has been sold the most. To extract this information we need to:", "The below image is an example of how we want to partition the data:", "Another set of very common operations Data Scientists face when crunching data, involve extracting information from strings. Of course, there are plenty of Spark APIs to do pretty much any (basic) manipulation with textual data. Let\u2019s start from the simple LIKE operator to then climb up to the usage of regular expressions. For a full list of APIs, I would refer to the documentation; below, those that are probably used the most.", "In the following example, we want to use the sales table to select all the strings where bill_raw_text is LIKE 'ab%cd%' (i.e. starts with the string ab and has a string cd somewhere in the middle).", "Sometimes the pattern we want to find is more complex and cannot be expressed with simple wildcards. In this case, we need to use regular expressions. Let\u2019s delve into a few functions. In the example below, we are always going to apply the same Regular Expression.", "Arrays are a type of data that should probably be used more when defining tables schemas/data marts in the Big Data realm. Spark implements a lot of functions to manipulate arrays (to be precise, this is true from version 2.4). Let\u2019s delve into the basics.", "Converting a column into an array is as simple as calling an aggregation function. Spark 2.3 has two main types of array aggregation functions collect_set and collect_list: the first contains only unique elements, while the latter is simply the conversion of a group into a list.", "The inverse operation of the aggregation, is the \u201carray explosion\u201d, meaning that from a horizontal array, we want to generate a \u201cvertical\u201d column. To do so, we can use the explode function.", "Unfortunately, Spark 2.3 does not support too many operations on Arrays. Luckily, Spark 2.4 does! Some functions that are available since Spark 2.4 include:", "And so forth. The above definitions are directly taken from the reference. I advise you to look into that to have more details!", "Finally, User Defined Functions. UDFs are the way-to-go when we can\u2019t find a Transformation in the default APIs. A UDF is a custom function that the programmer can define and apply to columns just like all the APIs we saw so far. They allow the maximum flexibility (we can write pretty much any code into them); the downside is that Spark treats them as black boxes, hence the internal Spark Engine Optimizer (Catalyst), is not able to do any optimization: a UDFs may slow down our code.", "Just as an example, let\u2019s implement a UDF that simulates the function array_repeat(element, count) that returns an array containing an element count times.", "Besides the syntax for the UDF, I would advise focusing on the lit function used above. Some Spark functions only accept columns as input: if we need to use a constant, we might need to convert that constant into a \u201cColumn\u201d. lit creates a Column of literal value.", "Awesome. I hope I was able to show that Spark is not any harder than SQL, it\u2019s basically the same thing, on steroids.", "As you can imagine, the title of the article was quite an overstatement: it will require way more than 15 minutes to be proficient with this tool; I believe that the above is a good quick-start, but Spark can offer so much more!", "Where to go from here? First, my advice is to start playing with the APIs above, as they will cover 70% of your use cases. When you\u2019ll be confident with the basics, I would suggest the two articles below, that a trustworthy author (lol) wrote a few months back. The first one will challenge you with some classical problems encountered when developing with this tool, while the second is a deep dive on Spark Joins.", "For more articles about you can follow me on Medium!", "Installing Spark in a local (non distributed) environment it\u2019s a surprisingly easy task. In this appendix, I\u2019ll show you the basic configuration of PyCharm Community Edition to run Spark with Python. There are five simple steps:", "Luckily for us, JetBrains has an open-source version of PyCharm. We can simply download the latest version from their website. Installation is straightforward.", "We only need to download a zip file from the official Spark website. When I am writing, there are two major versions available: 3.0.1 and 2.4.7. For the scope of the article, we can choose either one or the other.", "Once the download is complete, we just need to unzip the package in a suitable location.", "It\u2019s time to run PyCharm and install all the packages needed. First, let\u2019s open PyCharm, create a new project, and a new Virtual Environment.", "Finally, directly from PyCharm, we can simply install PySpark:", "Note that to enable hints, we should also install the pyspark-stubs package.", "Hopefully, we reached this point with no errors, so we only need to instruct PyCharm to run the correct Spark executor. This is located in the folder in which we unzipped Spark itself. Let\u2019s create a Run Configuration for our PyCharm project.", "To test if Spark is working, simply run the following snippet", "I\u2019m a Data Scientist, I usually ride a giant unicorn with a rainbow mane. I love learning by explaining. \u201cLike a bicycle I need to move to keep my balance\u201d."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F89cca49993f0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----89cca49993f0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Andrea Ialenti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc4f0dc70838c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=post_page-c4f0dc70838c----89cca49993f0---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F89cca49993f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----89cca49993f0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F89cca49993f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=-----89cca49993f0---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@tateisimikito?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Jukan Tateisi"}, {"url": "https://unsplash.com/s/photos/stairs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@andrea.ialenti", "anchor_text": "all my articles"}, {"url": "https://drive.google.com/file/d/1kCXnIeoPT6p9kS_ANJ0mmpxlfDwK1yio/view", "anchor_text": "this dataset"}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?utm_source=tr.im&utm_medium=no_referer&utm_campaign=tr.im%2F1Triu&utm_content=direct_input", "anchor_text": "Six Spark Exercises to Rule Them All"}, {"url": "https://en.wikipedia.org/wiki/Mr._Miyagi", "anchor_text": "Mr. Miyagi"}, {"url": "https://livy.apache.org/", "anchor_text": "Livy"}, {"url": "https://livy.incubator.apache.org/", "anchor_text": "Livy"}, {"url": "https://github.com/jupyter-incubator/sparkmagic", "anchor_text": "1"}, {"url": "https://spark.apache.org/docs/3.0.0-preview/web-ui.html", "anchor_text": "Spark UI"}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c", "anchor_text": "I wrote an entire article about this topic"}, {"url": "https://sparkbyexamples.com/pyspark/pyspark-window-functions/", "anchor_text": "Here\u2019s a list of Window Functions in Spark."}, {"url": "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions", "anchor_text": "I would refer to the documentation"}, {"url": "https://spark.apache.org/docs/2.4.0/api/sql/index.html#array_except", "anchor_text": "the reference"}, {"url": "https://databricks.com/glossary/catalyst-optimizer", "anchor_text": "Catalyst"}, {"url": "https://medium.com/@andrea.ialenti", "anchor_text": "follow me on Medium"}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c", "anchor_text": "The art of joining in SparkPractical tips to speedup joins in Sparktowardsdatascience.com"}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565", "anchor_text": "Six Spark Exercises to Rule Them AllSome challenging Spark SQL questions, easy to lift-and-shift on many real-world problems (with solutions)towardsdatascience.com"}, {"url": "https://github.com/steveloughran/winutils", "anchor_text": "Check out this Git repo for more info"}, {"url": "https://www.jetbrains.com/pycharm/download/#section=mac", "anchor_text": "their website"}, {"url": "https://spark.apache.org/downloads.html", "anchor_text": "from the official Spark website"}, {"url": "https://medium.com/tag/spark?source=post_page-----89cca49993f0---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/data-science?source=post_page-----89cca49993f0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----89cca49993f0---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----89cca49993f0---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----89cca49993f0---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F89cca49993f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----89cca49993f0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F89cca49993f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----89cca49993f0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F89cca49993f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----89cca49993f0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc4f0dc70838c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=post_page-c4f0dc70838c----89cca49993f0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F38edc5d7a9a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&newsletterV3=c4f0dc70838c&newsletterV3Id=38edc5d7a9a0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----89cca49993f0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Written by Andrea Ialenti"}, {"url": "https://medium.com/@andrea.ialenti/followers?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "543 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc4f0dc70838c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=post_page-c4f0dc70838c----89cca49993f0---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F38edc5d7a9a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F15-minutes-to-spark-89cca49993f0&newsletterV3=c4f0dc70838c&newsletterV3Id=38edc5d7a9a0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----89cca49993f0---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Andrea Ialenti"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "The art of joining in SparkPractical tips to speedup joins in Spark"}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "\u00b710 min read\u00b7Dec 9, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----dcbd33d693c----0-----------------clap_footer----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c?source=author_recirc-----89cca49993f0----0---------------------556da55e_b808_46e8_80d5_22b231054a0a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=-----89cca49993f0----0-----------------bookmark_preview----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----89cca49993f0----1---------------------556da55e_b808_46e8_80d5_22b231054a0a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----89cca49993f0----1-----------------bookmark_preview----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----89cca49993f0----2---------------------556da55e_b808_46e8_80d5_22b231054a0a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----89cca49993f0----2-----------------bookmark_preview----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Andrea Ialenti"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "Six Spark Exercises to Rule Them AllSome challenging Spark SQL questions, easy to lift-and-shift on many real-world problems (with solutions)"}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": "\u00b711 min read\u00b7Apr 7, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F242445b24565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsix-spark-exercises-to-rule-them-all-242445b24565&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----242445b24565----3-----------------clap_footer----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565?source=author_recirc-----89cca49993f0----3---------------------556da55e_b808_46e8_80d5_22b231054a0a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F242445b24565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsix-spark-exercises-to-rule-them-all-242445b24565&source=-----89cca49993f0----3-----------------bookmark_preview----556da55e_b808_46e8_80d5_22b231054a0a-------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "See all from Andrea Ialenti"}, {"url": "https://towardsdatascience.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "91"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----89cca49993f0----0-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----1-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----89cca49993f0----1-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----89cca49993f0----0---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----89cca49993f0----0-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Apache Spark Optimization TechniquesA review of some of the most common Spark performance problems and how to address them"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----fa7f20a9a2cf----1-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----89cca49993f0----1---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&source=-----89cca49993f0----1-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@antoniolui/applying-custom-functions-in-pyspark-337d63bf32a5?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@antoniolui?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@antoniolui?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Tony Lui"}, {"url": "https://medium.com/@antoniolui/applying-custom-functions-in-pyspark-337d63bf32a5?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Applying Custom Functions in PySparkHow to Use Spark UDFs and Row-wise RDD Operations"}, {"url": "https://medium.com/@antoniolui/applying-custom-functions-in-pyspark-337d63bf32a5?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b75 min read\u00b7Nov 10, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F337d63bf32a5&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40antoniolui%2Fapplying-custom-functions-in-pyspark-337d63bf32a5&user=Tony+Lui&userId=a2544693db86&source=-----337d63bf32a5----2-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/@antoniolui/applying-custom-functions-in-pyspark-337d63bf32a5?source=read_next_recirc-----89cca49993f0----2---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F337d63bf32a5&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40antoniolui%2Fapplying-custom-functions-in-pyspark-337d63bf32a5&source=-----89cca49993f0----2-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Josue Luzardo Gebrim"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "Data Quality in Python Pipelines!Discover What It Is And How To Achieve Data Quality In Your Data Streams!"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": "\u00b714 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&user=Josue+Luzardo+Gebrim&userId=9f59dfc0edf7&source=-----4ad1e8eb6603----3-----------------clap_footer----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----89cca49993f0----3---------------------9afbcc5a_3dc5_4ac5_b843_a5359976558e-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&source=-----89cca49993f0----3-----------------bookmark_preview----9afbcc5a_3dc5_4ac5_b843_a5359976558e-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----89cca49993f0--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----89cca49993f0--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}