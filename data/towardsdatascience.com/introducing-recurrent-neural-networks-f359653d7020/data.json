{"url": "https://towardsdatascience.com/introducing-recurrent-neural-networks-f359653d7020", "time": 1683014031.375614, "path": "towardsdatascience.com/introducing-recurrent-neural-networks-f359653d7020/", "webpage": {"metadata": {"title": "Introducing Recurrent Neural Networks | by Trist'n Joseph | Towards Data Science", "h1": "Introducing Recurrent Neural Networks", "description": "Artificial intelligence (AI) is bridging the gap between technology and humans by allowing machines to automatically learn things from data and become more \u2018human-like\u2019; thus, becoming more\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Artificial intelligence (AI) is bridging the gap between technology and humans by allowing machines to automatically learn things from data and become more \u2018human-like\u2019; thus, becoming more \u2018intelligent\u2019. In this case, intelligence can be considered to be the ability to process information which can be used to inform future decisions. This is ideal because humans can spontaneously put information together by recognizing old patterns, developing new connections, and perceiving something that they have learnt in a new light to develop new and effective processes. When combined with a machine\u2019s computational power, tremendous results can be achieved.", "The combination of automatic learning and computational efficiency can best be described by deep learning. This is a subset of AI and machine learning (ML) where algorithms are made to determine a pattern in data and develop a target function which best maps an input variable, x, to a target variable, y. The goal here is to automatically extract the most useful pieces of information needed to inform future decisions. Deep learning models are very powerful and they can be used to tackle a wide variety of problems; from predicting the likelihood that a student will pass a course, to recognizing an individual\u2019s face to unlock their iPhones using Face ID.", "Deep learning models are built on the idea of \u2018neural networks\u2019, and this is what allows the models to learn from raw data. Simply put, the deep neural network is created by stacking perceptrons, which is a single neuron. Information is propagated forward through this system by having a set of inputs, x, and each input has a corresponding weight, w. The input should also include a \u2018bias term\u2019 which is independent of x. The bias term is used to shift the function being used accordingly, given a problem at hand. Each corresponding input and weight are then multiplied, and the sum of products is calculated. The sum then passes through a non-linear activation function, and an output, y, is generated.", "However, this \u2018feed-forward\u2019 type of model is not always applicable, and their fundamental architecture makes it difficult to apply them to certain scenarios. For example, consider a model that is designed to predict where a flying object will go to next, given a snapshot of that flying object. This is a sequential problem because the object will be covering some distance over time, and the current position of the object will depend on where the object was previously. If no information about the object\u2019s previous position is given, then predicting where the object will go next is no better than a random guess.", "Let us consider another simple, yet important problem: predicting the next word. Models which do this are common now as they are used in applications such as autofill and autocorrect, and they are often taken for granted. This is a sequential task since the most appropriate \u2018next word\u2019 depends on the words which came before it. A feed-forward network would not be appropriate for this task because it would require a sentence with a particular length as an input to then predict the next word. However, this is an issue because we cannot guarantee an input of the same length each time, and the model\u2019s performance would then be negatively affected.", "A potential way to combat this issue is to only look at a subsection of this input sentence, such as the last two words maybe. This combats the issue of variable-length inputs because, despite the total input length, the model will only use the last two words of the sentence to predict the next word. But this is still not ideal because the model now cannot account for long-term dependencies. That is, consider the sentence \u201cI grew up in Berlin and only moved to New York a year ago. I can speak fluent \u2026\u201d. By only considering the last two words, every language would be equally likely. But when the entire sentence is considered, German would be most likely.", "The best way to overcome these issues is to have an entirely new network structure; one that can update information over time. This is a Recurrent Neural Network (RNN). This is similar to a perceptron in that over time, information is being forward through the system by a set of inputs, x, and each input has a weight, w. Each corresponding input and weight are then multiplied, and the sum of products is calculated. The sum then passes through a non-linear activation function, and an output, y, is generated.", "The difference is that, in addition to the output, the network is also generating an internal state update, u. This update is then used when analyzing the next set of input information and provides a different output that is also dependent on the previous information. This is ideal because information persists throughout the network over time. As the name suggests, this update function is essentially a recurrence relation that happens at every step of the sequential process, where u is a function of the previous u and the current input, x.", "The concept of looping through the RNN\u2019s system over time might be a bit abstract and difficult to grasp. Another way to think of an RNN is to actually unfold this system over time. That is, think of the RNN as a set of singular feed-forward models, where each model is linked together by the internal state update. Viewing the RNN like this can truly provide some insight as to why this structure is suitable for sequential tasks. At each step of the sequence, there is an input, some process being performed on that input, and a related output. For the next step of the sequence, the step before must have some influence does not affect the input but affects the related output.", "If we go back to either the flying object scenario or the word prediction scenario, and we consider them using the unfolded RNN, we would be able to understand the solutions more. At each previous position of the flying object, we can predict a possible path. The predicted path updates as the model receives more information about where the object was previously, and this information updates itself to then feed into the future sequences of the model. Similarly, as each new word from the sentence scenario is fed into the model, a new combination of likely words is generated.", "Neural networks are an essential part of AI and ML as they allow models to automatically learn from data, and they combine a version of human learning with great computational ability. However, applying a non-sequential structure to a sequential task will result in poor model performance, and the true power of neural networks would not be harnessed. RNNs are artificial learning systems which internally update themselves based on previous information, in order to predict the most accurate results over time.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist? Yes. Researcher? Somewhat. Content creator? Sure, why not."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff359653d7020&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://trisxcjoseph.medium.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": ""}, {"url": "https://trisxcjoseph.medium.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Trist'n Joseph"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32920ce9f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&user=Trist%27n+Joseph&userId=32920ce9f4b&source=post_page-32920ce9f4b----f359653d7020---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://dspace.mit.edu/bitstream/handle/1721.1/113146/1018306404-MIT.pdf?sequence=1", "anchor_text": "dspace.mit.edu/bitstream/handle/1721.1/113146/1018306404-MIT.pdf?sequence=1"}, {"url": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "anchor_text": "stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks"}, {"url": "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/", "anchor_text": "wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "karpathy.github.io/2015/05/21/rnn-effectiveness/"}, {"url": "https://deeplearning.mit.edu/", "anchor_text": "deeplearning.mit.edu/"}, {"url": "http://neuralnetworksanddeeplearning.com/", "anchor_text": "neuralnetworksanddeeplearning.com/"}, {"url": "https://towardsdatascience.com/what-is-deep-learning-adf5d4de9afc", "anchor_text": "towardsdatascience.com/what-is-deep-learning-adf5d4de9afc"}, {"url": "https://towardsdatascience.com/the-mathematics-behind-deep-learning-f6c35a0fe077", "anchor_text": "towardsdatascience.com/the-mathematics-behind-deep-learning-f6c35a0fe077"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f359653d7020---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f359653d7020---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----f359653d7020---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f359653d7020---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----f359653d7020---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&user=Trist%27n+Joseph&userId=32920ce9f4b&source=-----f359653d7020---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&user=Trist%27n+Joseph&userId=32920ce9f4b&source=-----f359653d7020---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff359653d7020&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f359653d7020---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f359653d7020--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f359653d7020--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f359653d7020--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f359653d7020--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f359653d7020--------------------------------", "anchor_text": ""}, {"url": "https://trisxcjoseph.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://trisxcjoseph.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Trist'n Joseph"}, {"url": "https://trisxcjoseph.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "385 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F32920ce9f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&user=Trist%27n+Joseph&userId=32920ce9f4b&source=post_page-32920ce9f4b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcfd73cacf13a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-recurrent-neural-networks-f359653d7020&newsletterV3=32920ce9f4b&newsletterV3Id=cfd73cacf13a&user=Trist%27n+Joseph&userId=32920ce9f4b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}