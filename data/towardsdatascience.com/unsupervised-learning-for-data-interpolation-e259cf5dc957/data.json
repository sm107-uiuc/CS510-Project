{"url": "https://towardsdatascience.com/unsupervised-learning-for-data-interpolation-e259cf5dc957", "time": 1682993781.454101, "path": "towardsdatascience.com/unsupervised-learning-for-data-interpolation-e259cf5dc957/", "webpage": {"metadata": {"title": "Unsupervised deep learning for data interpolation | by Aliaksei Mikhailiuk | Towards Data Science", "h1": "Unsupervised deep learning for data interpolation", "description": "Real-world data are noisy. Noise can come in the form of incorrect or missing values. This article describes a way of filling missing values with auto-encoders. An auto-encoder is trained on noisy\u2026"}, "outgoing_paragraph_urls": [{"url": "http://earthdoc.eage.org/publication/publicationdetails/?publication=92298", "anchor_text": "seismic data reconstruction", "paragraph_index": 0}, {"url": "https://github.com/mikhailiuk/image_reconstruction", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic Gradient Descend", "paragraph_index": 7}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer", "anchor_text": "Adam", "paragraph_index": 7}, {"url": "https://www.linkedin.com/in/aliakseimikhailiuk/", "anchor_text": "https://www.linkedin.com/in/aliakseimikhailiuk/", "paragraph_index": 16}], "all_paragraphs": ["Real-world data are noisy. Noise can come in the form of incorrect or missing values. This article describes a way of filling missing values with auto-encoders. An auto-encoder is trained on noisy data with no reference values available for missing entries. The procedure is explained on the task of image reconstruction. The method has been successfully applied to seismic data reconstruction in the past. Tensorflow implementation is available here.", "Imagine a situation where data are abundant, however, the data are noisy, and there is no access to the reference. A good example are images, as in Figure 1. Here black dots in the picture are noise \u2014 image values set to 0, and we assume that there is no ground truth data available for them. The type of data is not restricted to images and can be anything, for example, patient records with part of data missing.", "Ideally, if training data with reference is available, we could train the network to reconstruct missing values by comparing reconstruction to the target. But in the case where there are no target data, it is impossible, since comparing reconstruction to 0 (i.e., missing value) doesn\u2019t make sense. Here I discuss a way of training auto-encoders on the task of data reconstruction with no reference available.", "This section gives a quick recap of the neural networks and auto-encoders.", "A simple feedforward Artificial Neural Network (ANN) has several layers. The first layer is an input layer, where data is fed. It is followed by a number of hidden layers. The last is an output layer. Layers consist of basic units \u2014 neurons. Neurons in one layer are connected to neurons in the following layer. Two parameter types are optimized during the process of training: weights, corresponding to every edge connecting neurons, and a bias associated with every neuron. Thus input into a neuron is a linear combination of weighted outputs from neurons in the previous layer and a bias. A neuron\u2019s output is obtained by mapping the input to the neuron to a new space via activation function, e.g., sigmoid. The task of regression can be related to the task of feature learning. In an ANN, a feature is input connections to a single neuron in hidden layers.", "Training is an iterative process split into two stages: feedforward and backpropagation. Feedforward is a process of data being fed into the input and propagating forward through the ANN, resulting in an output. For every layer, this process can be described by:", "where x is an input vector to the current layer, y is an output of the current layer, W is the matrix of weights with Wki = wki and wki is the weight of the connection between xi and yk, b is a vector of biases, and s is an activation function applied element-wise.", "After the feedforward pass the objective function needs to be evaluated, and parameters, minimising it, need to be estimated. A commonly used optimisation method is a Stochastic Gradient Descend (SGD) or Adam optimiser.", "This work considers ANNs based on auto-encoders. The choice is justified by the intention to eliminate any prior assumptions about data. A simple auto-encoder has only one hidden layer with fewer units than the number of inputs. A deep auto-encoder is formed of multiple hidden layers with non-linear activation functions. This structure allows learning abstract features and complex relationships in the deeper layers of the ANN.", "An auto-encoder is split into an encoder - f and a decoder g. The aim of the encoder is to map D-dimensional input x to a generally lower K-dimensional feature space i.e. f(x)=h. The decoder aims to map the feature space back to the original space, such that the input is reconstructed i.e. g(h)=g(f(x))=r(x) ~ x, where r(x) is a reconstruction function.", "Since reference values for missing parts of the signal are not given, the neural network was trained to reconstruct uncorrupted parts of the signal only. The corrupted data is fed into the neural network, however, the error only for the reconstruction of uncorrupted data points is evaluated and used in the backpropagation. This procedure resides on the assumption that patches have different noise distributions. If a signal value is not used in the backpropagation in the current iteration, the subsequent patch fed into the neural network will have values in different positions missing. Thus weights not updated in the current iteration are updated in the subsequent one.", "Since monitoring the goodness of reconstruction during training based on given values is biased, an additional binary validation mask is applied to the data. The validation mask contains 2% noise and is projected on the data. I ensure that missing values in the data and those with value 0 in the validation mask do not overlap. Points corrupted by a validation mask are used during training. After every epoch, the error for values corrupted by the validation mask is calculated using reference values. Every time the validation error reaches a local minimum, the current configuration of the network is saved, and the training is continued.", "The algorithm comprises seven stages (fig. 2). Firstly, data are pre-processed \u2014 scaled between 0 and 1 and split into patches. On the next step, patches are passed through the ANN. Error for clean data is then computed, and the parameters are updated. In the next stage, the validation error is calculated using the validation mask. If the ANN reached the local minima, the current state of the network is saved. This step is skipped if the ANN is not in its minima. In the next step, hyper-parameters are updated and data are shuffled. If the stop condition is satisfied, i.e., the maximum epoch is reached, the reconstruction for missing data is obtained, otherwise, the training is continued.", "Images with low-frequency components are reconstructed better than with high-frequency components, i.e., more complex scenes are harder to reconstruct. Reconstruction is better when larger patches are used, i.e., the network has more information. The worst reconstruction is on edges and corners of patches, where pixels have either five or three neighbors \u2014 in contrast to pixels in the center of the patch, where pixels are surrounded by eight neighbors. A possible solution for that is to use patches of larger sizes and use only the central part for reconstruction. The work can be improved by using CNNs to work on images and tested on RGB images and applied to other data types.", "It is interesting whether the network is capable of generalising, i.e. being trained on one image and reconstructing another. As expected the reconstruction is better, when the reconstructed image is the same as the one used for training. Below are two examples: network trained on baboon and reconstructing peppers and trained on peppers and reconstructing baboon.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer at Snap. Ex-AI Team Lead at Huawei, PhD from University of Cambridge https://www.linkedin.com/in/aliakseimikhailiuk/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe259cf5dc957&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mikhailiuk.medium.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": ""}, {"url": "https://mikhailiuk.medium.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Aliaksei Mikhailiuk"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bef13bba71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=post_page-30bef13bba71----e259cf5dc957---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://earthdoc.eage.org/publication/publicationdetails/?publication=92298", "anchor_text": "seismic data reconstruction"}, {"url": "https://github.com/mikhailiuk/image_reconstruction", "anchor_text": "here"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "Stochastic Gradient Descend"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer", "anchor_text": "Adam"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "http://www.imageprocessingplace.com/root_files_V3/image_databases.htm", "anchor_text": "Standard Test image dataset"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----e259cf5dc957---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----e259cf5dc957---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----e259cf5dc957---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e259cf5dc957---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e259cf5dc957---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=-----e259cf5dc957---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=-----e259cf5dc957---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe259cf5dc957&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e259cf5dc957---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e259cf5dc957--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e259cf5dc957--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e259cf5dc957--------------------------------", "anchor_text": ""}, {"url": "https://mikhailiuk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mikhailiuk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Aliaksei Mikhailiuk"}, {"url": "https://mikhailiuk.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://www.linkedin.com/in/aliakseimikhailiuk/", "anchor_text": "https://www.linkedin.com/in/aliakseimikhailiuk/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bef13bba71&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=post_page-30bef13bba71--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F97a3ec4a4d3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-learning-for-data-interpolation-e259cf5dc957&newsletterV3=30bef13bba71&newsletterV3Id=97a3ec4a4d3c&user=Aliaksei+Mikhailiuk&userId=30bef13bba71&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}