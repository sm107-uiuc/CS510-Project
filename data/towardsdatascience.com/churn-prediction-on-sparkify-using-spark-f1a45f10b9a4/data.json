{"url": "https://towardsdatascience.com/churn-prediction-on-sparkify-using-spark-f1a45f10b9a4", "time": 1683013006.567404, "path": "towardsdatascience.com/churn-prediction-on-sparkify-using-spark-f1a45f10b9a4/", "webpage": {"metadata": {"title": "Churn Prediction for Sparkify Using Spark on AWS cluster | by Tselmeg Chenlemuge | Towards Data Science", "h1": "Churn Prediction for Sparkify Using Spark on AWS cluster", "description": "Churn prediction, namely predicting clients who might want to turn down the service, is one of the most common business applications of machine learning. It is especially important for those\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2#:~:text=Accuracy%20is%20used%20when%20the,and%20False%20Positives%20are%20crucial&text=In%20most%20real%2Dlife%20classification,to%20evaluate%20our%20model%20on.", "anchor_text": "here", "paragraph_index": 34}, {"url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "anchor_text": "AUC", "paragraph_index": 34}, {"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here", "paragraph_index": 41}, {"url": "https://elitedatascience.com/overfitting-in-machine-learning", "anchor_text": "overfitting", "paragraph_index": 42}, {"url": "https://elitedatascience.com/overfitting-in-machine-learning", "anchor_text": "other methods", "paragraph_index": 43}, {"url": "https://towardsdatascience.com/when-cross-validation-fails-9bd5a57f07b5#:~:text=Cross%20Validation%20is%20usually%20a,result%20in%20worse%20performance%20measures.&text=This%20resulted%20in%20worse%20cross%20validation%20performance.", "anchor_text": "link", "paragraph_index": 45}, {"url": "https://medium.com/@dhiraj.p.rai/essentials-of-feature-engineering-in-pyspark-part-i-76a57680a85", "anchor_text": "some techniques", "paragraph_index": 49}, {"url": "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114", "anchor_text": "feature engineering", "paragraph_index": 49}, {"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here", "paragraph_index": 50}, {"url": "https://www.linkedin.com/in/tselmeg-chenlemuge/", "anchor_text": "LinkedIn", "paragraph_index": 53}, {"url": "https://github.com/Tselmeg-C", "anchor_text": "Github", "paragraph_index": 53}], "all_paragraphs": ["Churn prediction, namely predicting clients who might want to turn down the service, is one of the most common business applications of machine learning. It is especially important for those companies providing streaming services. In this project, an event data set from a fictional music streaming company named Sparkify was analyzed. A tiny subset (128MB) of the full dataset (12GB) was first analyzed locally in Jupyter Notebook with a scalable script in Spark and the whole data set was analyzed on the AWS EMR cluster. Find the code here.", "Let\u2019s first have a look at the data. There were 286500 rows and 18 columns in the mini data set (in the big data set, there were 26259199 rows). The columns and first five rows were shown as follows.", "Let\u2019s check missing values in the data set. We will find a pattern from the table below in the missing values: There was the same number of missing values in the \u201cartist\u201d,\u201d length\u201d, and the \u201dsong\u201d columns, and the same number of missing values in the \u201cfirstName\u201d, \u201cgender\u201d, \u201clastName\u201d, \u201clocation\u201d,\u201d registration\u201d, and \u201duserAgent\u201d columns.", "If we see closer at the \u201cuserId\u201d, whose \u201cfirstName\u201d was missing, we will find that those \u201cuserId\u201d was actually empty strings (in the bid data was the user with the ID 1261737), with exactly 8346 records (with 778479 rows in the bid data), which I decided to treat as missing values and deleted. This might be someone who has only visited the Sparkify website without registering.", "After deleting the \u201cproblematic\u201d userId, there was 255 unique users left (this number was 22277 for the big data).", "Let\u2019s dig further on remaining missing values. As the data is event data, which means every operation of single users was recorded. I hypothesized that those missing values in the \u201cartist\u201d column might have an association with the certain actions (page visited) of the users, that\u2019s why I check the visited \u201cpages\u201d associated with the missing \u201cartist\u201d and compared with the \u201cpages\u201d in the complete data and found that: \u201cmissing artist\u201d is combined with all the other pages except \u201cnext song\u201d, which means the \u201cartist\u201d (singer of the song) information is recorded only when a user hit \u201cnext song\u201d.", "If I delete those \u201cnull\u201d artist rows, there will be no missing values anymore in the data set and unique users number in the clean data set will still be 255.", "After dealing with missing values, I transformed timestamp into epoch date, and simplified two categorical columns, extracting only \u201cstates\u201d information from the \u201clocation\u201d column and platform used by the users (marked as \u201cagent\u201d) from the \u201cuserAgent\u201d column.", "The data cleaning step is completed so far, and let\u2019s start to explore the data and find out more information. As the final purpose is to predict churn, we need to first label the churned users (downgrade was also labeled in the same method). I used the \u201cCancellation Confirmation\u201d events to define churn: those churned users who visited the \u201cCancellation Confirmation\u201d page was marked as \u201c1\u201d, and who did not was marked as \u201c0\u201d. Similarly who visited page \u201cDowngrade\u201d at least once was marked as \u201c1\u201d, and who did not was marked as \u201c0\u201d. Now the data set with 278154 rows and columns shown below is ready for some exploratory analysis. Let\u2019s do some comparisons between churned and stayed users.", "There were 52 churned and 173 stayed users in the small data set (those numbers were 5003 and 17274 respectively for the big data), with slightly more males than females in both groups (left figure below). It seemed that among the stayed users there were more people who have downgraded their account at least once (right figure below).", "The \u201clevel\u201d column has two values \u201cfree\u201d and \u201cpaid\u201d. Some users might have changed their level more than once. To check how \u201clevel\u201d has differed between churned and stayed users, a \u201cvalid_level\u201d column was created to record the latest level of users. As shown in the figure below, there are more paid users among the stayed users.", "The stayed users registered for more days than the churned users apparently, and the stayed users played on average more songs than the churned users both on a daily and a session base.", "As shown below, the daily average item per session was slightly higher for stayed users than churned users.", "The average session duration was also longer for stayed users than churned users.", "To analyze how the user activities differ between churned and stayed users, the daily average numbers of \u201cthumbs up\u201d, \u201cadd to playlist\u201d, \u201cadd friend\u201d, \u201croll adverts\u201d, and\u201d thumbs down\u201d for each user were calculated. Those features were selected because they were the most visited pages among others (see table below).", "As a result, churned users added fewer friends, gave less \u201cthumbs up\u201d, and added fewer songs into their playlists on a daily base than stayed users. While the churned users gave more \u201cthumbs down\u201d and rolled over more advertisements daily than stayed users.", "The platform (marked as \u201cagent\u201d in the table) used by users are plotted below. It appeared that the churning rates were different among the six agents. It means the platform on which the users are using Sparkify\u2019s service might influence churn.", "Similarly, the churning rates seemed to be changing in different states (see figure below).", "Before fitting any model, the following columns were assembled to create the final data set df_model for modeling.", "label: 1 for churned and 0 for not", "downgraded: 1 for downgraded and 0 for not", "gender: M for male and F for female", "agent: platform used by users with five categories (windows, macintosh, iPhone, iPad, and compatible)", "registered_days: counted by the maximum value of \u201cts\u201d (timestamp of actions) subtracted by \u201cregistration\u201d timestamp and transformed to days", "avg_daily_song: average song listened on a daily base", "songs_per_session: average songs listened per session", "friends: daily number of friends added by a user", "thumbs up: daily number of thumbs up given by a user", "thumbs down: daily number of thumbs down given by a user", "add_playlist: daily number of \u201cadd to playlist\u201d action", "roll_advert: daily number of \u201croll advert\u201d action", "Categorical variables \u2018gender\u2019,\u2019valid_level\u2019, and \u2019agent\u2019 were first transformed into indexes using the StringIndexer.", "And the numeric variables were first assembled into a vector using VectorAssembler and then scaled using StandardScaler.", "In the end, all the categorical and numeric features were combined and again transformed into a vector.", "As the goal was to predict a binary result (1 for churn and 0 for not), logistic regression, random forest, and gradient boosted tree classifiers were selected to fit the data set. F1 score and AUC were calculated as evaluation metrics. Because our training data was imbalanced (there were fewer churned than stayed users). And from the perspective of the company, incorrectly identifying a user who was going to churn is more costly. In this case, F1-score is a better metric than accuracy, because it provides a better measure of the incorrectly classified cases (for more information click here). AUC, on the other hand, gives us a perspective over how good the model is regarding the separability, in another word, distinguishing 1 (churn) from 0 (stay).", "The data set was first broke into 80% of training data and 20% as a test set.", "There were more stayed users than churned users in the whole data set, and in our training set the number of churned is 42, which represents only around 22% of total users. To solve this imbalance problem and get better prediction results, class_weights values were introduced into the model.", "A logistic regression model with weighed features was built like the following and BinaryClassificationEvaluator was used to evaluate the model.", "The scores of the logistic regression model were like the following:", "And the feature importance is shown as the following. The feature registered days, the average number of songs listened per session, and the average session duration was negatively associated with churn, while the average number of songs listened per session and the action of downgraded was positively associated with churn. In another word, users who listen to more songs per day and downgraded at least once are more likely to churn. Whereas, the longer one session lasts and the more songs one listens per session, the less likely for this user to churn.", "It sounds a bit irrational that, the more songs one listens per day, the more likely for him to churn. To draw a safe conclusion, I would include more samples to fit the model again. This will be the future work.", "In a similar manner, a random forest model was fit into the training data, refer the original code here. And the metrics were as the following:", "There is obviously an overfitting problem. Both the F1 and AUC scores were very high for the training set and poorer in the test set. The feature importance analysis showed: Besides registered days and songs listened per day, the number of friends added, thumbs up, and thumbs down given on a daily base were the most important features regarding churn prediction. As future work, I would fit this model again on the big data set to see if adding samples will solve the overfitting problem.", "GBT model showed a more severe overfitting problem. A suggestion for improvement will be the same as mentioned before. Try on the big data set first, if necessary do finer feature engineering or try other methods.", "According to the F1 and AUC scores of all three models, I decided to pick the logistic regression model to do further hyperparameter tuning and 3-fold cross-validation.", "However, except for an obvious improvement in model performance on the training set. Both the F1 and AUC scores were lower on the test set. For an overfitting situation, parameter tuning was a bit tricky, and cross-validation did not help in this case to improve model performance, check the link here which might through some insight into this problem.", "Feature importance of logistic regression after parameter tuning and cross-validation showed a different pattern from before. The registered day was the most promising indicator of churn (this information might with little interest to the service provider company). Besides, the number of thumbs-ups, friends added, thumbs-downs and roll advert were the features with the highest importance.", "In this project, churn prediction was performed based on an event data set for a music streaming provider. This was basically a binary classification problem. After loading and cleaning data, I performed some exploratory analysis and provided insights on the next step of feature engineering. All together 13 explanatory features were selected and logistic regression, random forest, and gradient-boosted tree models were fitted respectively to a training data set.", "The model performance was the best for the logistic regression on small data set, with an F1 score of 73.10 on the test set. The other two models were both suffered from overfitting. Hyperparameter tuning and cross-validation was not very helpful in solving overfitting, probably because of a small number of sample size. Due to time and budget limitations, the final models were not tested on the big data set. However, the completely scalable process shed a light on solving the churn prediction problem on big data with Spark on Cloud.", "How to chose the proper explanatory features was one of the most critical steps in this task. After EDA, I simply included all the features that I created. I wanted to create more features, however, the further computation was dragged down by limited computation capacity. There are some techniques ( for example the ChiSqSelector provided by Spark ML) on feature engineering that might help in this step. The \u201cstate\u201d column had 58 different values (100 for the big data). I tried to turn them into index values using StringIndexer and include it to the explanatory feature. However, it was not possible to build a random forest/GBTs model with indexes exceeded the maxBins (= 32), that\u2019s why I had to exclude this feature. If it was possible to use the dummy variable of this feature, the problem could have been avoided. It was a pity that I run out of time and did not manage to do a further experiment.", "Most of the time I spent on this project was \u201cwaiting\u201d for the result. It was very frustrating that I had to stop and run the codes from the beginning over and over again due to stage errors because the cluster was running out of memory. To solve this problem, I had to separate my code into two parts (one for modeling) and the other for plotting and run them separately. And I have to reduce the number of explanatory variables that I created. It was a pity that I only managed once to run the simple version of code for the big data set on AWS cluster (refer to the code here) and had to stop because it took too much time and cost. The scores of the build models on the big data set were unfortunately not satisfying. However, the last version of codes (Sparkify_visualization and Sparkify_modeling in Github repo) should be completely scalable. The performance of models on big data set should be improved if the latest codes are to be run on the big data again.", "Because the training data set is imbalanced with more \u201c0\u201d labeled rows than \u201c1\u201d, I wanted to try if randomly selecting the same number of \u201c0\u201d rows as \u201c1\u201d rows would have improved the model performance. Due to the time limit, it will be only the work for the future.", "ps: one extra tip which might be very useful, perform \u201ccache\u201d on critical points to speed up the program.", "Any discussion is welcome! Please reach me through LinkedIn and Github", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ph.D. in Ecology, Data Scientist, challenge lover, problem solver"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff1a45f10b9a4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@chenlemuge?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chenlemuge?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Tselmeg Chenlemuge"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3195020a7184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&user=Tselmeg+Chenlemuge&userId=3195020a7184&source=post_page-3195020a7184----f1a45f10b9a4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://upswell.org/2018/10/01/what-the-heck-is-a-spark-talk/", "anchor_text": "https://upswell.org/2018/10/01/what-the-heck-is-a-spark-talk/"}, {"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here"}, {"url": "https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2#:~:text=Accuracy%20is%20used%20when%20the,and%20False%20Positives%20are%20crucial&text=In%20most%20real%2Dlife%20classification,to%20evaluate%20our%20model%20on.", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5", "anchor_text": "AUC"}, {"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here"}, {"url": "https://elitedatascience.com/overfitting-in-machine-learning", "anchor_text": "overfitting"}, {"url": "https://elitedatascience.com/overfitting-in-machine-learning", "anchor_text": "other methods"}, {"url": "https://towardsdatascience.com/when-cross-validation-fails-9bd5a57f07b5#:~:text=Cross%20Validation%20is%20usually%20a,result%20in%20worse%20performance%20measures.&text=This%20resulted%20in%20worse%20cross%20validation%20performance.", "anchor_text": "link"}, {"url": "https://medium.com/@dhiraj.p.rai/essentials-of-feature-engineering-in-pyspark-part-i-76a57680a85", "anchor_text": "some techniques"}, {"url": "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114", "anchor_text": "feature engineering"}, {"url": "https://github.com/Tselmeg-C/Churn_prediction_Udacity_Capstone.git", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/tselmeg-chenlemuge/", "anchor_text": "LinkedIn"}, {"url": "https://github.com/Tselmeg-C", "anchor_text": "Github"}, {"url": "https://medium.com/tag/churn-prediction?source=post_page-----f1a45f10b9a4---------------churn_prediction-----------------", "anchor_text": "Churn Prediction"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f1a45f10b9a4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/spark?source=post_page-----f1a45f10b9a4---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----f1a45f10b9a4---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/aws?source=post_page-----f1a45f10b9a4---------------aws-----------------", "anchor_text": "AWS"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&user=Tselmeg+Chenlemuge&userId=3195020a7184&source=-----f1a45f10b9a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&user=Tselmeg+Chenlemuge&userId=3195020a7184&source=-----f1a45f10b9a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff1a45f10b9a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f1a45f10b9a4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f1a45f10b9a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chenlemuge?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chenlemuge?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tselmeg Chenlemuge"}, {"url": "https://medium.com/@chenlemuge/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "21 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3195020a7184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&user=Tselmeg+Chenlemuge&userId=3195020a7184&source=post_page-3195020a7184--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F3195020a7184%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchurn-prediction-on-sparkify-using-spark-f1a45f10b9a4&user=Tselmeg+Chenlemuge&userId=3195020a7184&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}