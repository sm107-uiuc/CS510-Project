{"url": "https://towardsdatascience.com/linear-mixed-model-from-scratch-f29b2e45f0a4", "time": 1683012265.468163, "path": "towardsdatascience.com/linear-mixed-model-from-scratch-f29b2e45f0a4/", "webpage": {"metadata": {"title": "Linear Mixed Model from Scratch. Derive and code LMM using Maximum\u2026 | by Nikolay Oskolkov | Towards Data Science", "h1": "Linear Mixed Model from Scratch", "description": "This is the eighteenth article from the column Mathematical Statistics and Machine Learning for Life Sciences where I try to explain some mysterious analytical techniques used in Bioinformatics and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences?source=post_page---------------------------", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/how-linear-mixed-model-works-350950a82911", "anchor_text": "How Linear Mixed Model Works", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-test", "anchor_text": "paired t-test", "paragraph_index": 1}, {"url": "https://www.statisticssolutions.com/assumptions-of-linear-regression/", "anchor_text": "normally distributed residuals", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/how-linear-mixed-model-works-350950a82911", "anchor_text": "previously", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-test", "anchor_text": "paired t-test", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test", "anchor_text": "Wilcoxon signed-rank test", "paragraph_index": 3}, {"url": "https://stats.stackexchange.com/questions/22988/how-to-obtain-the-p-value-check-significance-of-an-effect-in-a-lme4-mixed-mode", "anchor_text": "do not provide measures", "paragraph_index": 6}, {"url": "https://www.maplesoft.com/", "anchor_text": "Maple", "paragraph_index": 20}, {"url": "https://www.wolfram.com/mathematica/", "anchor_text": "Mathematica", "paragraph_index": 20}, {"url": "https://www.mathworks.com/products/matlab.html", "anchor_text": "Matlab", "paragraph_index": 20}, {"url": "https://github.com/NikolayOskolkov/LMMFromScratch", "anchor_text": "Github", "paragraph_index": 26}, {"url": "https://medium.com/u/8570b484f56c?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Nikolay Oskolkov", "paragraph_index": 26}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186?source=post_page---------------------------", "anchor_text": "Linkedin", "paragraph_index": 26}], "all_paragraphs": ["This is the eighteenth article from the column Mathematical Statistics and Machine Learning for Life Sciences where I try to explain some mysterious analytical techniques used in Bioinformatics and Computational Biology in a simple way. Linear Mixed Model (also called Linear Mixed Effects Model) is widely used in Life Sciences, there are many tutorials showing how to run the model in R, however it is sometimes unclear how exactly the Random Effects parameters are optimized in the likelihood maximization procedure. In my previous post How Linear Mixed Model Works I gave an introduction to the concepts of the model, and in this tutorial we will derive and code the Linear Mixed Model (LMM) from scratch applying the Maximum Likelihood (ML) approach, i.e. we will use plain R to code LMM and compare the output with the one from lmer and lme R functions. The goal of this tutorial is to explain LMM \u201clike for my grandmother\u201d implying that people with no mathematical background should be able to understand what LMM does under the hood.", "Let us consider a toy data set which is very simple but still keeps all necessary elements of the typical setup for Linear Mixed Modelling (LMM). Suppose we have only 4 data points / samples: 2 originating from Individual #1 and the other 2 coming from Individual #2. Further, the 4 points are spread between two conditions: untreated and treated. Let us assume we measure a response (Resp) of each individual to the treatment, and would like to address whether the treatment resulted in a significant response of the individuals in the study. In other words, we are aiming to implement something similar to the paired t-test and assess the significance of treatment. Later we will relate the outputs from LMM and paired t-test and show that they are indeed identical. In the toy data set, 0 in the Treat column implies \u201cuntreated\u201d, and 1 means \u201ctreated\u201d. First, we will use a naive Ordinary Least Squares (OLS) linear regression that does not take relatedness between the data points into account.", "Technically it works, however, this is not a good fit, we have a problem here. Ordinary Least Squares (OLS) linear regression assumes that all observations (data points on the plot) are independent, that should result in uncorrelated and hence normally distributed residuals. However, we know that the data points on the plot belong to 2 individuals, i.e. 2 points for each individual. In principal, we can fit a linear model for each individual separately. However, this is not a good fit either. We have two points for each individual, so too few to make a reasonable fit for each individual. In addition, as we saw previously individual fits do not say much about the overall / population profile as some of them may have opposite behavior compared to the rest of individual fits.", "In contrast, if we want to fit all the four data points together we will need to somehow account for the fact that they are not independent, i.e. two of them belong to the Individual #1 and two belong to the Individual #2. This can be done within the Linear Mixed Model (LMM) or a paired test, e.g. paired t-test (parametric) or Wilcoxon signed-rank test (non-parametric).", "We use LMM when there is a non-independence between observations. In our case, the observations cluster within individuals. Let us apply LMM with Fixed Effects for slopes and intercepts and Random Effects for intercepts, this will result in adding a (1 | Ind) term to the Resp ~ Treat formula:", "Here REML=FALSE simply means that we are using the traditional Maximum Likelihood (ML) optimization and not Restricted Maximum Likelihood (we will talk about REML another time). In the Random Effects section of the lmer output, we see estimates for 2 parameters of minimization: residual variance corresponding to the standard deviation (Std.Dev.) of 4.243, and the random effects (shared between individuals) variance associated with the Intercept with the standard deviation of 5.766. Similarly, in the Fixed Effects section of the lmer output we can see two estimates for: 1) Intercept equal to 6.5, and 2) Slope / Treat equal to 9. Therefore, we have 4 parameters of optimization that correspond to 4 data points. The values of Fixed Effects make sense if we look at the very first figure in the Toy Data Set section and realize that the mean of two values for untreated samples is (3 + 10) / 2 =6.5, we will denote it as \u03b21, and the mean of treated samples is (6 + 25) / 2 = 15.5, let us denote it as \u03b22. The latter would be equivalent to 6.5 + 9, i.e. the estimate for the Fixed Effect of Intercept (=6.5) plus the estimate for the Fixed Effect of Slope (=9). Here, we pay attention to the exact values of Random and Fixed effects because we are going to reproduce them later when deriving and coding LMM.", "By default, lme4 R package and lmer R function do not provide measures of statistical significance such as p-values, however if you still would like to have a p-value of your LMM fit, it is possible to use lme function from the nlme R package:", "Again, here we have Random Effects for Intercept (StdDev = 5.766264) and Residual (StdDev = 4.242649), and Fixed Effects for Intercept (Value = 6.5) and Slope / Treat (Value = 9). Quite interesting, the standard errors of Fixed Effects and hence their t-values (t-value=1.5 for Treat) do not agree between lmer and lme. However, if we demand REML=TRUE in the lmer function, the Fixed Effects statistics including t-values are identical between lme and lmer, however the Random Effects statistics are different.", "This is the difference between the Maximum Likelihood (ML) and Restricted Maximum Likelihood (REML) approaches that we will cover next time.", "Previously, we said that LMM is a more complex form of a simple paired t-test. Let us demonstrate that for our toy data set they do give identical outputs. On the way, we will also understand the technical difference between paired and un-paired t-tests. Let us first run the paired t-test between the treated and un-treated groups of samples taking into account the non-independence between them:", "We can see that the t-value=1.5 and p-value = 0.3743 reported by the paired t-test are identical to the ones obtained by LMM using the nlme function or lmer with REML = TRUE. The reported by the paired t-test statistic \u201cmean of the differences = 9\u201d also agrees with the Fixed Effect estimates from lmer and nlme, remember we had the Treat Estimate = 9 that was simply the difference between the means of the treated and untreated samples.", "Now, what is the paired t-test exactly doing? Well, the idea of the paired t-test is to make the setup look like a one-sample t-test where values in one group are tested for significant deviation from zero, which is a sort of the mean of the second group. In other words, we can view a paired t-test as if we shift the intercepts of the individual fits (see the very first figure) or the mean values of the untreated group down to zero. In a simple way, this would be equivalent to subtracting untreated Resp values from the treated ones, i.e. transforming the Resp variable to Resp_std (standardized Response) as shown below, and then performing an un-paired t-test on the Resp_std variable instead of Resp:", "We observe that the values of Response became 0 for Treat = 0, i.e. untreated group, while the Response values of the treated group (Treat=1) are reduced by the values of the untreated group. Then we simply used the new Resp_std variable and ran an un-paired t-test, the result is equivalent to running paired t-test on the original Resp variable. Therefore, we can summarize that LMM reproduces the result of the paired t-test but allows for much more flexibility, for example, not only two (like for t-test) but multiple groups comparison etc.", "Let us now try to derive a few LMM equations using our toy data set. We will again have a look at the 4 data points and make some mathematical notations accounting for treatment effects, \u03b2, which is nothing else than Fixed Effects, and the block-wise structure u due to points clustering within two individuals, which is actually the Random Effects contribution. We are going to express the Response (Resp) coordinates y in terms of \u03b2 and u parameters.", "Here, \u03b21 is the Response of the individuals in the Untreated state, while \u03b22 is the Response on the Treatment. One can also say, that \u03b21 is the mean of the untreated samples while \u03b22 is the mean of the treated samples. The variables u1 and u2 are block variables accounting for effects specific to Individual #1 and Individual #2, respectively. Finally, \u03f5ij \u223c N(0, \u03c3\u00b2) is the Residual error, i.e. the error we can\u2019t model and can only try to minimize it as the goal of the Maximum Likelihood optimization problem. Therefore, we can write down the Response variable y as a combination of parameters \u03b2, u, i.e. Fixed and Random Effects, and \u03f5 as Eq. (1). In a general form, this system of algebraic equations can be rewritten as Eq. (2), where the index i = 1, 2 corresponds to treatment effects and j = 1, 2 describes individual effects. We can also express this system of equations in the matrix form Eq. (3). Therefore we arrive to the following famous matrix form of LMM which is shown in all textbooks but not always properly explained, Eq. (4).", "Here, X is called the design matrix and K is called the block matrix, it codes the relationship between the data points, i.e. whether they come from related individuals or even from the same individual like in our case. It is important to note that the treatment is modeled as a fixed effect because the levels treated-untreated exhaust all possible outcomes of treatment. In contrast, the block-wise structure of the data is modeled as a Random Effect since the individuals were sampled from population, and might not correctly represent the entire population of individuals. In other words, there is an error associated with the random effects, i.e. uj \u223c N(0, \u03c3s\u00b2), while fixed affects are assumed to be error free. For example, sex is usually modeled as a Fixed Effect because it is usually assumed to have only two levels (males, females), while batch-effects in Life Sciences should be modeled as Random Effects because potentially additional experimental protocols or labs would produce many more, that is many levels, systematic differences between samples that confound the data analysis. As a rule of thumb one could think that Fixed Effects should not have many levels, while Random Effects are typically multi-level categorical variables where the levels represent just a sample of all possibilities but not all of them.", "Let us proceed with deriving the mean and the variance of the data points Y. Since both the Random Effect error and the Residual error come from Normal distribution with zero mean, while the non-zero component in E[Y] originates from the Fixed Effect, we can express the expected value of Y as Eq. (5). Next, the variance of the Fixed Effect term is zero, as Fixed Effects are assumed to be error free, therefore, for the variance of Y we obtain Eq. (6).", "Eq. (6) was obtained by taking into account that var(Ku)=K*var(u)*K^T and var(\u03f5) = \u03c3\u00b2*I and var(u)= \u03c3s\u00b2*I, where I is a 4 x 4 identity matrix. Here, \u03c3\u00b2 is the Residual variance (unmodeled/unreduced error), and \u03c3s\u00b2 is the random Intercept effects (shared across data points) variance. The matrix in front of \u03c3s\u00b2 is called the kinship matrix and is given by Eq. (7). The kinship matrix codes all relatedness between data points. For example, some data points may come from genetically related people, geographic locations in close proximity, some data points may come from technical replicates. Those relationships are coded in the kinship matrix. Thus, the variance-covariance matrix of the data points from Eq. (6) takes the ultimate form of Eq. (8). Once we have obtained the variance-covariance matrix, we can continue with optimization procedure of the Maximum Likelihood function that requires the variance-covariance.", "Why did we spend so much time deriving the variance-covariance matrix and what does it have to do with the linear regression? It turns out that the whole concept of fitting a linear model, as well as many other if not all concepts of traditional Frequentist statistics, comes from the Maximum Likelihood (ML) principle. For this purpose, we need to maximize the Multivariate Gaussian distribution function with respect to parameters \u03b21, \u03b22, \u03c3s\u00b2 and \u03c3\u00b2, Eq. (9).", "Here |\u03a3y| denotes the determinant of the variance-covariance matrix. We see that the inverse matrix and determinant of the variance-covariance matrix are explicitly included into the Likelihood function, this is why we had to compute its expression via the random effects variance \u03c3s\u00b2 and residual variance \u03c3\u00b2. Maximization of the Likelihood function is equivalent to minimization of the log-likelihood function, Eq. (10).", "We will need to perform a tedious symbolic derivation of the determinant of the variance-covariance matrix, the inverse variance-covariance matrix and the product of the inverse variance-covariance matrix with Y\u2212X\u03b2 terms. To my experience, this is hard to do in R / Python, however we can use Maple (or similarly Mathematica or Matlab) for making symbolic calculations, and derive the expressions for determinant and inverse of the variance-covariance matrix:", "Using Maple we can obtain the determinant of the variance-covariance matrix as Eq. (11). Next, the last term in Eq. (10) for log-likelihood takes the form of Eq. (12).", "Now we are ready to perform the numeric minimization of the log-likelihood function with respect to \u03b21, \u03b22, \u03c3s\u00b2 and \u03c3\u00b2 using the optim R function:", "We can see that the minimization algorithm has successfully converged since we got the \u201cconvergence = 0\u201d message. In the output, \u03c3=4.242640687 is the residual standard deviation, which exactly reproduces the result from lme and lmer (with REML = FALSE). By analogy, \u03c3s=5.766281297 is the shared standard deviation that again exactly reproduces the corresponding Random Effects Intercept outputs from lme and lmer (with REML = FALSE) functions. As expected, the Fixed Effect \u03b21 = 6.5 is the mean of the untreated samples in agreement with the Intercept Fixed Effect Estimate from lmer and lme. Next, \u03b22 = 15.5 is the mean of treated samples, which is the Intercept Fixed Effect Estimate (= 6.5) plus the Slope / Treat Fixed Effect Estimate (= 9) from lmer and lme R functions.", "Fantastic job! We have successfully reproduced the Fixed Effects and Random Effects outputs from lmer / lme functions by deriving and coding the Linear Mixed Model (LMM) from scratch!", "In this article, we have learnt how to derive and code a Linear Mixed Model (LMM) with Fixed and Random Effects on a toy data set. We covered the relation between LMM and the paired t-test, and reproduced the Fixed and Random Effects parameters from lmer and lme R functions.", "In the comments below, let me know which analytical techniques from Life Sciences seem especially mysterious to you and I will try to cover them in the future posts. Check the codes from the post on my Github. Follow me at Medium Nikolay Oskolkov, in Twitter @NikolayOskolkov and do connect in Linkedin. In the next post, we are going to cover the difference between the Maximum Likelihood (ML) and Restricted Maximum Likelihood (REML) approaches, stay tuned.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff29b2e45f0a4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c----f29b2e45f0a4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences"}, {"url": "https://unsplash.com/photos/iar-afB0QQw", "anchor_text": "Image source"}, {"url": "https://towardsdatascience.com/tagged/stats-ml-life-sciences?source=post_page---------------------------", "anchor_text": "Mathematical Statistics and Machine Learning for Life Sciences"}, {"url": "https://towardsdatascience.com/how-linear-mixed-model-works-350950a82911", "anchor_text": "How Linear Mixed Model Works"}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-test", "anchor_text": "paired t-test"}, {"url": "https://www.statisticssolutions.com/assumptions-of-linear-regression/", "anchor_text": "normally distributed residuals"}, {"url": "https://towardsdatascience.com/how-linear-mixed-model-works-350950a82911", "anchor_text": "previously"}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-test", "anchor_text": "paired t-test"}, {"url": "https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test", "anchor_text": "Wilcoxon signed-rank test"}, {"url": "https://stats.stackexchange.com/questions/22988/how-to-obtain-the-p-value-check-significance-of-an-effect-in-a-lme4-mixed-mode", "anchor_text": "do not provide measures"}, {"url": "https://www.maplesoft.com/", "anchor_text": "Maple"}, {"url": "https://www.wolfram.com/mathematica/", "anchor_text": "Mathematica"}, {"url": "https://www.mathworks.com/products/matlab.html", "anchor_text": "Matlab"}, {"url": "https://github.com/NikolayOskolkov/LMMFromScratch", "anchor_text": "Github"}, {"url": "https://medium.com/u/8570b484f56c?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "http://linkedin.com/in/nikolay-oskolkov-abb321186?source=post_page---------------------------", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f29b2e45f0a4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f29b2e45f0a4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----f29b2e45f0a4---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/stats-ml-life-sciences?source=post_page-----f29b2e45f0a4---------------stats_ml_life_sciences-----------------", "anchor_text": "Stats Ml Life Sciences"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----f29b2e45f0a4---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----f29b2e45f0a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&user=Nikolay+Oskolkov&userId=8570b484f56c&source=-----f29b2e45f0a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff29b2e45f0a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f29b2e45f0a4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f29b2e45f0a4--------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nikolay-oskolkov.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nikolay Oskolkov"}, {"url": "https://nikolay-oskolkov.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8570b484f56c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&user=Nikolay+Oskolkov&userId=8570b484f56c&source=post_page-8570b484f56c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff4a74ad409c6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-mixed-model-from-scratch-f29b2e45f0a4&newsletterV3=8570b484f56c&newsletterV3Id=f4a74ad409c6&user=Nikolay+Oskolkov&userId=8570b484f56c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}