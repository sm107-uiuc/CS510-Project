{"url": "https://towardsdatascience.com/how-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5", "time": 1682993861.397419, "path": "towardsdatascience.com/how-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5/", "webpage": {"metadata": {"title": "Reaching for the gut of Machine Learning: A brief intro to CLT | by Tirthajyoti Sarkar | Towards Data Science", "h1": "Reaching for the gut of Machine Learning: A brief intro to CLT", "description": "Knowing the fundamentals of the computational learning theory can empower you immensely as a practitioner of machine learning."}, "outgoing_paragraph_urls": [{"url": "https://www.netlanguages.com/blog/index.php/2017/06/28/what-is-inductive-learning/", "anchor_text": "inductively learning", "paragraph_index": 8}, {"url": "https://www.geeksforgeeks.org/proposition-logic/", "anchor_text": "propositional logic", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/where-did-the-least-square-come-from-3f1abc7f7caf", "anchor_text": "it is able to find the optimal line", "paragraph_index": 30}, {"url": "https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture28-pac.pdf", "anchor_text": "PAC-learnable", "paragraph_index": 46}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.6931", "anchor_text": "Haussler bound", "paragraph_index": 49}, {"url": "http://disi.unitn.it/moschitti/Teaching-slides/VC-dim.pdf", "anchor_text": "VC-dimension", "paragraph_index": 51}, {"url": "https://en.wikipedia.org/wiki/Vladimir_Vapnik", "anchor_text": "Vladimir Vapnik", "paragraph_index": 51}, {"url": "https://github.com/tirthajyoti?tab=repositories", "anchor_text": "GitHub repositories", "paragraph_index": 54}, {"url": "https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/", "anchor_text": "add me on LinkedIn", "paragraph_index": 54}, {"url": "https://twitter.com/tirthajyotiS", "anchor_text": "follow me on Twitter.", "paragraph_index": 54}], "all_paragraphs": ["Suppose, it is a sunny day, you have friends visiting and your favorite restaurant opened a branch \u2014 12 miles away. Generally, you avoid long drives, but would to go out for lunch today? Do you have past examples of this kind of situation (some factors are positive and some are negative) from which you have formulated a rule?", "This is how we learn from past experiences and actions, form rules, and apply them to present situations. Machines are no different either. But there is also a theory behind this kind of machine learning.", "Computational Learning Theory (CLT) is a branch of statistics/machine learning/artificial intelligence (in general) which deals with fundamental bounds and theorems about analyzing our (man and machine) ability to learn rules and patterns from data.", "It goes beyond the realm of specific algorithms that we regularly hear about \u2014 regression, decision trees, support vector machines or deep neural network \u2014 and tries to answer fundamental questions about the limits and possibilities of the whole enterprise of machine learning.", "This is how we learn from past experiences and actions, form rules, and apply them to present situations. Machines are no different either", "Sounds exciting? Please read on for a quick tour of this realm\u2026", "When studying machine learning it is natural to wonder what general laws may govern machine (and non-machine) learners. For example,", "Here is the disappointing answer: General answers to all these questions are not yet known.", "But we can focus on a particular setting which comes up most often in any practical machine learning task, that of \u2014 inductively learning an unknown target function, given only training examples of this target function and a set of candidate hypotheses.", "Within this setting, we are chiefly concerned with questions such as,", "As we shall see, it is possible to set quantitative bounds on these measures, depending on attributes of the learning problem such as,", "CLT tries to answer fundamental questions about the limits and possibilities of the whole enterprise of machine learning.", "For the sake of a comprehensive discussion, here is my attempt to define the basic keywords generally used in CLT.", "Data: A given set of examples from which we are trying to learn a target concept.", "Target concept (aka rule): This is the hidden pattern we are trying to learn from the data for example \u2014 \u201cWe go out for lunch IF it is sunny AND we got friends OR IF favorite cuisine restaurant is nearby AND we got friends AND even IF it is NOT sunny\u201d\u2026", "This kind of rule is written in terms of statements belonging to propositional logic i.e. Truth values expressed with AND, OR, NOT.", "Hypothesis space: This is a set of hypotheses from which we hope to discover the target concept. In this example, the \u2018intelligent\u2019 choice of hypotheses should look like the logically connected phrase we wrote above as the target concept. But they could be simpler or different looking such as,", "Note the subtle difference between the two hypotheses above and the target concept. These two hypotheses are not rich enough to capture the true target concept and they will have errors if applied to the given data.", "Because they are not of the form \u201cconjunction of disjunctive statements\u201d i.e. (X1 & X2) | (X3 & X4) | (X5 & !X6). They are too simplistic and general and unable to capture all the nuance of the data presented.", "So, the moral of the story is that whether you will be successful in your search for target concept in a machine learning (here a classification) task, depends largely on the richness and complexity of the hypothesis space you choose to work with.", "Predictor and response variables: These are self-explanatory. The \u2018Sunny?\u2019, \u2018Favorite restaurant distance\u2019 and \u2018Got friends?\u2019 are predictor variables and \u2018Go out for lunch\u2019 is the response variable.", "Remember the decision trees for classification? Here are two such trees and their richness in terms of hypothesis space with regard to the learning problem described above.", "If you read the conditions satisfied by the edges of the tree starting from the root and down to a leaf, you will automatically get propositional logic statements just like above. Try it.", "So, the moral of the story is that whether you will be successful in your search for target concept in a machine learning (here a classification) task, depends largely on the richness and complexity of the hypothesis space you choose to work with.", "So, what is the size of the hypothesis space here?", "If you are building trees with all three predictor variables you can start with any one of those, then you can have O(2^(n-1)) leaves at the depth n if you are using all the predictors. But there is a choice of putting \u2018Yes\u2019 and \u2018No\u2019 on all those leaves. So, the size can be as large as O(n*2^(2^n)). For this example, with 3 variables, we can have 3*2^(2^(3\u20131)) = 48 trees! These 48 trees each represent a different hypothesis. Many of them are superfluous and can be eliminated with simple thinking, but that is beyond the point.", "So, if we consider a rich enough and big enough hypothesis space, are we guaranteed to find the target concept (given enough data)?", "Consider a simple linear regression problem.", "How many predictors are there? 1. So, what is the hypothesis space size? 2? 4?", "How many straight lines you can draw in a plane?", "Did your respect for the innocuous regression algorithm with least-square error minimization just grow immensely? After all, it is able to find the optimal line from those infinite possibilities :-)", "But here is the problem \u2014 even with an infinity-sized hypothesis space, we cannot hope to hit the true target concept in this regression task.", "This is due to the fact that the true concept lies in another space whose size is a \u2018bigger infinity\u2019. In this example, the true functional relationship between y and x may be a quadratic one. That implies infinite possibilities for the 2nd-degree terms + infinite possibilities for the linear terms + infinite possibilities of the intercept.", "Unless we decide to include a 2nd degree term in our hypothesis space, we will never come close to finding the true function even with our infinity-sized space with only the linear term (and intercept).", "So, in many cases, we need a richer space, not necessarily bigger. And, like Thanos, we need to constantly worry and search which infinity-sized space could be the best for the particular dataset we have to learn from!", "For the most part, CLT focuses not on individual learning algorithms, butrather on broad classes of learning algorithms characterized by the hypothesisspaces they consider, the presentation of training examples, etc. The key quantities it tries to reason about are,", "There are various ways to specify what it means for the learner to be \u201csuccessful.\u201d We might specify that to succeed, the learner must output ahypothesis identical to the target concept. Alternatively, we might simply require that it output a hypothesis that agrees with the target concept most of the time, or that it usually output such a hypothesis.", "Similarly, we must specify how training examples are to be obtained by the learner. It is a possibility that training examples are presented by a helpful teacher, or obtained by the learner performing carefully planned experiments (think A/B testing or scientific experiments), or simply generated at random according to some natural process outside the learner\u2019s control (think random click streams, cancer cell\u2019s interaction with drug). As we might expect, the answers to the above questions depend on the particular setting, or learning model, we have in mind.", "In this theoretical setting, we assume that all observed data was generated from a unknown but fixed (not time varying) distribution process whose parameters do not get affected by the process of our drawing sample from it. Also, without loss of generality, we can assume noise-free measurement process.", "Let H be the hypothesis space, D be the unknown true distribution, and c be the target concept. Let us say that after observing some data d, the learning algorithm L outputs a hypothesis h which it thinks is the best approximation of c.", "What is the measure of error/success here? Error is where the prediction of c and h disagrees.", "Our aim is to characterize classes of target concepts that can be reliably learned from a reasonable number of randomly drawn training examples and a reasonable amount of computation.", "We don\u2019t have infinite time, compute power, storage, or sensor bandwidth. Therefore, we don\u2019t try to make the error zero. For that, we need to see every instance possible as generated by D. For the same reason, we restrict ourselves to examining limited training samples and using a polynomial-time algorithm.", "Moreover, given that the training samples are drawn randomly,there will always be some nonzero probability that the training examplesencountered by the learner will be misleading.", "Therefore, we will require only that its error be bounded by some constant,that can be made arbitrarily small. Moreover, we will not require that the learner succeed for every sequence of randomly drawn training examples, instead, our demand will only be that its probability of failure be bounded by some constant, that can be made arbitrarily small.", "In short, we require only that the learner probably learn a hypothesis that is approximately correct.", "With these settings, we say that our concept class C, to which the target concept c belong, is PAC-learnable if the learning algorithm can output the hypothesis h after being trained with data d with a certain high probability and with a certain low error with a computational effort which is a polynomial function of 1/error, 1/(1-probability), size of C and length of the data d.", "We will not go through the formal proof here, but following the concepts, discussed in the previous section, an amazingly simple and elegant mathematical bound can be derived to answer the following question,", "\u201cWhat is the minimum number of training sample needed to learn an approximately correct hypothesis with certain probability when the hypothesis space has a certain size?\u201d", "This is called Haussler bound. This inequality readily demonstrates the following facts which we experience in practice for any machine learning task,", "There is a general criticism of this type of complexity bounds that they are too pessimistic and do not represent the practical learning problems. There is much debate on that topic and you can read some of it from the references I have put at the end of this article.", "A natural question arises about infinite hypothesis spaces. Does the sample bound go to infinity? It turns out that there is a concept called \u2018VC-dimension\u2019 (V here stands for Vladimir Vapnik, the inventor of support vector machine), which helps to keep the sample complexity finite for many practical learning problems even with infinite hypothesis spaces like a linear regression or a kernel-machine. But we could probably talk about such advanced concepts in another article.", "I hope this article could initiate some interesting concepts about fundamental machine learning theory and helped to wheat your appetite to learn more on these topics.", "For an excellent tutorial on these topics, watch this video,", "If you have any questions or ideas to share, please contact the author at tirthajyoti[AT]gmail.com. Also, you can check author\u2019s GitHub repositories for other fun code snippets in Python, R, or MATLAB and machine learning resources. If you are, like me, passionate about machine learning/data science, please feel free to add me on LinkedIn or follow me on Twitter.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Sr. Director of AI/ML platform | Stories on Artificial Intelligence, Data Science, and ML | Speaker, Open-source contributor, Author of multiple DS books"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9d93b15fc3e5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@tirthajyoti?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tirthajyoti?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Tirthajyoti Sarkar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb9d97d4b61a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&user=Tirthajyoti+Sarkar&userId=cb9d97d4b61a&source=post_page-cb9d97d4b61a----9d93b15fc3e5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.netlanguages.com/blog/index.php/2017/06/28/what-is-inductive-learning/", "anchor_text": "inductively learning"}, {"url": "https://www.geeksforgeeks.org/proposition-logic/", "anchor_text": "propositional logic"}, {"url": "https://towardsdatascience.com/where-did-the-least-square-come-from-3f1abc7f7caf", "anchor_text": "it is able to find the optimal line"}, {"url": "https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture28-pac.pdf", "anchor_text": "PAC-learnable"}, {"url": "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.6931", "anchor_text": "Haussler bound"}, {"url": "http://disi.unitn.it/moschitti/Teaching-slides/VC-dim.pdf", "anchor_text": "VC-dimension"}, {"url": "https://en.wikipedia.org/wiki/Vladimir_Vapnik", "anchor_text": "Vladimir Vapnik"}, {"url": "http://www.cs.cmu.edu/~./awm/tutorials/pac.html", "anchor_text": "PAC learning tutorial from CMU"}, {"url": "http://www.cs.cmu.edu/~guestrin/Class/10701-S05/slides/pac-vc.pdf", "anchor_text": "PAC learning, VC-dimensions, and Margin based bounds"}, {"url": "https://arxiv.org/pdf/1808.06324.pdf", "anchor_text": "PAC learning is undecidable"}, {"url": "https://pdfs.semanticscholar.org/733d/d84bc10fa96c65a10c7856f6f9bd1b389700.pdf", "anchor_text": "Efficiency and Computational Limitations of Learning Algorithms"}, {"url": "https://github.com/tirthajyoti?tab=repositories", "anchor_text": "GitHub repositories"}, {"url": "https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/", "anchor_text": "add me on LinkedIn"}, {"url": "https://twitter.com/tirthajyotiS", "anchor_text": "follow me on Twitter."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9d93b15fc3e5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9d93b15fc3e5---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9d93b15fc3e5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----9d93b15fc3e5---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/analytics?source=post_page-----9d93b15fc3e5---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&user=Tirthajyoti+Sarkar&userId=cb9d97d4b61a&source=-----9d93b15fc3e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&user=Tirthajyoti+Sarkar&userId=cb9d97d4b61a&source=-----9d93b15fc3e5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9d93b15fc3e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9d93b15fc3e5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9d93b15fc3e5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tirthajyoti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tirthajyoti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tirthajyoti Sarkar"}, {"url": "https://medium.com/@tirthajyoti/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "12.5K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb9d97d4b61a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&user=Tirthajyoti+Sarkar&userId=cb9d97d4b61a&source=post_page-cb9d97d4b61a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb285331282ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-analyze-learning-short-tour-of-computational-learning-theory-9d93b15fc3e5&newsletterV3=cb9d97d4b61a&newsletterV3Id=b285331282ca&user=Tirthajyoti+Sarkar&userId=cb9d97d4b61a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}