{"url": "https://towardsdatascience.com/an-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2", "time": 1682996636.9420118, "path": "towardsdatascience.com/an-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2/", "webpage": {"metadata": {"title": "An Introduction to Big Data, Apache Spark, and RDDs | by Hoyt Gong | Towards Data Science", "h1": "An Introduction to Big Data, Apache Spark, and RDDs", "description": "A yelp review, an ad click, or a geographic coordinate \u2014 you name it and our digital footprint is likely to be there. From millions of content creators on social media platforms to constant streams\u2026"}, "outgoing_paragraph_urls": [{"url": "https://eng.uber.com/uber-big-data-platform/", "anchor_text": "100+ PB geo-traffic insights on Uber", "paragraph_index": 1}, {"url": "http://hoytgong.com", "anchor_text": "http://hoytgong.com", "paragraph_index": 24}], "all_paragraphs": ["We collectively produce over 2.5 quintillion bytes of data every day.", "A yelp review, an ad click, or a geographic coordinate \u2014 you name it and our digital footprint is likely to be there. From millions of content creators on social media platforms to constant streams of transactional line items, our world has continued to churn out data at exponential rates. They range in size from 0.7 MB twitter posts to 100+ PB geo-traffic insights on Uber.", "And with this trend, importantly, has been our ability to capture it, interpret it, and make \u201cdata-driven decisions\u201d based on it. But in order for us to actually arrive at those insights, data scientists have created a whole field around big data and how to handle information at such a magnitude.", "In particular, big data has necessitated more robust computational tools beyond the standard excel regressions or even the python pandas that you may be familiar with. Especially when working on enterprise-grade production level datasets or considering scaling for any startup with data play, big data platforms are central in the management and analysis of all your big data needs. One of these platforms, Apache Spark, has become de-facto in working with big data and continues to be the most used in academia and industry by data experts. This article aims to break down the core concepts of Spark into straightforward descriptions without the fluff.", "Let\u2019s start on the Apache Spark website \u2014 Spark is a \u201cunified analytics engine for big data processing.\u201d On a high level, it is a computing framework that allows us to:", "Seeing the pattern? Various computing functionalities to handle big data. We write code for Apache Spark in Python, R, Scala, and Java in scripts typically ran on platforms that support execution of these heavyset computations.", "These platforms that run Spark are typically cloud-based (Microsoft Azure, AWS, Google Cloud, etc.) and written in notebooks connected with the cloud environment. These notebooks are backed by networked computer clusters to efficiently process the large datasets that your lone laptop or PC wouldn\u2019t be able to handle. (More on the how later)", "Apache Spark handles these huge sums of data through an abstraction called a Resilient Distributed Dataset (RDD). You\u2019ll be hearing this word a lot as it is the foundation behind Spark\u2019s robust data processing engine.", "On a high level, an RDD is a logical construct that allows us to visualize data often in the traditional table format so familiar to us and run the necessary SQL queries on our dataset. It is a java object at its core and has built-in methods (e.g. RDD_example.map(), RDD_example.filter(), etc.) provided by Spark that allow us to manipulate the original data we pass in. An RDD is merely an abstraction responsible for handling (storing & transforming) the data we pass in.", "Under the hood, however, an RDD effectively handles big data through partitioning subsets of data that can be operated on in parallel across various nodes and has replications per partition to prevent loss of data. Here\u2019s a tangible example of how data is represented by an RDD:", "Assume we have 5 worker nodes available to us in this setting. Spark recognizes that it would be inefficient to give all 100 GB to one worker node and leave the other four empty. Instead, it chooses to partition out this original dataset across the worker nodes to evenly distribute the workload. Spark decides to partition the data into 100 partitions (technically the # of partitions is a parameter you\u2019d set first), each partition being a different GB.", "But not all data is created equally \u2014 some might be faster to run than others and some might be too burdensome that it crashes a node.", "So while each worker node has its original 20 GB it is primarily responsible for, it also stores copies of other GB partitions. As such, Spark effectively partitions data onto nodes such that worker nodes can compute on the data in parallel while preventing idle nodes. That is, if a worker node finishes its computation early, it can \u201cpick up the slack\u201d from another worker node (that may be slow or have crashed) and support computation of another GB partition.", "From the example we can see the following takeaways:", "This gives rise to the name Resilient Distributed Dataset. Of course, more nuances exist to this process but the example above seeks to illustrate a simplified thought process in Spark\u2019s efficiency with RDDs.", "Note that with the first line of the parallelize method, we are creating the RDD from a list of integers we pass in. Think of paralleizing as just that \u2014 creating the RDD so that we can operate on our data in parallel.", "Upon that RDD we created, we apply two additional methods on the object, both of which still returns the RDD object. Filter and map are both parts of the MapReduce framework that takes in their respective anonymous functions. In this case, we filter the RDD to contain elements that are odd, then map a doubling function to those respective elements.", "At this point, the methods of the RDD seem identical to ones we\u2019ve seen in introductory CS courses. So why are we going through all this effort to filter and map a function onto a list? To evaluate how Spark computes lazily.", "The example above, on the final lines where we call collect, succinctly shows the difference between a spark transformation and action. Here is where we can dive into a deeper layer of understanding \u2014 the transformations of .filter() and .map() earlier are not actually performed but instead placed into an execution map only to be activated later by an action. The .collect() action method actually serves to execute the entire code sequence and start the computation across nodes.", "That execution plan that the transformations create on our local environment is stored in a directed acyclic graph (DAG). As in, the steps of the computation follow one continuous direction, never looping back onto itself.", "Long story short, the transformation methods are RDD methods returning RDDs placed into this DAG. The action methods are typically a final operation that starts the Spark engine for computation. Transformations add the DAG on the local environment and upon an action call, the DAG is sent to the master Spark interpreter on the main driver program.", "In the larger scope of how Spark operates and how the RDD fits into the framework, the diagram below captures the core of how a central driver program distributes across the worker nodes.", "The sc object, or SparkContext, that we call the initial .parallelize() method on is the built-in functionality of Apache Spark we can see as part of the main Driver Program. This spark context object is what we create or what\u2019s given to us such that we are empowered to create the RDD. From there, the master Driver Program receives the DAG execution plan from your PySpark script, serializes the code (e.g. turn into the bits and bytes), and sends the respective partitions to the worker nodes which they receive with their API call. The workers then each execute the operations assigned to them from the DAG. This gives rise to Spark\u2019s ability to compute in parallel and efficiently handle big data.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Big Data Analytics Teaching Assistant @Upenn | Wharton x Computational Biology | http://hoytgong.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F975ef4d91be2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hoytgong?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoytgong?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Hoyt Gong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43953daeec80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&user=Hoyt+Gong&userId=43953daeec80&source=post_page-43953daeec80----975ef4d91be2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral", "anchor_text": "NASA"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://eng.uber.com/uber-big-data-platform/", "anchor_text": "100+ PB geo-traffic insights on Uber"}, {"url": "https://spark.apache.org/docs/latest/cluster-overview.html", "anchor_text": "https://spark.apache.org/docs/latest/cluster-overview.html"}, {"url": "https://spark.apache.org/docs/latest/cluster-overview.html", "anchor_text": "https://spark.apache.org/docs/latest/cluster-overview.html"}, {"url": "https://medium.com/tag/big-data?source=post_page-----975ef4d91be2---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/technology?source=post_page-----975ef4d91be2---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/introduction?source=post_page-----975ef4d91be2---------------introduction-----------------", "anchor_text": "Introduction"}, {"url": "https://medium.com/tag/data-science?source=post_page-----975ef4d91be2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----975ef4d91be2---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&user=Hoyt+Gong&userId=43953daeec80&source=-----975ef4d91be2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&user=Hoyt+Gong&userId=43953daeec80&source=-----975ef4d91be2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F975ef4d91be2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----975ef4d91be2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----975ef4d91be2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----975ef4d91be2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----975ef4d91be2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoytgong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hoytgong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hoyt Gong"}, {"url": "https://medium.com/@hoytgong/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "41 Followers"}, {"url": "http://hoytgong.com", "anchor_text": "http://hoytgong.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43953daeec80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&user=Hoyt+Gong&userId=43953daeec80&source=post_page-43953daeec80--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F43953daeec80%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-big-data-apache-spark-and-rdds-975ef4d91be2&user=Hoyt+Gong&userId=43953daeec80&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}