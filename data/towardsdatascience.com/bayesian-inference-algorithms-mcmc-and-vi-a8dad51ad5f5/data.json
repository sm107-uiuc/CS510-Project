{"url": "https://towardsdatascience.com/bayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5", "time": 1683004670.6956868, "path": "towardsdatascience.com/bayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5/", "webpage": {"metadata": {"title": "Bayesian Inference Algorithms: MCMC and VI | by Wicaksono Wijono | Towards Data Science", "h1": "Bayesian Inference Algorithms: MCMC and VI", "description": "Unlike other areas of machine learning (ML), Bayesian ML requires us to know when an output is not trustworthy. When you train a regression or xgboost model, the model can be taken at face value\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf", "anchor_text": "NUTS", "paragraph_index": 6}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Concentration_of_measure", "anchor_text": "concentration of measure", "paragraph_index": 24}, {"url": "http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf", "anchor_text": "NUTS", "paragraph_index": 26}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article", "paragraph_index": 26}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article", "paragraph_index": 28}, {"url": "https://mc-stan.org/docs/2_22/stan-users-guide/reparameterization-section.html", "anchor_text": "Stan documentation", "paragraph_index": 30}, {"url": "http://www.stat.columbia.edu/~gelman/research/published/brooksgelman2.pdf", "anchor_text": "R hat", "paragraph_index": 33}, {"url": "https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/", "anchor_text": "the converse is not true", "paragraph_index": 34}, {"url": "http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf", "anchor_text": "PSIS-LOOCV", "paragraph_index": 48}, {"url": "https://en.wikipedia.org/wiki/Generalized_Pareto_distribution", "anchor_text": "generalized Pareto distribution", "paragraph_index": 48}, {"url": "https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence", "anchor_text": "Renyi divergence", "paragraph_index": 53}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler divergence", "paragraph_index": 53}, {"url": "https://en.wikipedia.org/wiki/Gibbs%27_inequality", "anchor_text": "here", "paragraph_index": 56}, {"url": "http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf", "anchor_text": "Latent Dirichlet Allocation", "paragraph_index": 71}, {"url": "https://en.wikipedia.org/wiki/Stochastic_approximation", "anchor_text": "Robbins-Monro conditions", "paragraph_index": 72}, {"url": "https://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf", "anchor_text": "paper", "paragraph_index": 73}, {"url": "https://arxiv.org/pdf/1401.0118.pdf", "anchor_text": "here", "paragraph_index": 75}, {"url": "https://arxiv.org/pdf/1603.00788.pdf", "anchor_text": "here", "paragraph_index": 79}, {"url": "https://en.wikipedia.org/wiki/Generalized_Pareto_distribution", "anchor_text": "generalized pareto distribution", "paragraph_index": 87}], "all_paragraphs": ["Unlike other areas of machine learning (ML), Bayesian ML requires us to know when an output is not trustworthy. When you train a regression or xgboost model, the model can be taken at face value given the settings and data. With Bayesian ML, the output is not guaranteed to be correct.", "Bayesian workflow can be split into three major components: modeling, inference, and criticism. Even when we have written a sensible probabilistic model, the results can be misleading due to the inference algorithm, whether because the algorithm has failed or because we have chosen an inappropriate algorithm. This article will explain how each algorithm works, discuss the pros and cons of each, and how to diagnose their performance.", "The major goal of Bayesian computation is to find a workaround to the denominator in Bayes\u2019 Theorem:", "Except for the simplest of models, that integral is impossible to compute. Inference algorithms are ways to get p(\u03b8|X) without ever having to evaluate that integral.", "Markov Chain Monte Carlo, as the name implies, runs a Monte Carlo simulation using a Markov Chain that must satisfy some conditions so we always end up at our desired stationary distribution (the posterior) regardless of starting point.", "Imagine the posterior distribution is some kind of hilly terrain. You want to explore the terrain and spend time at any spot proportional to the height of the mound. The caveat is that it\u2019s so foggy you can\u2019t see anything. Even if you stand on top of a hill, you don\u2019t know whether it is a tall hill or a short hill compared to the others. You can know that you are standing at an elevation of 2km, but are the other hills a mere 1km high, or are there 5km hills? Equipped with only a device to measure altitude, you need to come up with a rule to achieve your goal.", "Some rules are more efficient than others. In practice, most MCMC is NUTS (No-U-Turn Sampler) with some Gibbs thrown in when needed (mostly when parameters are discrete).", "Suppose we want to find the posterior distribution of two parameters, x and y. We can jump from spot to spot without restriction, or we can decompose each jump into a horizontal movement + a vertical movement. This is what Gibbs does. We toss our hands up and say: we don\u2019t know how to come up with a rule for the former, but we can create rules for the latter.", "Gibbs requires conditional conjugacy. We go through all the parameters one by one. The order doesn\u2019t matter \u2014 intuitively (but not really), horizontal + vertical = vertical + horizontal. We sample each parameter by analytically solving for the posterior, holding all other parameters fixed.", "As a simple example, suppose we want to estimate mean \u03bc and precision \u03bb = 1/\u03c3\u00b2 of a normal distribution. We place the priors \u03bc~N(0,1) and \u03bb~Gamma(1,1). Then the conditional posterior is", "We want to alternate between sampling from these two conditional posteriors. Here\u2019s R code to show how Gibbs sampling works for this model:", "Note the burn-in setting. MCMC hopefully will converge to the target distribution but it might take a while to get there. As a rule of thumb, we discard the first 1000 because the chain might not have reached its destination yet.", "Try changing the values to get the intuition of how the posterior behaves. If we trace the path of the movements, we see the horizontal-vertical patterns:", "We can compute the credible intervals using the marginal distributions:", "Gibbs can be preferable to other methods when your model is conditionally conjugate. For instance, trying to run NUTS on LDA does not work because there is no gradient with respect to discrete latent variables. However, running a Gibbs sampler for LDA is (comparatively) quick and easy.", "The Metropolis algorithm looks at Bayes\u2019 Theorem and asks \u201ccan we make the denominator cancel each other out?\u201d The algorithm:", "Remember p(X) is an unknown constant. Because our goal is to spend time at a spot proportional to the posterior density, we can do so without ever computing p(X).", "To easiest way to satisfy ergodicity and detailed balance is to sample \u03b8* from N(\u03b8, s\u00b2). A symmetric continuous distribution will do.", "Metropolis-Hastings (MH) generalizes this algorithm to non-symmetric proposal distributions while maintaining detailed balance. Look closely at the acceptance rule for MH and compare it to what detailed balance means.", "Here\u2019s some R code to see how the Metropolis algorithm works, using a N(0,1) prior on \u03b8 and given that we know X ~ N(\u03b8,1) :", "One problem with the Metropolis algorithm is that it is sensitive to our choice of proposal distribution. Using different standard deviations yields different results:", "As you can see, it takes some time for the chain to reach its target distribution. Analytically, we know that the posterior should be N(0.92, 0.09\u00b2). We should discard samples from the burn-in period, say the first 1000, to see it more clearly:", "Had we made s very small, say 0.01, perhaps the chain will not have reached the target distribution yet even after 1000 iterations. On the other hand, having a large s results in very jagged transitions as we reject most of the proposals. The best s lies somewhere between 0.1 and 1. We need to find it through trial and error, which can get cumbersome. Although we won\u2019t use Metropolis, it is important to get the intuition of how MCMC is sensitive to the settings.", "Anything I say here will pale in comparison to McElreath\u2019s excellent article, so I suggest reading that for animations and details. The basic idea is that Hamiltonian Monte Carlo (HMC) is a physics simulation. You have a ball rolling around some terrain that is the negative log posterior shifted up by some unknown constant. For a 2-D normal distribution, imagine flipping it over so you have a bowl. You flick the ball in a random direction with a random momentum, stop it after a certain time, and record where it ends up. You reject the sample when the total energy (potential + kinetic) differs too much from your starting energy, indicating a failure in your simulation. Stan calls these \u201cdivergent transitions\u201d.", "MH fails in extremely high dimensions because eventually you\u2019ll get close to 0% acceptance rate. Human intuition breaks down in high dimensions. Our 3-D brain might imagine a high-dimensional multivariate normal distribution as a solid ball, but it is actually a very thin shell of a sphere due to concentration of measure. If we project this down to 2D it will look like a donut instead of a circle. The fact that HMC performs well on donuts is profound.", "Physics simulations have to approximate trajectories by discretizing the steps. If you check every 10 \u201cseconds\u201d, then your simulated trajectory might differ too much from the actual trajectory. If you check every 0.00001 \u201cseconds\u201d, then your simulation will take a long time to compute a single trajectory even though it will be much more accurate. You need to tune the simulation settings just right to get good results out of HMC.", "NUTS automatically tunes the settings for you during the warm-up phase (instead of burn-in) and gives you better samples by preventing U-turns. If you didn\u2019t check the article linked above, I suggest looking at it now. There is virtually no reason to use MH or HMC over NUTS in this day and age.", "That said, NUTS still runs into some issues.", "First, it can get stuck near a single mode of a multimodal posterior (again, refer to the article). You can detect this problem through diagnostics (run multiple chains!) and then ask NUTS to obtain more samples to more fully explore the posterior.", "Second, NUTS needs to evaluate the gradient of the terrain after each step. Computing gradients is extremely costly and we must use the entire dataset, so it\u2019s not scalable.", "Third, it cannot explore something like Neal\u2019s funnel. This is a particularly degenerate case of a hierarchical model. You can read up on the example in the Stan documentation. Essentially, y is a log scale parameter to model the variance between groups while x is the group mean parameter. NUTS learns a single step size but this kind of terrain requires different step sizes depending on where the ball is on the funnel. A step size that works in the wide section will not work in the narrow section, while a step size that works in the narrow part will explore the wide part far too slowly.", "You can find this problem if you see too many divergent transitions and they all happen in the same region. The modeler needs to reparameterize the model so NUTS can work its magic, possibly by finding (relatively) uncorrelated parameterizations or rescaling the data so the parameters are on the same scale. For fixed effects models, this is done by QR decomposition on the predictor matrix.", "As an aside: reparameterization is often a good idea to speed up computation. Think of it this way: the ball can roll all over the place if we provide a nice bowl-shaped surface. Exploring a straw is more difficult. Without divergent transitions, samples from both methods should be correct, but runtime can be magnitudes faster with QR decomposition.", "R hat looks suspiciously like the F statistic in ANOVA, so that\u2019s the intuition I will give. If all of the chains are the same, then the \u201cF statistic\u201d should be 1.", "However, the converse is not true. It is possible for Rhat to be 1, and yet the chains do not converge to anything. We still need to check other diagnostics, but at the very least if Rhat > 1.00 then we quickly know that something is wrong. (It\u2019s funny that the older textbooks said > 1.1, then it changed to >1.01, and now moving to >1.005. Let\u2019s stick with 1.00.)", "The effective number of sample size is defined as:", "where \u03c1_t is the autocorrelation at lag t. In practice, we truncate the summation where we think the autocorrelation has gone to 0.", "MCMC does not draw independent samples because of the Markov property \u2014 at the very least your samples depend on the previous sample. Historically people skirted this issue by thinning their samples, e.g. keeping only every tenth sample. Now we know better; we should keep all the samples and use n_eff for CLT-like purposes.", "This is a useful diagnostic because if your n_eff is much lower than your total number of samples (minus the burn-in / warm-up), then something has gone terribly wrong (or you need to draw more samples).", "One of my favorite passages in a textbook is from McElreath\u2019s Statistical Rethinking 2:", "When people start using Stan, or some other Hamiltonian sampler, they often find that models they used to fit in Metropolis-Hastings and Gibbs samplers\u2026no longer work well. The chains are slow. There are lots of warnings. \u2026 Those problems were probably always there, even in the other tools. But since Gibbs doesn\u2019t use gradients, it doesn\u2019t notice some issues that a Hamiltonian engine will. A culture has evolved in applied statistics of just running bad chains for a very long time \u2014 for millions of iterations \u2014 and then thinning aggressively, praying, and publishing. This must stop. [example [redacted] \u2014 5 million samples, neff of 66!]", "He publicly shamed a paper; that paper deserves every bit of shaming it gets. Savage.", "This point can be a strong argument for using NUTS as the default. I suspect that Gibbs can draw reasonable samples but get stuck in some local space so the diagnostics are fine, but NUTS will try to explore other places and throw a warning.", "Sometimes n_eff will be higher than your number of samples. That\u2019s no cause for alarm.", "Think of expected log pointwise predictive density (ELPD) as a generalization of log-likelihood for the Bayesian case. Bayesian models output probability distributions, while metrics like RMSE / cross-entropy evaluate the performance of point predictions. ELPD evaluates the entire predicted distribution.", "Other similar metrics exist, but ELPD is all you need. AIC and BIC evaluate point predictions. WAIC has nice asymptotic properties but has erratic behavior for smaller samples. Their similarity is in the interpretation. ELPD is meaningless on its own, but it can be used to compare different models like you would use AIC.", "Because we care about how well the model generalizes, we want to obtain ELPD from cross-validation. Otherwise, we will be overly optimistic about model performance \u2014 evaluating a model on the training set will yield optimistically low error estimates.", "Contrary to conventional wisdom in machine learning, leave-one-out cross-validation (LOOCV) is much more computationally efficient than k-fold cross-validation for Bayesian models. K-fold requires us to refit the model k times, but fitting the model is the expensive part. We can approximate LOOCV using importance sampling on the samples we have already obtained from the posterior, so we don\u2019t need to refit the model.", "Nowadays, people use Pareto-Smoothed Importance Sampling (PSIS-LOOCV). These acronyms keep getting longer. Other than improving the stability of ELPD estimates, PSIS-LOOCV provides an additional diagnostic: k. This algorithm takes the 20% highest importance weights and fits a generalized Pareto distribution to it. When k > 0.5, the GPD has infinite variance and signals that the ELPD estimates might be untrustworthy, though from empirical testing the approximation isn\u2019t that bad until k > 0.7. When k is large, it can indicate highly influential observations that mess with the model.", "A cousin of trace plots. While trace plots can be useful to detect degenerate cases, it can be hard to interpret. Rank plots are easier to inspect. Using the code for Metropolis from before, and creating four chains with s = 0.2:", "These two plots should show some uniform mixing. Otherwise, something has gone wrong.", "With MCMC, understanding the algorithm is key. With VI, I think understanding the objective function is more important than the algorithms.", "Variational Inference (VI) takes a different approach from MCMC but still uses Monte Carlo in most applications. Instead of sampling from the posterior, we propose a simpler and tractable family of distributions to approximate the posterior. The question is then framed as an optimization problem. Thus, VI can be scaled to big data whereas NUTS cannot possibly work on big data.", "While several objective functions exist (the main alternative is Renyi divergence), the most commonly used one is the Kullback-Leibler divergence (KL divergence), defined as:", "The exact posterior is typically denoted p while our variational approximation is denoted q. Understanding the properties of KL divergence is vital for working with VI, and we will start with two:", "First, it is not symmetric. KL(p||q) requires us to take the expectation w.r.t. p, while KL(q||p) requires us to take the expectation w.r.t. q. Hence, it is not a distance metric.", "Second, it is nonnegative. From the expression it\u2019s not immediately obvious and you can refer to the proof here.", "KL(p||q) is called the forward-KL and it is intractable because we need to integrate over p (if we know p, why are we even doing this?). Instead, VI seeks to minimize KL(q||p), the reverse-KL. For example, we might want to approximate a highly complex posterior with a normal distribution; we seek the variational parameters \u03bc and \u03c3\u00b2 that will minimize reverse-KL. In more precise notation, letting \u03bd be the variational parameters, we want to find the \u03bd that minimizes:", "But we still have that pesky unknown posterior in the denominator, so we cannot directly work with the KL. Just like with Metropolis, we apply a trick so we never have to compute p(X):", "Recall that p(X) is a constant so we can take it out of the expectation. Rearranging gives us the Evidence Lower BOund (ELBO), the objective function of VI:", "Because KL is nonnegative, the maximum possible value of the ELBO is log(p(X)), the log evidence. Hence why it\u2019s called ELBO: the log evidence must be at least as high as the ELBO. However, it can be a very loose bound and the gap will vary across hypotheses and models. Never compare hypotheses using ELBO. Instead, compute the Bayes factors using the fitted posteriors.", "The ELBO has two important properties:", "First, the ELBO is entropy minus the cross-entropy. It\u2019s interesting. Think about it for a bit. The entropy wants q to be spread out as much as possible while the cross-entropy wants q to converge to a point mass on the mode of p. This has a similar weighted-average feel of the prior and MLE, as is the theme in Bayesian statistics.", "Second, the ELBO encourages q to have variances that are too low. In places where p has high density, overshooting by x results in a % error that is small relative to overshooting by x in a region where p has low density. To compound this issue, we are taking the expectation w.r.t. q, so placing less mass in low density regions of p will place lower weight on this error.", "VI has trouble with multimodal posteriors and highly correlated posteriors.", "As an illustration, let\u2019s try both NUTS and ADVI on a multimodal posterior. It commonly shows up in mixture models, but we\u2019ll use the simplest example possible:", "NUTS reports an Rhat of 1.53, letting us know that the model is ill-specified. ADVI converged without any warnings! Because the fitted variational distribution has almost 0 mass on the right part of the graph, the parts it failed to cover has almost 0 weight in the ELBO. Thus, it reports much lower variance than it should, making us overconfident in the wrong conclusion.", "Next, let\u2019s compare NUTS vs ADVI on highly correlated posteriors.", "NUTS managed to pick up the correlation just fine, but VI thinks the parameters are uncorrelated! What gives? (To be fair, Stan warns you that the approximation is bad.)", "By default, VI speeds up computation through the mean-field assumption, i.e. local parameters are uncorrelated with each other. This makes the observations conditionally exchangeable and speeds up the gradient computations. However, as this example demonstrates, the results can be terribly wrong!", "CAVI is your vanilla gradient ascent. Someone computes the analytic updates and we iterate until the ELBO converges. This is possible only for conditionally conjugate models. If it\u2019s impossible to set up a Gibbs sampler for your model, then CAVI is also impossible.", "Simple models like the Latent Dirichlet Allocation still requires a good deal of mathematical know-how. (I say simple because the model can be described in maybe five lines, it is conditionally conjugate, and it is possible to compute the gradient.) Even with analytic updates, CAVI can be extremely slow to converge, but if a model is amenable to CAVI then we can use SVI.", "If CAVI is gradient ascent, then SVI is stochastic gradient ascent. As long as we satisfy the Robbins-Monro conditions, then SVI is guaranteed to converge (though it might take many many many iterations). The step size should go down slow enough for us to fully explore the parameter space but it should go down fast enough for it to converge to a point. The LDA implementation in Spark uses SVI by default.", "Initially, I thought that SVI will perform worse than CAVI, but it\u2019s surprisingly the opposite. This paper shows that the parameters are learned much faster using SVI. A previous personal project corroborates this. A single CAVI iteration through all the documents yields worse results than SVI with only 10% of the documents.", "If you can compute the natural gradients for SVI, then it should be the best algorithm for fitting the model. The main challenge: you must compute them by hand. The next two flavors of VI are used when it is too difficult or even impossible to compute natural gradients. Dubbed \u201cblack box variational inference\u201d, they approximate the gradient using Monte Carlo methods. The svi function in Pyro is BBVI.", "Paper here. Derivation in the appendix. We want to do SGD by approximating the gradient of the ELBO. The intuition:", "Applying these in order gives us", "We can do a Monte Carlo approximation on this expectation by sampling from our current q and evaluating each of the terms in the integrand.", "In reality, the score gradient has too high of a variance to make it practical. Additional expertise is needed to get the variance under control. Otherwise, the BBVI will not converge in any reasonable time as we step all over the place.", "Paper here. This is the version of VI that is implemented by default on most probabilistic programming packages. I suggest reading the original paper as it\u2019s very clearly written.", "The basic idea is that we know how to do VI on a multivariate normal distribution, so why not transform all VI problems to something we already know how to solve? All the parameters in our model are MVN that have been transformed. We can apply the chain rule on these transformation functions (reparameterizations) and compute the gradients using automatic differentiation.", "In practice, the posterior distribution is sensitive to the reparameterization. It\u2019s not clear what functions yield the best approximations. Again, expertise is needed for VI to work well. Algorithms to automatically find the best reparameterizations is high on my wish list and I\u2019ll keep an eye out for it.", "Just like SGD algorithms, we can inspect whether the objective function has converged or not. In reality, it\u2019s hard to know when to stop. The ELBO can jump once it escapes a local optimum, but we can\u2019t tell whether it\u2019s stuck in a local optimum. While the trace plot is nice, the real diagnostic is\u2026", "This is the diagnostic that Stan uses to warn users when ADVI converges to a bad fit. Suppose we want to compute E[\u03b8] w.r.t. the posterior, but we can\u2019t do that because we don\u2019t know the posterior. One neat trick is", "So even if we can\u2019t sample from p, we can do a Monte Carlo approximation by sampling from a convenient q. We approximate the expectation by taking this weighted average", "Where w_i is the importance weight defined by", "Just like with the Metropolis algorithm, we never have to evaluate p(X) because it cancels out when taking the weighted average (see a pattern?). Luckily we already have a convenient q to sample from: our fitted variational distribution. It is well-known that the importance weights can have infinite variance if p and q don\u2019t overlap much.", "Stan fits a generalized pareto distribution to the 20% highest importance weights. The GPD has infinite variance if k > 0.5, though in practice the fit is relatively decent until k > 0.7, as a rule of thumb. Stan warns the user when k > 0.7. This should be your primary diagnostic to assess the fit of your VI.", "Hopefully this article has provided good information to use and diagnose the Bayesian inference algorithms. As always, if you see anything wrong or have any suggestions, please let me know so I can amend the article.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Bayesian data scientist. Alternates between light reading and more in-depth articles about applied statistics and machine learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa8dad51ad5f5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@wwijono?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wwijono?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Wicaksono Wijono"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5e69e4814607&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&user=Wicaksono+Wijono&userId=5e69e4814607&source=post_page-5e69e4814607----a8dad51ad5f5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Markov_chain#Ergodicity", "anchor_text": "ergodicity"}, {"url": "https://en.wikipedia.org/wiki/Detailed_balance#Reversible_Markov_chains", "anchor_text": "detailed balance"}, {"url": "http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf", "anchor_text": "NUTS"}, {"url": "https://commons.wikimedia.org/wiki/File:Perpendicular_Vector_Addition.svg", "anchor_text": "source"}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article"}, {"url": "https://en.wikipedia.org/wiki/Concentration_of_measure", "anchor_text": "concentration of measure"}, {"url": "http://Physics simulations have to approximate trajectories by discretizing the steps. If you check every 10 \"seconds\", then your simulated trajectory might differ too much from the actual trajectory. If you check every 0.00001 \"seconds\", then your simulation will take a long time to compute even a single trajectory even though it will be much more accurate. One major downside of HMC is the need to tune the settings of the simulation.", "anchor_text": "source"}, {"url": "http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf", "anchor_text": "NUTS"}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article"}, {"url": "https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/", "anchor_text": "article"}, {"url": "https://mc-stan.org/docs/2_22/stan-users-guide/reparameterization-section.html", "anchor_text": "source"}, {"url": "https://mc-stan.org/docs/2_22/stan-users-guide/reparameterization-section.html", "anchor_text": "Stan documentation"}, {"url": "http://www.stat.columbia.edu/~gelman/research/published/brooksgelman2.pdf", "anchor_text": "R hat"}, {"url": "https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/", "anchor_text": "the converse is not true"}, {"url": "http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf", "anchor_text": "PSIS-LOOCV"}, {"url": "https://en.wikipedia.org/wiki/Generalized_Pareto_distribution", "anchor_text": "generalized Pareto distribution"}, {"url": "https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence", "anchor_text": "Renyi divergence"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler divergence"}, {"url": "https://en.wikipedia.org/wiki/Gibbs%27_inequality", "anchor_text": "here"}, {"url": "http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf", "anchor_text": "Latent Dirichlet Allocation"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_approximation", "anchor_text": "Robbins-Monro conditions"}, {"url": "https://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1401.0118.pdf", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Dominated_convergence_theorem", "anchor_text": "dominated covergence theorem"}, {"url": "https://en.wikipedia.org/wiki/Score_(statistics)", "anchor_text": "score function"}, {"url": "https://arxiv.org/pdf/1603.00788.pdf", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1603.00788.pdf", "anchor_text": "source"}, {"url": "https://en.wikipedia.org/wiki/Generalized_Pareto_distribution", "anchor_text": "generalized pareto distribution"}, {"url": "https://medium.com/tag/bayesian-statistics?source=post_page-----a8dad51ad5f5---------------bayesian_statistics-----------------", "anchor_text": "Bayesian Statistics"}, {"url": "https://medium.com/tag/probabilistic-programming?source=post_page-----a8dad51ad5f5---------------probabilistic_programming-----------------", "anchor_text": "Probabilistic Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a8dad51ad5f5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----a8dad51ad5f5---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a8dad51ad5f5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&user=Wicaksono+Wijono&userId=5e69e4814607&source=-----a8dad51ad5f5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&user=Wicaksono+Wijono&userId=5e69e4814607&source=-----a8dad51ad5f5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa8dad51ad5f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a8dad51ad5f5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a8dad51ad5f5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wwijono?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wwijono?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Wicaksono Wijono"}, {"url": "https://medium.com/@wwijono/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "785 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5e69e4814607&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&user=Wicaksono+Wijono&userId=5e69e4814607&source=post_page-5e69e4814607--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd2f99368ce0a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5&newsletterV3=5e69e4814607&newsletterV3Id=d2f99368ce0a&user=Wicaksono+Wijono&userId=5e69e4814607&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}