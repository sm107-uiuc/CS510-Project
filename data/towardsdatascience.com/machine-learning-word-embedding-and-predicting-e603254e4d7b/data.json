{"url": "https://towardsdatascience.com/machine-learning-word-embedding-and-predicting-e603254e4d7b", "time": 1683004533.285731, "path": "towardsdatascience.com/machine-learning-word-embedding-and-predicting-e603254e4d7b/", "webpage": {"metadata": {"title": "Machine Learning: Word Embedding and Predicting | by Anuradha Wickramarachchi | Towards Data Science", "h1": "Machine Learning: Word Embedding and Predicting", "description": "Word embedding is a popular technique of converting sparse representation vectors into dense smaller vectors. This increases computation times by a significant factor and saves resources. In this\u2026"}, "outgoing_paragraph_urls": [{"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "URL", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/The_Metamorphosis", "anchor_text": "Metamorphosis", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "here", "paragraph_index": 6}], "all_paragraphs": ["Word embedding is a popular technique of converting sparse representation vectors into dense smaller vectors. This increases computation times by a significant factor and saves resources. In this article let\u2019s see how we can develop a prediction engine and utilize the knowledge of word embedding in the workflow.", "This is where individual words are adjusted to the closest matching correct word. In most of the cases, this approach tries to fix spelling. For example, if you type \u201chelo\u201d, it is quite likely that your phone would make it \u201chello\u201d.", "This is a newer approach where you get your grammar corrected. Words are replaced to make sentences more natural. For example, if you say \u201cYou\u2019re a beautiful per\u201d we can have a rational logic that the word might turn up to be \u201cperson\u201d. In fact, this shall be completed as \u201cYou\u2019re a beautiful person\u201d. In this article, we will focus on this auto-correction which uses the context information. This is somewhat complex than typo fixing. I hope you all are victims/users of this feature on mobile phones. Let us build one ourselves!", "Once I stumbled upon this URL which directed me to the eBook named Metamorphosis. This is available free to download as a text document in ASCII encoding (UTF-8). Henceforth, I will be referring to this source as my dataset for training. First things first! Let us quickly preprocess and tokenize so we are ready to go. I will be using the following python libraries for preprocessing (In case you don\u2019t have them already).", "One of the first steps we shall perform is the tokenization of words in the training set. This is because we should fit all the words in the entire corpus in a finite space for downstream processing. Usually, neural networks perform better within a range of values. Thus, we should embed all those data in dense vectors. It is rather a compression of space that our word tokens like. Let\u2019s see how it works.", "This is a very common method of embedding words by considering the frequency of a word in a document and its occurrence in the corpus. The size of the vector will be equal to the number of unique words considered. Usually implemented using a sparse matrix. Let\u2019s have a look at the sample code below.", "This will print the following outputs in the terminal (Read more about theory here).", "By the look of this vector you\u2019ll see that they are high dimensional, thus requires a lot of resources for computations.", "This is where we use an embedding layer, which will condense sparse representations into a target dimension making a smaller representation. Let\u2019s have a look at an example.", "This will be followed by the output;", "You could see that we see a tensor of shape N, 1, 3 this is because our target dimension is 3, we have one word. Multiple words would increase the second dimension of the tensor. These will be hyperparameters of your learning model. Now you will have sentences with words in 3 dimensions in contrast to the previous dimension which was the vocabulary size.", "Now that we have good know-how about the preliminary steps, let us build the model.", "We will load data and tokenize words using the aforementioned book Metamorphosis as the corpus. We will consider 3 consecutive words. Inputs to the model are the first 2 words and output will be the last word for each set of 3 words.", "Let us build a simple model for our training. In this article I will develop a very simple model, that will consider two preceding words to predict or correct the next word. My output will be in a categorical binary format to predict the next word. I will use the Keras functional API which I love using.", "Note that we use categorical cross-entropy since we are training to predict binary categorical values. One bit will indicate one item in a specific index.", "We will be able to see the below model when we run our code.", "We can initiate the training program using the following lines of code.", "Now that we have trained the model we can start predicting the next word and correcting. Let us see how we do the prediction part from the trained model.", "Here in bold notation, I have put so, which is the last word typed half (for simulation of user input). Note that I consider the first 2 words for prediction. Our predictor will predict the word \u201csome\u201d. So the complete sentence would be \u201cthere\u2019s still some\u201d. We are using argmax to pick the predicted category and look the word up in the tokenizer dictionary.", "We are naively picking the most probable item. However, if we had \u201cthere\u2019s still some fo\u201d, the next word could easily be \u201cfood\u201d. The simplest workaround for this is picking the set of most probable items without argmax. Then look the words up and assign the closest match. You can use cosine distance for this purpose.", "Try to plot your Keras model for clarity.Find a good corpus for training (What I have chosen is naive)Where categorical encoding would not fit, use binary encoding with binary cross-entropy.", "I hope you enjoy reading this! G\u2019day!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fe603254e4d7b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://anuradhawick.medium.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": ""}, {"url": "https://anuradhawick.medium.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Anuradha Wickramarachchi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fddf633dcad17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&user=Anuradha+Wickramarachchi&userId=ddf633dcad17&source=post_page-ddf633dcad17----e603254e4d7b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/quinntheislander-1139623/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2574751", "anchor_text": "Quinn Kampschroer"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2574751", "anchor_text": "Pixabay"}, {"url": "https://machinelearningmastery.com/clean-text-machine-learning-python/", "anchor_text": "URL"}, {"url": "https://en.wikipedia.org/wiki/The_Metamorphosis", "anchor_text": "Metamorphosis"}, {"url": "https://en.wikipedia.org/wiki/Tf%E2%80%93idf", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----e603254e4d7b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----e603254e4d7b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----e603254e4d7b---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----e603254e4d7b---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/keras?source=post_page-----e603254e4d7b---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&user=Anuradha+Wickramarachchi&userId=ddf633dcad17&source=-----e603254e4d7b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&user=Anuradha+Wickramarachchi&userId=ddf633dcad17&source=-----e603254e4d7b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fe603254e4d7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----e603254e4d7b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----e603254e4d7b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----e603254e4d7b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----e603254e4d7b--------------------------------", "anchor_text": ""}, {"url": "https://anuradhawick.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://anuradhawick.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Anuradha Wickramarachchi"}, {"url": "https://anuradhawick.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2K Followers"}, {"url": "https://anuradhawick.com/", "anchor_text": "https://anuradhawick.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fddf633dcad17&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&user=Anuradha+Wickramarachchi&userId=ddf633dcad17&source=post_page-ddf633dcad17--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9f8ac7ab9f5b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-word-embedding-and-predicting-e603254e4d7b&newsletterV3=ddf633dcad17&newsletterV3Id=9f8ac7ab9f5b&user=Anuradha+Wickramarachchi&userId=ddf633dcad17&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}