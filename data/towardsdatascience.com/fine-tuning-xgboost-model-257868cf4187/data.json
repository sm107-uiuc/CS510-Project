{"url": "https://towardsdatascience.com/fine-tuning-xgboost-model-257868cf4187", "time": 1683012445.073397, "path": "towardsdatascience.com/fine-tuning-xgboost-model-257868cf4187/", "webpage": {"metadata": {"title": "Fine Tuning XGBoost model. Tuning the model is the way to\u2026 | by Neetika Khandelwal | Towards Data Science", "h1": "Fine Tuning XGBoost model", "description": "Tuning the model is the way to supercharge the model to increase their performance. Let us look into an example where there is a comparison between the untuned XGBoost model and tuned XGBoost model\u2026"}, "outgoing_paragraph_urls": [{"url": "https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020", "anchor_text": "https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020", "paragraph_index": 14}], "all_paragraphs": ["Tuning the model is the way to supercharge the model to increase their performance. Let us look into an example where there is a comparison between the untuned XGBoost model and tuned XGBoost model based on their RMSE score. Later, you will know about the description of the hyperparameters in XGBoost.", "Below is the code example for untuned parameters in XGBoost model:", "Now let us look to the value of RMSE when the parameters are tuned to some extent:", "It can be seen that there is around 15% reduction in the RMSE score when the parameters got tuned.", "For each base learner of the XGBoost, there are different parameters that can be tuned to increase the model performance.", "Below are some of the tuning examples:", "It can be seen that the increasing value of eta gives a better model.", "It can be seen that the increasing value of tree depth gives a better model.", "The models will give better performance only when the values of the hyperparameters are optimal. So, the question is how to find the optimal value to get the lowest possible loss?", "The two common strategies for choosing several hyperparameters at the same time is Grid Search and Random Search.", "So, let's see how both can be used in XGBoost?", "It is a method of exhaustively searching through a collection of possible parameter values. For example, if you have to tune 3 hyperparameters and each has 4 possible values then the grid search over that parameter space would try all 64 configurations and pick the configuration that gives the best value for the metrics that is been used (here we used root mean squared error). Let\u2019s see an example.", "It is somewhat different from Grid Search. It creates a range of hyperparameter values per hyperparameter that you would like to search over. It also sets the number of iterations that you would for the random search to continue. During each iteration, a randomly drawn value in the range of specified values for each hyperparameter searched over and train/test a model with those hyperparameters. After reaching the maximum number of iterations it selects the best hyperparameters with the best scores.", "So, now you know what tuning means and how it helps to boost up the model. This article discussed tuning the hyperparameter eta and max-depth, but there can be other hyperparameters too that can be tuned to there best value and can give your model a better performance, and choosing the best values can be done with the help of Grid Search and Random Search.", "If you want to learn more about hyperparameter tuning in general, consider the following link: https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F257868cf4187&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----257868cf4187--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kwal.neetika?source=post_page-----257868cf4187--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kwal.neetika?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Neetika Khandelwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffab4084efde4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&user=Neetika+Khandelwal&userId=fab4084efde4&source=post_page-fab4084efde4----257868cf4187---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@emilymorter?utm_source=medium&utm_medium=referral", "anchor_text": "Emily Morter"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020", "anchor_text": "https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----257868cf4187---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/xgboost?source=post_page-----257868cf4187---------------xgboost-----------------", "anchor_text": "Xgboost"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----257868cf4187---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----257868cf4187---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/tag/hyperparameter?source=post_page-----257868cf4187---------------hyperparameter-----------------", "anchor_text": "Hyperparameter"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&user=Neetika+Khandelwal&userId=fab4084efde4&source=-----257868cf4187---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&user=Neetika+Khandelwal&userId=fab4084efde4&source=-----257868cf4187---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----257868cf4187--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F257868cf4187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----257868cf4187---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----257868cf4187--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----257868cf4187--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----257868cf4187--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----257868cf4187--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----257868cf4187--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kwal.neetika?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kwal.neetika?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Neetika Khandelwal"}, {"url": "https://medium.com/@kwal.neetika/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "12 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffab4084efde4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&user=Neetika+Khandelwal&userId=fab4084efde4&source=post_page-fab4084efde4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fde215cc35e0d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffine-tuning-xgboost-model-257868cf4187&newsletterV3=fab4084efde4&newsletterV3Id=de215cc35e0d&user=Neetika+Khandelwal&userId=fab4084efde4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}