{"url": "https://towardsdatascience.com/understanding-fixup-initialization-6bf08d41b427", "time": 1683000855.8541172, "path": "towardsdatascience.com/understanding-fixup-initialization-6bf08d41b427/", "webpage": {"metadata": {"title": "Understanding Fixup initialization | by Jan Joseph Malin | Towards Data Science", "h1": "Understanding Fixup initialization", "description": "Fixup initialization allows us to train neural networks with even 10,000 layers without normalization layers. The article describes the main ideas behind Fixup and shows how to implement it."}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=AcA8HAYh7IE&feature=youtu.be&t=1138&fbclid=IwAR02htQ6jcHEROSaBt0RrSq2aIpHpWcgoOnpioWrstC7pBnJlbjt0itziFg", "anchor_text": "lectures", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1901.09321.pdf", "anchor_text": "paper", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1901.09321.pdf", "anchor_text": "article", "paragraph_index": 4}, {"url": "https://github.com/hongyi-zhang/Fixup", "anchor_text": "GitHub", "paragraph_index": 22}], "all_paragraphs": ["Proper initialization of weight matrices is extremely important. According to Jeremy Howard, people for decades could not train neural networks because of improper initialization. In order to see it, we can reproduce one of the experiments from Jeremy\u2019s lectures. Let\u2019s initialize a random weight matrix and a vector. We can simulate a neural network by taking x -> Ax and repeating this procedure n times.", "As a result, we will see that both, mean and standard deviation are infinite. The fault is in our random initialization.", "Fortunately, there are other ways of initializing weight matrices. One of them is Fixup.", "Fixup (fixed-update initialization) is a recent initialization method for ResNets created by Hongyi Zhang, Yann N. Dauphin and Tengyu Ma. In their paper, the authors showed that it\u2019s possible to train a residual network without batch norm layers. What is more, the authors managed to achieve state of the art performance in image classification and machine translation.", "Let\u2019s consider the basic block of ResNet without normalization layers. In some regions of such a network (Positively homogeneous blocks, the detailed description of this term is provided in the article.) the variance grows exponentially with depth:", "As a result, problems with convergence, speed of the training and generalizability may occur. Normalization layers were to be a solution. In recent years it\u2019s been thought that the solution is unique.", "However, as we will see this turns out to be untrue.", "If we think about exploding gradients (if the gradients get too big, then it\u2019s easy to overshoot the minimum) in an intuitive way, we can notice that the issue will not occur if in each step the change in the output is O(\u03b7), where \u03b7 is the learning rate. More formally:", "Therefore, if we have L residual branches we want each of them to be updated by O(\u03b7/L), on average.", "Now, let\u2019s assume that each residual branch has m layers, where m is a small positive integer (usually 2 or 3).", "The authors proved that the change in the output in each step of the SGD will be O(\u03b7) if the product of the scaling factors (except for the smallest one) is O(\u03b7).", "Therefore, the following formula was proposed:", "Now, as we have achieved our main goal we can think about stuff that will improve the network\u2019s performance.", "Using scalar biases and multipliers is a common practice, as they make the output of each layer fit into the activations of the subsequent layer. If we want to change the mean, we simply add a bias. Similarily, multipliers help to manipulate the standard deviation.", "\u201cwe find that inserting just one scalar bias before each weight layer and nonlinear activation layer significantly improves the training performance.\u201d", "\u201cIn a branch with multipliers, this in turn causes the growth of the multipliers, increasing the effective learning rate of other layers. In particular, we observe that inserting just one scalar multiplier per residual branch mimics the weight norm dynamics of a network with normalization, and spares us the search of a new learning rate schedule.\u201d", "Keeping all of these in mind, the following architecture of a residual block is proposed:", "Summing up, in order to Fixup initialize your network you have to:", "1.Initialize the classification layer and the last layer of each residual branch to 0.", "2.Initialize every other layer using a standard method (e.g., He et al. (2015)), and scale only the weight layers inside residual branches by L^(1/(2m-2))", "3.Add a scalar multiplier (initialized at 1) in every branch and a scalar bias (initialized at 0) before each convolution, linear, and element-wise activation layer.", "It\u2019s important to note that the second point is a must for training deep neural networks without regularization, whilst the other two boost its performance.", "The implementation of the paper can be found on one of the author's GitHub. We are going to go through the most important parts.", "First, we initialize two basic Fixup blocks: FixupBasicBlock and FixupBottleneck. As in the paper, the scalar biases and scaling factors are set to zeros and ones respectively.", "FixupBottleneck has one more convolutional layer and two more biases compared to FixupBasicBlock.", "Then, we are ready to build our first Fixup initialized ResNet. We start by defining the basis such as the number of layers, convolutions etc.", "Then we iterate through all parts of the network and initialize the weights. Note that the scaling factor is calculated according to the formula L^(1/(2m-2)). The additional factor of two on the top helps to preserve standard deviation being equal to one.", "As FixupBasicBlock has 2 layers m=2 and we scale the weights by the factor L^(-0.5). Similarily, FixupBottleneck has three layers so we scale it by L^(-0.25)", "Finally, we can define our fixup initialized ResNets!", "Fixup initialization is a powerful tool for initializing weight matrices. It is very important as, it is one of the first method, which allows for training even extremely deep neural networks without batch norm layers.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Physics student at @UniversityOfOxford. Interested in AI and ML."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6bf08d41b427&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@janjosephmalin?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@janjosephmalin?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Jan Joseph Malin"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff7601fcf8b47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&user=Jan+Joseph+Malin&userId=f7601fcf8b47&source=post_page-f7601fcf8b47----6bf08d41b427---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/watch?v=AcA8HAYh7IE&feature=youtu.be&t=1138&fbclid=IwAR02htQ6jcHEROSaBt0RrSq2aIpHpWcgoOnpioWrstC7pBnJlbjt0itziFg", "anchor_text": "lectures"}, {"url": "https://arxiv.org/pdf/1901.09321.pdf", "anchor_text": "paper"}, {"url": "https://arxiv.org/pdf/1901.09321.pdf", "anchor_text": "article"}, {"url": "https://github.com/hongyi-zhang/Fixup", "anchor_text": "GitHub"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6bf08d41b427---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----6bf08d41b427---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/weight-initialization?source=post_page-----6bf08d41b427---------------weight_initialization-----------------", "anchor_text": "Weight Initialization"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6bf08d41b427---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/resnet?source=post_page-----6bf08d41b427---------------resnet-----------------", "anchor_text": "Resnet"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&user=Jan+Joseph+Malin&userId=f7601fcf8b47&source=-----6bf08d41b427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&user=Jan+Joseph+Malin&userId=f7601fcf8b47&source=-----6bf08d41b427---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6bf08d41b427&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6bf08d41b427---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6bf08d41b427--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6bf08d41b427--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6bf08d41b427--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@janjosephmalin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@janjosephmalin?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jan Joseph Malin"}, {"url": "https://medium.com/@janjosephmalin/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "13 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff7601fcf8b47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&user=Jan+Joseph+Malin&userId=f7601fcf8b47&source=post_page-f7601fcf8b47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ff7601fcf8b47%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-fixup-initialization-6bf08d41b427&user=Jan+Joseph+Malin&userId=f7601fcf8b47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}