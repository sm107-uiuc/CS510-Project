{"url": "https://towardsdatascience.com/bias-what-it-means-in-the-big-data-world-6e64893e92a1", "time": 1682995439.067102, "path": "towardsdatascience.com/bias-what-it-means-in-the-big-data-world-6e64893e92a1/", "webpage": {"metadata": {"title": "Human Bias in Machine Learning. A brief exploration on the impacts that\u2026 | by Mark Xiang | Towards Data Science", "h1": "Human Bias in Machine Learning", "description": "Bias is an inescapable part of human nature. Previous research suggests that cognitive biases form to optimize brain function when humans are distracted. Biases are influenced by your environment\u2026"}, "outgoing_paragraph_urls": [{"url": "https://pdfs.semanticscholar.org/c6c0/2f8929a48871689d757122c1bb346c6265b5.pdf", "anchor_text": "research", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 9}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe", "paragraph_index": 9}, {"url": "https://researchportal.bath.ac.uk/en/publications/semantics-derived-automatically-from-language-corpora-necessarily", "anchor_text": "affected by the prejudice in the real world", "paragraph_index": 9}, {"url": "http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/", "anchor_text": "sentiment analysis model built using GloVe embedding", "paragraph_index": 10}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "racial biases with prediction models in the criminal justice system", "paragraph_index": 15}, {"url": "https://pdfs.semanticscholar.org/c6c0/2f8929a48871689d757122c1bb346c6265b5.pdf", "anchor_text": "The Psychology of Prejudice, Stereotyping and Discrimination: An Overview", "paragraph_index": 22}, {"url": "https://www.businessinsider.com/cognitive-biases-that-affect-decisions-2015-8", "anchor_text": "20 cognitive biases that screw up your decisions", "paragraph_index": 23}, {"url": "https://arxiv.org/pdf/1902.11097.pdf", "anchor_text": "Predictive Inequity in Object Detection", "paragraph_index": 24}, {"url": "http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/", "anchor_text": "How to make a racist AI without really trying", "paragraph_index": 25}, {"url": "https://www.linkedin.com/in/markxy/", "anchor_text": "https://www.linkedin.com/in/markxy/", "paragraph_index": 27}], "all_paragraphs": ["Bias is an inescapable part of human nature. Previous research suggests that cognitive biases form to optimize brain function when humans are distracted. Biases are influenced by your environment, experiences, and can be difficult to eliminate. One such solution to minimize the effects of biases is to be aware of possible biases that you have or may encounter.", "In this post, I will be describing some of the impacts that different types of biases can cause in machine learning projects. With examples on the roots of the issues caused by these biases as well as reasoning on why bias can be useful.", "Due to the innate nature of biases within humans, biases are reflected in all data that exists in the world. With the increasing popularity and accessibility of Machine Learning and big data; there exists an unimaginable depth of data and accessible tools in the world. With all this data, there exists ways that bias influences data and our inferences.", "Biases do not just exist only within the data, there are also incognitive biases that a scientist may have while performing research, experimenting, or implementing algorithms. Simple steps such as not considering certain parameters or features when testing can lead to real consequences.", "The term for the bias that affects Machine Learning algorithms is Machine Bias. It relates to how biases in the data used or biases from the researcher affect the end results. Machine Bias has real world implications that bring danger and reinforces systematic bias.", "This specific issue is caused by Sampling Bias, a form of bias that comes from imbalanced training data which doesn\u2019t represent the environment that the model will operate in. For example, a pedestrian recognition model trained on only pictures of pedestrians in rural America will not operate well in a multicultural urban city because pedestrians from the two populations would not have similar appearances.", "This example has real life implementations as society move towards more self driving cars on the road. This issue is most likely caused by the lack of individuals from under represented backgrounds in the training data while training the CNN algorithm. This can also be caused by the natural difficulty of less contrast between darker skin, or darker clothing, and the background.", "Prejudice Bias arises when algorithms take in subtle biases from the data source, even if it was sampled perfectly.", "The classic example used to describe this bias is a machine learning model that\u2019s designed to differentiate between men and women in pictures. The training data contains more pictures of women in kitchens than men in kitchens, or more pictures of men coding than women, then the algorithm is trained to make incorrect inferences about the gender of people engaged in those activities due to prejudices that occur in the real world, represented in the data.", "Sentiment Analysis is the use of machine learning algorithms to detect the emotional or subjective sentiment of a body of text. Currently, these algorithms operate by utilizing a prebuilt word embedding, a pre-designed system of models used to produce vectors that construct linguistic context from bodies of text, to analyze the sentiment of text. However, almost all popular word embedding are trained on human data, such as news articles (word2vec) or webpages (GloVe) and are affected by the prejudice in the real world.", "Below is an example of the outputs of a simple sentiment analysis model built using GloVe embedding and a linear classifier. This example of a simple sentiment analysis model does not reflect of consumer level systems.", "This is how the system is expected to work, i.e \u201cpretty cool\u201d have correlation with other positive words, which gives it a higher score than \u201csucks\u201d.", "The influence of bias appears, as there are more negative webpages with the word \u201cMexican\u201d and \u201cChinese\u201d than the word \u201cItalian\u201d, the sentiment score becomes more positive with \u201cItalian\u201d than the other words.", "This example is similar to the last, more common names tend to appear in more positive webpages, which raises positive sentiment, compared to less common names.", "Simply, racial bias exists within the sentiment analysis system because racial bias also appears in the data that it is trained with. When sentiments of words are trained by webpages, in the case of GloVe, ethnic words or names can have lower sentiments because of a smaller number of positive web comments and pages that contains those words or names. This creates racial bias within our model because of the data given which only enforces the systematic prejudice that exists in the real world.", "Prejudice bias exists in many forms, such as racial biases with prediction models in the criminal justice system and is hard to correct because it comes from a reflection of biases that exist within the real world. It is important for there to be domain knowledge on the data you are working with to be aware of the intricacies that exists within it.", "Sometimes, it really is just a problem with the algorithm. Algorithmic bias is when the algorithm, due to how it is designed, will have bias built in. Spotify creates a playlist every year based off the songs that you listened to the previous year. Because of how the algorithm is designed, there exists an algorithmic bias for songs that you listened to 2 years ago. Because the algorithm considers how much you listen to the songs in the previous playlist, it establishes a bias for those songs.", "Humans don\u2019t usually experience drastic change in preferences in music. Songs that you enjoyed in previous years tend to be enjoyable in the current year. Bias is not inherently negative, while there exist bias within the algorithm, the algorithm works within the Sporify platform. Having biased training data is a form of preprocessed data. It is important to be aware of the bias, but it doesn\u2019t have to be a bad thing.", "For example, LinkedIn has a messenger system with a great response suggestion system. This is because the messages that LinkedIn trains their model on are more biased towards business-formal messages. Biased training data can benefit a model based off the context in which they are used. LinkedIn\u2019s response recommendation system wouldn\u2019t work well if used for casual text messages, but is perfect for business messages in a professional career based website.", "It is important to be aware of the possible biases that can arise in every step of the analytical process. Being conscious of biases and how they influence our model with context is important because it can be a fatal flaw or an amazing benefit. As more data is collected and analyzed in the world, it is important to be aware of all the details and intricacies data can have.", "It\u2019s important to understand that Machine Learning algorithms are algorithms. Underneath the statistics and programming are math equations simply trying to maximize or minimize an equation. At the end of the day, it\u2019s understood that \u201cGarbage in means Garbage out\u201d.", "Notes: Because I want to focus on forms of biases that can arise from data, or implementation of models, I chose to speak a little about the technical definitions of statistical and machine learning bias.", "[1] S. Plous, The Psychology of Prejudice, Stereotyping and Discrimination: An Overview (2003), Understanding prejudice and discrimination (pp. 3\u201348). New York, NY, US: McGraw-Hill.", "[2] S. Lee and S. Lebowitz, 20 cognitive biases that screw up your decisions (2015), Business Insider", "[3] B. Wilson, J. Hoffman and J.Morgenstern, Predictive Inequity in Object Detection (2019), arXiv", "[5] R. Speer, How to make a racist AI without really trying (2017), ConceptNet Blog", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Statistics undergrad with an interest in learning and data science. Connect with me: https://www.linkedin.com/in/markxy/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6e64893e92a1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@MarkXY?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MarkXY?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Mark Xiang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e15fd7ddb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&user=Mark+Xiang&userId=1e15fd7ddb3e&source=post_page-1e15fd7ddb3e----6e64893e92a1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pdfs.semanticscholar.org/c6c0/2f8929a48871689d757122c1bb346c6265b5.pdf", "anchor_text": "research"}, {"url": "https://www.businessinsider.com/cognitive-biases-that-affect-decisions-2015-8", "anchor_text": "Source"}, {"url": "https://arxiv.org/pdf/1902.11097.pdf", "anchor_text": "scientific paper"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://researchportal.bath.ac.uk/en/publications/semantics-derived-automatically-from-language-corpora-necessarily", "anchor_text": "affected by the prejudice in the real world"}, {"url": "http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/", "anchor_text": "sentiment analysis model built using GloVe embedding"}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "racial biases with prediction models in the criminal justice system"}, {"url": "https://pdfs.semanticscholar.org/c6c0/2f8929a48871689d757122c1bb346c6265b5.pdf", "anchor_text": "The Psychology of Prejudice, Stereotyping and Discrimination: An Overview"}, {"url": "https://www.businessinsider.com/cognitive-biases-that-affect-decisions-2015-8", "anchor_text": "20 cognitive biases that screw up your decisions"}, {"url": "https://arxiv.org/pdf/1902.11097.pdf", "anchor_text": "Predictive Inequity in Object Detection"}, {"url": "https://researchportal.bath.ac.uk/en/publications/semantics-derived-automatically-from-language-corpora-necessarily", "anchor_text": "Semantics derived automatically from language corpora contain human-like biases"}, {"url": "https://doi.org/10.1126/science.aal4230", "anchor_text": "https://doi.org/10.1126/science.aal4230"}, {"url": "http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/", "anchor_text": "How to make a racist AI without really trying"}, {"url": "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing", "anchor_text": "Machine Bias"}, {"url": "https://medium.com/tag/bias?source=post_page-----6e64893e92a1---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6e64893e92a1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----6e64893e92a1---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/tag/psychology?source=post_page-----6e64893e92a1---------------psychology-----------------", "anchor_text": "Psychology"}, {"url": "https://medium.com/tag/human-behavior?source=post_page-----6e64893e92a1---------------human_behavior-----------------", "anchor_text": "Human Behavior"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&user=Mark+Xiang&userId=1e15fd7ddb3e&source=-----6e64893e92a1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&user=Mark+Xiang&userId=1e15fd7ddb3e&source=-----6e64893e92a1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6e64893e92a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6e64893e92a1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6e64893e92a1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6e64893e92a1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6e64893e92a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MarkXY?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MarkXY?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mark Xiang"}, {"url": "https://medium.com/@MarkXY/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9 Followers"}, {"url": "https://www.linkedin.com/in/markxy/", "anchor_text": "https://www.linkedin.com/in/markxy/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e15fd7ddb3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&user=Mark+Xiang&userId=1e15fd7ddb3e&source=post_page-1e15fd7ddb3e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F1e15fd7ddb3e%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-what-it-means-in-the-big-data-world-6e64893e92a1&user=Mark+Xiang&userId=1e15fd7ddb3e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}