{"url": "https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1", "time": 1682995904.150314, "path": "towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1/", "webpage": {"metadata": {"title": "AI Fairness \u2014 Explanation of Disparate Impact Remover | by Stacey Ronaghan | Towards Data Science", "h1": "AI Fairness \u2014 Explanation of Disparate Impact Remover", "description": "AI Fairness is an important topic for machine learning practitioners. We must be aware that there can be both positive and negative implications for users when they interact with our models. Although\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1412.3756", "anchor_text": "\u201cCertifying and removing disparate impact\u201d by M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian", "paragraph_index": 15}, {"url": "https://nbviewer.jupyter.org/github/srnghn/bias-mitigation-examples/blob/master/Bias%20Mitigation%20with%20Disparate%20Impact%20Remover.ipynb", "anchor_text": "here", "paragraph_index": 26}, {"url": "http://aif360.mybluemix.net/", "anchor_text": "AI Fairness 360", "paragraph_index": 26}], "all_paragraphs": ["AI Fairness is an important topic for machine learning practitioners. We must be aware that there can be both positive and negative implications for users when they interact with our models. Although our metric of success tends to be a performance metric (e.g. accuracy), those that interact with our models may consider other values as well. Tools using AI are being built to: approve or deny loans; decide if a person should be considered for an interview, and; determine if someone\u2019s a good candidate for treatment. These outcomes all have high impact repercussions for the individual. This is why fairness is such an important value to consider.", "In order to ensure fairness, we must analyze and address any bias that may be present in our training data. Machine learning discovers and generalizes patterns in the data and could, therefore, replicate bias. When implementing these models at scale, it can result in a large number of biased decisions, harming a large number of users.", "Data collection, processing, and labeling are common activities where we introduce bias in our data.", "Disparate Impact is a metric to evaluate fairness. It compares the proportion of individuals that receive a positive output for two groups: an unprivileged group and a privileged group.", "The calculation is the proportion of the unprivileged group that received the positive outcome divided by the proportion of the privileged group that received the positive outcome.", "The industry standard is a four-fifths rule: if the unprivileged group receives a positive outcome less than 80% of their proportion of the privileged group, this is a disparate impact violation. However, you may decide to increase this for your business.", "One approach for mitigating bias that some people often suggest is simply to remove the feature that should be protected. For example, if you are concerned of a model being sexist and you have gender available in your data set, remove it from the features passed to the machine learning algorithm. Unfortunately, this rarely fixes the problem.", "Opportunities experienced by the privileged group may not have been presented to the unprivileged group; members of each group may not have access to the same resources, whether financial or otherwise. This means their circumstances, and consequently, their features for a machine learning model, are different and not necessarily comparable. This is a consequence of systematic bias.", "Let\u2019s take a toy example with an unprivileged group, Blue, and a privileged group, Orange. Due to circumstances out of their control, Blue tend to have lower values for our feature of interest, Feature.", "We can plot the distribution of Feature for each of the two groups and visually see this disparity.", "If you were to randomly pick a data point, you could use its value of Feature to predict which group you selected from.", "For example, if you select a data point with Feature value 6 you would most likely assume the corresponding individual belonged in the Orange group. Conversely, for 5, you\u2019d assume they belonged in Blue.", "Feature may not necessarily be a useful attribute to predict the expected outcome. However, if the labels for your training data favor group Orange, Feature will be weighted more highly as it can be used to infer grouping.", "As an example, a person\u2019s name doesn\u2019t necessarily impact their ability to do a job and, therefore, shouldn\u2019t impact whether or not they are hired. However, if the recruiter is unconsciously biased, they may infer the candidate\u2019s gender or race from the name and use this as part of their decision making.", "Disparate Impact Remover is a pre-processing technique that edits values, which will be used as features, to increase fairness between the groups. As seen in the diagram above, a feature can give a good indication as to which group a data point may belong to. Disparate Impact Remover aims to remove this ability to distinguish between group membership.", "The technique was introduced in the paper \u201cCertifying and removing disparate impact\u201d by M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian.", "The algorithm requires the user to specify a repair_level, this indicates how much you wish for the distributions of the groups to overlap. Let\u2019s explore the impact of two different repair levels, 1.0 and 0.8.", "This diagram shows the repaired values for Feature for the unprivileged group Blue and privileged group Orange after using DisparateImpactRemover with a repair level of 1.0.", "You are no longer able to select a point and infer which group it belongs to. This would ensure no group bias is discovered by a machine learning model.", "This diagram shows the repaired values for Feature for the unprivileged group Blue and privileged group Orange after using DisparateImpactRemover with a repair level of 0.8.", "The distributions do not entirely overlap but you would still struggle to distinguish between membership, making it more difficult for a model to do so.", "When features show a disparity between two groups, we assume that they\u2019ve been presented with different opportunities and experiences. However, within group, we are assuming that their experiences are similar. Consequently, we wish for an individual\u2019s ranking within their group to be preserved after repair. Disparate Impact Remover preserves rank-ordering within groups; if an individual has the highest score for group Blue, it will still have the highest score among Blues after repair.", "Once Disparate Impact Remover has been implemented, a machine learning model can be built using the repaired data. The Disparate Impact metric will validate if the model is unbiased (or within an acceptable threshold).", "Bias mitigation may result in a lower performance metric (e.g. accuracy) but this doesn\u2019t necessarily mean the final model would be inaccurate.", "This is a challenge for AI practitioners: when you know you have biased data, you realize that the ground truth you\u2019re building a model with doesn\u2019t necessarily reflect reality nor the values you wish to uphold.", "As part of my investigation into DisparateImpactRemover, I created an example notebook using a toy dataset. It demonstrates the following:", "This is available on GitHub here. The library we are using to implement this algorithm is AI Fairness 360.", "The concept of fairness is incredibly nuanced and no algorithmic approach to bias mitigation is perfect. However, by considering our users\u2019 values, and implementing these techniques, we are stepping in the right direction to a fairer world.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist keen to share experiences & learnings from work & studies"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fce0da59451f1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://srnghn.medium.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": ""}, {"url": "https://srnghn.medium.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Stacey Ronaghan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F60a50d133053&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&user=Stacey+Ronaghan&userId=60a50d133053&source=post_page-60a50d133053----ce0da59451f1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/abs/1412.3756", "anchor_text": "\u201cCertifying and removing disparate impact\u201d by M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian"}, {"url": "https://nbviewer.jupyter.org/github/srnghn/bias-mitigation-examples/blob/master/Bias%20Mitigation%20with%20Disparate%20Impact%20Remover.ipynb", "anchor_text": "here"}, {"url": "http://aif360.mybluemix.net/", "anchor_text": "AI Fairness 360"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ce0da59451f1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----ce0da59451f1---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/fairness?source=post_page-----ce0da59451f1---------------fairness-----------------", "anchor_text": "Fairness"}, {"url": "https://medium.com/tag/bias?source=post_page-----ce0da59451f1---------------bias-----------------", "anchor_text": "Bias"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ce0da59451f1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&user=Stacey+Ronaghan&userId=60a50d133053&source=-----ce0da59451f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&user=Stacey+Ronaghan&userId=60a50d133053&source=-----ce0da59451f1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fce0da59451f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ce0da59451f1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ce0da59451f1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ce0da59451f1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ce0da59451f1--------------------------------", "anchor_text": ""}, {"url": "https://srnghn.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://srnghn.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Stacey Ronaghan"}, {"url": "https://srnghn.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F60a50d133053&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&user=Stacey+Ronaghan&userId=60a50d133053&source=post_page-60a50d133053--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcb737eb5ff94&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1&newsletterV3=60a50d133053&newsletterV3Id=cb737eb5ff94&user=Stacey+Ronaghan&userId=60a50d133053&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}