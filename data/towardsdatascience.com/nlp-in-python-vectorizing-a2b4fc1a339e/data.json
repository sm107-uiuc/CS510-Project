{"url": "https://towardsdatascience.com/nlp-in-python-vectorizing-a2b4fc1a339e", "time": 1683008832.164999, "path": "towardsdatascience.com/nlp-in-python-vectorizing-a2b4fc1a339e/", "webpage": {"metadata": {"title": "NLP in Python- Vectorizing. Common vectorizing techniques employed\u2026 | by Divya Raghunathan | Towards Data Science", "h1": "NLP in Python- Vectorizing", "description": "In this article, we will learn about vectorizing and different vectorizing techniques employed in an NLP model. Then, we will apply these concepts to the context of a problem. We will work with a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@divyar2630", "anchor_text": "article", "paragraph_index": 5}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "Count Vectorizer", "paragraph_index": 6}], "all_paragraphs": ["In this article, we will learn about vectorizing and different vectorizing techniques employed in an NLP model. Then, we will apply these concepts to the context of a problem.", "We will work with a dataset that classifies news as fake or real. The dataset is available on Kaggle, the link to the dataset is below:", "The initial step involved in a typical machine learning text pipeline is data cleaning. This step is covered in detailed in a previous article, linked below:", "The raw news titles were transformed into a cleaned format containing only the essential information (last column of the above picture). The next step is to further transform the cleaned text into a form that the machine learning model can understand. This process is known as Vectorizing. In our context, each news title is converted to a numerical vector representative of that particular title. There are many vectorization techniques, but in this article, we will focus on the three widely used vectorization techniques- Count vectorization, N-Grams, TF-IDF, and their implementation in Python.", "As discussed above, vectorization is the process of converting text to numerical entries in a matrix form. In the count vectorization technique, a document term matrix is generated where each cell is the count corresponding to the news title indicating the number of times a word appears in a document, also known as the term frequency. The document term matrix is a set of dummy variables that indicates if a particular word appears in the document. A column is dedicated to each word in the corpus. The count is directly proportionate to the correlation of the category of the news title. This means, if a particular word appears many times in fake news titles or real news titles, then the particular word has a high predictive power of determining if the news title is fake or real.", "Dissecting the above code, the function \u201cclean_title\u201d- joins the lowercase news titles without punctuation. Then, the text is split on any non-word character. Finally, the non-stop words are stemmed and presented as a list. A detailed description of the cleaning process is given in this article.", "Next, we have made use of the \u201cCountVectorizer\u201d package available in the sklearn library under sklearn.feature_extraction.text. The default values and the definition are available in the scikit-learn \u2014 Count Vectorizer documentation. In the above code, we have instantiated Count Vectorizer and defined one parameter \u2014 analyzer. The other parameters are its default values. The analyzer parameter calls for a string and we have passed a function, that takes in raw text and returns a cleaned string.", "The vectorizer produces a sparse matrix output, as shown in the picture. Only the locations of the non-zero values will be stored to save space. So, an output of the vectorization will look something like this:", "but, converting the above to an array form yields the below result:", "As shown in the picture, most of the cells contain a 0 value, this is known as a sparse matrix. Many vectorized outputs would look similar to this, as naturally many titles wouldn\u2019t contain a particular word.", "Similar to the count vectorization technique, in the N-Gram method, a document term matrix is generated and each cell represents the count. The difference in the N-grams method is that the count represents the combination of adjacent words of length n in the title. Count vectorization is N-Gram where n=1. For example, \u201cI love this article\u201d has four words and n=4.", "if n=3, i.e trigram, then the columns would be \u2014 [\u201cI love this\u201d, \u201dlove this article\u201d]", "The n value is chosen based on performance.", "For the python code, the cleaning process is performed similarly to the count vectorization technique, but the words are not in a tokenized list form. The tokenized words are joined to form a string, so the adjacent words can be gathered to effectively perform N-Grams.", "The cleaned title text is shown below:", "The remaining vectorization technique is the same as the Count Vectorization method we did above.", "The trade-off is between the number of N values. Choosing a smaller N value, may not be sufficient enough to provide the most useful information. Whereas choosing a high N value, will yield a huge matrix with loads of features. N-gram may be powerful, but it needs a little more care.", "3. Term Frequency-Inverse Document Frequency (TF-IDF)", "Similar to the count vectorization method, in the TF-IDF method, a document term matrix is generated and each column represents a single unique word. The difference in the TF-IDF method is that each cell doesn\u2019t indicate the term frequency, but the cell value represents a weighting that highlights the importance of that particular word to the document.", "The second term of the equation helps in pulling out the rare words. What does that mean? If a word appeared multiple times across many documents, then the denominator df will increase, reducing the value of the second term. Term frequency or tf is the percentage of the number of times a word (x) occurs in the document (y) divided by the total number of words in y.", "For the python code, we will use the same cleaning process as the Count Vectorizer method. Sklearn\u2019s TfidfVectorizer can be used for the vectorization portion in Python.", "The sparse matrix output for this method displays decimals representing the weight of the word in the document. High weight means that the word occurs many times within a few documents and low weight means that the word occurs fewer times in a lot of documents or repeats across multiple documents.", "There is no rule of thumb in choosing a vectorization method. I often decide based on the business problem at hand. If there are no constraints, I often start with the easiest method (usually fastest).", "I\u2019d love to hear your thoughts and feedback on my articles. Please do leave them in the comment section below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Budding Data Scientist | Business Analytics Graduate Student"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa2b4fc1a339e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@divyar2630?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@divyar2630?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Divya Raghunathan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F66aeee465ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&user=Divya+Raghunathan&userId=66aeee465ed4&source=post_page-66aeee465ed4----a2b4fc1a339e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@romankraft", "anchor_text": "Roman Kraft"}, {"url": "https://unsplash.com/", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset", "anchor_text": "https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset"}, {"url": "https://towardsdatascience.com/nlp-in-python-data-cleaning-6313a404a470", "anchor_text": "NLP in Python-Data cleaningData cleaning steps involved in a typical NLP machine learning model pipeline using the real or fake news dataset from\u2026towardsdatascience.com"}, {"url": "https://medium.com/@divyar2630", "anchor_text": "article"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html", "anchor_text": "Count Vectorizer"}, {"url": "https://medium.com/tag/nlp?source=post_page-----a2b4fc1a339e---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a2b4fc1a339e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----a2b4fc1a339e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data?source=post_page-----a2b4fc1a339e---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a2b4fc1a339e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&user=Divya+Raghunathan&userId=66aeee465ed4&source=-----a2b4fc1a339e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&user=Divya+Raghunathan&userId=66aeee465ed4&source=-----a2b4fc1a339e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa2b4fc1a339e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a2b4fc1a339e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a2b4fc1a339e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@divyar2630?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@divyar2630?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Divya Raghunathan"}, {"url": "https://medium.com/@divyar2630/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "30 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F66aeee465ed4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&user=Divya+Raghunathan&userId=66aeee465ed4&source=post_page-66aeee465ed4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa68f67a2a7d4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-in-python-vectorizing-a2b4fc1a339e&newsletterV3=66aeee465ed4&newsletterV3Id=a68f67a2a7d4&user=Divya+Raghunathan&userId=66aeee465ed4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}