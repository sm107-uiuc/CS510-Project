{"url": "https://towardsdatascience.com/feature-selection-and-dimensionality-reduction-f488d1a035de", "time": 1682995508.1145668, "path": "towardsdatascience.com/feature-selection-and-dimensionality-reduction-f488d1a035de/", "webpage": {"metadata": {"title": "Feature Selection and Dimensionality Reduction | by Tara Boyle | Towards Data Science", "h1": "Feature Selection and Dimensionality Reduction", "description": "This article explores methods for feature selection and dimensionality reduction in python. Techniques include removal of low variance features and PCA."}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Feature_selection", "anchor_text": "wikipedia", "paragraph_index": 0}, {"url": "https://www.kaggle.com/tboyle10/feature-selection", "anchor_text": "here.", "paragraph_index": 3}], "all_paragraphs": ["According to wikipedia, \u201cfeature selection is the process of selecting a subset of relevant features for use in model construction\u201d or in other words, the selection of the most important features.", "In normal circumstances, domain knowledge plays an important role and we could select features we feel would be the most important. For example, in predicting home prices the number of bedrooms and square footage are often considered important.", "Unfortunately, here in the Don\u2019t Overfit II competition, the use of domain knowledge is impossible as we have a binary target and 300 continuous variables \u201cof mysterious origin\u201d forcing us to try automatic feature selection techniques.", "The full notebook can be found here.", "Often, feature selection and dimensionality reduction are grouped together (like here in this article). While both methods are used for reducing the number of features in a dataset, there is an important difference.", "Feature selection is simply selecting and excluding given features without changing them.", "Dimensionality reduction transforms features into a lower dimension.", "In this article we will explore the following feature selection and dimensionality reduction techniques:", "We\u2019ll use logistic regression as our baseline model. We first split into test and train sets and scale the data:", "We can see the model is overfitting from the variation in cross validation scores. We can attempt to improve these scores through feature selection.", "Checking for missing values is a good first step in any machine learning problem. We can then remove columns exceeding a threshold we define.", "Unfortunately for our dimensionality reduction efforts, this dataset has zero missing values.", "In sklearn\u2019s feature selection module we find VarianceThreshold. It removes all features whose variance doesn\u2019t meet some threshold. By default it removes features with zero variance or features that have the same value for all samples.", "The competition description stated that our features are all continuous. We can see from above there are no features with the same value in all columns, so we have no features to remove here.", "We can always revisit this technique and consider removing features with low variance.", "Features that are highly correlated or co-linear can cause overfitting.", "When a pair of variables are highly correlated we can remove one to reduce dimensionality without much loss of information. Which one should we keep? The one with a higher correlation to the target.", "Let\u2019s explore correlations among our features:", "Here we see the features that are most highly correlated with our target variable. Feature 33 has the highest correlation to the target, but with a correlation value of only 0.37, it is only weakly correlated.", "We can also check the correlation of features to other features. Below we can visualize a correlation matrix. It looks like none of our features are very highly correlated.", "Let\u2019s try to drop features with a correlation value greater than 0.5:", "We have no columns to drop using highly correlated features. Let\u2019s continue to explore other strategies.", "Univariate feature selection works by selecting the best features based on univariate statistical tests.", "We can use sklearn\u2019s SelectKBest to select a number of features to keep. This method uses statistical tests to select features having the highest correlation to the target. Here we will keep the top 100 features.", "Recursive feature selection works by eliminating the least important features. It continues recursively until the specified number of features is reached. Recursive elimination can be used with any model that assigns weights to features, either through coef_ or feature_importances_", "Here we will use Random Forest to select the 100 best features:", "Like recursive feature selection, sklearn\u2019s SelectFromModel is used with any estimator that has a coef_ or feature_importances_ attribute. It removes features with values below a set threshold.", "PCA (Principle Component Analysis) is a dimensionality reduction technique that projects the data into a lower dimensional space.", "While there are many effective dimensionality reduction techniques, PCA is the only example we will explore here.", "PCA can be useful in many situations, but especially in cases with excessive multicollinearity or explanation of predictors is not a priority.", "Here we will apply PCA and keep 90% of the variance:", "We can see that we are left with 139 features that explain 90% of the variance in our data.", "Feature selection is an important part of any machine learning process. Here we explored several methods for feature selection and dimensionality reduction that can aid in improving model performance.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m passionate about all things data! I\u2019m interested in leveraging data to create business solutions."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff488d1a035de&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f488d1a035de--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@terrah27?source=post_page-----f488d1a035de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@terrah27?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Tara Boyle"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a7b274f3032&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&user=Tara+Boyle&userId=2a7b274f3032&source=post_page-2a7b274f3032----f488d1a035de---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/CMuFjjDHI70?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "rawpixel"}, {"url": "https://unsplash.com/search/photos/collection?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Feature_selection", "anchor_text": "wikipedia"}, {"url": "https://www.kaggle.com/tboyle10/feature-selection", "anchor_text": "here."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f488d1a035de---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f488d1a035de---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/feature-selection?source=post_page-----f488d1a035de---------------feature_selection-----------------", "anchor_text": "Feature Selection"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----f488d1a035de---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&user=Tara+Boyle&userId=2a7b274f3032&source=-----f488d1a035de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&user=Tara+Boyle&userId=2a7b274f3032&source=-----f488d1a035de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff488d1a035de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f488d1a035de---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f488d1a035de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f488d1a035de--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f488d1a035de--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f488d1a035de--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f488d1a035de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@terrah27?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@terrah27?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tara Boyle"}, {"url": "https://medium.com/@terrah27/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a7b274f3032&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&user=Tara+Boyle&userId=2a7b274f3032&source=post_page-2a7b274f3032--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Feca374d3ba4a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-and-dimensionality-reduction-f488d1a035de&newsletterV3=2a7b274f3032&newsletterV3Id=eca374d3ba4a&user=Tara+Boyle&userId=2a7b274f3032&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}