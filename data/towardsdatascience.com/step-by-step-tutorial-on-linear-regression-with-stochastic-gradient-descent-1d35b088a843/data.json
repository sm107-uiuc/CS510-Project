{"url": "https://towardsdatascience.com/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843", "time": 1682994161.345244, "path": "towardsdatascience.com/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843/", "webpage": {"metadata": {"title": "Tutorial: Linear Regression with Stochastic Gradient Descent | by Raimi Karim | Towards Data Science", "h1": "Tutorial: Linear Regression with Stochastic Gradient Descent", "description": "This article should provide you a good start for us to dive deep into deep learning. Let me walk you through the step-by-step calculations for a linear regression task using stochastic gradient\u2026"}, "outgoing_paragraph_urls": [{"url": "https://remykarem.github.io/backpropagation-demo/", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://www.tensorflow.org/api_docs/python/tf/placeholder", "anchor_text": "TensorFlow", "paragraph_index": 23}, {"url": "https://remykarem.github.io/backpropagation-demo/", "anchor_text": "here", "paragraph_index": 59}, {"url": "https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281", "anchor_text": "Line-by-Line Word2Vec Implementation", "paragraph_index": 61}, {"url": "https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9", "anchor_text": "10 Gradient Descent Optimisation Algorithms + Cheat Sheet", "paragraph_index": 62}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889", "anchor_text": "Counting No. of Parameters in Deep Learning Models", "paragraph_index": 63}, {"url": "https://medium.com/@renjietan", "anchor_text": "Ren Jie", "paragraph_index": 64}, {"url": "https://medium.com/@derekchia", "anchor_text": "Derek", "paragraph_index": 64}, {"url": "https://www.twitter.com/remykarem", "anchor_text": "Twitter", "paragraph_index": 65}, {"url": "http://www.linkedin.com/in/raimibkarim", "anchor_text": "LinkedIn", "paragraph_index": 65}, {"url": "https://remykarem.github.io/", "anchor_text": "remykarem.github.io", "paragraph_index": 65}, {"url": "http://remykarem.medium.com/membership", "anchor_text": "remykarem.medium.com/membership", "paragraph_index": 66}], "all_paragraphs": ["You can find the backpropagation demo here.", "This article should provide you a good start for us to dive deep into deep learning. Let me walk you through the step-by-step calculations for a linear regression task using stochastic gradient descent.", "We have some data: as we observe the independent variables x\u2081 and x\u2082, we observe the dependent variable (or response variable) y along with it.", "In our dataset, we have 6 examples (or observations).", "The next question to ask: \u201cHow are both x\u2081 and x\u2082 related to y?\u201d", "We believe that they are connected to each other by this equation:", "Our job today is to find the \u2018best\u2019 w and b values.", "I have used the deep learning conventions w and b, which stand for weights and biases respectively. But note that linear regression is not deep learning.", "Let\u2019s say at the end of this exercise, we\u2019ve figured out our model to be", "How do we know if our model is doing well?", "We simply compare the predicted \u0177 and the observed y through a loss function. There are many ways to define the loss function but in this post, we define it as the squared difference between \u0177 and y.", "Generally, the smaller the L, the better.", "Because we want the difference between \u0177 and y to be small, we want to make an effort to minimise it. This is done through stochastic gradient descent optimisation. It is basically iteratively updating the values of w\u2081 and w\u2082 using the value of gradient, as in this equation:", "This algorithm tries to find the right weights by constantly updating them, bearing in mind that we are seeking values that minimise the loss function.", "You are w and you are on a graph (loss function). Your current value is w=5. You want to move to the lowest point in this graph (minimising the loss function).", "You also know that, with your current value, your gradient is 2. You somehow must make use of this value to move on with life.", "From high school math, 2 means you\u2019re on an inclined slope and the only way you can descend is to move left, at this point.", "If taking 5+2 means you\u2019re going to the right climbing up the slope, then the only way is to take 5\u20132 which brings you to the left, descending down. So gradient descent is all about subtracting the value of the gradient from its current value.", "The workflow for training our model is simple: forward propagation (or feed-forward or forward pass) and backpropagation.", "Definition: trainingTraining just means regularly updating the values of your weights, put simply.", "Below is the workflow. Click to jump to the section.", "To keep track of all the values, we first build a \u2018computation graph\u2019 that comprises nodes colour-coded in", "For forward propagation, you should read this graph from top to bottom and for backpropagation bottom to top.", "NoteI have adopted the term \u2018placeholder\u2019, a nomenclature used in TensorFlow to refer to these \u2018data variables\u2019.I will also use the term \u2018weights\u2019 to refer to w and b collectively.", "Since gradient descent is all about updating the weights, we need them to start with some values, known as initialising weights.", "Here we initialised the weights and bias as follows:", "These are reflected in the dark green nodes in Fig. 2.1.1 below:", "There are many ways to initialise weights (zeros, ones, uniform distribution, normal distribution, truncated normal distribution, etc.) but we won\u2019t cover them in this post. In this tutorial, we initialised the weights by using truncated normal distribution and the bias with 0.", "Next, we set the batch size to be 1 and we feed in this first batch of data.", "We can divide our dataset into smaller groups of equal size. Each group is called a batch and consists of a specified number of examples, called batch size. If we multiply these two numbers, we should get back the number of observations in our data.", "Here, our dataset consists of 6 examples and since we defined the batch size to be 1 in this training, we have 6 batches altogether.", "Current batch of data used to feed in the model is bolded below:", "In Fig. 2.1.2, the orange nodes are where we feed in the current batch of data.", "Now that we have the values of x\u2081, x\u2082, w\u2081, w\u2082 and b ready, let\u2019s compute \u0177.", "The value of \u0177 (=-0.1) is reflected in the light green node below:", "How far is our predicted \u0177 from the given y data? We compare them by calculating the loss function L as defined earlier.", "You can see this value in the yellow node in the computation graph.", "It is a common practice to log the loss during training, together with other information like the epoch, batch and time taken. In my demo, you can see this under the Training progress panel.", "Before we start adjusting the values of the weights and bias w\u2081, w\u2082 and b, let\u2019s first compute all the partial differentials. These are needed later when we do the weight update.", "Namely, we compute all possible paths leading to every w and b only, because these are the only variables which we are interested in updating. From Fig. 2.2.1 above, we see that there are 4 edges that we labeled with the partial differentials.", "Recall the equations for the model and loss function:", "The partial differentials are as follows:", "Note that the values of the partial differentials follow the values from the current batch. For example, in Eqn. 2.2.1C, x\u2081 = 4.", "Also pay attention to the \u2018direction\u2019 of the pathway from the yellow node to the green node. They go from bottom to top.", "This is stochastic gradient descent \u2014 updating the weights using backpropagation, making use of the respective gradient values.", "Let\u2019s first focus on updating b. The formula for updating b is", "To get the gradient, we need to multiply the paths from L leading to b using chain rule:", "We would require the current batch values of x, y, \u0177 and the partial differentials so let\u2019s just place them below for easy reference:", "Using the stochastic gradient descent equation in Eqn. 2.2.2A and plugging in all the values from Eqn. 2.2.2B-D gives us:", "That\u2019s it for updating b! Phew! We are left with updating w\u2081 and w\u2082, which we update in a similar fashion.", "Congrats! That\u2019s it for dealing with the first batch!", "Now we need to iterate the above-mentioned steps to the other 5 batches, namely examples 2 to 6.", "We complete 1 epoch when the model has iterated through all the batches once. In practice, we extend the epoch to more than 1.", "One epoch is when our setup has seen all the observations in our dataset once. But one epoch is almost always never enough for the loss to converge. In practice, this number is manually tuned.", "At the end of it all, you should get a final model, ready for inference, say:", "Let\u2019s have a review of the entire workflow in a pseudo-code:", "One epoch is never enough for a stochastic gradient descent optimisation problems. Remember that in Fig. 4.1, our loss is at 4.48. If we increase the number of epochs, which means just increasing the number of times we update the weights and biases, we can converge it to a satisfactory low.", "Below are the things you can improve the training:", "I built an interactive explorable demo on linear regression with gradient descent in JavaScript. Here are the libraries I used:", "Check out the interactive demo here.", "You might also like to check out A Line-by-Line Layman\u2019s Guide to Linear Regression using TensorFlow below, which focuses on coding linear regression using the TensorFlow library.", "Line-by-Line Word2Vec Implementation (on word embeddings)", "10 Gradient Descent Optimisation Algorithms + Cheat Sheet", "Counting No. of Parameters in Deep Learning Models", "Thanks to Ren Jie and Derek for ideas, suggestions and corrections to this article.", "Follow me on Twitter @remykarem or LinkedIn. You may also reach out to me via raimi.bkarim@gmail.com. Feel free to visit my website at remykarem.github.io.", "\ud83c\uddf8\ud83c\uddec Software Engineer at GovTech \u2022 Master of Computing AI at NUS \u2022 Subscribe at remykarem.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1d35b088a843&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://unsplash.com/photos/7_kRuX1hSXM?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Lindsay Henwood"}, {"url": "https://unsplash.com/search/photos/stairs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://remykarem.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Raimi Karim"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc2958659896a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=post_page-c2958659896a----1d35b088a843---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d35b088a843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=-----1d35b088a843---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d35b088a843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=-----1d35b088a843---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://remykarem.github.io/backpropagation-demo/", "anchor_text": "here"}, {"url": "http://raiboso.me/backpropagation-demo/", "anchor_text": "here"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/placeholder", "anchor_text": "TensorFlow"}, {"url": "https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9", "anchor_text": "here"}, {"url": "https://remykarem.github.io/backpropagation-demo/", "anchor_text": "here"}, {"url": "https://medium.com/datadriveninvestor/a-line-by-line-laymans-guide-to-linear-regression-using-tensorflow-3c0392aa9e1f", "anchor_text": "A line-by-line layman\u2019s guide to Linear Regression using TensorFlowLinear regression is a great start to the journey of machine learning, given that it is a pretty straightforward\u2026medium.com"}, {"url": "https://colah.github.io/posts/2015-08-Backprop/", "anchor_text": "Calculus on Computational Graphs: Backpropagation -- colah's blogBackpropagation is the key algorithm that makes training deep models computationally tractable. For modern neural\u2026colah.github.io"}, {"url": "https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45", "anchor_text": "Animated RNN, LSTM and GRU"}, {"url": "https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281", "anchor_text": "Line-by-Line Word2Vec Implementation"}, {"url": "https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9", "anchor_text": "10 Gradient Descent Optimisation Algorithms + Cheat Sheet"}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889", "anchor_text": "Counting No. of Parameters in Deep Learning Models"}, {"url": "https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3", "anchor_text": "Attn: Illustrated Attention"}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a", "anchor_text": "Illustrated: Self-Attention"}, {"url": "https://medium.com/@renjietan", "anchor_text": "Ren Jie"}, {"url": "https://medium.com/@derekchia", "anchor_text": "Derek"}, {"url": "https://www.twitter.com/remykarem", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/in/raimibkarim", "anchor_text": "LinkedIn"}, {"url": "https://remykarem.github.io/", "anchor_text": "remykarem.github.io"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1d35b088a843---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----1d35b088a843---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/gradient-descent?source=post_page-----1d35b088a843---------------gradient_descent-----------------", "anchor_text": "Gradient Descent"}, {"url": "https://medium.com/tag/backpropagation?source=post_page-----1d35b088a843---------------backpropagation-----------------", "anchor_text": "Backpropagation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d35b088a843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=-----1d35b088a843---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d35b088a843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=-----1d35b088a843---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d35b088a843&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc2958659896a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=post_page-c2958659896a----1d35b088a843---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F307a18475417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&newsletterV3=c2958659896a&newsletterV3Id=307a18475417&user=Raimi+Karim&userId=c2958659896a&source=-----1d35b088a843---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Written by Raimi Karim"}, {"url": "https://remykarem.medium.com/followers?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "2.2K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "http://remykarem.medium.com/membership", "anchor_text": "remykarem.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc2958659896a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&user=Raimi+Karim&userId=c2958659896a&source=post_page-c2958659896a----1d35b088a843---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F307a18475417&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843&newsletterV3=c2958659896a&newsletterV3Id=307a18475417&user=Raimi+Karim&userId=c2958659896a&source=-----1d35b088a843---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Raimi Karim"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Illustrated: Self-AttentionA step-by-step guide to self-attention with illustrations and code"}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "\u00b79 min read\u00b7Nov 18, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d627e33b20a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-self-attention-2d627e33b20a&user=Raimi+Karim&userId=c2958659896a&source=-----2d627e33b20a----0-----------------clap_footer----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a?source=author_recirc-----1d35b088a843----0---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "28"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d627e33b20a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-self-attention-2d627e33b20a&source=-----1d35b088a843----0-----------------bookmark_preview----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----1d35b088a843----1---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----1d35b088a843----1-----------------bookmark_preview----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----1d35b088a843----2---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----1d35b088a843----2-----------------bookmark_preview----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Raimi Karim"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "Counting No. of Parameters in Deep Learning Models by Hand5 simple examples to count no. of parameters of FFNN, RNN and CNN models"}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": "5 min read\u00b7Jan 21, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8f1716241889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcounting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889&user=Raimi+Karim&userId=c2958659896a&source=-----8f1716241889----3-----------------clap_footer----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889?source=author_recirc-----1d35b088a843----3---------------------3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8f1716241889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcounting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889&source=-----1d35b088a843----3-----------------bookmark_preview----3febca1f_28d9_40ba_9ced_d6ae8ec24a21-------", "anchor_text": ""}, {"url": "https://remykarem.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "See all from Raimi Karim"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Sayef"}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Logistic Regression with Gradient Descent and Regularization: Binary & Multi-class ClassificationLearn how to implement logistic regression with gradient descent optimization from scratch."}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b713 min read\u00b7Apr 9"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcc25ed63f655&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40msayef%2Flogistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655&user=Sayef&userId=e05fb963b9fd&source=-----cc25ed63f655----0-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@msayef/logistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc25ed63f655&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40msayef%2Flogistic-regression-with-gradient-descent-and-regularization-binary-multi-class-classification-cc25ed63f655&source=-----1d35b088a843----0-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----1d35b088a843----1-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@AmyGrabNGoInfo?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Amy @GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "GrabNGoInfo"}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Gradient Descent vs Stochastic Gradient Descent vs Batch Gradient Descent vs Mini-batch Gradient\u2026Data science interview questions and answers"}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b74 min read\u00b7Dec 16, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgrabngoinfo%2F616ba269de8d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fgradient-descent-vs-616ba269de8d&user=Amy+%40GrabNGoInfo&userId=ef6171ffb4ed&source=-----616ba269de8d----0-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/grabngoinfo/gradient-descent-vs-616ba269de8d?source=read_next_recirc-----1d35b088a843----0---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F616ba269de8d&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgrabngoinfo%2Fgradient-descent-vs-616ba269de8d&source=-----1d35b088a843----0-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----1-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----1d35b088a843----1---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----1d35b088a843----1-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "vinay"}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "What is the R2 score and adjusted R2The R2 score and adjusted R2 are two metrics used to evaluate the performance of a regression model. R2, also known as the coefficient of\u2026"}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b73 min read\u00b7Dec 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7661ee355566&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-is-the-r2-score-and-adjusted-r2-7661ee355566&user=vinay&userId=6a7f4791df03&source=-----7661ee355566----2-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@vinaychaudhari1996/what-is-the-r2-score-and-adjusted-r2-7661ee355566?source=read_next_recirc-----1d35b088a843----2---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7661ee355566&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40vinaychaudhari1996%2Fwhat-is-the-r2-score-and-adjusted-r2-7661ee355566&source=-----1d35b088a843----2-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://ai.plainenglish.io/l1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@peterkaras?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/@peterkaras?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Peter Karas"}, {"url": "https://ai.plainenglish.io/?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "Artificial Intelligence in Plain English"}, {"url": "https://ai.plainenglish.io/l1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "L1 (Lasso) and L2 (Ridge) regularizations in logistic regressionLogistic regression , Lasso and Rigde regularizations, derivations, math"}, {"url": "https://ai.plainenglish.io/l1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": "\u00b76 min read\u00b7Feb 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fai-in-plain-english%2F53ab6c952f15&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fl1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15&user=Peter+Karas&userId=2b327b985531&source=-----53ab6c952f15----3-----------------clap_footer----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://ai.plainenglish.io/l1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15?source=read_next_recirc-----1d35b088a843----3---------------------124d744b_ecc8_432d_9c68_8a390c4e7906-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F53ab6c952f15&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fl1-lasso-and-l2-ridge-regularizations-in-logistic-regression-53ab6c952f15&source=-----1d35b088a843----3-----------------bookmark_preview----124d744b_ecc8_432d_9c68_8a390c4e7906-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1d35b088a843--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----1d35b088a843--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}