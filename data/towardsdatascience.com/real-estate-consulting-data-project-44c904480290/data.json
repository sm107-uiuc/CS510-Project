{"url": "https://towardsdatascience.com/real-estate-consulting-data-project-44c904480290", "time": 1683014080.0677938, "path": "towardsdatascience.com/real-estate-consulting-data-project-44c904480290/", "webpage": {"metadata": {"title": "Real Estate Consulting Data Project | by Nate Cibik | Towards Data Science", "h1": "Real Estate Consulting Data Project", "description": "Note from Towards Data Science\u2019s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author\u2019s contribution. You should\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms", "paragraph_index": 0}, {"url": "https://github.com/FoamoftheSea/dsc-mod-4-project-online-ds-sp-000", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://www.zillow.com/research/where-rent-covers-mortgage-15624/", "anchor_text": "Zillow research article", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Subprime_mortgage_crisis", "anchor_text": "subprime mortgage crisis", "paragraph_index": 11}, {"url": "https://www.zillow.com/research/where-rent-covers-mortgage-15624/", "anchor_text": "This Zillow research article", "paragraph_index": 12}, {"url": "https://www.financialsamurai.com/real-estate-investing-rule-rent-luxury-buy-utility/", "anchor_text": "Financial Samurai article", "paragraph_index": 14}], "all_paragraphs": ["Note from Towards Data Science\u2019s editors: While we allow independent authors to publish articles in accordance with our rules and guidelines, we do not endorse each author\u2019s contribution. You should not rely on an author\u2019s works without seeking professional advice. See our Reader Terms for details.", "Recently, I took on the task of advising an imaginary real estate investment firm on the top 5 zip codes to invest in according to insights attained from a dataset sourced from Zillow containing the average home sale price for each of 14,723 zip codes on a monthly frequency over a time window beginning on April 1996 and ending on April 2018. The analysis and modeling for the project were done using a combination of Python and R Jupyter notebooks. The data and project notebooks are available here in the project repository.", "Since the data used for the project end in April 2018, it was appropriate to imagine that this was the time at which the consultation was provided, since recent developments in the world are having widespread effects on financial and real estate markets, and there is no way to relate the project data to current events. It suffices to say that it is important to keep in mind that macroeconomic and sociopolitical issues can cause shocks in the market which are unforeseen, and any attempts at forecasting should take into account volatility clustering caused by such shocks. Fortunately, the data span across a time frame which includes the 2007\u20132010 financial and housing market collapse, providing an opportunity to observe how well individual zip codes weathered the last storm, allowing some insight into those which could be expected to show resilience to adverse economic and market conditions in the future. A number of zip codes did not have complete data over the time period of the database, making it impossible to make proper comparisons of their behavior against those which did, and were therefore left out of consideration.", "The investment recommendations were based on two main criteria: high expected capital appreciation rate with low expected variance, and the profitability of leasing the properties within the zip code over the investment horizon. To project capital appreciation rates for each zip code, a method was devised to quickly generate an appropriate SARIMAX model for each zip code so that comparisons could be made of the forecasted mean and volatility of returns over the investment horizon. To compare profitability of leasing properties within each zip code, a database was obtained from a 2017 Zillow research article containing P2R (price-to-rent) ratios for various metropolitan areas. These ratios could be compared to the national average, and give an idea of how many years of rent payments would pay off the value of a property in a given area.", "Coding blocks will follow the workflow presented in this article for demonstration. For a more in-depth investigation into the methods employed, please see the Jupyter notebooks in the repository. This article will cover an efficient method to generate well-fit SARIMAX models to time series data within a Python workflow which is fast enough to allow for each zip code to be individually modeled, so that these models can be compared to find the zip codes with the best outlooks. The method involves mixing the strengths of time series modeling packages from both Python and R (statsmodels and forecast, respectively), by calling the speedy model generating functionality of the auto.arima function in R\u2019s forecast package from within a Python workflow using the rpy2 package in order to generate optimal orders and coefficients for a SARIMAX model, then smoothing a statsmodels SARIMAX model with the values obtained. This was found to generate consistently satisfactory models in a way that avoids the time consuming process of grid searching for optimal model orders using loops, and allows for the benefits of all of the statistical explicity and functionality of statsmodels, as well as working in a Python environment.", "Please note that the contents of this article are intended only as a demonstration of a data science workflow and methods related to analyzing and modeling time-series data in the context of real estate, and are not to be taken as any form of investment advice. Unless otherwise noted, all images are the property of the author.", "First, we need to import all the libraries to use; we will be using many standard Python data science packages, especially pandas and statsmodels.", "Now using pandas to read the data:", "Looking at the raw data, we can see that there are two columns with 5 digit numbers to identify the \u201cregions.\u201d A few quick Google searches reveals that the \u2018RegionName\u2019 column contains the zip codes. The other column is not useful to us. We can also observe that the data are in what is called \u201cwide format,\u201d where the dates and their corresponding values for each zip code are contained in columns which expand the dataframe to the right, which is why it has 273 columns. To convert the data to long format, pandas\u2019 melt method can be used. For our purposes, we will want the data in long format. Testing found that the sizeRank feature was not useful.", "This operation has duplicated each zip code for each date that was found in the columns, leading to a dataframe with 3,901,595 rows. It would be possible to use a MultiIndex DataFrame to work with panel data at this point, but using a GroupBy object is the method I will use here. First, the \u2018date\u2019 column needs to be converted to datetime, and we need to check for missing values.", "This last operation reveals that there are 156,891 missing values in the \u2018value\u2019 column, which we will need to keep in mind moving forward. Now, let\u2019s create our GroupBy object, and take our first look at some zip codes.", "Having our first look at some data, we can see that the individual zip codes have many differences. Just looking at the first 6 out of 14,723, we can see differences in average value and growth rate. We can also see that there is a general trend that they are following, with rising values up until the subprime mortgage crisis between 2007 and 2010 crashed the market, and then a subsequent recovery beginning around 2013. Just looking at these 6, we can see that some zip codes weathered the storm better than others, and this would be an attractive feature for investors who realize that future downturns may be caused by unforeseen macroeconomic effects.", "We now have some ideas about what we might look for when identifying the \u201c5 best zip codes\u201d to recommend to an investor: growth rate and resilience to poor economic environment; but there are others to consider. First, one would feel most confident in an investment if the expected rate of growth is complemented by low expected volatility. Second, it would be best to lease the owned properties to renters during the holding period, so that the capital is not just sitting around doing nothing. This means that we should recommend zip codes that not only have strong expected growth, low expected variance, and resilience to poor economic conditions, but that also have a better than average leasing profitability. In order to determine this, we can turn to a metric called Price-to-Rent (P2R) Ratio. This ratio gives us an idea of the proportion between the price to purchase and own a property in a given area, and the amount that renters are willing to pay per year there. This Zillow research article by Jamie Anderson provides more considerations real estate investors should make about the profitability of renting properties, and provides the data which we will import now.", "We can see that the national average P2R at the time of the article (June 19, 2017, conveniently near the end of our data set) was 11.44. According the the article, the majority of homes in most \u201cmajor markets\u201d can be rented for a profit, so it stands to reason that real estate investments in any zip code with a P2R below the national average will not only be profitable to the property owner as a rental, but the profitability will be better than the average across the country.", "Another rich source of real estate investment advice comes from this Financial Samurai article written by Sam Dogen. In the article, Dogen suggests investors follow what he calls a \u201ckey real estate investing rule\u201d: Buy Utility, Rent Luxury (BURL). Dogen explains that luxury properties (especially in coastal cities) tend not to have near the profitability through leasing as utility homes (especially in the Midwest), and often have no leasing profitability at all, where the rent does not cover the yearly costs of ownership. Dogen cites the Zillow research article from above, and uses the P2R ratio to make distinctions between luxury and utility, where he labels everything with a P2R less than 9.6 as utility, and anything with a P2R above 13.3 as luxury. This means that we should be looking for zip codes with P2R below the national average, and hopefully below 9.6 if possible. It stands to reason that since expected rate of capital appreciation is one of our criteria, we may not be able to get all zip codes with P2R below 9.6 since expected growth rate is often reflected in the price of capital, but this gives us a solid target for our contenders. It is also safe to assume that a zip code with homes that would be considered utility would not have an average sale price over $500,000, so this will help narrow our list as well.", "Before we can iterate through all of our zip codes and produce a model for each, we need a good way to quickly generate a well-fit model for a single zip code. Statsmodels gives us great functionality with SARIMAX models, but it does not contain a method to determine the optimal orders for such a model. Grid searching using loops and comparing AIC scores is painfully slow, especially if one wants to consider lags up to, say, 5 or 6 for the AR and MA terms. Luckily, the forecast package for R has an auto.arima function which can quickly find optimal orders and coefficients given a time series. With this, we have the option of either taking the suggested orders and have statsmodels estimate the coefficients, or we could smooth a statsmodels SARIMAX of the suggested order with the given coefficients. It was found during this study that the coefficients estimated by the auto.arima function consistently produced lower AIC scores than those estimated using statsmodels, so we will make our models using the former. To see how we will do this, we first need to look at how we can call an R function from Python using rpy2. We will start by importing the necessary items.", "We can now use functions from the forecast package in our Python workflow, but making use of the outputs will take a bit of tinkering. The coefficients and their names are available in vectors attached to the returned object, but the orders are not stored in such a convenient way. Let\u2019s see what a printout of the return from the auto.arima function looks like, using the first zip code in our data set for the test. Note that we must cast the time series as a FloatVector so it is compatible with the R function. Also, take note of how the time series is accessed from the pandas GroubBy object, by getting a group by its name (zip code), setting the date column as the index, then taking the value column. Also note that Python drops the first zeros in these \u201clower\u201d zip codes because they are numeric values, but we know it is really a 5 digit zip code with a zero on the front. In financial time series analysis, it is general practice to model the returns of a series, rather than the prices, because this gives us a common scale on which to compare all of our zip codes. For mathematical convenience, the log returns are generally favored over percentage increases, since they can be cumulatively summed over time. These are generated by taking the differenced log values of a series. This produces a NaN value on the first date of the series which we will drop. Also, the frequency \u2018MS\u2019 is assigned to the resulting returns series as this tells pandas that the data are monthly.", "Here we can see the return stream of the first zip code. We can see that the series has trends, and the variance is not constant, meaning it is not stationary. The trends can be removed by another order of differencing, but the heteroscedasticity will remain, invariably leading to heteroscedastic errors in our model. Although the residuals will be heteroscedastic, as long as the errors are centered around zero across time, with a roughly normal distribution, and not serially correlated, the model will be mostly effective. The model will estimate parameters based on the log likelihood of the data given the estimated parameters, so what will be affected by the inconsistent volatility will be the estimate of sigma2 (variance) for the model, which will find a happy medium between the lower variance of the early years and the higher variance after around 2009. This is mostly important in our forecasting considerations because the model will generate confidence intervals based on an estimate of variance which is somewhat biased to an outdated market regime with lower variance, leading to narrower confidence bands than might actually be appropriate.", "However, despite this issue with forecasted confidence intervals, when comparing the models of many zip codes which are experiencing different degrees of variance swings during and after the crash, there is an advantage to using the entire time series to estimate model parameters, even with heteroscedasticity present, because periods of more intense volatility during the crash will lead to higher estimates of variance in the models fit to zip codes which did not handle the crash well. This means that once all of the models are generated, those with more optimistic outlooks for future variance will be those which were fed data that did not have as large of spikes in volatility; in other words, those that showed resilience during the crash, meaning that the comparisons of the models will still work in our favor to find what we are looking for. One could adjust for the biased sigma2 estimate for forecasting after the fact, changing just this parameter in the smoothing step to a value which is more reflective of the variance in recent years before performing forecasts, but since this is a hypothetical project with plenty to cover already, I will leave this out.", "The traditional method for finding the orders for ARMA models is the Box-Jenkins method which uses the ACF and PACF to visually find spikes in autocorrelation. We will be using a more modern approach with the auto.arima function, but it would be interesting to take a look at the ACF and PACF for our first zip code for a visual reference along with the suggested orders. Remember the returns will need an order of differencing, so we apply this before looking at the autocorrelation to be modeled, and drop the leading NaN value.", "We can see there certainly is some serial correlation in the series, but it is difficult to tell exactly what orders would best model it. It looks like the yearly seasonality is evident at 12 lags, and there is some strong autocorrelation up to lag 5. Let\u2019s see what the object returned from the auto.arima call looks like. Note that when making the time series object using the ts function in R, the frequency is given as 12 to indicate monthly data.", "We can see this is a bit of a mess, but everything we need is there. The parameter estimates and their names, as stated before, are conveniently attached to the object as vectors which can be easily accessed. The orders, however, are not conveniently stored, and will be extracted by converting this output into a string and indexing it to get the desired information. Below are two functions, one which can extract the parameters and another which can extract the orders from this object.", "Now we have helper functions to extract the information we want from our auto.arima output. There is one snag left to manage, which is that when the auto.arima output has a constant, we need to provide an exogenous variable to the statsmodels SARIMAX object in the form of a vector of ones which the coefficient will be assigned to. Also, creating our auto.arima response object could be much simpler. Rather than generating these each time, we can create yet another helper function to give us everything we need for the creation of our statsmodels SARIMAX model in one step, as below:", "We now have everything we need to quickly generate an appropriate model to a time series. Let\u2019s try this on our first zip code\u2019s log returns, to see if it worked:", "We can see this model has some issues but that it is fairly effective. The residuals are heteroscedastic, as expected, and there is some mild autocorrelation in the residuals at lag 5, which is not ideal. However, the residuals are centered around zero, and although the leptokurtocity (excess kurtosis, meaning a slender peak, being caused by the volatility clustering) is causing the JB test null hypothesis of normally distributed residuals to be rejected, they are not too far off, having reasonable skew and kurtosis. Testing this process on a few other zip codes shows that the models generated tend not to have autocorrelated residuals in general, and close-to but not normally distributed residuals, with heteroscedasticity following the same general pattern of increasing volatility over time, and the resulting leptokurtocity. There is much discussion centered on the fact that having perfect SARIMAX model fit for financial time series is not common, and these models are fairly solid considering this domain, especially considering the rapidity with which they are being generated.", "We now want to apply this modeling process to all zip codes which have complete data, and which have most recent average sales prices below $500,000. Each model will be used to make a forecast over 5 years, then we will take the average of the predicted mean and the lower confidence limit over the projection period for each model for comparisons. The reason that these two metrics make a good combination for zip code comparisons is that a high mean of expected returns tells us that the model has an optimistic outlook of returns in the future, and when this is paired with higher value for the mean of the lower confidence limit over the same time period, it means that not only does the zip code have a positive outlook for gains, it also has a relatively tight confidence interval, and thus lower expected variance. Zip codes which experienced less intense volatility clustering during the financial crash will have lower estimates for sigma2 in their models, and thus will have tighter confidence bands in their forecasts. This method should lead us to zip codes which are at the top of the list for 3 of our investment criteria: high expected capital appreciation rate, low expected volatility, and resilience to poor economic conditions during the crash. Once we have our contenders, we can then look at their P2R ratios to find those which also satisfy our need for leasing profitability.", "Although we have a novel and efficient way to generate the models, 14,723 zip codes is still a lot, and generating a model for each one will take a few hours. The following code will run the appropriate loop to compile a dataframe of the metrics which we will use to select our top zip code candidates.", "Excellent. A few short hours later and we have some nice forecast metrics to lead us to superior zip codes for investment. The most informative metric we have taken is the mean of the lower confidence limit throughout the 5 year forecast. There is a lot of information built into this one number, because it can\u2019t be high without having a high mean predicted mean of returns over time as well as a low expected variance. This means that we can sort our results by this metric in descending order to find our top contenders so far, and then include P2R to finalize a list of our top 5 zip codes for investment.", "The results are in, but we need a more descriptive dataframe, and we want the P2R ratios as well. Earlier, we saw that the P2R dataframe has the locations recorded in a \u2018Region Name\u2019 column, which is the name of the metro together with the state abbreviation. We can create a similar column from our original dataframe combining the metro and state columns, so we can merge the two dataframes. Let\u2019s limit our results to the top 200, then iterate through the index and create an info dataframe, then merge everything together.", "Now we have all of the information we need in one place. We can see that there are missing values in the P2R column, so we will not be able to comment on the leasing profitability for these zip codes, and we will focus on those for which we do have P2R info. Let\u2019s filter our results to everything with a P2R below the national average and go from there.", "Now our search is coming to a close. What is left to do from here is inspect the models for each of these zip codes individually to find the best opportunities for investors. To save a bit of space here, the top two zip codes on this list had historically low volatility, then in the one or two most recent months saw massive unexpected growth rates, the combination of which makes the model forecasts quite optimistic in the short term. However, it would be better to advise the client to invest in zip codes with a little more than a couple of recent months of great returns, so we move on down the list. San Antonio has a great P2R ratio, close to Dogen\u2019s recommendation of 9.6. Since our target P2R is around 10, let\u2019s consider what this means: it takes 10 years of rent payments to pay off the cost of ownership of a property. This means that if an investor holds the property for 10 years and leases it out during that time, they will have paid off their initial investment, and can still sell the properties at a potentially higher value! That gives them a great return on their investment. Let\u2019s look at the model for San Antonio and make forecasts over a period of 10 years.", "We can see this model fits fairly well except for the typical heteroscedasticity to expect from any zip code in this dataset. The residuals are close to a normal distribution, and the residuals are not autocorrelated. Let\u2019s look at a in-sample and out-of-sample 10 year forecast.", "Here\u2019s a 10 year forecast in-sample, taking us back to to the middle of the crash, when things were most uncertain.", "We can see that even though our sigma2 may be a bit underestimated, the confidence bands of our model contained everything following April 2008 apart from the recent spike in growth. Let\u2019s see what the model predicts about the next 10 years.", "This looks pretty good. The predicted mean is around 2% a month and the confidence bands are mostly above the zero line. The area in the shaded region which falls below the zero line is much smaller than the area above it, giving an investor confidence that they are unlikely to lose money in the next 10 years.", "Picking the top 5 zip codes at this point was done by hand by examining individual models for each. The three code blocks above can be adjusted to generate a model and its predictions for any zip code just by changing the zip code in the initial get_group call. In picking the top 5, picking two zip codes in the same city was avoided since diversification is generally a good thing in capital investment, so that in the event that something adversely affects the market in one location, the portfolio is not over-exposed. However, two zip codes from the Dallas/Fort Worth metro were picked, although in different districts, one suburban and one urban. The best 5 zip codes were:", "All of these zip codes have good forecasts of mean returns, low estimated volatility, and P2R ratios below the national average. Because these zip codes also have the highest average lower confidence interval in their forecasts, they represent the areas least likely to lose value into the future, according to the SARIMAX models. The properties in these zip codes can have the cost of ownership paid off with around 10 years of rent, so that, assuming the home does nothing other than hold its value, the investor can have 100% profit over that time interval, and any capital gains on the properties would be an addition to that. Considering these zip codes have the lowest probability of losing value, they are quite attractive choices for a real estate investor. Let\u2019s look at their price curves together.", "This gives us a good picture of the resilience of these zip codes to the market crash and the recent growth that we were looking for. Let\u2019s look at the models from the rest of the top 5 zip codes.", "In this project, an imaginary real estate investment firm was to be advised on the top five zip codes to invest in. In order to answer this question, domain knowledge was combined with comparisons of SARIMAX models generated for the return series of each individual zip code. To generate such a large quantity of models in a reasonable time frame, an efficient method to generate well-fitting models for a large number of time series in Python has been demonstrated. By using the strength of the auto.arima function in R\u2019s forecast package within a Python environment, it has been possible to use a Python workflow and statsmodels functionality with appropriate models generated quickly. The zip codes were evaluated by their outlooks on capital appreciation, looking for strong growth with low expected variance. The P2R ratios of the zip codes with the best outlooks were then used to filter the results, and zip codes with both strong outlooks and above average leasing profitability were hand selected for recommendation. Since the target P2R was around 10, 10 year forecasts were generated to see what the model expectations were over a holding period for which the owner could expect to pay off the costs of property ownership. Since the zip codes selected (78210, 37020, 75228, 46770, and 75028) were among the least likely to depreciate over that time period of any of the 14,723 in the data set, they make the best prospects for a real estate investor.", "Data Scientist with a focus in autonomous navigation", "Road to Full Stack Data Science"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F44c904480290&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://natecibik.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Nate Cibik"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82bf2304955e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=post_page-82bf2304955e----44c904480290---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F44c904480290&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=-----44c904480290---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F44c904480290&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=-----44c904480290---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@morningbrew?utm_source=medium&utm_medium=referral", "anchor_text": "Morning Brew"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/questions-96667b06af5", "anchor_text": "rules and guidelines"}, {"url": "https://towardsdatascience.com/readers-terms-b5d780a700a4", "anchor_text": "Reader Terms"}, {"url": "https://github.com/FoamoftheSea/dsc-mod-4-project-online-ds-sp-000", "anchor_text": "here"}, {"url": "https://www.zillow.com/research/where-rent-covers-mortgage-15624/", "anchor_text": "Zillow research article"}, {"url": "https://en.wikipedia.org/wiki/Subprime_mortgage_crisis", "anchor_text": "subprime mortgage crisis"}, {"url": "https://www.zillow.com/research/where-rent-covers-mortgage-15624/", "anchor_text": "This Zillow research article"}, {"url": "https://www.financialsamurai.com/real-estate-investing-rule-rent-luxury-buy-utility/", "anchor_text": "Financial Samurai article"}, {"url": "https://medium.com/tag/data-science?source=post_page-----44c904480290---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/real-estate-investments?source=post_page-----44c904480290---------------real_estate_investments-----------------", "anchor_text": "Real Estate Investments"}, {"url": "https://medium.com/tag/python?source=post_page-----44c904480290---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----44c904480290---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/flatiron-school?source=post_page-----44c904480290---------------flatiron_school-----------------", "anchor_text": "Flatiron School"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F44c904480290&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=-----44c904480290---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F44c904480290&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=-----44c904480290---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F44c904480290&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82bf2304955e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=post_page-82bf2304955e----44c904480290---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc3a5a021d58e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&newsletterV3=82bf2304955e&newsletterV3Id=c3a5a021d58e&user=Nate+Cibik&userId=82bf2304955e&source=-----44c904480290---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Written by Nate Cibik"}, {"url": "https://natecibik.medium.com/followers?source=post_page-----44c904480290--------------------------------", "anchor_text": "61 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F82bf2304955e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&user=Nate+Cibik&userId=82bf2304955e&source=post_page-82bf2304955e----44c904480290---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc3a5a021d58e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freal-estate-consulting-data-project-44c904480290&newsletterV3=82bf2304955e&newsletterV3Id=c3a5a021d58e&user=Nate+Cibik&userId=82bf2304955e&source=-----44c904480290---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/predicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Nate Cibik"}, {"url": "https://medium.com/analytics-vidhya?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Analytics Vidhya"}, {"url": "https://medium.com/analytics-vidhya/predicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Predicting Returns with Fundamental Data and Machine Learning in PythonCan ML algorithms predict winners and losers using fundamentals?"}, {"url": "https://medium.com/analytics-vidhya/predicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "50 min read\u00b7Nov 25, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fanalytics-vidhya%2Fa0e5757206e8&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fpredicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8&user=Nate+Cibik&userId=82bf2304955e&source=-----a0e5757206e8----0-----------------clap_footer----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://medium.com/analytics-vidhya/predicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8?source=author_recirc-----44c904480290----0---------------------d919029b_308c_4d99_9147_4341273610c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa0e5757206e8&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fpredicting-returns-with-fundamental-data-and-machine-learning-in-python-a0e5757206e8&source=-----44c904480290----0-----------------bookmark_preview----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----44c904480290----1---------------------d919029b_308c_4d99_9147_4341273610c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----44c904480290----1-----------------bookmark_preview----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----44c904480290----2---------------------d919029b_308c_4d99_9147_4341273610c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----44c904480290----2-----------------bookmark_preview----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-northwind-traders-dataset-5513bd7b63b0?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Nate Cibik"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-northwind-traders-dataset-5513bd7b63b0?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "The Northwind Traders DatasetStudying the effects of discount on customer behavior"}, {"url": "https://towardsdatascience.com/the-northwind-traders-dataset-5513bd7b63b0?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": "\u00b79 min read\u00b7Apr 19, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5513bd7b63b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-northwind-traders-dataset-5513bd7b63b0&user=Nate+Cibik&userId=82bf2304955e&source=-----5513bd7b63b0----3-----------------clap_footer----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-northwind-traders-dataset-5513bd7b63b0?source=author_recirc-----44c904480290----3---------------------d919029b_308c_4d99_9147_4341273610c7-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5513bd7b63b0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-northwind-traders-dataset-5513bd7b63b0&source=-----44c904480290----3-----------------bookmark_preview----d919029b_308c_4d99_9147_4341273610c7-------", "anchor_text": ""}, {"url": "https://natecibik.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "See all from Nate Cibik"}, {"url": "https://towardsdatascience.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/mlearning-ai/building-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://bassel-karami.medium.com/?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://bassel-karami.medium.com/?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Bassel Karami"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/building-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Building A Scorecard Web App For Residential Areas In DubaiMercury helps you easily convert your Jupyter notebook into a web app"}, {"url": "https://medium.com/mlearning-ai/building-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b710 min read\u00b7Nov 9, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2F8fdd5867cc68&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fbuilding-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68&user=Bassel+Karami&userId=68fc7cb80932&source=-----8fdd5867cc68----0-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/building-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8fdd5867cc68&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fbuilding-a-scorecard-for-residential-areas-in-dubai-using-mercury-8fdd5867cc68&source=-----44c904480290----0-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/illumination/4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://ankit-goyal.medium.com/?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://ankit-goyal.medium.com/?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Ankit Goyal"}, {"url": "https://medium.com/illumination?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "ILLUMINATION"}, {"url": "https://medium.com/illumination/4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "4 Nontraditional Product Pricing Methods To Set Winning Product PriceThe right product\u2019s price can make or break your business."}, {"url": "https://medium.com/illumination/4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b75 min read\u00b7Dec 4, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fillumination%2F76ed93086c76&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fillumination%2F4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76&user=Ankit+Goyal&userId=15c273bb00fe&source=-----76ed93086c76----1-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/illumination/4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F76ed93086c76&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fillumination%2F4-nontraditional-product-pricing-methods-to-set-winning-product-price-76ed93086c76&source=-----44c904480290----1-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/how-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://zainbaq.medium.com/?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Zain Baquar"}, {"url": "https://blog.devgenius.io/?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Dev Genius"}, {"url": "https://blog.devgenius.io/how-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "How To Build A Dynamic Pricing System Using Machine Learning in PythonDon\u2019t know how to price your products? Look no further than this article!"}, {"url": "https://blog.devgenius.io/how-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b78 min read\u00b7Feb 5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdev-genius%2Fad6d4e4292f8&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Fhow-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8&user=Zain+Baquar&userId=d16fc4a70186&source=-----ad6d4e4292f8----0-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/how-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8?source=read_next_recirc-----44c904480290----0---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fad6d4e4292f8&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Fhow-to-build-a-dynamic-pricing-system-using-machine-learning-in-python-ad6d4e4292f8&source=-----44c904480290----0-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/road-to-full-stack-data-science/customer-behaviour-analysis-with-python-38eb90e98771?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@tdalis?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@tdalis?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Tasos Pardalis"}, {"url": "https://medium.com/road-to-full-stack-data-science?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Road to Full Stack Data Science"}, {"url": "https://medium.com/road-to-full-stack-data-science/customer-behaviour-analysis-with-python-38eb90e98771?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Customer Behaviour Analysis with PythonUse data science and Python to better understand your customer behaviour."}, {"url": "https://medium.com/road-to-full-stack-data-science/customer-behaviour-analysis-with-python-38eb90e98771?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b714 min read\u00b7Feb 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Froad-to-full-stack-data-science%2F38eb90e98771&operation=register&redirect=https%3A%2F%2Fmedium.com%2Froad-to-full-stack-data-science%2Fcustomer-behaviour-analysis-with-python-38eb90e98771&user=Tasos+Pardalis&userId=ec5020cbf4f7&source=-----38eb90e98771----1-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/road-to-full-stack-data-science/customer-behaviour-analysis-with-python-38eb90e98771?source=read_next_recirc-----44c904480290----1---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38eb90e98771&operation=register&redirect=https%3A%2F%2Fmedium.com%2Froad-to-full-stack-data-science%2Fcustomer-behaviour-analysis-with-python-38eb90e98771&source=-----44c904480290----1-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----2-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----44c904480290----2---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----44c904480290----2-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----3-----------------clap_footer----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----44c904480290----3---------------------6fd0387f_cc15_4667_954a_fa3cf7a3450a-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----44c904480290----3-----------------bookmark_preview----6fd0387f_cc15_4667_954a_fa3cf7a3450a-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----44c904480290--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----44c904480290--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----44c904480290--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----44c904480290--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----44c904480290--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----44c904480290--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----44c904480290--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}