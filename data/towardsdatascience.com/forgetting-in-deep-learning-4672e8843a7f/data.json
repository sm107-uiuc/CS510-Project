{"url": "https://towardsdatascience.com/forgetting-in-deep-learning-4672e8843a7f", "time": 1683017823.624941, "path": "towardsdatascience.com/forgetting-in-deep-learning-4672e8843a7f/", "webpage": {"metadata": {"title": "Forgetting in Deep Learning. Team member: Qiang Fei, Yingsi Jian\u2026 | by Mingyue Wei | Towards Data Science", "h1": "Forgetting in Deep Learning", "description": "Disclaimer: The views expressed in this blog are those of the authors and are not endorsed by Harvard or Google. Neural network models suffer from the phenomenon of catastrophic forgetting: a model\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/qiang-fei-6b1314116/", "anchor_text": "Qiang Fei", "paragraph_index": 0}, {"url": "https://www.linkedin.com/in/yingsi-jian-576b65130/", "anchor_text": "Yingsi Jian", "paragraph_index": 0}, {"url": "https://www.linkedin.com/in/mingyuewei/", "anchor_text": "Mingyue Wei", "paragraph_index": 0}, {"url": "https://www.linkedin.com/in/shuyuan-xiao-20ba0711b/", "anchor_text": "Shuyuan Xiao", "paragraph_index": 0}, {"url": "https://drive.google.com/file/d/1HLLFdydjIf8asFNkWXrJ-YQHWv0B98RM/view?usp=sharing", "anchor_text": "project poster", "paragraph_index": 1}, {"url": "https://youtu.be/i6BG2p5RW3A", "anchor_text": "video", "paragraph_index": 1}], "all_paragraphs": ["Authors: Qiang Fei, Yingsi Jian, Mingyue Wei, Shuyuan Xiao", "You may also checkout the contents through our project poster and video.", "Disclaimer: The views expressed in this blog are those of the authors and are not endorsed by Harvard or Google.", "Neural network models suffer from the phenomenon of catastrophic forgetting: a model can drastically lose its generalization ability on a task after being trained on a new task. This usually means a new task will likely override the weights that have been learned in the past (see Figure 1), and thus degrade the model performance for the past tasks. Without fixing this problem, a single neural network will not be able to adapt itself to a continuous learning scenario, because it forgets the existing information/knowledge when it learns new things.", "For realistic applications of deep learning, where continual learning can be crucial, catastrophic forgetting would need to be avoided. However, there is only limited study about catastrophic forgetting and its underlying causes. In this project, we will explore how commonly used deep learning methods mitigate or exacerbate the degree of forgetting (e.g. batch-norm, dropout, data augmentation, weight decay, etc.). Further, we would like to select one or several methods and try to learn about the cause of effects.", "For forgetting measurement, the main approach is to revisit a task after training on later tasks and compare the accuracy before and after\u00b2. With different task settings, Kemker et al. proposed a method specifically for incremental class learning\u00b3 (for each new section, data of a single class will be learned), and Arora et al. suggest using scaled accuracy when comparing different models\u2074.", "There have been studies of ways to reduce the forgetting effect, and some of the proposed or accepted methods include: adding dropout layers\u2075, max pooling, decreasing number of layers, and decreasing learning rates.", "The dataset we use is CIFAR-10. This dataset consists of 60,000 color images in total, evenly divided into 10 classes. For each class, 5,000 images are in the train set and the remaining are in the test set. The images are of size 32x32. The 10 classes of the dataset are:", "We went with the approach of comparing before and after accuracy to measure forgetting effects. Our experiment workflow is shown in Figure 2.", "The whole dataset is first evenly split into task 1 and task 2, each consisting of 5 classes of images. We train the model consecutively on task 1 and task 2, and after that, we re-evaluate the model on task 1 data by only refitting the output layer.", "The two accuracy scores were then compared.", "We used 2 sets of splits throughout the experiments.", "The first set was used during the initial modeling and exploration stage, which consists of 5 different splits, (split 0 to split 4), all are randomly divided.", "We formalized the second set of splits after some experiments, which consists of one semantic split based on image similarity from human perspective and two random splits. This set was used for extended experiments of random shift and constant learning rate experiments. Following are the task 1 classes for each split:", "Figure 3 shows the structure of our model. It is a customized CNN with decent performance across various task splits and trials, achieving consistent Accuracy 1 around 90%.", "Other than the input and output layer, the model consists of 4 intermediate convolutional blocks, each with 2 convolutional layers, 1 batch normalization layer, 1 max pooling layer, and 1 dropout layer with 0.2 dropout rate.", "The main objective of our experiments was to confirm whether the proposed methods of mitigating forgetting effects could work. We had two major directions: the first consists of experiments with various data augmentation methods, and the second dealt with training settings, including learning rate, weight decay, and training epochs.", "After initial exploration of these approaches, we specifically extended our experiments on random shifting in data augmentation, and learning rate in training settings.", "We experimented with some basic data augmentation methods:", "These data augmentation methods were applied on both task 1 and task 2 training process. The test set did not involve any data augmentation. Their influences on forgetting comparing to the baseline are shown in Figure 4.", "There is some variation between different data splits from the results. For most of the data augmentation methods, we cannot conclude if they have any effect on forgetting, as in some splits they increased forgetting while in some they did not, and the change was also generally not large.", "However, among all the methods, random shift were clearly increasing forgetting, and the influence seems to increase when we shift more. We confirmed that Accuracy 1 of the models with random shifts were comparable to that of baseline without data augmentation, and as results were consistent across all 5 task splits, we believe that random shift does increase forgetting. This is interesting and quite surprising for us to learn more because random shift is a popular method applied to CIFAR-10 data to improve model performance.", "Apart from basic data augmentation methods, we also experimented with mixup. Mixup is a popular method that can improve classification accuracy (as shown in Figure 5). Instead of feeding the network with raw images, mixup refers to take 2 images and do a linear combination of them using \u03bb:", "\u03bb is a number between 0 and 1 and is drawn from Beta(\ud835\udefc, \ud835\udefc) each time, with \ud835\udefc being a pre-defined hyper-parameter. Smaller \ud835\udefc creates less mixup effect, and mixup with large \ud835\udefc could lead to under-fitting. We experimented with \ud835\udefc values of [0.1, 0.2, 0.3, 0.4], all within the suggested range from Zhang et al.\u2076", "Figure 6 shows results from mixup experiments. For most of the data splits and \ud835\udefc values, mixup did not mitigate forgetting. Impact of mixup on forgetting varied across different data splits as well, e.g. when \ud835\udefc= 0.1, forgetting was decreased with two data splits but increased with the other.", "After the initial experiments, we reached the following conclusions:", "Based on these, we performed extended experiments with random shift using the second set of task splits.", "In addition to the previous experiments applying random shift to both task 1 and task 2, we also did experiments where random shift was applied only to task 1, the results of which were presented in dashed lines in Figure 7. As the images are of size 32x32, we controlled the number of pixels up to which the image might shift in each experiment, with random shift of 4 pixels being the common practice in the field. All experiments were repeated 9 times and the average is presented.", "In the third plot, we can see that when applying random shift to both task 1 and task 2, there is a clear trend across all data splits, that forgetting decreases when the images were randomly shifted for 1 pixel and then increases when shifted pixels increase.", "Learning rate controls the speed of neural network updating its weights during training. We did two sets of exploration experiments study the effect of learning rate on forgetting.", "We experimented with 5 initial learning rates [0.001, 0.005, 0.01, 0.05, 0.1] based on common practice. We applied piecewise learning rate decay which applies cascading decrease after every certain amount of iterations. The same learning rate and rate decay were applied to both Task 1 and Task 2 training. The experiment was run on one task split only.", "Figure 8 presents the results. Learning rates 0.05, 0.01, and 0.005 had similar effects on Accuracy 1, but given the similar Accuracy 1, they had different effects on forgetting. Learning rate 0.005 resulted in the least amount of forgetting.", "Figure 9 shows the results of the experiments. However, either fixing initial learning rate on task 1 or task 2 did not give apparent trend. One observation is that the diagonal seems to have the least forgetting, which corresponds to cases when task 1 and task 2 have the same initial learning rates.", "With the experiments in exploration, it is hard to draw more conclusions because there are too many hyper-parameters to select for each experiment setting, and it was hard to associate the forgetting effect with any single one of them. We then decided to focused on constant learning rate experiments without rate decay.", "Figure 10 shows the forgetting effects in the three splits. Heat map is easier to discern trend when we need to fix value on one of the axes. From the plots we got the following conclusions:", "In order to investigate why increasing the learning rate on task 1 could decrease forgetting effects, we also experimented with task 2 frozen accuracy, which is the test accuracy on task 2 without training on task 2. The hypothesis we wanted to test is that larger task 1 learning rate leads to better features generated, which then lead to mitigated forgetting. However, our experiments did not show a trend or relationship between task 1 learning rate and task 2 frozen accuracy.", "We set up experiments by fixing task 2 training epochs to learn the effect of number of epochs for task 1 on forgetting. Since both tasks training converge at around 40 epochs, we set task 2 training epoch = 40 and experimented with task 1 training epoch = [40, 60, 80, 100].", "Figure 11 shows that Accuracy 1 generally increases when the number of epochs increases, which aligns with common notice of longer training leading to better performance. But in the meanwhile, the forgetting effect generally increases when the task 1 number of epochs increases.", "We also ran experiments to investigate the influence of weight decay on forgetting. We did 2 sets of experiments:", "Accuracy 1 all seem valid with these settings. However, the resultant forgetting did not show consistent trends between different data splits, and thus we could not reach a conclusion on the effect of weight decay on forgetting.", "From our four sets of experiments, we find some interesting results related to data augmentation and learning rates.", "Our next step would be to interpret these results. More specifically, for the data augmentation part, we want to know why random shifts and mixup have such relationships with forgetting. For learning rate, we would also like to explore why increasing task 1 learning rate mitigates forgetting. One hypothesis is that larger task 1 learning rate helps capture and generate better features, but we would need other control experiments to test it.", "[4] Arora, G., Rahimi, A., & Baldwin, T. (2019). Does an LSTM forget more than a CNN? An empirical study of catastrophic forgetting in NLP. In Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association (pp. 77\u201386).", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4672e8843a7f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mingyue-wei.medium.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": ""}, {"url": "https://mingyue-wei.medium.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Mingyue Wei"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e04ad3ec31d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&user=Mingyue+Wei&userId=3e04ad3ec31d&source=post_page-3e04ad3ec31d----4672e8843a7f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://google.com", "anchor_text": "Google"}, {"url": "https://www.linkedin.com/in/qiang-fei-6b1314116/", "anchor_text": "Qiang Fei"}, {"url": "https://www.linkedin.com/in/yingsi-jian-576b65130/", "anchor_text": "Yingsi Jian"}, {"url": "https://www.linkedin.com/in/mingyuewei/", "anchor_text": "Mingyue Wei"}, {"url": "https://www.linkedin.com/in/shuyuan-xiao-20ba0711b/", "anchor_text": "Shuyuan Xiao"}, {"url": "https://drive.google.com/file/d/1HLLFdydjIf8asFNkWXrJ-YQHWv0B98RM/view?usp=sharing", "anchor_text": "project poster"}, {"url": "https://youtu.be/i6BG2p5RW3A", "anchor_text": "video"}, {"url": "https://arxiv.org/pdf/1903.06070.pdf", "anchor_text": "Attention-Based Selective Plasticity (Kolouri et al., 2019)"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----4672e8843a7f---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/catastrophic-forgetting?source=post_page-----4672e8843a7f---------------catastrophic_forgetting-----------------", "anchor_text": "Catastrophic Forgetting"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&user=Mingyue+Wei&userId=3e04ad3ec31d&source=-----4672e8843a7f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&user=Mingyue+Wei&userId=3e04ad3ec31d&source=-----4672e8843a7f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4672e8843a7f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4672e8843a7f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4672e8843a7f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4672e8843a7f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4672e8843a7f--------------------------------", "anchor_text": ""}, {"url": "https://mingyue-wei.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mingyue-wei.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mingyue Wei"}, {"url": "https://mingyue-wei.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3e04ad3ec31d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&user=Mingyue+Wei&userId=3e04ad3ec31d&source=post_page-3e04ad3ec31d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F3e04ad3ec31d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforgetting-in-deep-learning-4672e8843a7f&user=Mingyue+Wei&userId=3e04ad3ec31d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}