{"url": "https://towardsdatascience.com/how-to-collect-data-from-any-website-cb8fad9e9ec5", "time": 1683010031.056274, "path": "towardsdatascience.com/how-to-collect-data-from-any-website-cb8fad9e9ec5/", "webpage": {"metadata": {"title": "How I used Python to Collect Data from any Website | Towards Data Science", "h1": "How I used Python to Collect Data from any Website", "description": "See a basic tutorial on Python's beautifulsoup library to web scrape data from any website by knowing a little code and html to navigate various web pages."}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Web_scraping", "anchor_text": "Web Scraping", "paragraph_index": 2}, {"url": "https://marco-santos.medium.com/membership", "anchor_text": "Sign up for a Medium Membership here to gain unlimited access and support content like mine! With your support I earn a small portion of the membership fee. Thanks!", "paragraph_index": 3}, {"url": "http://quotes.toscrape.com/", "anchor_text": "this website", "paragraph_index": 5}, {"url": "https://selenium-python.readthedocs.io/", "anchor_text": "Selenium", "paragraph_index": 37}, {"url": "http://linkedin.com/in/marco-s-santos", "anchor_text": "linkedin.com/in/marco-s-santos", "paragraph_index": 39}], "all_paragraphs": ["There are moments while working when you realize that you may need a large amount of data in a short amount of time. These could be instances when your boss or customer wants a specific set of information from a specific website. Maybe they want you to collect over a thousand pieces of information or data from said website. So what do you do?", "One option could be to check out this website and manually type in every single piece of information requested. Or better yet, you could make Python do all the heavy lifting for you!", "Utilizing one of Python\u2019s most useful libraries, BeautifulSoup, we can collect most data displayed on any website by writing some relatively simple code. This action is called Web Scraping. In the next few parts, we will be learning and explaining the basics of BeautifulSoup and how it can be used to collect data from almost any website.", "Sign up for a Medium Membership here to gain unlimited access and support content like mine! With your support I earn a small portion of the membership fee. Thanks!", "In order to learn how to use BeautifulSoup, we must first have a reason to use it. Let\u2019s say that hypothetically, you have a customer that is looking for quotes from famous people. They want to have a new quote every week for the next year. They\u2019ve tasked us with the job to present them with at least fifty-two quotes and their respective authors.", "We can probably just go to any website to find these quotes but we will be using this website for the list of quotes. Now our customer wants these quotes formatted into a simple spreadsheet. So now we have the choice of either typing out fifty-two quotes and their respective authors in a spreadsheet or we can use Python and BeautifulSoup to do all of that for us. So for the sake of time and simplicity, we would rather go with Python and BeautifulSoup.", "Let\u2019s begin with opening up any IDE that you prefer but we will be using Jupyter Notebook. (The Github code for all of this will be available at the end of the article).", "We will start by importing the libraries needed for BeautifulSoup:", "Next, we\u2019ll have to actually access the website for BeautifulSoup to parse by running the following code:", "This returns a response status code letting us know if the request has been successfully completed. Here we are looking for Response [200] meaning that we have successfully reached the website.", "Here we will be parsing the website using BeautifulSoup.", "Running this code will return what looks like a printed text document in HTML code that looks like this:", "We can navigate through the above, parsed document using BeautifulSoup.", "Now we will need to find the exact thing we are looking for in the parsed HTML document. Let\u2019s start by finding the quotes.", "An easy way to find what we are looking for is by:", "This will bring up a new window that look like this:", "The highlighted section is where we will find the quote we are looking for. Just click the arrow on the left of the highlighted section to see the quote in the code.", "Based on the HTML code we see highlighted we can use that information to navigate the soup. We will be using the .find_all() attribute in our own code to potentially find the quotes we are looking for. This attribute will be able to return to us the desired line (or lines) of code based on whatever arguments we give it. Since we can see that the HTML code for the quote contains class=\u201ctext\u201d, we can use that in our BeautifulSoup code:", "Running this code will return the following results:", "From this we can see that we are able to successfully locate and retrieve the code and text containing the quotes needed.", "In order to only retrieve the text and exclude the unnecessary code, we will have to use the .text attribute in each result. To do so, we will have iterate through the list using a \u201cfor\u201d loop:", "This will give us the list of quotes without their respective HTML code:", "Now we know how we can access the quotes within the website and retrieve them for our purposes. Repeat the steps mentioned before to retrieve the author names for each quote as well:", "Now that we know how to retrieve data from a specific webpage, we can move on to the data from the next set of pages. As we can see from the website, all the quotes are not stored on a single page. We must be able to navigate to different pages in the website in order to get more quotes.", "Notice that the url for each new page contains a changing value:", "Knowing this we can create a simple list of URLs to iterate through in order to access different pages in the website:", "This returns a list of websites we can use:", "From this list, we can create another \u201cfor\u201d loop to collect the necessary number of quotes and their respective authors.", "One important thing to note: some websites do not approve of web scraping. These sites will implement ways to detect if you are using a web scraping tool such as Beautiful Soup. For example, a website can detect if a large number requests were made in a short amount of time, which is what we are doing here. In order to potentially avoid detection, we can randomize our request rate to closely mimic human interaction. Here is how we do that:", "Then at the end of every loop, input the following piece of code:", "Here we are randomly choosing a value from the list we created and waiting that selected amount of time before the loop begins again. This will slow down our code but will help us avoid detection.", "Now that we have all the pieces, we can construct the final \u201cfor\u201d loop that will gather at least 52 quotes and their respective authors:", "Once we run the code above we will end up with a list of quotes and a list of authors. However, our customer wants the quotes in a spreadsheet. To accommodate that request, we will have to use the Python library: Pandas.", "Inputting the lists into a Pandas DataFrame is very simple:", "Since the quotes and the authors were scraped in order, they will be easy to input into the DataFrame.", "Once we have finished and ran the code above, the final DF will look like so:", "Excellent! The DF looks great and is in the exact format requested from the customer. We can then save the DF as an excel spreadsheet file which we can then send to our customer.", "We hope you learned a little bit about web scraping from this step-by-step tutorial. Even though the example we used may be quite simple, the techniques used will still be applicable to many different websites all over the internet. More complex looking websites that require extensive user interaction will require another Python library called Selenium. However, most websites will only need BeautifulSoup to scrape data. The walkthrough we have done here should be enough to get you started. Happy scraping!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "NYC Data Scientist specializing in AI/ML with a passion for code | Let\u2019s connect! \u2014 linkedin.com/in/marco-s-santos."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcb8fad9e9ec5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://marco-santos.medium.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": ""}, {"url": "https://marco-santos.medium.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Marco Santos"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06d69ac26aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&user=Marco+Santos&userId=e06d69ac26aa&source=post_page-e06d69ac26aa----cb8fad9e9ec5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@firsara?utm_source=medium&utm_medium=referral", "anchor_text": "Fabian Irsara"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Web_scraping", "anchor_text": "Web Scraping"}, {"url": "https://marco-santos.medium.com/membership", "anchor_text": "Sign up for a Medium Membership here to gain unlimited access and support content like mine! With your support I earn a small portion of the membership fee. Thanks!"}, {"url": "http://quotes.toscrape.com/", "anchor_text": "this website"}, {"url": "http://quotes.toscrape.com/", "anchor_text": "http://quotes.toscrape.com/"}, {"url": "http://quotes.toscrape.com/page/{i}/", "anchor_text": "http://quotes.toscrape.com/page/{i}/"}, {"url": "https://selenium-python.readthedocs.io/", "anchor_text": "Selenium"}, {"url": "https://github.com/marcosan93/Article-Walkthroughs/blob/master/WebScraper.ipynb", "anchor_text": "marcosan93/Article-WalkthroughsPermalink Dismiss GitHub is home to over 50 million developers working together to host and review code, manage\u2026github.com"}, {"url": "https://medium.com/tag/python?source=post_page-----cb8fad9e9ec5---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/programming?source=post_page-----cb8fad9e9ec5---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/data-science?source=post_page-----cb8fad9e9ec5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/technology?source=post_page-----cb8fad9e9ec5---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----cb8fad9e9ec5---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&user=Marco+Santos&userId=e06d69ac26aa&source=-----cb8fad9e9ec5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&user=Marco+Santos&userId=e06d69ac26aa&source=-----cb8fad9e9ec5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcb8fad9e9ec5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cb8fad9e9ec5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cb8fad9e9ec5--------------------------------", "anchor_text": ""}, {"url": "https://marco-santos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://marco-santos.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Santos"}, {"url": "https://marco-santos.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.3K Followers"}, {"url": "http://linkedin.com/in/marco-s-santos", "anchor_text": "linkedin.com/in/marco-s-santos"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06d69ac26aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&user=Marco+Santos&userId=e06d69ac26aa&source=post_page-e06d69ac26aa--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc323f276f5e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-collect-data-from-any-website-cb8fad9e9ec5&newsletterV3=e06d69ac26aa&newsletterV3Id=c323f276f5e0&user=Marco+Santos&userId=e06d69ac26aa&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}