{"url": "https://towardsdatascience.com/gan-pix2pix-generative-model-c9bf5d691bac", "time": 1683002479.825681, "path": "towardsdatascience.com/gan-pix2pix-generative-model-c9bf5d691bac/", "webpage": {"metadata": {"title": "GAN Pix2Pix Generative Model. Image-to-image translation with Pix2Pix\u2026 | by Anirudh S | Towards Data Science", "h1": "GAN Pix2Pix Generative Model", "description": "We hear a lot about language translation with deep learning where the neural network learns a mapping from one language to another. In fact, Google translate uses it to translate to more than 100\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/search/cs?searchtype=author&query=Isola%2C+P", "anchor_text": "Phillip Isola", "paragraph_index": 1}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+J", "anchor_text": "Jun-Yan Zhu", "paragraph_index": 1}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+T", "anchor_text": "Tinghui Zhou", "paragraph_index": 1}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Efros%2C+A+A", "anchor_text": "Alexei A. Efros", "paragraph_index": 1}, {"url": "https://arxiv.org/abs/1611.07004", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://hackerstreak.com/colorizing-pokemon-with-deep-learning/", "anchor_text": "1. How to train an AI cGAN model in 5 simple steps", "paragraph_index": 19}], "all_paragraphs": ["We hear a lot about language translation with deep learning where the neural network learns a mapping from one language to another. In fact, Google translate uses it to translate to more than 100 languages. But, can we do a similar task with images? Certainly, yes! If it\u2019s possible to capture the intricacies of languages, it\u2019ll surely be possible to translate an image to another. Indeed, this shows the power of deep learning.", "Pix2Pix GAN paper was published back in 2016 by Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros. Find the paper here. It was later revised in 2018. When it was published, internet users tried something creative. They used the pix2pix GAN system to a variety of different scenarios like a frame-to-frame translation of a video of one person to another, mimicking the former\u2019s moves. Cool, isn\u2019t it? Using pix2pix, we can map any image to any other image like the edges of an object to the image of the object. Further, we\u2019ll explore more about its architecture and its working in detail. Now, let\u2019s dive right in!", "Heard about GANs (Generative Adversarial Network) that generate realistic synthetic images? Similarly, Pix2pix belongs to one such type called conditional GAN or cGAN. They have some conditional settings and they learn the image-to-to mapping under this condition. Whereas, basic GAN\u2019s generate images from a random distribution vector with no condition applied. Confused? Try to get this.", "Say, we have a GAN trained with the images of the MS-COCO data set. In GANs, the output image that is generated with the generator network is random. That is, it might generate images of any object that was there in the data set. But, with a cGAN, we can generate images that we want. If we want it to generate a person, it\u2019ll generate an image of a person. This is achieved by conditioning the GAN.", "Let\u2019s take another example of an image-to-image translation task, \u2018black&white to color image \u2018 conversion. In pix2pix cGAN, the B&W image is given as input to the generator model. And, the output of the generated model and the given input (B&W image) pair of images is the generated pair (fake pair). The B&W input image and the target output (i.e the real color version of the input B&W image) forms the real pair.", "The discriminator classifies a given pair of images as the real pair or the generated pair. The one that is used in Pix2Pix is different from normally how we\u2019d expect a classifier\u2019s output to be. It produces an output classification that classifies multiple patches in the input image pairs (patchGAN). I\u2019ll explain more about it in detail. In the below depictions, concatenation is represented as \u2295.", "Pix2Pix GAN has a generator and a discriminator just like a normal GAN would have. For our black and white image colorization task, the input B&W is processed by the generator model and it produces the color version of the input as output. In Pix2Pix, the generator is a convolutional network with U-net architecture.", "It takes in the input image (B&W, single-channel), passes it through a series of convolution and up-sampling layers. Finally, it produces an output image that is of the same size as the input but has three channels (colorized). But before training, the generator produces just random output.", "After the generator, the synthetic image is concatenated with the input B&W image. Therefore, the number of color channels will be four (height x width x 4). This is concatenated tensor is fed as input to the discriminator network. In Pix2Pix, the authors employ a different type of discriminator network (patchGAN type). The patchGAN network takes the concatenated input images and produces an output of size NxN.", "The discriminator loss function measures how good or bad the discriminator\u2019s predictions are. The lesser the discriminator loss, the more accurate it becomes at identifying synthetic image pairs.", "A normal binary classifier that\u2019s used in GANs produces just a single output neuron to predict real or fake. But, the patchGAN\u2019s NxN output predicts a number of overlapping patches in the input image. For example, in Pix2Pix, the output size is 30x30x1 which predicts for each 70\u00d770 patch of the input. We\u2019ll see more about patchGANs in another post. The 30\u00d730 output is fed to a log loss function that compares it with a 30\u00d730 zero matrix (since it is generated and not real).", "This is called generated loss. The real loss is calculated for the pair of B&W and its corresponding color image from the data set. This is a real pair. Hence, \u2018real loss\u2019 is the sigmoid cross-entropy of the NxN output and a matrix of ones of the NxN size.", "The total discriminator loss is the sum of the above two losses. The gradients of the loss function are computed with respect to the discriminator network and are backpropagated to minimize the loss. While the discriminator loss is back-propagated, weights of the generator network are frozen. Phew! Now we\u2019re almost done.", "The generator loss measures how real the synthetic images look. By minimizing this, the generator could produce more realistic images.", "This loss is almost the same as generated loss except that it is the sigmoid cross-entropy of the NxN discriminator output and a matrix of ones. When this loss is back-propagated, the discriminator network\u2019s parameters are frozen. And only the generator\u2019s weights are adjusted.", "To improve the aesthetics of the generated image, the authors of the pix2pix paper added an L1 loss term. It calculates the L1 distance between the target image and the generated image. It is then multiplied with a parameter \u2018Lambda\u2019 and gets added to the generator loss.", "To train the model to convert B&W images to color, we have to feed the network with the input and target images. Hence, any data set with color images like the ImageNet can be used. The data set can be constructed by converting the color images to B&W to form the input. And the color image itself forms the target. Thus, the network can be trained by iterating through the data set, feeding the images to the pix2pix model, one by one or by batch.", "That\u2019s pix2pix for you! Hope you got a clear idea about what pix2pix GAN is and how it works.", "See how to train a cGAN model yourself on your custom data set.", "1. How to train an AI cGAN model in 5 simple steps", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Always Believing there's more to learn!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc9bf5d691bac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@baakchsu.sprx77?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baakchsu.sprx77?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Anirudh S"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a92cae35860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&user=Anirudh+S&userId=1a92cae35860&source=post_page-1a92cae35860----c9bf5d691bac---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Isola%2C+P", "anchor_text": "Phillip Isola"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+J", "anchor_text": "Jun-Yan Zhu"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+T", "anchor_text": "Tinghui Zhou"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Efros%2C+A+A", "anchor_text": "Alexei A. Efros"}, {"url": "https://arxiv.org/abs/1611.07004", "anchor_text": "here"}, {"url": "https://hackerstreak.com/colorizing-pokemon-with-deep-learning/", "anchor_text": "1. How to train an AI cGAN model in 5 simple steps"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----c9bf5d691bac---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c9bf5d691bac---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/generative-art?source=post_page-----c9bf5d691bac---------------generative_art-----------------", "anchor_text": "Generative Art"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----c9bf5d691bac---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----c9bf5d691bac---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&user=Anirudh+S&userId=1a92cae35860&source=-----c9bf5d691bac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&user=Anirudh+S&userId=1a92cae35860&source=-----c9bf5d691bac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc9bf5d691bac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c9bf5d691bac---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c9bf5d691bac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baakchsu.sprx77?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baakchsu.sprx77?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Anirudh S"}, {"url": "https://medium.com/@baakchsu.sprx77/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "127 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a92cae35860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&user=Anirudh+S&userId=1a92cae35860&source=post_page-1a92cae35860--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff34e096e7feb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgan-pix2pix-generative-model-c9bf5d691bac&newsletterV3=1a92cae35860&newsletterV3Id=f34e096e7feb&user=Anirudh+S&userId=1a92cae35860&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}