{"url": "https://towardsdatascience.com/machine-learning-field-guide-726989c928a1", "time": 1683009127.3263202, "path": "towardsdatascience.com/machine-learning-field-guide-726989c928a1/", "webpage": {"metadata": {"title": "Machine Learning Field Guide. The no BS ML guide from start to\u2026 | by Kamron Bhavnagri | Towards Data Science", "h1": "Machine Learning Field Guide", "description": "Machine learning/data science field guide, from importing, data cleaning and visualisations to modelling and production!"}, "outgoing_paragraph_urls": [{"url": "https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z", "anchor_text": "these fundamentals", "paragraph_index": 1}, {"url": "https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19", "anchor_text": "we\u2019ve found, collected or scraped our data", "paragraph_index": 2}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv", "paragraph_index": 10}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat", "paragraph_index": 14}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat", "paragraph_index": 14}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html", "anchor_text": "DataFrame", "paragraph_index": 14}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat", "paragraph_index": 15}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv", "paragraph_index": 16}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html", "anchor_text": "read_excel", "paragraph_index": 16}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html", "anchor_text": "read_sql", "paragraph_index": 16}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html", "anchor_text": "option", "paragraph_index": 16}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html", "anchor_text": "DataFrame.astype", "paragraph_index": 17}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html", "anchor_text": "DataFrame.drop", "paragraph_index": 28}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html", "anchor_text": "unique", "paragraph_index": 35}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html", "anchor_text": "value_counts", "paragraph_index": 35}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#plot-formatting", "anchor_text": "more info here", "paragraph_index": 42}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html", "anchor_text": "train_test_split", "paragraph_index": 51}, {"url": "https://scikit-learn.org/stable/modules/cross_validation.html", "anchor_text": "cross-validation", "paragraph_index": 52}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "Grid search", "paragraph_index": 54}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "Random search", "paragraph_index": 57}, {"url": "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model", "anchor_text": "Linear regression", "paragraph_index": 59}, {"url": "https://scikit-learn.org/stable/modules/svm.html", "anchor_text": "support vector machines (SVM\u2019s)", "paragraph_index": 60}, {"url": "https://scikit-learn.org/stable/modules/neural_networks_supervised.html", "anchor_text": "neural networks", "paragraph_index": 62}, {"url": "https://www.kamwithk.com/PyTorch.org/", "anchor_text": "PyTorch", "paragraph_index": 64}, {"url": "https://www.tensorflow.org/", "anchor_text": "TensorFlow", "paragraph_index": 64}, {"url": "https://scikit-learn.org/stable/modules/tree.html", "anchor_text": "Decision trees", "paragraph_index": 65}, {"url": "https://scikit-learn.org/stable/modules/clustering.html#k-means", "anchor_text": "k-means", "paragraph_index": 66}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html", "anchor_text": "regression", "paragraph_index": 71}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "classification", "paragraph_index": 71}, {"url": "https://xgboost.readthedocs.io/", "anchor_text": "XGBoost", "paragraph_index": 75}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html", "anchor_text": "classification", "paragraph_index": 76}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html", "anchor_text": "regression", "paragraph_index": 76}, {"url": "https://www.streamlit.io/", "anchor_text": "Streamlit", "paragraph_index": 78}, {"url": "https://www.streamlit.io/", "anchor_text": "Streamlit", "paragraph_index": 79}, {"url": "https://www.heroku.com/", "anchor_text": "Heroku", "paragraph_index": 80}, {"url": "https://twitter.com/kamwithk_", "anchor_text": "follow me on Twitter", "paragraph_index": 82}, {"url": "https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z", "anchor_text": "The Complete Coding Practitioners Handbook", "paragraph_index": 83}, {"url": "https://www.kamwithk.com/zero-to-hero-nlp-project-edition-ck6zsqtbo05srdfs135o8blcf", "anchor_text": "choosing a project", "paragraph_index": 83}, {"url": "https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19", "anchor_text": "collecting your own dataset through webscraping", "paragraph_index": 83}], "all_paragraphs": ["We all have to deal with data, and we try to learn about and implement machine learning into our projects. But everyone seems to forget one thing\u2026 it\u2019s far from perfect, and there is so much to go through! Don\u2019t worry, we\u2019ll discuss every little step, from start to finish \ud83d\udc40.", "All you\u2019ll need are these fundamentals", "We all start with either a dataset or a goal in mind. Once we\u2019ve found, collected or scraped our data, we pull it up, and witness the overwhelming sight of merciless cells of numbers, more numbers, categories, and maybe some words \ud83d\ude28! A naive thought crosses our mind, to use our machine learning prowess to deal with this tangled mess\u2026 but a quick search reveals the host of tasks we\u2019ll need to consider before training a model \ud83d\ude31!", "Once we overcome the shock of our unruly data we look for ways to battle our formidable nemesis \ud83e\udd14. We start with trying to get our data into Python. It is relatively simple on paper, but the process can be slightly\u2026 involved. Nonetheless, a little effort was all that was needed (lucky us).", "Without wasting any time we begin data cleaning to get rid of the bogus and expose the beautiful. Our methods start simple \u2014 observe and remove. It works a few times, but then we realise\u2026 it really doesn\u2019t do us justice! To deal with the mess though, we find a powerful tool to add to our arsenal: charts! With our graphs, we can get a feel for our data, the patterns within it and where things are missing. We can interpolating (fill in) or removing missing data.", "Finally, we approach our highly anticipated \ud83d\ude0e challenge, data modelling! With a little research, we find out which tactics and models are commonly used. It is a little difficult to decipher which one we should use, but we still manage to get through it and figure it all out!", "We can\u2019t finish a project without doing something impressive though. So, a final product, website, app or even a report will take us far! We know first impressions are important so we fix up the GitHub repository and make sure everything\u2019s well documented and explained. Now we are finally able to show off our hard work to the rest of the world \ud83d\ude0e!", "Data comes in all kinds of shapes and sizes and so the process we use to get everything into code often varies.", "Let\u2019s be real, importing data seems easy, but sometimes\u2026 it\u2019s a little pesky.", "The hard part about data cleaning isn\u2019t the coding or theory, but instead our preparation! When we first start a new project and download our dataset, it can be tempting to open up a code editor and start typing\u2026 but this won\u2019t do us any good. If we want to get a head start we need to prepare ourselves for the best and worst parts of our data. To do this we\u2019ll need to start basic, by manually inspecting our spreadsheet/s. Once we understand the basic format of the data (file type along with any particularities) we can move onto getting it all into Python.", "When we\u2019re lucky and just have one spreadsheet we can use the Pandas read_csv function (letting it know where our data lies):", "In reality, we run into way more complex situations, so look out for:", "Although we\u2019re discussing a range of scenarios, we normally only deal with a few at a time.", "Our first few problems (importing specific parts of our data/renaming columns) are easy enough to deal with using a few parameters, like the number of rows to skip, the specific columns to import and our column names:", "Whenever our data is spread across multiple files, we can combine them using Pandas concat function. The concat function combines a list of DataFrame's together:", "We parse to concat a list of spreadsheets (which we import just like before). The list can, of course, be attained in any way (so a fancy list comprehension or a casual list of every file both work just as well), but just remember that we need dataframes, not filenames/paths!", "If we don\u2019t have a CSV file Pandas still works! We can just swap out read_csv for read_excel, read_sql or another option.", "After all the data is inside a Pandas dataframe, we need to double-check that our data is formatted correctly. In practice, this means checking each series datatype, and making sure they are not generic objects. We do this to ensure that we can utilize Pandas inbuilt functionality for numeric, categorical and date/time values. To look at this just run DataFrame.dtypes. If the output seems reasonable (i.e. numbers are numeric, categories are categorical, ect), then we should be fine to move on. However, this normally is not the case, and as we need to change our datatypes! This can be done with Pandas DataFrame.astype. If this doesn't work, there should be another more Pandas function for that specific conversion:", "If we need to analyse separate groups of data (i.e. maybe our data is divided by country), we can use Pandas groupby. We can use groupby to select particular data, and to run functions on each group separately:", "Other more niche tricks like multi/hierarchical indices can also be helpful in specific scenarios, however, are more tricky to understand and use.", "Data is useful, data is necessary, however, it needs to be clean and to the point! If our data is everywhere, it simply won\u2019t be of any use to our machine learning model.", "Everyone is driven insane by missing data, but there\u2019s always a light at the end of the tunnel.", "The easiest and quickest way to go through data cleaning is to ask ourselves:", "What features within our data will impact our end-goal?", "By end-goal, we mean whatever variable we are working towards predicting, categorising or analysing. The point of this is to narrow our scope and not get bogged down in useless information.", "Once we know what our primary objective features are, we can try to find patterns, relations, missing data and more. An easy and intuitive way to do this is graphing! Quickly use Pandas to sketch out each variable in the dataset, and try to see where everything fits into place.", "Once we have identified potential problems, or trends in the data we can try and fix them. In general, we have the following options:", "To go from identifying missing data to choosing what to do with it we need to consider how it affects our end-goal. With missing data we remove anything which doesn\u2019t seem to have a major influence on the end result (i.e. we couldn\u2019t find a meaningful pattern), or where there just seems too much missing to derive value. Sometimes we also decide to remove very small amounts of missing data (since it\u2019s easier than filling it in).", "If we\u2019ve decided to get rid of information, Pandas DataFrame.drop can be used. It removes columns or rows from a dataframe. It is quite easy to use, but remember that Pandas does not modify/remove data from the source dataframe by default, so inplace=True must be specified. It may be useful to note that the axis parameter specifies whether rows or columns are being removed.", "When not removing a full column, or particularly targeting missing data, it can often be useful to rely on a few nifty Pandas functions. For removing null values, DataFrame.dropna can be utilized. Do keep in mind though that by default, dropna completely removes all missing values. However, setting either the parameter how to all or setting a threshold (thresh, representing how many null values are required for it to delete) can compensate for this.", "If we\u2019ve got small amounts of irregular missing values, we can fill them in several ways. The simplest is DataFrame.fillna which sets the missing values to some preset value. The more complex, but flexible option is interpolation using DataFrame.interpolate. Interpolation essentially allows anyone to simply set the method they would like to replace each null value with. These include the previous/next value, linear and time (the last two deduce based on the data). Whenever working with time, time is a natural choice, and otherwise make a reasonable choice based on how much data is being interpolated and how complex it is.", "As seen above, interpolate needs to be passed in a dataframe purely containing the columns with missing data (otherwise an error will be thrown).", "Resampling is useful can whenever we see regularly missing data or have multiple sources of data using different timescales (like ensuring measurements in minutes and hours can be combined). It can be slightly difficult to intuitively understand resampling, but it is essential when you average measurements over a certain timeframe. For example, we can get monthly values by specifying that we want to get the mean of each month\u2019s values:", "The \"M\" stands for month and can be replaced with \"Y\" for year and other options.", "Although the data cleaning process can be quite challenging, if we remember our initial intent, it becomes a far more logical and straight forward task! If we still don\u2019t have the needed data, we may need to go back to phase one and collect some more. Note that missing data indicates a problem with data collection, so it\u2019s useful to carefully consider, and note down where occurs.", "For completion, the Pandas unique and value_counts functions are useful to decide which features to straight-up remove and which to graph/research.", "Visualisation sounds simple and it is, but it\u2019s hard to\u2026 not overcomplicate. It\u2019s far too easy for us to consider plots as a chore to create. Yet, these bad boys do one thing very, very well \u2014 intuitively demonstrate the inner workings of our data! Just remember:", "We graph data to find and explain how everything works.", "Hence, when stuck for ideas, or not quite sure what to do, we basics can always fall back on identifying useful patterns and meaningful relationships. It may seem iffy \ud83e\udd76, but it is really useful.", "Our goal isn\u2019t to draw fancy hexagon plots, but instead to picture what is going on, so absolutely anyone can simply interpret a complex system!", "A few techniques are undeniably useful:", "To get started graphing, simply use Pandas .plot() on any series or dataframe! When we need more, we can delve into MatPlotLib, Seaborn or an interactive plotting library.", "90% of the time, this basic functionality will suffice (more info here), and where it doesn\u2019t a search should reveal how to draw particularly exotic graphs \ud83d\ude0f.", "Now finally for the fun stuff \u2014 deriving results. It seems so simple to train a scikit learn model, but no one goes into the details! So, let\u2019s be honest here, not every dataset, nor model are equal.", "Our approach to modelling will vary widely based on our data. There are three especially important factors:", "Our type of problem comes down to whether we are trying to predict a class/label (called classification), a value (called regression), or to group data (called clustering). If we are trying to train a model on a dataset where we already have examples of what we\u2019re trying to predict we call our model supervised, if not, unsupervised. The amount of available data, and how complex it is foreshadows how simple a model will suffice. Data with more features (i.e. columns) tends to be more complex.", "The point of interpreting complexity is to understand which models are too good or too bad for our data", "Models goodness of fit informs us on this! If a model struggles to interpret our data (too simple) we can say it underfits, and if it is completely overkill (too complex) we say it overfits. We can think of it as a spectrum from learning nothing to memorising everything. We need to strike balance, to ensure our model is able to generalise our conclusions to new information. This is typically known as the bias-variance tradeoff. Note that complexity also affects model interpretability.", "Complex models take a substantially greater time to train, especially with large datasets. So, upgrade that computer, run the model overnight, and chill for a while \ud83d\ude01!", "Before training a model it is important to note that we will need some dataset to test it on (so we know how well it performs). Hence, we often divide our dataset into separate training and testing sets. This allows us to test how well our model can generalise to new unseen data. This normally works because we know our data is decently representative of the real world.", "The actual amount of test data doesn\u2019t matter too much, but 80% train and 20% test is often used.", "In Python with Scikit learn the train_test_split function does this:", "Cross-validation is where a dataset is split into several folds (i.e. subsets or portions of the original dataset). This tends to be more robust and resistant to overfitting than using a single test/validation set! Several Sklearn functions help with cross-validation, however, it\u2019s normally done straight through a grid or random search (discussed below).", "There are some factors our model cannot account for, and so we set certain hyperparameters. These vary model to model, but we can either find optimal values through manual trial and error or a simple algorithm like grid or random search. With grid search, we try all possible values (brute force \ud83d\ude07) and with random search random values from within some distribution/selection. Both approaches typically use cross-validation.", "Grid search in Sklearn works through a parameters dictionary. Each entries key represents the hyperparameter to tune, and the value (a list or tuple) is the selection of values to chose from:", "After we\u2019ve created the grid, we can use it to train the models, and extract the scores:", "The important thing here is to remember that we need to train on the training and not testing data. Even though cross-validation is used to test the models, we\u2019re ultimately trying to get the best fit on the training data and will proceed to test each model on the testing set afterwards:", "Random search in Sklearn works similarly but is slightly more complex as we need to know what type of distribution each hyperparameter takes in. Although it, in theory, can yield the same or better results faster, that changes from situation to situation. For simplicity it is likely best to stick to a grid search.", "With Sklearn, it\u2019s as simple as finding our desired model name and then just creating a variable for it. Check the links to the documentation for further details! For example", "Linear regression is trying to fit a straight line to our data. It is the most basic and fundamental model. There are several variants of linear regression, like lasso and ridge regression (which are regularisation methods to prevent overfitting). Polynomial regression can be used to fit curves of higher degrees (like parabolas and other curves). Logistic regression is another variant which can be used for classification.", "Just like with linear/logistic regression, support vector machines (SVM\u2019s) try to fit a line or curve to data points. However, with SVM\u2019s the aim is to maximise the distance between a boundary and each point (instead of getting the line/curve to go through each point).", "The main advantage of support vector machines is their ability to use different kernels. A kernel is a function which calculates similarity. These kernels allow for both linear and non-linear data, whilst staying decently efficient. The kernels map the input into a higher dimensional space so a boundary becomes present. This process is typically not feasible for large numbers of features. A neural network or another model will then likely be a better choice!", "All the buzz is always about deep learning and neural networks. They are complex, slow and resource-intensive models which can be used for complex data. Yet, they are extremely useful when encountering large unstructured datasets.", "When using a neural net, make sure to watch out for overfitting. An easy way is through tracking changes in error with time (known as learning curves).", "Deep learning is an extremely rich field, so there is far too much to discuss here. In fact, Scikit learn is a machine learning library, with little deep learning abilities (compared to PyTorch or TensorFlow).", "Decision trees are simple and quick ways to model relationships. They are basically a tree of decisions which help to decide on what class or label a datapoint belongs too. Decision trees can be used for regression problems too. Although simple, to avoid overfitting, several hyperparameters must be chosen. These all, in general, relate to how deep the tree is and how many decisions are to be made.", "We can group unlabeled data into several clusters using k-means. Normally the number of clusters present is a chosen hyperparameter.", "K-means works by trying to optimize (reduce) some criterion (i.e. function) called inertia. It can be thought of like trying to minimize the distance from a set of centroids to each data point.", "Random forests are combinations of multiple decision trees trained on random subsets of the data (bootstrapping). This process is called bagging and allows random forests to obtain a good fit (low bias and low variance) with complex data.", "The rationale behind this can be likened to democracy.", "One voter may vote for a bad candidate, but we\u2019d hope that the majority of voters make informed, positive decisions", "For regression problems, we average each decision tree\u2019s outputs, and for classification, we choose the most popular one. This might not always work, but we assume it in general will (especially with large datasets with multiple columns).", "Another advantage with random forests is that insignificant features shouldn\u2019t negatively impact performance because of the democratic-esc bootstrapping process!", "Hyperparameter choices are the same as those for decision trees but with the number of decision trees as well. For the aforementioned reasons, more trees equal less overfitting!", "Note that random forests use random subsets with the replacement of rows and columns!", "Ensemble models like AdaBoost or XGBoost work by stacking one model on top of another. The assumption here is that each successive weak learner will correct for the flaws of the previous one (hence called boosting). Hence, the combination of models should provide the advantages of each model without its potential pitfalls.", "The iterative approach means previous models performances effects current models, and better models are given a higher priority. Boosted models perform slightly better than bagging models (a.k.a random forests), but are also slightly more likely to overfit. Sklearn provides AdaBoost for classification and regression.", "This is the last but potentially most important part of the process \ud83e\uddd0. We\u2019ve put in all this work, and so we need to go the distance and create something impressive!", "There are a variety of options. Streamlit is an exciting option for data-oriented websites, and tools like Kotlin, Swift and Dart can be used for Android/IOS development. JavaScript with frameworks like VueJS can also be used for extra flexibility.", "After trying most of these I honestly would recommend sticking to Streamlit, since it is so much easier than the others!", "Here it is important to start with a vision (simpler the better) and try to find out which parts are most important. Then try and specifically work on those. Continue till completion! For websites, a hosting service like Heroku will be needed, so the rest of the world can see the amazing end-product of all our hard work \ud83e\udd2f\ud83d\ude31.", "Even if none of the above options above suite the scenario, a report or article covering what we\u2019ve done, what we\u2019ve learnt and any suggestions/lessons learnt along with a well documented GitHub repository are indispensable! Make sure that readme file is up to date.", "I really hope this article has helped you out! For updates follow me on Twitter.", "If you enjoyed this, you may also like The Complete Coding Practitioners Handbook which goes through each and every practical coding tool you\u2019ll need to know. If you\u2019re lost considering what project to take on, consider checkout out my zero-to-hero guide on choosing a project and collecting your own dataset through webscraping.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Super passionate up and coming data scientist documenting my journey! Learning and creating ML content (data science projects and blog posts)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F726989c928a1&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----726989c928a1--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kamwithk?source=post_page-----726989c928a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kamwithk?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Kamron Bhavnagri"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F176786e2f4ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&user=Kamron+Bhavnagri&userId=176786e2f4ea&source=post_page-176786e2f4ea----726989c928a1---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z", "anchor_text": "these fundamentals"}, {"url": "https://unsplash.com/photos/pCqzMe04s8g", "anchor_text": "National Cancer Institute"}, {"url": "https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19", "anchor_text": "we\u2019ve found, collected or scraped our data"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html", "anchor_text": "DataFrame"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html", "anchor_text": "concat"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html", "anchor_text": "read_csv"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html", "anchor_text": "read_excel"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html", "anchor_text": "read_sql"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html", "anchor_text": "option"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html", "anchor_text": "DataFrame.astype"}, {"url": "https://unsplash.com/photos/D4LDw5eXhgg", "anchor_text": "Adam Nowakowski"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html", "anchor_text": "DataFrame.drop"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html", "anchor_text": "unique"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html", "anchor_text": "value_counts"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#plot-formatting", "anchor_text": "more info here"}, {"url": "https://unsplash.com/photos/JKUTrJ4vK00", "anchor_text": "Luke Chesser"}, {"url": "https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html", "anchor_text": "Documentation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html", "anchor_text": "train_test_split"}, {"url": "https://scikit-learn.org/stable/modules/cross_validation.html", "anchor_text": "cross-validation"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "Grid search"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html", "anchor_text": "Random search"}, {"url": "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model", "anchor_text": "Linear regression"}, {"url": "https://scikit-learn.org/stable/modules/svm.html", "anchor_text": "support vector machines (SVM\u2019s)"}, {"url": "https://scikit-learn.org/stable/modules/neural_networks_supervised.html", "anchor_text": "neural networks"}, {"url": "https://www.kamwithk.com/PyTorch.org/", "anchor_text": "PyTorch"}, {"url": "https://www.tensorflow.org/", "anchor_text": "TensorFlow"}, {"url": "https://scikit-learn.org/stable/modules/tree.html", "anchor_text": "Decision trees"}, {"url": "https://scikit-learn.org/stable/modules/clustering.html#k-means", "anchor_text": "k-means"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html", "anchor_text": "regression"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html", "anchor_text": "classification"}, {"url": "https://unsplash.com/photos/3ap0EoGXXGk", "anchor_text": "Guilherme Caetano"}, {"url": "https://xgboost.readthedocs.io/", "anchor_text": "XGBoost"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html", "anchor_text": "classification"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html", "anchor_text": "regression"}, {"url": "https://www.streamlit.io/", "anchor_text": "Streamlit"}, {"url": "https://www.streamlit.io/", "anchor_text": "Streamlit"}, {"url": "https://www.heroku.com/", "anchor_text": "Heroku"}, {"url": "https://unsplash.com/photos/z3cMjI6kP_I", "anchor_text": "ThisisEngineering RAEng"}, {"url": "https://twitter.com/kamwithk_", "anchor_text": "follow me on Twitter"}, {"url": "https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z", "anchor_text": "The Complete Coding Practitioners Handbook"}, {"url": "https://www.kamwithk.com/zero-to-hero-nlp-project-edition-ck6zsqtbo05srdfs135o8blcf", "anchor_text": "choosing a project"}, {"url": "https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19", "anchor_text": "collecting your own dataset through webscraping"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----726989c928a1---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----726989c928a1---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/projects?source=post_page-----726989c928a1---------------projects-----------------", "anchor_text": "Projects"}, {"url": "https://medium.com/tag/programming?source=post_page-----726989c928a1---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----726989c928a1---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&user=Kamron+Bhavnagri&userId=176786e2f4ea&source=-----726989c928a1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&user=Kamron+Bhavnagri&userId=176786e2f4ea&source=-----726989c928a1---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----726989c928a1--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F726989c928a1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----726989c928a1---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----726989c928a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----726989c928a1--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----726989c928a1--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----726989c928a1--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----726989c928a1--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kamwithk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kamwithk?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kamron Bhavnagri"}, {"url": "https://medium.com/@kamwithk/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "39 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F176786e2f4ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&user=Kamron+Bhavnagri&userId=176786e2f4ea&source=post_page-176786e2f4ea--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F176786e2f4ea%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-field-guide-726989c928a1&user=Kamron+Bhavnagri&userId=176786e2f4ea&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}