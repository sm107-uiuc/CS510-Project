{"url": "https://towardsdatascience.com/tracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79", "time": 1682993654.043425, "path": "towardsdatascience.com/tracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79/", "webpage": {"metadata": {"title": "Tracking NYC Citi Bike real time utilization using Kafka Streams | by Lei He | Towards Data Science", "h1": "Tracking NYC Citi Bike real time utilization using Kafka Streams", "description": "We are big fans of Apache Kafka when it comes to building distributed real time stream processing systems. It\u2019s massively scalable, has simple pub-sub semantics, and offers fault-tolerant persistent\u2026"}, "outgoing_paragraph_urls": [{"url": "https://hackernoon.com/building-a-real-time-nyc-subway-tracker-with-apache-kafka-40d4e09bfe98", "anchor_text": "previous post", "paragraph_index": 0}, {"url": "https://docs.confluent.io/current/streams/introduction.html", "anchor_text": "Kafka Streams", "paragraph_index": 2}, {"url": "https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/", "anchor_text": "blog post by Confluent", "paragraph_index": 2}, {"url": "https://www.citibikenyc.com/system-data", "anchor_text": "historical data set", "paragraph_index": 3}, {"url": "http://gbfs.citibikenyc.com/gbfs/gbfs.json", "anchor_text": "GBFS feed", "paragraph_index": 3}, {"url": "https://developers.google.com/api-client-library/java/google-http-java-client/", "anchor_text": "google http java client", "paragraph_index": 7}, {"url": "https://avro.apache.org/docs/current/", "anchor_text": "avro", "paragraph_index": 9}, {"url": "https://docs.confluent.io/current/schema-registry/docs/index.html", "anchor_text": "Schema Registry", "paragraph_index": 9}, {"url": "https://kafka.apache.org/10/documentation/streams/developer-guide/datatypes.html#avro", "anchor_text": "Avro Serdes class", "paragraph_index": 9}, {"url": "https://github.com/cloudboxlabs/blog-code/blob/master/citibikekafkastreams/src/main/java/com/cloudboxlabs/LowAvailability.java", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://github.com/cloudboxlabs/blog-code/blob/master/citibikekafkastreams/src/main/java/com/cloudboxlabs/TurnoverRatio.java", "anchor_text": "here", "paragraph_index": 19}, {"url": "https://kafka.apache.org/quickstart", "anchor_text": "here", "paragraph_index": 22}, {"url": "https://github.com/cloudboxlabs/blog-code/tree/master/citibikekafkastreams", "anchor_text": "Cloudbox Labs github", "paragraph_index": 26}], "all_paragraphs": ["We are big fans of Apache Kafka when it comes to building distributed real time stream processing systems. It\u2019s massively scalable, has simple pub-sub semantics, and offers fault-tolerant persistent data store. It\u2019s a great platform to process event stream data, e.g. click events, distributed logs, time-series metrics, etc. We wrote about building real time analytics using Apache Kafka in a previous post.", "But in most use cases, data streams are not processed in isolation. Often enough when a Kafka message is received, some stateful data store is queried in order to have enough information to process that message. For example, if we have an order stream that receives customer orders, most likely that order needs to be query a database with customer information and/or product metadata in order to process, so how does stream data work together with stateful data, like a database table?", "This is when Kafka Streams comes in. Kafka Streams is a set of application API (currently in Java & Scala) that seamlessly integrates stateless (stream) and stateful (table) processing. The underlying premise of the design is very interesting. In short it is based on the fact that a table can be reconstructed from a stream of change data capture (CDC) or transaction log records. If we have a stream of change logs, a table is just a local store that reflects that latest state of each change record. Armed with that concept, stream-stream or stream-table joins becomes a unified operation of routing data through various internal Kafka topics. By default RocksDB is used for local stateful store, but other key value databases can be used too. I encourage you to read the blog post by Confluent explaining the motivation of designing Kafka Streams. It is very eye opening for me.", "In this post, we are going to use Kafka Streams to track real time statistics of Citi Bike utilization in New York City. CitiBikeNYC publishes both a historical data set containing bike trips and a real time GBFS feed of each bike station information and availability. While the historical data set is a treasure trove of insights, some utilization metrics are better gained through the real time data feed. We are going to calculate two important utilization real time metrics.", "A visual of the data flow looks like this.", "First things first, since Citi Bike feed is a Restful API, we need to add a Java app that polls the endpoints and turn the JSON response into streams and publish onto Kafka topics.", "The sample of station_information and station_status JSON looks like this", "We use google http java client to transform the http response into POJO (Plain old java object).", "Then we serialize the list of station_information and station_statuses objects to string and publish it to their named Kafka topics respectively.", "A note about serialize/deserialize messages to/from Kafka. For production grade systems, Apache Kafka Streams API uses avro based serialization and stores the avro schema with Schema Registry. I feel that adds a lot of unnecessary cruft for the purpose of this post, so I\u2019m leaving that part out and whenever possible use string based serialization schema. If you are curious about Avro based SerDes(Serialization/Deserialization) check out Avro Serdes class.", "Now that we have data streaming in from the station_information and station_status topics, let\u2019s look at how to find stations that has less than 10% of bike availability. The full code is here.", "First we construct a KakfaStreams object with a bunch of configurations including Kafka bootstrap servers, local state on the file system, and Kafka consumer options.", "Then we can wire up each step of transformation as if we were building a streaming data pipeline.", "2. Build a KTable from the input from Kafka topic station_information.", "You might ask why we use a KStream for station statuses but a KTable for station information. Remember the stream and table duality? Table is the end state of a stream of change events. In this case we want to capture each station status change because it tells us how the number of bikes available changes over time. On the other hand, station information is static data, including capacity, name, geolocation, etc. We only care about the latest values for each piece of data, so a KTable allows us to compact a stream of changes into a final snapshot.", "3. Now comes the \u201cwhat the magic is going on here?\u201d part. Let\u2019s do a LeftJoin on the KStream and KTable. Remember our metric is (num_bikes_available) / (station_capacity). The numerator is from the station_status object but the denominator is from the station_information object, so we need to do a stream-table join here. This is where the power of Kafka Streams lies. Being able to casually join an evolving data stream with a static local store without a mountain of code is simple awesome.", "After joining the streams we filter the calculated availability to be less than 10% and map the data to human readable output string.", "4. This step is not strictly necessary but we finally publish the analytics onto an output Kafka topic so we can examine them.", "5. If we fire up a console Kafka consumer, we can see that output looks like this", "Now let\u2019s take a look how to calculate turnover ratio in a session window. We have similar steps of building KStream/KTable of station_information and station_status. The code is here.", "2. Now that windowed net change of bikes is calculated, let\u2019s join again with the station_information KTable and outputs our analytics onto an output topic.", "3. The output looks like this. Note the key in this case is a Windowed<String> because we applied a rolling window over the the stream.", "In order to run the code, follow the quick start here to spin up Zookeeper, Kafka, create topics and run the Java application.", "In conclusion what do we think about using Kafka Streams in practice? The answer is \u201cit depends\u201d. It depends on what does your data look like and how complicated is the business logic.", "Kafka Streams stands on the shoulders of a giant that\u2019s Apache Kafka, so implicitly it comes with the scalability and elasticity of a massively distributed streaming data platform. The ease with which we can work with stream and stateful data interchangeably speaks to how well designed the library APIs are. If your data is pretty simple in form, e.g. counting click events, ranking page views, it\u2019s a great option for real time data analytics.", "In the flip side, due to the fact the internals of Kafka Streams uses Kafka pub-sub as the storage backbone, you constantly have to think about how to serialize/deserialize your data at each stage of the data pipe. This means if you are using a lot of POJO(Plain old java object) in your application, you have the added task of specifying how to serialize them in order to pass them down the pipeline, Avro schema or not. Although understandable, it adds an extra dimension of complexity that I\u2019m not sure is always worth it in business logic heavy applications. Kafka Streams does not have a python based API at time of writing, so for data scientists that perform heavy analytics, it\u2019s a very steep learning curve.", "As always you can find the full code discussed in this post on Cloudbox Labs github.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software engineer, data infrastructure, blog @CloudboxLabs.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1c0ea9e24e79&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@leihetito?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leihetito?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Lei He"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb31456848a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&user=Lei+He&userId=bb31456848a9&source=post_page-bb31456848a9----1c0ea9e24e79---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@aginsbrook?utm_source=medium&utm_medium=referral", "anchor_text": "Anthony Ginsbrook"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://hackernoon.com/building-a-real-time-nyc-subway-tracker-with-apache-kafka-40d4e09bfe98", "anchor_text": "previous post"}, {"url": "https://docs.confluent.io/current/streams/introduction.html", "anchor_text": "Kafka Streams"}, {"url": "https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/", "anchor_text": "blog post by Confluent"}, {"url": "https://www.citibikenyc.com/system-data", "anchor_text": "historical data set"}, {"url": "http://gbfs.citibikenyc.com/gbfs/gbfs.json", "anchor_text": "GBFS feed"}, {"url": "https://developers.google.com/api-client-library/java/google-http-java-client/", "anchor_text": "google http java client"}, {"url": "https://avro.apache.org/docs/current/", "anchor_text": "avro"}, {"url": "https://docs.confluent.io/current/schema-registry/docs/index.html", "anchor_text": "Schema Registry"}, {"url": "https://kafka.apache.org/10/documentation/streams/developer-guide/datatypes.html#avro", "anchor_text": "Avro Serdes class"}, {"url": "https://github.com/cloudboxlabs/blog-code/blob/master/citibikekafkastreams/src/main/java/com/cloudboxlabs/LowAvailability.java", "anchor_text": "here"}, {"url": "https://github.com/cloudboxlabs/blog-code/blob/master/citibikekafkastreams/src/main/java/com/cloudboxlabs/TurnoverRatio.java", "anchor_text": "here"}, {"url": "https://kafka.apache.org/quickstart", "anchor_text": "here"}, {"url": "https://github.com/cloudboxlabs/blog-code/tree/master/citibikekafkastreams", "anchor_text": "Cloudbox Labs github"}, {"url": "https://medium.com/tag/big-data?source=post_page-----1c0ea9e24e79---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1c0ea9e24e79---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/apache-kafka?source=post_page-----1c0ea9e24e79---------------apache_kafka-----------------", "anchor_text": "Apache Kafka"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----1c0ea9e24e79---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/tag/java?source=post_page-----1c0ea9e24e79---------------java-----------------", "anchor_text": "Java"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&user=Lei+He&userId=bb31456848a9&source=-----1c0ea9e24e79---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&user=Lei+He&userId=bb31456848a9&source=-----1c0ea9e24e79---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1c0ea9e24e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1c0ea9e24e79---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1c0ea9e24e79--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leihetito?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@leihetito?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lei He"}, {"url": "https://medium.com/@leihetito/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "222 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb31456848a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&user=Lei+He&userId=bb31456848a9&source=post_page-bb31456848a9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fbb31456848a9%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftracking-nyc-citi-bike-real-time-utilization-using-kafka-streams-1c0ea9e24e79&user=Lei+He&userId=bb31456848a9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}