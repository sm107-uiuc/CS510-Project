{"url": "https://towardsdatascience.com/web-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde", "time": 1683009520.0907662, "path": "towardsdatascience.com/web-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde/", "webpage": {"metadata": {"title": "Web Scraping Boardgamegeek.com Using Selenium, BeautifulSoup, Requests, lxml, and Scrapy | by Pei Guo | Towards Data Science", "h1": "Web Scraping Boardgamegeek.com Using Selenium, BeautifulSoup, Requests, lxml, and Scrapy", "description": "This is a tutorial of web scraping in 3 ways using 5 different tools: Selenium, BeautifulSoup, Requests, LXML, and Scrapy. We will be scraping data from the same website, boardgamegeek.com. This\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.boardgamegeek.com/", "anchor_text": "boardgamegeek.com", "paragraph_index": 0}, {"url": "http://linkedin.com/in/pei-guo/", "anchor_text": "linkedin.com/in/pei-guo/", "paragraph_index": 42}], "all_paragraphs": ["This is a tutorial of web scraping in 3 ways using 5 different tools: Selenium, BeautifulSoup, Requests, LXML, and Scrapy. We will be scraping data from the same website, boardgamegeek.com.", "This website stores data of nearly 120,000 board games, which including game metadata, forum data, online market data, gamers community data, etc. You can say that Boardgamegeek.com is the IMDB for board games.", "The site provides a rank list. The picture below shows the top 10 games. You can see in the upper right that there are 1180 pages of rank list. Each page has 100 games. As of June 16, 2020, the database stored 118,066 board games. However, not all the games have complete information. Only 19,023 games have rank data. The rank value is calculated based on gamers\u2019 votes. No rank means no one has voted for this game. In this project, we will only scrape the 19,023 games with the rank data available.", "BGG also has an API. Each game has its XML page. Below is a partial screenshot of the XML file of the game \u2018Gloomhaven\u2019.", "Every tool or language library was invented to meet certain use cases. Based on the website design and the data volume /complexity, utilizing different tools will make the job easier or faster.", "In a nutshell, web scraping is the process of requesting the web pages and then parsing the data contained in the HTML.", "Pros: It is the most commonly-used Python library. It is simple and easy to learn. A great choice to connect to websites with APIs.", "Cons: Cannot be used to emulate human interactions such as clicking buttons.", "Pros: It can interact with the site by emulating a human\u2019s actions such as clicking and dragging. It is a great choice for websites written with dynamic Javascript.", "Cons: It requires a Chrome driver to work and must exactly match your chrome version. This makes the code less portable. Its speed is slow as well.", "Pros: It is fast, structured, and feature-rich. It\u2019s uses parallel processing to rapidly scrape data. It has tools capable of scraping and processing data in the same tool.", "Cons: The learning curve is steep.", "Pros: Very forgiving for broken HTML/XML files. Easy to learn and well documented. Great choice for html from website directly instead of API files.", "Cons: A little slower than lxml.", "Pros: Specialized in parsing XML. A powerful extension of Python\u2019s builtin ElementTree with full xpath featues. Easy to use.", "Cons: Not as fast as Scrapy. Only works for XML files.", "Scrapy: Pros and cons the same as above request phase", "To scrape the top ranking 19,023 games, we need to do as follows:", "The BGG API does not provide ranking information so we need to scrape the ranking pages first. Then we extract the gameID from each game\u2019s URL, so that we can call API using a URL containing the gameID to request each game\u2019s page. We need to scrape the ranking webpages\u2019 HTML first.", "With the gameID list, we will be able to request each game\u2019s XML file, download them to the local computer then parse the data into a data frame and save it into a CSV file.", "There is a way to do everything above using Scrapy. We will get it a try.", "We are scraping the website\u2019s HTML. The site contains Javascript, so Selenium is needed. Also, we are not sure if the HTML has any errors because data directly from webpages are not as structured as the data from API. As a result, BeautifulSoup is chosen to parse the data.", "The gameIDs are inside the URL. We need to extract them into a list for the next step.", "We are going to request the XML pages through BGG API. This is a simple task, there is no human-like interaction needed. So Python\u2019s Requests library can do the job very well. After we get the XML file, parsing them using lxml is a good approach because lxml is specialized in XML parsing with full Xpath features and relatively fast speed.", "There are 47 tags that later converted into data frame columns. The actual parsing code is very long. Below is some sample code covering different tag situations in the BGG XML files.", "This a good representation of how to use lxml.", "Since the XML files have no ranking information or game URL, we need to join both tables to get the final data frame.", "We need to remove the columns that have the duplicated data, then save the data frame into a CSV file. Our final data has 50 columns and 19023 rows.", "Scrapy is a powerful scraping framework. All of the work we did in steps 1 and 2 can be done by just using Scrapy. Plus, it has many advantages:", "Open the command line terminal first, type \u201cpip install scrapy\u201d. Then navigate to the folder where to save the project files, type in the terminal:", "scrapy startproject BGG(or your project name)", "After a new project is created in the terminal, a set of files are automatically generated by Scrapy in the project folder. When you load the folder in a code editor, you can see the file structure in the red square area.", "Scrapy uses \u2018spiders\u2019 to scrape. In the spiders folder, you can create a new spider file, which will be a Python script. The other included .py files provide you the code structure for various purposes to help your later coding, like grouping all the customized settings in the \u201csettings.py\u201d or for building a data pipeline. The output file is also organized in this area for your convenience.", "Now we will write the spider Python script. To scrape, all Scrapy needs is one spider class. First, two variables need to be defined: \u201cname\u201d and \u201cstart_urls\u201d. Note that their names are predetermined, you can\u2019t use other names. \u201cname\u201d is used to run the spider later and start_urls shows the first page/pages to crawl.", "In BS4 and lxml, the objects we manipulate are \u201csoup\u201d and \u201ctree\u201d. In Scrapy, it is the \u201cresponse\u201d. What makes Scrapy more different is its syntax. It only uses .css and .xpath as its Selectors. With the new syntax in mind, writing the parse function is really similar to working with BS or lxml. Here are quotes from Scrapy\u2019s documents:", "Another difference is how we store the output. We need to create a dictionary to store the data. Instead of using \u201creturn\u201d, we need to use \u201cyield\u201d. \u201cyield\u201d will send the parsed data result from each iteration to Scrapy then go back to the loop to continue parsing the next row of data. Scrapy will save the results from all the iterations then save the data into one of the four file types you defined in the setting.py file: CSV, JSON, JSON Lines, or XML.", "When we scrape using other libraries, we usually define a function with an input for the number of pages. While using Scrapy, you only need to tell it the URL to start with, then it will use a next page selector to keep clicking the next page until the end or arrive at the page limit you set in the code. This is a self callback function, which is a few lines of codes.", "The last step is to run the spider script. In the terminal, type", "scrapy crawl bggranks(or the string of your \u2018name\u2019 variable)", "With a click, you can witness Scrapy\u2019s super crawling speed. The picture below shows the resulting CSV file. 19,000 game ranking records were scraped in just 90 seconds!", "In this article, we learned the differences between multiple web request tools and XML/HTML parsing tools. In reality, people usually stick to certain tools out of habit. However, knowing multiple tools can make your web scraping much faster and easier to handle complex projects. Thanks for your reading!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science Enthusiast. Looking for opportunities to join a Data Science team. linkedin.com/in/pei-guo/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1902d478ecde&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1902d478ecde--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@guopei?source=post_page-----1902d478ecde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@guopei?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Pei Guo"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4cc7960aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&user=Pei+Guo&userId=4cc7960aec&source=post_page-4cc7960aec----1902d478ecde---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Markus Spiske"}, {"url": "https://towardsdatascience.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@robert_coelho?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Robert Coelho"}, {"url": "https://towardsdatascience.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.boardgamegeek.com/", "anchor_text": "boardgamegeek.com"}, {"url": "https://funthon.wordpress.com/2017/05/21/beautiful-soup-4/", "anchor_text": "https://funthon.wordpress.com/2017/05/21/beautiful-soup-4/"}, {"url": "https://medium.com/tag/scrapy?source=post_page-----1902d478ecde---------------scrapy-----------------", "anchor_text": "Scrapy"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----1902d478ecde---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/tag/board-games?source=post_page-----1902d478ecde---------------board_games-----------------", "anchor_text": "Board Games"}, {"url": "https://medium.com/tag/data-extraction?source=post_page-----1902d478ecde---------------data_extraction-----------------", "anchor_text": "Data Extraction"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1902d478ecde---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&user=Pei+Guo&userId=4cc7960aec&source=-----1902d478ecde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&user=Pei+Guo&userId=4cc7960aec&source=-----1902d478ecde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1902d478ecde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1902d478ecde---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1902d478ecde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1902d478ecde--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1902d478ecde--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1902d478ecde--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1902d478ecde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@guopei?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@guopei?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pei Guo"}, {"url": "https://medium.com/@guopei/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "108 Followers"}, {"url": "http://linkedin.com/in/pei-guo/", "anchor_text": "linkedin.com/in/pei-guo/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4cc7960aec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&user=Pei+Guo&userId=4cc7960aec&source=post_page-4cc7960aec--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F16e2738ab548&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fweb-scraping-boardgamegeek-com-using-selenium-beautifulsoup-requests-lxml-and-scrapy-1902d478ecde&newsletterV3=4cc7960aec&newsletterV3Id=16e2738ab548&user=Pei+Guo&userId=4cc7960aec&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}