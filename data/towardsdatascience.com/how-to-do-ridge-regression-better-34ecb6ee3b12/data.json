{"url": "https://towardsdatascience.com/how-to-do-ridge-regression-better-34ecb6ee3b12", "time": 1683002151.748041, "path": "towardsdatascience.com/how-to-do-ridge-regression-better-34ecb6ee3b12/", "webpage": {"metadata": {"title": "How to Do Ridge Regression Better | by Ryan Burn | Towards Data Science", "h1": "How to Do Ridge Regression Better", "description": "Let X and y represent a sample of training data where X is a matrix with n rows of feature vectors and y is a vector of n corresponding target values. If \ud835\udc31\u2032 is an out-of-sample feature vector with\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)", "anchor_text": "cross-validations", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation", "anchor_text": "Leave-One-Out Cross-Validation", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Definiteness_of_a_matrix", "anchor_text": "positive definite", "paragraph_index": 13}, {"url": "https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula", "anchor_text": "Sherman-Morrison formula", "paragraph_index": 15}, {"url": "https://towardsdatascience.com/what-form-of-cross-validation-should-you-use-76aaecc45c75", "anchor_text": "installment", "paragraph_index": 36}, {"url": "https://buildingblock.ai", "anchor_text": "buildingblock.ai", "paragraph_index": 37}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html", "anchor_text": "sklearn.linear_model.RidgeCV", "paragraph_index": 38}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV", "anchor_text": "sklearn.model_selection.GridSearchCV", "paragraph_index": 38}, {"url": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-gradient-verify.ipynb", "anchor_text": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-gradient-verify.ipynb", "paragraph_index": 39}], "all_paragraphs": ["Let X and y represent a sample of training data where X is a matrix with n rows of feature vectors and y is a vector of n corresponding target values. If \ud835\udc31\u2032 is an out-of-sample feature vector with unknown target value y\u2032, then we might fit a linear model b\u0302 with the goal of minimizing the expected out-of-sample error", "One approach to fitting the model, least squares, chooses b\u0302 to minimize the sum of squared errors of the training data", "While this can be a good choice given enough training data, with less training data, more noise, or more features with weaker predictors, it can overfit the data so that b\u0302 reflects noise more so than it does underlying statistical relationships.", "Ridge regression modifies least squares to minimize", "With a suitably matrix \u0393, ridge regression can shrink or otherwise restrict the coefficients of b\u0302 to reduce overfitting and improve the performance of out-of-sample prediction. The challenge is properly choosing \u0393.", "Commonly, \u0393 is restricted to the form", "and \u03b1 is chosen by trialing different values on cross-validations of the training data and picking the one with the best score\u00b9. I\u2019ll refer to this, or other similar such methods of choosing \u0393, as tweaking. Tweaking has the disadvantage that it leads to excessive computation and doesn\u2019t scale to any but the simplest parameterizations of \u0393. For example, if we wanted each variable to have a separate regularizer", "and we had more than a few variables, setting \u0393 by tweaking would be out of the question.", "In this blog post, I\u2019ll show how maximizing the performance \u0393 for certain cross-validations can be set up as a proper optimization problem where we compute first, second derivatives, and efficiently iterate to the best performing parameters with the help of an optimizer. This will allow us to scale to parameterizations with many variables and frequently will lead to better results than what can achieved by a tweaking approach.", "denote the feature matrix and target vector with the ith entry removed and let", "denote the regressors fit to such data. We define the Leave-One-Out Cross-Validation (LOOCV) as", "and seek to minimize this value with respect to \u0393 using an efficient optimizer. Optimizers work by making local approximations of a function from its derivatives. They use the approximations to take successive steps that improve the objective until a local optimum is reached. But before we can compute derivatives of the LOOCV to supply to an optimizer, we\u2019ll need to derive a more tractable form for the objective.", "we can, thus, rewrite the ridge regression equation as", "Because z and y don\u2019t depend on b, and A is positive definite, it follows that the equation is minimized when", "Solving ridge regression like this for each entry will still be expensive, but fortunately, we can further manipulate the equation to achieve something much more efficient. Note that", "From the Sherman-Morrison formula, we have", "we can rewrite the ith leave-one-out ridge regression solution as", "Substituting this into the ith term of the LOOCV, we get", "We can use our formulation from the previous section to also derive equations for the derivatives. Let \u03b1 denote the vector of parameters of \u0393 and define L(\u03b1) to be the LOOCV for the given parameters with L_i denoting the ith term of the LOOCV summation. I\u2019ll assume that \u0393 is parameterized by the diagonal matrix", "though the equations can be easily adapted to other parameterizations and the single variable parameterization", "can be computed, simply, as a sum over the multivariable partials.", "Then the derivative of the ith LOOCV term is", "For the partial derivative of \u0177, we have", "Note: Here, we\u2019ve made use of this formula for differentiating an inverse matrix", "Similarly, we can compute the partial derivative of h", "Combining the terms and summing, the full derivative is then\u00b3", "With efficient formulations for the derivative and value, we can start from any initial guess and, using an optimizer, quickly descend to parameters that minimize the LOOCV.", "Note: It can also be beneficial to provide optimizers with the hessian matrix of the LOOCV\u2019s second derivatives. These equations are more complex, and this blog post only derives the first derivatives, but they can be computed in a similar manner to the gradient.", "Let\u2019s compare the performance of ridge regression using a single regularizer to that using separate regularizers for each regressor.", "For each trial of the simulation, models will be fit to generated training data with n x 3 feature matrices of independent identically distributed random variables where", "The target values will be generated by", "The results of a trial are the prediction errors", "on an out-of-sample datapoint \ud835\udc31\u2032, y\u2032 generated from the same distributions as the training data. Errors are averaged over multiple trial runs and the training size, n, is varied\u2074. The three models compared are", "The below graph shows the mean prediction error of the models for each value of n along with error bars representing a 95% confidence interval for the mean (using a t-statistic).", "While the results are sensitive to the simulation parameters, this shows that, at least for some problems, separate regularizers can provide better performance than a single regularizer.", "We showed how to efficiently compute the LOOCV for ridge regression and we derived equations for its derivatives. This allowed us to use an optimizer to find regularization parameters that minimized the LOOCV error. An optimizer takes away the work of having to pick and trial different parameters; but most importantly, it opens the door to using more complex multivariable parameterizations of the regularization matrix. And we demonstrated how one such multivariable parameterization (using a separate regularizer for each feature variable) led to better performance on a test problem.", "In the next installment, I\u2019ll explain why leave-one-out is frequently not the right form of cross-validation to use and introduce Generalized Cross-Validation as what we should be using instead. I\u2019ll also compare the performance of different approaches to ridge regression on a real-world problem.", "If you\u2019re interested in auto-tuning regularization parameters or using multiple regularizers, check out the buildingblock.ai.", "[1]: sklearn.linear_model.RidgeCV (and similarly sklearn.model_selection.GridSearchCV), for example, compute cross-validations by brute force over a list of pre-selected parameters to find the best scoring one.", "[3]: It can be easy to make mistakes when deriving derivative equations like this, but fortunately it\u2019s also easy to test using finite differences. See https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-gradient-verify.ipynb", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F34ecb6ee3b12&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ryan.burn?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ryan.burn?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Ryan Burn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff55ad0a8217&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&user=Ryan+Burn&userId=f55ad0a8217&source=post_page-f55ad0a8217----34ecb6ee3b12---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/optimization-and-ml", "anchor_text": "Optimization and Machine Learning"}, {"url": "https://unsplash.com/@therawhunter?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Massimiliano Morosinotto"}, {"url": "https://unsplash.com/s/photos/peak?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)", "anchor_text": "cross-validations"}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation", "anchor_text": "Leave-One-Out Cross-Validation"}, {"url": "https://en.wikipedia.org/wiki/Definiteness_of_a_matrix", "anchor_text": "positive definite"}, {"url": "https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula", "anchor_text": "Sherman-Morrison formula"}, {"url": "https://towardsdatascience.com/what-form-of-cross-validation-should-you-use-76aaecc45c75", "anchor_text": "installment"}, {"url": "https://buildingblock.ai", "anchor_text": "buildingblock.ai"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html", "anchor_text": "sklearn.linear_model.RidgeCV"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV", "anchor_text": "sklearn.model_selection.GridSearchCV"}, {"url": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-verify.ipynb", "anchor_text": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-verify.ipynb"}, {"url": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-gradient-verify.ipynb", "anchor_text": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-gradient-verify.ipynb"}, {"url": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-simulation.ipynb", "anchor_text": "https://github.com/rnburn/ridge-regression-doc/blob/master/notebooks/loocv-simulation.ipynb"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----34ecb6ee3b12---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ridge-regression?source=post_page-----34ecb6ee3b12---------------ridge_regression-----------------", "anchor_text": "Ridge Regression"}, {"url": "https://medium.com/tag/linear-regression?source=post_page-----34ecb6ee3b12---------------linear_regression-----------------", "anchor_text": "Linear Regression"}, {"url": "https://medium.com/tag/optimization?source=post_page-----34ecb6ee3b12---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/optimization-and-ml?source=post_page-----34ecb6ee3b12---------------optimization_and_ml-----------------", "anchor_text": "Optimization And Ml"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&user=Ryan+Burn&userId=f55ad0a8217&source=-----34ecb6ee3b12---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&user=Ryan+Burn&userId=f55ad0a8217&source=-----34ecb6ee3b12---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F34ecb6ee3b12&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----34ecb6ee3b12---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----34ecb6ee3b12--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ryan.burn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ryan.burn?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ryan Burn"}, {"url": "https://medium.com/@ryan.burn/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "94 Followers"}, {"url": "http://buildingblock.ai", "anchor_text": "buildingblock.ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff55ad0a8217&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&user=Ryan+Burn&userId=f55ad0a8217&source=post_page-f55ad0a8217--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdc9aa2a87345&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-do-ridge-regression-better-34ecb6ee3b12&newsletterV3=f55ad0a8217&newsletterV3Id=dc9aa2a87345&user=Ryan+Burn&userId=f55ad0a8217&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}