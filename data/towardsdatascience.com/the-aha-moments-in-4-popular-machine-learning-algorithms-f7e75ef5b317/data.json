{"url": "https://towardsdatascience.com/the-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317", "time": 1683012661.9176042, "path": "towardsdatascience.com/the-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317/", "webpage": {"metadata": {"title": "The Aha! Moments In 4 Popular Machine Learning Algorithms | by Andre Ye | Towards Data Science", "h1": "The Aha! Moments In 4 Popular Machine Learning Algorithms", "description": "This article seeks to explain not only how algorithms work, but give an intuitive understanding of why they work, to deliver that lightbulb aha! moment. Decision Trees divide the feature space using\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://towardsdatascience.com/how-injecting-randomness-can-improve-model-accuracy-11cdc04b3eeb", "anchor_text": "bagging", "paragraph_index": 18}, {"url": "https://medium.com/analytics-vidhya/every-ml-engineer-needs-to-know-neural-network-interpretability-afea2ac0824e", "anchor_text": "activation maximization and sensitivity analysis", "paragraph_index": 28}, {"url": "https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126", "anchor_text": "here", "paragraph_index": 29}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership", "paragraph_index": 34}], "all_paragraphs": ["Most people are either in two camps:", "This article seeks to explain not only how algorithms work, but give an intuitive understanding of why they work, to deliver that lightbulb aha! moment.", "Decision Trees divide the feature space using horizontal and vertical lines. For example, consider a very simplistic Decision Tree below, which has one conditional node and two class nodes, indicating a condition and under which category a training point that satisfies it will fall into.", "Note that there is a lot of overlap between the fields marked as each color and the data points within that area that actually are that color, or (roughly) entropy. The decision tree is constructed to minimize the entropy. In this scenario, we can add an additional layer of complexity. If we were to add another condition; if x is less than 6 and y is larger than 6, we can designate points in that area as red. The entropy has been lowered with this move.", "Each step, the Decision Tree algorithm attempts to find a method to build the tree such that the entropy is minimized. Think of entropy more formally as the amount of \u2018disorder\u2019 or \u2018confusion\u2019 a certain divider (the conditions) has, and its opposite as \u2018information gain\u2019 \u2014 how much a divider adds information and insight to the model. Feature splits that have the highest information gain (as well as a lowest entropy) are placed at the top.", "The conditions may split their one-dimensional features somewhat like this:", "Note that condition 1 has clean separation, and therefore low entropy and high information gain. The same cannot be said for condition 3, which is why it is placed near the bottom of the Decision Tree. This construction of the tree ensures that it can remain as lightweight as possible.", "You can read more about entropy and its use in Decision Trees as well as neural networks (cross-entropy as a loss function) here.", "Random Forest is a bagged (bootstrap aggregated) version of the Decision Tree. The primary idea is that several Decision Trees are each trained on a subset of data. Then, an input is passed through each model, and their outputs are aggregated through a function like a mean to produce a final output. Bagging is a form of ensemble learning.", "There are many analogies for why Random Forest works well. Here is a common version of one:", "You need to decide which restaurant to go to next. To ask someone for their recommendation, you must answer a variety of yes/no questions, which will lead them to make their decision for which restaurant you should go to.", "Would you rather only ask one friend or ask several friends, then find the mode or general consensus?", "Unless you only have one friend, most people would answer the second. The insight this analogy provides is that each tree has some sort of \u2018diversity of thought\u2019 because they were trained on different data, and hence have different \u2018experiences\u2019.", "This analogy, clean and simple as it is, never really stood out to me. In the real world, the single-friend option has less experience than all the friends in total, but in machine learning, the decision tree and random forest models are trained on the same data, and hence, same experiences. The ensemble model is not actually receiving any new information. If I could ask one all-knowing friend for a recommendation, I see no objection to that.", "How can a model trained on the same data that randomly pulls subsets of the data to simulate artificial \u2018diversity\u2019 perform better than one trained on the data as a whole?", "Take a sine wave with heavy normally distributed noise. This is your single Decision Tree classifier, which is naturally a very high-variance model.", "100 \u2018approximators\u2019 will be chosen. These approximators randomly select points along the sine wave and generate a sinusoidal fit, much like decision trees being trained on subsets of the data. These fits are then averaged to form a bagged curve. The result? \u2014 a much smoother curve.", "The reason why bagging works is because it reduces the variance of models, and helps improve capability to generalize, by artificially making the model more \u2018confident\u2019. This is also why bagging does not work as well on already low-variance models like logistic regression.", "You can read more about the intuition and more rigorous proof of the success of bagging here.", "Support Vector Machines attempt to find a hyperplane that can divide the data best, relying on the concept of \u2018support vectors\u2019 to maximize the divide between the two classes.", "Unfortunately, most datasets are not so easily separable, and if they were, SVM would likely not be the best algorithm to handle it. Consider this one-dimensional separation task; there is no good divider, since any one separation will cause two separate classes to be lumped into the same one.", "SVM is powerful at solving these kinds of problems by using a so-called \u2018kernel trick\u2019, which projects data into new dimensions to make the separation task easier. For instance, let\u2019s create a new dimension, which is simply defined as x\u00b2 (x is the original dimension):", "Now, the data is cleanly separable after the data was projected onto a new dimension (each data point represented in two dimensions as (x, x\u00b2)).", "Using a variety of kernels \u2014 most popularly, polynomial, sigmoid, and RBF kernels \u2014 the kernel trick does the heavy lifting to create a transformed space such that the separation task is simple.", "Neural Networks are the pinnacle of machine learning. Their discovery, and that unlimited variations and improvements that can be made upon it have warranted it the subject of its own field, deep learning. Admittedly, the success of neural networks is still incomplete (\u201cNeural networks are matrix multiplications that no one understands\u201d), but the easiest way to explain them is through the Universal Approximation Theorem (UAT).", "At their core, every supervised algorithm seeks to model some underlying function of the data; usually this is either a regression plane or the feature boundary. Consider this function y = x\u00b2, which can be modelled to an arbitrary accuracy with several horizontal steps.", "This is essentially what a neural network can do. Perhaps it can be a little more complex and model relationships beyond horizontal steps (like quadratic and linear lines below), but at its core, the neural network is a piecewise function approximator.", "Each node is in delegated to one part of the piecewise function, and the purpose of the network is to activate certain neurons responsible for parts of the feature space. For instance, if one were to classify images of men with beards or no beards, several nodes should be delegated specifically to pixel locations where beards often appear. Somewhere in multi-dimensional space, these nodes represent a numerical range.", "Note, again, that the question \u201cwhy do neural networks work\u201d is still unanswered. The UAT doesn\u2019t answer this question, but states that neural networks, under certain human interpretations, can model any function. The field of Explainable/Interpretable AI is emerging to answer these questions with methods like activation maximization and sensitivity analysis.", "You can read a more in-depth explanation and view visualizations of the Universal Approximation Theorem here.", "In all four algorithms, and many others, these look very simplistic at a low dimensionality. A key realization in machine learning is that a lot of the \u2018magic\u2019 and \u2018intelligence\u2019 we purport to see in AI is really a simple algorithm hidden under the guise of high dimensionality.", "Decision trees splitting regions into squares is simple, but decision trees splitting high-dimensional space into hypercubes is less so. SVM performing a kernel trick to improve separability from one to two dimensions is understandable, but SVM doing the same thing on a dataset of hundreds of dimensions large is almost magic.", "Our admiration and confusion of machine learning is predicated on our lack of understanding for high dimensional spaces. Learning how to get around high dimensionality and understanding algorithms in a native space is instrumental to an intuitive understanding.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML enthusiast. Join Medium through my referral link: https://andre-ye.medium.com/membership."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff7e75ef5b317&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andre-ye.medium.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006----f7e75ef5b317---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/illustrations/light-bulb-think-idea-solution-2010022/", "anchor_text": "Pixabay"}, {"url": "https://towardsdatascience.com/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/how-injecting-randomness-can-improve-model-accuracy-11cdc04b3eeb", "anchor_text": "bagging"}, {"url": "https://medium.com/analytics-vidhya/every-ml-engineer-needs-to-know-neural-network-interpretability-afea2ac0824e", "anchor_text": "activation maximization and sensitivity analysis"}, {"url": "https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/the-fascinating-no-gradient-approach-to-neural-net-optimization-abb287f88c97", "anchor_text": "The Fascinating No-Gradient Approach to Neural Net OptimizationForget Adam, Adagrad, SGDtowardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f7e75ef5b317---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----f7e75ef5b317---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----f7e75ef5b317---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f7e75ef5b317---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----f7e75ef5b317---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&user=Andre+Ye&userId=be743a65b006&source=-----f7e75ef5b317---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&user=Andre+Ye&userId=be743a65b006&source=-----f7e75ef5b317---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff7e75ef5b317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f7e75ef5b317---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f7e75ef5b317--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://andre-ye.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff44a966e4ff1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-aha-moments-in-4-popular-machine-learning-algorithms-f7e75ef5b317&newsletterV3=be743a65b006&newsletterV3Id=f44a966e4ff1&user=Andre+Ye&userId=be743a65b006&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}