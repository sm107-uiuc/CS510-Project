{"url": "https://towardsdatascience.com/using-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8", "time": 1683017480.31653, "path": "towardsdatascience.com/using-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8/", "webpage": {"metadata": {"title": "Using Python and Spark to research the Climate Change, Part 1 | by Kaya Kupferschmidt | Towards Data Science", "h1": "Using Python and Spark to research the Climate Change, Part 1", "description": "The climate change currently is a hot topic, with many experts claiming a significant increase of the average temperature over the whole world. Nevertheless some people don\u2019t believe these experts\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/dimajix/weather-analysis", "anchor_text": "GitHub", "paragraph_index": 3}, {"url": "https://www.anaconda.com/products/individual", "anchor_text": "Anaconda Python", "paragraph_index": 11}, {"url": "https://github.com/dimajix/weather-analysis", "anchor_text": "GitHub repository", "paragraph_index": 11}, {"url": "https://www.noaa.gov/", "anchor_text": "National Oceanic and Atmospheric Administration", "paragraph_index": 14}, {"url": "https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf", "anchor_text": "isd-format-document.pdf", "paragraph_index": 18}, {"url": "https://filezilla-project.org/", "anchor_text": "FileZilla", "paragraph_index": 19}], "all_paragraphs": ["The climate change currently is a hot topic, with many experts claiming a significant increase of the average temperature over the whole world. Nevertheless some people don\u2019t believe these experts and claim that the climate didn\u2019t change, and other people question the influence of the human species on the current development.", "While I am by no means an expert for climate or weather, I was wondering if I could follow the claims of an increase of the average temperature by analyzing appropriate data. Depending on the chosen data source, following this idea can be a technically challenging and insightful journey into weather data. In this article series I want to present my approach of using PySpark for analyzing ca 100GB of compressed raw weather data for reconstructing some relevant metrics substantiating the climate change.", "The purpose of the article series actually is two-fold: Diving into working with weather measurements and providing a non-trivial example for using PySpark with real data.", "Many details of processing steps are omitted in this article to keep focus on the general approach. You can find a Jupyter notebook containing the complete working code on GitHub.", "Since the whole analysis from downloading the data until performing some analysis involves many steps, the whole journey is split up into three separate articles as follows", "I am neither an expert for meteorology nor for climate models. I will try to use common sense to gather some insights. Eventually this was part of my idea: Everyone who has some experience with working with data should be able to perform some conclusions on the climate change given a detailed enough data set.", "I will add some remarks where I know that things are not correct. As far as I know real expert would go down a completely different route and build a weather model from the given measurements and then interpolate the weather evenly across the whole earth. This is completely out of scope for me, we instead will use simple averages of the measurements per country.", "By reading this first article in the series and even more by following the Jupyter notebook, you will learn several things:", "Before we start with the actual work, I\u2019d like to present the prerequisites required to follow the next steps.", "Whenever an article gives you recommendations about hardware, you should be warned. That\u2019s not different in this case. We will be working with 100 GB of compressed raw data, which requires appropriate storage capacity. We will derive additional data sets from this raw data, which again needs free storage capacity. Plus we will be using PySpark which requires additional temporary disk space.", "But disk space is not enough for processing 100GB compressed data, you also need CPU power and possibly RAM, which Spark can use. So I recommend the following hardware:", "For following all steps, you need to provide a Python environment containing PySpark and Jupyter. I use the Anaconda Python distribution for this task and you will find an appropriate environment.yml file in the GitHub repository for creating a conda environment with all required dependencies. Once you cloned the repository and installed Anaconda (or Miniconda), you can create a self-contained Python environment with the following command", "Then you can activate the environment and start the Jupyter Lab server via", "In order to perform some analysis on weather data, we first need to get some weather data. When you search the internet, you might find many different sources, which differ in various aspects:", "A couple of years ago, I found a very valuable source for precisely such data provided by the National Oceanic and Atmospheric Administration (NOAA) called the \u201cIntegrates Surface Database\u201d (ISD).", "The data set is really very impressive because of its detail and history:", "Originally I was searching for a non-trivial data set to be used in Spark workshops, but after some time I realized that this data is really a small treasure which could be used for more serious questions concerning weather and climate.", "The data can be downloaded via ftp either from one of the two following URLs:", "Under each of these URLs you will find multiple sub directories for all the years since 1901. You will need all these yearly sub directories. In addition you will also need a file called isd-history.csv which contains important meta information on all weather station. I also strongly suggest to download the documentation isd-format-document.pdf of the file format used for all weather measurements.", "I highly recommend using a dedicated ftp Client providing a download queue and automatic retries. I used the venerable FileZilla for downloading all files:", "Be patient when downloading the data, I think it took almost two days until my computer fetched all the 100GB of compressed data. (FTP isn\u2019t the fastest protocol for many small files plus the NOAA servers only allow for two parallel connections per source IP address).", "We will refine the data in multiple processing steps to make it more accessible for our use case. This approach is in line with the concepts of a Data Lake, except that we only use a single data source. The important take away here is that we", "As we will see below, the measurements data is stored in a non-standard file format and therefore needs some work to make it easily accessible. This essentially involves classical data extraction patterns on a (relatively) massive amount of data. In order to avoid any limitations by the amount of available RAM for processing 100GB of raw data, we employ PySpark as our workhorse which provides us a scalable data processing framework.", "The original data set essentially is made up of two different record types:", "In order to warm up, let\u2019s start inspecting the master data, as it is much easier to work with.", "The master data contained in the file isd-history.csv is a simple CSV file (as the extension already suggest). So we can easily read the file via PySpark standard functionality:", "The master data contains several columns of importance for us", "We see that some column names contain some problematic characters like whitespaces and braces. Therefore we rename some columns and eventually save the result as Parquet files, which we will then use in later steps.", "That was all for the master data. But beware, now come the weather measurements:", "Working with the measurements is much more difficult, even on a purely technical level (without interpreting the semantics), since the data is stored in a proprietary ASCII format. Let\u2019s peek inside an arbitrary year:", "That doesn\u2019t exactly look like something simple to work with. The details of the format are described in the isd-format-document.pdf which is also available on the FTP servers. When you read the documentation, you\u2019ll find out that the format actually is rather complex. Essentially the file is", "All data stored at fixed locations can easily be extracted (although it always takes some time to get things right), but the dynamic part is really difficult. Actually you will also find some Java source code on the FTP server to parse the data \u2014 but that is obviously not a trivial option in a Python environment. Fortunately the most interesting metrics like air temperature and wind speed is stored at fixed locations (precipitation is not, but we ignore this aspect for today):", "In order to extract these values from each ASCII record, we simply use the PySpark SQL function substring and cast the result to an appropriate data type. We also incorporate any required scaling for temperature and wind speed.", "With this knowledge, we already can extract some important information (some columns are omitted in the code example below):", "You will find some additional code to extract precipitation data in the Jupyter notebook. Finally, a Python function is provided that extracts all the required columns (and some more) from the raw data:", "Note that in addition to the measurements themselves we also extract quality indicators for each measurements (not shown in the code above). These indicators are also described in the official documentation and tell us if each metric of each measurement is valid or not. There are multiple different scenarios which result in partially invalid measurements:", "So far we only focused on extracting relevant metrics from a single year, but of course we need to apply the logic the full history from 1901 until today. This is easily achieved by reading, transforming and writing each year seperately in a simple for loop.", "We keep the pattern of having a separate directory for each year \u2014 this might come in handy for questions about a limited time range.", "Note that depending on the beefiness of your machine, this extraction and conversion might take several hours. But keep in mind, that we are processing 100GB of compressed data.", "In this first part of the series, we mainly achieved two goals: We downloaded all the raw data from the NOAA ftp server and we extracted some important metrics from the raw files and stored them in Parquet files. So far we didn\u2019t really perform any interpretation of the data, all steps merely were a technical format conversion. Such a first step is quite common to transform incoming data into a format that is well supported by the used processing framework \u2014 which in our case is Apache Spark.", "So far we didn\u2019t investigate into the semantics of the data, we merely extracted some metrics without understanding their meaning. In the next part of this series we will move up one level from a purely technical conversion and add semantic processing steps performed on the Parquet files in order to further simplify working with the data in an analytical context.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance Big Data and Machine Learning expert at dimajix."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7616b71cefe8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@kupferk", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://kupferk.medium.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Kaya Kupferschmidt"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa1b1c406b9d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=post_page-a1b1c406b9d0----7616b71cefe8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/data-for-change", "anchor_text": "Data for Change"}, {"url": "https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral", "anchor_text": "NASA"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/dimajix/weather-analysis", "anchor_text": "GitHub"}, {"url": "https://towardsdatascience.com/using-python-and-spark-to-research-the-climate-change-part-2-e2ac9faba821", "anchor_text": "Preparing the data."}, {"url": "https://www.anaconda.com/products/individual", "anchor_text": "Anaconda Python"}, {"url": "https://github.com/dimajix/weather-analysis", "anchor_text": "GitHub repository"}, {"url": "https://www.noaa.gov/", "anchor_text": "National Oceanic and Atmospheric Administration"}, {"url": "https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf", "anchor_text": "isd-format-document.pdf"}, {"url": "https://filezilla-project.org/", "anchor_text": "FileZilla"}, {"url": "https://en.wikipedia.org/wiki/List_of_FIPS_country_codes", "anchor_text": "https://en.wikipedia.org/wiki/List_of_FIPS_country_codes"}, {"url": "https://medium.com/tag/climate-change?source=post_page-----7616b71cefe8---------------climate_change-----------------", "anchor_text": "Climate Change"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----7616b71cefe8---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/big-data-analytics?source=post_page-----7616b71cefe8---------------big_data_analytics-----------------", "anchor_text": "Big Data Analytics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7616b71cefe8---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-for-change?source=post_page-----7616b71cefe8---------------data_for_change-----------------", "anchor_text": "Data For Change"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=-----7616b71cefe8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=-----7616b71cefe8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7616b71cefe8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7616b71cefe8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7616b71cefe8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7616b71cefe8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7616b71cefe8--------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://kupferk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kaya Kupferschmidt"}, {"url": "https://kupferk.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "223 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa1b1c406b9d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=post_page-a1b1c406b9d0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F874fa4e516b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-python-and-spark-to-research-the-climate-change-part-1-7616b71cefe8&newsletterV3=a1b1c406b9d0&newsletterV3Id=874fa4e516b6&user=Kaya+Kupferschmidt&userId=a1b1c406b9d0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}