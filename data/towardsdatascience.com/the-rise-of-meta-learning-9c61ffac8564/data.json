{"url": "https://towardsdatascience.com/the-rise-of-meta-learning-9c61ffac8564", "time": 1682992997.370274, "path": "towardsdatascience.com/the-rise-of-meta-learning-9c61ffac8564/", "webpage": {"metadata": {"title": "The Rise of Meta Learning. OpenAI\u2019s robotic hand is fueled by\u2026 | by Connor Shorten | Towards Data Science", "h1": "The Rise of Meta Learning", "description": "Meta-Learning describes the abstraction to designing higher level components associated with training Deep Neural Networks. The term \u201cMeta-Learning\u201d is thrown around in Deep Learning literature\u2026"}, "outgoing_paragraph_urls": [{"url": "https://openai.com/blog/learning-dexterity/", "anchor_text": "very similar study", "paragraph_index": 1}, {"url": "https://arxiv.org/pdf/1511.04599.pdf", "anchor_text": "adversarial noise injections", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1612.07828", "anchor_text": "SimGAN", "paragraph_index": 3}, {"url": "https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "anchor_text": "Generative Adversarial Network", "paragraph_index": 3}, {"url": "https://arxiv.org/pdf/1703.06907.pdf", "anchor_text": "Domain Randomization", "paragraph_index": 4}, {"url": "https://d4mucfpksywv.cloudfront.net/papers/solving-rubiks-cube.pdf", "anchor_text": "See Appendeix B of Solving Rubik\u2019s Cube with a Robot Hand for more details", "paragraph_index": 6}, {"url": "https://arxiv.org/pdf/1901.01753.pdf", "anchor_text": "Paired Open-Ended Trailblazer (POET)", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1707.09835.pdf", "anchor_text": "Meta-Learning optimizers", "paragraph_index": 11}, {"url": "https://link.springer.com/article/10.1186/s40537-019-0197-0", "anchor_text": "Data Augmentation", "paragraph_index": 11}, {"url": "https://paperswithcode.com/sota/image-classification-on-imagenet", "anchor_text": "paperswithcode.com", "paragraph_index": 14}, {"url": "https://arxiv.org/abs/1905.05393", "anchor_text": "Population-Based Search proven useful in Data Augmentation by Researchers at UC Berkeley", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/1805.09501", "anchor_text": "AutoAugment from Google", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/1502.03167?context=cs", "anchor_text": "Batch Normalization", "paragraph_index": 19}, {"url": "https://www.amazon.com/Rebooting-AI-Building-Artificial-Intelligence-ebook/dp/B07MYLGQLB", "anchor_text": "Gary Marcus?", "paragraph_index": 20}, {"url": "https://openreview.net/pdf?id=rJMw747l_4", "anchor_text": "it doesn\u2019t seem like the current state-of-the-art generative models such as BigGAN or VQ-VAE-2 works for data augmentation on ImageNet classification.", "paragraph_index": 21}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet classification", "paragraph_index": 22}, {"url": "https://www.kaggle.com/c/severstal-steel-defect-detection", "anchor_text": "identifying steel defects", "paragraph_index": 22}, {"url": "https://arxiv.org/abs/1905.10985", "anchor_text": "escribed in Jeff Clune\u2019s AI-GAs", "paragraph_index": 24}], "all_paragraphs": ["Meta-Learning describes the abstraction to designing higher level components associated with training Deep Neural Networks. The term \u201cMeta-Learning\u201d is thrown around in Deep Learning literature frequently referencing \u201cAutoML\u201d, \u201cFew-Shot Learning\u201d, or \u201cNeural Architecture Search\u201d when in reference to the automated design of neural network architectures. Emerging from comically titled papers such as \u201cLearning to learn by gradient descent by gradient descent\u201d, the success of OpenAI\u2019s rubik\u2019s cube robotic hand demonstrates the maturity of the idea. Meta-Learning is the most promising paradigm to advance the state-of-the-art of Deep Learning and Artificial Intelligence.", "OpenAI set the AI world on fire by demonstrating ground-breaking capabilities of a robotic hand trained with Reinforcement Learning. This success builds on a very similar study presented in July 2018 tasking a robotic hand to orient a block in a configuration matching a visual prompt. This evolution from block orientation to solving a rubik\u2019s cube is fueled by a Meta-Learning algorithm controlling the training data distribution in simulation, Automatic Domain Randomization (ADR).", "Domain randomization is an algorithm to address the data augmentation problem for Sim2Real transfer. The core function of function approximation (and Deep Learning) is to generalize from what it has learned in training, to never-seen-before test data. Although not as surprising as misclassifications do to hardly noticeable adversarial noise injections, Deep Convolutional Neural Networks will not generalize when trained on images in simulation (displayed below on the left) to real visual data (shown below on the right) without special modifications.", "Naturally, there are two approaches to align the simulated and real data distributions. One such approach, developed by researchers at Apple is called SimGAN. SimGAN uses an adversarial loss to train the generator of a Generative Adversarial Network to make simulated images appear as realistic as possible, criticized by a discriminator classifying images as belonging to the real or simulated dataset. The research reports a positive result on eye gaze estimation and hand pose estimation. The other approach is to make the simulated data as diverse as possible, contrarily to as realistic as possible.", "The latter approach is referred to as Domain Randomization. This idea is well illustrated in the image below from Tobin et al.\u2019s paper in 2017:", "Domain Randomization appears to be the key to bridging the Sim2Real gap, allowing Deep Neural Networks to generalize to real data when trained on simulation. Not unlike most algorithms, Domain Randomization comes with many parameters to be tuned. The image below shows randomizations in the colors of the blocks, the lighting of the environment, and the magnitude of shadows, to name a few. Each of these randomized environment features comes with a lower to upper bound interval and some kind of sampling distribution. For example, when sampling a randomized environment, what is the probability this environment has very bright lighting?", "In OpenAI\u2019s original Dactyl study achieving block orientation with a robotic hand, the domain randomization data curriculum is manually encoded prior to the experiment. This domain randomization transcends the visual world, randomizing components in the physics simulator that leads to a policy enabling the robotic hand to move with dexterity and precision. Similarly to the idea of visual randomization, these physics randomizations include dimensions such as the size/mass of the cube and the friction of the fingers in the robot\u2019s hand, amongst others (See Appendeix B of Solving Rubik\u2019s Cube with a Robot Hand for more details).", "The key from Dactyl to the Rubik\u2019s Cube solver is that the domain randomization is curriculum defining the intensity of randomization is automated rather than manually designed, clearly defined in the following lines of the ADR algorithm:", "AI that Designs its Own Data", "One of the best examples of AI that designs its own data is the Paired Open-Ended Trailblazer (POET) algorithm developed by researchers at Uber AI Labs.", "POET trains a bipedal walking agent by simultaneously optimizing the agent and the environment in which it learns to walk in. POET is different from OpenAI\u2019s rubik\u2019s cube solver in that it uses an evolutionary algorithm, maintaining a population of walkers and environments. The structure of having populations of agents and environments is key to structuring the evolution of complexity in this research. Despite the use of Reinforcement Learning to train a single agent compared to Population-based Learning to adapt a group of agents, POET and Automatic Domain Randomization are very similar. They both develop a progression of increasingly challenging training datasets in an automated way. The Bipedal\u2019s walking environment does not change as a manually encoded function, but rather as a result of the population of walkers performances in the different environments, signaling when it is time to crank up the challenge of the terrain.", "Research in Meta-Learning has generally focused on data and model architectures, with exceptions such as Meta-Learning optimizers, which seems to still fall under the umbrella of model optimization. Meta-learning in the data space such as Automatic Domain Randomization has been heavily studied in the form of Data Augmentation.", "Data Augmentation is most easily understood in the context of image data, although we have already seen how the physics data can be augmented and randomized as well. These image augmentations typically include horizontal flips and small magnitudes of rotations or translations. This kind of augmentation is typical in any computer vision pipeline such as image classification, object detection, or super resolution.", "Curriculum Learning is another data-level optimization concerned with the order in which data is presented to learning models. For example, starting a student off with easy examples such as 2 + 2 = 4, before introducing more difficult ideas such as 2\u00b3 = 8. Meta-Learning controllers of Curriculum Learning look at how data is ranked according to some metric of perceived difficulty and the order in which this data should be presented in. A recent study from Hacohen and Weinshall presents interesting success with this (shown below) in the ICML 2019 conference.", "Neural Architecture Search, or Meta-Learning models generally receive more attention than data-level optimizations. This is highly motivated by the trends in Deep Learning research. There is a clear performance benefit from extending the foundational AlexNet architecture that pioneered the use of Deep Convolutional Networks trained on big datasets on big GPU computing to the ResNet architecture. ResNet was further extended with manual designs such as DenseNet, and then surpassed by meta-learning techniques such as AmoebaNet and EfficientNet. The timeline of image classification benchmark advancement can be found on paperswithcode.com.", "Meta-learning neural architectures try to describe a space of possible architectures and then search for the best architecture according to one or multiple objective metrics.", "Neural Architecture Search has employed a wide range of algorithms to search for architectures, Random Search, Grid Search, Bayesian Optimization, Neuro-evolution, Reinforcement Learning, and Differentiable Search. These search algorithms are all relatively sophisticated compared to the technique presented in OpenAI\u2019s Automatic Domain Randomization. It seems likely that the ideas of Automatic Domain Randomization would be improved with advanced search algorithms, i.e. something like the Population-Based Search proven useful in Data Augmentation by Researchers at UC Berkeley or AutoAugment from Google.", "One of the limitations of Meta-Learning frequently addressed in Neural Architecture Search is the constraint of the search space. Neural Architecture Searches begin from a manually designed encoding of possible architectures. This manual encoding naturally limits the discoveries possible by the search. However, there is a trade-off necessary to make the search computable at all.", "Current architecture searches view neural architectures as Directed Acyclic Graphs (DAGs) and try to optimize the connections between nodes. Papers such as \u201cWeight Agnostic Neural Networks\u201d by Gaier and Ha and \u201cExploring Randomly Wired Neural Networks for Image Recognition\u201d by Xie et al. show that constructing DAG neural architectures is complex and not well understood.", "The interesting question is when will Neural Architecture Search be able to optimize the operations at nodes, the connections between them, and then have the freedom to discover things like novel activation functions, optimizers, or normalization techniques such as Batch Normalization.", "It is interesting to think about how abstract can Meta-Learning controllers be. For example, OpenAI\u2019s Rubik\u2019s cube solver essentially has 3 \u201cintelligent\u201d components, a symbolic rubik\u2019s cube solver, a vision model, and a controller network to manipulate the robotic hand. Could Meta-Learning controllers be smart enough to understand this kind of modularity and design the hybrid systems between symbolic and Deep Learning systems recently campaigned by Gary Marcus?", "Meta-Learning data augmentation is very constrained as well. Most data augmentation searches (even automatic domain randomization) is constrained to a set of transformations available to the meta-learning controller. These transformations could include things like the brightness of the image or the intensity of shadows in the simulation. An interesting opportunity for increasing the freedom of data augmentation is to combine these controllers with generative models capable of exploring very unique data points. These generative models could design new images of dogs and cats, rather than rotating existing ones or making the images darker/brighter. Although very interesting, it doesn\u2019t seem like the current state-of-the-art generative models such as BigGAN or VQ-VAE-2 works for data augmentation on ImageNet classification.", "\u201cMeta-Learning\u201d is frequently used to describe the capabilities of transfer and few-shot learning, differently from how \u201cAutoML\u201d is used to describe the optimization of models or datasets. This kind of definition aligns well with the domain adaptation task of Sim2Real solved by Automatic Domain Randomization. However, this definition also describes learning such as transferring from ImageNet classification to identifying steel defects.", "An interesting result of the Rubik\u2019s Cube Solver is the ability to adapt to perturbations. For example, the solver is able to continue despite putting a rubber glove on the hand, tying fingers together, and blanket occlusion of the cube, (the vision model must be completely impaired, thus the sensing has to be done by the Giiker cube\u2019s sensors). This kind of Transfer Meta-Learning is a result of the LSTM layers in the policy network used to train the robotic hand control. I think this use of \u201cMeta-Learning\u201d is more of a characteristic of Memory Augmented Networks compared to AutoML optimization. I think this demonstrates the difficulty of unifying Meta-Learning and settling on a single definition for the term.", "The success of the Rubik\u2019s Cube solver is obviously compelling due to the flashy display of robot hand coordination. However, the more interesting component of this research is the Meta-Learning Data Randomization under the hood. This is an algorithm that is learning while simultaneously designing its training data. This paradigm, described in Jeff Clune\u2019s AI-GAs, of algorithms that contain meta-learning architectures, meta-learning the learning algorithms themselves, and generating effective learning environments stand to be an enormous opportunity for the advancement of Deep Learning and Artificial Intelligence. Thank you for reading, if you want to learn more about OpenAI\u2019s paper, please check out the video below!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9c61ffac8564&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://connorshorten300.medium.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Connor Shorten"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59216259c525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&user=Connor+Shorten&userId=59216259c525&source=post_page-59216259c525----9c61ffac8564---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://openai.com/blog/solving-rubiks-cube/", "anchor_text": "https://openai.com/blog/solving-rubiks-cube/"}, {"url": "https://openai.com/blog/learning-dexterity/", "anchor_text": "very similar study"}, {"url": "https://arxiv.org/pdf/1511.04599.pdf", "anchor_text": "adversarial noise injections"}, {"url": "https://arxiv.org/abs/1612.07828", "anchor_text": "SimGAN"}, {"url": "https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf", "anchor_text": "Generative Adversarial Network"}, {"url": "https://arxiv.org/pdf/1703.06907.pdf", "anchor_text": "Domain Randomization"}, {"url": "https://d4mucfpksywv.cloudfront.net/papers/solving-rubiks-cube.pdf", "anchor_text": "See Appendeix B of Solving Rubik\u2019s Cube with a Robot Hand for more details"}, {"url": "https://arxiv.org/pdf/1901.01753.pdf", "anchor_text": "Paired Open-Ended Trailblazer (POET)"}, {"url": "https://arxiv.org/pdf/1707.09835.pdf", "anchor_text": "Meta-Learning optimizers"}, {"url": "https://link.springer.com/article/10.1186/s40537-019-0197-0", "anchor_text": "Data Augmentation"}, {"url": "https://paperswithcode.com/sota/image-classification-on-imagenet", "anchor_text": "paperswithcode.com"}, {"url": "https://arxiv.org/abs/1905.05393", "anchor_text": "Population-Based Search proven useful in Data Augmentation by Researchers at UC Berkeley"}, {"url": "https://arxiv.org/abs/1805.09501", "anchor_text": "AutoAugment from Google"}, {"url": "https://arxiv.org/abs/1502.03167?context=cs", "anchor_text": "Batch Normalization"}, {"url": "https://www.amazon.com/Rebooting-AI-Building-Artificial-Intelligence-ebook/dp/B07MYLGQLB", "anchor_text": "Gary Marcus?"}, {"url": "https://openreview.net/pdf?id=rJMw747l_4", "anchor_text": "it doesn\u2019t seem like the current state-of-the-art generative models such as BigGAN or VQ-VAE-2 works for data augmentation on ImageNet classification."}, {"url": "http://www.image-net.org/", "anchor_text": "ImageNet classification"}, {"url": "https://www.kaggle.com/c/severstal-steel-defect-detection", "anchor_text": "identifying steel defects"}, {"url": "https://arxiv.org/abs/1905.10985", "anchor_text": "escribed in Jeff Clune\u2019s AI-GAs"}, {"url": "https://medium.com/tag/meta-learning?source=post_page-----9c61ffac8564---------------meta_learning-----------------", "anchor_text": "Meta Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----9c61ffac8564---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9c61ffac8564---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9c61ffac8564---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9c61ffac8564---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&user=Connor+Shorten&userId=59216259c525&source=-----9c61ffac8564---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&user=Connor+Shorten&userId=59216259c525&source=-----9c61ffac8564---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9c61ffac8564&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9c61ffac8564---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9c61ffac8564--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9c61ffac8564--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9c61ffac8564--------------------------------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://connorshorten300.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Connor Shorten"}, {"url": "https://connorshorten300.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2K Followers"}, {"url": "https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw", "anchor_text": "https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F59216259c525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&user=Connor+Shorten&userId=59216259c525&source=post_page-59216259c525--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F303e04c63860&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-rise-of-meta-learning-9c61ffac8564&newsletterV3=59216259c525&newsletterV3Id=303e04c63860&user=Connor+Shorten&userId=59216259c525&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}