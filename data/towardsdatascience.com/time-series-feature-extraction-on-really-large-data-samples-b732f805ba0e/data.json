{"url": "https://towardsdatascience.com/time-series-feature-extraction-on-really-large-data-samples-b732f805ba0e", "time": 1683017406.7119749, "path": "towardsdatascience.com/time-series-feature-extraction-on-really-large-data-samples-b732f805ba0e/", "webpage": {"metadata": {"title": "Time Series Feature Extraction on (Really) Large Data Samples | by Nils Braun | Towards Data Science", "h1": "Time Series Feature Extraction on (Really) Large Data Samples", "description": "Time Series data is everywhere today. From stock market trends to EEG measurements, from Industry 4.0 production lines to IoT sensors \u2014 temporarily annotated data hides in a lot of places. It comes\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/time-series-analysis-with-deep-learning-simplified-5c444315d773", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://tsfresh.readthedocs.io/en/latest/", "anchor_text": "tsfresh", "paragraph_index": 6}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/data_formats.html", "anchor_text": "in the documentation", "paragraph_index": 8}, {"url": "http://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures", "anchor_text": "UCI page", "paragraph_index": 12}, {"url": "https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://docs.dask.org/en/latest/setup.html", "anchor_text": "dask documentation", "paragraph_index": 22}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/tsfresh_on_a_cluster.html", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://medium.com/@nils-braun/tsfresh-on-large-data-samples-part-ii-4d6843155dfc", "anchor_text": "next post", "paragraph_index": 26}, {"url": "https://twitter.com/dotcsDE", "anchor_text": "@dotcsDE", "paragraph_index": 27}, {"url": "https://twitter.com/snwalther", "anchor_text": "snwalther", "paragraph_index": 27}], "all_paragraphs": ["Time Series data is everywhere today. From stock market trends to EEG measurements, from Industry 4.0 production lines to IoT sensors \u2014 temporarily annotated data hides in a lot of places. It comes in many flavors, sizes, and complexities.", "In this series of two posts, we will explore how we can extract features from time series using tsfresh - even when the time series data is very large and the computation takes a very long time on a single core.", "But first, let\u2019s define some common properties of time series data:", "Many tasks around time series involve the application of machine learning algorithms, e.g. to classify the collected data of different ids or to predict future values of the time series. But before an algorithm can deduce, if for example, a measured heart rate shows the first signs of a heart attack or a stock chart line indicates the next big thing, useful features of the time series need to be extracted. Using these features, a machine learning algorithm can then learn to differentiate between signal and background data.", "Side note: in recent times a lot of effort has been put into time series analysis with deep learning methods. While this approach has definitely its benefits, it is only applicable to a certain range of problems. There exist a lot of documentation on how to use deep learning with time-series data (e.g. here) so we will not cover it in this post.", "Manual feature extraction is a time consuming and tedious task. In most cases it involves thinking about possible features, writing feature calculator code, consulting library API documentation, and drinking a lot of coffee. And in the end, most of the features will not make it to the production machine learning pipeline anyway.", "Therefore we invented tsfresh[1], which is a automated feature extraction and selection library for time series data. It basically consists of a large library of feature calculators from different domains (which will extract more than 750 features for each time series) and a feature selection algorithm based on hypothesis testing. In today's post (which will be the first of two parts about feature extraction with large time series data), we will only cover the feature extraction, as this is typically the (computationally) time-consuming part. The feature extractors range from simple ones like min, max, length to more complex ones like autocorrelation, fast Fourier transformation or augmented Dickey-Fuller tests. You can find a list of all features here.", "To extract the full set of features, all you need to do is installing tsfresh (via pip or conda) and calling with your pandas data frame df:", "The resulting pandas data frame df_features will contain all extracted features for each time series kind and id. tsfresh understands multiple input data frame schemas, which are described in detail in the documentation. You can also control which features are extracted with the settings parameters (default is to extract all features from the library with reasonable default configuration).", "So far, so easy. But what happens if you not only have a bunch of time-series but multiple? Thousands, millions?", "The time spent on feature extraction scales linearly with the number of time series. If you have gigabytes of time series, you should better grab another cup of coffee!", "Well, or you read on! :-) In this series of two posts, we are going to discuss four possibilities to speed up the calculation. Depending on the amount of data (and resources) you have, you can choose between:", "If you want to follow along with the code examples, make sure to install the most recent version of tsfresh (the following was tested with v0.15.1). You also need an example data set for testing. tsfresh comes with multiple example data, so let\u2019s choose one of them: the robot failure time series data. You can learn more about the data sample from the UCI page. To load it, add the following lines to your script:", "There is a lot to discover, so let\u2019s start! Feel free to immediately jump into one of the parts, if you already know what you are looking for.", "As a first step to speed up the calculation of features, we can distribute the feature extraction to multiple cores. Actually, if you have executed the code example from above, you have already done so! tsfresh comes with native support for multiprocessing and will use all of your CPU cores for the calculation. For this, each time series of distinct kind and id will be treated independently and send to a different core, where the feature extraction will happen. The results are collected in the end and combined into a large data frame.", "You can control the multiprocessing behavior with parameters passed to extract_features:", "Especially the chunk size has a large potential for optimizations. By default, it is chosen according to a heuristic which worked best in our tests \u2014 use it to balance between parallelism speedup and introduced overhead. For most of the applications though, you can keep the defaults.", "Note: As tsfresh uses Python\u2019s multiprocessing library under the hood, you need to fulfill all the requirements for its usage. Especially on Windows, this means you need to wrap your code with a if __name__ = '__main__' line, otherwise it will fail (See here for more information). You can also turn multiprocessing off by setting n_jobs to 0.", "Using multiple cores instead of one core for the feature calculation is already better, but how can you increase the processing speed even more? To distribute the calculation of the features to multiple machines tsfresh gives you the possibility to define a distributor. The data is still loaded on your local machine (and is required to be a pandas data frame, we will release this constraint in the next post), but you can use a distributor to e.g. let the heavy lifting of the feature calculation be done on multiple machines. This has the benefit of speeding up your computation without the need to change anything on your usual data science pipeline.", "Distributors offer a very general framework for implementing your own way, how you want your calculation to be shuffled on your cluster. As an example, an implementation of a distributor utilizing a cluster of dask workers comes already shipped with tsfresh. If you do not know what dask is: up to now think of it as a possibility to distribute work over a cluster of machines. We will come to the more complicated features of dask in the next post.", "Please note: with a distributor you can only control how the feature extraction calculation is distributed. This means the dask distributor just uses dask\u2019s capabilities to use multiple workers for performing a task. We are not (yet) using any of dask\u2019s distributed data features - this means you still need to be able to load the data into your (scheduling/driver) machine all at once.", "To use it, all you need to do is to define an instance of the ClusterDaskDistributor and pass it to the extract_features call:", "The address of the dask master depends on the way you have set up your dask cluster. Please refer to the awesome dask documentation for this! For testing, you could create your own small dask cluster by calling (after having installed dask via pip or conda):", "in another one. Use the printed scheduler address in your code. Now, you can scale your computation very easily by just adding more workers (or using one of the other possibilities to scale a dask cluster, e.g. via kubernetes, YARN, etc.). Please note that by default only a single CPU is used per worker. If you want to run more processes on each machine, use the --nprocs command line option when starting each worker.", "Distributing work with dask is just an example. If you want to support your own distribution framework, you can create your own Distributor class and implement the job scheduling logic. Some documentation is available here.", "So far we have covered how to extract time-series features on a large amount of data by speeding up the computation. Either by distributing the feature extracting over multiple CPU cores on your local machine or by distributing the work over a cluster of machines, e.g. using a cluster of dask workers. The clear benefit of using these possibilities: no need to change the rest of your pipeline. You start and end with pandas data frames and you still read in the data on your local machine - it basically looks like you would do your feature extraction on just a small sample.", "In the next post we will go one step further: what happens if you need to distribute the data because it does not fit into a single machine?", "Thanks to @dotcsDE and snwalther for reviewing this post!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb732f805ba0e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://nils-braun.medium.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": ""}, {"url": "https://nils-braun.medium.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Nils Braun"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b92b7d7556c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&user=Nils+Braun&userId=3b92b7d7556c&source=post_page-3b92b7d7556c----b732f805ba0e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/making-sense-of-big-data", "anchor_text": "Making Sense of Big Data"}, {"url": "https://unsplash.com/@chrisliverani?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Chris Liverani"}, {"url": "https://unsplash.com/s/photos/graph?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/time-series-analysis-with-deep-learning-simplified-5c444315d773", "anchor_text": "here"}, {"url": "https://tsfresh.readthedocs.io/en/latest/", "anchor_text": "tsfresh"}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html", "anchor_text": "here"}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/data_formats.html", "anchor_text": "in the documentation"}, {"url": "https://medium.com/@nils-braun/tsfresh-on-large-data-samples-part-ii-4d6843155dfc", "anchor_text": "next post"}, {"url": "https://medium.com/@nils-braun/tsfresh-on-large-data-samples-part-ii-4d6843155dfc", "anchor_text": "next post"}, {"url": "http://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures", "anchor_text": "UCI page"}, {"url": "https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods", "anchor_text": "here"}, {"url": "https://docs.dask.org/en/latest/setup.html", "anchor_text": "dask documentation"}, {"url": "https://tsfresh.readthedocs.io/en/latest/text/tsfresh_on_a_cluster.html", "anchor_text": "here"}, {"url": "https://medium.com/@nils-braun/tsfresh-on-large-data-samples-part-ii-4d6843155dfc", "anchor_text": "next post"}, {"url": "https://twitter.com/dotcsDE", "anchor_text": "@dotcsDE"}, {"url": "https://twitter.com/snwalther", "anchor_text": "snwalther"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b732f805ba0e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----b732f805ba0e---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/python?source=post_page-----b732f805ba0e---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----b732f805ba0e---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/making-sense-of-big-data?source=post_page-----b732f805ba0e---------------making_sense_of_big_data-----------------", "anchor_text": "Making Sense Of Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&user=Nils+Braun&userId=3b92b7d7556c&source=-----b732f805ba0e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&user=Nils+Braun&userId=3b92b7d7556c&source=-----b732f805ba0e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb732f805ba0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b732f805ba0e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b732f805ba0e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b732f805ba0e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b732f805ba0e--------------------------------", "anchor_text": ""}, {"url": "https://nils-braun.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://nils-braun.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nils Braun"}, {"url": "https://nils-braun.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "98 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b92b7d7556c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&user=Nils+Braun&userId=3b92b7d7556c&source=post_page-3b92b7d7556c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7f5298962150&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftime-series-feature-extraction-on-really-large-data-samples-b732f805ba0e&newsletterV3=3b92b7d7556c&newsletterV3Id=7f5298962150&user=Nils+Braun&userId=3b92b7d7556c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}