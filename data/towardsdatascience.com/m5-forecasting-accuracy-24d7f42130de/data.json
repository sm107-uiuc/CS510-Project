{"url": "https://towardsdatascience.com/m5-forecasting-accuracy-24d7f42130de", "time": 1683009619.334856, "path": "towardsdatascience.com/m5-forecasting-accuracy-24d7f42130de/", "webpage": {"metadata": {"title": "M5 Forecasting- Accuracy. Forecasting is done using Xgboost\u2026 | by Jaswanth Badvelu | Towards Data Science", "h1": "M5 Forecasting- Accuracy", "description": "In this blog, the Exploratory Data analysis for M5 competition data is performed using R, and sales for 28 days were forecasted using Xgboost, Catboost, Lightgbm, and Facebook prophet. The best model\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db", "anchor_text": "link", "paragraph_index": 35}, {"url": "https://arxiv.org/pdf/1811.10192.pdf", "anchor_text": "articles", "paragraph_index": 38}], "all_paragraphs": ["In this blog, the Exploratory Data analysis for M5 competition data is performed using R, and sales for 28 days were forecasted using Xgboost, Catboost, Lightgbm, and Facebook prophet. The best model is chosen by comparing the SMAPE error rate and One standard error rule.", "The Makridakis Competitions (also known as the M Competitions) are series of open competitions organized by teams led by forecasting researcher Spyros Makridakis and intended to evaluate and compare the accuracy of different forecasting methods. he first competition named M-Competition was held way back in 1982 with only 1001 data points, the complexity of the model and data scale increased with every successive iteration.", "In March this year(2020), the fifth iteration named M5 competition was held. This m5 competition aims to forecast daily sales for the next 28 days i.e., till 22nd May 2016, and to make uncertainty estimates for these forecasts. In this blog, I am just going to do forecasting and uncertainty will be performed in my next blog with the best-chosen model.", "The dataset provided contains 42,840 hierarchical sales data from Walmart. The dataset covers stores in three US states (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details for 5 years starting from 29th Jan 2011 to 24th April 2016. Also, it has explanatory variables such as price, snap events, day of the week, and special events and festivals.", "The data comprises 3049 individual products from 3 categories and 7 departments, sold in 10 stores in 3 states. The hierarchical aggregation captures the combinations of these factors which makes it feasible to perform a bottom-up approach or top-down approach. For instance, we can create 1 time series for all sales or perform for each state separately and so on.", "Based on the data given some of the factors that may affect sales are:", "Before diving deep into data exploration, A quick overview of population & Median Income for each state:", "The exploratory data analysis was done to test these hypothesis statements.", "Let\u2019s start data analysis by knowing which state recorded the highest sales and also the individual department sales in each of these three states.", "As expected, the Food department recorded the highest sales in all 3 states. Also, It can be seen from fig 2 that California had the highest sales overall. Having 4 stores and more population might be the reason. Surprisingly, Wisconsin even with low population density when compared to Texas recorded equal sales. To get better understanding sales for each store are plotted.", "Since sales are almost double for CA_3 when compared with other stores. The CA_3 may be a bigger store. The population density and median income also affect these sales.", "Now we have an idea about how sales are impacted by a different location, now let\u2019s explore the individual department for insights", "The number of available products is more in the Food_3 department. So Food 3 department may consist of daily consumed food products like milk etc. Now, let\u2019s see whether the price is having any impact on sales or not", "It can be seen that the Hobbies_1 department has the highest mean price and Food 3 being the lowest. Despite, California state population having more mean annual household income when compared to texas and Wisconsin, the mean price is almost similar for 3 states which makes the products more affordable for the California state population. Now let\u2019s see state wise sales for each product.", "Here, the Food 3 department with the lowest mean price had the highest sales. One more interesting thing to note here is despite, Hobbies 1 having the highest mean price and almost double when compared with Hobbies 2, the sales are high for Hobbies 1. HouseHold 1 sales are high. This may indicate that this product department holds the everyday essential items like soaps and detergents.", "As observed earlier California state is having more sales followed by Texas and Wisconsin. The expectation being the Food 1and Food 2 categories where Wisconsin sales are higher when compared with texas. So, it can be assumed Wisconsin state population had a liking towards Food 1 and Food 2 departments.", "We were able to prove a few thesis statements related to product price, location, and product category. Now, let\u2019s jump into Time series analysis to see how different weekdays, months, and events are affecting sales.", "The time series for all years is plotted to observe the seasonality trend for all 3 states for different departments.", "The seasonality trend follows the same pattern and is parallel for all 3 states. The highest Food being the department with the highest sales followed by Hobbies and Household. To better understand daily trends a heat map was plotted for the year 2015.", "It appears that Walmart is closed on Christmas. It can be seen that sales are very less on some days like New year and Thanksgiving days. This is due to reduced working hours on Festival days. Also, sales are relatively high on weekends in comparison to normal days.", "It is surprising to see the same trend across all 3 states for 5 years. It can be seen that total sales are increasing every year. This trend is due to the introduction of new products every year at Walmart. Also, the trend pattern for increase or decrease is almost similar for every year. To better understand the monthly trends all monthly sales are grouped for a year and the graph is plotted.", "It can be observed that the sales were increasing every year and are at a peak in March. After March, there is a decrease in sales till May and plummeted in June recording the lowest sales every year. After, June there is a gradual increase in sales for two months, before dropping further until November.", "As expected the total sales are more during Saturday and Sunday when compared to normal weekdays. Even here, the Wisconsin state is an exception where peak sales at observed on Saturday, whereas it is Sunday for Calfornia and Texas state. So, maybe the Wisconsin state population prefers to do grocery shopping on Saturday.", "To better observe trends for weekdays and month a heat map with total states for weekday vs month is plotted.", "There is an interesting pattern in this sales heatmap. It can be observed that there is a shift in more number of sales recorded every month. i.e., if the highest sales are recorded on Monday in February, we can see that in March there are more sales on Tuesday.", "The sales were highest on SuperBowl sporting events. On the day of the National holidays, sales were low. And sales were consistent on the day of the religious festivals. To observe the sales trend, the seasonality trend was plotted for the year 2015.", "This competition aims to predict sales for 28 days.", "Because of the lack of computation power, 10% of the data is selected using stratified sampling. Stratified random sampling accurately reflects the population being studied because it is stratifying the entire population before applying random sampling methods. In short, it ensures each subgroup within the population receives proper representation within the sample.", "Since the machine learning model, we are using is time-series having lag days and roll mean helps to improve the model so new lag variables are introduced for time-varifying effect variables 1 week,2 weeks,1 month, 2 months respectively. With better computation power 1 year also lag can be introduced since yearly sales patterns are similar. The rolling mean and rolling standard deviation were introduced for 1 week and 1-month lag variables.", "For people who don\u2019t know about lag, A lag is a fixed amount of passing time; One set of observations in a time series is plotted (lagged) against a second, later set of data. The kth lag is the period that happened \u201ck\u201d time points before time", "Since we need to forecast for 28 days, with 5 years of data. All the data with dates less than or equal to March 27th,2016 is considered as training data. And the 28 days data with dates greater than March 27th,2016, and less than April 24th, 2016 is taken as test data. The last 28 days are kept for validation.", "As many machine learning models can\u2019t read character type data, all the columns should be converted into the numeric format. I used a simple command in R", "Ensemble methods help improve machine learning results by combining multiple models. Using ensemble methods allows us to produce better predictions compared to a single model. Therefore, the ensemble methods placed first in many prestigious machine learning competitions, so different ensemble are compared using the sMAPE error rate.", "The sMAPE error rate is used because it is a prescribed evaluation metric in the M3 forecasting. The sMape error rate or symmetrical mean absolute percent error is listed as one of the significant, but uncommon forecast error measurements. However, its complexity in calculation and difficulty in explanation makes it a distant third to the fat more common MAD and MAPE forecast error calculations.", "The sMape error is calculated as follows", "For anyone who wants to learn more about the models used and the advantages of one model over others here is a link to a great article comparing Xgboost vs catboost vs Lightgbm.", "The Xgboost requires data in xgb.DMatrix format for prediction so both train and test sets are converted to xgb.Dmatrix matrix using the following command.", "The parameters chosen are for Xgboost are as follows", "Since our data contains a lot of zero values using objective as regression didn\u2019t give the expected results. After going through some research articles it is found that Tweedie is the best model for non-negative data with lots of zero\u2019s. So the Tweedie objective is used for training the model.", "Since the latest Xgboost version supports using GPU the model is trained using GPU. The RMSE evaluation metric was chosen for training the model. An early stopping round of 10 is given so if the model RMSE didn\u2019t improve for 10 iterations model will stop. And the best RMSE value will be returned.", "The best RMSE value was 2.48", "The 3 fold cross-validation was done to check model consistency. The best RMSE value returned for cross-validation was 2.637.", "A function was defined to calculate sMAPE value as follows:", "The catboost requires data in load_pool format for prediction so both train and test sets are converted to load_pool format using the following command.", "The parameters chosen are for Catboost are as follows", "The RMSE is used as a loss function and as an evaluation metric for training the model. The computation time with Kaggle GPU was around 5 mins for 1500 iterations. The early round is given as 100 rounds.", "The 3 fold cross-validation was performed to check model consistency. The best RMSE value returned for cross-validation was 2.39741.", "The value of sMAPE for Catboost is 1.34523, which seems to better than xgboost.", "The lighgbm requires data in lgb_dataset format for prediction so both train and test sets are converted to LGB.Dataset format using the following command.", "The parameters used are as follows", "The Tweedie is used as an objective function and RMSE as an evaluation metric for training the model.", "The 3 fold cross-validation was performed to check model consistency. The best RMSE value returned for cross-validation was 2.21.", "The value of sMAPE for the Lgboost model is 1.14, which is the best out of all 3 models.", "Based on the sMape error Lgb is the best model. Just for confirmation one standard error is applied with the cross-validated RMSE values of all 3 models.", "For those who don\u2019t know about one standard error rule, one standard error rule is used in cross-validation, in which we take the simplest model whose error is within one standard error of the best model (The model with Least error).", "Even here, the LGB is the best performing model with the lowest RMSE value. Since other model mean error points are not in the standard deviation range of the Lihtgbm model. According to one standard error rule, Lightgbm is chosen as the best model.", "The submission score with the best performing model is around 0.46.", "All plots are made using the ggplot2 package in R. Since the Code is very big. I am sharing my Kaggle Notebook for anyone who wants to use code for the competition.", "The sample dataset after stratified sampling looks like this", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write articles about easy ways to implement Data Science and Machine learning techniques in real world."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F24d7f42130de&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jaswanth-badvelu.medium.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": ""}, {"url": "https://jaswanth-badvelu.medium.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Jaswanth Badvelu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff209e223c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&user=Jaswanth+Badvelu&userId=f209e223c8&source=post_page-f209e223c8----24d7f42130de---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jamie452?utm_source=medium&utm_medium=referral", "anchor_text": "Jamie Street"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/m5-forecasting-accuracy", "anchor_text": "https://www.kaggle.com/c/m5-forecasting-accuracy"}, {"url": "https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db", "anchor_text": "link"}, {"url": "https://arxiv.org/pdf/1811.10192.pdf", "anchor_text": "articles"}, {"url": "https://www.kaggle.com/jaswanthhbadvelu/cat-xgb-lgboost-prophet", "anchor_text": "https://www.kaggle.com/jaswanthhbadvelu/cat-xgb-lgboost-prophet"}, {"url": "https://www.kaggle.com/c/m5-forecasting-accuracy/data", "anchor_text": "https://www.kaggle.com/c/m5-forecasting-accuracy/data"}, {"url": "https://medium.com/tag/timeseries-forecasting?source=post_page-----24d7f42130de---------------timeseries_forecasting-----------------", "anchor_text": "Timeseries Forecasting"}, {"url": "https://medium.com/tag/m5-forecasting?source=post_page-----24d7f42130de---------------m5_forecasting-----------------", "anchor_text": "M5 Forecasting"}, {"url": "https://medium.com/tag/data-science?source=post_page-----24d7f42130de---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----24d7f42130de---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&user=Jaswanth+Badvelu&userId=f209e223c8&source=-----24d7f42130de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&user=Jaswanth+Badvelu&userId=f209e223c8&source=-----24d7f42130de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F24d7f42130de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----24d7f42130de---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----24d7f42130de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----24d7f42130de--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----24d7f42130de--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----24d7f42130de--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----24d7f42130de--------------------------------", "anchor_text": ""}, {"url": "https://jaswanth-badvelu.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jaswanth-badvelu.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jaswanth Badvelu"}, {"url": "https://jaswanth-badvelu.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "97 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff209e223c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&user=Jaswanth+Badvelu&userId=f209e223c8&source=post_page-f209e223c8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F86e4a804601b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fm5-forecasting-accuracy-24d7f42130de&newsletterV3=f209e223c8&newsletterV3Id=86e4a804601b&user=Jaswanth+Badvelu&userId=f209e223c8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}