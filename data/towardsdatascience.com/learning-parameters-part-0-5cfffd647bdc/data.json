{"url": "https://towardsdatascience.com/learning-parameters-part-0-5cfffd647bdc", "time": 1682996212.7857542, "path": "towardsdatascience.com/learning-parameters-part-0-5cfffd647bdc/", "webpage": {"metadata": {"title": "Learning Parameters, Part 0: Basic Stuff | by Akshay L Chandra | Towards Data Science", "h1": "Learning Parameters, Part 0: Basic Stuff", "description": "This is an optional read for the 5 part series I wrote on learning parameters. In this post, you will find some basic stuff you\u2019d need to understand my other blog posts on how deep neural networks\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives#partial-derivative-and-gradient-articles", "anchor_text": "set of videos", "paragraph_index": 7}, {"url": "http://M.Sc", "anchor_text": "M.Sc", "paragraph_index": 23}], "all_paragraphs": ["This is an optional read for the 5 part series I wrote on learning parameters. In this post, you will find some basic stuff you\u2019d need to understand my other blog posts on how deep neural networks learn their parameters better. You can check out all the posts in the Learning Parameters series by clicking on the kicker tag at the top of this post.", "We will briefly look at the following topics:", "A multivariable function is just a function whose input and/or output is made up of multiple numbers/variables. E.g., f(x, y) = z= x\u00b2 + y\u00b2.", "Functions with multiple outputs are also called multivariable functions, but they are irrelevant here.", "The term \u201cgradient\u201d is just a fancy way of referring to derivatives of multivariable functions. While a derivative can be defined for functions of a single variable, for functions of several variables the gradient takes its place. The gradient is a vector-valued function while the derivative is scalar-valued.", "The derivative of a single variable function, denoted by f\u2019(x) or df/dx, tells us how much the function value changes with a unit change in the input. But if a function takes multiple inputs x and y, we need to know how much the value of the function changes with respect to x and y individually i.e., how much f(x,y) changes when x changes a teeny-tiny bit while keeping y constant and also how much it changes when y changes a teeny-tiny bit while keeping x constant. These are called partial derivatives of the function often denoted by \u2202f/\u2202x and \u2202f/\u2202y respectively and when you put these two innocent scalars in a vector, denoted by \u2207f, like the following, you get what we call the hero of calculus, the gradient!!", "There are many more properties but let us just focus on two necessary ones:", "The first property says that if you imagine standing at a point (x, y) in the input space of f, the vector \u2207f(x, y) tells you which direction you should travel to increase the value of f most rapidly. This obviously generalizes to N dims. When I first learned this in school, it was not at all obvious why this would be the case, but check out these set of videos on Khan Academy to know more about this.", "To understand the second property, we need to know what a derivate is, visually. The derivate of a line is the slope of the line, the derivative of a curve at any point is the slope of the tangent to that curve at that point.", "For functions of two variables (a surface), there are many lines tangent to the surface at a given point. If we have a nice enough function, all of these lines form a plane called the tangent plane to the surface at the point.", "I am sure you can convince yourself that this plane at the maximum of the surface, i.e., at the tip of the surface, will be parallel to the XY-plane Which suggests that the tangent\u2019s slope is 0 at maximum. If you can\u2019t, look at the following.", "Arguably, the value you\u2019d want to care about the most while training a neural network is the loss/cost. It measures how \u201cgood\u201d or \u201cbad\u201d your model is fitting the data. Any GD like algorithm\u2019s primary goal is to find the set of parameters that produce the least cost. All the drama around references like \u201cfinding the minimum,\u201d \u201cwalking on the error surface\u201d are just talking about adjusting the parameters in a way we end up with the least possible cost function value. You could think of a cost function as a multivariable function with model weights as the parameters. Try not to think beyond 2 parameters \u2014 you know why!", "There are many ways you can frame your loss function. Different types of problems (classification & regression) can have different types of loss functions framed that best represent the performance of the models, which is for another day, another post. For now, this intuition is good enough to understand the rest of the story. You can watch this video [6] by Siraj Raval to know more about loss functions.", "In figure 1, how many \u201cminimums\u201d do you see? I see just one. How nice! If your loss function looked like that, you could start your descent from anywhere on the graph (I mean, keep changing your parameters) with a reliable guide alongside (ahem Gradient Descent ahem), there is a good chance you\u2019d end up at that sweet dark green spot on the surface. Too bad, the error surfaces you\u2019d end up while optimizing even the smallest networks could be bumpier and in some sense, scarier.", "In many real-world cases, the minimum values you are going attain depend significantly on the point at which you start the descent. If you started your descent near a valley, the GD algorithm would most definitely force you to go into that valley (a local minimum), but the real minimum (global minimum) could be somewhere else on the surface.", "Take a look at the cost function of the two of the most popular neural networks, VGG-56 and VGG-110.", "Pause and ponder!! How can you possibly visualise a \u201cbig\u201d network\u2019s cost function in 3D? Big networks often have millions of parameters so how is this even possible? Read the paper linked in the references to find out.", "Visualizing things in 3-D can sometimes be a bit cumbersome, and contour maps come in as a handy alternative for representing functions with 2-D input and 1-D output. It is easier to explain it graphically than in text.", "Step 1: Start with the graph of the function.Step 2: Slice it up in regular intervals with planes parallel to the input plane at different heights.Step 3: Mark all the places on the graph the plane cuts through. Step 4: Project the markings on a 2-D plane, label the corresponding plane heights and map them accordingly.", "It is alright if you are still unable to comprehend the concept of contour maps completely. You can test your understanding by guessing the 3-D plots (without looking at the solution present on the right column of Figure 6) for the following contour maps.", "Please read this brilliant article [7] by Khan Academy to know more about Contour Maps.", "Check out the next post in this series at :", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "M.Sc. Student @ University of Freiburg"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5cfffd647bdc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@acl21?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Akshay L Chandra"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F202534492f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&user=Akshay+L+Chandra&userId=202534492f47&source=post_page-202534492f47----5cfffd647bdc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives#partial-derivative-and-gradient-articles", "anchor_text": "set of videos"}, {"url": "https://towardsdatascience.com/learning-parameters-part-1-eb3e8bb9ffbb", "anchor_text": "Learning Parameters, Part-1: Gradient Descent."}, {"url": "https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html", "anchor_text": "The hard thing about deep learning"}, {"url": "https://www.oreilly.com/people/4a99a-reza-zadeh", "anchor_text": "Reza Zadeh"}, {"url": "https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/", "anchor_text": "Intro to optimization in deep learning: Gradient Descent"}, {"url": "https://blog.paperspace.com/author/ayoosh/", "anchor_text": "Ayoosh Kathuria"}, {"url": "https://www.cs.umd.edu/~tomg/projects/landscapes/", "anchor_text": "Visualizing the Loss Landscape of Neural Nets"}, {"url": "http://ruder.io/optimizing-gradient-descent/index.html", "anchor_text": "An overview of gradient descent optimization algorithms"}, {"url": "http://ruder.io/", "anchor_text": "Sebastian Ruder"}, {"url": "https://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/tangent/tangent.html", "anchor_text": "Tangent Planes And Total Differentials"}, {"url": "https://www.youtube.com/watch?v=IVVVjBSk9N0", "anchor_text": "Loss Functions Explained"}, {"url": "https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/ways-to-represent-multivariable-functions/a/contour-maps", "anchor_text": "Contour Maps (article)"}, {"url": "https://www.cse.iitm.ac.in/~miteshk/CS7015.html", "anchor_text": "CS7015: Deep Learning, Indian Institute Of Technology"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5cfffd647bdc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/gradient-descent?source=post_page-----5cfffd647bdc---------------gradient_descent-----------------", "anchor_text": "Gradient Descent"}, {"url": "https://medium.com/tag/optimization?source=post_page-----5cfffd647bdc---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----5cfffd647bdc---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/learning-parameters?source=post_page-----5cfffd647bdc---------------learning_parameters-----------------", "anchor_text": "Learning Parameters"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&user=Akshay+L+Chandra&userId=202534492f47&source=-----5cfffd647bdc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&user=Akshay+L+Chandra&userId=202534492f47&source=-----5cfffd647bdc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5cfffd647bdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5cfffd647bdc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5cfffd647bdc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@acl21?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Akshay L Chandra"}, {"url": "https://medium.com/@acl21/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "http://M.Sc", "anchor_text": "M.Sc"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F202534492f47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&user=Akshay+L+Chandra&userId=202534492f47&source=post_page-202534492f47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4c4c11d45430&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearning-parameters-part-0-5cfffd647bdc&newsletterV3=202534492f47&newsletterV3Id=4c4c11d45430&user=Akshay+L+Chandra&userId=202534492f47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}