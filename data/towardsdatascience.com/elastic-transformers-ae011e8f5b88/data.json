{"url": "https://towardsdatascience.com/elastic-transformers-ae011e8f5b88", "time": 1683013510.965197, "path": "towardsdatascience.com/elastic-transformers-ae011e8f5b88/", "webpage": {"metadata": {"title": "Search (Pt 3) \u2014 Elastic Transformers | by Mihail Dungarov | Towards Data Science", "h1": "Search (Pt 3) \u2014 Elastic Transformers", "description": "This is a technical tutorial on how to set up and add semantic search via transformers as an Elasticsearch index. We go through all steps needed and will introduce the utility class\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github", "paragraph_index": 3}, {"url": "https://github.com/UKPLab/sentence-transformers", "anchor_text": "sentence-transformers", "paragraph_index": 4}, {"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github repo", "paragraph_index": 5}, {"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github repo", "paragraph_index": 8}, {"url": "https://elasticsearch-py.readthedocs.io/en/master/#", "anchor_text": "elasticsearch", "paragraph_index": 9}, {"url": "https://www.sbert.net/docs/pretrained_models.html#semantic-textual-similarity", "anchor_text": "sentence-transformers with distilbert", "paragraph_index": 13}, {"url": "https://github.com/cran/fastcluster", "anchor_text": "Faiss", "paragraph_index": 21}, {"url": "https://github.com/spotify/annoy", "anchor_text": "Annoy", "paragraph_index": 21}, {"url": "https://www.youtube.com/watch?v=SKrHs03i08Q", "anchor_text": "Billion-scale Approximate Nearest Neighbor Search.", "paragraph_index": 21}, {"url": "https://github.com/cran/fastcluster", "anchor_text": "fastcluster", "paragraph_index": 21}, {"url": "https://github.com/deepset-ai/haystack", "anchor_text": "Haystack", "paragraph_index": 22}, {"url": "https://arxiv.org/abs/2007.14062", "anchor_text": "BigBird", "paragraph_index": 24}, {"url": "https://www.linkedin.com/in/mihail-dungarov-cfa-a0291a88", "anchor_text": "LinkedIn", "paragraph_index": 27}], "all_paragraphs": ["This is a technical tutorial on how to set up and add semantic search via transformers as an Elasticsearch index. We go through all steps needed and will introduce the utility class ElasticTransformers. Finally we will consider some speed comparisons.", "This is the last part of a three part series about Search. For the non-technical discussions of how this fits into the wider topic of search consider the previous two parts.", "Already in part 1 we saw how Elasticsearch provides a wide range of search capabilities out of the box. In this article we will show how to add one more \u2014 contextual semantic search", "I will briefly outline the approach here. You can also follow on github.", "We will deploy locally Elasticsearch as a docker container. Data will be stored locally. Using Jupyter notebook, we will chunk the data and iteratively embed batches of records using the sentence-transformers library and commit to the index. Finally, we will also perform search out of the notebook. To enable, all of this, I prepared a utility class ElasticTransformers", "All of these steps are also documented in the github repo and performed as part of the notebooks included.", "Using those utilities, we sequentially: create an index, write several different sizes of the dataset to index with embeddings and perform some experiments", "Finally, all of these steps used to be complicated to perform. Thankfully, it\u2019s 2020 and a lot of this is simpler: we can deploy a Elasticsearch on Docker (since 2016 actually) with 2 lines of code, transformers come pre-trained with some cutting edge libraries and we can accomplish all of the above out of the comfort of our Jupyter notebook\u2026", "All of these steps are also documented in the github repo and performed as part of the notebooks included.", "ElasticTrasnformers builds on the elasticsearch library by simply wrapping some of the instantiation steps, adding simple utilities for index creation & mapping (something I personally always struggled with) and importantly an easy to use chunking tool for large documents that can write embeddings to the search index", "Initialize class as well as (optionally) the name of the index to work with", "Create specification for the index. Lists of relevant fields can be provided based on whether those would be needed for keyword search or semantic (dense vector) search. It also has parameters for the size of the dense vector as those can vary", "Create index \u2014 uses the spec created earlier to create an index ready for search", "Write to large files \u2014 breaks up a large csv file into chunks and iteratively uses a predefined embedding utility to create the embeddings list for each chunk and subsequently feed results to the index. In the notebooks, we show an example of how to create the embed_wrapper, notice that the actual embedder can therefore be any function. We use sentence-transformers with distilbert because it provides a nice balance between speed and performance. However, this can vary for the use case you are interested in.", "Search \u2014 can select either keyword (\u2018match\u2019 in Elastic) or contextual (\u2018dense\u2019 in Elastic) search. Note, it requires the same embedding function used in write_large_csv. This only checks if type = \u2018dense\u2019 to treat is as embedding search otherwise can take the common: \u2018match\u2019, \u2018wildcard\u2019, \u2018fuzzy\u2019, etc.", "We will index data from A Million News Headlines in several different index sizes (tiny: 1k, medium: 100k and large: 1.1million (all) headlines). Finally, we will use those to perform some speed comparisons.", "We just indexed about 1.1 million sentences, but does all this actually scale? Naturally, there will always be a slowdown when scanning a massive index, but how much?", "I performed several tests (each with 10 repetitions):", "Results are in the below charts:", "Notably, the common requirement on interactive search applications is for results to be retrieved in under 1sec, in some cases under 300ms, hence this is a significant slowdown. Some solutions are explored below", "Speed of search is a crucial aspect as search often needs to be interactive and document size will often be significant. In this case, we can see that there is an exponential slow down with size of the dataset. This is due to the fact that we are comparing all documents against the query, vs using an inverted index in the keyword search approach. A number of ways exist to fix this but unfortunately they come with trade-offs with respect to accuracy.", "For instance, Approximate nearest neighbour (ANN) approaches would use less space and perform faster at the cost of sometimes returning results which are not exactly the most relevant \u2014 for implementations check out Faiss or Annoy as well as this great example on mixing embeddings, keyword search and using Faiss. A great talk about different trade off of ANN at scale and how to choose one \u2014 Billion-scale Approximate Nearest Neighbor Search. Another approach might be to perform agglomerative clustering and collect the relevant number of results at retrieval time only. Check out fastcluster for an implementation.", "Haystack provides an extensive framework for combining transformers with search. However, queries are considered as natural language questions and a QA answering framework is employed. The difference is that, in QA framework the quality of the match between a query and each individual candidate document is evaluated as a pair. This is in itself a significantly more computationally expensive problem, as opposed to what we are doing here where each document is represented by an embedding which is compared to the query at runtime. The bigger computational load is dealt with initially reducing the search space to a smaller number of relevant candidates.", "The contextual solution we have seen is limited by the document size too - constrained by the token limitations of the transformers models. In this case, we can fit up to 512 tokens (word-like chunks, e.g. the word look is one token, looking is two tokens \u2014 look & ing, etc.). Such a constraint works well with a headline or even a paragraph but not full sized documents, e.g. news article body, research papers, etc.", "These models can be extended to take in longer sequences however they grow quadratically in memory usage with the increase of length. Common solutions tend to keep the standard length, but use workarounds, e.g. some averaging of embeddings where relevant. This is still an active area of research with one notable recent addition being BigBird \u2014 a Google Research transformer based model which can handle longer sequences while keeping memory usage growth linear to the size of the document", "We have seen how to easily deploy an Elasticsearch container and index it with some of the most powerful contextual embeddings available to us. Evaluation showed that semantic search might slow down for large indices and, however, we have also considered some alternative solutions to this.", "The future of this field remains very hopeful and increasingly accessible.", "Hopefully, this was useful. Thank you for reading. If you feel like saying Hi or just like to tell me I am wrong, feel free to reach out via LinkedIn", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fae011e8f5b88&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mihail.dungarov?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mihail.dungarov?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Mihail Dungarov"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff882548c947b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&user=Mihail+Dungarov&userId=f882548c947b&source=post_page-f882548c947b----ae011e8f5b88---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/search-pt-1-a-gentle-introduction-335656c0f814", "anchor_text": "Pt 1"}, {"url": "https://medium.com/@mihail.dungarov/search-pt-2-semantic-horse-race-5128cae7ce8d", "anchor_text": "Pt 2"}, {"url": "https://gifox.io/", "anchor_text": "gifox"}, {"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github"}, {"url": "https://github.com/UKPLab/sentence-transformers", "anchor_text": "sentence-transformers"}, {"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github repo"}, {"url": "https://www.kaggle.com/therohk/million-headlines", "anchor_text": "A Million News Headlines"}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html", "anchor_text": "here"}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_pulling_the_image", "anchor_text": "Pulling the image"}, {"url": "https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-dev-mode", "anchor_text": "Starting a single node cluster with Docker"}, {"url": "https://www.elastic.co/blog/text-similarity-search-with-vectors-in-elasticsearch", "anchor_text": "these excellent resources"}, {"url": "https://github.com/UKPLab/sentence-transformers", "anchor_text": "sentence-transformers"}, {"url": "https://github.com/md-experiments/elastic_transformers", "anchor_text": "github repo"}, {"url": "https://elasticsearch-py.readthedocs.io/en/master/#", "anchor_text": "elasticsearch"}, {"url": "https://www.sbert.net/docs/pretrained_models.html#semantic-textual-similarity", "anchor_text": "sentence-transformers with distilbert"}, {"url": "https://github.com/cran/fastcluster", "anchor_text": "Faiss"}, {"url": "https://github.com/spotify/annoy", "anchor_text": "Annoy"}, {"url": "https://www.youtube.com/watch?v=SKrHs03i08Q", "anchor_text": "Billion-scale Approximate Nearest Neighbor Search."}, {"url": "https://github.com/cran/fastcluster", "anchor_text": "fastcluster"}, {"url": "https://github.com/deepset-ai/haystack", "anchor_text": "Haystack"}, {"url": "https://arxiv.org/abs/2007.14062", "anchor_text": "BigBird"}, {"url": "https://www.linkedin.com/in/mihail-dungarov-cfa-a0291a88", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ae011e8f5b88---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----ae011e8f5b88---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/transformers?source=post_page-----ae011e8f5b88---------------transformers-----------------", "anchor_text": "Transformers"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----ae011e8f5b88---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/elasticsearch?source=post_page-----ae011e8f5b88---------------elasticsearch-----------------", "anchor_text": "Elasticsearch"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&user=Mihail+Dungarov&userId=f882548c947b&source=-----ae011e8f5b88---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&user=Mihail+Dungarov&userId=f882548c947b&source=-----ae011e8f5b88---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fae011e8f5b88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ae011e8f5b88---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ae011e8f5b88--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mihail.dungarov?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mihail.dungarov?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mihail Dungarov"}, {"url": "https://medium.com/@mihail.dungarov/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "90 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff882548c947b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&user=Mihail+Dungarov&userId=f882548c947b&source=post_page-f882548c947b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ff882548c947b%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Felastic-transformers-ae011e8f5b88&user=Mihail+Dungarov&userId=f882548c947b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}