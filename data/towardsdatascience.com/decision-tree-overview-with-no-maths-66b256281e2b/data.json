{"url": "https://towardsdatascience.com/decision-tree-overview-with-no-maths-66b256281e2b", "time": 1683000251.4693089, "path": "towardsdatascience.com/decision-tree-overview-with-no-maths-66b256281e2b/", "webpage": {"metadata": {"title": "Decision tree: Part 1/2. Develop intuition about the Decision\u2026 | by Azika Amelia | Towards Data Science", "h1": "Decision tree: Part 1/2", "description": "Invented about 70 years ago, a decision tree is one of the oldest Machine Learning algorithms used today for predictive modeling. They may be one of the simplest ML algorithms to understand but don\u2019t\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=o6b9JpBFjd4", "anchor_text": "powerful", "paragraph_index": 2}, {"url": "https://medium.com/@azika/decision-tree-part-2-34b31b1dc328?sk=3ce477bb2ee7001988eee05239313008", "anchor_text": "part 2", "paragraph_index": 24}, {"url": "https://www.linkedin.com/in/azika-amelia/", "anchor_text": "Linkedin", "paragraph_index": 26}], "all_paragraphs": ["Invented about 70 years ago, a decision tree is one of the oldest Machine Learning algorithms used today for predictive modeling. They may be one of the simplest ML algorithms to understand but don\u2019t let its simplicity fool you into underestimating its capabilities.", "This article aims to build an intuition about Decision trees. We\u2019ll talk about linearly separable and inseparable datasets, decision boundaries, and regions, explain why the decision boundaries are parallel to the axis, and point out the pros and problems (along with a remedy) of using a decision tree.", "Decision Trees are among the simplest algorithm to understand, and you can easily explain their reasoning since they are among the \u201cwhite box\u201d methods. They are powerful enough to fit complex datasets, and versatile enough that they can be used for classification as well as regression tasks without needing much data pre-processing.", "Moreover, decision trees are the building blocks of the widely used \u201cRandom Forest\u201d method which is among the most powerful Machine Learning algorithms available today.", "Decision trees can, unlike linear models, fit linearly inseparable datasets. An inseparable dataset is one where data points of different classes cannot be separated by a single line, as opposed to linearly separable where a single line is enough. These are depicted in the diagram below:", "In figure 1 the graph on the left shows how a linear classifier would make its decision boundary \u2014 the dotted line. The one on the right represents how a decision tree constructs its decision boundaries to fit the linearly inseparable dataset.", "You might notice that the decision boundaries made by a decision tree are parallel to the axis, and that\u2019s how they always are: Parallel to the axis. The reason for this is that a Decision tree splits the data based on a feature value and this value would remain constant throughout for one decision boundary e.g., x=2 or y=3 where x and y are two different features. Whereas in a linear classifier, a decision boundary could be for instance: y=mx+c.", "In decision trees, these decision boundaries are drawn iteratively for every decision region and a tree is built. For a visual explanation, follow through the series of graphs coming down your way! \ud83d\udc47", "Let\u2019s look at an example below and see how this happens with just using our human instincts and no maths!", "The first node of the tree called the \u201croot node\u201d contains the number of instances of all the classes respectively.", "Basically, we have to draw a line called \u201cdecision boundary\u201d that separates the instances of different classes into different regions called \u201cdecision regions\u201d. Remember, that this line needs to be axis parallel.", "The first decision boundary should be made at X=3 for the graph above.", "Taking X=3 as our split point, a graph shown below is yielded. Since now that we have two decision regions, we\u2019ll add both regions as two different nodes of the tree where each node contains the number of respective instances.", "Since a decision region should contain a significant majority of one class over the rest, we need to split these further. We\u2019ll split the left region of the resultant graph at Y=2. Followed by Y=2.5 in the right region.", "Now every decision region contains only the instances of one class and that\u2019s our cue to stop splitting (since we haven\u2019t defined any other stopping criterion).", "\u26a0\ufe0f Beware though, not setting other stopping criteria can be harmful for you model. (Elaborated below)", "It is important to note here that splitting till the last instance, as we did above, is not the only criterion where you\u2019d stop splitting. In fact, this would probably lead to an over-fitted model.", "Over-fitted model: A model learns the data so well that it cannot generalize well on unseen data.", "\ud83d\udca1 Fix: Some of the other conditions for stopping can be the depth of the tree, the minimum number of instances a node must have before it can be split further, or the ratio between the majority or minority class e.g. if 80% of the data-points belong to one class then stop splitting to avoid over-fitting.", "Since decision trees make axis parallel boundaries they are sensitive to data rotation. Take a look at the diagram below. Data that could easily be split by a single diagonal is split by multiple decision boundaries, we can almost tell by just looking that the simpler model would generalize better for this particular problem.", "\ud83d\udca1 Fix: This problem can be limited by using dimensionality reduction techniques like PCA which orients the data better.", "\ud83d\udca1 Fix: In general, Decision trees are sensitive to small data variations and can result in different tree structures. The robustness of decision trees can be enhanced by using lots of them together and averaging their predicted value and use that as the final prediction. Such a classifier is called Random Forest.", "The pros still outweigh the cons, and with some hyperparameter tuning, decision trees can perform really well.", "Of all the data-science-related interviews I\u2019ve ever given, I am always asked to explain the decision tree algorithm, literally every.single.time! So, I decided to write an article focusing on the aspect of the trees that generally isn\u2019t given much attention.", "If you want to know more about decision trees and the maths behind them, you can check out part 2 of this series. There we\u2019ll talk about entropy and information gain for finding the best split and the maths behind it. As for this post, that\u2019s all folks!", "If you found this article helpful please give it a clap \ud83d\udc4f Clapping makes a post accessible to more people. \ud83d\udc26", "If you have any questions or suggestions, feel free to post it down below. You may also connect with me on Linkedin. \ud83d\udcbc", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A Data Science enthusiast and a rookie guitarist."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F66b256281e2b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----66b256281e2b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@azika?source=post_page-----66b256281e2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@azika?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Azika Amelia"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F50e1cd76b649&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&user=Azika+Amelia&userId=50e1cd76b649&source=post_page-50e1cd76b649----66b256281e2b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@subtlecinematics?utm_source=medium&utm_medium=referral", "anchor_text": "Subtle Cinematics"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@vimarovi?utm_source=medium&utm_medium=referral", "anchor_text": "Victor Rodriguez"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.youtube.com/watch?v=o6b9JpBFjd4", "anchor_text": "powerful"}, {"url": "https://unsplash.com/@abbysavagecreative?utm_source=medium&utm_medium=referral", "anchor_text": "Abby Savage"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@timcollinsphoto?utm_source=medium&utm_medium=referral", "anchor_text": "Tim Collins"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@calypso999?utm_source=medium&utm_medium=referral", "anchor_text": "Raul Varzar"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@azika/decision-tree-part-2-34b31b1dc328?sk=3ce477bb2ee7001988eee05239313008", "anchor_text": "part 2"}, {"url": "https://www.linkedin.com/in/azika-amelia/", "anchor_text": "Linkedin"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----66b256281e2b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----66b256281e2b---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/decision-boundary?source=post_page-----66b256281e2b---------------decision_boundary-----------------", "anchor_text": "Decision Boundary"}, {"url": "https://medium.com/tag/decision-region?source=post_page-----66b256281e2b---------------decision_region-----------------", "anchor_text": "Decision Region"}, {"url": "https://medium.com/tag/linearly-inseparable?source=post_page-----66b256281e2b---------------linearly_inseparable-----------------", "anchor_text": "Linearly Inseparable"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&user=Azika+Amelia&userId=50e1cd76b649&source=-----66b256281e2b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&user=Azika+Amelia&userId=50e1cd76b649&source=-----66b256281e2b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F66b256281e2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----66b256281e2b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----66b256281e2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----66b256281e2b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----66b256281e2b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----66b256281e2b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----66b256281e2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@azika?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@azika?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Azika Amelia"}, {"url": "https://medium.com/@azika/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "268 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F50e1cd76b649&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&user=Azika+Amelia&userId=50e1cd76b649&source=post_page-50e1cd76b649--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb367f81591c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecision-tree-overview-with-no-maths-66b256281e2b&newsletterV3=50e1cd76b649&newsletterV3Id=b367f81591c3&user=Azika+Amelia&userId=50e1cd76b649&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}