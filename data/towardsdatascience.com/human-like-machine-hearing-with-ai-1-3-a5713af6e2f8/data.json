{"url": "https://towardsdatascience.com/human-like-machine-hearing-with-ai-1-3-a5713af6e2f8", "time": 1682988316.5343769, "path": "towardsdatascience.com/human-like-machine-hearing-with-ai-1-3-a5713af6e2f8/", "webpage": {"metadata": {"title": "Human-Like Machine Hearing With AI (1/3) | by Daniel Rothmann | Towards Data Science", "h1": "Human-Like Machine Hearing With AI (1/3)", "description": "In this article series, I will detail a framework for real-time audio signal processing with AI which was inspired by human neurobiology."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/the-promise-of-ai-in-audio-processing-a7e4996eb2ca", "anchor_text": "The promise of AI in audio processing", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd", "anchor_text": "What\u2019s wrong with CNNs and spectrograms for audio processing?", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/human-like-machine-hearing-with-ai-2-3-f9fab903b20a", "anchor_text": "Human-Like Machine Hearing With AI (2/3)", "paragraph_index": 2}, {"url": "https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/", "anchor_text": "the inspiration from the complex and more spatially invariant cells of the visual system in CNNs", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd", "anchor_text": "\u201cWhat\u2019s wrong with CNNs and spectrograms for audio processing?\u201d", "paragraph_index": 3}, {"url": "http://www.au.dk/en/", "anchor_text": "Aarhus University", "paragraph_index": 5}, {"url": "https://www.dynaudio.com/", "anchor_text": "Dynaudio A/S", "paragraph_index": 5}, {"url": "https://github.com/detly/gammatone", "anchor_text": "Gammatone Filterbank Toolkit by Jason Heeris", "paragraph_index": 16}, {"url": "https://deeplearning4j.org/deepautoencoder", "anchor_text": "autoencoder NN architecture", "paragraph_index": 22}, {"url": "https://www.tensorflow.org/tutorials/word2vec", "anchor_text": "word embeddings", "paragraph_index": 22}], "all_paragraphs": ["Significant breakthroughs in AI technology have been achieved through modeling human systems. While artificial neural networks (NNs) are mathematical models which are only loosely coupled with the way actual human neurons function, their application in solving complex and ambiguous real-world problems has been profound. Additionally, modeling the architectural depth of the brain in NNs has opened up broad possibilities in learning more meaningful representations of data.", "If you\u2019ve missed out on the other articles, click below to get up to speed:", "Background: The promise of AI in audio processingCriticism: What\u2019s wrong with CNNs and spectrograms for audio processing?Part 2: Human-Like Machine Hearing With AI (2/3)", "In image recognition and processing, the inspiration from the complex and more spatially invariant cells of the visual system in CNNs has also produced great improvements to our technologies. If you\u2019re interested in applying image recognition technologies on audio spectrograms, check out my article \u201cWhat\u2019s wrong with CNNs and spectrograms for audio processing?\u201d.", "As long as human perceptual capacity exceeds that of machines, we stand to gain by understanding the principles of human systems. Humans are very skillful when it comes to perceptual tasks and the contrast between human understanding and the status quo of AI becomes particularly apparent in the area of machine hearing. Considering the benefits reaped from getting inspired by human systems in visual processing, I propose that we stand to gain from a similar process in machine hearing with neural networks.", "In this article series, I will detail a framework for real-time audio signal processing with AI which was developed in cooperation with Aarhus University and intelligent loudspeaker manufacturer Dynaudio A/S. Its inspiration is primarily drawn from cognitive science which attempts to combine perspectives of biology, neuroscience, psychology and philosophy to gain greater understanding of our cognitive faculties.", "Perhaps the most abstract domain of sound is how we, as humans, perceive it. While a solution for a signal processing problem has to operate within the parameters of intensity, spectral and temporal properties on a low level, the end goal is most often a cognitive one: Transforming a signal in such a way that our perceptions of the sounds it contains are altered.", "If one wishes to programatically change the gender of a recorded spoken voice for example, it is necessary to describe this problem in more meaningful terms before defining its lower level characteristics. The gender of a speaker can be conceived as a cognitive property which is constructed from many factors: General pitch and timbre of a voice, differences in pronunciation, differences in choice of words and language and a common understanding of how these properties relate to gender.", "These parameters can be described in lower level features like intensity, spectral and temporal properties but only in more complex combinations do they form high-level representations. This forms a hierarchy of audio features from which the \u201cmeaning\u201d of a sound can be derived. The cognitive property representing a human voice can be thought of as a combinatory pattern of temporal developments in a sound\u2019s intensity, spectral and statistical properties.", "NNs are great at extracting abstracted representations of data and are therefore well suited for the task of detecting cognitive properties in sound. In order to build a system for this purpose, let\u2019s examine how sound is represented in human auditory organs that we can use to inspire representation of sound for processing with NNs.", "Hearing in humans starts at the outer ear which firstly consists of the pinna. The pinna acts as a form of spectral preprocessing in which the incoming sound is modified depending on its direction in relation to the listener. Sound then travels through the opening in the pinna into the ear canal which further acts to modify spectral properties of incoming sound by resonating in a way that amplifies frequencies in the range ~1\u20136 kHz [1].", "As sound waves reach the end of the ear canal, they excite the eardrum onto which the ossicles (the smallest bones in the body) are attached. These bones transmit the pressure from the ear canal to the fluid-filled cochlea in the inner ear [1]. The cochlea is of great interest in guiding sound representation for NNs because this is the organ responsible for transducing acoustic vibrations into neural activity in humans .", "It is a coiled tube which is separated along its length by two membranes being the Reissner\u2019s membrane and the basilar membrane. Along the length of the cochlea, there is a row of around 3,500 inner hair cells [1]. As pressures enter the cochlea, its two membranes are pushed down. The basilar membrane is narrow and stiff at its base but loose and wide at its apex so that each place along its length responds more intensely at a particular frequency.", "To simplify, the basilar membrane can be thought of as a continuous array of bandpass filters which, along the length of the membrane, acts to separate sounds into their spectral components.", "This is the primary mechanism by which humans convert sound pressures into neural activity. Therefore, it is reasonable to assume that spectral representations of audio would be beneficial in modeling sound perception with AI. Since frequency responses along the basilar membrane vary exponentially [2], logarithmic frequency representations might prove most efficient. One such representation could be derived using a gammatone filterbank. These filters are commonly applied in modeling spectral filtering in the auditory system since they approximate the impulse response of human auditory filters derived from the measured auditory nerve fiber response to white noise stimuli called the \u201crevcor\u201d function [3].", "Since the cochlea has ~3500 inner hair cells and humans can detect gaps in sounds down to ~2\u20135 ms in length [1], a spectral resolution of 3500 gammatone filters separated into 2 ms windows seem optimal parameters for achieving human-like spectral representation in machines. In practical scenarios however, I assume that lesser resolutions could still achieve desirable effects in most analysis and processing tasks while being more viable from a computational standpoint.", "A number of software libraries for auditory analysis are available online. A notable example is the Gammatone Filterbank Toolkit by Jason Heeris. It provides adjustable filters as well as tools for spectrogram-like analysis of audio signals with gammatone filters.", "As neural activity moves from the cochlea onto the auditory nerve and the ascending auditory pathways, a number of processes are applied in brainstem nuclei before it reaches the auditory cortex.", "These processes form a neural code which represents an interface between stimulus and perception [4]. Much knowledge about the specific inner workings of these nuclei is still speculative or unknown, so I will detail these nuclei only at their higher levels of functioning.", "Humans have a set of these nuclei for each ear that are interconnected, but for simplicity, I\u2019ve illustrated the flow for only one ear. The cochlear nucleus is the first coding step for neural signals coming from the auditory nerve. It consists of a variety of neurons with different properties which serve to perform initial processing of sound features, some of which are directed to the superior olive which is associated with sound localization while others are directed to the lateral lemniscus and inferior colliculus, commonly associated with more advanced features [1].", "J. J. Eggermont details this flow of information from the cochlear nucleus in \u201cBetween sound and perception: reviewing the search for a neural code\u201d as follows: \u201cThe ventral [cochlear nucleus] (VCN) extracts and enhances the frequency and timing information that is multiplexed in the firing patterns of the [auditory nerve] fibers, and distributes the results via two main pathways: the sound localization path and the sound identification path. The anterior part of the VCN (AVCN) mainly serves the sound localization aspects and its two types of bushy cells provide input to the superior olivary complex (SOC), where interaural time differences (ITDs) and level differences (ILDs) are mapped for each frequency separately\u201d [4].", "The information carried by the sound identification pathway is a representation of complex spectra such as vowels. This representation is mainly created in the ventral cochlear nucleus by special types of units dubbed \u201cchopper\u201d (stellate) neurons [4]. The details of these auditory encodings are difficult to specify but they indicate to us that a form of \u201ccoding\u201d of incoming frequency spectra could improve understanding of low level sound features as well as making sound impressions less expensive to process in NNs.", "We can apply the unsupervised autoencoder NN architecture as an attempt to learn common properties associated with complex spectra. Like word embeddings, its possible to find commonalities in frequency spectra that represent select features (or a more tightly condensed meaning) of sounds.", "An autoencoder is trained to encode an input into a compressed representation that can be reconstructed back into a representation with a high similarity to the input. This means that the autoencoder\u2019s target output is the input itself [5]. If an input can be reconstructed without great loss, the network has learnt to encode it in such a way that the compressed internal representation contains enough meaningful information. This internal representation is then what we refer to as the embedding. The encoding part of the autoencoder can be decoupled from the decoder to generate embeddings for other applications.", "Embeddings also have the benefit that they are often of lower dimensionality than the original data. For instance, an autoencoder could compress a frequency spectrum with a total of 3500 values into a vector with a length of 500 values. Put simply, each value of such a vector could describe higher level factors of a spectrum such as vowel, harshness or harmonicity - These are only examples, as the meaning of statistically common factors derived by an autoencoder might often be difficult to label in plain language.", "In the next article, we will expand upon this idea with added memory to produce embeddings for temporal developments of audio frequency spectra.", "This wraps up the first part of my article series on audio processing with artificial intelligence. Next, we will discuss the essential concepts of sensory memory and temporal dependencies in sound.", "Follow to stay updated and feel free to leave claps if you enjoyed the article!", "[3] A.M. Darling, \u201cProperties and implementation of the gammatone filter: A tutorial\u201d, Speech hearing and language, University College London, 1991.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa5713af6e2f8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@danielrothmann?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Daniel Rothmann"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc078747a2b73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&user=Daniel+Rothmann&userId=c078747a2b73&source=post_page-c078747a2b73----a5713af6e2f8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.flickr.com/photos/jonathangrossphotography/", "anchor_text": "Jonathan Gross"}, {"url": "https://towardsdatascience.com/the-promise-of-ai-in-audio-processing-a7e4996eb2ca", "anchor_text": "The promise of AI in audio processing"}, {"url": "https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd", "anchor_text": "What\u2019s wrong with CNNs and spectrograms for audio processing?"}, {"url": "https://towardsdatascience.com/human-like-machine-hearing-with-ai-2-3-f9fab903b20a", "anchor_text": "Human-Like Machine Hearing With AI (2/3)"}, {"url": "https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/", "anchor_text": "the inspiration from the complex and more spatially invariant cells of the visual system in CNNs"}, {"url": "https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd", "anchor_text": "\u201cWhat\u2019s wrong with CNNs and spectrograms for audio processing?\u201d"}, {"url": "http://www.au.dk/en/", "anchor_text": "Aarhus University"}, {"url": "https://www.dynaudio.com/", "anchor_text": "Dynaudio A/S"}, {"url": "https://github.com/detly/gammatone", "anchor_text": "Gammatone Filterbank Toolkit by Jason Heeris"}, {"url": "https://deeplearning4j.org/deepautoencoder", "anchor_text": "autoencoder NN architecture"}, {"url": "https://www.tensorflow.org/tutorials/word2vec", "anchor_text": "word embeddings"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a5713af6e2f8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----a5713af6e2f8---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----a5713af6e2f8---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/audio?source=post_page-----a5713af6e2f8---------------audio-----------------", "anchor_text": "Audio"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----a5713af6e2f8---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&user=Daniel+Rothmann&userId=c078747a2b73&source=-----a5713af6e2f8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&user=Daniel+Rothmann&userId=c078747a2b73&source=-----a5713af6e2f8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa5713af6e2f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a5713af6e2f8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a5713af6e2f8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@danielrothmann?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Daniel Rothmann"}, {"url": "https://medium.com/@danielrothmann/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc078747a2b73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&user=Daniel+Rothmann&userId=c078747a2b73&source=post_page-c078747a2b73--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F385004d73127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhuman-like-machine-hearing-with-ai-1-3-a5713af6e2f8&newsletterV3=c078747a2b73&newsletterV3Id=385004d73127&user=Daniel+Rothmann&userId=c078747a2b73&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}