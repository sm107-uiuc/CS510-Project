{"url": "https://towardsdatascience.com/transforming-text-files-to-data-tables-with-python-553def411855", "time": 1683007910.046344, "path": "towardsdatascience.com/transforming-text-files-to-data-tables-with-python-553def411855/", "webpage": {"metadata": {"title": "Transforming Text Files to Data Tables with Python | by Sebastian Guggisberg | Towards Data Science", "h1": "Transforming Text Files to Data Tables with Python", "description": "In this article, I describe how to transform a set of text files into a data table which can be used for natural language processing and machine learning. To showcase my approach I use the raw BBC\u2026"}, "outgoing_paragraph_urls": [{"url": "http://mlg.ucd.ie/datasets/bbc.html", "anchor_text": "dataset", "paragraph_index": 0}, {"url": "http://mlg.ucd.ie/datasets/bbc.html", "anchor_text": "BBC news dataset", "paragraph_index": 6}, {"url": "https://github.com/guggio/bbc_news/tree/master/article_to_csv", "anchor_text": "repository", "paragraph_index": 23}], "all_paragraphs": ["In this article, I describe how to transform a set of text files into a data table which can be used for natural language processing and machine learning. To showcase my approach I use the raw BBC News Article dataset published by D. Greene and P. Cunningham in 2006.", "Before jumping into the IDE and start coding, I usually follow a process consisting of understanding the data, defining an output, and translating everything into code. I consider the tasks before coding usually as the most important since they help to structure and follow the coding process more efficiently.", "Before being able to extract any information from a text file, we want to know how its information is structured as well as how and where the text files are stored (e.g. name, directory).", "To understand the structure, we take a look at some of the text file to get a sense of how the data is structured.", "In the context of news articles, it can be easily assumed that the first and second section correspond to the title and the subtitle respectively. The following paragraphs represent the article\u2019s text. Looking at the sample data, we also recognise that the segments are separated by new lines which can be used for splitting the text.", "To write a script that automatically runs through every text file, we need to know how the text files are stored. Thus, we are interested in the naming and organisation of the directories. Potentially, we need to restructure things, so we can loop more easily through the files.", "Luckily for us, the BBC news dataset is already well structured for automating the information extraction. As it can be seen in the screenshots above, the text files are stored in directories according to their genre. The names are also similar for every genre and are made up by leading zeros (if the file number is below 100), the file number, and \u201c.txt\u201d.", "Based on the insights of the data understanding step, we can define what information should be included in the output. In order to determine the output, we have to consider the learnings of the previous step as well as think about potential use cases for the output.", "Based on the information we can potentially extract from the text files, I come up with two different use cases for machine learning training:", "In order to fulfil the requirements for both potential use cases, I would suggest extracting the following information.", "I would also include the length of the text (in number of tokens), to make it easier to filter for shorter or longer texts later on. To store the extracted data, I would suggest a tab-separated-values (.tsv) file, since commas or semicolons could be present in the text column.", "Thanks to the previous steps, we know the data we are dealing with and what kind of information we want to output at the end of the transformation process. As you might know by now, I like to break tasks into smaller parts. The coding step doesn\u2019t constitute an exception to this :) Generally, I would split the coding into at least three different parts and wrap them in individual functions:", "In order to make this news article extractor reusable, I create a new class that implements the functions.", "In order to read a file with python, we need the corresponding path consisting of the directory and the filename. As we observed in the Data Understanding step, the files are stored in their corresponding genre\u2019s directory. This means that to access a file, we need the base path (\u2018data\u2019 for me), its genre and its name.", "If the file exists, we want to read it, split it by the new line characters (\u2018\\n\u2019), filter empty strings and return the remaining text sections as a list. In the case, that the file doesn\u2019t exist (e.g. the file number is larger than the number of available files), we want to return an empty list. I prefer this rather than working with exceptions or returning none, if the file doesn\u2019t exist.", "As you can see in the code above, uses the os package. Thus, we need to import this package.", "In order to extract the information of the text files and prepare these for the next step, I would suggest pursuing this for every genre. This means, that we loop over every file in the corresponding genre\u2019s directory. By keeping a current_number variable, we can format the filename with the leading zeros and then read and split the file by calling the above-implemented method.", "If the returned list is empty, we want to stop the loop, since this means, that we reached the end of the loop and that there aren\u2019t any new files left in the directory.", "Otherwise, we add the returned information of the reading and splitting function to specific data containers, such as titles, subtitles, and texts. Since I suggested to also provide the token count of the text in the final output, we can use the nltk package to tokenize the text and add the length of the list of tokens to our token_counts list. Finally, we increment the current_number by 1 to continue the extraction process with the next file.", "After finishing the loop through the genre files, we create a data frame based on the extracted information that was stored inside the specific lists. Similar to the previous step, we need to import two packages (nltk and pandas). Please also make sure, that you have downloaded the \u2018punkt\u2019 data of the nltk package, since it is required to tokenize texts.", "In a final step, we have to create a loop over the existing genres, extract the information per genre by calling the above-implemented method, concatenating the output for every genre and finally saving the concatenated data frame as a csv with the desired separator.", "After implementing the class and its method, we need to create an instance of the ArticleCSVParser class and call the transform_texts_to_df method by providing the desired name for the resulting csv and a list containing every genre. Et voil\u00e0.", "In this article, I showed how to transform text files into a data frame and save it as a csv/tsv. In order to reuse the class for a different data set, just create a new class that inherits from the ArticleCSVParser and override the methods that have to be changed.", "You can find the complete code and dataset also in this repository.", "I hope you enjoyed and happy coding!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software engineer with business degree, rock climber and lifelong learner from Switzerland."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F553def411855&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----553def411855--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----553def411855--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://sebastian-guggisberg.medium.com/?source=post_page-----553def411855--------------------------------", "anchor_text": ""}, {"url": "https://sebastian-guggisberg.medium.com/?source=post_page-----553def411855--------------------------------", "anchor_text": "Sebastian Guggisberg"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F673026f7b16a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&user=Sebastian+Guggisberg&userId=673026f7b16a&source=post_page-673026f7b16a----553def411855---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@qwitka?utm_source=medium&utm_medium=referral", "anchor_text": "Maksym Kaharlytskyi"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://mlg.ucd.ie/datasets/bbc.html", "anchor_text": "dataset"}, {"url": "http://mlg.ucd.ie/datasets/bbc.html", "anchor_text": "BBC news dataset"}, {"url": "https://github.com/guggio/bbc_news/tree/master/article_to_csv", "anchor_text": "repository"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----553def411855---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/data-science?source=post_page-----553def411855---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----553def411855---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----553def411855---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/database?source=post_page-----553def411855---------------database-----------------", "anchor_text": "Database"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&user=Sebastian+Guggisberg&userId=673026f7b16a&source=-----553def411855---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&user=Sebastian+Guggisberg&userId=673026f7b16a&source=-----553def411855---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----553def411855--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F553def411855&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----553def411855---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----553def411855--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----553def411855--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----553def411855--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----553def411855--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----553def411855--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----553def411855--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----553def411855--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----553def411855--------------------------------", "anchor_text": ""}, {"url": "https://sebastian-guggisberg.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://sebastian-guggisberg.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sebastian Guggisberg"}, {"url": "https://sebastian-guggisberg.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "100 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F673026f7b16a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&user=Sebastian+Guggisberg&userId=673026f7b16a&source=post_page-673026f7b16a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F28501f03ecbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransforming-text-files-to-data-tables-with-python-553def411855&newsletterV3=673026f7b16a&newsletterV3Id=28501f03ecbb&user=Sebastian+Guggisberg&userId=673026f7b16a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}