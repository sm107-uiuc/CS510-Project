{"url": "https://towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183", "time": 1683012325.366497, "path": "towardsdatascience.com/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183/", "webpage": {"metadata": {"title": "Manifold Learning [t-SNE, LLE, Isomap, +] Made Easy | by Andre Ye | Towards Data Science", "h1": "Manifold Learning [t-SNE, LLE, Isomap, +] Made Easy", "description": "Principal Component Analysis is a powerful method, but it often fails in that it assumes that the data can be modelled linearly. PCA expressed new features as linear combinations of existing ones by\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/beyond-ordinary-pca-nonlinear-principal-component-analysis-54a93915a702", "anchor_text": "Nonlinear PCA for a solution to this", "paragraph_index": 3}, {"url": "https://medium.com/analytics-vidhya/linear-discriminant-analysis-explained-in-under-4-minutes-e558e962c877?source=your_stories_page---------------------------", "anchor_text": "Linear/Quadratic Discriminant Analysis", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-distribution", "anchor_text": "t-distributions", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3", "anchor_text": "entropy", "paragraph_index": 20}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership", "paragraph_index": 29}], "all_paragraphs": ["Principal Component Analysis is a powerful method, but it often fails in that it assumes that the data can be modelled linearly. PCA expressed new features as linear combinations of existing ones by multiplying each by a coefficient. To address the limitations of PCA, various techniques have been created by apply for data with different specific structures. Manifold learning, however, seeks to find a method that can generalize to all structures of data.", "Different structures of data refer to its different attributes within the data. For instance, it may be linearly separable, or it may be very sparse. Relationships within the data may be tangent, parallel, enveloping, or orthogonal to others. PCA works well on a very specific subset of data structures, since it operates on the assumption of linearity.", "To put things in context, consider 300 by 300 pixel headshots. Under perfect conditions, each of the images would be centered perfectly, but in reality, there are many additional degrees of freedom to consider, such as lighting or the tilt of the face. If we were to treat a headshot as a point in 90,000 dimensional space, changing various effects like tilting the head or looking in a different direction move it nonlinearly through space, even though it is the same object with the same class.", "This kind of data appears very often in real-world datasets. In addition to this effect, PCA is flustered when presented with skewed distributions, extreme values, and multiple dummy (one-hot encoded) variables (see Nonlinear PCA for a solution to this). There is a need for a generalizable method of dimensionality reduction.", "Manifold learning refers to this very task. There are many approaches within manifold learning that perhaps have been seen before, such as t-SNE and Locally Linear Embeddings (LLE). There are many articles and papers that go into the technical and mathematical details of these algorithms, but this one will focus on the general intuition and implementation.", "Note that while there have been a few variants of dimensionality reduction that are supervised (e.g. Linear/Quadratic Discriminant Analysis), manifold learning generally refers to an unsupervised reduction, where the class is not presented to the algorithm (but may exist).", "Whereas PCA attempts to create several linear hyperplanes to represent dimensions, much like multiple regression constructs as an estimation of the data, manifold learning attempts to learn manifolds, which are smooth, curved surfaces within the multidimensional space. As in the image below, these are often formed by subtle transformations on an image that would otherwise fool PCA.", "Then, \u2018local linear patches\u2019 that are tangent to the manifold can be extracted. These patches are usually in enough abundance such that they can accurately represent the manifold. Because these manifolds are not modelled by any one mathematical function but by several small linear patches, these linear neighborhoods can model any manifold. Although this may not be explicitly how certain algorithms approach the modelling of manifolds, the fundamental ideas are very similar.", "The following are fundamental assumptions or aspects of manifold learning algorithms:", "This idea can be understood well by looking at different approaches between unravelling this coiled dataset. On the left is a more PCA-like approach towards preserving the shape of the data, where each point is connected to each other. On the right, however, is an approach in which only the distance between neighborhoods of data points are valued.", "This relative disregard for points outside of a neighborhood leads to interesting results. For instance, consider this Swiss Roll dataset, which was coiled in three dimensions and reduced to a strip in two dimensions. In some scenarios, this effect would not be desirable. However, if this curve was the result of, say, tilting of the camera in an image or external effects on audio quality, manifold learning does us a huge favor by delicately unravelling these complex nonlinear relationships.", "On the Swiss Roll dataset, PCA and even specialized variations like Kernel PCA fail to capture the gradient of values. Locally Linear Embeddings (LLE), a manifold learning algorithm, on the other hand, is able to.", "Let\u2019s get into more detail about three popular manifold learning algorithms: IsoMap, Locally Linear Embeddings, and t-SNE.", "One of the first explorations in manifold learning was the Isomap algorithm, short for Isometric Mapping. Isomap seeks a lower-dimensional representation that maintains \u2018geodesic distances\u2019 between the points. A geodesic distance is a generalization of distance for curved surfaces. Hence, instead of measuring distance in pure Euclidean distance with the Pythagorean theorem-derived distance formula, Isomap optimizes distances along a discovered manifold.", "Isomap performs better than PCA when trained on the MNIST dataset, showing a proper sectioning-off of different types of digits. The proximity and distance between certain groups of digits is revealing to the structure of the data. For instance, the \u20185\u2019 and the \u20183\u2019 that are close to each other (in the bottom left) in distance indeed look similar.", "Below is the implementation of Isomap in Python. Since MNIST is a very large dataset, you may want to only train Isomap on the first 100 training examples with .fit_transform(X[:100]).", "Locally Linear Embeddings use a variety of tangent linear patches (as demonstrated with the diagram above) to model a manifold. It can be thought of as performing a PCA on each of these neighborhoods locally, producing a linear hyperplane, then comparing the results globally to find the best nonlinear embedding. The goal of LLE is to \u2018unroll\u2019 or \u2018unpack\u2019 in distorted fashion the structure of the data, so often LLE will tend to have a high density in the center with extending rays.", "Note that LLE\u2019s performance on the MNIST dataset is relatively poor. This is likely because the MNIST dataset consists of multiple manifolds, whereas LLE is designed to work on simpler datasets (like the Swiss Roll). It performs relatively similarly, or even worse, than PCA in this case. This makes sense; its \u2018represent one function as several small linear ones\u2019 strategy likely does not work well with large and complex dataset structures.", "The implementation for LLE is as follows, assuming the dataset (X) has already been loaded.", "t-SNE is one of the most popular choices for high-dimensional visualization, and stands for t-distributed Stochastic Neighbor Embeddings. The algorithm converts relationships in original space into t-distributions, or normal distributions with small sample sizes and relatively unknown standard deviations. This makes t-SNE very sensitive to the local structure, a common theme in manifold learning. It is considered to be the go-to visualization method because of many advantages it possesses:", "Isomap and LLE are best use to unfold a single, continuous, low-dimensional manifold. On the other hand, t-SNE focuses on the local structure of the data and attempts to \u2018extract\u2019 clustered local groups instead of trying to \u2018unroll\u2019 or \u2018unfold\u2019 it. This gives t-SNE an upper hand in detangling high-dimensional data with multiple manifolds. It is trained using gradient descent and tries to minimize entropy between distributions. In this sense, it is almost like a simplified, unsupervised neural network.", "t-SNE is very powerful because of this \u2018clustering\u2019 vs. \u2018unrolling\u2019 approach to manifold learning. With a high-dimensional and multiple-manifold dataset like MNIST, where rotations and shifts cause nonlinear relationships, t-SNE performs even better than LDA, which was given the labels.", "However, t-SNE does have some disadvantages:", "t-SNE can implemented in sklearn as well:", "Laurens van der Maaten, t-SNE\u2019s author, says to consider the following when t-SNE yields a poor output:", "As a sanity check, try running PCA on your data to reduce it to two dimensions. If this also gives bad results, then maybe there is not very much nice structure in your data in the first place. If PCA works well but t-SNE doesn\u2019t, I am fairly sure you did something wrong.", "Why does he say so? As an additional reminder to hit the point home, manifold learning is not another variation of PCA but a generalization. Something that performs well in PCA is almost guaranteed to perform well in t-SNE or another manifold learning technique, since they are generalizations.", "Much like an object that is an apple is also a fruit (a generalization), usually something is wrong if something does not yield a similar result as its generalization. On the other hand, if both methods fail, the data is probably inherently tricky to model.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML enthusiast. Join Medium through my referral link: https://andre-ye.medium.com/membership."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F42cfd61f5183&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andre-ye.medium.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006----42cfd61f5183---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/beyond-ordinary-pca-nonlinear-principal-component-analysis-54a93915a702", "anchor_text": "Nonlinear PCA for a solution to this"}, {"url": "https://medium.com/analytics-vidhya/linear-discriminant-analysis-explained-in-under-4-minutes-e558e962c877?source=your_stories_page---------------------------", "anchor_text": "Linear/Quadratic Discriminant Analysis"}, {"url": "https://en.wikipedia.org/wiki/Student%27s_t-distribution", "anchor_text": "t-distributions"}, {"url": "https://towardsdatascience.com/understanding-entropy-the-golden-measurement-of-machine-learning-4ea97c663dc3", "anchor_text": "entropy"}, {"url": "http://web.mit.edu/cocosci/Papers/sci_reprint.pdf", "anchor_text": "Isomap"}, {"url": "https://cs.nyu.edu/~roweis/lle/papers/lleintro.pdf", "anchor_text": "Locally Linear Embedding"}, {"url": "https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf", "anchor_text": "t-SNE"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----42cfd61f5183---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----42cfd61f5183---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----42cfd61f5183---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----42cfd61f5183---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----42cfd61f5183---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&user=Andre+Ye&userId=be743a65b006&source=-----42cfd61f5183---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&user=Andre+Ye&userId=be743a65b006&source=-----42cfd61f5183---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F42cfd61f5183&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----42cfd61f5183---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----42cfd61f5183--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----42cfd61f5183--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----42cfd61f5183--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://andre-ye.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff44a966e4ff1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183&newsletterV3=be743a65b006&newsletterV3Id=f44a966e4ff1&user=Andre+Ye&userId=be743a65b006&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}