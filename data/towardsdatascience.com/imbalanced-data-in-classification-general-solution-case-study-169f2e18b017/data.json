{"url": "https://towardsdatascience.com/imbalanced-data-in-classification-general-solution-case-study-169f2e18b017", "time": 1683005058.279892, "path": "towardsdatascience.com/imbalanced-data-in-classification-general-solution-case-study-169f2e18b017/", "webpage": {"metadata": {"title": "Imbalanced Data in Classification: General Solution & Case Study | by Hadeer Hammad | Towards Data Science", "h1": "Imbalanced Data in Classification: General Solution & Case Study", "description": "When dealing with a classification problem, how does the one approach a dataset that has significantly more data points in one of its binary classes compared to the other class? Such datasets are\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/e596798cce69?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Min Zhou", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/2002.04592", "anchor_text": "https://arxiv.org/abs/2002.04592", "paragraph_index": 2}], "all_paragraphs": ["Authors: Hadeer Hammad & Min Zhou, PhD", "When dealing with a classification problem, how does the one approach a dataset that has significantly more data points in one of its binary classes compared to the other class? Such datasets are referred as imbalanced. Would it be wise to simply implement a classification model on the imbalanced data and wish for the best? There are many resampling techniques out there that \u201cbalance\u201d imbalanced datasets and plenty of classification models. How do we select the optimal one for our problem?", "The intention of this article is to summarize the following academic research \u201cImbalanced Classification: an objective-oriented review\u201d for non-technical practitioners in the data science field [https://arxiv.org/abs/2002.04592]. This article is accessible to readers with at minimum basic prior knowledge in Machine Learning.", "Imbalanced datasets are very common across all industries. Let\u2019s assume you work for a bank and you have a credit-card transaction data with fraud labels. You discover that the fraud class is highly imbalanced (0.17% of data is Fraud=0 & 99.83% of data is Non_Fraud=1). Naively implementing a classification model on such imbalanced data will likely result in very low predictive accuracy. In classification problems, it is almost impossible to do a perfect job in simultaneously predicting the two classes (Fraud and Non-Fraud). This is because classification models carry two types of errors, type I and type II, and inherently there is a trade-off between the two. Type I error indicates the probability of misclassifying a fraud transaction as non-fraud. Type II error means the opposite: the probability of misclassifying a non-fraud transaction as fraud. It is often the case that a Type I error is more costly than a Type II error. Our case here is an example of that, as you could anger your clients by wrongly flagging their transactions to be fraud and thereby risk losing them. However, generally speaking, depending on the nature of the problem, you may choose to treat the weights of type I and type II errors differently, which accordingly determines the classification paradigm to operate under.", "We will provide a brief overview of classification paradigms and resampling tecnhiques. Then, we will use the above example of credit-card fraud data, which is a real case, to pair up each resampling technique with classification models under different classification paradigms. The objective is to find the optimal combination of resampling technique with classification model for each paradigm. At the end of this article, we provide samples of writing R codes on applying classification paradigms and resampling techniques.", "Each classification paradigm treats the weights of type I and type II errors differently:", "1. Classical Classification (CC) paradigm minimizes the overall classification error, which implies equal weights on type I and type II errors. It does not serve well in cases where type I error could be more serious than type II error or vice-versa. Thus, we will next introduce two other paradigms that address this issue of asymmetric error importance.", "2. Cost-Sensitive (CS) learning paradigm assigns different costs to type I and type II errors and then minimizes their totality. It has multiple approaches, but we will apply the postprocessing method onto our case study. The downside of CS learning is assigning cost values to type I and type II errors, as they are usually unknown. Another disadvantage is that even if we tune the empirical type I error to be equal to a pre-specified level (alpha), the true population-level type I error still has some likelihood of exceeding alpha. Nevertheless, Neyman-Pearson deals with this issue.", "3. Neyman-Pearson paradigm is an emerging statistical framework that controls asymmetric error through aiming to minimize type II error while controlling type I error under a desirable level. To learn more, please read the following paper: Neyman-Pearson classification algorithms and NP receiver operating characteristics", "We leverage resampling techniques to alleviate the effect of the imbalanced class size on the predictive power of classification models. Resampling techniques create new training datasets through balancing the number of data points in the minority and majority classes. We will go over three different techniques: undersampling, oversampling, and hybrid.", "1. Undersampling method eliminates a subset of data points in the majority class, using two general approaches. The first one is random-undersampling, which randomly discards data points from the majority class to balance its size with that of the minority class. While it is a simple and time-efficient approach, it could create bias in the data by throwing information that makes the data sample less representative of the true entire population. The second technique, Cluster-based undersampling, could weaken this bias issue. It applies a clustering algorithm on the majority class in order to obtain a few clusters which are balanced with the size of the minority class. This technique could be slow if the size of the majority class is large. A general drawback of undersampling is that it could cause critical information to be lost given that a large portion of the majority class\u2019s data is being discarded.", "2. Oversampling increases the number of data points in the minority class to balance it with the size of the majority class. Random oversampling achieves this through randomly duplicating data points in the minority class until they are equally proportionate to the size of the majority class. Synthetic Minority Over-sampling Technique (SMOTE) utilizes k nearest neighbors to generate new data points for the minority class that are equally proportionate to the size of the majority class. Oversampling method could lead to over-fitting and it usually requires longer training time relative to undersampling.", "3. Hybrid is a mere combination of undersampling and oversampling techniques. It simultaneously applies oversampling to increase the number of data points in the minority class, while applying undersampling to lower the number of data points in the majority class.", "Due to our limited computational power, we extract a subsample from the above large dataset. We specify the imbalance ratio (IR) as 100; that is, IR=100. We randomly select n0=300 data points for class 0 (fraud) and select n1=n0*IR=30,000 for class 1. This creates our training set. The testing set consists of the remaining m0=192, [492\u2013300] for class 0 and m1=m0*IR=19,200 for class 1. This splitting mechanism guarantees that IR will be equal for the training and testing sets.", "Below are the resampling techniques that we use", "The following are classi\ufb01cation models that we apply, followed by R packages (note: we use the packages\u2019 default parameters):", "For classi\ufb01cation paradigms, we specify the following parameters:", "Before assessing our results, we need to first set the foundation by reviewing several evaluation metrics, which are used to assess the models\u2019 performance. Please note that we label the minority class (Fraud) as 0 and the majority class (No Fraud) as 1. We call class 0 (negative class, Fraud) and class 1 (positive class, Fraud).", "Classification models are typically summarized in a table called confusion matrix, such as the one below. It is called \u201cconfusion\u201d because classification models are never perfect in identifying the positive from the negative class (that is, they confuse them). The right diagonal represents the labels that were wrongly predicted, while the left one represents the labels that were correctly predicted.", "Confusion matrix comprises of the following:", "Below we compute the proportion of each class to use that information when computing empirical risk and classification cost next:", "\u2014 Overall Classification error (or \u201cempirical risk\u201d): the percentage of misclassifying data points in both classes. It is denoted as follows:=Prop0*Type I + Prop1*Type II =(FP+FN)/(TP+FP+TN+FN)=0.0257", "\u2014 F-score is a common metric when dealing with imbalanced classification problems. It is derived from measuring precision and recall; please see the following table 3 for their computations. F-score is set to 0 if the corresponding precision or recall is undefined or equal to 0.", "o Precision: measures the number of times your model made correct predictions out of its predicted identifications (that is, correct and incorrect predictions) for each class.", "o Recall: measures the number of times your model made correct predictions out of the true identifications for each class.", "Using the above computations of precision and recall, we calculate the F-score for each class:", "The Receiver Operating Characteristic (ROC) curve is a graphical illustration of the classification model\u2019s performance in identifying the positive from the negative class as the discrimination threshold is varied (see below Figure 2). Additionally, it reflects the trade-off between type I and type II errors. As we successfully identify more true negative\u2019s (Fraud) in our data, it comes at the expense of misidentifying non-fraud records as fraud (committing false positive). The area under the ROC curve (AUC) is a single-number summary that quantifies the model\u2019s performance in discriminating the positive from the negative class. It typically falls between 0 and 1. The larger the value, the better an indication of the models\u2019 performance. A value of 0.5 does not serve any better than making a random guess. As depicted below in figure 2, ROC-AUC is 0.9734907, which suggests that the model has done a nice job on identifying fraud transactions from non-fraud.", "Precision-Recall (PR) curves and their AUCs (PR-AUC) are alternative metrics when dealing with imbalanced data. In Figure 3, PR-AUC is 0.857943 for Fraud class and 0.9995953 for non-fraud class.", "In summary, for type I and type II errors, empirical risk, and empirical classification costs, smaller values indicate better classification models\u2019 performance. However, for F-score\u2019s, ROC-AUC, and PR-AUC, larger values indicate better performance.", "To stabilize our results, the process is repeated 50 times and the average performance is reported (the mean of evaluation metrics) for all classifiers under the three classification paradigms. The results are summarized in Figures 4 to 7 and Tables 4 to 6.", "Figure 4 (above) exhibits the results of pairing up each resampling technique with classification models under CC paradigm. We observe that the empirical risk of all classi\ufb01ers without resampling is smaller (better) than that of all resampling techniques. Additionally, F-scores are also better (higher) for all classifiers without resampling techniques. Thus, we conclude that if our learning objective is to minimize risk (operating under CC paradigm), applying XGBoost classification model on the original data without performing resampling technique is the optimal choice (\u201cXGB+Original\u201d).", "It is worthy to note that minimizing the overall classification error on imbalanced data could lead to large type I error, which is clearly shown above. Nevertheless, we can have much better control over type I error through leveraging resampling techniques.", "For readers\u2019 convenience, we summarize below the optimal combinations of resampling techniques with classification models under CC paradigm according to several evaluation metrics:", "ROC-AUC and PR-AUCs in Figure 5 (below) measure the overall models\u2019 performance without the need to specify the classification paradigm. Those metrics suggest that XGBoost works best across all resampling techniques. Nonetheless, resampling techniques cannot improve the performance of logistic regression according to ROC-AUC. However, they can benefit support vector machine significantly under ROC-AUC and PR-AUC (Non-Fraud class). Finally, \u201cXGB+Hybrid\u201d is the optimal combination by the standards of ROC-AUC and PR-AUC (Non-Fraud class), while \u201cXGB+SMOTE\u201d is the best one by the assessment of PR-AUC (Fraud class).", "If our objective is to minimize the total misclassification cost, then we should operate under CS learning paradigm. From the above figure 6, we discover that all the models bene\ufb01t signi\ufb01cantly from resampling techniques by using type I error as the evaluation metric. The table below summarizes the optimal combinations of resampling techniques with classification models under CS learning paradigm by the assessment of different metrics.", "If our goal is to minimize type II error while controlling type I error under a target level, then we should operate under NP paradigm. Its results are shown above in Figure 7. We observe that type I error is well-controlled under \u03b1 across all combinations of resampling techniques with classi\ufb01cation models. Finally, we summarize the optimal combinations for NP paradigm in the table below.", "When working with imbalanced data, it is critical to start with asking yourself which error is more costly to make in your problem: type I or type II? This question will help you to determine the appropriate classification paradigm to operate under. Once you identify the appropriate paradigm, select the optimal combination of resampling technique and classification model from the given charts here to apply on your dataset. Your selection should be based on the evaluation metric that you want to use to assess your classifier performance. There are several evaluation metrics available; choose the one that focuses on the error you find to be relatively costly. Nonetheless, please keep in mind that we have merely considered a selective list of resampling techniques and three classi\ufb01cation models in our case study. There are many other combinations that are worthwhile to explore. Additionally note that in our case study, we randomly selected a subsample of the non-fraud class to construct our classifiers, which might be unrepresentative for our problem.", "Applying classification paradigms and resampling techniques: We apply logistic regression as a mere example.", "2. Cost-Sensitive Learning Paradigm (postprocessing method)", "3. Neyman-Pearson Paradigm (NP umbrella algorithm)It is worthy to note that when constructing NP classifier, we can only apply resampling techniques onto a partial sample of the training set. It is because the algorithm behind it (NP umbrella) splits class 0 of the training set into two parts: one to fit the model and the other to select the threshold. The details of NP umbrella algorithm can be found in the following paper \u201cNeyman-Pearson classification algorithms and NP receiver operating characteristics.\u201d", "3. Hybrid:Here it combines \u201cUnder\u201d and SMOTE resampling techniques with the final training set consisting of the below:", "Finally, please note that ROC-AUC and PR-AUC can be calculated by the functions of \u201croc.curve\u201d and \u201cpr.curve\u201d respectively in \u201cPRROC\u201d package. For other evaluation metrics, you can simply use the formulas included here to compute them.", "Many thanks to Professor Xin Tong, PhD for his kind and continuous support!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F169f2e18b017&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----169f2e18b017--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hadeer.hammad?source=post_page-----169f2e18b017--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hadeer.hammad?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Hadeer Hammad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff52761610b4a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&user=Hadeer+Hammad&userId=f52761610b4a&source=post_page-f52761610b4a----169f2e18b017---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/u/e596798cce69?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Min Zhou"}, {"url": "https://www.vectorstock.com/royalty-free-vector/balance-scale-isolated-icon-design-vector-9656446", "anchor_text": "https://www.vectorstock.com/royalty-free-vector/balance-scale-isolated-icon-design-vector-9656446"}, {"url": "https://arxiv.org/abs/2002.04592", "anchor_text": "https://arxiv.org/abs/2002.04592"}, {"url": "https://www.kaggle.com/mlg-ulb/creditcardfraud", "anchor_text": "[https://www.kaggle.com/mlg-ulb/creditcardfraud"}, {"url": "https://medium.com/tag/imbalanced-data?source=post_page-----169f2e18b017---------------imbalanced_data-----------------", "anchor_text": "Imbalanced Data"}, {"url": "https://medium.com/tag/imbalanced-class?source=post_page-----169f2e18b017---------------imbalanced_class-----------------", "anchor_text": "Imbalanced Class"}, {"url": "https://medium.com/tag/classification-problem?source=post_page-----169f2e18b017---------------classification_problem-----------------", "anchor_text": "Classification Problem"}, {"url": "https://medium.com/tag/resampling?source=post_page-----169f2e18b017---------------resampling-----------------", "anchor_text": "Resampling"}, {"url": "https://medium.com/tag/classifcation-models?source=post_page-----169f2e18b017---------------classifcation_models-----------------", "anchor_text": "Classifcation Models"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&user=Hadeer+Hammad&userId=f52761610b4a&source=-----169f2e18b017---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&user=Hadeer+Hammad&userId=f52761610b4a&source=-----169f2e18b017---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F169f2e18b017&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----169f2e18b017---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----169f2e18b017--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----169f2e18b017--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----169f2e18b017--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----169f2e18b017--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----169f2e18b017--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hadeer.hammad?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hadeer.hammad?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Hadeer Hammad"}, {"url": "https://medium.com/@hadeer.hammad/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff52761610b4a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&user=Hadeer+Hammad&userId=f52761610b4a&source=post_page-f52761610b4a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7be152c70513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimbalanced-data-in-classification-general-solution-case-study-169f2e18b017&newsletterV3=f52761610b4a&newsletterV3Id=7be152c70513&user=Hadeer+Hammad&userId=f52761610b4a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}