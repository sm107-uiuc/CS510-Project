{"url": "https://towardsdatascience.com/drawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9", "time": 1683014291.7025542, "path": "towardsdatascience.com/drawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9/", "webpage": {"metadata": {"title": "\u2018Drawing\u2019 the inner world of a story using GauGAN in a real environment | by ~shirin anlen | Towards Data Science", "h1": "\u2018Drawing\u2019 the inner world of a story using GauGAN in a real environment", "description": "Both AI and interactive storytelling are complex and unpredictable systems. As we deepened Marrow\u2019s design process, the challenge of combining those two systems into one coherent experience became\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Generative_adversarial_network", "anchor_text": "Generative Adversarial Networks", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/a-tool-for-collaborating-over-gans-latent-space-b7ea92ad63d8", "anchor_text": "previous post", "paragraph_index": 3}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Pix2Pix", "paragraph_index": 5}, {"url": "https://immerse.news/family2family-first-steps-5f085dc75666", "anchor_text": "our prototype", "paragraph_index": 6}, {"url": "https://arxiv.org/abs/1903.07291", "anchor_text": "GauGAN", "paragraph_index": 7}, {"url": "https://nvlabs.github.io/SPADE/", "anchor_text": "SPADE", "paragraph_index": 7}, {"url": "https://github.com/nightrome/cocostuff", "anchor_text": "COCO-Stuff", "paragraph_index": 7}, {"url": "http://nvidia-research-mingyuliu.com/gaugan/", "anchor_text": "Try it yourself here.", "paragraph_index": 7}, {"url": "https://theta360.com/en/about/theta/z1.html", "anchor_text": "RICOH THETA Z1", "paragraph_index": 9}, {"url": "https://plato.stanford.edu/entries/kant-mind/#3.2", "anchor_text": "transcendental philosophy", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "anchor_text": "Neural Correlates of Consciousness", "paragraph_index": 18}, {"url": "https://github.com/Marrow-AI/gan-deeplab-spade?fbclid=IwAR2yixniZbSSwbZY97zadd7wlMZ85OaEMFFpRMJn0AiiKpfQtTEqSHPmxcY", "anchor_text": "Open Source GitHub repository", "paragraph_index": 20}, {"url": "https://www.facebook.com/philippel/", "anchor_text": "Philippe Lambert", "paragraph_index": 21}, {"url": "https://palomadawkins.com/", "anchor_text": "Paloma Dawkins", "paragraph_index": 21}, {"url": "https://www.nfb.ca/interactive/marrow/", "anchor_text": "NFB Interactive", "paragraph_index": 21}, {"url": "https://atlasv.io/ive-always-been", "anchor_text": "Atlas V.", "paragraph_index": 21}], "all_paragraphs": ["Both AI and interactive storytelling are complex and unpredictable systems. As we deepened Marrow\u2019s design process, the challenge of combining those two systems into one coherent experience became apparent. On the one hand, as the authors, we developed AI systems and real-time interactions to lead the flow of the experience. On the other hand, we wished to tell a story that also provokes the participants\u2019 imagination and emotions.", "Marrow is a story about the possibility of mental illness in machine learning models, focusing mainly on Generative Adversarial Networks (GAN). We question what kind of mental disorders could emerge in advanced AIs, and invite participants to play in an interactive theater scene operated by GAN. Together they play as one dysfunctional family of AIs. Since we are dealing with very abstract and complex concepts, we wanted to explore multiple ways to communicate the story, more than just through dialogue between the family members. Our tactic was to make the room more \u2018alive,\u2019 reflecting on the embodied models\u2019 mental state. We wanted to dissolve the barriers between the participants and the environment; to slowly immerse them in an unfamiliar magical experience within that room. The room and the dinner scene were an invitation to let go and indulge in an emotional affair with three other strangers.", "In practice, this meant that we had to implement GAN networks that frequently interacted with the environment and with the participants. Since GAN\u2019s training process does not happen in real-time, this became a challenge of manipulating the output of a pre-trained GAN network in response to real-time changes in the environment. To explain our solution, we first need to look at the difference between standard GANs and conditional GANs.", "In its basic form, GAN is trained to produce new images that are visually similar to the training set. If we used a dataset of faces, it would generate new faces. If we trained it on cats, it would render new cats. It can maintain variability (not producing the same image every time) by taking an input \u2018noise\u2019 vector (essentially a series of random numbers) and using them as the basis for the output image. Thus, if we want to connect GAN\u2019s output to changes in the environment, we need to manipulate the noise vector based on those changes. However, as we showed in our previous post, there is hardly any control over what kind of change would emerge as a result of changing the noise vector.", "We could link different variables in the physical room (such as the participants\u2019 position, the position of objects, and mood analysis of the participants) to the generated output, but the lack of precise control over the output results in a tenuous connection to the environment.", "That is where conditional GANs enter the picture. Instead of training on one set of images, we train the network on pairs consisting of an image and a label (numerical input), conditioned to generate one type of image when being presented with a specific kind of label. That grants the user full control over how GAN generates its output for a particular input. The result still varies along with the noise vector, as in the original GAN. However, now the author can create meaningful interactions with the environment. One of the most famous conditional GANs is Pix2Pix.", "It is a general-purpose image-to-image translator. It can be conditioned on any type of image to generate another. It analyzes pixels in both images, learning how to convert from one color to another. Pix2Pix is used in a variety of ways, such as transforming sketches into paintings and colormaps into photos. We have also used it in our prototype to convert a human\u2019s colored pose analysis to a generated human from stock images of families.", "Where Pix2Pix finds its strength, being a generic translator from any image to any image, it also has its weakness. Relying only on color misses out on metadata that one could feed into the network. The algorithm looks only at shapes and colors. It cannot differentiate between a dinner plate and a flying saucer if they look visually similar in the photo. That is what the researchers at NVIDIA addressed when they created GauGAN. Named after post-Impressionist painter Paul Gauguin, GauGAN also creates realistic images from colormaps. However, instead of learning pixel values, it learns the semantic data of the image. The project is also known as SPADE: Semantic Image Synthesis with Spatially-Adaptive Normalization. Instead of learning where green and blue are in the picture, GauGAN learns where there are grass and sky. That is possible because the images used in the training set, such as the generic database COCO-Stuff, contain semantic classifications of the different elements in the picture. The researchers were then able to demonstrate the capability of GauGAN by crafting an interactive painting tool where colors are not just colors but have meanings. When you paint green into the source sketch, you are telling GauGAN that here lies grass. Try it yourself here.", "GauGAN can generate photorealistic images from hand-drawn sketches. Our goal was to have it interact with a real-time physical environment. Solving this was like putting together pieces of a puzzle:", "The code itself was relatively straightforward and mostly had to do with format conversions between the two networks. We also upgraded DeepLab\u2019s webcam code to stream from our 360 camera: RICOH THETA Z1. The segmentation networks are so robust that we could feed the widened stitched image straight to segmentation and generation. The result was surprisingly accurate.", "We now had a generated mirror image, depicting GAN\u2019s (COCO-Stuff) version of whatever the camera is witnessing in the room. But we wanted more; we wanted a space that changes according to the story and resembles the character\u2019s state of mind. We looked for ways to generate visuals that will connect to the story-world. To find meanings in between the words and lure the users into keeping acting, move objects around, see the reflection, and wonder what this is all about.", "We realized that we could interfere in the process of perception and generation. Right after DeepLab analyzers the labels in the camera stream, why not replace them with something else? For example, let\u2019s map any recognized bowl to a sea.", "We started looking for patterns that our characters\u2019 stories can surface and that the physical space can support throughout the visual form: a face, a landscape, an object, a flower. Stories are recognizable patterns, and in those patterns, we find meaning. They are the signal within the noise.", "When we finally got to the lab space to test it all, we discovered the effect of the physical setting. We started playing by arranging (and rearranging) strange elements and exploring the results we can achieve. We developed a scripting platform that lets us easily map objects to other objects. We could mask certain objects from the scene, select multiple objects at once, or invert the selection to map everything other than the objects specified. For example: \u2018Dinner table,\u2019 \u2018table,\u2019 \u2018desk,\u2019 \u2018desk stuff,\u2019 \u2018floor,\u2019 \u2018bed, \u2018car\u2019 \u2014 suddenly became the same item and were mapped into a sea, while everything else was discarded. Although we didn\u2019t have a car or plastic, or bed in the space. Or \u2018frisbee\u2019, \u2018paper\u2019, \u2018mouse\u2019, \u2018metal\u2019, \u2018rock, \u2018bowl\u2019, \u2018wine glass\u2019, \u2018bottle\u2019 \u2014 all mapped to \u2018rock\u2019. Again, interesting to note that we didn\u2019t have a mouse, frisbee, metal, rock, or paper in the real scene, but the network detected them. Therefore, we needed to consider them as well.", "If that wasn\u2019t enough, we discovered that changes in the lights, shadow, and camera angles generated different labels every time, which messed up our mapping. In an interactive storytelling framework, this felt both incredible and horrific. We had a little less than ten days before the opening to refine the space and debug the technology while understanding the range of possibilities we can create with what we just developed.", "We played together with our network, with little control over the visuals, we looked to visualize the story of our characters\u2019 inner world.", "Slowly, we started to learn the system \u2014 what works, what doesn\u2019t, how to clean the scene, how to stabilize the lighting. We also decided to project both stages of the process, the colored segmented analysis of DeepLab and GAN\u2019s generated output. Gradually, the physical environment became more immersive and could link with the words of the story.", "While we still feel that there is a lot more room for experimentation and polishing the images around our story, the results give us the first glimpse of GAN\u2019s \u201cconsciousness\u201d as a perceiving entity that generates its inner world. Such a process resonates with the philosophy of human consciousness.", "Immanuel Kant\u2019s transcendental philosophy speaks of the act of synthesis: Our representations act together to mold one unified consciousness. In modern neuroscience, we speak of the Neural Correlates of Consciousness that describe the neural activity required for consciousness, not as a discrete feedforward mechanism of object recognition, but a long sustained feedback wave of a unified experience. That is also the type of experience we wished to design in Marrow\u2019s room, where the final \u2018editing\u2019 happens in the participant\u2019s mind.", "One thing we are sure will not bring harm to this creative work \u2014 is for more people to use it. You will not know what you\u2019re doing unless you\u2019re making it many times, especially in this complicated type of project. Just make make make.", "Here is the project\u2019s Open Source GitHub repository. Please share with us what you are making and thinking!", "The development phase was done in collaboration with Philippe Lambert, sound artist, and Paloma Dawkins, animator. In the co-production of NFB Interactive and Atlas V.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd8e303aaa2f9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@s.h.i.r.i.n?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@s.h.i.r.i.n?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "~shirin anlen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4ad93386998f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&user=%7Eshirin+anlen&userId=4ad93386998f&source=post_page-4ad93386998f----d8e303aaa2f9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://avner.js.org/", "anchor_text": "Avner Peled"}, {"url": "https://shirin.works/Marrow-dev-phase-Machine-learning-immersive-theater-WIP", "anchor_text": "Marrow"}, {"url": "https://blogs.nvidia.com/blog/2019/07/30/gaugan-ai-painting/", "anchor_text": "GauGan"}, {"url": "https://en.wikipedia.org/wiki/Generative_adversarial_network", "anchor_text": "Generative Adversarial Networks"}, {"url": "https://towardsdatascience.com/a-tool-for-collaborating-over-gans-latent-space-b7ea92ad63d8", "anchor_text": "previous post"}, {"url": "https://towardsdatascience.com/a-tool-for-collaborating-over-gans-latent-space-b7ea92ad63d8", "anchor_text": "A tool for Collaborating over GAN\u2019s latent spaceIn January 2020 we finalized the development phase of Marrow. Shirin Anlen and I are sharing lessons learned during\u2026towardsdatascience.com"}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "Pix2Pix"}, {"url": "https://phillipi.github.io/pix2pix/", "anchor_text": "https://phillipi.github.io/pix2pix/"}, {"url": "https://immerse.news/family2family-first-steps-5f085dc75666", "anchor_text": "our prototype"}, {"url": "https://immerse.news/family2family-first-steps-5f085dc75666", "anchor_text": "Family2Family: first stepsIn November 2018, we presented the prologue of Marrow: I\u2019ve Always Been Jealous of Other People\u2019s Families at IDFA\u2026immerse.news"}, {"url": "https://arxiv.org/abs/1903.07291", "anchor_text": "GauGAN"}, {"url": "https://nvlabs.github.io/SPADE/", "anchor_text": "SPADE"}, {"url": "https://github.com/nightrome/cocostuff", "anchor_text": "COCO-Stuff"}, {"url": "http://nvidia-research-mingyuliu.com/gaugan/", "anchor_text": "Try it yourself here."}, {"url": "https://www.nvidia.com/en-us/research/ai-playground/", "anchor_text": "https://www.nvidia.com/en-us/research/ai-playground/"}, {"url": "https://github.com/kazuto1011/deeplab-pytorch", "anchor_text": "DeepLab v2 network"}, {"url": "https://github.com/nightrome/cocostuff", "anchor_text": "COCO-Stuff"}, {"url": "https://theta360.com/en/about/theta/z1.html", "anchor_text": "RICOH THETA Z1"}, {"url": "https://plato.stanford.edu/entries/kant-mind/#3.2", "anchor_text": "transcendental philosophy"}, {"url": "https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness", "anchor_text": "Neural Correlates of Consciousness"}, {"url": "https://github.com/Marrow-AI/gan-deeplab-spade?fbclid=IwAR2yixniZbSSwbZY97zadd7wlMZ85OaEMFFpRMJn0AiiKpfQtTEqSHPmxcY", "anchor_text": "Open Source GitHub repository"}, {"url": "https://www.facebook.com/philippel/", "anchor_text": "Philippe Lambert"}, {"url": "https://palomadawkins.com/", "anchor_text": "Paloma Dawkins"}, {"url": "https://www.nfb.ca/interactive/marrow/", "anchor_text": "NFB Interactive"}, {"url": "https://atlasv.io/ive-always-been", "anchor_text": "Atlas V."}, {"url": "https://medium.com/tag/interactive?source=post_page-----d8e303aaa2f9---------------interactive-----------------", "anchor_text": "Interactive"}, {"url": "https://medium.com/tag/ai?source=post_page-----d8e303aaa2f9---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d8e303aaa2f9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/experimental?source=post_page-----d8e303aaa2f9---------------experimental-----------------", "anchor_text": "Experimental"}, {"url": "https://medium.com/tag/storytelling?source=post_page-----d8e303aaa2f9---------------storytelling-----------------", "anchor_text": "Storytelling"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&user=%7Eshirin+anlen&userId=4ad93386998f&source=-----d8e303aaa2f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&user=%7Eshirin+anlen&userId=4ad93386998f&source=-----d8e303aaa2f9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd8e303aaa2f9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d8e303aaa2f9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d8e303aaa2f9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@s.h.i.r.i.n?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@s.h.i.r.i.n?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "~shirin anlen"}, {"url": "https://medium.com/@s.h.i.r.i.n/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "187 Followers"}, {"url": "https://www.shirin.works/", "anchor_text": "https://www.shirin.works/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4ad93386998f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&user=%7Eshirin+anlen&userId=4ad93386998f&source=post_page-4ad93386998f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F4ad93386998f%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdrawing-the-inner-world-of-a-story-using-gaugan-in-a-real-environment-d8e303aaa2f9&user=%7Eshirin+anlen&userId=4ad93386998f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}