{"url": "https://towardsdatascience.com/machine-learning-pipelines-with-kubeflow-4c59ad05522", "time": 1683014050.671809, "path": "towardsdatascience.com/machine-learning-pipelines-with-kubeflow-4c59ad05522/", "webpage": {"metadata": {"title": "Machine Learning Pipelines with Kubeflow | by George Novack | Towards Data Science", "h1": "Machine Learning Pipelines with Kubeflow", "description": "How a build automated machine learning workflows using Kubeflow Pipelines."}, "outgoing_paragraph_urls": [{"url": "https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning", "anchor_text": "MLOps: Continuous delivery and automation pipelines in machine learning", "paragraph_index": 5}, {"url": "https://www.kubeflow.org/", "anchor_text": "Kubeflow", "paragraph_index": 6}, {"url": "https://github.com/features/actions", "anchor_text": "GitHub Actions", "paragraph_index": 17}, {"url": "https://hub.docker.com/", "anchor_text": "Docker Hub", "paragraph_index": 17}, {"url": "https://github.com/gnovack/kubeflow-pipelines", "anchor_text": "https://github.com/gnovack/kubeflow-pipelines", "paragraph_index": 29}, {"url": "https://github.com/gnovack/kubeflow-pipelines", "anchor_text": "https://github.com/gnovack/kubeflow-pipelines", "paragraph_index": 40}], "all_paragraphs": ["A lot of attention is being given now to the idea of Machine Learning Pipelines, which are meant to automate and orchestrate the various steps involved in training a machine learning model; however, it\u2019s not always made clear what the benefits are of modeling machine learning workflows as automated pipelines.", "When tasked with training a new ML model, most Data Scientists and ML Engineers will probably start by developing some new Python scripts or interactive notebooks that perform the data extraction and preprocessing necessary to construct a clean set of data on which to train the model. Then, they might create several additional scripts or notebooks to try out different types of models or different machine learning frameworks. And finally, they\u2019ll gather and explore metrics to evaluate how each model performed on a test dataset, and then determine which model to deploy to production.", "This is obviously an over-simplification of a true machine learning workflow, but the key point is that this general approach requires a lot of manual involvement, and is not reusable or easily repeatable by anyone but the engineer(s) that initially developed it.", "We can use Machine Learning Pipelines to address these concerns. Rather than treating the data preparation, model training, model validation, and model deployment as a single codebase meant for the specific model that we\u2019re working on, we can treat this workflow as a sequence of separate, modular steps that each focus on a specific task.", "There are a number of benefits of modeling our machine learning workflows as Machine Learning Pipelines:", "If you\u2019re interested in a deeper dive into Machine Learning pipelines and their benefits, Google Cloud has a great article that describes a natural progression toward better, more automated practices (including ML Pipelines) that teams can adopt to mature their ML workflows: MLOps: Continuous delivery and automation pipelines in machine learning", "Kubeflow is an open-source platform, built on Kubernetes, that aims to simplify the development and deployment of machine learning systems. Described in the official documentation as the ML toolkit for Kubernetes, Kubeflow consists of several components that span the various steps of the machine learning development lifecycle. These components include notebook development environments, hyperparameter tuning, feature management, model serving, and, of course, machine learning pipelines.", "In this article, we\u2019ll just be focused on the Pipelines component of Kubeflow.", "To run the example pipeline, I used a Kubernetes cluster running on bare metal, but you can run the example code on any Kubernetes cluster where Kubeflow is installed.", "The only dependency needed locally is the Kubeflow Pipelines SDK. You can install the SDK using pip:", "Pipelines in Kubeflow are made up of one or more components, which represent individual steps in a pipeline. Each component is executed in its own Docker container, which means that each step in the pipeline can have its own set of dependencies, independent of the other components.", "For each component we develop, we\u2019ll create a separate Docker image that accepts some inputs, performs an operation, then exposes some outputs. We\u2019ll also have a separate python script, pipeline.py that creates pipeline components out of each Docker image, then constructs a pipeline using the components.", "We\u2019ll create four components in all:", "If all this talk of components and Docker images sounds confusing: don\u2019t worry, it should all start to make more sense when we get into the code.", "The first component in our pipeline will use sklearn.datasets to load in the Boston Housing dataset. We\u2019ll split this dataset into train and test sets using Sci-kit learn\u2019s train_test_split function, then we\u2019ll use np.save to save our dataset to disk so that it can be reused by later components.", "So far this is just a simple Python script. Now we need to create a Docker image that executes this script. We\u2019ll write a Dockerfile to build the image:", "Starting from the python:3.7-slim base image, we\u2019ll install the necessary packages using pip , copy the preprocess Python script from our local machine to the container, and then specify the preprocess.py script as the container entrypoint, which means that when the container starts, it will execute our script.", "Now we\u2019ll get started on the pipeline. First, you\u2019ll need to make sure that the Docker image that we defined above is accessible from your Kubernetes cluster. For the purpose of this example, I used GitHub Actions to build the image and push it to Docker Hub.", "Now let\u2019s define a component. Each component is defined as a function that returns an object of type ContainerOp . This type comes from the kfp SDK that we installed earlier. Here is a component definition for the first component in our pipeline:", "Notice that for the image argument, we\u2019re passing the name of the Docker image defined by the Dockerfile above, and for the file_outputs argument, we\u2019re specifying the file paths of the four .npy files that are saved to disk by our component Python script.", "By specifying these four files as File Outputs, we make them available for other components in the pipeline.", "Note: It\u2019s not a very good practice to hard-code file paths in our components, because, as you can see from the code above, this requires that the person creating the component definition knows specific details about the component implementation (that is, the implementation contained in the Docker image). It would be much cleaner to have our component accept the file paths as command-line arguments. This way the person defining the component has full control over where to expect the output files. I\u2019ve left it hard-coded this way to hopefully make it easier to see how all of these pieces fit together.", "With our first component defined, we can create a pipeline that uses the preprocess-data component.", "The pipeline definition is a Python function decorated with the @dsl.pipeline annotation. Within the function, we can use the component like we would any other function.", "To execute the pipeline, we create a kfp.Client object and invoke the create_run_from_pipeline_func function, passing in the function that defines our pipeline.", "If we execute this script, then navigate to the Experiments view in the Pipelines section of the Kubeflow central dashboard, we\u2019ll see the execution of our pipeline. We can also see the four file outputs from the preprocess-data component by clicking on the component in the graph view of the pipeline.", "So we can execute our pipeline and visualize it in the GUI, but a pipeline with a single step isn\u2019t all that exciting. Let\u2019s create the remaining components.", "For the train-model component, we\u2019ll create a simple python script that trains a regression model using Sci-kit learn. This should look similar to the python script for the preprocessor component. The big difference is that here we\u2019re using argparse to accept the file paths to the training data as command-line arguments.", "The Dockerfile, likewise, is very similar to the one we used for the first component. We start with the base image, install the necessary packages, copy the python script into the container, then execute the script.", "The two other components, test-model and deploy-model, follow this same pattern. In fact, they\u2019re so similar to the two components we\u2019ve already implemented, that for the sake of brevity I won\u2019t show them here. If you\u2019re interested, you can find all of the code for the pipeline in this GitHub repository: https://github.com/gnovack/kubeflow-pipelines", "Just like with the preprocess-data component from earlier, we\u2019ll build Docker images out of these three components and push them to Docker Hub:", "Now it\u2019s time to create the full machine learning pipeline.", "First, we\u2019ll create component definitions for the train-model, test-model, and deploy-model components.", "The only major difference between the definition of the train-model component and that of the preprocess-data component from earlier is that train-model accepts two arguments, x_train and y_train which will be passed to the container as command-line arguments, and will be parsed out in the component implementation using the argparse module.", "Now the definitions for the test-model and deploy-model components:", "With the four pipeline components defined, we\u2019ll now revisit the boston_pipeline function from earlier and use all of our components together.", "Now if we create a run from the pipeline and navigate to the Pipelines UI in the Kubeflow central dashboard, we should see all four components displayed in the pipeline graph.", "In this article, we created a very simple machine learning pipeline that loads in some data, trains a model, evaluates it on a holdout dataset, and then \u201cdeploys\u201d it. By using Kubeflow Pipelines, we were able to encapsulate each step in this workflow into Pipeline Components that each run in their very own, isolated Docker container environments.", "This encapsulation promotes loose coupling between the steps in our machine learning workflow and opens up the possibility of reusing components in future pipelines. For example, there wasn\u2019t anything in our training component specific to the Boston Housing dataset. We might be able to reuse this component any time we want to train a regression model using Sci-kit learn.", "We just scratched the surface of what\u2019s possible with Kubeflow Pipelines, but hopefully, this article helped you understand the basics of components, and how we can use them together to create and execute pipelines.", "If you\u2019re interested in exploring the whole codebase used in this article, you can find it all in this GitHub repo: https://github.com/gnovack/kubeflow-pipelines", "Thanks for reading! Feel free to reach out with any questions or comments.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4c59ad05522&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gnovack.medium.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": ""}, {"url": "https://gnovack.medium.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "George Novack"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76cce7566b5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&user=George+Novack&userId=76cce7566b5e&source=post_page-76cce7566b5e----4c59ad05522---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning", "anchor_text": "MLOps: Continuous delivery and automation pipelines in machine learning"}, {"url": "https://www.kubeflow.org/", "anchor_text": "Kubeflow"}, {"url": "https://github.com/features/actions", "anchor_text": "GitHub Actions"}, {"url": "https://hub.docker.com/", "anchor_text": "Docker Hub"}, {"url": "https://github.com/gnovack/kubeflow-pipelines", "anchor_text": "https://github.com/gnovack/kubeflow-pipelines"}, {"url": "https://github.com/gnovack/kubeflow-pipelines", "anchor_text": "https://github.com/gnovack/kubeflow-pipelines"}, {"url": "https://kubeflow-pipelines.readthedocs.io/en/latest/index.html", "anchor_text": "https://kubeflow-pipelines.readthedocs.io/en/latest/index.html"}, {"url": "https://www.kubeflow.org/docs/pipelines/sdk/build-component/", "anchor_text": "https://www.kubeflow.org/docs/pipelines/sdk/build-component/"}, {"url": "https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning", "anchor_text": "MLOps: Continuous delivery and automation pipelines in machine learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----4c59ad05522---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/kubeflow-pipelines?source=post_page-----4c59ad05522---------------kubeflow_pipelines-----------------", "anchor_text": "Kubeflow Pipelines"}, {"url": "https://medium.com/tag/kubeflow?source=post_page-----4c59ad05522---------------kubeflow-----------------", "anchor_text": "Kubeflow"}, {"url": "https://medium.com/tag/machine-learning-pipeline?source=post_page-----4c59ad05522---------------machine_learning_pipeline-----------------", "anchor_text": "Machine Learning Pipeline"}, {"url": "https://medium.com/tag/kubernetes?source=post_page-----4c59ad05522---------------kubernetes-----------------", "anchor_text": "Kubernetes"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&user=George+Novack&userId=76cce7566b5e&source=-----4c59ad05522---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&user=George+Novack&userId=76cce7566b5e&source=-----4c59ad05522---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F4c59ad05522&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----4c59ad05522---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----4c59ad05522--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----4c59ad05522--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4c59ad05522--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----4c59ad05522--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----4c59ad05522--------------------------------", "anchor_text": ""}, {"url": "https://gnovack.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gnovack.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "George Novack"}, {"url": "https://gnovack.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "136 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76cce7566b5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&user=George+Novack&userId=76cce7566b5e&source=post_page-76cce7566b5e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc5cf182bbc89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-pipelines-with-kubeflow-4c59ad05522&newsletterV3=76cce7566b5e&newsletterV3Id=c5cf182bbc89&user=George+Novack&userId=76cce7566b5e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}