{"url": "https://towardsdatascience.com/svms-jack-of-all-trades-fd6fe3b49580", "time": 1683006588.7564712, "path": "towardsdatascience.com/svms-jack-of-all-trades-fd6fe3b49580/", "webpage": {"metadata": {"title": "Support Vector Machines \u2014 Jack of all trades? | by Papasot | Towards Data Science", "h1": "Support Vector Machines \u2014 Jack of all trades?", "description": "The following explanation assumes that you have a basic understanding of supervised machine learning as well as linear discriminant functions. However, if like me, you have been gifted with the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Supervised_learning", "anchor_text": "Supervised Machine Learning", "paragraph_index": 2}, {"url": "http://vision.psych.umn.edu/users/schrater/schrater_lab/courses/PattRecog09/Lec7PattRec09.pdf", "anchor_text": "Linear Discriminant Functions", "paragraph_index": 3}, {"url": "https://www.youtube.com/watch?v=JiM_LXpAtLc", "anchor_text": "shown", "paragraph_index": 27}, {"url": "https://data-flair.training/blogs/svm-kernel-functions/", "anchor_text": "here", "paragraph_index": 38}, {"url": "https://svivek.com/teaching/lectures/slides/svm/kernels.pdf", "anchor_text": "Kernels and the Kernel Trick: Lecture (The University of Utah)", "paragraph_index": 39}], "all_paragraphs": ["The following explanation assumes that you have a basic understanding of supervised machine learning as well as linear discriminant functions.", "However, if like me, you have been gifted with the memory of goldfish, let us remind ourselves the following,", "Supervised Machine Learning entails the creation of an algorithm that is capable of mapping an input to an output based on example input-output pairs. In other words, the data fed to the neural network is already classified beforehand, practically \u2018supervising\u2019 the process.", "In supervised machine learning, a primitive, yet effective means of classifying our input data are linear classifiers such as Linear Discriminant Functions. These functions effectively divide our feature space by a hyperplane decision surface that helps classify data present on either side.", "As a subset of linear discriminant functions, SVM\u2019s also classify labeled training data for each predefined category with an N-dimensional hyperplane. N being the number of attributes considered.", "Let us consider the following dataset of red and blue circles. In this case, there are only 2 attributes, x and y, resulting in the hyperplane becoming a two-dimensional line.", "From the diagram, it is clear that there exist multiple possible orientations for the green hyperplane separating the two classes, which influence both the variance and bias of the model.", "Therefore, SVM\u2019s try to address the question of which of the hyperplanes is the optimum choice?", "To do so, a margin is defined as the distance between the hyperplane surface and the nearest points in the dataset, called support vectors. In fact, the margin can vary in width and orientation depending on the selected support vectors. As a result, they are chosen accordingly to maximize the margin of classification.", "Data points located on either side of the margin are classified as belonging to the corresponding dataset.", "The basic form of a linear discriminant function is as follows,", "where w is the weight vector associated with the data point x, and w0 is the bias or threshold weight.", "On the hyperplane g(x) = 0, and then depending whether g(x)>0 or g(x)<0, points are classified accordingly. If we plot g(x) for our dataset, we expect the final outcome to look as follows,", "Now, let us define the vector b, which consists of -1s and 1s depending on which side of the hyperplane each data point x, is situated.", "If we multiply g(x) with b(x), we expect all the data points to be translated on the right-hand side of the previous diagram, as all g(x)<0 points will be multiplied by -1.", "As a result, the distance M, between g(x) =0 and the leftmost data point is defined as the margin.", "However, if a support vector happens to be an outlier, an erroneous point in the dataset, it can result in poor classification as it skews the hyperplane.", "As evident from the diagram, the rightmost red data point skews the hyperplane as it overfits to compensate for the anomaly. In fact, the optimum hyperplane remains the one positioned at a steeper gradient located equally between the two datasets.", "What if there is a way to make the SVM less sensitive to support vectors, to result in a more generalizable result?", "We can define a softness value, C, which defines the extent to which data points can surpass the margin guidelines, such that erroneous support vectors do not jeopardize the accuracy of our model. The value of C can be selected from cross-validation techniques.", "If the value of C is too large we allow for many points to go beyond the determined boundary. However, if the value of C is too small, we define a hard boundary and risk overfitting the data.", "Subsequently, the margin maximization equation can be updated, with a newly defined parameter \u03b5, related to the softness C, as follows,", "In some cases, it is not possible to linearly separate datasets, instead, non-linear mappings are capable of classifying the datasets to a more accurate extent. Common examples include the XOR dataset or circular ones.", "As a result, there is a need for non-linear mapping which places the dataset into a higher-order space where a suitable separation hyperplane can be determined. The mapping is performed by the transform function \u03a6 and the linear support vector dot product can now be re-expressed with \u03c6(x).", "Perhaps an example will make this more intuitive,", "Consider the circular dataset above. It is possible to map the data points from an inseparable 2-dimensional space into a separable 3-dimensional one, with the following transform function,", "With the aforementioned \u03c6(x) the discriminant function is updated as follows,", "Moreover, it can be shown that w is always a linear combination of x (or \u03c6(x) if operating in the transformed space) such that,", "As a result, in order to determine the SVM decision boundary, the following higher dimensional dot product needs to be determined [1],", "Despite solving the problem, this approach has a higher number of computational operations. There are 3x2 operations to transform into the 3-dimensional space and an additional 3 to perform the dot product. Additionally, the computational complexity is O(n\u00b2).", "To facilitate the procedure, reducing both computational complexity and cost, there exist functions called Kernels.", "Kernels transform linearly inseparable data to linearly separable ones, without the need to transform the data into a higher-dimensional space and calculating the dot product.", "Therefore, the previous example can be solved using a Kernel as follows,", "In comparison to the previous method, the kernel approach uses 2 computing operations and has a computational complexity is O(n).", "The following was an example of linear Kernels, additional common Kernels include:", "where c and d represent the polynomial degree and are defined by the user to optimize the classification.", "Linear classifiers have c=0 and d=1.", "where d is the polynomial degree and \u03b3 defines the closeness of selected support vectors. A high gamma value selects the nearest support vectors, whilst a low gamma value selects further ones.", "More Kernel types can be found here.", "[1] Kernels and the Kernel Trick: Lecture (The University of Utah)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Your neighborhood mechanical engineer. Born in Greece, educated in the UK and currently working in France."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ffd6fe3b49580&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@papasot?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@papasot?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Papasot"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F48f7231ee52a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&user=Papasot&userId=48f7231ee52a&source=post_page-48f7231ee52a----fd6fe3b49580---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Supervised_learning", "anchor_text": "Supervised Machine Learning"}, {"url": "http://vision.psych.umn.edu/users/schrater/schrater_lab/courses/PattRecog09/Lec7PattRec09.pdf", "anchor_text": "Linear Discriminant Functions"}, {"url": "https://www.youtube.com/watch?v=JiM_LXpAtLc", "anchor_text": "shown"}, {"url": "https://data-flair.training/blogs/svm-kernel-functions/", "anchor_text": "here"}, {"url": "https://svivek.com/teaching/lectures/slides/svm/kernels.pdf", "anchor_text": "Kernels and the Kernel Trick: Lecture (The University of Utah)"}, {"url": "https://medium.com/tag/svm?source=post_page-----fd6fe3b49580---------------svm-----------------", "anchor_text": "Svm"}, {"url": "https://medium.com/tag/kernel?source=post_page-----fd6fe3b49580---------------kernel-----------------", "anchor_text": "Kernel"}, {"url": "https://medium.com/tag/supervised-learning?source=post_page-----fd6fe3b49580---------------supervised_learning-----------------", "anchor_text": "Supervised Learning"}, {"url": "https://medium.com/tag/linear-discriminant?source=post_page-----fd6fe3b49580---------------linear_discriminant-----------------", "anchor_text": "Linear Discriminant"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----fd6fe3b49580---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&user=Papasot&userId=48f7231ee52a&source=-----fd6fe3b49580---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&user=Papasot&userId=48f7231ee52a&source=-----fd6fe3b49580---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ffd6fe3b49580&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----fd6fe3b49580---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----fd6fe3b49580--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@papasot?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@papasot?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Papasot"}, {"url": "https://medium.com/@papasot/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F48f7231ee52a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&user=Papasot&userId=48f7231ee52a&source=post_page-48f7231ee52a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F48f7231ee52a%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsvms-jack-of-all-trades-fd6fe3b49580&user=Papasot&userId=48f7231ee52a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}