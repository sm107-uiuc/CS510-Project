{"url": "https://towardsdatascience.com/text-processing-is-coming-c13a0e2ee15c", "time": 1682996605.818251, "path": "towardsdatascience.com/text-processing-is-coming-c13a0e2ee15c/", "webpage": {"metadata": {"title": "Text Processing Is Coming. How to use Regular Expression (Regex)\u2026 | by Madeline McCombe | Towards Data Science", "h1": "Text Processing Is Coming", "description": "If you\u2019re like me, and you\u2019ve seen more memes about Game of Thrones (GOT) than actual episodes of the show, you might be wondering why everyone is so obsessed with it. Since I don\u2019t have time to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@madelinemccombe/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42?postPublishedType=initial", "anchor_text": "available here", "paragraph_index": 0}, {"url": "https://www.kaggle.com/khulasasndh/game-of-thrones-books#005ssb.txt", "anchor_text": "on Kaggle here", "paragraph_index": 1}, {"url": "https://docs.python.org/3/library/re.html", "anchor_text": "Regex package", "paragraph_index": 2}, {"url": "https://www.dataquest.io/blog/regex-cheatsheet/", "anchor_text": "found here", "paragraph_index": 4}, {"url": "https://docs.python.org/3/howto/regex.html", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://www.w3schools.com/python/python_regex.asp", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://developers.google.com/edu/python/regular-expressions", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python", "anchor_text": "found here", "paragraph_index": 15}, {"url": "https://www.geeksforgeeks.org/python-nltk-tokenize-regexp/", "anchor_text": "peruse here", "paragraph_index": 16}, {"url": "https://python.gotrained.com/nltk-regex/", "anchor_text": "reference here", "paragraph_index": 18}, {"url": "https://www.datacamp.com/community/tutorials/wordcloud-python", "anchor_text": "found here", "paragraph_index": 20}, {"url": "https://www.mien.in/2017/10/02/visual-text-analytics-with-python/", "anchor_text": "different methods of visualization", "paragraph_index": 20}, {"url": "https://python.gotrained.com/frequency-distribution-in-nltk/", "anchor_text": "Frequency Distribution plot", "paragraph_index": 21}, {"url": "https://www.scikit-yb.org/en/latest/api/text/dispersion.html", "anchor_text": "Lexical dispersion plot", "paragraph_index": 23}, {"url": "https://towardsdatascience.com/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42", "anchor_text": "here", "paragraph_index": 25}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/Regex_NLTK_GoT1.ipynb", "anchor_text": "here on github", "paragraph_index": 26}], "all_paragraphs": ["If you\u2019re like me, and you\u2019ve seen more memes about Game of Thrones (GOT) than actual episodes of the show, you might be wondering why everyone is so obsessed with it. Since I don\u2019t have time to watch the show or read the books, I\u2019m going to use basic text processing to get a general understanding of what I\u2019m missing. In this article I\u2019ll be using the regular expression and natural language toolkit packages in Python to explore, clean, tokenize, and visualize the text. If you are interested more in vectorization, POS tagging, or sentiment analysis, there is another article I wrote available here.", "The text from all 5 books can be found on Kaggle here. I will be using the text of the first book (A Game of Thrones, 1996), which has 571 pages containing 20,168 lines of text. I will be explaining these concepts in order to clean the text:", "Regular expression is a language of different symbols and syntax that can be used to search for a piece of string within a larger string. It can be used in almost any coding language, and is very useful when trying to search for general string patterns. Most often, it is used in web scraping, input validation, and simple parsing. In Python the Regex package can be imported using import re. This gives you access to many different functions and string sequences that allow you to search for anything you want to.", "A regex string refers to the string of letters, symbols, or numbers that tells Regex what to look for. For example, if you want to find all instances of \u2018Daenerys\u2019, the regex string would look like r\u2018Daenerys\u2019. However, if you want to find all words that start with \u2018D\u2019, the regex string would look like r\u2018D[a-z]+\u2019. The D at the beginning of the string must be matched, the square brackets represent a pick one, and the + says that you must pick 1 or more times from the brackets to complete the word. I am going to go through some basic forms of regex strings that will be useful when searching through text.", "There are several special sequences in regex that consist of a backslash followed by a letter. A backslash (\\) is an escape character that can negate the traditional meaning of whatever follows it. A \u2018w\u2019 would normally match \u2018w\u2019, but r\u2018\\w+\u2019 matches one or more alphanumeric characters. If the letter is lowercase, then it matches everything that the special sequence defines, but if the letter is uppercase then the regex string matches everything except what it defines. A list of the special sequences letters can be found here. There are many more techniques than those I briefly covered, and you can go here, here, here, or here to see further information!", "The re package has several built in functions that can be used to apply a regex string to a body of text and find matches among other things. I will go over a few, and explain the differences between them. All of these functions take at least two arguments: the pattern to match (regex string) and the text to search. The following three functions return a match object, which consists of the index of the string matched (start and stop), as well as what string the function matched. They are also limited to finding one match per query.", "The next two functions find all matches within a string of the pattern. Here, re.findall returns a list of all the matches, whereas re.finditer allows you to pull out specific information about each match using a loop.", "The following two functions are ways to split or modify a string after searching for a pattern. They both return the modified string.", "Now that we\u2019ve covered the basics of Regex, let\u2019s move on to preprocessing the GOT text.", "In order to analyze a text, its words must be pulled out and analyzed. One way to do this is to split each text by spaces so that individual words are returned. However, this doesn\u2019t take into account punctuation or other symbols that might want to be removed. This process of breaking sentences, paragraphs, or chapters into individual words is called tokenization, and is an essential step before any type of text analysis is performed. Luckily, there is a package in Python called the Natural Language Toolkit that has a ton of useful functions to manipulate text. It can be imported using import nltk. This package includes a word tokenizer and a sentence tokenizer, which breaks the text down into words and sentences respectively. The word tokenizer breaks text into words, punctuation, and any miscellaneous characters. This means that punctuation detaches itself from the word and becomes its own element in the list. The sentence tokenizer breaks text by traditional sentence punctuation (., ?, !, etc.), and keeps the punctuation attached to the sentence. Here is an example of each:", "So now that you have a list of all the words and punctuation in the text, what next? The list of tokens can be run through a loop and everything that is in a list of stopwords can be removed. Stopwords are words that occur too frequently or have very little meaning, and should be removed. This can be thought of as a type of dimension reduction, as you are taking away words that will not allow you to glean information about the text. It can also be useful to remove words that occur too infrequently.", "With this text, each Page number of the book is specified as \u2018Page X\u2019. In my current list of cleaned words each instance of this is shown as [\u2018page\u2019, \u2018#\u2019], and I will deal with that in my next article when I do further text analysis.", "If either of those words sound like a weird form of gardening, I totally get it. However, these are actually two techniques used to combine all variants of a word into its parent form. For example, if a text has \u2018running\u2019, \u2018runs\u2019, and \u2018run\u2019 , those are all forms of the parent word \u2018run\u2019, and should be transformed and counted as the same word since they have the same meaning. Going through the text line by line and trying to figure out if each word should be transformed to its base form is computationally intensive and a waste of time. Luckily the nltk package introduced in the previous section has functions that can do this for you!", "Stemming removes the end of a word (-ing, -ed, -s, or another common ending) in the hopes that it will find the \u2018base\u2019 form of a word. This method works well for words like \u2018running\u2019-\u2019run\u2019, \u2018climbing\u2019-\u2019climb\u2019, and \u2018pouring\u2019=\u2019pour\u2019, but doesn\u2019t work for other words, such as \u2018leaves\u2019-\u2019leav\u2019. Here is a simple example of this in action:", "This method doesn\u2019t quite get all the words correctly transformed, and george is changed to georg. To fix this, lemmatization can be used instead of stemming, which achieves the same effect but uses a dictionary of lemma (the base form of a word) to figure out if truncating the end of a word makes sense. It also takes into account the type of word (noun, verb, adjective) to better guess at the parent. This method allows \u2018leaves\u2019 to transform to \u2018leaf\u2019, rather than \u2018leav\u2019.", "Notice how lemmatization correctly transforms urged, began, and asked to urge, begin, and ask because it treats all of the tokens as a verb and searches for the base form. It also ignores all words that do not need to be transformed. A useful guide on how to do stemming and lemmatization in Python can be found here.", "Now that you\u2019ve learned a little about Regex and a little about what NLTK has to offer, I am going to explain the intersection of the two. When tokenizing a text, it is possible to split on something other than the default in the nltk. This is done by using nltk.tokenize.RegexpTokenizer(pattern).tokenize(text), and you can specify what Regex string to split on. This is similar to re.split(pattern, text), but the pattern specified in the NLTK function is the pattern of the token you would like it to return instead of what will be removed and split on. There are also a bunch of other tokenizers built into NLTK that you can peruse here. Here are some examples of the nltk.tokenize.RegexpTokenizer():", "There is also an easy way to implement some of the functions covered previously, especially re.search. This can be used to double check that the stemming/lemmatization did what was expected. In this case we can see that verbs ending in -ing were removed from the list of words during lemmatization.", "Another useful way to find instances of phrases within a list of tokens is available by first turning the list into a text object using nltk.Text(list), and then subsetting that object using text.findall(r\u2018<>\u2019) Where each <> holds the regex string to match one token in a sequence. I will go through some examples below, and there is a helpful reference here for further exploration.", "This is a pretty cool way to figure out what mini phrases your text might have hidden, and is a good place to start to analyzing a text. in particular, following Daenerys through the whole book gives a very quick summary of her character arc. Next, I am going to introduce different ways to visualize the frequencies of words within a list of tokens.", "A handy way to get a grasp of the text before actually analyzing it is to look at what words occur most frequently. This is also a good idea to do to make sure that you have removed all of the stop words that are necessary. A basic way to visualize words and their relative frequency is a wordcloud, and a great walkthrough of this can be found here. This method only shows the relative frequencies of each word as compared to the others, and can be difficult to interpret given the abstract nature. To remedy this, I am going to explore different methods of visualization included in the nltk package, including lexical dispersion plots, frequency distribution plot, and n-gram frequency distribution plots.", "A Frequency Distribution plot plots the words according to frequency. Plot twist, I know. This is useful because it shows how much of the text is made up of different themes or ideas. The more common a word it, the more central it is to the theme of a text.", "I included the original tokens in one distribution and the filtered, lemmatized words in another distribution to highlight the importance of removing stopwords and other non-essential symbols. The first distribution tells me nothing about the book, whereas the second gives me several words and character names that captures the essence and writing style of George R.R. Martin. Based on the findings of the lemmatized distribution, I chose 10 words to graph in a lexical dispersion plot.", "A Lexical dispersion plot shows the distribution of a word respective to when it shows up in the text (the offset). For example, if the word of interest was \u2018fox\u2019 and the sentence was, \u2018The quick brown fox jumps over the lazy dog\u2019, the offset of the word would be four, since it is the fourth word in the sentence. This technique of plotting word and its offset shows themes over time. It is also a very customizable plot, since you can choose the words to visualize.", "As you can see, there are different themes in the book at different times. Further analysis of different keywords would uncover different meaning, but this a good start to see what concepts are important in the book.", "In this article we introduced Regex and different methods of searching through text, then went through basic tools in the NLTK package and saw how Regex could be combines with NLTK. At the end we drew broad summaries from the book, and prepared the text for further analysis. I hope you enjoyed this journey, and you can check out more text processing concepts here!", "A copy of my code, which has further examples and explanation, can be found here on github! Feel free to take and use the code as you please.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc13a0e2ee15c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@madelinemccombe?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Madeline McCombe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa4a48b9cfaca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&user=Madeline+McCombe&userId=a4a48b9cfaca&source=post_page-a4a48b9cfaca----c13a0e2ee15c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@bharat_patil_photography?utm_source=medium&utm_medium=referral", "anchor_text": "Bharat Patil"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@madelinemccombe/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42?postPublishedType=initial", "anchor_text": "available here"}, {"url": "https://www.kaggle.com/khulasasndh/game-of-thrones-books#005ssb.txt", "anchor_text": "on Kaggle here"}, {"url": "https://docs.python.org/3/library/re.html", "anchor_text": "Regex package"}, {"url": "https://www.dataquest.io/blog/regex-cheatsheet/", "anchor_text": "found here"}, {"url": "https://docs.python.org/3/howto/regex.html", "anchor_text": "here"}, {"url": "https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial", "anchor_text": "here"}, {"url": "https://www.w3schools.com/python/python_regex.asp", "anchor_text": "here"}, {"url": "https://developers.google.com/edu/python/regular-expressions", "anchor_text": "here"}, {"url": "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python", "anchor_text": "found here"}, {"url": "https://www.geeksforgeeks.org/python-nltk-tokenize-regexp/", "anchor_text": "peruse here"}, {"url": "https://python.gotrained.com/nltk-regex/", "anchor_text": "reference here"}, {"url": "https://www.datacamp.com/community/tutorials/wordcloud-python", "anchor_text": "found here"}, {"url": "https://www.mien.in/2017/10/02/visual-text-analytics-with-python/", "anchor_text": "different methods of visualization"}, {"url": "https://python.gotrained.com/frequency-distribution-in-nltk/", "anchor_text": "Frequency Distribution plot"}, {"url": "https://www.scikit-yb.org/en/latest/api/text/dispersion.html", "anchor_text": "Lexical dispersion plot"}, {"url": "https://towardsdatascience.com/a-game-of-words-vectorization-tagging-and-sentiment-analysis-c78ff9a07e42", "anchor_text": "here"}, {"url": "https://github.com/madelinemccombe/LaunchDS/blob/master/Regex_NLTK_GoT1.ipynb", "anchor_text": "here on github"}, {"url": "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk", "anchor_text": "https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"}, {"url": "https://www.datacamp.com/courses/natural-language-processing-fundamentals-in-python", "anchor_text": "https://www.datacamp.com/courses/natural-language-processing-fundamentals-in-python"}, {"url": "https://medium.com/tag/regex?source=post_page-----c13a0e2ee15c---------------regex-----------------", "anchor_text": "Regex"}, {"url": "https://medium.com/tag/python?source=post_page-----c13a0e2ee15c---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c13a0e2ee15c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c13a0e2ee15c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/text?source=post_page-----c13a0e2ee15c---------------text-----------------", "anchor_text": "Text"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&user=Madeline+McCombe&userId=a4a48b9cfaca&source=-----c13a0e2ee15c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&user=Madeline+McCombe&userId=a4a48b9cfaca&source=-----c13a0e2ee15c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc13a0e2ee15c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c13a0e2ee15c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c13a0e2ee15c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@madelinemccombe?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Madeline McCombe"}, {"url": "https://medium.com/@madelinemccombe/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "189 Followers"}, {"url": "http://www.linkedin.com/in/madelinemccombe", "anchor_text": "www.linkedin.com/in/madelinemccombe"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa4a48b9cfaca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&user=Madeline+McCombe&userId=a4a48b9cfaca&source=post_page-a4a48b9cfaca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc57fe1f09258&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-processing-is-coming-c13a0e2ee15c&newsletterV3=a4a48b9cfaca&newsletterV3Id=c57fe1f09258&user=Madeline+McCombe&userId=a4a48b9cfaca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}