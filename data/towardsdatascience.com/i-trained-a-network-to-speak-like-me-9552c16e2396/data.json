{"url": "https://towardsdatascience.com/i-trained-a-network-to-speak-like-me-9552c16e2396", "time": 1683000213.058172, "path": "towardsdatascience.com/i-trained-a-network-to-speak-like-me-9552c16e2396/", "webpage": {"metadata": {"title": "I trained a network to speak like me | by Ma\u00ebl Fabien | Towards Data Science", "h1": "I trained a network to speak like me", "description": "Over the course of the past few months, I wrote over 100 articles on my personal blog: https://maelfabien.github.io/. That\u2019s quite a decent amount of content. An idea then came to my mind: Or more\u2026"}, "outgoing_paragraph_urls": [{"url": "https://maelfabien.github.io/", "anchor_text": "https://maelfabien.github.io/", "paragraph_index": 0}, {"url": "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms", "anchor_text": "Kaggle Kernel", "paragraph_index": 4}], "all_paragraphs": ["Over the course of the past few months, I wrote over 100 articles on my personal blog: https://maelfabien.github.io/. That\u2019s quite a decent amount of content. An idea then came to my mind:", "\ud83d\ude80 Train a language generation model to speak like me. \ud83d\ude80", "Or more specifically, to write like me. This is the perfect way to illustrate the main concepts of language generation, its implementation using Keras, and the limits of my model.", "The whole code of this article can be found on this repository :", "Before we get started, I have found this Kaggle Kernel to be a useful resource to understand the structure of a language generation algorithm.", "Natural Language Generation is a field that aims to generate meaningful natural language.", "Most often, the content is generated as a sequence of individual words. For the big idea, here is how it works :", "The first step is to build a dataset that can be understood by the network we are later on going to build. Start by importing the following packages :", "The header of each and every article I have written follows this template :", "This is the type of content we would typically not like to have in our final dataset. We will instead focus on the text itself.", "All articles are written in a separate Markdown file. The header basically carries information regarding the title, the picture header and so on.", "First, we need to point to the folder that contains the articles, in my directory called \u201cmaelfabien.github.io\u201d.", "Then, open each article, and append the content of each article to a list. However, since our aim is to generate sentences and not whole articles, we will split each article into a list of sentences, and append each sentence to the list \u201call_sentences\u201d :", "Overall, we have a little more than 6'800 training sentences. The process so far is the following :", "Then, the idea is to create N-grams of words that occur together. To do so, we need to:", "It can be illustrated in the following way :", "Let\u2019s implement this. We first need to fit the tokenizer :", "The variable `total_words` contains the total number of different words that have been used. Here, 8976. Then, for each sentence, get the corresponding tokens and generate the N-grams :", "The `token_list` variable contains the sentence as a sequence of tokens :", "Then, the `n_gram_sequences` creates the n-grams. It starts with the first two words, and then gradually adds words :", "We are now facing the following problem: not all sequences have the same length! How can we solve this?", "We will use padding. Paddings adds sequences of 0\u2019s before each line of the variable `input_sequences` so that each line has the same length as the longest line.", "In order to pad all sentences to the maximum length of the sentences, we must first find the longest sentence :", "It is equal to 792 in my case. Well, that looks quite large for a single sentence! Since my blog contains some code and tutorials, I expect this single sentence to actually by Python code. Let\u2019s plot the histogram of the length of the sequences :", "There are indeed very few examples with 200 + words in a single sequence. How about setting the maximal sequence length to 200?", "We now have fixed-length arrays, most of them are filled with 0\u2019s before the actual sequence. Right, how do we turn that into a training set? We need to split X and y! Remember that our aim is to predict the next word of a sequence. We must, therefore, take all tokens except for the last one as our X, and take the last one as our y.", "In Python, it\u2019s as simple as that :", "We will now see this problem as a multi-class classification task. As usual, we must first one-hot encode the y to get a sparse matrix that contains a 1 in the column that corresponds to the token, and 0 elsewhere :", "In Python, using Keras Utils `to_categorical` :", "We have around 165'000 training samples. X is 199 columns wide since it corresponds to the longest sequence we allow (200 - 1, the label to predict). Y has 8976 columns, which corresponds to a sparse matrix of all the vocabulary words. The dataset is now ready!", "We will be using Long Short-Term Memory networks (LSTM). LSTM has the important advantage of being able to understand dependence over a whole sequence, and therefore, the beginning of a sentence might have an impact on the 15th word to predict. On the other hand, Recurrent Neural Networks (RNNs) only imply a dependence on the previous state of the network, and only the previous word would help predict the next one. We would quickly miss context if we chose RNNs, and therefore, LSTMs seem to be the right choice.", "Since the training can be very (very) (very) (very) (very) (no joke) long, we will build a simple 1 Embedding + 1 LSTM layer + 1 Dense network :", "First, we add an embedding layer. We pass that into an LSTM with 100 neurons, add a dropout to control neuron co-adaptation, and end with a dense layer. Notice that we apply a softmax activation function on the last layer to get the probability that the output belongs to each class. The loss used is the categorical cross-entropy, since it is a multi-class classification problem.", "The summary of the model is :", "We are now (finally) ready to train the model!", "The training of the model will then start :", "On a CPU, a single epoch takes around 8 minutes. On a GPU (e.g in Colab), you should modify the Keras LSTM network used since it cannot be used on GPU. You would instead need this :", "I tend to stop the training at several steps to make so sample predictions and control the quality of the model given several values of the cross-entropy.", "If you have read the article up to here, this is what you are expecting: generating new sentences! To generate sentences, we need to apply the same transformations to the input text. We will build a loop that generates for a given number of iterations the next word :", "When the loss is around 3.1, here is the sentence it generates with \u201cGoogle\u201d as an input :", "Google is a large amount of data produced worldwide", "It does not really mean anything, but it successfully associates Google to the notion of a large amount of data. It\u2019s quite impressive since it simply relies on the co-occurrence of words, and does not integrate any grammatical notion.", "\ud83d\ude80 If we wait a bit longer in the training and let the loss decrease to 2.5, and give it the input \u201cRandom Forest\u201d :", "Random Forest is a fully managed service distributed designed to support a large amount of startups vision infrastructure", "Again, there is no meaning in what is being generated, but the grammatical structure is rather correct.", "The loss diverges after approximately 50 epochs and never goes below 2.5.", "I think we hit the limits here of the approach developed :", "That being said, I find the results quite interesting, and the trained model can easily be deployed on a Flask WebApp for example.", "I hope this article was useful. I have tried to illustrate the main concepts, challenges, and limits of language generation. Larger networks and better data are definitely sources of improvement compared to the approach we discussed in this article. Please leave a comment if you have any question or remark :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9552c16e2396&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9552c16e2396--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mael4impact?source=post_page-----9552c16e2396--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mael4impact?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Ma\u00ebl Fabien"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fddcee06de4c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&user=Ma%C3%ABl+Fabien&userId=ddcee06de4c8&source=post_page-ddcee06de4c8----9552c16e2396---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/towards-data-science/inside-ai/home", "anchor_text": "Inside AI"}, {"url": "https://maelfabien.github.io/", "anchor_text": "https://maelfabien.github.io/"}, {"url": "https://github.com/maelfabien/Machine_Learning_Tutorials", "anchor_text": "maelfabien/Machine_Learning_TutorialsIn this repository, I'm uploading code, notebooks and articles from my personal blog : https://maelfabien.github.io/\u2026github.com"}, {"url": "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms", "anchor_text": "Kaggle Kernel"}, {"url": "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms", "anchor_text": "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms"}, {"url": "https://maelfabien.github.io/project/NLP_Gen/#generating-sequences", "anchor_text": "https://maelfabien.github.io/project/NLP_Gen/#generating-sequences"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9552c16e2396---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----9552c16e2396---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9552c16e2396---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9552c16e2396---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9552c16e2396---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&user=Ma%C3%ABl+Fabien&userId=ddcee06de4c8&source=-----9552c16e2396---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&user=Ma%C3%ABl+Fabien&userId=ddcee06de4c8&source=-----9552c16e2396---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9552c16e2396&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9552c16e2396---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9552c16e2396--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9552c16e2396--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9552c16e2396--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9552c16e2396--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9552c16e2396--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mael4impact?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mael4impact?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ma\u00ebl Fabien"}, {"url": "https://medium.com/@mael4impact/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "749 Followers"}, {"url": "http://biped.ai", "anchor_text": "biped.ai"}, {"url": "https://bento.me/mael4impact", "anchor_text": "https://bento.me/mael4impact"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fddcee06de4c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&user=Ma%C3%ABl+Fabien&userId=ddcee06de4c8&source=post_page-ddcee06de4c8--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc8a99819d6f0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fi-trained-a-network-to-speak-like-me-9552c16e2396&newsletterV3=ddcee06de4c8&newsletterV3Id=c8a99819d6f0&user=Ma%C3%ABl+Fabien&userId=ddcee06de4c8&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}