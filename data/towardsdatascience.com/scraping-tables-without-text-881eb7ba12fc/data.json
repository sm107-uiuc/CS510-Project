{"url": "https://towardsdatascience.com/scraping-tables-without-text-881eb7ba12fc", "time": 1683011287.7963579, "path": "towardsdatascience.com/scraping-tables-without-text-881eb7ba12fc/", "webpage": {"metadata": {"title": "Scraping Tables without Text. Sometimes the data you need is\u2026 | by Kate Christensen | Towards Data Science", "h1": "Scraping Tables without Text", "description": "The past two weeks I\u2019ve discussed how to scrape text from certain tables on Wikipedia. Two weeks ago, I showed how to scape parts of a table from Wikipedia here and last week, I showed how to scrape\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/scraping-from-all-over-wikipedia-4aecadcedf11?source=friends_link&sk=f5f047f39c7a4685afb39e67781cfc22", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://wikitable2csv.ggor.de/", "anchor_text": "this site", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)", "anchor_text": "season one of The Great British Bake Off", "paragraph_index": 1}], "all_paragraphs": ["The past two weeks I\u2019ve discussed how to scrape text from certain tables on Wikipedia. Two weeks ago, I showed how to scape parts of a table from Wikipedia here and last week, I showed how to scrape data from multiple pages here. This week, we\u2019re going to tackle a slightly different table related issue: colors.", "If you just wanted to scrape a full table from Wikipedia, you can easily just use this site to generate a csv file. Sure you can also do this in python using Requests and BeautifulSoup, but frankly, there\u2019s no need to reinvent the wheel when you\u2019ve got a perfectly viable option right there. However, this week we\u2019re going to be looking at the elimination chart for season one of The Great British Bake Off.", "First off, let\u2019s show why using that csv site won\u2019t work. When you run the url through the site and look at the csv generated for the elimination chart, this is what you get:", "And this is what the table looks like on the actual page:", "Obviously, the csv file fails to capture the colors on this chart, and as we see in the color key, those colors convey potentially valuable information:", "Therefore, we have to go into the code to get all the information. To start, as always, we\u2019re going to run the url through BeautifulSoup so we can go through the html:", "Now, we\u2019re going to isolate the elimination chart:", "These lines essentially say, \u201clook at all the tables, if the text \u2018Elimination Chart\u2019 is in the text of the header, that is what we\u2019re defining as \u2018elim_chart\u2019\u201d", "Next, we\u2019re going to make a list that contains the headers for each column. If we look at the chart, that list should look like this:", "To generate that list, here\u2019s the code:", "These lines essentially say, \u201cfor the items in the elimination chart that are tagged th, as long as the item\u2019s text does not start with \u2018Elim\u2019 (since we don\u2019t want to scrape the larger header of \u2018Elimination Chart\u2019), add each item\u2019s text to the header list\u201d The .rstrip() is added at the end because in the initial list, there was a newline character after the 6, and this can unnecessarily complicate matters.", "Switching gears, we\u2019re going to look at the color key and create a dictionary that we can use later on when creating our table.", "This line essentially scrapes all the info about the colors and the text assigned to them as displayed in the color key. By using re.compile when searching for text, you don\u2019t need to have an exact match, which can make your life a lot easier when you take potential invisible characters like spaces and newlines into account. From here, we dive into this list by doing the following:", "First, we create two lists, color_list, which is a list of all the colors that are in the color key, and meaning_text_list, which is a list of the text each color is assigned. We access the colors by doing re.split on the style part of each item in the meaning list, making the phrase right before the color, background-color:, a non-capture group, then capturing the word directly after it. From there, we make all the words in the color list all lowercase, to avoid any potential mismatches because of inconsistent capitalization. To get the text of each color meaning, we split the item\u2019s text and capture the words after the dash, then take the last item in the resulting list. From there we zip those two lists into one dictionary, full_text_meaning_dict:", "The one issue with this is that the values are far too long when processing data. There might be a way to more efficiently do this, but I just created the following list:", "Then I zipped that list and the color list to get this dictionary:", "Then I added the following entry, silver defined as not_in_comp (not in the competition), since it was not included in the color key, but will be necessary when looking at the table:", "From here we can turn back to our elimination table. Here\u2019s a reminder of what we\u2019re looking at:", "We\u2019ll be scraping this table by doing the following:", "That\u2019s a lot, so let\u2019s walk through it. First, we start by creating a row list. This row list will be a list of dictionaries, where the keys will be the headers and the values will be the info for each row.", "Then the next three lines, we start by finding all the names of the bakers, which is the first item in each row. From there we start a list, row, that contains the text of each item we\u2019ve accessed, which is the name. From there, we get the next six siblings of each name. These six siblings correspond to the six different columns representing contestant performance for each episode.", "From here, we look at each item in each row (line 7). For each item, we access the color of that item, and we have a col variable that is set equal to one. We have this col variable because sometimes, if a contestant gets the same outcome for two consecutive episodes (i.e. they\u2019re a judge favorite for two weeks in a row), the code will just say \u201ccreate a block of the judge favorite color that is two columns wide.\u201d However, this complicates matters when we\u2019re trying to recreate a table and we need six items for every row. Therefore, lines 12 and 13 say, \u201cIf the code specifies that the color block is wider than one column, make that col variable equal to the number of columns that block spans.\u201d Lines 15\u201317 then add that color to the row list by slicing the color variable created on line 9 so just the color name is accessed, then running that color through the dictionary we created that defines the meaning of each color, then multiplying that color by the col variable. This ensures that each row list we create is the same length and represents repeat outcomes. At the end, we get a row list that looks like this:", "From here, all we have to do to make this into an actual pandas table is the following:", "Note, I set the baker column as the index because that just made more sense to me. This code produces the following table:", "Now, this is just essentially directly scraping the table from the page. However, if you want to do any kind of analysis on this data, you\u2019re going to have to create dummy variables. If you\u2019re not sure what a dummy variable is, it essentially is a numeric way to represent categorical data (in this case how a contestant did on an episode). In pandas, there\u2019s a function called get_dummies. If we do this:", "A one in the first column represents if that person got eliminated on episode one, in the second column represents if that person was a judge favorite, and so on. However, say you want to focus the columns on when a contestant was a favorite or just got through to the next round. You would do this by flipping the data frame so the index became the columns, then doing the get_dummies function I showed previously. In code, the flipping looks like this:", "Then creating the dummy variables looks like this:", "From here, you now have data you can process and analyze (even though six rows may not be a lot of data to work with). And that is how we take colorful, non-textual table, and process it into actual valuable data.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F881eb7ba12fc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@katec125?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Kate Christensen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F103f2c837773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&user=Kate+Christensen&userId=103f2c837773&source=post_page-103f2c837773----881eb7ba12fc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@aridley88?utm_source=medium&utm_medium=referral", "anchor_text": "Andrew Ridley"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/using-beautifulsoup-on-wikipedia-dd0c620d5861?source=friends_link&sk=ba9fd2d3ddd3d5dc2fab2433f6848b81", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/scraping-from-all-over-wikipedia-4aecadcedf11?source=friends_link&sk=f5f047f39c7a4685afb39e67781cfc22", "anchor_text": "here"}, {"url": "https://wikitable2csv.ggor.de/", "anchor_text": "this site"}, {"url": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)", "anchor_text": "season one of The Great British Bake Off"}, {"url": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)", "anchor_text": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)"}, {"url": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)'", "anchor_text": "https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_1)'"}, {"url": "https://medium.com/tag/programming?source=post_page-----881eb7ba12fc---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/technology?source=post_page-----881eb7ba12fc---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/data-science?source=post_page-----881eb7ba12fc---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----881eb7ba12fc---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scraping?source=post_page-----881eb7ba12fc---------------scraping-----------------", "anchor_text": "Scraping"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&user=Kate+Christensen&userId=103f2c837773&source=-----881eb7ba12fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&user=Kate+Christensen&userId=103f2c837773&source=-----881eb7ba12fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F881eb7ba12fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----881eb7ba12fc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----881eb7ba12fc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@katec125?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kate Christensen"}, {"url": "https://medium.com/@katec125/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "129 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F103f2c837773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&user=Kate+Christensen&userId=103f2c837773&source=post_page-103f2c837773--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7f9729f0c45c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscraping-tables-without-text-881eb7ba12fc&newsletterV3=103f2c837773&newsletterV3Id=7f9729f0c45c&user=Kate+Christensen&userId=103f2c837773&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}