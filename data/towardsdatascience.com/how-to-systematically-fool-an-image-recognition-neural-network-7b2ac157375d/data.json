{"url": "https://towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d", "time": 1683014270.2956748, "path": "towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d/", "webpage": {"metadata": {"title": "How to Systematically Fool an Image Recognition Neural Network | by Andre Ye | Towards Data Science", "h1": "How to Systematically Fool an Image Recognition Neural Network", "description": "Convolutional neural networks \u2014 CNNs \u2014 form the basis for image recognition, which is undoubtedly one of the most important applications of deep learning. Unfortunately, much of research in deep\u2026"}, "outgoing_paragraph_urls": [{"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership", "paragraph_index": 29}], "all_paragraphs": ["Convolutional neural networks \u2014 CNNs \u2014 form the basis for image recognition, which is undoubtedly one of the most important applications of deep learning. Unfortunately, much of research in deep learning is done in the \u2018perfect-world\u2019 constraints of datasets in pursuit of a few percentage points in accuracy. Thus, we\u2019ve developed architectures that work tremendously well in theoretical tests but not necessarily so in the real world.", "Adversarial examples or inputs (think adversary: enemy) are indistinguishable from regular images to the human eye, but can completely fool a variety of image recognition architectures. There are clearly many unsettling and dangerous implications of adversarial inputs being deployed, especially as AI is given more power to make decisions for itself.", "Thus, it is important to understand and solve methods of systematically producing adversarial inputs \u2014 ethical hacking, applied to deep learning.", "One simple approach towards systematic generation of adversarial inputs is known as the \u2018fast gradient signed method\u2019, introduced by Goodfellow et al.", "In order to perform element-by-element multiplication and summing (e.g. [1,2,3] \u00d7 [1,2,3] = 1+4+9 = 14), we multiply the transpose of the first vector by the second vector. This will be referred to as the \u2018weighted sum\u2019.", "We have two goals here we must both achieve to generate an adversarial input:", "The solution introduced by Goodfellow et al. is two-pronged \u2014 and quite clever for a few reasons.", "\u03b7 is set to sign(w), where the sign function returns -1 for negative values, and 1 for positive values (0 for 0). If the weight is negative, it is multiplied by negative one to produce a positive sum; if the weight is positive, it is multiplied by positive one with no change.", "For example, if the weight vector was [3,-5,7], \u03b7 would be [1,-1,1]. The weighted sum is 3+5+7=15. Note that performing this operation essentially flips the negatives into positives and leaves the positives alone (abs() function). This means that every number is as large as it can be, and the highest possible weighted sum if weights are within the interval [-1, 1].", "Consider some \u2018images\u2019 below. Although they represented two-dimensionally, think of them just as one-dimensional vectors.", "The end sum is 10, which is a large departure from the original output, -7. Surely, this will screw up the network\u2019s predictions.", "This achieves the goal of making large changes, but it isn\u2019t very discreet at all. After all, our image has noticeably changed a lot when we perturb it:", "Remember that our earlier representation of the final sum as w(x) + w(\u03b7) where w() is the weighted sum and \u03b7 is the perbutation vector is really an expansion of w(x+\u03b7). We want to change each pixel\u2019s value slightly. While the total effect must be maximized, each element of \u03b7 must be small enough as to be unnoticeable.", "In the actual production of an adversarial input, pixel number j is defined as the jth value of x plus the jth value of \u03b7. The notation first introduced takes a bit of a shortcut to demonstrate the purpose of \u03b7, which is to heavily increase the collective sum, not necessarily individual pixel values.", "Each element of \u03b7 is fairly large: +1 or -1, which makes a big impact on properly scaled data. To solve this, we will multiply each element of \u03b7 by a signed \u03f5, where \u03f5 is the smallest numerical unit that sensors detect (or smaller). That number would be 256 for 8-bit colors, and hence \u03f5 = 1/255.", "Since \u03f5 is \u2018undetectable\u2019 (or just barely so), it should make no difference visually to the image. However, each change is built \u2014 following the sign function \u2014 such that the change in weighted sum is maximized.", "Hence, we add -\u03f5 or +\u03f5 to each element of the input vector, which is a small enough change such that it is undetectable but constructed with the sign function such that the change is maximized.", "Many small components can add up to be quite large, especially if they are constructed in a smart way.", "Let\u2019s consider the effect of this on our previous example with \u03f5=0.2. We are able to make a difference of 3 units (the sum of -4).", "This is quite substantial, especially considering the small change the perbutation vector has on the original input vector.", "If the weight vector has n dimensions and the average absolute value of an element is m, then the activation value will grow by \u03f5nm. In high-dimensional images (say 256 by 256 by 3), the value of n is 196608. m and \u03f5 can be very small, yet there will still be a substantial affect on the output.", "This method is very fast, since it only changes inputs by +\u03f5 or -\u03f5: but it does so in a way so effective it completely fools the neural network.", "Goodfellow et al. find interesting results when applying FGSM:", "Clearly, these adversarial inputs cause heavy error rates, but perhaps more concerning is a high confidence. Not only are the networks getting their predictions wrong; they\u2019re confident in their incorrect outputs. This is clearly problematic: imagine the difference in teaching a student who hesitantly answers 2\u00d74=6 versus one who proudly proclaims it.", "These adversarial inputs/examples can be explained as a property of high-dimensional dot products: when there is a large number of pixels for sums to be distributed among, the weighted sum can be larger and the change to each individual pixel smaller.", "In fact, adversarial examples are an effect of networks being too linear. After all, such changes would have little effect on, say, a network populated with sigmoid functions, since perbutations have diminishing effects in most locations. Ironically, it is this very trait \u2014 dying gradients \u2014 that populated the rise of ReLU and other unbounded functions prone to adversarial inputs.", "Additional points articulated in the paper included:", "It is becoming ever more important to step outside of the limiting and perfect-condition world of datasets and into the less orderly real world. By discovering effective strategies to fool our image recognition models, we can shield against them before they are used for more malicious purposes.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML enthusiast. Join Medium through my referral link: https://andre-ye.medium.com/membership."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7b2ac157375d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://andre-ye.medium.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006----7b2ac157375d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/1X8VQsDEyVU", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1412.6572.pdf", "anchor_text": "Goodfellow et al."}, {"url": "https://arxiv.org/pdf/1412.6572.pdf", "anchor_text": "Explaining and Harnessing Adversarial Examples (Goodfellow et al.)"}, {"url": "https://arxiv.org/pdf/1706.06083.pdf", "anchor_text": "Towards Deep Learning Models Resistant to Adversarial Attacks (Madry et al.)"}, {"url": "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm", "anchor_text": "TensorFlow Tutorial: Adversarial Examples with FGSM"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7b2ac157375d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7b2ac157375d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----7b2ac157375d---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7b2ac157375d---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7b2ac157375d---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&user=Andre+Ye&userId=be743a65b006&source=-----7b2ac157375d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&user=Andre+Ye&userId=be743a65b006&source=-----7b2ac157375d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7b2ac157375d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7b2ac157375d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7b2ac157375d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7b2ac157375d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7b2ac157375d--------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://andre-ye.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andre Ye"}, {"url": "https://andre-ye.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://andre-ye.medium.com/membership", "anchor_text": "https://andre-ye.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbe743a65b006&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&user=Andre+Ye&userId=be743a65b006&source=post_page-be743a65b006--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff44a966e4ff1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d&newsletterV3=be743a65b006&newsletterV3Id=f44a966e4ff1&user=Andre+Ye&userId=be743a65b006&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}