{"url": "https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b", "time": 1682993384.257386, "path": "towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b/", "webpage": {"metadata": {"title": "A Complete Machine Learning Walk-Through in Python: Part Three | by Will Koehrsen | Towards Data Science", "h1": "A Complete Machine Learning Walk-Through in Python: Part Three", "description": "Machine learning models are often criticized as black boxes: we put data in one side, and get out answers \u2014 often very accurate answers \u2014 with no explanations on the other. In the third part of this\u2026"}, "outgoing_paragraph_urls": [{"url": "https://datascience.stackexchange.com/questions/22335/why-are-machine-learning-models-called-black-boxes", "anchor_text": "black boxes", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420", "anchor_text": "Part one", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2", "anchor_text": "Part two", "paragraph_index": 1}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough", "anchor_text": "code for this project", "paragraph_index": 2}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb", "anchor_text": "third Jupyter Notebook, corresponding to this post, is here", "paragraph_index": 2}, {"url": "http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml", "anchor_text": "New York City building energy data", "paragraph_index": 3}, {"url": "http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/", "anchor_text": "Gradient Boosted Regressor", "paragraph_index": 3}, {"url": "https://2.bp.blogspot.com/-AL1LsaTHVNQ/Wh589GDwkaI/AAAAAAAAaxc/nwpqKEUIgXokRxt75nzgzQz00IRqH68PACLcBGAs/s1600/B2G1g0UIMAEieiR.png", "anchor_text": "scale of model interpretability", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_learning", "anchor_text": "decision trees", "paragraph_index": 4}, {"url": "https://pdfs.semanticscholar.org/ab4a/92795ee236632e6dbbe9338ae99778b57e1e.pdf", "anchor_text": "explain machine learning predictions", "paragraph_index": 5}, {"url": "https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf", "anchor_text": "measure the mean decrease impurity", "paragraph_index": 6}, {"url": "https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined", "anchor_text": "reduction in error from including the feature", "paragraph_index": 6}, {"url": "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html", "anchor_text": "extract the feature importances", "paragraph_index": 6}, {"url": "https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy", "anchor_text": "Energy Use Intensity", "paragraph_index": 8}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb", "anchor_text": "the Jupyter notebook", "paragraph_index": 8}, {"url": "http://parrt.cs.usfca.edu/doc/rf-importance/index.html", "anchor_text": "to be careful about reading too much into the feature importances", "paragraph_index": 9}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html", "anchor_text": "Scikit-Learn function", "paragraph_index": 10}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html", "anchor_text": "export_graphviz", "paragraph_index": 10}, {"url": "https://www.graphviz.org/", "anchor_text": "Graphviz visualization software", "paragraph_index": 11}, {"url": "https://towardsdatascience.com/overfitting-vs-underfitting-a-conceptual-explanation-d94ee20ca7f9", "anchor_text": "overfit to the training data", "paragraph_index": 17}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2", "anchor_text": "second article", "paragraph_index": 18}, {"url": "https://en.wikipedia.org/wiki/Flowchart", "anchor_text": "flowchart-based", "paragraph_index": 19}, {"url": "http://scikit-learn.org/stable/modules/ensemble.html", "anchor_text": "Decision-tree-based ensembles", "paragraph_index": 19}, {"url": "https://blog.statsbot.co/ensemble-learning-d1dcd548e936", "anchor_text": "Ensembles of trees tend to be very accurate", "paragraph_index": 19}, {"url": "https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime", "anchor_text": "LIME aims to explain a single prediction from any machine learning model", "paragraph_index": 20}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "full details can be found in the paper", "paragraph_index": 20}, {"url": "https://www.youtube.com/watch?v=hnSgIUA57hg", "anchor_text": "better decisions", "paragraph_index": 29}, {"url": "http://blog.kaggle.com/2016/06/29/communicating-data-science-a-guide-to-presenting-your-work/", "anchor_text": "clearly communicate the results", "paragraph_index": 30}, {"url": "http://jupyter.org/", "anchor_text": "Jupyter Notebooks", "paragraph_index": 31}, {"url": "https://github.com/ipython-contrib/jupyter_contrib_nbextensions", "anchor_text": "notebook extensions", "paragraph_index": 32}, {"url": "https://github.com/kirbs-/hide_code", "anchor_text": "hide the code from our final report", "paragraph_index": 32}, {"url": "http://sites.ieee.org/pcs/communication-resources-for-engineers/audience-purpose-and-context/understand-your-audience/", "anchor_text": "understand your audience", "paragraph_index": 33}, {"url": "https://hbr.org/2015/04/the-best-presentations-are-tailored-to-the-audience", "anchor_text": "tailor the message accordingly", "paragraph_index": 33}, {"url": "https://www.latex-project.org/", "anchor_text": "Latex", "paragraph_index": 34}, {"url": "https://www.texstudio.org/", "anchor_text": "texStudio", "paragraph_index": 34}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Building%20Data%20Report.pdf", "anchor_text": "final version", "paragraph_index": 34}, {"url": "https://en.wikipedia.org/wiki/Iteration", "anchor_text": "iterative rather than linear process", "paragraph_index": 37}, {"url": "https://twitter.com/koehrsen_will", "anchor_text": "@koehrsen_will", "paragraph_index": 39}], "all_paragraphs": ["Machine learning models are often criticized as black boxes: we put data in one side, and get out answers \u2014 often very accurate answers \u2014 with no explanations on the other. In the third part of this series showing a complete machine learning solution, we will peer into the model we developed to try and understand how it makes predictions and what it can teach us about the problem. We will wrap up by discussing perhaps the most important part of a machine learning project: documenting our work and presenting results.", "Part one of the series covered data cleaning, exploratory data analysis, feature engineering, and feature selection. Part two covered imputing missing values, implementing and comparing machine learning models, hyperparameter tuning using random search with cross validation, and evaluating a model.", "All the code for this project is on GitHub. The third Jupyter Notebook, corresponding to this post, is here. I encourage anyone to share, use, and build on this code!", "As a reminder, we are working through a supervised regression machine learning problem. Using New York City building energy data, we have developed a model which can predict the Energy Star Score of a building. The final model we built is a Gradient Boosted Regressor which is able to predict the Energy Star Score on the test data to within 9.1 points (on a 1\u2013100 scale).", "The gradient boosted regressor sits somewhere in the middle on the scale of model interpretability: the entire model is complex, but it is made up of hundreds of decision trees, which by themselves are quite understandable. We will look at three ways to understand how our model makes predictions:", "The first two methods are specific to ensembles of trees, while the third \u2014 as you might have guessed from the name \u2014 can be applied to any machine learning model. LIME is a relatively new package and represents an exciting step in the ongoing effort to explain machine learning predictions.", "Feature importances attempt to show the relevance of each feature to the task of predicting the target. The technical details of feature importances are complex (they measure the mean decrease impurity, or the reduction in error from including the feature), but we can use the relative values to compare which features are the most relevant. In Scikit-Learn, we can extract the feature importances from any ensemble of tree-based learners.", "With model as our trained model, we can find the feature importances usingmodel.feature_importances_ . Then we can put them into a pandas DataFrame and display or plot the top ten most important:", "The Site EUI(Energy Use Intensity) and the Weather Normalized Site Electricity Intensity are by far the most important features, accounting for over 66% of the total importance. After the top two features, the importance drops off significantly, which indicates we might not need to retain all 64 features in the data to achieve high performance. (In the Jupyter notebook, I take a look at using only the top 10 features and discover that the model is not quite as accurate.)", "Based on these results, we can finally answer one of our initial questions: the most important indicators of a building\u2019s Energy Star Score are the Site EUI and the Weather Normalized Site Electricity Intensity. While we do want to be careful about reading too much into the feature importances, they are a useful way to start to understand how the model makes its predictions.", "While the entire gradient boosting regressor may be difficult to understand, any one individual decision tree is quite intuitive. We can visualize any tree in the forest using the Scikit-Learn function export_graphviz. We first extract a tree from the ensemble then save it as a dot file:", "Using the Graphviz visualization software we can convert the dot file to a png from the command line:", "The result is a complete decision tree:", "This is a little overwhelming! Even though this tree only has a depth of 6 (the number of layers), it\u2019s difficult to follow. We can modify the call to export_graphviz and limit our tree to a more reasonable depth of 2:", "Each node (box) in the tree has four pieces of information:", "(Leaf nodes only have 2.\u20134. because they represent the final estimate and do not have any children).", "A decision tree makes a prediction for a data point by starting at the top node, called the root, and working its way down through the tree. At each node, a yes-or-no question is asked of the data point. For example, the question for the node above is: Does the building have a Site EUI less than or equal to 68.95? If the answer is yes, the building is placed in the right child node, and if the answer is no, the building goes to the left child node.", "This process is repeated at each layer of the tree until the data point is placed in a leaf node, at the bottom of the tree (the leaf nodes are cropped from the small tree image). The prediction for all the data points in a leaf node is the value. If there are multiple data points ( samples ) in a leaf node, they all get the same prediction. As the depth of the tree is increased, the error on the training set will decrease because there are more leaf nodes and the examples can be more finely divided. However, a tree that is too deep will overfit to the training data and will not be able to generalize to new testing data.", "In the second article, we tuned a number of the model hyperparameters, which control aspects of each tree such as the maximum depth of the tree and the minimum number of samples required in a leaf node. These both have a significant impact on the balance of under vs over-fitting, and visualizing a single decision tree allows us to see how these settings work.", "Although we cannot examine every tree in the model, looking at one lets us understand how each individual learner makes a prediction. This flowchart-based method seems much like how a human makes decisions, answering one question about a single value at a time. Decision-tree-based ensembles combine the predictions of many individual decision trees in order to create a more accurate model with less variance. Ensembles of trees tend to be very accurate, and also are intuitive to explain.", "The final tool we will explore for trying to understand how our model \u201cthinks\u201d is a new entry into the field of model explanations. LIME aims to explain a single prediction from any machine learning model by creating a approximation of the model locally near the data point using a simple model such as linear regression (the full details can be found in the paper ).", "Here we will use LIME to examine a prediction the model gets completely wrong to see what it might tell us about why the model makes mistakes.", "First we need to find the observation our model gets most wrong. We do this by training and predicting with the model and extracting the example on which the model has the greatest error:", "Next, we create the LIME explainer object passing it our training data, the mode, the training labels, and the names of the features in our data. Finally, we ask the explainer object to explain the wrong prediction, passing it the observation and the prediction function.", "The plot explaining this prediction is below:", "Here\u2019s how to interpret the plot: Each entry on the y-axis indicates one value of a variable and the red and green bars show the effect this value has on the prediction. For example, the top entry says the Site EUI is greater than 95.90 which subtracts about 40 points from the prediction. The second entry says the Weather Normalized Site Electricity Intensity is less than 3.80 which adds about 10 points to the prediction. The final prediction is an intercept term plus the sum of each of these individual contributions.", "We can get another look at the same information by calling the explainer .show_in_notebook() method:", "This shows the reasoning process of the model on the left by displaying the contributions of each variable to the prediction. The table on the right shows the actual values of the variables for the data point.", "For this example, the model prediction was about 12 and the actual value was 100! While initially this prediction may be puzzling, looking at the explanation, we can see this was not an extreme guess, but a reasonable estimate given the values for the data point. The Site EUI was relatively high and we would expect the Energy Star Score to be low (because EUI is strongly negatively correlated with the score), a conclusion shared by our model. In this case, the logic was faulty because the building had a perfect score of 100.", "It can be frustrating when a model is wrong, but explanations such as these help us to understand why the model is incorrect. Moreover, based on the explanation, we might want to investigate why the building has a perfect score despite such a high Site EUI. Perhaps we can learn something new about the problem that would have escaped us without investigating the model. Tools such as this are not perfect, but they go a long way towards helping us understand the model which in turn can allow us to make better decisions.", "An often under-looked part of any technical project is documentation and reporting. We can do the best analysis in the world, but if we do not clearly communicate the results, then they will not have any impact!", "When we document a data science project, we take all the versions of the data and code and package it so it our project can be reproduced or built on by other data scientists. It\u2019s important to remember that code is read more often than it is written, and we want to make sure our work is understandable both for others and for ourselves if we come back to it a few months later. This means putting in helpful comments in the code and explaining your reasoning. I find Jupyter Notebooks to be a great tool for documentation because they allow for explanations and code one after the other.", "Jupyter Notebooks can also be a good platform for communicating findings to others. Using notebook extensions, we can hide the code from our final report , because although it\u2019s hard to believe, not everyone wants to see a bunch of Python code in a document!", "Personally, I struggle with succinctly summarizing my work because I like to go through all the details. However, it\u2019s important to understand your audience when you are presenting and tailor the message accordingly. With that in mind, here is my 30-second takeaway from the project:", "Originally, I was given this project as a job-screening \u201cassignment\u201d by a start-up. For the final report, they wanted to see both my work and my conclusions, so I developed a Jupyter Notebook to turn in. However, instead of converting directly to PDF in Jupyter, I converted it to a Latex .tex file that I then edited in texStudio before rendering to a PDF for the final version. The default PDF output from Jupyter has a decent appearance, but it can be significantly improved with a few minutes of editing. Moreover, Latex is a powerful document preparation system and it\u2019s good to know the basics.", "At the end of the day, our work is only as valuable as the decisions it enables, and being able to present results is a crucial skill. Furthermore, by properly documenting work, we allow others to reproduce our results, give us feedback so we can become better data scientists, and build on our work for the future.", "Throughout this series of posts, we\u2019ve walked through a complete end-to-end machine learning project. We started by cleaning the data, moved into model building, and finally looked at how to interpret a machine learning model. As a reminder, the general structure of a machine learning project is below:", "While the exact steps vary by project, and machine learning is often an iterative rather than linear process, this guide should serve you well as you tackle future machine learning projects. I hope this series has given you confidence to be able to implement your own machine learning solutions, but remember, none of us do this by ourselves! If you want any help, there are many incredibly supportive communities where you can look for advice.", "A few resources I have found helpful throughout my learning process:", "As always, I welcome feedback and discussion and can be reached on Twitter @koehrsen_will.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist at Cortex Intel, Data Science Communicator"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F388834e8804b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9----388834e8804b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://datascience.stackexchange.com/questions/22335/why-are-machine-learning-models-called-black-boxes", "anchor_text": "black boxes"}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420", "anchor_text": "Part one"}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2", "anchor_text": "Part two"}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough", "anchor_text": "code for this project"}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb", "anchor_text": "third Jupyter Notebook, corresponding to this post, is here"}, {"url": "http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml", "anchor_text": "New York City building energy data"}, {"url": "http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/", "anchor_text": "Gradient Boosted Regressor"}, {"url": "https://2.bp.blogspot.com/-AL1LsaTHVNQ/Wh589GDwkaI/AAAAAAAAaxc/nwpqKEUIgXokRxt75nzgzQz00IRqH68PACLcBGAs/s1600/B2G1g0UIMAEieiR.png", "anchor_text": "scale of model interpretability"}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_learning", "anchor_text": "decision trees"}, {"url": "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html", "anchor_text": "Feature importances"}, {"url": "https://github.com/marcotcr/lime", "anchor_text": "LIME: Local Interpretable Model-Agnostic Explainations"}, {"url": "https://pdfs.semanticscholar.org/ab4a/92795ee236632e6dbbe9338ae99778b57e1e.pdf", "anchor_text": "explain machine learning predictions"}, {"url": "https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf", "anchor_text": "measure the mean decrease impurity"}, {"url": "https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined", "anchor_text": "reduction in error from including the feature"}, {"url": "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html", "anchor_text": "extract the feature importances"}, {"url": "https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy", "anchor_text": "Energy Use Intensity"}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb", "anchor_text": "the Jupyter notebook"}, {"url": "http://parrt.cs.usfca.edu/doc/rf-importance/index.html", "anchor_text": "to be careful about reading too much into the feature importances"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html", "anchor_text": "Scikit-Learn function"}, {"url": "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html", "anchor_text": "export_graphviz"}, {"url": "https://www.graphviz.org/", "anchor_text": "Graphviz visualization software"}, {"url": "https://towardsdatascience.com/overfitting-vs-underfitting-a-conceptual-explanation-d94ee20ca7f9", "anchor_text": "overfit to the training data"}, {"url": "https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2", "anchor_text": "second article"}, {"url": "https://en.wikipedia.org/wiki/Flowchart", "anchor_text": "flowchart-based"}, {"url": "http://scikit-learn.org/stable/modules/ensemble.html", "anchor_text": "Decision-tree-based ensembles"}, {"url": "https://blog.statsbot.co/ensemble-learning-d1dcd548e936", "anchor_text": "Ensembles of trees tend to be very accurate"}, {"url": "https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime", "anchor_text": "LIME aims to explain a single prediction from any machine learning model"}, {"url": "https://arxiv.org/pdf/1602.04938.pdf", "anchor_text": "full details can be found in the paper"}, {"url": "https://www.youtube.com/watch?v=hnSgIUA57hg", "anchor_text": "better decisions"}, {"url": "http://blog.kaggle.com/2016/06/29/communicating-data-science-a-guide-to-presenting-your-work/", "anchor_text": "clearly communicate the results"}, {"url": "http://jupyter.org/", "anchor_text": "Jupyter Notebooks"}, {"url": "https://github.com/ipython-contrib/jupyter_contrib_nbextensions", "anchor_text": "notebook extensions"}, {"url": "https://github.com/kirbs-/hide_code", "anchor_text": "hide the code from our final report"}, {"url": "http://sites.ieee.org/pcs/communication-resources-for-engineers/audience-purpose-and-context/understand-your-audience/", "anchor_text": "understand your audience"}, {"url": "https://hbr.org/2015/04/the-best-presentations-are-tailored-to-the-audience", "anchor_text": "tailor the message accordingly"}, {"url": "https://www.latex-project.org/", "anchor_text": "Latex"}, {"url": "https://www.texstudio.org/", "anchor_text": "texStudio"}, {"url": "https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Building%20Data%20Report.pdf", "anchor_text": "final version"}, {"url": "https://en.wikipedia.org/wiki/Iteration", "anchor_text": "iterative rather than linear process"}, {"url": "http://shop.oreilly.com/product/0636920052289.do", "anchor_text": "Hands-On Machine Learning with Scikit-Learn and Tensorflow"}, {"url": "https://github.com/ageron/handson-ml", "anchor_text": "Jupyter Notebooks for this book"}, {"url": "http://www-bcf.usc.edu/~gareth/ISL/", "anchor_text": "An Introduction to Statistical Learning"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle: The Home of Data Science and Machine Learning"}, {"url": "https://www.datacamp.com/", "anchor_text": "Datacamp"}, {"url": "https://www.coursera.org/", "anchor_text": "Coursera"}, {"url": "https://www.udacity.com/", "anchor_text": "Udacity"}, {"url": "https://twitter.com/koehrsen_will", "anchor_text": "@koehrsen_will"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----388834e8804b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----388834e8804b---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/education?source=post_page-----388834e8804b---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/tag/data-science?source=post_page-----388834e8804b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----388834e8804b---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----388834e8804b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&user=Will+Koehrsen&userId=e2f299e30cb9&source=-----388834e8804b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F388834e8804b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----388834e8804b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----388834e8804b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----388834e8804b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----388834e8804b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----388834e8804b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----388834e8804b--------------------------------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://williamkoehrsen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://williamkoehrsen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "38K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe2f299e30cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&user=Will+Koehrsen&userId=e2f299e30cb9&source=post_page-e2f299e30cb9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe7d4a87a913e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-machine-learning-walk-through-in-python-part-three-388834e8804b&newsletterV3=e2f299e30cb9&newsletterV3Id=e7d4a87a913e&user=Will+Koehrsen&userId=e2f299e30cb9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}