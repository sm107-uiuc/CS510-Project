{"url": "https://towardsdatascience.com/what-is-a-markov-decision-process-anyways-bdab65fd310c", "time": 1683004558.860131, "path": "towardsdatascience.com/what-is-a-markov-decision-process-anyways-bdab65fd310c/", "webpage": {"metadata": {"title": "What is a Markov Decision Process Anyways? | by Nathan Lambert | Towards Data Science", "h1": "What is a Markov Decision Process Anyways?", "description": "Anyone interested in the growth of reinforcement learning should know the model they\u2019re built on \u2014 Markov Decision Processes. They set up the structure of a world with uncertainty in where actions\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Graph_traversal", "anchor_text": "graph search", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Game_tree", "anchor_text": "game trees", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning", "anchor_text": "alpha-beta pruning", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Minimax", "anchor_text": "minimax search", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Expectiminimax", "anchor_text": "expectimax search", "paragraph_index": 1}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec12.pdf", "anchor_text": "here\u2019s a lecture on convergence of MDP solutions", "paragraph_index": 17}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/", "anchor_text": "here", "paragraph_index": 19}, {"url": "http://ai.berkeley.edu/home.html", "anchor_text": "here", "paragraph_index": 19}, {"url": "http://robotic.substack.com", "anchor_text": "robotic.substack.com", "paragraph_index": 22}, {"url": "http://natolambert.com", "anchor_text": "natolambert.com", "paragraph_index": 22}], "all_paragraphs": ["Anyone interested in the growth of reinforcement learning should know the model they\u2019re built on \u2014 Markov Decision Processes. They set up the structure of a world with uncertainty in where actions will take you, and agents need to learn how to act.", "Search is a central problem to artificial intelligence and intelligent agents. By planning into the future, search allows agents to solve games and logistical problems \u2014 but they rely on knowing where a certain action will take you. In traditional, tree-based methods, an action takes you to a next state, there is no distribution of next-states. That means, if you have the storage for it, you can plan set, deterministic trajectories into the future. Markov Decision Processes make this planning stochastic, or non-deterministic. The list of topics in search related to this article is long \u2014 graph search, game trees, alpha-beta pruning, minimax search, expectimax search, etc.", "In the real world, this is a far better model for how agents act. Every simple action we take \u2014 pouring the coffee, sending a letter, moving a joint \u2014 has an expected outcome, but there is a sort of randomness to life. Markov Decision Processes are the tool that makes planning capture this uncertainty.", "Markov is all about Andrey Markov \u2014 a famous Russian mathematician most known for his work on stochastic processes.", "\u201cMarkov\u201d generally means that given the present state, the future and the past are independent.", "The key idea of making a Markovian system is memorylessness. Memorylessness is the idea that the history of a system does not impact the current state. In probability notation, memorylessness translates into this. Consider a sequence of actions yields a trajectory, and we are looking to see where the current action will take us. The long conditional probability could look like:", "Now \u2014 if the system is Markovian, the history is all encompassed in the current state. So, our one step distribution is far simpler.", "This one step is a game-changer for computational efficiency. The Markov Property underpins the existence and success of all modern reinforcement learning algorithms.", "An MDP is defined by the following quantities:", "This definition gives us a finite world, we a set forward dynamics model. We know the exact probabilities for each transition, and how good each action is. Ultimately, this model is a scenario \u2014 a scenario where we will plan how to act knowing that our actions may go slightly awry.", "If the robot is next to the fire pit, should the robot always choose North knowing that there\u2019s a chance that North will send it East?", "No \u2014 the optimal policy will be West. Going into the wall will eventually (20% chance) go North, and put the robot on track for the goal.", "Learning how to act in an unknown environment is the final goal of understanding an environment. In MDPs, this is called the policy.", "A policy is a function that gives you an action from a state. \u03c0*: S \u2192 A.", "There are many methods of getting to a policy, but the core ideas are value and policy iteration. Both of these methods iteratively build estimates for the total utility of a state, and maybe an action.", "The Utility of a state is the sum of (discounted) rewards.", "Once every state has a utility, planning and policy generation at a high level becomes following the line of maximum utility.", "In MDPs and other learning approaches, the models add a discount factor \u03b3 to prioritize near term to long term rewards. The discount factor makes sense intuitively \u2014 humans and biological creates value money (or food) in hand now more than later. The discount factor also carries with it immense computational convergence help by changing the sum\u2019s of rewards into a geometric series. (If you\u2019re interested, here\u2019s a lecture on convergence of MDP solutions).", "I leave it as an exercise for the reader to figure out the optimal policy for this example \u2014 think about what the terminal state would be. Can we avoid it? Learning how to get these policies is left for another article.", "More in the works for introductions to reinforcement learning \u2014 you can also find course materials here or here. A couple more articles from me, below.", "More? Subscribe to my newsletter on robotics, artificial intelligence, and society!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Trying to think freely and create equitable & impactful automation @ UCBerkeley EECS. Subscribe directly at robotic.substack.com. More at natolambert.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbdab65fd310c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://natolambert.medium.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Nathan Lambert"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890b1765e6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&user=Nathan+Lambert&userId=890b1765e6d&source=post_page-890b1765e6d----bdab65fd310c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Graph_traversal", "anchor_text": "graph search"}, {"url": "https://en.wikipedia.org/wiki/Game_tree", "anchor_text": "game trees"}, {"url": "https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning", "anchor_text": "alpha-beta pruning"}, {"url": "https://en.wikipedia.org/wiki/Minimax", "anchor_text": "minimax search"}, {"url": "https://en.wikipedia.org/wiki/Expectiminimax", "anchor_text": "expectimax search"}, {"url": "https://www.pexels.com/@mhtoori?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "mhtoori .com"}, {"url": "https://www.pexels.com/photo/aerial-photography-of-concrete-road-1646164/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://en.wikipedia.org/wiki/Andrey_Markov", "anchor_text": "Andrey Markov (1856\u20131922)."}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec10.pdf", "anchor_text": "lecture"}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec12.pdf", "anchor_text": "here\u2019s a lecture on convergence of MDP solutions"}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/assets/lecture/lec10.pdf", "anchor_text": "lecture"}, {"url": "https://inst.eecs.berkeley.edu/~cs188/sp20/", "anchor_text": "here"}, {"url": "http://ai.berkeley.edu/home.html", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/the-hidden-linear-algebra-of-reinforcement-learning-406efdf066a", "anchor_text": "The hidden linear algebra of reinforcement learningHow do fundamentals of linear algebra support the pinnacles of deep reinforcement learning?towardsdatascience.com"}, {"url": "https://towardsdatascience.com/convergence-of-reinforcement-learning-algorithms-3d917f66b3b7", "anchor_text": "Convergence of Reinforcement Learning AlgorithmsAre there any simple bounds one can put on convergence?towardsdatascience.com"}, {"url": "https://towardsdatascience.com/fundamental-iterative-methods-of-reinforcement-learning-df8ff078652a", "anchor_text": "Fundamental Iterative Methods of Reinforcement LearningHow much can you master of reinforcement learning by studying Value and Policy Iteration? A lot.towardsdatascience.com"}, {"url": "https://robotic.substack.com/", "anchor_text": "Democratizing AutomationA blog about robots & artificial intelligence, making them beneficial for everyone, and the coming automation wave\u2026robotic.substack.com"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bdab65fd310c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/math?source=post_page-----bdab65fd310c---------------math-----------------", "anchor_text": "Math"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----bdab65fd310c---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----bdab65fd310c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----bdab65fd310c---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&user=Nathan+Lambert&userId=890b1765e6d&source=-----bdab65fd310c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&user=Nathan+Lambert&userId=890b1765e6d&source=-----bdab65fd310c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbdab65fd310c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bdab65fd310c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bdab65fd310c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bdab65fd310c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bdab65fd310c--------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://natolambert.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nathan Lambert"}, {"url": "https://natolambert.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "653 Followers"}, {"url": "http://robotic.substack.com", "anchor_text": "robotic.substack.com"}, {"url": "http://natolambert.com", "anchor_text": "natolambert.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F890b1765e6d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&user=Nathan+Lambert&userId=890b1765e6d&source=post_page-890b1765e6d--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F15278b7ad062&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-is-a-markov-decision-process-anyways-bdab65fd310c&newsletterV3=890b1765e6d&newsletterV3Id=15278b7ad062&user=Nathan+Lambert&userId=890b1765e6d&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}