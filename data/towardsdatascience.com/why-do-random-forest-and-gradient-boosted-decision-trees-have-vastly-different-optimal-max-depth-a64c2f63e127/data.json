{"url": "https://towardsdatascience.com/why-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127", "time": 1683003154.5528162, "path": "towardsdatascience.com/why-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127/", "webpage": {"metadata": {"title": "Why do Random Forest and Gradient Boosted Decision Trees have vastly different optimal max_depth? | by Wanshun Wong | Towards Data Science", "h1": "Why do Random Forest and Gradient Boosted Decision Trees have vastly different optimal max_depth?", "description": "Since the introduction of XGBoost in 2014, Gradient Boosted Decision Trees (GBDT) has gained a lot of popularity due to its predictive power and its ease-of-use. In particular, it has dethroned\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting", "anchor_text": "scikit-learn", "paragraph_index": 0}], "all_paragraphs": ["Since the introduction of XGBoost in 2014, Gradient Boosted Decision Trees (GBDT) has gained a lot of popularity due to its predictive power and its ease-of-use. In particular, it has dethroned Random Forest and become arguably the best algorithm for heterogeneous tabular data. Nowadays many data scientists are familiar with at least one of the implementations of GBDT, such as XGBoost, LightGBM, CatBoost, or even scikit-learn.", "However, those of us who have experience with Random Forest might find it surprising that Random Forest and GBDT have vastly different optimal hyperparameters, even though both are collections of Decision Trees. In particular, they differ hugely in max_depth which is one of the most important hyperparameters. Random Forest usually have max_depth \u2265 15, while for GBDT it is typically 4 \u2264 max_depth \u2264 8. In this article we will look into the cause for this discrepancy.", "We briefly recall the bias-variance tradeoff property. The expected loss of a model can be decomposed into three components: bias, variance, and noise.", "Ideally we want to minimize both bias and variance, but usually it cannot be done simultaneously. Hence there is a tradeoff between bias and variance. For example, making our model more expressive will decrease the bias but will increase the variance.", "Decision Tree is an excellent base learner for ensemble methods because it can perform bias-variance tradeoff easily by simply tuning max_depth. The reason is that Decision Tree is very good at capturing interactions among different features, and the order of interactions captured by a tree is controlled by its max_depth. For example, max_depth = 2 means interactions between 2 features are captured, but interactions among 3 features are not.", "Another way to look at bias-variance tradeoff via tuning max_depth is by estimating the number of leaf nodes. A decision tree can have at most 2^max_depth leaf nodes. The more leaf nodes, the higher capacity a tree has to partition different data points.", "Random Forest uses a modification of bagging to build de-correlated trees and then averages the output. As these trees are identically distributed, the bias of Random Forest is the same as that of any individual tree. Therefore we want trees in Random Forest to have low bias.", "On the other hand, it is fine for these trees to have high variance individually. This is because averaging the trees reduces variance. Combining these two results we end up with deep trees which have low bias and high variance.", "Gradient Boosting builds trees in a sequential manner. Roughly speaking, it tries to reduce the loss of the ensemble by fitting a new tree to the negative gradients of the loss function, thus effectively performing gradient descent. Every time the ensemble adds a new tree, its model complexity increases and its overall bias decreases, even if the new tree is quite simple.", "On the other hand, while there isn\u2019t much theoretical study on the variance of Gradient Boosting, empirical results show that the variance of the ensemble is not effectively reduced over the boosting process. Therefore for GBDT we use shallow trees with high bias and low variance.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa64c2f63e127&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@wanshunwong?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanshunwong?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Wanshun Wong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb145fb04b8bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&user=Wanshun+Wong&userId=b145fb04b8bd&source=post_page-b145fb04b8bd----a64c2f63e127---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@k15hore?utm_source=medium&utm_medium=referral", "anchor_text": "Kishore Ragav Ganesh Kumar"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting", "anchor_text": "scikit-learn"}, {"url": "https://devblogs.nvidia.com/bias-variance-decompositions-using-xgboost/", "anchor_text": "This"}, {"url": "https://homes.cs.washington.edu/~pedrod/papers/mlc00a.pdf", "anchor_text": "A Unified Bias-Variance Decomposition and its Applications"}, {"url": "https://medium.com/tag/random-forest?source=post_page-----a64c2f63e127---------------random_forest-----------------", "anchor_text": "Random Forest"}, {"url": "https://medium.com/tag/xgboost?source=post_page-----a64c2f63e127---------------xgboost-----------------", "anchor_text": "Xgboost"}, {"url": "https://medium.com/tag/lightgbm?source=post_page-----a64c2f63e127---------------lightgbm-----------------", "anchor_text": "Lightgbm"}, {"url": "https://medium.com/tag/bias-variance-tradeoff?source=post_page-----a64c2f63e127---------------bias_variance_tradeoff-----------------", "anchor_text": "Bias Variance Tradeoff"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&user=Wanshun+Wong&userId=b145fb04b8bd&source=-----a64c2f63e127---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&user=Wanshun+Wong&userId=b145fb04b8bd&source=-----a64c2f63e127---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa64c2f63e127&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a64c2f63e127---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a64c2f63e127--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a64c2f63e127--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a64c2f63e127--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanshunwong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@wanshunwong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Wanshun Wong"}, {"url": "https://medium.com/@wanshunwong/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "263 Followers"}, {"url": "https://www.linkedin.com/in/wanshunwong/", "anchor_text": "https://www.linkedin.com/in/wanshunwong/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb145fb04b8bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&user=Wanshun+Wong&userId=b145fb04b8bd&source=post_page-b145fb04b8bd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa149bfd5dd79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-do-random-forest-and-gradient-boosted-decision-trees-have-vastly-different-optimal-max-depth-a64c2f63e127&newsletterV3=b145fb04b8bd&newsletterV3Id=a149bfd5dd79&user=Wanshun+Wong&userId=b145fb04b8bd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}