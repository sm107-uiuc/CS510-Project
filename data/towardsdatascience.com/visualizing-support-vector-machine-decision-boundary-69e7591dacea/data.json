{"url": "https://towardsdatascience.com/visualizing-support-vector-machine-decision-boundary-69e7591dacea", "time": 1682997154.848892, "path": "towardsdatascience.com/visualizing-support-vector-machine-decision-boundary-69e7591dacea/", "webpage": {"metadata": {"title": "Principal Component Analysis and SVM in a Pipeline with Python | by Saptashwa Bhattacharyya | Towards Data Science", "h1": "Principal Component Analysis and SVM in a Pipeline with Python", "description": "In a previous post I have described about principal component analysis (PCA) in detail and, the mathematics behind support vector machine (SVM) algorithm in another. Here, I will combine SVM, PCA\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/dive-into-pca-principal-component-analysis-with-python-43ded13ead21", "anchor_text": "principal component analysis", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-1-lagrange-multipliers-5c24a52ffc5e", "anchor_text": "mathematics behind support vector machine (SVM) algorithm", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "scikit-learn cancer data-set", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/data-handling-using-pandas-cleaning-and-processing-3aa657dc9418", "anchor_text": "no missing data", "paragraph_index": 2}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn library", "paragraph_index": 3}, {"url": "https://seaborn.pydata.org/generated/seaborn.jointplot.html", "anchor_text": "seaborn jointplot", "paragraph_index": 4}, {"url": "https://mathisonian.github.io/kde/", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976", "anchor_text": "I wrote separately", "paragraph_index": 14}, {"url": "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976", "anchor_text": "my other post", "paragraph_index": 15}, {"url": "https://scikit-learn.org/0.20/auto_examples/svm/plot_iris.html", "anchor_text": "maximum margin separating hyperplane", "paragraph_index": 16}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function", "anchor_text": "decision function", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-1-lagrange-multipliers-5c24a52ffc5e", "anchor_text": "my previous post", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-2-kernel-trick-mercers-theorem-e1e6848c6c4d", "anchor_text": "other post on SVM kernels", "paragraph_index": 21}, {"url": "https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka-ebook/dp/B00YSILNL0", "anchor_text": "Machine Learning with Python", "paragraph_index": 25}, {"url": "https://github.com/suvoooo/Machine_Learning/tree/master/SVM_Decision_Boundary", "anchor_text": "Github", "paragraph_index": 26}], "all_paragraphs": ["In a previous post I have described about principal component analysis (PCA) in detail and, the mathematics behind support vector machine (SVM) algorithm in another. Here, I will combine SVM, PCA, and Grid-search Cross-Validation to create a pipeline to find best parameters for binary classification and eventually plot a decision boundary to present how good our algorithm has performed. What you expect to learn/review in this post \u2014", "Here, I have used scikit-learn cancer data-set, relatively easy data-set for studying binary classification, with 2 classes being Malignant and Benign. Let\u2019s look at the few rows of the data-frames.", "As we can see there are total 569 samples and 30 features in the data-set and, our task is to classify malignant samples from benign samples. After checking that there are no missing data, we check the feature names and check correlation plots of the mean features.", "Below is the correlation plot of mean features potted using seaborn library. As expected \u2018area\u2019, \u2018perimeter\u2019, and \u2018radius\u2019 are highly correlated.", "We can use \u2018seaborn jointplot\u2019 to understand relationship between individual features. Let\u2019s see 2 examples below, where as an alternative of scatter plots, I have opted for 2D density plots. On the right panel, I used \u2018hex\u2019 setting, where along with histograms, we can understand the concentration of number of points in a small hexagonal area. Darker the hexagon, more number of points (observations) fall in that region and this intuition can also be checked with the histograms plotted on the boundaries for the 2 features.", "On the left, apart from the histogram of individual features that are plotted on the boundaries, the contours are representing the 2D kernel density estimation (KDE). Instead of just discrete histograms, KDE\u2019s are often useful and, you can find one fantastic explanation here.", "We can also plot some pair plots to study which features are kind of \u2018 more relevant \u2019 to classify malignant from benign samples. Let\u2019s see one example below \u2014", "Once we have played enough with the data-set to explore and understand what we have got in hand, then, let\u2019s move towards the main classification task.", "Now we will create a pipeline using StandardScaler, PCA and Support Vector Machine following the steps below \u2014", "Let\u2019s plot the cancer-data for these selected 4 principal components \u2014", "As you can see in the plots, first 2 principal components are more relevant to separate malignant and benign samples. How about the variance ratio?", "As expected, first 2 components are contributing for ~80% of the total variance. This is relevant to show before choosing 2 components for plotting the decision boundary because, you may have some data-set with many features where choosing 2 principal components is not justified in terms of percentage variance ratio. It is always a good check before you create pipeline with PCA and some classifier to justify the choice of 2 principal components.", "2.2. Pipeline & Grid-Search Cross Validation:", "Once we have seen how important PCA is for classification and plotting decision boundary for the classifier, now, we create a pipeline with StandardScaler, PCA and SVM.", "You can check more about Pipeline and Grid-Search Cross Validation in details, that I wrote separately. I chose 2 principal components because, our goal is to draw decision boundary in a 2D/3D plot and, the best parameters \u2018C\u2019 and \u2018Gamma\u2019 for SVM with radial basis function kernel are obtained with a fix value of number principal components. Let\u2019s check the fit parameters \u2014", "Here, we see that using 2 principal components and 4 fold cross-validation our pipeline with SVM classifier obtained 94% accuracy. You can of course play around with various values or maybe use a different kernel. For more on mathematics behind kernel function, you can check my other post. Before moving on to the next section, we can complete the analysis by plotting the confusion matrix, from which, one can obtain precision, recall and F1 score.", "I have followed Scikit-Learn\u2019s tutorial to plot maximum margin separating hyperplane, but instead of linear kernel as used in the tutorial, radial basis function kernel is used here. We are going to use decision function method which returns the decision function of the sample for each class in the sample. Intuitively, for binary classification, we can think of this method as if it tells us on which side and how far of the hyperplane generated by the classifier, we are. For the mathematical formulation of decision rule for SVM, you can check my previous post, if you are interested. Let\u2019s see contours of decision function", "Let\u2019s understand the code I have used to plot the the above figure \u2014", "Hopefully, this post has helped you to understand the strategy to set up a support vector machine classifier and effectively use Principal Component Analysis to visualize decision boundary.", "Let\u2019s see a 3D animated view of it \u2014", "Finally, I conclude the post by emphasizing that it is always good to check your understanding and, here we can see how the gamma factor affects the decision function contours.", "For the plots above, we had \u03b3 = 0.5, C = 1. You can read my other post on SVM kernels, where I have discussed how increasing \u03b3 parameter can give rise to complicated decision boundaries.", "Let\u2019s check this using 2 different values of \u2018Gamma\u2019 by keeping \u2018C\u2019 parameter fixed to the best fit value\u2014", "As you can see that increasing gamma parameter gives rise to extremely complicated contours. Most importantly, almost all the samples (of each classes) for high gamma values are acting as support vectors. This is certainly a case of over-fitting for such simple, easy to classify cancer data-set.", "\u201cAlways check your intuition and understanding !!\u201d \u2014 Anonymous", "For further reading, I suggest you to check several excellent demonstrations given in Sebastian Raschka\u2019s book on Machine Learning with Python (Pages: 76\u201388, 2nd Edition September 2017).", "Find Codes used for this post in Github.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F69e7591dacea&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://saptashwa.medium.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": ""}, {"url": "https://saptashwa.medium.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Saptashwa Bhattacharyya"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a3c3c477239&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=post_page-9a3c3c477239----69e7591dacea---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/dive-into-pca-principal-component-analysis-with-python-43ded13ead21", "anchor_text": "principal component analysis"}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-1-lagrange-multipliers-5c24a52ffc5e", "anchor_text": "mathematics behind support vector machine (SVM) algorithm"}, {"url": "https://seaborn.pydata.org/", "anchor_text": "Seaborn Library"}, {"url": "https://matplotlib.org/", "anchor_text": "Matplotlib"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html", "anchor_text": "scikit-learn cancer data-set"}, {"url": "https://towardsdatascience.com/data-handling-using-pandas-cleaning-and-processing-3aa657dc9418", "anchor_text": "no missing data"}, {"url": "https://seaborn.pydata.org/", "anchor_text": "seaborn library"}, {"url": "https://seaborn.pydata.org/generated/seaborn.jointplot.html", "anchor_text": "seaborn jointplot"}, {"url": "https://mathisonian.github.io/kde/", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/dive-into-pca-principal-component-analysis-with-python-43ded13ead21", "anchor_text": "other post on PCA"}, {"url": "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976", "anchor_text": "I wrote separately"}, {"url": "https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976", "anchor_text": "my other post"}, {"url": "https://scikit-learn.org/0.20/auto_examples/svm/plot_iris.html", "anchor_text": "maximum margin separating hyperplane"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function", "anchor_text": "decision function"}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-1-lagrange-multipliers-5c24a52ffc5e", "anchor_text": "my previous post"}, {"url": "https://stackoverflow.com/questions/36013063/what-is-the-purpose-of-meshgrid-in-python-numpy", "anchor_text": "Numpy Meshgrid"}, {"url": "https://towardsdatascience.com/understanding-support-vector-machine-part-2-kernel-trick-mercers-theorem-e1e6848c6c4d", "anchor_text": "other post on SVM kernels"}, {"url": "https://www.amazon.com/Python-Machine-Learning-Sebastian-Raschka-ebook/dp/B00YSILNL0", "anchor_text": "Machine Learning with Python"}, {"url": "https://github.com/suvoooo/Machine_Learning/tree/master/SVM_Decision_Boundary", "anchor_text": "Github"}, {"url": "https://medium.com/tag/data-science?source=post_page-----69e7591dacea---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----69e7591dacea---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----69e7591dacea---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----69e7591dacea---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----69e7591dacea---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=-----69e7591dacea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=-----69e7591dacea---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F69e7591dacea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----69e7591dacea---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----69e7591dacea--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----69e7591dacea--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----69e7591dacea--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----69e7591dacea--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----69e7591dacea--------------------------------", "anchor_text": ""}, {"url": "https://saptashwa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://saptashwa.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Saptashwa Bhattacharyya"}, {"url": "https://saptashwa.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.3K Followers"}, {"url": "https://www.linkedin.com/in/saptashwa", "anchor_text": "https://www.linkedin.com/in/saptashwa"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a3c3c477239&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=post_page-9a3c3c477239--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F423a8008308d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-support-vector-machine-decision-boundary-69e7591dacea&newsletterV3=9a3c3c477239&newsletterV3Id=423a8008308d&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}