{"url": "https://towardsdatascience.com/introduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d", "time": 1683016544.159659, "path": "towardsdatascience.com/introduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d/", "webpage": {"metadata": {"title": "Introduction to decision tree classifiers from scikit-learn | by Philip Wilkinson | Towards Data Science", "h1": "Introduction to decision tree classifiers from scikit-learn", "description": "So here I am going to focus on how a decision tree may be implemented using the scikit-learn library in python on the iris dataset, along with some of the functionality that is useful in analysing\u2026"}, "outgoing_paragraph_urls": [{"url": "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html", "anchor_text": "here", "paragraph_index": 32}, {"url": "http://www.linkedin.com/in/philip-wilkinson1", "anchor_text": "www.linkedin.com/in/philip-wilkinson1", "paragraph_index": 38}], "all_paragraphs": ["There are plenty of articles out there that explain what a decision tree is and what it does:", "So here I am going to focus on how a decision tree may be implemented using the scikit-learn library in python on the iris dataset, along with some of the functionality that is useful in analysing the performance of the algorithm.", "A classifier algorithm is used to map input data to a target variable through decision rules and can be used to predict and understand what characteristics are associated with a specific class or target. This means that it is a supervised machine learning algorithm as we already have the final labels, we just want to know how they may be predicted. For our purpose, we can use the Decision Tree Classifier to predict the type of iris flower we have based on features of: Petal Length, Petal Width, Sepal Length and Sepal Width.", "A decision tree a tree like structure whereby an internal node represents an attribute, a branch represents a decision rule, and the leaf nodes represent an outcome. This works by splitting the data into separate partitions according to an attribute selection measure, which in this case is the Gini index (although we can change this to information gain if we wanted). This essentially means that we each split aims toreduce Gini impurity which measures how impure a node is according to incorrectly classified results.", "We first of all want to get the data into the correct format so that we can create our decision tree. Here, we will use the iris dataset from the sklearn datasets databases which is quite simple and works as a showcase for how to implement a decision tree classifier.", "The good thing about the Decision Tree Classifier from scikit-learn is that the target variable can be categorical or numerical. For clarity purpose, given the iris dataset, I prefer to keep the categorical nature of the flowers as it is simpler to interpret later on, although the labels can be brought in later if so desired. The following code can therefore be used to import the dataset here:", "The next thing we want to do is to extract our training and test dataset. The purpose of this is to ensure that the model is not trained on all the available data so that we can test how it performs on unseen data. If we were to use all the data as the training data then we may end up overfitting the model, meaning that it may perform poorly on unseen data.", "Now that we have the data in the correct format, we can start to create the decision tree so that we can try to predict the classification of the different flowers. To this end, the first thing to do is to import the DecisionTreeClassifier from the sklearn package. For which, more information can be found here.", "The next thing to do is then to apply this to training data. For this purpose, the classifier is assigned to clf and set max_depth = 3 and random_state = 42. Here, the max_depth parameter is the maximum depth the tree, which we control to ensure there is no overfitting and that we can easily follow how the final result was achieved. The random_state parameter ensures that the results can be replicated in further analyses.", "We then fit algorithm to the training data:", "We want to be able to understand how the algorithm has behaved, which one of the positives of using a decision tree classifier is that the output is intuitive to understand and can be easily visualised.", "This can be done in two ways:", "2) As a text based diagram", "Which clearly show how the algorithm has behaved. Here, the first split is based on the Petal Length, with being less than 2.45 cm being identified as Iris-setosa, while those with greater being classed as Iris-virginica. However, a further split occurs for those with petal length greater than 2.45, with two further splits to end up with more accurate final classifications.", "Of course, we are not just interested in how it performed on the training data, but how well it performs on unseen test data. This means we have to use it to predict the class from the test values, which is done using the predict() method.", "We are interested in how this performs in terms of true positives (predicted true and actually true), false positives (predicted true but not actually true), false negatives (predicted false but actually true) and true negatives (predicted false and actually false).", "One way to do so is to examine the results in a confusion matrix. A confusion matrix allows us to visualise how the predicted and true labels match up by showing predicted values on one axis and actual values on the other. This is useful to identify where we may get false positives or false negatives and hence how the algorithm has performed.", "As can be seen here, from the unseen data, only one value has failed to be predicted from the Iris-versicolor class, which suggests that overall this algorithm has done well on predicting unseen data.", "To measure performance however there are several metrics that can be produced.", "The accuracy score is the fraction of true positives and true negatives over the total number of assigned labels and is calculated as:", "sum(diagonals in the confusion matrix) / sum (all boxes in the confusion matrix)", "This tells us how many of the values we predicted to be in a certain class are actually in that class. Essentially, this tells us how we performed in terms of false positives. It is calculated as:", "True positive (number in diagonal)/All positives (column sum)", "This tells us how many of the values in each class were given the correct label, thus telling use how it performed relative to false negatives. It is calculated as:", "True positive (number in diagonal)/All assignments (row sum)", "This is a weighted average of precision and recall scale, with 1 being the best and 0 the worst. This uses the harmonmic mean, so that the value is closer to the smaller number, and prevents overestimating the performance of the model in cases where one parameter is high and the other low. It is calculated as:", "Of course, we can get all of these metrics in a single output with the following piece of code:", "Where the support for each class is simply the number of occurrences in each class in the test labels.", "Another useful feature is calculating the importance of each of the features in the final tree output. This is the total amount that the gini index or entropy index (gini in our case) decreases due to splits over a given feature. This can be gained from:", "Which shows here that Petal Length had the greatest importance as the first division was based on this. However, since only one decision tree has been run this does not mean that the other features are not important, only that they were not needed in this decision tree. For a true perspective the decision trees must be run multiple times (as in a random forest) and the results aggregated. This can then be compared to random variables, or features be dropped based on a certain criteria.", "We can try to improve the model by changing the features used, but we can also see how it responds to changes in hyperparameters by using GridSearchCV. This performs cross validation on the model by performing the algorithm on multiple runs of the sets of the training set, and tells us how the model responds.", "For our purpose, we can change the max_depth and min_samples_split parameters which control how deep the tree goes, and the number of samples required to split an internal node.", "which tells us the best hyperparameters for this are max_depth =2 and min_smaples_split =2. Other hyperparameters to change can be found here.", "Thus showing you how to implement a simple decision tree in practice!", "The advantages of using a decision tree are that they are easy to follow and interpret, they can handle both numerical and categorical data, they limit the influence of poor predictors and we can extract their structure to visualise. Of course, there are also downsides in that they can create biased trees if one class dominates, we can get over-complex trees leading to overfitting and small variations in the data may create widely different results. However, they can be very useful in practice and can be used alongside other classification algorithms such as k-nearest neighbours or random forest to help make decisions and understand how the classifications came about.", "If you enjoyed what you read and are not yet a medium member, consider supporting me and other authors on the platform by signing up using my referral code below:", "Or if you are interested in other stories by me, feel free to read some of the ones below:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "CASA PhD student, Spatial Analysis, Data Science and Software Engineering. 400,000+ views. Connect on: www.linkedin.com/in/philip-wilkinson1"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F32cd5d23f4d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://philip-wilkinson.medium.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": ""}, {"url": "https://philip-wilkinson.medium.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Philip Wilkinson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec0e018f30da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&user=Philip+Wilkinson&userId=ec0e018f30da&source=post_page-ec0e018f30da----32cd5d23f4d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@nateggrant?utm_source=medium&utm_medium=referral", "anchor_text": "Nate Grant"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/swlh/decision-tree-classification-de64fc4d5aac", "anchor_text": "Decision Tree ClassificationA Decision Tree is a simple representation for classifying examples. It is a Supervised Machine Learning where the data\u2026medium.com"}, {"url": "https://towardsdatascience.com/the-basics-decision-tree-classifiers-b0d20394eaeb", "anchor_text": "The Basics: Decision Tree ClassifiersAn intuition for how decision trees work and are builttowardsdatascience.com"}, {"url": "https://medium.com/@borcandumitrumarius/decision-tree-classifiers-explained-e47a5b68477a", "anchor_text": "Decision Tree Classifiers ExplainedDecision Tree Classifier is a simple Machine Learning model that is used in classification problems. It is one of the\u2026medium.com"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html", "anchor_text": "here"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html", "anchor_text": "here"}, {"url": "https://philip-wilkinson.medium.com/membership", "anchor_text": "Join Medium with my referral link - Philip WilkinsonAs a Medium member, a portion of your membership fee goes to writers you read, and you get full access to every story\u2026philip-wilkinson.medium.com"}, {"url": "https://towardsdatascience.com/ucl-data-science-society-python-fundamentals-3fb30ec020fa", "anchor_text": "UCL Data Science Society: Python FundamentalsWorkshop 1: Jupyter notebook, variables, data types and operationstowardsdatascience.com"}, {"url": "https://towardsdatascience.com/an-introduction-to-object-oriented-programming-for-data-scientists-879106d90d89", "anchor_text": "An introduction to Object-Oriented Programming for Data ScientistsThe basics of OOP for those who may not have come across the idea before or are wanting to know moretowardsdatascience.com"}, {"url": "https://towardsdatascience.com/introduction-to-random-forest-classifiers-9a3b8d8d3fa7", "anchor_text": "Introduction to Random Forest ClassifiersPredicting the position of NBA players \u2014 are we seeing a truly \u2018positionless\u2019 league?towardsdatascience.com"}, {"url": "https://medium.com/tag/python?source=post_page-----32cd5d23f4d---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/scikit-learn?source=post_page-----32cd5d23f4d---------------scikit_learn-----------------", "anchor_text": "Scikit Learn"}, {"url": "https://medium.com/tag/classification?source=post_page-----32cd5d23f4d---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/decision-tree?source=post_page-----32cd5d23f4d---------------decision_tree-----------------", "anchor_text": "Decision Tree"}, {"url": "https://medium.com/tag/data-science?source=post_page-----32cd5d23f4d---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&user=Philip+Wilkinson&userId=ec0e018f30da&source=-----32cd5d23f4d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&user=Philip+Wilkinson&userId=ec0e018f30da&source=-----32cd5d23f4d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F32cd5d23f4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----32cd5d23f4d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----32cd5d23f4d--------------------------------", "anchor_text": ""}, {"url": "https://philip-wilkinson.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://philip-wilkinson.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Philip Wilkinson"}, {"url": "https://philip-wilkinson.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.7K Followers"}, {"url": "http://www.linkedin.com/in/philip-wilkinson1", "anchor_text": "www.linkedin.com/in/philip-wilkinson1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec0e018f30da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&user=Philip+Wilkinson&userId=ec0e018f30da&source=post_page-ec0e018f30da--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb48e8a3cfc32&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-decision-tree-classifiers-from-scikit-learn-32cd5d23f4d&newsletterV3=ec0e018f30da&newsletterV3Id=b48e8a3cfc32&user=Philip+Wilkinson&userId=ec0e018f30da&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}