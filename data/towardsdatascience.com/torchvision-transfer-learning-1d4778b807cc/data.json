{"url": "https://towardsdatascience.com/torchvision-transfer-learning-1d4778b807cc", "time": 1683000334.766256, "path": "towardsdatascience.com/torchvision-transfer-learning-1d4778b807cc/", "webpage": {"metadata": {"title": "Torchvision & Transfer Learning. Attempts at Direct Manipulation of\u2026 | by Steve Brown | Towards Data Science", "h1": "Torchvision & Transfer Learning", "description": "This article will probably be of most interest to individuals just starting out in deep learning or people who are relatively new to leveraging PyTorch. It is a summary of my experience with recent\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["This article will probably be of most interest to individuals just starting out in deep learning or people who are relatively new to leveraging PyTorch. It is a summary of my experience with recent attempts to modify the torchvision package\u2019s CNNs that have been pre-trained on data from Imagenet. The aim of making a multiple architecture classifier a little easier to program.", "It\u2019s a well-known fact that a machine learning practitioner can take advantage of pre-trained models by retaining all but the last layer of the pre-trained model, freezing the parameters in the remaining layers and then attaching a custom classifier to the end of the model that is later trained with the user\u2019s data.", "I finished what Udacity refers to as a nano-degree in, \u201cAI Programming with Python\u201d in late March of 2019. For the final project of the course, students had to use at least two different types of CNN architectures to properly classify photographs of different types of plants and wild flowers.", "The CNN architectures available to students were supplied by PyTorch\u2019s torchvision module and were pretrained on images from Imagenet. The challenge was to take these different pre-trained CNN architectures and then, using the concept of transfer learning, attach our own classification layer leveraging PyTorch to the end of the model. That classifier would then be trained on photographs of plants and wild flowers supplied by a source on the internet.", "To examine the architecture of the pretrained models included with torchvision, I used the process below from the Python interpreter:", "Note that for the torchvision vgg13 pretrained implementation, the last parent module, which is the one that gets replaced by the student\u2019s classifier, is named, \u201cclassifier\u201d.", "Since the goal of the assignment was to use at least two different pretrained CNN architectures, I took a look at the other models offered by the torchvision module. What I found was that there were at least two different names used for the classification portion of the torchvision pretrained CNN models. In addition to \u2018classifier\u2019, the resnet101 pretrained CNN used, \u2018fc\u2019 (presumably standing for, \u201cfully connected\u201d) for it\u2019s final classification module.", "Ultimately, my custom classification layer would need to be attached to the pretrained CNN using a statement similar to the following:", "But, what would happen if the user specified a resnet101 architecture from the command line? How would I overwrite the last module using the technique above since the architecture would have a different name than, \u2018classifier\u2019?", "Since I wanted to reuse as much code as possible for the project, I had a few choices. One, I could choose architectures that had the same name for the classification module or, two, I could see if I could find a way to go ahead and implement any general architecture and find a way to work with the fact that the different architectures had different names for the classification module. A third choice was to attach the custom classifier onto the user chosen architecture based on the model the user chose. For example, \u201cif\u201d the user chose resnet101, \u201cthen\u201d we use \u201cfc\u201d, otherwise, we use \u201cclassifier\u201d.", "Ultimately, I chose option two. My decision was to attempt to equate the \u2018classifier\u2019 module name to the \u2018fc\u2019 module name. In other words, I chose to do something similar to this:", "The objective was to provide multiple names to my custom classifier so that regardless of the architecture I chose, I could refer to the classification layer with the name \u2018fc\u2019. This appeared to work and it was what I went with for my final project (which passed).", "After finishing the \u201cDeep Learning\u201d nano-degree program in August of 2019 (my second AI related nano-degree), I wanted to go back to my original \u201cAI Programming with Python\u201d project and spend a little more time becoming familiar with PyTorch since the majority of the Deep Learning program used Tensorflow. I also wanted to add a command line parameter so that the user could specify the number of categories the classifier would distinguish rather than have the number fixed in the code base.", "Soon, I was poking around the code of my project I had completed months earlier to prepare for modifying it to accept the number of categories that the classifier could distinguish from the command line.", "It wasn\u2019t long at all before I discovered that my \u201ctrick\u201d wasn\u2019t doing what I intended it to do at all. The code worked just fine, but not as I had originally intended to design it.", "Instead of enabling me to refer to my custom classifier with more than one name, the code was instead adding two custom classifiers to the end of the pretrained architecture I had selected. For example, what I ended up with in the case of the vgg13 architecture was the following:", "As you can see from the modules named, \u2018classifier\u2019 and \u2018fc\u2019, the end result of my attempt at providing more than one name for my custom classifier failed. All it did was to put two copies of the custom classification module at the end of the pre-trained vgg13 CNN. What\u2019s worse, my dropout layer appeared in the wrong place. I wanted it to show up after the hidden layer. Back to the proverbial drawing board.", "What I realized I needed was a method I could use to manipulate the architecture of the pretrained models provided by the torchvision module. If I was able to manipulate the architecture, I could, for example, perform what amounted to a \u201cdelete\u201d (or perhaps a \u201crename\u201d) of the last module of any of the pretrained CNNs provided by torchvision. Then, I thought, it wouldn\u2019t matter what the name of the classification module was in the pretrained CNN, I could call it whatever I wanted to and not have to worry about what the classification module was named. Even better, I wouldn\u2019t have to worry about decision making code to handle the use of different architectures.", "At this point, I decided to see exactly what methods and attributes were available to the torchvision models. To do this, I again went back to the interpreter:", "One of the first things I learned by looking at the output above was the fact that there are methods that correspond to each of the top level modules. For example, there are methods for each of \u2018features\u2019, \u2018avgpool\u2019 and \u2018classifier\u2019. Where the names differ according to the torchvision model, so the methods will differ. The resnet101 model, for example, has no \u2018classifer\u2019 method. It does have an \u2018fc\u2019 method for the classifier.", "I spent some time experimenting with the different methods and leveraging Python\u2019s help facility to explore them and came up with my first (albeit, na\u00efve) idea to use the \u2018add_module\u2019 method inherited from nn.Module:", "Based on the information above, this seemed to be exactly what I needed and I tested the implementation as follows:", "Note that the \u2018classifier\u2019 module is not listed in the tv_model_children list. Since we\u2019re ultimately going to be attaching our own classifier to the model named, \u2018model\u2019, that we created above, this is exactly what we want.", "Now, let\u2019s get the modules in the tv_model_children list into our new model:", "At this point, everything seemed to be as I wanted it. I had effectively \u2018deleted\u2019 the classifier module from the torchvision vgg13 pretrained model. I could now attach a classifier onto the model with any name I chose to give it. My next step was to replicate this approach inside of my program and see how it worked:", "Well, that didn\u2019t quite work all that well, did it? Let\u2019s take a look at the model that was generated and compare it to the pretrained vgg13 architecture since the exception output mentions issues with the size of the tensors involved in a multiplication step. Perhaps something got mangled during the creation of the model?", "Everything looks in order. There\u2019s only one copy of my classifier named, \u2018fc\u2019, and the dropout layer is now in the right place although there will be more of them once I\u2019m finished. At this point, I was stumped. Off to Google\u2019s search engine I went.", "Searching for strings similar to, \u201cdelete last module of torchvision model\u201d provided numerous leads. One lead suggested that the Python \u2018del\u2019 function could be used with the argument of the name of the layer which I wanted to remove. This wouldn\u2019t work as the PyTorch \u2018Sequential\u2019 object has no \u2018del\u2019 method. Many of the other leads contained questions similar to my own but were unanswered.", "Still other leads contained variations of a common theme. These threads relied on the use of the \u2018children()\u2019 method but they bypassed the add_module() method directly. For example:", "This looked quite similar to the method that I had attempted earlier. But, since it didn\u2019t use the add_module method directly, I thought I\u2019d give it a shot in my code. After executing my program again, I wound up with the exact same exception output. No luck here either.", "At this point, I began to consider potential sources of the size mismatch. Since I had pretty much the same architecture in my new model as the pretrained model, I began to wonder what the difference was between the two models. When I used the torchvision vgg13 model directly, it worked. When I \u201ccopied\u201d it while attempting to remove the classification module, it didn\u2019t.", "I went back and looked at the traceback once more and saw mention of calls to \u201cforward\u201d. This gave me an idea. What if merely copying the modules from one architecture to another didn\u2019t include a copy of the forward() method associated with the model? After stumbling upon this idea, I went back to my code and added the following line:", "Running the program again produced yet another exception but this time it was very different and its content helped me come to a realization:", "Note here that not only is the exception different, but it appears to be rooted in a call to a method called, \u2018classifier\u2019 and not \u2018fc\u2019! In other words, the transfer of the forward method to my new model worked for solving the size mismatch. But the forward code inside of the torchvision vgg13 model was still looking for a method called, \u2018classifier\u2019 and not \u2018fc\u2019. If I wanted this approach to work, I was going to have code my own forward method so that the input through each of the different layers produced the right size input going into my classifier with the right name for the classifier. Not worth it.", "I also began to wonder about the parameters that were associated with the torchvision vgg13 model. It\u2019s likely I\u2019d have to take care of those too. Again, not worth it.", "As a result of the research I put into trying to manipulate layers of a torchvision pretrained model, I came to the conclusion that there was no method I could use that would allow me to generalize my approach to different networks in my training code.", "I\u2019d have to account for differences in the layer names from inside of my code or simply choose torchvision architectures that had the same name for the final classification module. I can at least say that I\u2019ve learned a lot through this exercise and enjoyed the journey.", "I hope you found this informative and a worthwhile read.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I work for a large technology corporation and hold a degree in mathematics from Missouri State University. Learning new technical skills is a passion of mine."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1d4778b807cc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@arbeiterZ?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arbeiterZ?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Steve Brown"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f751d74060&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&user=Steve+Brown&userId=6f751d74060&source=post_page-6f751d74060----1d4778b807cc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral", "anchor_text": "Possessed Photography"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1d4778b807cc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----1d4778b807cc---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/image-classifier?source=post_page-----1d4778b807cc---------------image_classifier-----------------", "anchor_text": "Image Classifier"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----1d4778b807cc---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&user=Steve+Brown&userId=6f751d74060&source=-----1d4778b807cc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&user=Steve+Brown&userId=6f751d74060&source=-----1d4778b807cc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1d4778b807cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1d4778b807cc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1d4778b807cc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1d4778b807cc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1d4778b807cc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arbeiterZ?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@arbeiterZ?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Steve Brown"}, {"url": "https://medium.com/@arbeiterZ/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f751d74060&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&user=Steve+Brown&userId=6f751d74060&source=post_page-6f751d74060--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F6f751d74060%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftorchvision-transfer-learning-1d4778b807cc&user=Steve+Brown&userId=6f751d74060&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}