{"url": "https://towardsdatascience.com/recent-advancements-in-nlp-2-2-df2ee75e189", "time": 1683002378.9937909, "path": "towardsdatascience.com/recent-advancements-in-nlp-2-2-df2ee75e189/", "webpage": {"metadata": {"title": "Recent Advancements in NLP. In my first post in the series, I had\u2026 | by Moiz Saifee | Towards Data Science", "h1": "Recent Advancements in NLP", "description": "In a previous post, I wrote about two recent important concepts in NLP \u2014 Word Embedding and RNN. In this post, I\u2019ll cover the concept of Attention and Transformer which have become the building\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c", "anchor_text": "previous post", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1409.0473", "anchor_text": "Attention", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Transformer", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Transfer_learning", "anchor_text": "transfer learning", "paragraph_index": 0}, {"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "AlphaStar", "paragraph_index": 4}, {"url": "https://deepmind.com/", "anchor_text": "DeepMind", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1409.0473", "anchor_text": "this", "paragraph_index": 5}, {"url": "https://research.googleblog.com/2017/08/transformer-novel-neural-network.html", "anchor_text": "Google Blog", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "this", "paragraph_index": 12}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT", "paragraph_index": 17}], "all_paragraphs": ["In a previous post, I wrote about two recent important concepts in NLP \u2014 Word Embedding and RNN. In this post, I\u2019ll cover the concept of Attention and Transformer which have become the building blocks for most of the state of the art models in NLP at present. I\u2019ll also review BERT which made the powerful concept of transfer learning easier in NLP", "Like my earlier post, I\u2019ll skip most of the mathematics and focus more on intuitive understanding. The reason for this is \u2014 use of excessive notations and equations is a turn off for many, myself included. That\u2019s actually not even critical for conceptual understanding which I believe is a lot more important than understanding each and every underlying mathematical equation.", "While variants of RNN like Bi-LSTM give a pretty solid performance on various NLP tasks, following are some of the key challenges that still remain:", "The above challenges were the motivation for a lot of work which happened in 2017 and forward. The concept of attention addresses challenge #2 above and the transformer architecture addresses challenge # 1 and #3.", "One thing to note is \u2014 while the concepts of attention and transformer helped break established benchmarks in NLP tasks, these are generic techniques with wide application in any sequence to sequence task. For instance, the transformer architecture was also a building block for AlphaStar the DeepMind bot that beat the top StarCraft II professional player.", "The attention is one of the most influential ideas in Deep Learning in general. While the concept was originally developed for machine translation, its use quickly spread to a lot of other areas. It was proposed by Dzmitry Bahdanau et al in this influential paper.", "The core idea behind it is \u2014 when performing a certain task, for example, translation of a sentence from one language to the other, say English to French, each word in the output French sentence would be informed by (relevant context of) all words in the original input English sentence with varying degree of attention or importance rather than a single/constant context generated by processing the whole English sentence.", "Consider the following excellent English to French translation example from Google Blog. The \u201cit\u201d in the two sentences refers to different nouns, and its translation to French differs depending on which noun the \u201cit\u201d refers to.", "To a human, It is obvious that in the first sentence pair \u201cit\u201d refers to the animal, and in the second to the street", "The following picture depicts what happens conceptually with (self) attention. Rather than taking a context vector of the whole sentence and that informing the translation of the word \u201cit\u201d, the translation context would be informed by different words in the input sentence by a different amount as shown by the color coding (darker = more important)", "One important thing to note is \u2014 attention weights in the model are not fixed, like the other parameters which are learned by neural network models, but are calculated as a function of input / hidden states \u2014 that\u2019s how the model knows how to put appropriate emphasis on relevant words in the input sentence for any given sentence.", "As illustrated above, the concept of attention addresses the problem of long term dependencies by using more appropriate context at each step (rather than a \u201cconstant\u201d context, example in LSTM based encoder-decoder), but the problem of non parallelism in computation remains as the computation still needs to be done sequentially. With attention, if anything, we make the computation even more complex compared to simple LSTMs, this is where the Transformer architecture came to the rescue.", "Transformer was introduced in 2017 in this seminal paper by Vaswani et al from Google. The network architecture of Transformer is solely based on attention mechanism and has no RNN or CNN units. Following are some of the key benefits of this architecture:", "The figure above shows the overall architecture of the Transformer, which is a bit scary at first blush. Let\u2019s look at high level details of the architecture:", "With those details, the results which Transformer achieved were impressive, however, there were some areas of improvement:", "BERT \u2014 Bidirectional Encoder Representations from Transformers", "First, an honest confession \u2014 I just can\u2019t memorize the full form for BERT no matter how many times I read it, I think the full form was derived from the acronym rather than the other way around :-)", "BERT was proposed by Jacob et al from Google, its a language representation model based on Transformer. I think the major contribution of BERT, in addition to its novel bi-directional training, etc is that it played a big role in popularizing the concept of pre-training / transfer learning in NLP", "Before we go further \u2014 just a few words about transfer learning. Its one of the most elegant concepts in Deep Learning was more popular in ComputerVision compared to NLP. The basic idea is \u2014 one can train a (deep, that is having multiple layers) model on a generic but related task, and just fine-tune the last few layers on their task-specific data to achieve great performance.", "The rationale for transfer learning is \u2014 the earlier layers in a deep model learn more fundamental patterns, for example, learning to detect lines and curves in a computer vision model, and the latter layers learn the task-specific patters, example learning whether there is a cat in the picture or not. The major benefit of this approach is \u2014 you can get great performance even with a modest amount of data on deep learning models which are pretty data hungry in general.", "Following are some important details about BERT:", "Since the Original paper of BERT in Oct\u20192018, there have been many variants and modifications which have been proposed. Most notable among them are \u2014 RoBERTa and mBERT by Facebook AI, XLNet by researchers at CMU and GPT-2 by Open AI.", "This concludes my roundup of some exciting things off late in NLP, clearly, there is so much happening in the field and also at such a rapid pace. There is a lot which people can do with very little effort these days thanks to the giants in the field which have done the heavy lifting and made it easier.", "Senior Principal at Correlation Venture. Passionate about Artificial Intelligence. Kaggle Master; IIT Kharagpur alum"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdf2ee75e189&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@moiz.saifee?source=post_page-----df2ee75e189--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Moiz Saifee"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe747ca1923f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=post_page-e747ca1923f5----df2ee75e189---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf2ee75e189&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=-----df2ee75e189---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf2ee75e189&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=-----df2ee75e189---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c", "anchor_text": "previous post"}, {"url": "https://arxiv.org/abs/1409.0473", "anchor_text": "Attention"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Transformer"}, {"url": "https://en.wikipedia.org/wiki/Transfer_learning", "anchor_text": "transfer learning"}, {"url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii", "anchor_text": "AlphaStar"}, {"url": "https://deepmind.com/", "anchor_text": "DeepMind"}, {"url": "https://arxiv.org/abs/1409.0473", "anchor_text": "this"}, {"url": "https://research.googleblog.com/2017/08/transformer-novel-neural-network.html", "anchor_text": "Google Blog"}, {"url": "https://research.googleblog.com/2017/08/transformer-novel-neural-network.html", "anchor_text": "Google Blog"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "this"}, {"url": "https://arxiv.org/pdf/1706.03762.pdf", "anchor_text": "Transformer Paper"}, {"url": "https://arxiv.org/abs/1810.04805", "anchor_text": "BERT"}, {"url": "https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/", "anchor_text": "visualization"}, {"url": "https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/deep_dives/transformer_from_scratch.ipynb", "anchor_text": "Building"}, {"url": "https://github.com/huggingface/transformers", "anchor_text": "library"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----df2ee75e189---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----df2ee75e189---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----df2ee75e189---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----df2ee75e189---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----df2ee75e189---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf2ee75e189&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=-----df2ee75e189---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf2ee75e189&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=-----df2ee75e189---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf2ee75e189&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=post_page-----df2ee75e189--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe747ca1923f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=post_page-e747ca1923f5----df2ee75e189---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408ae670d9f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&newsletterV3=e747ca1923f5&newsletterV3Id=408ae670d9f1&user=Moiz+Saifee&userId=e747ca1923f5&source=-----df2ee75e189---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Written by Moiz Saifee"}, {"url": "https://medium.com/@moiz.saifee/followers?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "365 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe747ca1923f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&user=Moiz+Saifee&userId=e747ca1923f5&source=post_page-e747ca1923f5----df2ee75e189---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F408ae670d9f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecent-advancements-in-nlp-2-2-df2ee75e189&newsletterV3=e747ca1923f5&newsletterV3Id=408ae670d9f1&user=Moiz+Saifee&userId=e747ca1923f5&source=-----df2ee75e189---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/gpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Moiz Saifee"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/gpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "GPT-3: The New Mighty Language Model from OpenAIPushing Deep Learning to the Limit with 175B Parameters"}, {"url": "https://towardsdatascience.com/gpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "4 min read\u00b7May 31, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa74ff35346fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc&user=Moiz+Saifee&userId=e747ca1923f5&source=-----a74ff35346fc----0-----------------clap_footer----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/gpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc?source=author_recirc-----df2ee75e189----0---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa74ff35346fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgpt-3-the-new-mighty-language-model-from-openai-a74ff35346fc&source=-----df2ee75e189----0-----------------bookmark_preview----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----df2ee75e189----1---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----df2ee75e189----1-----------------bookmark_preview----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----df2ee75e189----2---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----df2ee75e189----2-----------------bookmark_preview----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Moiz Saifee"}, {"url": "https://medium.com/swlh?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "The Startup"}, {"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "Recent Advancements in NLP (1/2)I have spent a good fifteen years in the field of Data Science and AI and have worked a fair bit on NLP in this period, but the pace with\u2026"}, {"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": "7 min read\u00b7Dec 10, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fswlh%2F192ac7eefe3c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Frecent-advancements-in-nlp-1-2-192ac7eefe3c&user=Moiz+Saifee&userId=e747ca1923f5&source=-----192ac7eefe3c----3-----------------clap_footer----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/swlh/recent-advancements-in-nlp-1-2-192ac7eefe3c?source=author_recirc-----df2ee75e189----3---------------------e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F192ac7eefe3c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Frecent-advancements-in-nlp-1-2-192ac7eefe3c&source=-----df2ee75e189----3-----------------bookmark_preview----e402ac2a_464b_46e4_a1b6_ff13c5bb94f0-------", "anchor_text": ""}, {"url": "https://medium.com/@moiz.saifee?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "See all from Moiz Saifee"}, {"url": "https://towardsdatascience.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----df2ee75e189----0-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Babar M Bhatti"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Essential Guide to Foundation Models and Large Language ModelsThe term Foundation Model (FM) was coined by Stanford researchers to introduce a new category of ML models. They defined FMs as models\u2026"}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b714 min read\u00b7Feb 6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&user=Babar+M+Bhatti&userId=10dee34829b&source=-----27dab58f7404----1-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27dab58f7404&operation=register&redirect=https%3A%2F%2Fthebabar.medium.com%2Fessential-guide-to-foundation-models-and-large-language-models-27dab58f7404&source=-----df2ee75e189----1-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----df2ee75e189----0---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----df2ee75e189----0-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://lucianosphere.medium.com/?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "LucianoSphere"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Build ChatGPT-like Chatbots With Customized Knowledge for Your Websites, Using Simple ProgrammingLike ChatGPT but in a form that you can plug into your website and expand with any kind of tailored information by combining basic\u2026"}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b711 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&user=LucianoSphere&userId=d28939b5ab78&source=-----f393206c6626----1-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/build-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626?source=read_next_recirc-----df2ee75e189----1---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff393206c6626&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuild-chatgpt-like-chatbots-with-customized-knowledge-for-your-websites-using-simple-programming-f393206c6626&source=-----df2ee75e189----1-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----2-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----df2ee75e189----2---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----df2ee75e189----2-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "Language Models: GPT and GPT-2How smaller language models inspired modern breakthroughs"}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": "\u00b713 min read\u00b7Nov 24, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bdb9867c50a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-gpt-and-gpt-2-8bdb9867c50a&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----8bdb9867c50a----3-----------------clap_footer----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----df2ee75e189----3---------------------03326436_1910_4f9e_b5fa_efdea96bfa78-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bdb9867c50a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-gpt-and-gpt-2-8bdb9867c50a&source=-----df2ee75e189----3-----------------bookmark_preview----03326436_1910_4f9e_b5fa_efdea96bfa78-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----df2ee75e189--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----df2ee75e189--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}