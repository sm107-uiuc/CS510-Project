{"url": "https://towardsdatascience.com/how-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3", "time": 1683011835.739599, "path": "towardsdatascience.com/how-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3/", "webpage": {"metadata": {"title": "Speeding Up the Conversion Between PySpark and Pandas DataFrames | Towards Data Science", "h1": "Speeding Up the Conversion Between PySpark and Pandas DataFrames", "description": "How to optimize and speed up the conversion between PySpark and Pandas DataFrames with PyArrow when using toPandas()"}, "outgoing_paragraph_urls": [{"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow", "paragraph_index": 4}, {"url": "https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#recommended-pandas-and-pyarrow-versions", "anchor_text": "Spark\u2019s official documentation", "paragraph_index": 5}, {"url": "https://gmyrianthous.medium.com/membership", "anchor_text": "Become a member", "paragraph_index": 10}], "all_paragraphs": ["Converting a PySpark DataFrame to Pandas is quite trivial thanks to toPandas()method however, this is probably one of the most costly operations that must be used sparingly, especially when dealing with fairly large volume of data.", "Pandas DataFrames are stored in-memory which means that the operations over them are faster to execute however, their size is limited by the memory of a single machine.", "On the other hand, Spark DataFrames are distributed across the nodes of the Spark Cluster which is consisted of at least one machine and thus the size of the DataFrames is limited by the size of the cluster. When there is a need to store more data, you simply need to scale up your cluster by adding more nodes (and/or adding more memory to the nodes).", "It is important to understand that when toPandas() method is executed over a Spark DataFrame, all the rows which are distributed across the nodes of the cluster will be collected into the driver program that needs to have sufficient memory to fit the data.", "Apache Arrow is a language independent in-memory columnar format that can be used to optimize the conversion between Spark and Pandas DataFrames when using toPandas() or createDataFrame() .", "Firstly, we need to ensure that a compatible PyArrow and pandas versions are installed. These are 0.15.1 for the former and 0.24.2 for the latter. More recent versions may also be compatible, but currently Spark does not provide any guarantee so this is pretty much up to the user to test and verify the compatibility. For more details about required versions and compatibility, refer to Spark\u2019s official documentation.", "By default, arrow-based columnar data transfers are disabled therefore we have to slightly modify our configurations in order to take advantage of this optimization. To do so, spark.sql.execution.arrow.pyspark.enabled should be enabled.", "When an error occurs before the actual computation, PyArrow optimizations will be disabled. If we want to avoid potential fallbacks to non-arrow optimizations, we also need to enable the following configuration:", "Currently, some of the Spark SQL datatypes are not supported by Arrow-based optimization conversions. These types are:", "As we have already discussed, toPandas() is an expensive operation that should be used carefully in order to minimize the performance impact on our Spark applications. In case where this is required and especially when the dataframe is fairly large, you need to consider PyArrow optimization when converting Spark to Pandas DataFrames (and vice-verca).", "Become a member and read every story on Medium. Your membership fee directly supports me and other writers you read.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I write about Python, DataOps and MLOps"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8bda2c3875c3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://me.dm/@gmyrianthous", "anchor_text": "Mastodon"}, {"url": "https://towardsdatascience.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gmyrianthous.medium.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": ""}, {"url": "https://gmyrianthous.medium.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Giorgos Myrianthous"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76c21e75463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&user=Giorgos+Myrianthous&userId=76c21e75463a&source=post_page-76c21e75463a----8bda2c3875c3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@noah_bog", "anchor_text": "Noah Bogaard"}, {"url": "https://unsplash.com/photos/mJFtH4FFl7o", "anchor_text": "unsplash.com"}, {"url": "https://arrow.apache.org/", "anchor_text": "Apache Arrow"}, {"url": "https://spark.apache.org/docs/latest/sql-pyspark-pandas-with-arrow.html#recommended-pandas-and-pyarrow-versions", "anchor_text": "Spark\u2019s official documentation"}, {"url": "https://gmyrianthous.medium.com/membership", "anchor_text": "Become a member"}, {"url": "https://medium.com/tag/python?source=post_page-----8bda2c3875c3---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/spark?source=post_page-----8bda2c3875c3---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/pandas?source=post_page-----8bda2c3875c3---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/software-development?source=post_page-----8bda2c3875c3---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/big-data?source=post_page-----8bda2c3875c3---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&user=Giorgos+Myrianthous&userId=76c21e75463a&source=-----8bda2c3875c3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&user=Giorgos+Myrianthous&userId=76c21e75463a&source=-----8bda2c3875c3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8bda2c3875c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8bda2c3875c3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8bda2c3875c3--------------------------------", "anchor_text": ""}, {"url": "https://gmyrianthous.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gmyrianthous.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Giorgos Myrianthous"}, {"url": "https://gmyrianthous.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "6.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F76c21e75463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&user=Giorgos+Myrianthous&userId=76c21e75463a&source=post_page-76c21e75463a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe22c3c522ce1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-convert-a-pyspark-dataframe-to-pandas-8bda2c3875c3&newsletterV3=76c21e75463a&newsletterV3Id=e22c3c522ce1&user=Giorgos+Myrianthous&userId=76c21e75463a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}