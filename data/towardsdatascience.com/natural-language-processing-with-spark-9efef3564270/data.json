{"url": "https://towardsdatascience.com/natural-language-processing-with-spark-9efef3564270", "time": 1683002633.492821, "path": "towardsdatascience.com/natural-language-processing-with-spark-9efef3564270/", "webpage": {"metadata": {"title": "Natural Language Processing with Spark | by Suraj Malpani | Towards Data Science", "h1": "Natural Language Processing with Spark", "description": "This is an introductory tutorial on developing predictive machine learning models using PySpark. I am going to demonstrate the basics of Natural Language Processing (NLP) while utilizing the power of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/nlp-getting-started", "anchor_text": "\u2018NLP with Disaster Tweets\u2019 Kaggle competition.", "paragraph_index": 0}, {"url": "https://github.com/SurajMalpani/NLP-using-Spark/blob/master/nlp-using-pyspark-ml.ipynb", "anchor_text": "GitHub.", "paragraph_index": 0}, {"url": "https://monkeylearn.com/text-classification/", "anchor_text": "Monkeylearn", "paragraph_index": 2}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark Dataframes", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Regular_expression", "anchor_text": "Regular expressions (regex)", "paragraph_index": 7}, {"url": "https://spark.apache.org/docs/latest/ml-features#tokenizer", "anchor_text": "RegexTokenizer()", "paragraph_index": 8}, {"url": "https://spark.apache.org/docs/2.2.0/ml-features.html#stopwordsremover", "anchor_text": "StopWordsRemover()", "paragraph_index": 9}, {"url": "https://spark.apache.org/docs/2.2.0/ml-features.html#countvectorizer", "anchor_text": "CountVectorizer()", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Statistical_classification", "anchor_text": "classification machine learning algorithms.", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Logistic_function", "anchor_text": "a logistic function", "paragraph_index": 16}, {"url": "https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76", "anchor_text": "article", "paragraph_index": 17}, {"url": "https://github.com/SurajMalpani/NLP-using-Spark", "anchor_text": "Github.", "paragraph_index": 20}, {"url": "https://surajmalpani.github.io/", "anchor_text": "Website", "paragraph_index": 22}, {"url": "https://www.linkedin.com/in/suraj-malpani/", "anchor_text": "LinkedIn", "paragraph_index": 22}], "all_paragraphs": ["This is an introductory tutorial on developing predictive machine learning models using PySpark. I am going to demonstrate the basics of Natural Language Processing (NLP) while utilizing the power of Spark. We will use PySpark; which is a Python API for Spark. The dataset for this tutorial is fetched from the \u2018NLP with Disaster Tweets\u2019 Kaggle competition. The full code is available on GitHub.", "The data consists of tweets and our task is to predict which tweets are related to a disaster. This may improve the response time for several interested parties, such as Police Force, Fire Brigade or News Agencies, etc. We will be performing text classification, by building predictive machine learning models, which is a category of NLP. The following algorithms can help you get instigated in your Text Analytics or NLP endeavor and has numerous applications.", "Text classification is the process of assigning tags or categories to text according to its content. It\u2019s one of the fundamental tasks in Natural Language Processing (NLP) with broad applications such as sentiment analysis, topic labeling, spam detection, and intent detection. \u2014 From Monkeylearn", "Let\u2019s dive into the data without further delay. For that, we need to know a bit about Spark Dataframes. Now, we need to start a Spark session within Python to use Spark. We start the session using the following command, appName parameter, i.e. \u2018nlp\u2019 in this case could be of the user\u2019s choice.", "Once we start the Spark Session, we will load the data using \u2018spark.read.csv\u2019 function. After loading the data files into the workspace, we need to perform pre-processing on the text data. The head of the dataframe looks as displayed in the below image. We will be working on the \u2018text\u2019 field to predict the \u2018target\u2019 field.", "The following workflow details the process that we will follow for extracting features from the data. The descriptions of each stage follow the image.", "1) Drop null values: We drop all the records having a null/na value in the text. We can use dropna() function for this purpose.", "2) Remove numbers from the tweets: We use Regular expressions (regex) operators for further cleaning the text data. The following code drops all the numbers from the text. We are dealing with the words rather than numbers to recognize the disaster tweets.", "3) Segregate the words: Then we break the tweets into individual words to analyze them. We use RegexTokenizer() for this purpose.", "4) Remove stop words: We remove stop words from the segregated words using StopWordsRemover() function from the pyspark.ml library. Some of the examples of stop words are I, the, a, has, etc. As you can notice from these examples, these words don\u2019t carry much information and thus we remove them from the analysis.", "5) Create the features column: After removing the unimportant words from the data, we use CountVectorizer() function. This function converts words to a numeric vector to be able to feed it to a machine learning model.", "Now our data is ready to be fed to predictive models. The data looks like this after finishing the above process.", "Let me shed light on all the fields in the above dataframe; we started with the \u2018text\u2019 field. The \u2018words\u2019 display segregated words after performing the first 3 steps from our above workflow. The \u2018filtered\u2019 column shows words after removing stop words as described in step 4. The \u2018features\u2019 field is the numeric vector field after finishing step 5, this is the field we will be using for training machine learning models. The \u2018target\u2019 field is our predictor variable which shows whether the tweet is related to a disaster or not.", "We separate the data obtained from the previous process into train and validate. We use the train dataframe for training the machine learning models and validate dataframe to validate their accuracy on the unseen data. There are several criteria for validating the classification models, we will use ROC and accuracy for our analysis. After validating, we will make predictions on the test data.", "I will illustrate some of the common classification machine learning algorithms. I am assuming you are familiar with these algorithms and I will try not to bore you with these algorithms.", "Naive Bayes model is one of the most common algorithms for text classification. Naive Bayes algorithm assumes that all the predictor variables are independent of each other. Simply put, it assumes that the presence of one particular feature is unrelated to any other feature in the data. This assumption is not always correct in real life, however, it makes sense in text classification. The following code is used for training and validating the Naive Bayes Model using PySpark.", "It is a variant of regression that uses a logistic function for modeling a binary outcome variable. The following code demonstrates how to train and validate Logistic Regression.", "Decision trees essentially split the dataset based on columns trying to learn their behavior concerning the outcome variable, i.e. we segment the predictor space into simple regions. This article by Will Koehrsen could help understand decision trees and random forests in detail. We can use the following code for training and validating decision trees.", "Random forests are an ensemble machine learning method. They use bootstrapping techniques and are fundamentally a combination of numerous weak learners, specifically decision trees. Check the following code to learn to implement random forests in spark.", "Gradient boosting tree is an ensemble method analogous to random forests. The approach to building trees differs from the random forest; each new tree built by gradient boosting tree attempts to correct errors made by the previous tree. We use GBTClassifier from the pyspark.ml.classification library for training and validating the data.", "Now that we\u2019ve trained and validated several models, we make predictions on unseen test data. We can retrain the model on all available training data and then make predictions. The following code demonstrates how to make predictions using the Gradient boosting model. However, you can repeat the same for any of the trained models and also the full code for prediction using other models is available on Github.", "Once you\u2019ve made the predictions, you can convert the dataframe to a CSV format and submit it to the competition. You are now armed to use Spark for developing Machine Learning models. There are myriad applications of Text Classification, such as identifying spam emails, tagging website/product content, etc. and the above algorithms are applicable for all such tasks. Hopefully, you find this useful and will let me know what you think. Happy Learning!", "Thank you for reading. I hope you find this helpful. If you have any suggestions, please add them in the comments section. Feel free to connect with me on my Website or LinkedIn.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Traveler | Introvert | Avid Reader | Trekker | Adventurer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9efef3564270&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9efef3564270--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@surajmalpani?source=post_page-----9efef3564270--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajmalpani?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Suraj Malpani"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5120c2f3f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&user=Suraj+Malpani&userId=5120c2f3f19&source=post_page-5120c2f3f19----9efef3564270---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@8moments?utm_source=medium&utm_medium=referral", "anchor_text": "Simon Matzinger"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/nlp-getting-started", "anchor_text": "\u2018NLP with Disaster Tweets\u2019 Kaggle competition."}, {"url": "https://github.com/SurajMalpani/NLP-using-Spark/blob/master/nlp-using-pyspark-ml.ipynb", "anchor_text": "GitHub."}, {"url": "https://monkeylearn.com/text-classification/", "anchor_text": "Monkeylearn"}, {"url": "https://spark.apache.org/docs/latest/sql-programming-guide.html", "anchor_text": "Spark Dataframes"}, {"url": "https://en.wikipedia.org/wiki/Regular_expression", "anchor_text": "Regular expressions (regex)"}, {"url": "https://spark.apache.org/docs/latest/ml-features#tokenizer", "anchor_text": "RegexTokenizer()"}, {"url": "https://spark.apache.org/docs/2.2.0/ml-features.html#stopwordsremover", "anchor_text": "StopWordsRemover()"}, {"url": "https://spark.apache.org/docs/2.2.0/ml-features.html#countvectorizer", "anchor_text": "CountVectorizer()"}, {"url": "https://en.wikipedia.org/wiki/Statistical_classification", "anchor_text": "classification machine learning algorithms."}, {"url": "https://en.wikipedia.org/wiki/Logistic_function", "anchor_text": "a logistic function"}, {"url": "https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76", "anchor_text": "article"}, {"url": "https://github.com/SurajMalpani/NLP-using-Spark", "anchor_text": "Github."}, {"url": "https://surajmalpani.github.io/", "anchor_text": "Website"}, {"url": "https://www.linkedin.com/in/suraj-malpani/", "anchor_text": "LinkedIn"}, {"url": "https://spark.apache.org/docs/2.2.0/ml-classification-regression.html", "anchor_text": "https://spark.apache.org/docs/2.2.0/ml-classification-regression.html"}, {"url": "https://monkeylearn.com/text-classification/", "anchor_text": "https://monkeylearn.com/text-classification/"}, {"url": "https://www.kaggle.com/palmer0/binary-classification-with-pyspark-and-mllib", "anchor_text": "https://www.kaggle.com/palmer0/binary-classification-with-pyspark-and-mllib"}, {"url": "https://github.com/lp-dataninja/SparkML/blob/master/pyspark-nlp-kaggle.ipynb", "anchor_text": "https://github.com/lp-dataninja/SparkML/blob/master/pyspark-nlp-kaggle.ipynb"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9efef3564270---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----9efef3564270---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9efef3564270---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/spark?source=post_page-----9efef3564270---------------spark-----------------", "anchor_text": "Spark"}, {"url": "https://medium.com/tag/programming?source=post_page-----9efef3564270---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&user=Suraj+Malpani&userId=5120c2f3f19&source=-----9efef3564270---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&user=Suraj+Malpani&userId=5120c2f3f19&source=-----9efef3564270---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9efef3564270--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9efef3564270&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9efef3564270---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9efef3564270--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9efef3564270--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9efef3564270--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9efef3564270--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9efef3564270--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajmalpani?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajmalpani?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Suraj Malpani"}, {"url": "https://medium.com/@surajmalpani/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "126 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5120c2f3f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&user=Suraj+Malpani&userId=5120c2f3f19&source=post_page-5120c2f3f19--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8238879270d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-with-spark-9efef3564270&newsletterV3=5120c2f3f19&newsletterV3Id=8238879270d3&user=Suraj+Malpani&userId=5120c2f3f19&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}