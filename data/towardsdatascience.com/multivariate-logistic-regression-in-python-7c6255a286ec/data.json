{"url": "https://towardsdatascience.com/multivariate-logistic-regression-in-python-7c6255a286ec", "time": 1683008903.594441, "path": "towardsdatascience.com/multivariate-logistic-regression-in-python-7c6255a286ec/", "webpage": {"metadata": {"title": "Multivariate Logistic Regression in Python | by Sowmya Krishnan | Towards Data Science", "h1": "Multivariate Logistic Regression in Python", "description": "You probably use machine learning dozens of times a day without even knowing it. A simple web search on Google works so well because the ML software behind it has learnt to figure out which pages to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/sowmya20", "anchor_text": "https://github.com/sowmya20", "paragraph_index": 52}, {"url": "https://asbeyondwords.wordpress.com/", "anchor_text": "https://asbeyondwords.wordpress.com/", "paragraph_index": 52}], "all_paragraphs": ["You probably use machine learning dozens of times a day without even knowing it. A simple web search on Google works so well because the ML software behind it has learnt to figure out which pages to be ranked and how. Similarly, you are saved from wading through a ton of spam in your email because your computer has learnt to distinguish between spam & a non-spam email.", "Machine learning is a smart alternative to analyzing vast amounts of data. Based on the tasks performed and the nature of the output, you can classify machine learning models into three types:", "A large number of important problem areas within the realm of classification \u2014 an important area of supervised machine learning. And despite the term \u2018Regression\u2019 in Logistic Regression \u2014 it is, in fact, one of the most basic classification algorithms. Unlike linear regression which outputs continuous number values, logistic regression uses the logistic sigmoid function to transform its output to return a probability value which can then be mapped to two or more discrete classes.", "Before we begin building a multivariate logistic regression model, there are certain conceptual pre-requisites that we need to familiarize ourselves with.", "Earlier we spoke about mapping values to probabilities. This can be achieved by calling the sigmoid function, which will map any real value into another value between 0 and 1. Machine learning uses this function to map predictions to probabilities.", "Where, f(x) = output between 0 and 1 (probability estimate)", "To get a better sense of what a logistic regression hypothesis function computes, we need to know of a concept called \u2018decision boundary\u2019. The prediction function that we are using will return a probability score between 0 and 1. To map this score to a discrete class (positive/negative, true/false), we select a threshold value, say 0.5, above which we classify values into class 1 and below which the values will fall into class 2.", "For instance, say the prediction function returns a value of 0.8, this would get classified as true/positive (as it is above the selected value of threshold). A value of 0.3, on the other hand, would get classified as false/negative. When dealing with multivariate logistic regression, we select the class with the highest predicted probability.", "Logistic regression work with odds rather than proportions. The odds are simply calculated as a ratio of proportions of two possible outcomes. Let p be the proportion of one outcome, then 1-p will be the proportion of the second outcome.", "The statistical model for logistic regression is", "To understand the working of multivariate logistic regression, we\u2019ll consider a problem statement from an online education platform where we\u2019ll look at factors that help us select the most promising leads, i.e. the leads that are most likely to convert into paying customers.", "Note: Please follow the below given link (GitHub Repo) to find the dataset, data dictionary and a detailed solution to this problem statement.", "Once you load the necessary libraries and the dataset, let\u2019s have a look at the first few entries using the head() command.", "The shape commands tells us the dataset has a total of 9240 data points and 37 columns. Below listed are the name of the columns present in this dataset:", "As you can see, most of the feature variables listed are quite intuitive. Please refer to the data dictionary to understand them better.", "Further analysis reveals the presence of categorical variables in the dataset for which we would need to create dummy variables. Before that, we treat the dataset to remove null value columns and rows and variables that we think won\u2019t be necessary for this analysis (eg, city, country) A quick check for the percentage of retained rows tells us that 69% of the rows have been retained which seems good enough.", "The target variable for this dataset is \u2018Converted\u2019 which tells us if a past lead was converted or not, wherein 1 means it was converted and 0 means it wasn\u2019t converted.", "Import the test_train_split library and make a 70% train and 30% test split on the dataset.", "Few numeric variables in the dataset have different scales, so scale these variables using the MinMax scaler. The variables will be scaled in such a way that all the values will lie between zero and one using the maximum and the minimum values in the data.", "Moving on to the model building part, we see there are a lot of variables in this dataset that we cannot deal with. Hence, we\u2019ll use RFE to select a small set of features from this pool. Below is the code for the same:", "We\u2019ll now use statsmodels to create a logistic regression models based on p-values and VIFs. To begin with we\u2019ll create a model on the train set after adding a constant and output the summary. This is how the generalized model regression results would look like:", "We\u2019ll also compute the VIFs of all features in a similar fashion and drop variables with a high p-value and a high VIF. After re-fitting the model with the new set of features, we\u2019ll once again check for the range in which the p-values and VIFs lie. If appropriate, we\u2019ll proceed with model evaluation as the next step.", "We\u2019ll now predict the probabilities on the train set and create a new dataframe containing the actual conversion flag and the probabilities predicted by the model. Add a column to capture the predicted values with a condition of being equal to 1 (in case value for paid probability is greater than 0.5) or else 0.", "Some important concepts to be familiar with before we begin evaluating the model:", "We define classification accuracy as the ratio of correct predictions to total predictions. One of the major issues with this approach is that it often hides the very detail that you might require to better understand the performance of your model. A very likely example where you can encounter this problem is when you\u2019re working with a data having more than 2 classes. You may achieve an accuracy rate of, say 85%, but you\u2019ll not know if this is because some classes are being neglected by your model or whether all of them are being predicted equally well.", "Confusion matrix combats this problem. It tells you the exact number of ways your model is confused when it makes predictions.", "It is a summary of prediction results on a classification model.", "In two-class problems, we construct a confusion matrix by assigning the event row as \u201cpositive\u201d and the no-event row as \u201cnegative\u201d. The event column of predictions is assigned as \u201ctrue\u201d and the no-event one as \u201cfalse\u201d.", "The matrix would then consist of the following elements:", "(i) True positive \u2014 for correctly precited event values", "(ii) True negative \u2014 for correctly predicted no-event values", "(iii) False positive \u2014 for incorrectly predicted event values", "(iv) False negative \u2014 for incorrectly predicted no-event values", "Some basic performance measures derived from the confusion matrix are:", "(a) Sensitivity: Sensitivity (SN) is calculated as the number of correct positive predictions divided by the total number of positives. It is also called recall (REC) or true positive rate (TPR).", "(b) Specificity: Specificity (SP) is calculated as the number of correct negative predictions divided by the total number of negatives. It is also called true negative rate (TNR).", "(c) Precision: Precision (PREC) is calculated as the number of correct positive predictions divided by the total number of positive predictions. It is also called positive predictive value (PPV)", "(d) Recall: This is the fraction of all existing positives that we predict correctly.", "We\u2019ll use the above matrix and the metrics to evaluate the model. 0.5 was a randomly selected value to test the model performance. We need to optimise the threshold to get better results, which we\u2019ll do by plotting and analysing the ROC curve.", "The Receiver Operating Characteristic curve is basically a plot between false positive rate and true positive rate for a number of threshold values lying between 0 and 1.", "The ROC curve helps us compare curves of different models with different thresholds whereas the AUC (area under the curve) gives us a summary of the model skill.", "Here, the AUC is 0.86 which seems quite good. To find the optimal cut-off point, let\u2019s also check for sensitivity and specificity of the model at different probability cut-offs and plot the same.", "At 0.42, the curves of the three metrics seem to intersect and therefore we\u2019ll choose this as our cut-off value. (You may want to calculate the metrics, again, using this point) We\u2019ll make predictions on the test set following the same approach.", "When building a classification model, we need to consider both precision and recall. It is always possible to increase one value at the expense of the other (recall-focussed model/precision-focussed model). In choosing an optimal value for both these metrics, we should always keep in mind the type of problem we are aiming to solve.", "The trade-off curve and the metrics seem to suggest the cut-off point we have chosen is optimal. So we\u2019ll run one final prediction on our test set and confirm the metrics.", "The metrics seem to hold on the test data. Looks like we have created a decent model as the metrics are decent for both the test and the train datasets.", "You are now familiar with the basics of building and evaluating logistic regression models using Python. Generally, it is a straightforward approach:", "(i) Import the necessary packages and libraries", "(iii) Classification model to be created and trained with the existing data", "(iv) Evaluate and check for model performance", "(v) Make predictions on the test sets", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A business analyst/data scientist, I write about almost anything that interests me. https://github.com/sowmya20 | https://asbeyondwords.wordpress.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7c6255a286ec&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@svak1962?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@svak1962?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Sowmya Krishnan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F292301e5d539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&user=Sowmya+Krishnan&userId=292301e5d539&source=post_page-292301e5d539----7c6255a286ec---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#sigmoid-activation", "anchor_text": "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#sigmoid-activation"}, {"url": "https://github.com/sowmya20/LeadConversion_LogReg", "anchor_text": "sowmya20/LeadConversion_LogRegContribute to sowmya20/LeadConversion_LogReg development by creating an account on GitHub.github.com"}, {"url": "https://medium.com/tag/python?source=post_page-----7c6255a286ec---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----7c6255a286ec---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/confusion-matrix?source=post_page-----7c6255a286ec---------------confusion_matrix-----------------", "anchor_text": "Confusion Matrix"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7c6255a286ec---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/classification-models?source=post_page-----7c6255a286ec---------------classification_models-----------------", "anchor_text": "Classification Models"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&user=Sowmya+Krishnan&userId=292301e5d539&source=-----7c6255a286ec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&user=Sowmya+Krishnan&userId=292301e5d539&source=-----7c6255a286ec---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7c6255a286ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7c6255a286ec---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7c6255a286ec--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7c6255a286ec--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7c6255a286ec--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@svak1962?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@svak1962?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sowmya Krishnan"}, {"url": "https://medium.com/@svak1962/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "75 Followers"}, {"url": "https://github.com/sowmya20", "anchor_text": "https://github.com/sowmya20"}, {"url": "https://asbeyondwords.wordpress.com/", "anchor_text": "https://asbeyondwords.wordpress.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F292301e5d539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&user=Sowmya+Krishnan&userId=292301e5d539&source=post_page-292301e5d539--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb8608f7ff229&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultivariate-logistic-regression-in-python-7c6255a286ec&newsletterV3=292301e5d539&newsletterV3Id=b8608f7ff229&user=Sowmya+Krishnan&userId=292301e5d539&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}