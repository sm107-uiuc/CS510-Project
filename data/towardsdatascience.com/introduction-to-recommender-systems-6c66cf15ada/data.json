{"url": "https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada", "time": 1682996461.1488159, "path": "towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada/", "webpage": {"metadata": {"title": "Introduction to recommender systems | by Baptiste Rocca | Towards Data Science", "h1": "Introduction to recommender systems", "description": "During the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/b17ebd108358?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Joseph Rocca", "paragraph_index": 0}, {"url": "https://medium.com/u/b17ebd108358?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Joseph Rocca", "paragraph_index": 66}], "all_paragraphs": ["This post was co-written with Joseph Rocca.", "During the last few decades, with the rise of Youtube, Amazon, Netflix and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.", "In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy or anything else depending on industries).", "Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. As a proof of the importance of recommender systems, we can mention that, a few years ago, Netflix organised a challenges (the \u201cNetflix prize\u201d) where the goal was to produce a recommender system that performs better than its own algorithm with a prize of 1 million dollars to win.", "In this article, we will go through different paradigms of recommender systems. For each of them, we will present how they work, describe their theoretical basis and discuss their strengths and weaknesses.", "In the first section we are going to overview the two major paradigms of recommender systems : collaborative and content based methods. The next two sections will then describe various methods of collaborative filtering, such as user-user, item-item and matrix factorization. The following section will be dedicated to content based methods and how they work. Finally, we will discuss how to evaluate a recommender system.", "The purpose of a recommender system is to suggest relevant items to users. To achieve this task, there exist two major categories of methods : collaborative filtering methods and content based methods. Before digging more into details of particular algorithms, let\u2019s discuss briefly these two main paradigms.", "Collaborative methods for recommender systems are methods that are based solely on the past interactions recorded between users and items in order to produce new recommendations. These interactions are stored in the so-called \u201cuser-item interactions matrix\u201d.", "Then, the main idea that rules collaborative methods is that these past user-item interactions are sufficient to detect similar users and/or similar items and make predictions based on these estimated proximities. The class of collaborative filtering algorithms is divided into two sub-categories that are generally called memory based and model based approaches. Memory based approaches directly works with values of recorded interactions, assuming no model, and are essentially based on nearest neighbours search (for example, find the closest users from a user of interest and suggest the most popular items among these neighbours). Model based approaches assume an underlying \u201cgenerative\u201d model that explains the user-item interactions and try to discover it in order to make new predictions.", "The main advantage of collaborative approaches is that they require no information about users or items and, so, they can be used in many situations. Moreover, the more users interact with items the more new recommendations become accurate: for a fixed set of users and items, new interactions recorded over time bring new information and make the system more and more effective.", "However, as it only consider past interactions to make recommendations, collaborative filtering suffer from the \u201ccold start problem\u201d: it is impossible to recommend anything to new users or to recommend a new item to any users and many users or items have too few interactions to be efficiently handled. This drawback can be addressed in different way: recommending random items to new users or new items to random users (random strategy), recommending popular items to new users or new items to most active users (maximum expectation strategy), recommending a set of various items to new users or a new item to a set of various users (exploratory strategy) or, finally, using a non collaborative method for the early life of the user or the item.", "In the following sections, we will mainly present three classical collaborative filtering approaches: two memory based methods (user-user and item-item) and one model based approach (matrix factorisation).", "Unlike collaborative methods that only rely on the user-item interactions, content based approaches use additional information about users and/or items. If we consider the example of a movies recommender system, this additional information can be, for example, the age, the sex, the job or any other personal information for users as well as the category, the main actors, the duration or other characteristics for the movies (items).", "Then, the idea of content based methods is to try to build a model, based on the available \u201cfeatures\u201d, that explain the observed user-item interactions. Still considering users and movies, we will try, for example, to model the fact that young women tend to rate better some movies, that young men tend to rate better some other movies and so on. If we manage to get such model, then, making new predictions for a user is pretty easy: we just need to look at the profile (age, sex, \u2026) of this user and, based on this information, to determine relevant movies to suggest.", "Content based methods suffer far less from the cold start problem than collaborative approaches: new users or items can be described by their characteristics (content) and so relevant suggestions can be done for these new entities. Only new users or items with previously unseen features will logically suffer from this drawback, but once the system old enough, this has few to no chance to happen.", "Later in this post, we will further discuss content based approaches and see that, depending on our problem, various classification or regression models can be used, ranging from very simple to much more complex models.", "Let\u2019s focus a bit more on the main differences between the previously mentioned methods. More especially let\u2019s see the implication that the modelling level has on the bias and the variance.", "In memory based collaborative methods, no latent model is assumed. The algorithms directly works with the user-item interactions: for example, users are represented by their interactions with items and a nearest neighbours search on these representations is used to produce suggestions. As no latent model is assumed, these methods have theoretically a low bias but a high variance.", "In model based collaborative methods, some latent interaction model is assumed. The model is trained to reconstruct user-item interactions values from its own representation of users and items. New suggestions can then be done based on this model. The users and items latent representations extracted by the model have a mathematical meaning that can be hard to interpret for a human being. As a (pretty free) model for user-item interactions is assumed, this methods has theoretically a higher bias but a lower variance than methods assuming no latent model.", "Finally, in content based methods some latent interaction model is also assumed. However, here, the model is provided with content that define the representation of users and/or items: for example, users are represented by given features and we try to model for each item the kind of user profile that likes or not this item. Here, as for model based collaborative methods, a user-item interactions model is assumed. However, this model is more constrained (because representation of users and/or items are given) and, so, the method tends to have the highest bias but the lowest variance.", "The main characteristics of user-user and item-item approaches it that they use only information from the user-item interaction matrix and they assume no model to produce new recommendations.", "In order to make a new recommendation to a user, user-user method roughly tries to identify users with the most similar \u201cinteractions profile\u201d (nearest neighbours) in order to suggest items that are the most popular among these neighbours (and that are \u201cnew\u201d to our user). This method is said to be \u201cuser-centred\u201d as it represent users based on their interactions with items and evaluate distances between users.", "Assume that we want to make a recommendation for a given user. First, every user can be represented by its vector of interactions with the different items (\u201cits line\u201d in the interaction matrix). Then, we can compute some kind of \u201csimilarity\u201d between our user of interest and every other users. That similarity measure is such that two users with similar interactions on the same items should be considered as being close. Once similarities to every users have been computed, we can keep the k-nearest-neighbours to our user and then suggest the most popular items among them (only looking at the items that our reference user has not interacted with yet).", "Notice that, when computing similarity between users, the number of \u201ccommon interactions\u201d (how much items have already been considered by both users?) should be considered carefully! Indeed, most of the time, we want to avoid that someone that only have one interaction in common with our reference user could have a 100% match and be considered as being \u201ccloser\u201d than someone having 100 common interactions and agreeing \u201conly\u201d on 98% of them. So, we consider that two users are similar if they have interacted with a lot of common items in the same way (similar rating, similar time hovering\u2026).", "To make a new recommendation to a user, the idea of item-item method is to find items similar to the ones the user already \u201cpositively\u201d interacted with. Two items are considered to be similar if most of the users that have interacted with both of them did it in a similar way. This method is said to be \u201citem-centred\u201d as it represent items based on interactions users had with them and evaluate distances between those items.", "Assume that we want to make a recommendation for a given user. First, we consider the item this user liked the most and represent it (as all the other items) by its vector of interaction with every users (\u201cits column\u201d in the interaction matrix). Then, we can compute similarities between the \u201cbest item\u201d and all the other items. Once the similarities have been computed, we can then keep the k-nearest-neighbours to the selected \u201cbest item\u201d that are new to our user of interest and recommend these items.", "Notice that in order to get more relevant recommendations, we can do this job for more than only the user\u2019s favourite item and consider the n preferred items instead. In this case, we can recommend items that are close to several of these preferred items.", "The user-user method is based on the search of similar users in terms of interactions with items. As, in general, every user have only interacted with a few items, it makes the method pretty sensitive to any recorded interactions (high variance). On the other hand, as the final recommendation is only based on interactions recorded for users similar to our user of interest, we obtain more personalized results (low bias).", "Conversely, the item-item method is based on the search of similar items in terms of user-item interactions. As, in general, a lot of users have interacted with an item, the neighbourhood search is far less sensitive to single interactions (lower variance). As a counterpart, interactions coming from every kind of users (even users very different from our reference user) are then considered in the recommendation, making the method less personalised (more biased). Thus, this approach is less personalized than the user-user approach but more robust.", "One of the biggest flaw of memory based collaborative filtering is that they do not scale easily: generating a new recommendation can be extremely time consuming for big systems. Indeed, for systems with millions of users and millions of items, the nearest neighbours search step can become intractable if not carefully designed (KNN algorithm has a complexity of O(ndk) with n the number of users, d the number of items and k the number of considered neighbours). In order to make computations more tractable for huge systems, we can both take advantage of the sparsity of the interaction matrix when designing our algorithm or use approximate nearest neighbours methods (ANN).", "In most of the recommendation algorithms, it is necessary to be extremely careful to avoid a \u201crich-get-richer\u201d effect for popular items and to avoid getting users stuck into what could be called an \u201cinformation confinement area\u201d. In other words, we do not want that our system tend to recommend more and more only popular items as well as we do not want that our users only receive recommendations for items extremely close to the one they already liked with no chance to get to know new items they might like too (as these items are not \u201cclose enough\u201d to be suggested). If, as we mentioned, these problems can arise in most of the recommendation algorithms, it is especially true for memory based collaborative ones. Indeed, with the lack of model \u201cto regularise\u201d, this kind of phenomenon can be accentuated and observed more frequently.", "Model based collaborative approaches only rely on user-item interactions information and assume a latent model supposed to explain these interactions. For example, matrix factorisation algorithms consists in decomposing the huge and sparse user-item interaction matrix into a product of two smaller and dense matrices: a user-factor matrix (containing users representations) that multiplies a factor-item matrix (containing items representations).", "The main assumption behind matrix factorisation is that there exists a pretty low dimensional latent space of features in which we can represent both users and items and such that the interaction between a user and an item can be obtained by computing the dot product of corresponding dense vectors in that space.", "For example, consider that we have a user-movie rating matrix. In order to model the interactions between users and movies, we can assume that:", "However we don\u2019t want to give explicitly these features to our model (as it could be done for content based approaches that we will describe later). Instead, we prefer to let the system discover these useful features by itself and make its own representations of both users and items. As they are learned and not given, extracted features taken individually have a mathematical meaning but no intuitive interpretation (and, so, are difficult, if not impossible, to understand as human). However, it is not unusual to ends up having structures emerging from that type of algorithm being extremely close to intuitive decomposition that human could think about. Indeed, the consequence of such factorisation is that close users in terms of preferences as well as close items in terms of characteristics ends up having close representations in the latent space.", "In this subsection, we will give a simple mathematical overview of matrix factorization. More especially, we describe a classical iterative approach based on gradient descent that makes possible to obtain factorisations for very large matrices without loading all the data at the same time in computer\u2019s memory.", "Let\u2019s consider an interaction matrix M (nxm) of ratings where only some items have been rated by each user (most of the interactions are set to None to express the lack of rating). We want to factorise that matrix such that", "where X is the \u201cuser matrix\u201d (nxl) whose rows represent the n users and where Y is the \u201citem matrix\u201d (mxl) whose rows represent the m items:", "Here l is the dimension of the latent space in which users and item will be represented. So, we search for matrices X and Y whose dot product best approximate the existing interactions. Denoting E the ensemble of pairs (i,j) such that M_ij is set (not None), we want to find X and Y that minimise the \u201crating reconstruction error\u201d", "Adding a regularisation factor and dividing by 2, we get", "The matrices X and Y can then be obtained following a gradient descent optimisation process for which we can notice two things. First, the gradient do not have to be computed over all the pairs in E at each step and we can consider only a subset of these pairs so that we optimise our objective function \u201cby batch\u201d. Second, values in X and Y do not have to be updated simultaneously and the gradient descent can be done alternatively on X and Y at each step (doing so, we consider one matrix fixed and optimise for the other before doing the opposite at the next iteration).", "Once the matrix has been factorised, we have less information to manipulate in order to make a new recommendation: we can simply multiply a user vector by any item vector in order to estimate the corresponding rating. Notice that we could also use user-user and item-item methods with these new representations of users and items: (approximate) nearest neighbours searches wouldn\u2019t be done over huge sparse vectors but over small dense ones making some approximation techniques more tractable.", "We can finally notice that the concept of this basic factorisation can be extended to more complex models with, for example, more general neural network like \u201cdecomposition\u201d (we cannot strictly speak about \u201cfactorisation\u201d anymore). The first direct adaptation we can think of concerns boolean interactions. If we want to reconstruct boolean interactions, a simple dot product is not well adapted. If, however, we add a logistic function on top of that dot product, we get a model that takes its value in [0, 1] and, so, better fit the problem. In such case, the model to optimise is", "with f(.) our logistic function. Deeper neural network models are often used to achieve near state of the art performances in complex recommender systems.", "In the previous two sections we mainly discussed user-user, item-item and matrix factorisation approaches. These methods only consider the user-item interaction matrix and, so, belong to the collaborative filtering paradigm. Let\u2019s now describe the content based paradigm.", "In content based methods, the recommendation problem is casted into either a classification problem (predict if a user \u201clikes\u201d or not an item) or into a regression problem (predict the rating given by a user to an item). In both cases, we are going to set a model that will be based on the user and/or item features at our disposal (the \u201ccontent\u201d of our \u201ccontent-based\u201d method).", "If our classification (or regression) is based on users features, we say the approach is item-centred: modelling, optimisations and computations can be done \u201cby item\u201d. In this case, we build and learn one model by item based on users features trying to answer the question \u201cwhat is the probability for each user to like this item?\u201d (or \u201cwhat is the rate given by each user to this item?\u201d, for regression). The model associated to each item is naturally trained on data related to this item and it leads, in general, to pretty robust models as a lot of users have interacted with the item. However, the interactions considered to learn the model come from every users and even if these users have similar characteristic (features) their preferences can be different. This mean that even if this method is more robust, it can be considered as being less personalised (more biased) than the user-centred method thereafter.", "If we are working with items features, the method is then user-centred: modelling, optimisations and computations can be done \u201cby user\u201d. We then train one model by user based on items features that tries to answer the question \u201cwhat is the probability for this user to like each item?\u201d (or \u201cwhat is the rate given by this user to each item?\u201d, for regression). We can then attach a model to each user that is trained on its data: the model obtained is, so, more personalised than its item-centred counterpart as it only takes into account interactions from the considered user. However, most of the time a user has interacted with relatively few items and, so, the model we obtain is a far less robust than an item-centred one.", "From a practical point of view, we should underline that, most of the time, it is much more difficult to ask some information to a new user (users do not want to answer too much questions) than to ask lot of information about a new item (people adding them have an interest in filling these information in order to make their items recommended to the right users). We can also notice that, depending on the complexity of the relation to express, the model we build can be more or less complex, ranging from basic models (logistic/linear regression for classification/regression) to deep neural networks. Finally, let\u2019s mention that content based methods can also be neither user nor item centred: both informations about user and item can be used for our models, for example by stacking the two features vectors and making them go through a neural network architecture.", "Let\u2019s first consider the case of an item-centred classification: for each item we want to train a Bayesian classifier that takes user features as inputs and output either \u201clike\u201d or \u201cdislike\u201d. So, to achieve the classification task, we want to compute", "the ratio between the probability for a user with given features to like the considered item and its probability to dislike it. This ratio of conditional probabilities that defines our classification rule (with a simple threshold) can be expressed following the Bayes formula", "are priors computed from the data whereas", "are likelihoods assumed to follow Gaussian distributions with parameters to be determined also from data. Various hypothesis can be done about the covariance matrices of these two likelihood distributions (no assumption, equality of matrices, equality of matrices and features independence) leading to various well known models (quadratic discriminant analysis, linear discriminant analysis, naive Bayes classifier). We can underline once more that, here, likelihood parameters have to be estimated only based on data (interactions) related to the considered item.", "Let\u2019s now consider the case of a user-centred regression: for each user we want to train a simple linear regression that takes item features as inputs and output the rating for this item. We still denote M the user-item interaction matrix, we stack into a matrix X row vectors representing users coefficients to be learned and we stack into a matrix Y row vectors representing items features that are given. Then, for a given user i, we learn the coefficients in X_i by solving the following optimisation problem", "where one should keep in mind that i is fixed and, so, the first summation is only over (user, item) pairs that concern user i. We can observe that if we solve this problem for all the users at the same time, the optimisation problem is exactly the same as the one we solve in \u201calternated matrix factorisation\u201d when we keep items fixed. This observation underlines the link we mentioned in the first section: model based collaborative filtering approaches (such as matrix factorisation) and content based methods both assume a latent model for user-item interactions but model based collaborative approaches have to learn latent representations for both users and items whereas content-based methods build a model upon human defined features for users and/or items.", "As for any machine learning algorithm, we need to be able to evaluate the performances of our recommender systems in order to decide which algorithm fit the best our situation. Evaluation methods for recommender systems can mainly be divided in two sets: evaluation based on well defined metrics and evaluation mainly based on human judgment and satisfaction estimation.", "If our recommender system is based on a model that outputs numeric values such as ratings predictions or matching probabilities, we can assess the quality of these outputs in a very classical manner using an error measurement metric such as, for example, mean square error (MSE). In this case, the model is trained only on a part of the available interactions and is tested on the remaining ones.", "Still if our recommender system is based on a model that predicts numeric values, we can also binarize these values with a classical thresholding approach (values above the threshold are positive and values bellow are negative) and evaluate the model in a more \u201cclassification way\u201d. Indeed, as the dataset of user-item past interactions is also binary (or can be binarized by thresholding), we can then evaluate the accuracy (as well as the precision and the recall) of the binarized outputs of the model on a test dataset of interactions not used for training.", "Finally, if we now consider a recommender system not based on numeric values and that only returns a list of recommendations (such as user-user or item-item that are based on a knn approach), we can still define a precision like metric by estimating the proportion of recommended items that really suit our user. To estimate this precision, we can not take into account recommended items that our user has not interacted with and we should only consider items from the test dataset for which we have a user feedback.", "When designing a recommender system, we can be interested not only to obtain model that produce recommendations we are very sure about but we can also expect some other good properties such as diversity and explainability of recommendations.", "As mentioned in the collaborative section, we absolutely want to avoid having a user being stuck in what we called earlier an information confinement area. The notion of \u201cserendipity\u201d is often used to express the tendency a model has or not to create such a confinement area (diversity of recommendations). Serendipity, that can be estimated by computing the distance between recommended items, should not be too low as it would create confinement areas, but should also not be too high as it would mean that we do not take enough into account our users interests when making recommendations (exploration vs exploitation). Thus, in order to bring diversity in the suggested choices, we want to recommend items that both suit our user very well and that are not too similar from each others. For example, instead of recommending a user \u201cStart Wars\u201d 1, 2 and 3, it seems better to recommend \u201cStar wars 1\u201d, \u201cStart trek into darkness\u201d and \u201cIndiana Jones and the raiders of the lost ark\u201d: the two later may be seen by our system as having less chance to interest our user but recommending 3 items that look too similar is not a good option.", "Explainability is another key point of the success of recommendation algorithms. Indeed, it has been proven that if users do not understand why they had been recommended as specific item, they tend to loose confidence into the recommender system. So, if we design a model that is clearly explainable, we can add, when making recommendations, a little sentence stating why an item has been recommended (\u201cpeople who liked this item also liked this one\u201d, \u201cyou liked this item, you may be interested by this one\u201d, \u2026).", "Finally, on top of the fact that diversity and explainability can be intrinsically difficult to evaluate, we can notice that it is also pretty difficult to assess the quality of a recommendation that do not belong to the testing dataset: how to know if a new recommendation is relevant before actually recommending it to our user? For all these reasons, it can sometimes be tempting to test the model in \u201creal conditions\u201d. As the goal of the recommender system is to generate an action (watch a movie, buy a product, read an article etc\u2026), we can indeed evaluate its ability to generate the expected action. For example, the system can be put in production, following an A/B testing approach, or can be tested only on a sample of users. Such processes require, however, having a certain level of confidence in the model.", "The main takeaways of this article are:", "We should notice that we have not discussed hybrid approaches in this introductory post. These methods, that combine collaborative filtering and content based approaches, achieves state-of-the-art results in many cases and are, so, used in many large scale recommender systems nowadays. The combination made in hybrid approaches can mainly take two forms: we can either train two models independently (one collaborative filtering model and one content based model) and combine their suggestions or directly build a single model (often a neural network) that unify both approaches by using as inputs prior information (about user and/or item) as well as \u201ccollaborative\u201d interactions information.", "As we mentioned in the introduction of this post, recommender systems are becoming essential in many industries and, hence, have received always more attention in the recent years. In this article, we have introduced basics notions required for a better understanding of the questions related to these systems, but we highly encourage interested readers to explore this field further\u2026 without giving, ironically, any specific reading recommendations!", "Last articles written with Joseph Rocca:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6c66cf15ada&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@baptiste.rocca?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baptiste.rocca?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Baptiste Rocca"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F20ad1309823a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&user=Baptiste+Rocca&userId=20ad1309823a&source=post_page-20ad1309823a----6c66cf15ada---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/fr/users/stocksnap-894430/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2596809", "anchor_text": "StockSnap"}, {"url": "https://pixabay.com/", "anchor_text": "Pixabay"}, {"url": "https://medium.com/u/b17ebd108358?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Joseph Rocca"}, {"url": "https://medium.com/u/b17ebd108358?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Joseph Rocca"}, {"url": "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205", "anchor_text": "Ensemble methods: bagging, boosting and stackingUnderstanding the key concepts of ensemble learning.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/brief-introduction-to-markov-chains-2c8cab9c98ab", "anchor_text": "A brief introduction to Markov chainsDefinitions, properties and PageRank example.towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6c66cf15ada---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6c66cf15ada---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6c66cf15ada---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6c66cf15ada---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----6c66cf15ada---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&user=Baptiste+Rocca&userId=20ad1309823a&source=-----6c66cf15ada---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&user=Baptiste+Rocca&userId=20ad1309823a&source=-----6c66cf15ada---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6c66cf15ada&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6c66cf15ada---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6c66cf15ada--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6c66cf15ada--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6c66cf15ada--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baptiste.rocca?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@baptiste.rocca?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Baptiste Rocca"}, {"url": "https://medium.com/@baptiste.rocca/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F20ad1309823a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&user=Baptiste+Rocca&userId=20ad1309823a&source=post_page-20ad1309823a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffea591ab16a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-recommender-systems-6c66cf15ada&newsletterV3=20ad1309823a&newsletterV3Id=fea591ab16a4&user=Baptiste+Rocca&userId=20ad1309823a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}