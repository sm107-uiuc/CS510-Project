{"url": "https://towardsdatascience.com/natural-language-processing-workflow-1dddf3a48ab5", "time": 1683016818.47629, "path": "towardsdatascience.com/natural-language-processing-workflow-1dddf3a48ab5/", "webpage": {"metadata": {"title": "Natural Language Processing Workflow | by Jason Wong | Towards Data Science", "h1": "Natural Language Processing Workflow", "description": "Natural Language Processing (NLP) is the study of how computers interact (i.e. understand, interpret, manipulate) with humans through language, (e.g. speech, text). NLP got its start from the field\u2026"}, "outgoing_paragraph_urls": [{"url": "https://docs.python.org/3/library/re.html", "anchor_text": "Regular Expressions", "paragraph_index": 6}, {"url": "https://www.theonion.com/", "anchor_text": "The Onion", "paragraph_index": 11}, {"url": "https://www.reuters.com/", "anchor_text": "Reuters", "paragraph_index": 11}, {"url": "https://shorttext.readthedocs.io/en/latest/tutorial_dtm.html", "anchor_text": "Document Term Matrix", "paragraph_index": 27}, {"url": "https://www.tutorialspoint.com/python_text_processing/python_bigrams.htm", "anchor_text": "Bigrams", "paragraph_index": 28}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html", "anchor_text": "Pointwise Mutual Information Score", "paragraph_index": 29}], "all_paragraphs": ["Natural Language Processing (NLP) is the study of how computers interact (i.e. understand, interpret, manipulate) with humans through language, (e.g. speech, text). NLP got its start from the field of Linguistics, the study of language, primarily focusing on its semantics, phonetics, and grammar. Before machine learning began to show success with NLP tasks, it was mainly programming algorithms with rule-based methods from linguistics. The machine learning methods provided better accuracy, faster processing times, and dependability, resulting in the rule-based approaches taking the back seat.", "I will be going through the NLP process from data preprocessing to model evaluation and selection. The NLP libraries used for this tutorial are:", "The concepts that will be covered are as follows:", "As with all data science projects, I will be following the CRISP-DM workflow. I have labelled steps for NLP to the right side of the CRISP-DM model in the image below.", "When working with text data, one of the first steps is to vectorize the text to create a Bag of Words (BoW). This bag will hold information about the individual words, e.g., a count of how many times each word appears in a corpus. The words in the bag are not in any specific order and if we have a large enough corpus, we may begin to notice patterns.", "Before creating a BoW, the text data needs to be cleaned and tokenized. This will prevent the words with different punctuation and/or capitalization being counted separately. By removing punctuation and lowercasing everything, we\u2019re creating word tokens.", "Regular Expressions, \u201cregex\u201d for short, is a pattern describing a certain amount of text (Goyvaerts). This tool allows us to filter through and pull information from a text document without having to physically read it. Regex is especially helpful when tokenizing text by defining the rules for where strings will be split into tokens. The regular expressions library contains many useful tools:", "Instead of typing every letter in the alphabet, we can use a range from a-z. The left pattern above, [A-Z], will match on any uppercase letter. The pattern on the right, [A-Za-z0-9], will match on any uppercase letter, lowercase letter, and digit.", "Character classes, in a way, are similar to ranges. Think of these as a shortcut to ranges. The \\w class would find any lowercase word and the \\d class would match on any digit.", "Also similar to ranges, but require more specificity to match. The pattern above (A-Z0-9) can only match on that exact sequence.", "Work hand in hand with groups, giving us the ability to specify the amount of times a group need to appear in order to match. The {*} will match on a group that occurs 0 or more times, {+}, 1 or more times, and {?} 0 or 1 times.", "For this tutorial I will be using a dataset containing satirical and real news articles. The satirical articles were obtained from The Onion and the real news articles were obtained from Reuters. The satirical and real news articles as a whole can be referred to as the corpus.", "Now that the corpus has been loaded in, it\u2019s always a good idea to check how many documents there are, as well as, the class balance of the target variable.", "This corpus contains 1000 documents in the body column and 2 classes in the target column.", "This is a balanced dataset containing 500 documents of each class. Class 1 referring to a satirical article, and class 2, a real news article.", "Even though the NLTK library provides tokenizers to perform text preprocessing, manually tokenizing provides some freedom during preprocessing.", "Next, we need to remove the punctuation. We can manually do this with the String library. First, I am importing the String library and calling the punctuation function. Then I am using list comprehension to join each character together as long as the character is not a punctuation character.", "As you can see, the plot above is showing the highest frequency with stopwords. Since these words have low semantic value, they will be removed.", "Stopwords are basically filler words, e.g., prepositions and conjunctions. These words hold a low semantic value and should be removed so they aren\u2019t counted when we vectorize. We can make use of the list of stopwords provided by NLTK. Something to note, if the stopword list doesn\u2019t contain a stopword in a document, we can just add to the list.", "From the frequency distribution plot above, we can see there are still a few filler words we can add to our stopwords list. Let\u2019s go ahead and add could and one to the list.", "Numbers, like stopwords, usually have a low semantic value. This is the case for the text data we\u2019re using so let\u2019s go ahead and remove them. Removing numbers from the first document for example purposes.", "\u2018Noting that the resignation of James Mattis as Secretary of Defense marked the ouster of the third top administration official in less than three weeks, a worried populace told reporters Friday that it was unsure how many former Trump staffers it could safely reabsorb. \u201cJesus, we can\u2019t just take back these assholes all at once \u2014 we need time to process one before we get the next,\u201d said 53-year-old Gregory Birch of Naperville, IL echoing the concerns of 323 million Americans in also noting that the country was only now truly beginning to reintegrate former national security advisor Michael Flynn. \u201cThis is just not sustainable. I\u2019d say we can handle maybe one or two more former members of Trump\u2019s inner circle over the remainder of the year, but that\u2019s it. This country has its limits.\u201d The U.S. populace confirmed that they could not handle all of these pieces of shit trying to rejoin society at once.\u2019", "Stemming is a method where the end of words are removed if it shows a derivational change to the word. Basically just reducing a word tokens down to its root word. This is helpful because most of the semantic meaning of a word is in the root, and a majority of the time, the beginning of a word is the root.", "To see the difference between these two stemmers, let\u2019s stem the first_doc with them both.", "Lemming is similar to stemming but instead of just chopping off the end, uses part of speech tags when determining how to transform a word. Lemmatization reduces words showing sort of inflection in order to return a root word that belongs to the language. For example, stemming the word mice would not return mouse but lemming would.", "If we wanted to PoS tag the text ourselves, we can make use of the pos_tag function from NLTK. This function will tag each word in a document and return the word along with its PoS tag. We can then, transform the NLTK tags to the tags of the WordNetLemmatizer.", "We can make a function to transform the tags to match the WordNetLemmatizer tags.", "When performing NLP, the features can be extracted from the text by making a Bag-of-words (BoW). The BoW method will create a Document Term Matrix, a matrix where each column is a unique word and each row is a document. We can use Scikit-Learn\u2019s CountVectorizer to do this on our first_doc_lemmed.", "Instead of tokenizing the text we could also create Bigrams. A bigram is two adjacent words that are treated as one. Bigrams are helpful when performing sentiment analysis on text data, e.g., upset, barely upset. With bigrams we can apply a frequency filter to remove the bigrams that occur due to random chance. If a bigram occurs multiple times, it must have some meaning. The minimum frequency filter depends on the number of factors in the data, a normal starting value is 5 but should also be experimented with to get the most optimal value.", "Bigrams can also be created by calculating their Pointwise Mutual Information Score (PMI). This measures the mutual dependence between a pair of words. The bigram \u201csocial media\u201d would most likely return a high PMI score, the pair are more than likely appear together than not.", "TF-IDF scales down the frequencies of tokens to represent how important a word is.", "Instead of manually going through and performing the preprocessing steps above, let\u2019s just make a function to perform these steps up until count vectorizing.", "Below, I will import the necessary libraries and use the prepare_doc function above to clean the text. Next, I will perform a train test split and create a pipeline for the remaining preprocessing steps (TF-IDF Vectorizing, TF-IDF Normalisation). I will then fit the pipeline to the train split and predict on the test split.", "With NLP there are many different tools and methods you can use. It is worth taking the time to understand how the NLP libraries preprocess text in different ways, ensuring you choose the best method for your task. Making use of pipelines with the preprocessing and modeling steps help to streamline the workflow while cleaning up the code. I hope the concepts covered in this post can serve as a helpful resource when performing NLP.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist with a passion for statistical analysis and machine learning"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1dddf3a48ab5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jwong853.medium.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Jason Wong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1240e6b56e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&user=Jason+Wong&userId=e1240e6b56e3&source=post_page-e1240e6b56e3----1dddf3a48ab5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://www.shutterstock.com/g/lculig", "anchor_text": "ibreakstock"}, {"url": "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html", "anchor_text": "Documentation"}, {"url": "https://www.nltk.org/api/nltk.html", "anchor_text": "Documentation"}, {"url": "https://www.shutterstock.com/g/ievgeniiya", "anchor_text": "Ievgeniiya Ocheretna"}, {"url": "https://docs.python.org/3/library/re.html", "anchor_text": "Regular Expressions"}, {"url": "https://www.theonion.com/", "anchor_text": "The Onion"}, {"url": "https://www.reuters.com/", "anchor_text": "Reuters"}, {"url": "https://www.theonion.com/", "anchor_text": "https://www.theonion.com/"}, {"url": "https://shorttext.readthedocs.io/en/latest/tutorial_dtm.html", "anchor_text": "Document Term Matrix"}, {"url": "https://www.tutorialspoint.com/python_text_processing/python_bigrams.htm", "anchor_text": "Bigrams"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html", "anchor_text": "Pointwise Mutual Information Score"}, {"url": "http://www.tfidf.com/", "anchor_text": "TF"}, {"url": "http://www.tfidf.com/", "anchor_text": "IDF"}, {"url": "https://www.nltk.org/", "anchor_text": "https://www.nltk.org/"}, {"url": "https://scikit-learn.org/stable/", "anchor_text": "https://scikit-learn.org/stable/"}, {"url": "https://www.regular-expressions.info/tutorial.html", "anchor_text": "https://www.regular-expressions.info/tutorial.html"}, {"url": "https://machinelearningmastery.com/natural-language-processing/", "anchor_text": "https://machinelearningmastery.com/natural-language-processing/"}, {"url": "https://docs.python.org/3/library/re.html", "anchor_text": "https://docs.python.org/3/library/re.html"}, {"url": "https://www.geeksforgeeks.org/introduction-to-stemming/", "anchor_text": "https://www.geeksforgeeks.org/introduction-to-stemming/"}, {"url": "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python", "anchor_text": "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python"}, {"url": "https://shorttext.readthedocs.io/en/latest/tutorial_dtm.html", "anchor_text": "https://shorttext.readthedocs.io/en/latest/tutorial_dtm.html"}, {"url": "https://www.Reuters.com/", "anchor_text": "https://www.Reuters.com/"}, {"url": "https://www.theonion.com/", "anchor_text": "https://www.theonion.com/"}, {"url": "https://medium.com/tag/nlp?source=post_page-----1dddf3a48ab5---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1dddf3a48ab5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nltk?source=post_page-----1dddf3a48ab5---------------nltk-----------------", "anchor_text": "Nltk"}, {"url": "https://medium.com/tag/text-analytics?source=post_page-----1dddf3a48ab5---------------text_analytics-----------------", "anchor_text": "Text Analytics"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----1dddf3a48ab5---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&user=Jason+Wong&userId=e1240e6b56e3&source=-----1dddf3a48ab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&user=Jason+Wong&userId=e1240e6b56e3&source=-----1dddf3a48ab5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1dddf3a48ab5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1dddf3a48ab5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1dddf3a48ab5--------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jwong853.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jason Wong"}, {"url": "https://jwong853.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "199 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe1240e6b56e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&user=Jason+Wong&userId=e1240e6b56e3&source=post_page-e1240e6b56e3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdec1d5eb8281&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnatural-language-processing-workflow-1dddf3a48ab5&newsletterV3=e1240e6b56e3&newsletterV3Id=dec1d5eb8281&user=Jason+Wong&userId=e1240e6b56e3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}