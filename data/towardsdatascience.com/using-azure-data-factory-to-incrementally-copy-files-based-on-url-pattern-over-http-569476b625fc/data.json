{"url": "https://towardsdatascience.com/using-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc", "time": 1683014303.939171, "path": "towardsdatascience.com/using-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc/", "webpage": {"metadata": {"title": "Using Azure Data Factory to incrementally copy files based on URL pattern over HTTP | by Dhyanendra Singh Rathore | Towards Data Science", "h1": "Using Azure Data Factory to incrementally copy files based on URL pattern over HTTP", "description": "An innovative Azure Data Factory pipeline to copy multiple files incrementally based on URL pattern over HTTP from a third-party web server."}, "outgoing_paragraph_urls": [{"url": "https://github.com/CSSEGISandData/COVID-19", "anchor_text": "COVID-19 repository at GitHub", "paragraph_index": 4}, {"url": "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports", "anchor_text": "This folder", "paragraph_index": 4}, {"url": "https://portal.azure.com/", "anchor_text": "Azure Portal", "paragraph_index": 8}, {"url": "https://www.linkedin.com/in/dhyans/", "anchor_text": "LinkedIn", "paragraph_index": 46}, {"url": "https://dhyanintech.medium.com/membership", "anchor_text": "Medium", "paragraph_index": 46}], "all_paragraphs": ["Copying files using Azure Data Factory is straightforward; however, it gets tricky if the files are being hosted on a third-party web server, and the only way to copy them is by using their URL.", "In this article, we look at an innovative use of Data factory activities to generate the URLs on the fly to fetch the content over HTTP and store it in our storage account for further processing.", "Caution: Microsoft Azure is a paid service, and following this article can cause financial liability to you or your organization.", "If you don\u2019t have prerequisites set up yet, refer to our previous article for instructions on how to create them:", "This article will set up our Data factory to fetch publicly available CSV files from the COVID-19 repository at GitHub operated by Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). We\u2019re interested in the data residing within csse_covid_19_data/csse_covid_19_daily_reports. This folder contains daily case reports with new reports added once daily since January 22, 2020. Files follow a consistent naming convention of MM-DD-YYYY.csv", "A typical way of ingesting these files for our project is to download the repository as a zip from GitHub, extracting the files on your client machine, and upload the files to our storage account manually. On the other hand, we will have to upload a new file daily if we want to keep our Power BI report up to date with COVID-19 data. We want to find a solution to automate the ingesting task to keep our data up to date without additional manual efforts. We can achieve this using the Azure Data Factory. Our thought process should be:", "Activities typically contain the transformation logic or the analysis commands of the Azure Data Factory\u2019s work and defines actions to perform on your data.", "A pipeline is a logical grouping of Data Factory activities that together perform a task. Pipelines can be scheduled to execute, or a trigger can be defined that determines when a pipeline execution needs to be kicked off.", "Sign in to the Azure Portal, locate and open your Data factory. We can do that in multiple ways:", "Select Author & Monitor on the Overview page to load our Data Factory instance in a new browser tab. Switch to the next tab (our Data Factory) and select Manage on the left-corner menu. Let\u2019s start by creating linked services to tell the data factory where do our resources exist.", "Linked services are like connection strings, which define the connection information needed for the Data Factory to connect to external resources.", "We need to create two linked services, the first to tell the Data Factory about our data source (i.e., GitHub) and how to connect to it. We need to provide the HTTP address (Raw URL of the repository without a file name) as Base URL (https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/). Follow the below steps:", "The second linked service to tell our Data Factory about the data destination (i.e., storage account). Create a new linked service and search for Storage on the New linked service blade, select Azure Data Lake Store Gen2 from the matched resources list, and click Continue. Select the correct storage account from the drop-down (4).", "At this point, your screen should look like, as shown below. Click on Publish all to persist your changes, i.e., save. Click Publish on the Publish all blade and wait for the deployment to finish; it might take a few seconds.", "Next up, we need to create datasets to tell our Data factory what data to use and its format. We need to create two datasets linked to our two linked services.", "A dataset is a named view of data that simply points or references the data we want to use in our activities as inputs and outputs. Datasets represent data within different data stores, reachable via a linked service.", "Select the Author on the left-corner menu, locate Datasets on the Factory Resources blade and click on the number shown. Select New dataset and follow the steps to create our first dataset to represent our GitHub data.", "Our new dataset will open up, exposing options to configure further and define our data structure. Notice Base URL under the Connection tab is populated with the raw folder URL we provided in our linked service. Our data lies at the file URL, so we need to provide the absolute URL for the Data Factory to consume the data. We will use the Relative URL field to derive a complete URL to our file (Base URL + Relative URL). However, we want our pipeline to fetch multiple files; hence instead of providing a straight-up file name, we will use a parameter to generate file names dynamically on the fly.", "We can use parameters to pass external values into pipelines, datasets, linked services, and data flows. By parameterizing resources, we can reuse them with different values each time.", "Parameters are set for the whole duration of the pipeline run. They are like constants in a programming language, defined at the top of the source code.", "Switch to the Parameters tab and click + New to create a new parameter. Set the fields as shown; we\u2019re using the first CSV file\u2019s name as the default value. Switch to Connection tab and set Relative URL as @dataset().fileName.", "Syntax to refer to the dataset parameters: @dataset().PARAMETER_NAME", "We can either type the parameter name with correct syntax or use the Add dynamic content blade to fill it (5\u20137).", "Dynamic content in Azure Data Factory uses expression language.", "Create a new dataset representing the data in our storage account. Follow the steps mentioned previously (search for Azure Data Lake Storage Gen2 instead of HTTP on New dataset blade). Your new dataset should look like as below; publish all changes to make them available for use in our Data Factory.", "Now that we have fulfilled the requirements to set up our Data Factory, it\u2019s time to create a pipeline that will perform the actual task. Let\u2019s start by creating a new pipeline from the Factory Resources blade (similar to creating a new dataset).", "Give a name to your new pipeline and create two variables (i and j) of type string and 01\u201322\u20132020 as default value in the Variables tab.", "Variables can be set at the start of a pipeline, and read and modified during a run. Variables contain real value at runtime and can be assigned to parameters.", "They are like normal variables in a programming language.", "It\u2019s time to add activities to our pipeline; all activities are available on the Activities blade. We will use the following activities:", "Locate Get Metadata under the General category, drag and drop it on the canvas. Give it a name and proceed, as shown below.", "Syntax to refer to the output of the Get Metadata activity: @{activity('GET_METADATA_ACTIVITY_NAME').output.FIELD_NAME}", "Locate Set Variable under the General category, drag and drop it on the canvas. Connect it with the Success (green) end of Get Metadata activity. Give it a name and set variable i as follows", "You can open the Add dynamic content blade by clicking on the Value field; you can either type or copy-paste the above expression or use the blade's controls to create the expression.", "Locate Until under Iteration & conditionals category, drag and drop it on the canvas, and connect it with the previous set variable activity's success end. Give it a name; in the Settings tab, enter the following Expression:", "Move to the Activities tab and click on the edit icon to add the rest of the activities. We will add other activities inside the Until as we need to perform them multiple times. Clicking on the edit icon will show us an empty canvas, signifying we\u2019re now adding activities in the Until activity to iterate over.", "Locate Copy data under Move & transform category, drag and drop it on the canvas. Give it a name, set the Source and Sink tab configuration, as shown in the image. We will assign the fileName parameter with the variable i. Here\u2019s the fileName expression for convenient copy-paste :)", "Add another Set variable activity. Connect it with the success end of Copy data activity. Give it a name and set variable j as", "Add another Set variable activity and connect it with the success end of the previous Set variable activity. Set i as @variables('j')", "Our pipeline is now ready; it should look something like below. Additionally, you can refer to the JSON of our pipeline from GitHub at the end of the article for any troubleshooting purposes.", "The next step after adding all the activities is to validate our pipeline. Locate and select the Validate option to ensure our pipeline is free from errors and is ready to execute. The pipeline validation output blade will show us the results of the validation.", "We have two options to run our pipeline and see the fruits of our labor. We can debug run our pipeline without publishing our changes, or we can publish our changes first. It is advisable to Debug run the pipeline first, then publish the changes; debug run shows us logs and other useful tracking info in the pipeline's Output tab. Dedicate a few minutes to go through the output logs to get a clear picture of the execution and various activities. The sample output is shown below.", "You can also use the Add trigger option to run the pipeline right away or set a custom trigger to run the pipeline at specific intervals, time, or based on an external event.", "We presented a compelling problem of copying data over HTTP by using URL. We discussed the various components that make up a pipeline, and we set up an innovative Data Factory pipeline to solve the problem at hand. We also discussed how to set the pipeline's automatic execution and a brief overview of the pipeline execution logs.", "If you\u2019re following our series on turning CSV data into Power BI visuals, please head to our next article to continue the journey with cleansing and transforming data in Azure Databricks using PySpark.", "If you\u2019re trying to add and execute a Databricks notebook in your Data Factory pipeline, we have the perfect thing to show you the way.", "Let\u2019s be friends! You can find me on LinkedIn or join me on Medium.", "Analytics Expert. Data and BI Professional. Owner of Everyday BI. Private consultation - dhyan.singh@everydaybi.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F569476b625fc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://dhyanintech.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Dhyanendra Singh Rathore"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb038ca7c0471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=post_page-b038ca7c0471----569476b625fc---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F569476b625fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----569476b625fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F569476b625fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=-----569476b625fc---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@realaxer", "anchor_text": "tian kuan"}, {"url": "https://unsplash.com/?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://dhyanintech.medium.com/disclaimer-disclosure-terms-of-use-fb3bfbd1e0e5", "anchor_text": "https://dhyanintech.medium.com/disclaimer-disclosure-terms-of-use-fb3bfbd1e0e5"}, {"url": "https://medium.com/@dhyanintech/a-definitive-guide-to-turn-csv-files-into-power-bi-visuals-using-azure-4483cf406eab", "anchor_text": "A definitive guide to turn CSV files into Power BI visuals using AzureA step-by-step guide to turning COVID-19 data into stunning Power BI visuals using Microsoft Azure offerings.medium.com"}, {"url": "https://github.com/CSSEGISandData/COVID-19", "anchor_text": "COVID-19 repository at GitHub"}, {"url": "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports", "anchor_text": "This folder"}, {"url": "https://github.com/CSSEGISandData/COVID-19", "anchor_text": "CSSEGISandData/COVID-19This is the data repository for the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University\u2026github.com"}, {"url": "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports", "anchor_text": "GitHub URL"}, {"url": "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv", "anchor_text": "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/concepts-pipelines-activities", "anchor_text": "Pipelines and activities in Azure Data Factory \u2014 Azure Data FactoryAPPLIES TO: Azure Data Factory Azure Synapse Analytics (Preview) This article helps you understand pipelines and\u2026docs.microsoft.com"}, {"url": "https://portal.azure.com/", "anchor_text": "Azure Portal"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/control-flow-expression-language-functions", "anchor_text": "Expression and functions in Azure Data Factory \u2014 Azure Data FactoryAPPLIES TO: Azure Data Factory Azure Synapse Analytics (Preview) This article provides details about expressions and\u2026docs.microsoft.com"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/control-flow-get-metadata-activity", "anchor_text": "Get Metadata"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/control-flow-set-variable-activity", "anchor_text": "Set variable"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/control-flow-until-activity", "anchor_text": "Until"}, {"url": "https://docs.microsoft.com/en-us/azure/data-factory/copy-activity-overview", "anchor_text": "Copy data"}, {"url": "https://medium.com/@dhyanintech/cleansing-and-transforming-schema-drifted-csv-files-into-relational-data-in-azure-databricks-519e82ea84ff", "anchor_text": "Cleansing and transforming schema drifted CSV files into relational data in Azure DatabricksUsing PySpark to process and load schema drifted files to Azure Synapse Analytics data warehouse in Azure Databricksmedium.com"}, {"url": "https://medium.com/@dhyanintech/executing-azure-databricks-notebook-in-azure-data-factory-pipeline-using-access-tokens-3326b8703432", "anchor_text": "Executing Azure Databricks notebook in Azure Data Factory pipeline using Access TokensA guide on how to add and execute a Databricks notebook in Data Factory pipeline with Azure Key Vault safe Access\u2026medium.com"}, {"url": "https://www.linkedin.com/in/dhyans/", "anchor_text": "LinkedIn"}, {"url": "https://dhyanintech.medium.com/membership", "anchor_text": "Medium"}, {"url": "https://medium.com/tag/azure-data-factory?source=post_page-----569476b625fc---------------azure_data_factory-----------------", "anchor_text": "Azure Data Factory"}, {"url": "https://medium.com/tag/url-pattern?source=post_page-----569476b625fc---------------url_pattern-----------------", "anchor_text": "Url Pattern"}, {"url": "https://medium.com/tag/pipeline?source=post_page-----569476b625fc---------------pipeline-----------------", "anchor_text": "Pipeline"}, {"url": "https://medium.com/tag/csv-file?source=post_page-----569476b625fc---------------csv_file-----------------", "anchor_text": "Csv File"}, {"url": "https://medium.com/tag/adf?source=post_page-----569476b625fc---------------adf-----------------", "anchor_text": "Adf"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F569476b625fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----569476b625fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F569476b625fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----569476b625fc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F569476b625fc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb038ca7c0471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=post_page-b038ca7c0471----569476b625fc---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbd8cfa4cf694&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&newsletterV3=b038ca7c0471&newsletterV3Id=bd8cfa4cf694&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----569476b625fc---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Written by Dhyanendra Singh Rathore"}, {"url": "https://dhyanintech.medium.com/followers?source=post_page-----569476b625fc--------------------------------", "anchor_text": "258 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb038ca7c0471&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=post_page-b038ca7c0471----569476b625fc---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fbd8cfa4cf694&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-azure-data-factory-to-incrementally-copy-files-based-on-url-pattern-over-http-569476b625fc&newsletterV3=b038ca7c0471&newsletterV3Id=bd8cfa4cf694&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----569476b625fc---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/mounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Dhyanendra Singh Rathore"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/mounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Mounting & accessing ADLS Gen2 in Azure Databricks using Service Principal and Secret ScopesA guide to accessing Azure Data Lake Storage Gen2 from Databricks in Python with Azure Key Vault-backed Secret Scopes and Service\u2026"}, {"url": "https://towardsdatascience.com/mounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "\u00b77 min read\u00b7Sep 25, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96e5c3d6008b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----96e5c3d6008b----0-----------------clap_footer----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/mounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b?source=author_recirc-----569476b625fc----0---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96e5c3d6008b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmounting-accessing-adls-gen2-in-azure-databricks-using-service-principal-and-secret-scopes-96e5c3d6008b&source=-----569476b625fc----0-----------------bookmark_preview----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----569476b625fc----1---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----569476b625fc----1-----------------bookmark_preview----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----569476b625fc----2---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----569476b625fc----2-----------------bookmark_preview----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/a-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Dhyanendra Singh Rathore"}, {"url": "https://levelup.gitconnected.com/?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/a-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "A Secure way to use Credentials and Secrets in Azure FunctionsReferencing and Accessing Azure Key Vault Secrets in Azure Functions as Environment Variables in Node.js"}, {"url": "https://levelup.gitconnected.com/a-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": "\u00b76 min read\u00b7Oct 30, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F7ec91813c807&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fa-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807&user=Dhyanendra+Singh+Rathore&userId=b038ca7c0471&source=-----7ec91813c807----3-----------------clap_footer----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/a-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807?source=author_recirc-----569476b625fc----3---------------------39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ec91813c807&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fa-secure-way-to-use-credentials-and-secrets-in-azure-functions-7ec91813c807&source=-----569476b625fc----3-----------------bookmark_preview----39e3d7c5_5516_4f4b_a5dd_722417eb38fc-------", "anchor_text": ""}, {"url": "https://dhyanintech.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "See all from Dhyanendra Singh Rathore"}, {"url": "https://towardsdatascience.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/creative-data/custom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://patrickpichler.medium.com/?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://patrickpichler.medium.com/?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Patrick Pichler"}, {"url": "https://medium.com/creative-data?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Creative Data"}, {"url": "https://medium.com/creative-data/custom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Custom Logging in Azure Data Factory and Azure Synapse AnalyticsHow to implement a custom logger for Azure Data Factory and Azure Synapse Analytics by querying pipeline run information via REST API"}, {"url": "https://medium.com/creative-data/custom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b74 min read\u00b7Nov 9, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcreative-data%2Ff084643a5489&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcreative-data%2Fcustom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489&user=Patrick+Pichler&userId=73a93ddc5720&source=-----f084643a5489----0-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/creative-data/custom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff084643a5489&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcreative-data%2Fcustom-logging-in-azure-data-factory-and-azure-synapse-analytics-f084643a5489&source=-----569476b625fc----0-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Josue Luzardo Gebrim"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Data Quality in Python Pipelines!Discover What It Is And How To Achieve Data Quality In Your Data Streams!"}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b714 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&user=Josue+Luzardo+Gebrim&userId=9f59dfc0edf7&source=-----4ad1e8eb6603----1-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://jlgjosue.medium.com/data-quality-in-python-pipelines-4ad1e8eb6603?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ad1e8eb6603&operation=register&redirect=https%3A%2F%2Fjlgjosue.medium.com%2Fdata-quality-in-python-pipelines-4ad1e8eb6603&source=-----569476b625fc----1-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://syal-anuj.medium.com/?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Anuj Syal"}, {"url": "https://medium.datadriveninvestor.com/?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "DataDrivenInvestor"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "12 Must-Have Skills to become a Data EngineerThe Essential Skills for a Successful Data Engineering Career"}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b78 min read\u00b7Jan 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdatadriveninvestor%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&user=Anuj+Syal&userId=df3997c527b4&source=-----35b100dbee0a----0-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.datadriveninvestor.com/12-must-have-skills-to-become-a-data-engineer-35b100dbee0a?source=read_next_recirc-----569476b625fc----0---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35b100dbee0a&operation=register&redirect=https%3A%2F%2Fmedium.datadriveninvestor.com%2F12-must-have-skills-to-become-a-data-engineer-35b100dbee0a&source=-----569476b625fc----0-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----1-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----569476b625fc----1---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----569476b625fc----1-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/a-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/@adrian.causby15?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/@adrian.causby15?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Adrian Causby"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/a-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "A Snowflake Infrastructure in Terraform: Best PracticesWhat you Need and What to Consider"}, {"url": "https://medium.com/mlearning-ai/a-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b712 min read\u00b7Nov 1, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Fc8dbe1075310&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fa-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310&user=Adrian+Causby&userId=a8a0fb97638a&source=-----c8dbe1075310----2-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/a-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310?source=read_next_recirc-----569476b625fc----2---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8dbe1075310&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Fa-snowflake-infrastructure-in-terraform-best-practices-c8dbe1075310&source=-----569476b625fc----2-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/azure-fundamentals-practice-exam-questions-a216b9322fd5?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://plazagonzalo.medium.com/?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://plazagonzalo.medium.com/?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Gonzalo Fernandez Plaza"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/azure-fundamentals-practice-exam-questions-a216b9322fd5?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "Azure Fundamentals \u2014 Practice Exam QuestionsFree Microsoft Certified: Azure Fundamentals AZ-900 practice exam questions with solutions."}, {"url": "https://medium.com/geekculture/azure-fundamentals-practice-exam-questions-a216b9322fd5?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": "\u00b76 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2Fa216b9322fd5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fazure-fundamentals-practice-exam-questions-a216b9322fd5&user=Gonzalo+Fernandez+Plaza&userId=ab3e5de49d2c&source=-----a216b9322fd5----3-----------------clap_footer----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/azure-fundamentals-practice-exam-questions-a216b9322fd5?source=read_next_recirc-----569476b625fc----3---------------------5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa216b9322fd5&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fazure-fundamentals-practice-exam-questions-a216b9322fd5&source=-----569476b625fc----3-----------------bookmark_preview----5e1b6a8c_afdf_484e_8dbd_d2ca1019d6f8-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----569476b625fc--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----569476b625fc--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}