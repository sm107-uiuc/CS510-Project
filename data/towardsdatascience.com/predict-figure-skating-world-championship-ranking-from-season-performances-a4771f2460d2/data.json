{"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2", "time": 1683001508.588021, "path": "towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2/", "webpage": {"metadata": {"title": "Predict figure skating world championship ranking from season performances | by Khanh Nguyen | Towards Data Science", "h1": "Predict figure skating world championship ranking from season performances", "description": "Rank skaters from multiple factors"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient", "anchor_text": "Kendall\u2019s tau", "paragraph_index": 7}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "part 1", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood", "anchor_text": "log-likelihood", "paragraph_index": 19}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html", "anchor_text": "reindex", "paragraph_index": 27}, {"url": "https://docs.python.org/2/library/itertools.html#itertools.combinations", "anchor_text": "combinations", "paragraph_index": 30}, {"url": "https://towardsdatascience.com/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2?source=friends_link&sk=132ba842d95afc92d4e3a0dc6accc7e5", "anchor_text": "project", "paragraph_index": 35}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3", "paragraph_index": 53}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation", "anchor_text": "cross-validation", "paragraph_index": 66}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-7461dc5c0722?source=friends_link&sk=fcf7e410d33925363d0bbbcf59130ade", "anchor_text": "next part", "paragraph_index": 80}, {"url": "https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf", "anchor_text": "lecture note", "paragraph_index": 81}, {"url": "https://see.stanford.edu/Course/CS229/42", "anchor_text": "video", "paragraph_index": 81}, {"url": "https://see.stanford.edu/Course/CS229/49", "anchor_text": "lectures", "paragraph_index": 81}, {"url": "https://see.stanford.edu/Course/CS229/", "anchor_text": "CS229", "paragraph_index": 81}, {"url": "https://en.wikipedia.org/wiki/Learning_to_rank", "anchor_text": "strategies", "paragraph_index": 82}, {"url": "http://www.herbrich.me/papers/icann99_ordinal.pdf", "anchor_text": "paper", "paragraph_index": 83}, {"url": "http://fa.bianp.net/blog/2012/learning-to-rank-with-scikit-learn-the-pairwise-transform/", "anchor_text": "blog post", "paragraph_index": 83}, {"url": "https://stats.stackexchange.com/questions/436467/logistic-regression-does-not-seem-to-maximize-model-accuracy", "anchor_text": "asked", "paragraph_index": 84}, {"url": "https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models", "anchor_text": "thread", "paragraph_index": 84}], "all_paragraphs": ["In the previous parts of the project, I tried to predict the ranking in the annual world championship of figure skating based on the scores that skaters earned from previous competition events in the season. The main strategy is to separate the skater effect, the intrinsic ability of each skater, from the event effect, the influence of an event on a skater\u2019s performance, so that a more accurate ranking could be built.", "Specifically, in part 3 of the project, each event and each skater is represented by multiple latent factors. The products of these latent factors between an event and a skater, when added to a baseline score, will approximate the score of that event-skater pair during the season:", "Using gradient descent, we can find the latent scores of the different factors for all events and skaters. However, once the latent scores for each skater are found, we face a major conundrum: by what score are we supposed to rank the skaters?", "As discussed in part 3, If we rank the skaters by each individual factor, none of the factors can give a decent ranking: given 5 latent factors, the highest Kendall\u2019s tau from any one factor is 0.45 (from the 1st factor). This is far lower than that of even the baseline model of season averages (0.695), let alone the previous models that we built (0.732 for the additive and multiplicative model, and 0.724 for the hybrid model).", "Therefore, we must find a way to combine the latent scores across different factors to rank skaters more accurately.", "This was the hardest part of the project for me, as initially I was racking my brain to see how on earth I can combine the latent scores across several factors to rank the skaters.", "However, the \u201caha!\u201d moment came when I realized that I can just use the world championship ranking for each year to directly learn how to combine the latent scores. I was also in luck, as the simple ranking metric of Kendall\u2019s tau allows me to build a simple logistic regression model to combine them.", "Let\u2019s recap the formula for the ranking metric of Kendall\u2019s tau \u2014 also called Kendall rank correlation coefficient \u2014 which was explained in part 1 of the project. This is a metric that measures how much two rankings are similar to each other, such as between the predicted ranking and the actual ranking in the world championship.", "Using the same toy example of 4 skaters from the previous parts, let\u2019s assume that in the world championship at the end of that season, these 4 skaters are ranked as such (from highest to lowest; first names removed for simplicity):", "From this ranking, we can generate 4\u00d7(4\u20131)/2 = 6 ordered pairs, in which the first skater in each pair is always ranked higher than the second. In this example, the 6 ordered pairs are:", "A predicted ranking that matches completely with the world championship will also generate 6 ordered pairs of its own that match the 6 ordered pairs above. We call the ordered pairs that match in both rankings concordant pairs, while those that only appear in one ranking but not in the other as discordant pairs.", "The Kendall\u2019s tau between the two ranking, then, can be calculated as:", "As a result, this predicted ranking will have 6 concordant pairs and 0 discordant pairs out of 6 total ordered pairs. This translate to a Kendall\u2019s tau of (6\u20130)/6 = 1, which is also the upper limit of Kendall\u2019s tau between two ranking. In contrast, the lower limit is -1, which is the Kendall\u2019s tau between two completely opposite rankings.", "One important observation in the above formula is that Kendall\u2019s tau is strictly increasing with respect to the number of concordant pairs. Therefore, optimizing for Kendall\u2019s tau of a predicted ranking is the same as trying to get the highest number of concordant pairs from it. Put more simply, out of the ordered pairs in the world championship, our predicted ranking needs to guess correctly as many of these pairs as possible.", "But how can we make these intelligent guesses for these ordered pair? This is where the latent scores from the multi-factor model comes in. As mentioned earlier, from the world championship ranking of the 4 skaters in our toy example, we can generate 4(4\u20131)/2 = 6 ordered pairs.", "Given the setup above, it is clear that we can use logistic regression to predict the binary response for each pair/observation. More specifically, for each pair, we predict the probability that skater A will outrank skater B in the world championship P(A>B). As a result, the ideal scenario is for this predicted probability of each pair to be as close to 1 as possible, given the ground-truth response is always 1 for each observation.", "For logistic regression, this predicted probability that skater A will out rank skater B will be a sigmoid function applied to a linear combination of the difference in latent scores between the two skaters across different factors:", "Therefore, once we learn the linear coefficient \u03b2_f for the difference in each factor f, we can use the above formula to predict the probability that skater A will out rank skater B in the world championship. Then, if this predicted probability is greater than 0.5, we predict that skater A will outrank skater B. Finally, from these pairwise rank predictions, we can predict a final ranking of all skaters from top to bottom.", "But how can we learn the linear coefficients \u03b2 for our logistic regression model? The key is to find the coefficients that maximize the joint probability of observing the ground-truth responses \u2014 that skater A indeed out ranks skater B \u2014 from all n(n-1)/2 ordered pairs.", "Notice from the above formula that maximizing the joint probability is the same as maximizing the its logarithm, which we often called the log-likelihood. The reason for taking the logarithm is that the product of predicted probabilities is transformed into a sum over logarithms of these probabilities, which is a much easier objective function to maximize:", "Therefore, we can find the gradient of this objective function J with respect to each model coefficient\u2014 \u03b2_1 to \u03b2_n \u2014 and use gradient ascent to update these coefficients accordingly. Gradient ascent is nothing but gradient descent in reverse: for the update step of the model parameters, we add instead of subtract the gradient. In other words, since the goal is to maximize the objective function, we need to go along the gradient, not against it.", "More specifically, for a factor k, the gradient of the objective function with respect to its model coefficient \u03b2_k are found by simple chain rule:", "From the gradient formula above \u2014 expressed in both summation and vector notation \u2014 once we have the predicted probabilities for every pair as a column vector, we can subtract it from a vector of all one\u2019s. Then, we take the dot product of the resulting vector with the predictor column (latent score difference) of factor k. The scalar result of this dot product will be the gradient of the objective function with respect to the model coefficient of factor k.", "Once the gradients for all factors are calculated, we can update the coefficient of each factor by adding the corresponding gradient, along with a learning rate \u03b1 to control the rate of convergence for gradient ascent:", "In short, the gradient ascent algorithm can be summarized in the following steps:", "For gradient ascent, convergence can be monitored by checking the average log likelihood \u2014 log likelihood divided by the number of ordered pairs in the training sample \u2014 and see if it has stabilized from iteration to iteration. Dividing by the number of training pairs makes the log-likelihood independent of data size and easier to monitor.", "With the gradient ascent model above, let\u2019s see how we can code it using Python for our toy example. First, after training the multi-factor model with 2 factors, we now have a pandas DataFrame skater_scores of size (4,2) that represents the latent scores of these 2 factors across the 4 skaters.", "Next, we sort the skaters/rows of this DataFrame (using the reindex method) to match the order of the world championship ranking: FERNANDEZ > MURA > GE > MAJOROV. We also convert this DataFrame into a 2-D numpy array so we can manipulate it more easily:", "Next, for each factor, we normalize its scores by subtracting the mean and dividing by the standard deviation of that factor. This results in all the factors having zero means and standard deviations of 1. This normalization has two purposes:", "This normalization can be easily done in Python (see below), with the mean and standardization taken across axis=0, meaning across rows/skaters:", "Finally, we can use the combinations function from the itertools module to generate ordered pairs of rows in the normalized matrix, in which the first row is always above the second row. As a result, subtracting the second row from the first row will calculate the latent score differences between one skater (skater A) who ranks higher than another skater (skater B) in the world championship.", "This will give us the predictor matrix to work with for logistic regression, with 6 rows representing the 6 ordered pairs, and 2 columns representing the latent score differences for the two 2 factors in our example (see below).", "Once the predictor matrix is prepared, we can start coding the gradient ascent formula for logistic regression.", "Since there are 2 factors in this example, we can initialize two coefficients \u03b2_1 and \u03b2_2, both with values of 0.5, and contained in the numpy array beta of size (2, )", "With the learning rate alpha = 0.01, we let the gradient ascent runs for 100 iterations. As seen below, the core of algorithm is incredibly simple, with all the important steps achieved in just 3 lines of code!", "I have already explained how the code block above works in much greater detail in a previous project that also used logistic regression. The only differences between gradient ascent in that project and the code above are:", "Below is the diagram that outlines how the algorithm works for the first iteration of the gradient ascent algorithm:", "The average log-likelihood after each iteration can be checked easily by summing up all the log of probabilities and dividing it by the number of pairs in the training sample (6 in this case): np.log(prob).sum() / len(X). After 100 iterations, the average log-likelihood is -0.337, with an iteration-to-iteration difference of 1e-4.", "After gradient ascent has converged for our toy example, the model coefficient for the two factors are 0.745 for the first factor, and 0.367 for the second.", "Using these learned coefficients, we can finally predict the probability that for every pair in our training data, the first skater (skater A) will out rank the second skater (skater B) in the world championship. Furthermore, if this probability is higher than 0.5, we predict that skater A will out rank skater B; if not, we predict the reverse:", "Below are the results of the predicted probabilities and pairwise rankings for our toy example:", "From the above result, we can see that the predicted ranking got 5 correct pairs out of 6 ordered pairs from the world championship ranking. In other words, with 5 concordant pairs and 1 discordant pairs, the Kendall\u2019s tau of this predicted ranking is (5\u20131)/6 = 0.67.", "From the results for each predicted pairwise ranking (rightmost column in table above), it is clear that the only predicted ranking that can be created is FERNANDEZ > GE > MURA > MAJOROV. Let\u2019s see how we can arrive at this conclusion using code:", "First, we set up a list counter to count the points for each skater. They will all start with 0 point.", "Then, we generate ordered index pairs corresponding to each of the six ordered pairs. The first number of the index pair is the world championship ranking (starting from 0) of the first skater, while the second number is the ranking of the second skater. This is easily done using combinations, which technically will create a generator, but I\u2019ve enclosed it in a list for clarity.", "Next, using zip, we associate each index pair with the predicted pairwise ranking \u2014 True or False\u2014 in y_pred. If the predicted pairwise ranking is True, we add one point to the index of the first skater in counter; if the predicted ranking is False, we add one point to the index of the second skater.", "Here\u2019s a diagram of how the loop works when it iterates on each element of y_pred and index_pairs:", "Lastly, we rearrange the world ranking by the number of points that each skater has in the counter, from highest to lowest (hence the reverse=True argument). This will give us the final predicted ranking from the pairwise ranking outputs of logistic regression.", "Method 2: From combining factor scores", "Given the learned model coefficients in beta, we can multiply it with the normed_skater_scores matrix of normalized latent scores to obtain the combined score across the 2 factors for each skater:", "As a result, each skater is now represented by a single score, similar to all the previous models. By sorting these combined scores from highest to lowest, we can get the final predicted ranking:", "The reason why both methods give the same ranking is because if the combined score of a skater is higher than another skater, then the predicted probability of the ordered pair of these two skaters will be greater than 0.5, which means the predicted pair will hold in the world championship ranking:", "In other words, ranking skaters by their combined scores is identical to ranking them by going through all the predicted pairwise rankings in the previous method. However, it is clear that this method is not only simpler, but also has the benefit of condensing all the factors into a single combined score for each skater.", "We first apply the gradient ascent algorithm to the familiar example of male skaters in the 2017 season, each with 5 latent factors. Recall from part 3 of the project that none of the 5 factors alone can produce a decent ranking, so let\u2019s see if combining them using logistic regression can make the predicted ranking better.", "First, for each iteration of gradient ascent, we can track not only the average likelihood, but also the predicted ranking at that point in time (using the methods outlined just above), as well as the Kendall\u2019s tau from that ranking. These are visualized in the animated dashboard below for the first 250 iterations of gradient ascent (with a learning rate \u03b1 = 0.001):", "From the above dashboard, it can be seen that:", "Still, a curious thing happens during gradient ascent: the Kendall\u2019s tau peaks at 0.783 (or 246 out of 276 pairs) near the 30th iteration. After that, it converges back down to only 244 correct pairs after 250 iterations. Why does the Kendall\u2019s tau drops, albeit slightly, while the average log-likelihood continues to increase?", "In short, contrary to my prior belief, logistic regression will often, but not always, increase the accuracy of the model output. We will discuss shortly how to increase the accuracy i.e. Kendall\u2019s tau of the model.", "Once we gradient ascent algorithm has converged, we obtain the model coefficients for each factor (stored in beta, and displayed at the bottom of the accompanying graph). We then use these coefficients to calculate a single combined score for each skater, using the method outlined earlier.", "Since we can adjust the number of latent factors each skater has, perhaps more factors will help us rank the skaters better. This turned out to be true when we increased the number of factors to 50:", "However, if something seems too good to be true, it probably is. This is because:", "The above caveats mean that we need to separate the 10 seasons in the training set into 2 separate groups:", "We will validate the logistic regression model, including any improvements made on the model, using the following steps:", "Step 1: For each of the 10 seasons, we run a multi-factor model over the season scores to get the latent skater scores in that season. Then, we normalize these factors to the same scale and take differences in all factors between pairs of skaters.", "Step 2: For the seasons in the train group, we stack their difference matrices vertically into a single predictor matrix, and use it to train the logistic regression model. After gradient ascent has converged, we can use the model coefficients to rank skaters for each of these seasons and evaluate the Kendall\u2019s tau of that ranking. We will call these train Kendall\u2019s taus from here on, as the model coefficients used to produce the rankings are directly trained from the world championship results.", "Step 3: Similarly, for the seasons in the validation group, we also stack their difference matrices into a single predictor matrix. Then, we use the model coefficients learned from step 2 to rank skater for each of these seasons and evaluate the Kendall\u2019s tau of that ranking. We will case these validation Kendall\u2019s taus from here on, as the model coefficients used to produce the rankings were not trained, but only validated on these seasons.", "Step 4: For simplicity, we will use 2-fold cross-validation to split the seasons: with 10 seasons, this means that 5 seasons are randomly chosen to belong in the train group, and the remaining 5 in the validation group in step 2. After step 3, however, the seasons in each group are switched: those who were in the train group are now in the validation group, and vice versa. We then repeat step 2 and 3 to get the respective train and validation Kendall\u2019s taus.", "As a result of this switch, every season will have a corresponding train Kendall\u2019s tau , which involves a logistic regression model trained directly from the world championship of that season (among 4 others). Each season will also have a corresponding validation Kendall\u2019s tau, which involves a logistic regression model trained on 5 other seasons.", "Step 5: For each season, we can subtract its train or validation Kendall\u2019s tau by the Kendall\u2019s tau of the baseline model (using season averages) to get the respective improvements in Kendall\u2019s tau. Finally, we can simply average the improvements of the 10 train Kendall\u2019s taus and compare it to the average improvement of the 10 validation Kendall\u2019s taus.", "As a result, the former average represents the ranking improvement (from baseline model) for a logistic regression model trained directly from the world championship rankings, while the latter represents the improvement for a logistic regression model indirectly trained on other seasons. The latter is also is a much more realistic evaluation of the model, as the model will be used to predict the world championship rankings for future seasons, and such rankings are of course not yet available in the first place.", "With the model validation plan outlined above, we run all these steps for different numbers of factors (at \u03b1=0.005 and 1000 iterations), and obtain their average train and validation improvements in Kendall\u2019s tau from baseline model:", "The result when the number of factors increase by factors of 2 (from 2 all the way to 128 factors) are shown in the above graph. From this graph, we can see that:", "With that said, how can we reduce the model overfit as seen in the graph above? The answer should be familiar to readers who follow the previous parts of the project: early stopping.", "In the previous parts of the project, strategies used to reduce model overfit include model penalization and early stopping.", "Therefore, a much more convenient way to to reduce model overfit is to prematurely stop both the gradient descent algorithm for the multi-factor model, and the gradient ascent algorithm for the logistic regression model that follows it. By preventing these algorithms to fully converge, we might not get the best training performance, but hopefully these models will be less overfit to the training data and generalize better.", "In other words, we will see at which stopping iteration for either algorithm will we have the best validation performance i.e. highest average validation improvement in Kendall\u2019s tau compared to the baseline model. As a result, our two models combined \u2014 multi-factor and logistic regression \u2014 now has 3 hyper-parameters in total:", "For each combination of these 3 hyper-parameters, we can record its average train and validation improvement in Kendall\u2019s tau compared to the baseline model. These results are plotted below for:", "From the above plot, we can see that:", "Finally, for each number of factor, we record the stopping iterations for both multi-factor and logistic regression model that give the highest improvement in average validation Kendall\u2019s tau:", "From the result table above, a curious result immediately emerges:", "In the next part of the project, I will explain why this turned out to be the case, as well as how we can fix this problem.", "You can find the derivations for logistic regression and its gradient ascent method from the corresponding lecture note and video lectures of CS229 (a machine learning course taught by professor Andrew Ng that I highly recommend). Note that since our training data only has one class of predictor (all 1\u2019s), the formulas derived earlier are simpler than those for a typical logistic regression model.", "Next, we use logistic regression to learn how to rank skaters based on their latent scores. This task belongs to the appropriately-titled \u201clearning to rank\u201d strategies that are often used in information retrieval systems. For example, a search engine needs to rank articles based on certain attributes before displaying the top-ranked articles to each user. More specifically, by exploiting the pairwise nature of the ranking metric of Kendall\u2019s tau, our approach belongs to the pairwise subset of learning to rank strategies.", "Furthermore, once the pairwise differences in each latent factor are calculated, we can use other classification methods, not just logistic regression, to predict the pairwise ranking for each each observation/ordered pair. For example, here is a paper that uses SVM to predict pairwise rankings (also called RankSVM), and a much more readable blog post that explains how it works.", "Lastly, when I asked about the peculiar phenomenon in which logistic regression converges to a higher likelihood but lower accuracy on Stackoverflow, the answer I received links to several interesting discussions. For example, this thread highlights how accuracy is actually a separate problem from statistics, which in this case is the logistic regression model. Moreover, accuracy is not only a function of the predicted probabilities, but also of the threshold used to classify the samples. Therefore, evaluating models based on accuracy alone might not be a good idea for many problems.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa4771f2460d2&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://seismatica.medium.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Khanh Nguyen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb9e5af5001b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&user=Khanh+Nguyen&userId=bb9e5af5001b&source=post_page-bb9e5af5001b----a4771f2460d2---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/dknguyengit/skate_predict", "anchor_text": "repo"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "part 1"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&sk=86881d127654ece260be2e3029dfbad2", "anchor_text": "part 2"}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-7461dc5c0722?source=friends_link&sk=fcf7e410d33925363d0bbbcf59130ade", "anchor_text": "part 5"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-d97bfbd37807", "anchor_text": "part 6"}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3"}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3"}, {"url": "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient", "anchor_text": "Kendall\u2019s tau"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&sk=7e6b2992c6dd5e6e7e1803c574b4236d", "anchor_text": "part 1"}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood", "anchor_text": "log-likelihood"}, {"url": "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html", "anchor_text": "reindex"}, {"url": "https://docs.python.org/2/library/itertools.html#itertools.combinations", "anchor_text": "combinations"}, {"url": "https://towardsdatascience.com/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2?source=friends_link&sk=132ba842d95afc92d4e3a0dc6accc7e5", "anchor_text": "project"}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3"}, {"url": "https://towardsdatascience.com/predict-figure-skating-world-championship-ranking-from-season-performances-8af099351e9c?source=friends_link&sk=48c2971de1a7aa77352eb96eec77f249", "anchor_text": "part 3"}, {"url": "https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation", "anchor_text": "cross-validation"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&sk=86881d127654ece260be2e3029dfbad2", "anchor_text": "part 2"}, {"url": "https://en.wikipedia.org/wiki/Tikhonov_regularization", "anchor_text": "L2-regularization"}, {"url": "https://towardsdatascience.com/analyzing-my-weight-loss-journey-with-machine-learning-b74aa2e170f2?source=friends_link&sk=132ba842d95afc92d4e3a0dc6accc7e5", "anchor_text": "previous project"}, {"url": "https://towardsdatascience.com/predicting-figure-skating-world-championship-ranking-from-season-performances-part-2-hybrid-7d296747b15?source=friends_link&sk=86881d127654ece260be2e3029dfbad2", "anchor_text": "part 2"}, {"url": "https://medium.com/@seismatica/predict-figure-skating-world-championship-ranking-from-season-performances-7461dc5c0722?source=friends_link&sk=fcf7e410d33925363d0bbbcf59130ade", "anchor_text": "next part"}, {"url": "https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf", "anchor_text": "lecture note"}, {"url": "https://see.stanford.edu/Course/CS229/42", "anchor_text": "video"}, {"url": "https://see.stanford.edu/Course/CS229/49", "anchor_text": "lectures"}, {"url": "https://see.stanford.edu/Course/CS229/", "anchor_text": "CS229"}, {"url": "https://en.wikipedia.org/wiki/Learning_to_rank", "anchor_text": "strategies"}, {"url": "http://www.herbrich.me/papers/icann99_ordinal.pdf", "anchor_text": "paper"}, {"url": "http://fa.bianp.net/blog/2012/learning-to-rank-with-scikit-learn-the-pairwise-transform/", "anchor_text": "blog post"}, {"url": "https://stats.stackexchange.com/questions/436467/logistic-regression-does-not-seem-to-maximize-model-accuracy", "anchor_text": "asked"}, {"url": "https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models", "anchor_text": "thread"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a4771f2460d2---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/sports-analytics?source=post_page-----a4771f2460d2---------------sports_analytics-----------------", "anchor_text": "Sports Analytics"}, {"url": "https://medium.com/tag/figure-skating?source=post_page-----a4771f2460d2---------------figure_skating-----------------", "anchor_text": "Figure Skating"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----a4771f2460d2---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a4771f2460d2---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&user=Khanh+Nguyen&userId=bb9e5af5001b&source=-----a4771f2460d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&user=Khanh+Nguyen&userId=bb9e5af5001b&source=-----a4771f2460d2---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa4771f2460d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a4771f2460d2---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a4771f2460d2--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a4771f2460d2--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a4771f2460d2--------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://seismatica.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Khanh Nguyen"}, {"url": "https://seismatica.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "231 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbb9e5af5001b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&user=Khanh+Nguyen&userId=bb9e5af5001b&source=post_page-bb9e5af5001b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F23c332b6074c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredict-figure-skating-world-championship-ranking-from-season-performances-a4771f2460d2&newsletterV3=bb9e5af5001b&newsletterV3Id=23c332b6074c&user=Khanh+Nguyen&userId=bb9e5af5001b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}