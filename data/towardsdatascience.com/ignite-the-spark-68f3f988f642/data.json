{"url": "https://towardsdatascience.com/ignite-the-spark-68f3f988f642", "time": 1683003703.562731, "path": "towardsdatascience.com/ignite-the-spark-68f3f988f642/", "webpage": {"metadata": {"title": "Ignite the Spark!. Running Apache Spark on Kubernetes\u2026 | by Alexander Sack | Towards Data Science", "h1": "Ignite the Spark!", "description": "In this primer, you are first going to learn a little about how Apache Spark\u2019s cluster manager works and then how you can run PySpark within a Jupyter notebook interactively on an existing Kubernetes\u2026"}, "outgoing_paragraph_urls": [{"url": "https://spark.apache.org/docs/latest/spark-standalone.html", "anchor_text": "Standalone", "paragraph_index": 10}, {"url": "https://spark.apache.org/docs/latest/running-on-mesos.html", "anchor_text": "Apache Mesos", "paragraph_index": 11}, {"url": "https://spark.apache.org/docs/latest/running-on-yarn.html", "anchor_text": "Hadoop YARN", "paragraph_index": 12}, {"url": "https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/", "anchor_text": "kubeadm", "paragraph_index": 21}, {"url": "https://kubernetes.io/docs/tasks/tools/install-minikube/", "anchor_text": "MiniKube", "paragraph_index": 22}, {"url": "https://github.com/kubernetes/kubernetes/issues/82131", "anchor_text": "here", "paragraph_index": 34}, {"url": "https://stackoverflow.com/questions/57643079/kubernetes-watchconnectionmanager-exec-failure-http-403", "anchor_text": "here", "paragraph_index": 34}, {"url": "http://localhost:8888", "anchor_text": "http://localhost:8888", "paragraph_index": 49}, {"url": "https://en.wikipedia.org/wiki/Pi", "anchor_text": "the number Pi", "paragraph_index": 54}], "all_paragraphs": ["In this primer, you are first going to learn a little about how Apache Spark\u2019s cluster manager works and then how you can run PySpark within a Jupyter notebook interactively on an existing Kubernetes (k8s) cluster.", "After completing this article, you should be able to develop Spark applications on any Kubernetes cluster with confidence as well as have a deeper understanding of how the two are wired together.", "Spark is a fast and general-purpose cluster computing system which means by definition compute is shared across a number of interconnected nodes in a distributed fashion.", "But how does Spark actually distribute a given workload across a cluster?", "Spark adopts a Master/Slave approach whereby a driver program (\u201cthe master\u201d) creates a SparkContext object that connects to a cluster manager.", "The SparkContext created (either programmatically by your favorite language binding or on your behalf when you submit a job) abstracts the cluster as one large compute node that your application uses to perform work.", "The cluster manager on the other hand, is responsible for spawning and managing a number of worker nodes (\u201cthe slaves\u201d) that each run an executor process on behalf of the SparkContext to do the actual work.", "When data in the form of a Resilient Distributed Dataframe (RDD) is manipulated by your Spark application, the RDD is split into a number of partitions and distributed across these worker node/executor combinations for processing. The final result is aggregated across the nodes and sent back to the driver.", "One of the key advantages of this design is that the cluster manager is decoupled from your application and thus interchangeable.", "Traditionally, Spark supported three types of cluster managers:", "The Standalone cluster manager is the default one and is shipped with every version of Spark. It is a no frills, competent manager that is meant to get you up and running as fast as possible.", "Apache Mesos is a clustering technology in its own right and meant to abstract away all of your cluster\u2019s resources as if it was one big computer. Mesos ships with a cluster manager that you can leverage with Spark.", "Hadoop YARN (\u201cYet Another Resource Negotiator\u201d) was developed as an outgrowth of the Apache Hadoop project and mainly focused on distributing MapReduce workloads. As a result, it too is a cluster manager which Spark can talk to natively.", "As of 2.3.0, Spark now supports using Kubernetes directly as a cluster manager.", "But what does that really mean?", "That depends based on how you want to run Spark on Kubernetes.", "In cluster mode, after you submit an application using spark-submit, the SparkContext created on behalf of your application will ask the kube-apiserver to setup a driver node and a number of corresponding worker nodes (Pods) and proceed to run your workload on top of them.", "Once all the data processing has finished, on tear down, the ephemeral worker node Pods will be terminated automatically but the driver node Pod will remain so you can inspect any logs before manually deleting it.", "In client mode, you create the Spark driver node as a Pod then create a SparkContext using your favorite language\u2019s API bindings before finally submitting work.", "This primer is going to focus on configuring client mode for a few reasons:", "The below instructions assume the following:", "I\u2019m running a small 1.17.2 eight node cluster that was setup using the kubeadm tool. I believe any cluster 1.15+ should work just fine.", "If you don\u2019t have a cluster to work with, I highly suggest installing MiniKube on your desktop as a way to follow along.", "Before we start building images and deploying Pods, let\u2019s setup a dedicated namespace where our combo Jupyter notebook/Spark driver node will be deployed as well as all of its corresponding worker nodes.", "In order for your driver Pod to request resources from the cluster it has to use some kind of ServiceAccount that has the right Role Base Access Control (RBAC).", "The Spark documentation suggests creating a RoleBinding or a ClusterRoleBinding to accomplish this. Which method you choose to implement is entirely based on the security policy of your cluster.", "For this example, we will create a ServiceAccount called spark in the spark namespace with a ClusterRoleBinding that gives this account the right permissions:", "As per above, since every worker node is really just a Pod on our cluster, we will need a docker image with the correct Spark run-time.", "Fortunately, the Spark team provides a bunch of Dockerfiles and a tool (docker-image-tool.sh) to create images with them that are ready to be deployed on any Kubernetes cluster.", "Each Dockerfile is meant to be used with the three major language bindings Spark supports \u2014 Scala, Python, and R.", "Let\u2019s build the default images so we have at least some base image to work with:", "After the docker-image-tool.sh script completes, you should have three new images ready for deployment on your Kubernetes cluster:", "Since this tutorial is going to focus on using PySpark, we are going to use the spark-py image for our worker Pod. Normally, you would just push these images to whatever docker registry your cluster uses. However, we are going to create custom versions of them in order to work around a bug.", "At the time of this writing, there is an issue with using the existing Spark v2.4.4 Kubernetes client jar files with newer clusters due to a security CVE that was patched recently.", "You can read more about the issue here and here.", "The workaround is to build a Spark enabled docker image but with newer client jar files in it.", "Let\u2019s use the base images we just built to do exactly that. Since we are focused on using PySpark, we will only rebuild the spark-py image but the same steps apply to all of them.", "So now my-spark-py:v2.4.4 contains the same official Spark run-time but with updated Kubernetes client jar files taken from the v3.0.0-preview2 release.", "This image will be pulled by Kubernetes every time it creates a worker Pod on demand when we generate our SparkContext.", "Since our ultimate goal is to interactively develop a PySpark application on Kubernetes within a Jupyter notebook, that Pod will also act as our \u201cdriver\u201d node.", "The official PySpark docker image is a great place to start and I highly recommend it.", "I built a custom docker image that you can find by clicking the link above. I call this image my-notebook:latest.", "You should build, tag and push whatever image you ultimately choose to the docker registry that your cluster uses.", "As is all things Kubernetes, we need to write a YAML file to deploy our driver Pod that will be used to log into Jupyter and create a SparkContext.", "Here is what my deployment looks like:", "The highlighted text are directives you should pay attention to:", "When you are satisfied with your deployment, create it via:", "Check that your deployment is running:", "And now port-forward to 8888 so you can login into Jupyter:", "Now you should be able to point your favorite browser to http://localhost:8888 and log into Jupyter (if you used my image as a reference the password is \u2018jupyter\u2019 else you will need to copy/paste the generated auth token displayed in the container\u2019s log file).", "Start a new Python3 notebook and type the following in a cell:", "Let\u2019s break down the Spark config above:", "After you execute this cell, you should see a number of worker Pods being spawned in the spark namespace.", "You now have an a Spark cluster running on top of Kubernetes waiting for work!", "As is tradition, let\u2019s calculate the number Pi using our cluster in a new cell:", "After you have completed your development, you can shutdown your Spark cluster by simply executing:", "That will instruct your SparkContext to tear down the worker Pods you created above via the kube-apiserver.", "And now you are left with just your deployment/driver Pod in the spark namespace.", "I hope you are now more confident creating a Spark cluster on Kubernetes using PySpark and appreciate the architecture behind it.", "I know I used to run in stand alone mode for most of my early stage Spark development work, but now with Kubernetes support, it\u2019s cluster or bust!", "Feel free to post any questions, corrections, or concerns below and Happy Spark\u2019ing!", "Currently, I\u2019m a senior member of IEX Cloud's engineering team. We develop and evolve a streaming Fintech platform called Apperate."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68f3f988f642&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@pisymbol?source=post_page-----68f3f988f642--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Alexander Sack"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe13ebfdd5f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=post_page-e13ebfdd5f62----68f3f988f642---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68f3f988f642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----68f3f988f642---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68f3f988f642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=-----68f3f988f642---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://spark.apache.org/docs/latest/spark-standalone.html", "anchor_text": "Standalone"}, {"url": "https://spark.apache.org/docs/latest/running-on-mesos.html", "anchor_text": "Apache Mesos"}, {"url": "https://spark.apache.org/docs/latest/running-on-yarn.html", "anchor_text": "Hadoop YARN"}, {"url": "https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/", "anchor_text": "kubeadm"}, {"url": "https://kubernetes.io/docs/tasks/tools/install-minikube/", "anchor_text": "MiniKube"}, {"url": "https://hub.docker.com/", "anchor_text": "Docker Hub"}, {"url": "http://mirrors.gigenet.com/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz", "anchor_text": "http://mirrors.gigenet.com/apache/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz"}, {"url": "https://github.com/kubernetes/kubernetes/issues/82131", "anchor_text": "here"}, {"url": "https://stackoverflow.com/questions/57643079/kubernetes-watchconnectionmanager-exec-failure-http-403", "anchor_text": "here"}, {"url": "http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz", "anchor_text": "http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz"}, {"url": "http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz", "anchor_text": "spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz"}, {"url": "https://hub.docker.com/r/jupyter/pyspark-notebook/", "anchor_text": "official Jupyter PySpark image"}, {"url": "https://github.com/pisymbol/docker/blob/master/spark/Dockerfile", "anchor_text": "Build your own custom image"}, {"url": "https://spark.apache.org/docs/latest/running-on-kubernetes.html#client-mode", "anchor_text": "Spark client mode documentation"}, {"url": "http://blog.brainlounge.de/memoryleaks/getting-started-with-spark-on-kubernetes/", "anchor_text": "this helpful post"}, {"url": "http://localhost:8888", "anchor_text": "http://localhost:8888"}, {"url": "https://kubernetes.default.svc.cluster.local:443", "anchor_text": "https://kubernetes.default.svc.cluster.local:443"}, {"url": "https://kubernetes.default.svc.cluster.local:443", "anchor_text": "https://kubernetes.default.svc.cluster.local:443"}, {"url": "https://en.wikipedia.org/wiki/Pi", "anchor_text": "the number Pi"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----68f3f988f642---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/pyspark?source=post_page-----68f3f988f642---------------pyspark-----------------", "anchor_text": "Pyspark"}, {"url": "https://medium.com/tag/kubernetes?source=post_page-----68f3f988f642---------------kubernetes-----------------", "anchor_text": "Kubernetes"}, {"url": "https://medium.com/tag/big-data?source=post_page-----68f3f988f642---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/data-science?source=post_page-----68f3f988f642---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68f3f988f642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----68f3f988f642---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68f3f988f642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----68f3f988f642---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68f3f988f642&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=post_page-----68f3f988f642--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe13ebfdd5f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=post_page-e13ebfdd5f62----68f3f988f642---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff2ad4d2ded18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&newsletterV3=e13ebfdd5f62&newsletterV3Id=f2ad4d2ded18&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----68f3f988f642---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Written by Alexander Sack"}, {"url": "https://medium.com/@pisymbol/followers?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "33 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe13ebfdd5f62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&user=Alexander+Sack&userId=e13ebfdd5f62&source=post_page-e13ebfdd5f62----68f3f988f642---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff2ad4d2ded18&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fignite-the-spark-68f3f988f642&newsletterV3=e13ebfdd5f62&newsletterV3Id=f2ad4d2ded18&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----68f3f988f642---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/decoding-decentralization-f3af30068e75?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Alexander Sack"}, {"url": "https://medium.com/coinmonks?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Coinmonks"}, {"url": "https://medium.com/coinmonks/decoding-decentralization-f3af30068e75?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Decoding DecentralizationAn Ethereum Blockchain Data Primer: Part I"}, {"url": "https://medium.com/coinmonks/decoding-decentralization-f3af30068e75?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "11 min read\u00b7Apr 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcoinmonks%2Ff3af30068e75&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2Fdecoding-decentralization-f3af30068e75&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----f3af30068e75----0-----------------clap_footer----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/coinmonks/decoding-decentralization-f3af30068e75?source=author_recirc-----68f3f988f642----0---------------------20276921_128e_482a_bbbf_40d89036bc7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3af30068e75&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoinmonks%2Fdecoding-decentralization-f3af30068e75&source=-----68f3f988f642----0-----------------bookmark_preview----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----68f3f988f642----1---------------------20276921_128e_482a_bbbf_40d89036bc7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----68f3f988f642----1-----------------bookmark_preview----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----68f3f988f642----2---------------------20276921_128e_482a_bbbf_40d89036bc7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----68f3f988f642----2-----------------bookmark_preview----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/to-serve-man-60246a82d953?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Alexander Sack"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/to-serve-man-60246a82d953?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "To Serve ManDeploying models on Kubernetes using Seldon Core"}, {"url": "https://towardsdatascience.com/to-serve-man-60246a82d953?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": "12 min read\u00b7Feb 22, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F60246a82d953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-serve-man-60246a82d953&user=Alexander+Sack&userId=e13ebfdd5f62&source=-----60246a82d953----3-----------------clap_footer----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/to-serve-man-60246a82d953?source=author_recirc-----68f3f988f642----3---------------------20276921_128e_482a_bbbf_40d89036bc7d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60246a82d953&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-serve-man-60246a82d953&source=-----68f3f988f642----3-----------------bookmark_preview----20276921_128e_482a_bbbf_40d89036bc7d-------", "anchor_text": ""}, {"url": "https://medium.com/@pisymbol?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "See all from Alexander Sack"}, {"url": "https://towardsdatascience.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Apache Spark Optimization TechniquesA review of some of the most common Spark performance problems and how to address them"}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----fa7f20a9a2cf----0-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/apache-spark-optimization-techniques-fa7f20a9a2cf?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffa7f20a9a2cf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapache-spark-optimization-techniques-fa7f20a9a2cf&source=-----68f3f988f642----0-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Yifeng Jiang"}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Build an Open Data Lakehouse with Spark, Delta and Trino on S3Combining the strength of data lake and warehouse in a way that is open, simple, and runs anywhere"}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "\u00b76 min read\u00b7Nov 7, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fbd60521a12dd&operation=register&redirect=https%3A%2F%2Fuprush.medium.com%2Fbuild-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd&user=Yifeng+Jiang&userId=98df5da871eb&source=-----bd60521a12dd----1-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://uprush.medium.com/build-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd60521a12dd&operation=register&redirect=https%3A%2F%2Fuprush.medium.com%2Fbuild-an-open-data-lakehouse-with-spark-delta-and-trino-on-s3-bd60521a12dd&source=-----68f3f988f642----1-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://julianwest155.medium.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://julianwest155.medium.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Julian West"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Unit testing PySpark code using PytestWhen it comes to writing unit-tests for PySpark pipelines, writing focussed, fast, isolated and concise tests can be a challenge."}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "\u00b710 min read\u00b7Jan 16"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb5ab2fd54415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funit-testing-pyspark-code-using-pytest-b5ab2fd54415&user=Julian+West&userId=257ac04bf615&source=-----b5ab2fd54415----0-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unit-testing-pyspark-code-using-pytest-b5ab2fd54415?source=read_next_recirc-----68f3f988f642----0---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb5ab2fd54415&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funit-testing-pyspark-code-using-pytest-b5ab2fd54415&source=-----68f3f988f642----0-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----68f3f988f642----1---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----68f3f988f642----1-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/understand-the-internal-working-of-apache-spark-5a5eda4e937a?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@biswasavhijit007?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@biswasavhijit007?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Abhijit Biswas"}, {"url": "https://blog.devgenius.io/?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Dev Genius"}, {"url": "https://blog.devgenius.io/understand-the-internal-working-of-apache-spark-5a5eda4e937a?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Understand The Internal Working of Apache SparkIntroduction : Underlying Architecture of Apache Spark"}, {"url": "https://blog.devgenius.io/understand-the-internal-working-of-apache-spark-5a5eda4e937a?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "7 min read\u00b7Apr 19"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fdev-genius%2F5a5eda4e937a&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Funderstand-the-internal-working-of-apache-spark-5a5eda4e937a&user=Abhijit+Biswas&userId=3488677a69d5&source=-----5a5eda4e937a----2-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://blog.devgenius.io/understand-the-internal-working-of-apache-spark-5a5eda4e937a?source=read_next_recirc-----68f3f988f642----2---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5a5eda4e937a&operation=register&redirect=https%3A%2F%2Fblog.devgenius.io%2Funderstand-the-internal-working-of-apache-spark-5a5eda4e937a&source=-----68f3f988f642----2-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@chenglong.w1/the-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@chenglong.w1?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@chenglong.w1?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "Chenglong Wu"}, {"url": "https://medium.com/@chenglong.w1/the-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "The 5S Optimization Framework for Spark: Serialization OptimizationOptimizing Serialization in Apache Spark: Strategies to Improve Performance Using the 5S Optimization Framework"}, {"url": "https://medium.com/@chenglong.w1/the-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": "4 min read\u00b7Apr 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa7be7c3c37a6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40chenglong.w1%2Fthe-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6&user=Chenglong+Wu&userId=b3af2910a112&source=-----a7be7c3c37a6----3-----------------clap_footer----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/@chenglong.w1/the-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6?source=read_next_recirc-----68f3f988f642----3---------------------9d7b89d7_89cf_4bd2_b1ac_c92918889753-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7be7c3c37a6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40chenglong.w1%2Fthe-5s-optimization-framework-for-spark-serialization-optimization-a7be7c3c37a6&source=-----68f3f988f642----3-----------------bookmark_preview----9d7b89d7_89cf_4bd2_b1ac_c92918889753-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----68f3f988f642--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----68f3f988f642--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}