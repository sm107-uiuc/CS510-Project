{"url": "https://towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac", "time": 1683008638.543189, "path": "towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac/", "webpage": {"metadata": {"title": "Neural Machine Translation (NMT) with Attention Mechanism | by Harshil Patel | Towards Data Science", "h1": "Neural Machine Translation (NMT) with Attention Mechanism", "description": "It is an undeniable truth that in this era of globalization, language translation plays a vital role in communication among the denizens of different nation\u2019s. Moreover, in a country like India \u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3", "anchor_text": "here", "paragraph_index": 6}, {"url": "http://www.manythings.org/anki/", "anchor_text": "here", "paragraph_index": 12}, {"url": "https://github.com/thushv89/attention_keras/blob/master/layers/attention.py", "anchor_text": "here", "paragraph_index": 24}, {"url": "https://arxiv.org/pdf/1409.0473.pdf", "anchor_text": "\u2018Bahdanau Attention\u2019", "paragraph_index": 24}, {"url": "https://github.com/harshilpatel99/NMT_english2marthi", "anchor_text": "here", "paragraph_index": 41}, {"url": "https://www.linkedin.com/in/harshil-patel-708680148/", "anchor_text": "LinkedIn", "paragraph_index": 41}], "all_paragraphs": ["It is an undeniable truth that in this era of globalization, language translation plays a vital role in communication among the denizens of different nation\u2019s. Moreover, in a country like India - which a multilingual nation, language difference could be observed in its states itself! Hence, considering the importance of Language Translation, it becomes necessary to develop a system that could easily translate an unknown language to a known language.", "In accordance with this, in this story, we will make a Deep Learning model that will translate English sentences to Marathi sentences. I have chosen Marathi language as it is easy for me to recognize. You can use any other language that is comfortable for you, as the model nearly remains the same. Moreover, I will try to briefly explain a major concept in language processing called Attention Mechanism here!", "The major drawback of encoder-decoder model in sequence to sequence recurrent neural network is that it can only work on short sequences. It is difficult for the encoder model to memorize long sequences and convert it into a fixed-length vector. Moreover, the decoder receives only one information that is the last encoder hidden state. Hence it's difficult for the decoder to summarize large input sequence at once. So, how do we overcome this problem?", "How about if we give a vector representation from every encoder step to the decoder model!", "Now, this is where the concept of \u2018Attention Mechanism\u2019 comes. The major intuition about this is that it predicts the next word by concentrating on a few relevant parts of the sequence rather than looking on the entire sequence.", "In layman terms it can be described as an interference between encoder and decoder which extracts useful information from encoder and transmits it back to the decoder.", "Refer here for detailed understanding about Attention Mechanism.", "There are mainly two types of attention mechanism:", "Global Attention are those attention in which all the hidden state vectors of the encoder are passed to get the context vector.", "Local Attention are those attention in which only a few hidden state vectors of encoder are considered for the generation of context vector.", "We will be using global attention in this story. Let\u2019s now make use of attention mechanism and develop a language translator that will convert English sentence to Marathi sentence.", "Open Jupyter Notebook and import some required libraries:", "We will be working on a language dataset available here.", "This site contains a dataset of numerous languages and its translation to English. You can download any language dataset as per your preference and comfort. However, remember to choose a dataset which is quite huge, so that we can get better results after training the model. Here, I will be downloading Marathi-English dataset which comprises of 38696 sentences.", "After downloading load dataset, import the data as mentioned below:", "As you can see that it is a raw text file and hence it is necessary to clean and transform it as per our preference. We will separate Marathi and English sentences and form a list of it, continuing it by storing it into a dataframe so that it's easy for us to reuse it again easily.", "Now let\u2019s clean the data and make it suitable for our model. In the cleaning process, we will convert into lower case, remove all punctuation and other unnecessary letters and digits too.", "Adding \u2018start\u2019 and \u2018end\u2019 tag to marathi sentence. This will help the decoder to know from where to start decoding and when to end.", "We will split our dataset with a ratio of 0.1 so that our trained model can give precise results. X_train and y_train will be our training set while X_test and y_test will be our testing/validation set.", "Let\u2019s determine the maximum length of our sentences in both English and Marathi:", "As a neural network requires numerical data to process, it becomes necessary to convert our string input to a numerical list. One way of doing this is to use Tokenizer provided by keras-preprocessing library.", "Also, remember it is mandatory to have an equal length of all input sequences in sequence-to-sequence models. So, we will pad extra \u20180s\u2019 to make the sequence of the same length. This would be done by pad_sequence.", "To save our preprocessing time whenever we reuse it again in future, we will save our important attributes. So, let\u2019s do it first with the help of pickle library.", "Instead of a simple encoder-decoder architecture, we will be using Attention Mechanism as discussed earlier in this blog.", "Keras does not officially support attention layer. So, we can either implement our own attention layer or use a third-party implementation. For now, we will be using a third party attention mechanism. You can download the attention layer from here and copy it in a different file called attention.py. This attention is an implementation of \u2018Bahdanau Attention\u2019 .", "Let\u2019s define the structure of our model:", "You can modify this model as per your choice and requirement to get better results. You can change number of layers, number of units or some regularization techniques too. For the time being, let\u2019s move forward and see what our model looks like!", "We will first define some callbacks so that it would be easy for model visualization and evaluation in future.", "We are using \u2018Teacher Forcing\u2019 technique for faster training of our model. In the teacher forcing method, we also pass the target data as the input to the decoder. For example, if we are going to predict \u2018hello\u2019, then we will pass \u2018hello\u2019 itself as an input to the decoder. Due to this it makes the learning process faster.", "The execution time was around 39 seconds per epoch on 12GB NVIDIA Tesla K80 GPU. EarlyStopping was achieved at 18th epoch.", "We can visualize the loss difference in both training and validation phase as:", "We are getting some pretty good results from our model with around 90% validation accuracy and a validation loss of 0.5303.", "Let\u2019s save our trained model with proper weights. Do remember to save the model like I have done as we have to load weights too for the inference model.", "In machine learning we use inference model to predict our output sequences by considering weights from a pre-trained model. In other terms, it can be said that its a model that deduces properties that are learned in training phase and are now used for predicting new sequences.", "Now we have trained the sequence to sequence model and created the inference model using the trained model for making a prediction. Let\u2019s predict some Marathi sentences from the English sentences.", "Some transformation before giving a string to the function:", "Call the necessary functions and let\u2019s test our translation model:", "Our model makes some good translations of English sentences to Marathi sentences.", "I have deployed my model through Django and have hosted it on heroku. You can look at it here.", "In this story, we learned about the functionality of Attention Mechanism and implemented a Language Translation task. This task could have multiple use cases in daily lifestyles. For example, we can use this technique to build a multi-language translator that can translate various languages from a single language. Also, if we can integrate this with an Optical Character Recognition system, we can translate texts directly from images.", "If you have any other use case or technique to work with translation data and also, if you find a more improved model for NMT, do share in the response block below!", "The entire code for this article is available here. If you have any feedback, feel free to reach out to me on LinkedIn.", "A Deep Learning enthusiast with a profound background in Computer Science. Loves learning new and creative concepts about programming, science and life."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5e59b57bd2ac&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@harshil.99?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Harshil Patel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fef96953faa42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=post_page-ef96953faa42----5e59b57bd2ac---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5e59b57bd2ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=-----5e59b57bd2ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5e59b57bd2ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=-----5e59b57bd2ac---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21", "anchor_text": "Long Short Time Memory(LSTM)"}, {"url": "https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3", "anchor_text": "here"}, {"url": "http://www.manythings.org/anki/", "anchor_text": "here"}, {"url": "https://github.com/thushv89/attention_keras/blob/master/layers/attention.py", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1409.0473.pdf", "anchor_text": "\u2018Bahdanau Attention\u2019"}, {"url": "https://hurdlenet.herokuapp.com/", "anchor_text": "Harshil Patelhurdlenet.herokuapp.com"}, {"url": "https://github.com/harshilpatel99/NMT_english2marthi", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/harshil-patel-708680148/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----5e59b57bd2ac---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-translation?source=post_page-----5e59b57bd2ac---------------machine_translation-----------------", "anchor_text": "Machine Translation"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----5e59b57bd2ac---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5e59b57bd2ac---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/nlp?source=post_page-----5e59b57bd2ac---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5e59b57bd2ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=-----5e59b57bd2ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5e59b57bd2ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=-----5e59b57bd2ac---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5e59b57bd2ac&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fef96953faa42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=post_page-ef96953faa42----5e59b57bd2ac---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F324e807e9134&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&newsletterV3=ef96953faa42&newsletterV3Id=324e807e9134&user=Harshil+Patel&userId=ef96953faa42&source=-----5e59b57bd2ac---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Written by Harshil Patel"}, {"url": "https://medium.com/@harshil.99/followers?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "35 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fef96953faa42&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&user=Harshil+Patel&userId=ef96953faa42&source=post_page-ef96953faa42----5e59b57bd2ac---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F324e807e9134&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac&newsletterV3=ef96953faa42&newsletterV3Id=324e807e9134&user=Harshil+Patel&userId=ef96953faa42&source=-----5e59b57bd2ac---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Harshil Patel"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Image Super-Resolution using Convolution Neural Networks and Auto-encodersA guide to enhancing image quality with Deep Learning!"}, {"url": "https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "6 min read\u00b7May 16, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F28c9eceadf90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90&user=Harshil+Patel&userId=ef96953faa42&source=-----28c9eceadf90----0-----------------clap_footer----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90?source=author_recirc-----5e59b57bd2ac----0---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F28c9eceadf90&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimage-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90&source=-----5e59b57bd2ac----0-----------------bookmark_preview----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----5e59b57bd2ac----1---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----5e59b57bd2ac----1-----------------bookmark_preview----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----5e59b57bd2ac----2---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----5e59b57bd2ac----2-----------------bookmark_preview----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": "15 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----3-----------------clap_footer----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----5e59b57bd2ac----3---------------------43292d4c_c9ec_4c42_af27_a47a4539504b-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----5e59b57bd2ac----3-----------------bookmark_preview----43292d4c_c9ec_4c42_af27_a47a4539504b-------", "anchor_text": ""}, {"url": "https://medium.com/@harshil.99?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "See all from Harshil Patel"}, {"url": "https://towardsdatascience.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----0-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----5e59b57bd2ac----0-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----1-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----5e59b57bd2ac----1-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Sunil Yadav"}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Variational AutoencodersIn this article, we will continue our discussion with variational autoencoders (VAEs) after covering DGM basics and AGM. Variational\u2026"}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b76 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fce7fe921cce7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sunil7545%2Fvariational-autoencoders-ce7fe921cce7&user=Sunil+Yadav&userId=9ee175d244fd&source=-----ce7fe921cce7----0-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@sunil7545/variational-autoencoders-ce7fe921cce7?source=read_next_recirc-----5e59b57bd2ac----0---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fce7fe921cce7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40sunil7545%2Fvariational-autoencoders-ce7fe921cce7&source=-----5e59b57bd2ac----0-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Language Models: GPT and GPT-2How smaller language models inspired modern breakthroughs"}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b713 min read\u00b7Nov 24, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8bdb9867c50a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-gpt-and-gpt-2-8bdb9867c50a&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----8bdb9867c50a----1-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/language-models-gpt-and-gpt-2-8bdb9867c50a?source=read_next_recirc-----5e59b57bd2ac----1---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bdb9867c50a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flanguage-models-gpt-and-gpt-2-8bdb9867c50a&source=-----5e59b57bd2ac----1-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----5e59b57bd2ac----2---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----5e59b57bd2ac----2-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/translate-with-gpt-3-9903c4a6f385?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@bnjmn_marie?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/@bnjmn_marie?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Benjamin Marie"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/translate-with-gpt-3-9903c4a6f385?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "Translate with GPT-3Machine translation but without a machine translation system"}, {"url": "https://towardsdatascience.com/translate-with-gpt-3-9903c4a6f385?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": "\u00b718 min read\u00b7Nov 22, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9903c4a6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranslate-with-gpt-3-9903c4a6f385&user=Benjamin+Marie&userId=ad2a414578b3&source=-----9903c4a6f385----3-----------------clap_footer----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/translate-with-gpt-3-9903c4a6f385?source=read_next_recirc-----5e59b57bd2ac----3---------------------d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9903c4a6f385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftranslate-with-gpt-3-9903c4a6f385&source=-----5e59b57bd2ac----3-----------------bookmark_preview----d0ba06fc_f0bc_49b1_8d35_5eabaa477a27-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----5e59b57bd2ac--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}