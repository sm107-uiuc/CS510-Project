{"url": "https://towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a", "time": 1682995778.4254951, "path": "towardsdatascience.com/predicting-the-performance-of-deep-learning-models-9cb50cf0b62a/", "webpage": {"metadata": {"title": "Predicting the performance of deep learning models | by Archy de Berker | Towards Data Science", "h1": "Predicting the performance of deep learning models", "description": "It\u2019s widely acknowledged that the recent successes of Deep Learning rest heavily upon the availability of huge amounts of data. Vision was the first domain in which the promise of DL was realised\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www.image-net.org", "anchor_text": "ImageNet", "paragraph_index": 0}, {"url": "https://blogs.unity3d.com/en/2017/09/19/introducing-unity-machine-learning-agents/", "anchor_text": "simulators for RL", "paragraph_index": 0}, {"url": "https://www.youtube.com/watch?v=ORHFOnaEzPc", "anchor_text": "his 2018 NIPS talk", "paragraph_index": 2}, {"url": "https://www.theverge.com/2017/2/13/14599186/google-waymo-self-driving-salary-compensation-autonomous", "anchor_text": "made some people very rich indeed", "paragraph_index": 2}, {"url": "https://www.facebook.com/yann.lecun/posts/10154938130592143", "anchor_text": "Facebook post", "paragraph_index": 2}, {"url": "https://arxiv.org/abs/1712.00409", "anchor_text": "\u2018Deep Learning Scaling is Predictable, Empirically\u2019", "paragraph_index": 3}, {"url": "http://research.baidu.com/deep-learning-scaling-predictable-empirically/", "anchor_text": "excellent blogpost", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Kleiber%27s_law", "anchor_text": "Max Kleiber in 1947", "paragraph_index": 4}, {"url": "https://github.com/archydeberker/predictable-ml/blob/master/Predicting_CIFAR_PyTorch.ipynb", "anchor_text": "here", "paragraph_index": 11}, {"url": "http://deberker.com/archy/how-intelligent-are-our-machines/", "anchor_text": "difficulty of quantifying progress towards superintelligence", "paragraph_index": 28}, {"url": "http://deberker.com/archy/predicting-the-performance-of-deep-learning-models/?preview=true", "anchor_text": "deberker.com", "paragraph_index": 29}], "all_paragraphs": ["It\u2019s widely acknowledged that the recent successes of Deep Learning rest heavily upon the availability of huge amounts of data. Vision was the first domain in which the promise of DL was realised, probably because of the availability of large datasets such as ImageNet. The recent surge of simulators for RL further illustrates that as we push further to apply these techniques to real-world problems, data scarcity quickly becomes the bottleneck.", "In commercial contexts, this question comes up a lot. When time and money is at stake, it\u2019d be useful to be able to make some concrete statements about how improvements in model architecture are likely to weigh up against simply gathering more data. Should we pay a team of engineers for 6 months to finesse our models, or should we pay a team of crowdsourced helpers for 6 months to collate the data we need?", "The fact that we can\u2019t easily answer this question reflects the immaturity of deep learning as a field, a shortcoming that led Ali Rahimi to declare \u2018Machine learning has become alchemy\u2019 in a his 2018 NIPS talk (he\u2019s wrong in one sense at least; alchemy never made anybody any money, whilst deep learning has made some people very rich indeed). Yann LeCunn\u2019s widely publicised Facebook post response laid down the gauntlet: \u2018if you are not happy with our understanding of the methods you use everyday, fix it\u2019.", "A paper from Baidu, titled \u2018Deep Learning Scaling is Predictable, Empirically\u2019 , goes some way to answering this challenge. As the title suggests, their answer to the question is an empirical, not a theoretical, one. The paper is accompanied by an excellent blogpost, which I refer you to for a more detailed discussion of the findings, which I will summarise here.", "Before we dive into it, a small digression: the study of scaling laws has fascinated biologists for a long time. This plot, from Max Kleiber in 1947, shows that the metabolic rate of an animal (heat produced per day) scales in a log-log fashion (more on this below) with the body weight of that animal.", "In fact, it seems to scale as", "which is why the red line is steeper than the one labelled surface \u2014 which is", "but shallower than the one labelled weight. Fascinatingly, nobody really knows why this law holds, although it seems very robust.", "Back to Baidu and the world of artificial intelligence, and we are producing similar plots 70 years later:", "Essentially, the paper documents that increases in data produce decreases in test-set loss with the same power-law relationship, which ends up as a straight line when plotted on a log-log scale. Fascinatingly, the exponent of this relationship \u2014 the slope of the line on the linear scale- ends up being more or less the same for any architecture you throw at the problem at hand. So the datasets themselves define this exponent: the models merely shift the intercept. To hammer this home: the effect of adding more data is essentially the same for any model, given the dataset. That\u2019s pretty extraordinary.", "They don\u2019t provide any code for the paper, so I threw together some experiments in PyTorch to explore their conclusions.", "You can download the full Jupyter notebook here or read on for some gists.", "I built on the code provided in the PyTorch tutorial to produce a simple CNN to test against the CIFAR dataset (a small image classification task with 10 classes). I made it configurable with a hyperparameter dictionary because the optimal hyper parameters are very sensitive to dataset size \u2014 as we\u2019ll see, this is important for replicating the Baidu results.", "I split the training data into a training and a validation set, and subsampled the training set as suggested in the paper.", "I then trained 9 models, one for each dataset size, with a stopping condition defined by increasing validation error for 3 epochs in a row (the original paper is a little vague on the specifics of validation). I then evaluated each of them against the test set.", "As you would expect, the test-set accuracy increases with the increasing size of the train set. Moreover, it looks sort of power-law-ish.", "The loss decreases, in a similar fashion.", "However, neither the log-log plots of the accuracy or the loss look as cute as the one\u2019s in the Baidu paper. In fact, they each show some kind of vaguely logarithmic form themselves, suggesting that we have a sub-power law relationship.", "The reason for this is fairly obvious: I didn\u2019t do the exhaustive hyper-parameter search that they did at each training-set size. As such, we\u2019re not finding the best model for each dataset size. Most probably, our models are lacking the capacity to fully capture the larger datasets, and we\u2019re therefore not making best use of the data.", "You\u2019ll remember that in the model definition we set the layer sizes using a hyper parameter dictionary, thus making it easy to fiddle with the shape of our network through hyper parameter tuning. As such, it\u2019s relatively straightforward for us to implement some random search:", "We can now repeat the training loop for each dataset size, sampling parameters at random:", "And use this to train a bunch of networks for each dataset size, keeping the one that performs best on the validation set. I\u2019m performing this tuning on MacBook without a GPU so I limited myself to 10 searches for each dataset size, hoping I could prove the point without requisitioning an AWS instance.", "We can then go hunting for our power laws again, and sure enough, they\u2019re looking a lot more dapper:", "Not quite as nice as Kleiber\u2019s, but not bad.", "The original paper tests a variety of models in a variety of tasks \u2014 the closest to the one performed here is ImageNet with ResNets. It\u2019s pleasing to see that the results are so easily replicable with a different network, on a different dataset.", "In their discussion, the authors note:", "We have yet to find factors that affect the power-law exponent. To beat the power-law as we increase data set size, models would need to learn more concepts with successively less data.", "This is precisely the kind of scaling that you see with humans; the more you know, the easier it is to acquire new knowledge.", "I wrote previously about the difficulty of quantifying progress towards superintelligence. It seems that the advent of models that beat the power-law exponent \u2014 that get more data efficient as they learn \u2014 might be an important empirical milestone on that path.", "Originally published at deberker.com on April 14, 2019.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Product manager & data scientist. Writing about AI, building things, and climate change."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9cb50cf0b62a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://archydeberker.medium.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Archy de Berker"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f----9cb50cf0b62a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.image-net.org", "anchor_text": "ImageNet"}, {"url": "https://blogs.unity3d.com/en/2017/09/19/introducing-unity-machine-learning-agents/", "anchor_text": "simulators for RL"}, {"url": "https://www.youtube.com/watch?v=ORHFOnaEzPc", "anchor_text": "his 2018 NIPS talk"}, {"url": "https://www.theverge.com/2017/2/13/14599186/google-waymo-self-driving-salary-compensation-autonomous", "anchor_text": "made some people very rich indeed"}, {"url": "https://www.facebook.com/yann.lecun/posts/10154938130592143", "anchor_text": "Facebook post"}, {"url": "https://arxiv.org/abs/1712.00409", "anchor_text": "\u2018Deep Learning Scaling is Predictable, Empirically\u2019"}, {"url": "http://research.baidu.com/deep-learning-scaling-predictable-empirically/", "anchor_text": "excellent blogpost"}, {"url": "https://en.wikipedia.org/wiki/Kleiber%27s_law", "anchor_text": "Max Kleiber in 1947"}, {"url": "https://github.com/archydeberker/predictable-ml/blob/master/Predicting_CIFAR_PyTorch.ipynb", "anchor_text": "here"}, {"url": "http://deberker.com/archy/how-intelligent-are-our-machines/", "anchor_text": "difficulty of quantifying progress towards superintelligence"}, {"url": "http://deberker.com/archy/predicting-the-performance-of-deep-learning-models/?preview=true", "anchor_text": "deberker.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----9cb50cf0b62a---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----9cb50cf0b62a---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----9cb50cf0b62a---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----9cb50cf0b62a---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/python?source=post_page-----9cb50cf0b62a---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&user=Archy+de+Berker&userId=f651916e4a3f&source=-----9cb50cf0b62a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&user=Archy+de+Berker&userId=f651916e4a3f&source=-----9cb50cf0b62a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9cb50cf0b62a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9cb50cf0b62a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9cb50cf0b62a--------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://archydeberker.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Archy de Berker"}, {"url": "https://archydeberker.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "321 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff651916e4a3f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&user=Archy+de+Berker&userId=f651916e4a3f&source=post_page-f651916e4a3f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb1754fbd1852&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-the-performance-of-deep-learning-models-9cb50cf0b62a&newsletterV3=f651916e4a3f&newsletterV3Id=b1754fbd1852&user=Archy+de+Berker&userId=f651916e4a3f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}