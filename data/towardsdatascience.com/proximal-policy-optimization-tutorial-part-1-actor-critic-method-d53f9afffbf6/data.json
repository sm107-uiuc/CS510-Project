{"url": "https://towardsdatascience.com/proximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6", "time": 1682997650.302634, "path": "towardsdatascience.com/proximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6/", "webpage": {"metadata": {"title": "Proximal Policy Optimization Tutorial (Part 1/2: Actor-Critic Method) | by Chintan Trivedi | Towards Data Science", "h1": "Proximal Policy Optimization Tutorial (Part 1/2: Actor-Critic Method)", "description": "Welcome to the first part of a math and code turorial series. I\u2019ll be showing how to implement a Reinforcement Learning algorithm known as Proximal Policy Optimization (PPO) for teaching an AI agent\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/google-research/football", "anchor_text": "Google Football Environment", "paragraph_index": 2}, {"url": "https://medium.com/@chintan.t93/proximal-policy-optimization-tutorial-part-2-2-gae-and-ppo-loss-fe1b3c5549e8", "anchor_text": "PART 2 of this tutorial series", "paragraph_index": 25}, {"url": "https://medium.com/@chintan.t93", "anchor_text": "Medium", "paragraph_index": 26}, {"url": "https://github.com/ChintanTrivedi", "anchor_text": "GitHub", "paragraph_index": 26}, {"url": "http://youtube.com/c/DeepGamingAI", "anchor_text": "YouTube channel", "paragraph_index": 26}, {"url": "http://medium.com/deepgamingai", "anchor_text": "medium.com/deepgamingai", "paragraph_index": 28}], "all_paragraphs": ["Welcome to the first part of a math and code turorial series. I\u2019ll be showing how to implement a Reinforcement Learning algorithm known as Proximal Policy Optimization (PPO) for teaching an AI agent how to play football/soccer. By the end of this tutorial, you\u2019ll get an idea on how to apply an on-policy learning method in an actor-critic framework in order to learn navigating any game environment. We shall see what these terms mean in context of the PPO algorithm and also implement them in Python with the help of Keras. So, let\u2019s first start with the installation of our game environment.", "Note: The code for this entire series is available in the GitHub repository linked below.", "I\u2019m using the Google Football Environment for this tutorial but you can use any game environment, just make sure it supports OpenAI\u2019s Gym API in python. Please note that the football environment currently only supports Linux platform at the time of writing this tutorial.", "Start by creating a virtual environment named footballenv and activating it.", "Now install the system dependencies and python packages required for this project. Make sure you select the correct CPU/GPU version of gfootball appropriate for your system.", "Now that we have the game installed, let\u2019s try to test whether it runs correctly on your system or not.", "A typical Reinforcement Learning setup works by having an AI agent interact with our environment. The agent observes the current state of our environment, and based on somepolicy makes the decision to take a particular action. This action is then relayed back to the environment which moves forward by one step. This generates a reward which indicates whether the action taken was positive or negative in the context of the game being played. Using this reward as a feedback, the agent tries to figure out how to modify its existing policy in order to obtain better rewards in the future.", "So now let\u2019s go ahead and implement this for a random-action AI agent interacting with this football environment. Create a new python file named train.py and execute the following using the virtual environment we created earlier.", "This creates an environment object env for the academy_empty_goal scenario where our player spawns at half-line and has to score in an empty goal on the right side. representation='pixels' means that the state that our agent will observe is in the form of an RGB image of the frame rendered on the screen. If you see a player on your screen taking random actions in the game, congratulations, everything is setup correctly and we can start implementing the PPO algorithm!", "Here are the same installation steps in a video format if that\u2019s more your thing.", "The PPO algorithm was introduced by the OpenAI team in 2017 and quickly became one of the most popular RL methods usurping the Deep-Q learning method. It involves collecting a small batch of experiences interacting with the environment and using that batch to update its decision-making policy. Once the policy is updated with this batch, the experiences are thrown away and a newer batch is collected with the newly updated policy. This is the reason why it is an \u201con-policy learning\u201d approach where the experience samples collected are only useful for updating the current policy once.", "The key contribution of PPO is ensuring that a new update of the policy does not change it too much from the previous policy. This leads to less variance in training at the cost of some bias, but ensures smoother training and also makes sure the agent does not go down an unrecoverable path of taking senseless actions. So, let\u2019s go ahead and breakdown our AI agent into more details and see how it defines and updates its policy.", "We\u2019ll use the Actor-Critic approach for our PPO agent. It uses two models, both Deep Neural Nets, one called the Actor and other called the Critic.", "The Actor model performs the task of learning what action to take under a particular observed state of the environment. In our case, it takes the RGB image of the game as input and gives a particular action like shoot or pass as output.", "Here, we are first defining the input shape state_input for our neural net which is the shape of our RGB image. n_actions is the total number of actions available to us in this football environment and will be the total number of output nodes of the neural net.", "I\u2019m using the first few layers of a pretrained MobileNet CNN in order to process our input image. I\u2019m also making these layers\u2019 parameters non-trainable since we do not want to change their weights. Only the classification layers added on top of this feature extractor will be trained to predict the correct actions. Let\u2019s combine these layers as Keras Model and compile it using a mean-squared error loss (for now, this will be changed to a custom PPO loss later in this tutorial).", "We send the action predicted by the Actor to the football environment and observe what happens in the game. If something positive happens as a result of our action, like scoring a goal, then the environment sends back a positive response in the form of a reward. If an own goal occurs due to our action, then we get a negative reward. This reward is taken in by the Critic model.", "The job of the Critic model is to learn to evaluate if the action taken by the Actor led our environment to be in a better state or not and give its feedback to the Actor, hence its name. It outputs a real number indicating a rating (Q-value) of the action taken in the previous state. By comparing this rating obtained from the Critic, the Actor can compare its current policy with a new policy and decide how it wants to improve itself to take better actions.", "As you can see, the structure of the Critic neural net is almost the same as the Actor. The only major difference being, the final layer of Critic outputs a real number. Hence, the activation used is tanh and not softmax since we do not need a probability distribution here like with the Actor.", "Now, an important step in the PPO algorithm is to run through this entire loop with the two models for a fixed number of steps known as PPO steps. So essentially, we are interacting with our environemt for certain number of steps and collecting the states, actions, rewards, etc. which we will use for training.", "Now that we have our two models defined, we can use them to interact with the football environment for a fixed number of steps and collect our experiences. These experiences will be used to update the policies of our models after we have a large enough batch of such samples. This is how to implement the loop collecting such sample experiences.", "As you can see in the code above, we have defined a few python list objects that are be used to store information like the observed states, actions, rewards etc. when we are interacting with our environment for a total of ppo_steps. This gives us a batch of 128 sample experiences that will be used later on for training the Actor and Critic neural networks.", "Following two videos explain this code line-by-line and also show how the end result looks like on the game screen.", "That\u2019s all for this part of the tutorial. We installed the Google Football Environment on our Linux system and implemented a basic framework to interact with this environment. Next, we defined the Actor and Critic models and used them to interact with and collect sample experiences from this game. Hope you were able to keep up so far, otherwise let me know down below in the comments if you were held up by something and I\u2019ll try to help.", "Next time we\u2019ll see how to use these experiences we collected to train and improve the actor and critic models. We\u2019ll go over the Generalized Advantage Estimation algorithm and use that to calculate a custom PPO loss for training these networks. So stick around!", "EDIT: Here\u2019s PART 2 of this tutorial series.", "Thank you for reading. If you liked this article, you may follow more of my work on Medium, GitHub, or subscribe to my YouTube channel.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "AI, ML for Digital Games Researcher. Founder at DG AI Research Lab, India. Visit our publication homepage medium.com/deepgamingai for weekly AI & Games content!"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd53f9afffbf6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@chintan.t93?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chintan.t93?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Chintan Trivedi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcba121ffc3f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&user=Chintan+Trivedi&userId=cba121ffc3f5&source=post_page-cba121ffc3f5----d53f9afffbf6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/ChintanTrivedi/rl-bot-football", "anchor_text": "ChintanTrivedi/rl-bot-footballTested on Ubuntu 18.04 and a single NVIDIA GPU. Get the Google Research Football environment up and running using these\u2026github.com"}, {"url": "https://github.com/google-research/football", "anchor_text": "Google Football Environment"}, {"url": "https://medium.com/@chintan.t93/proximal-policy-optimization-tutorial-part-2-2-gae-and-ppo-loss-fe1b3c5549e8", "anchor_text": "PART 2 of this tutorial series"}, {"url": "https://medium.com/@chintan.t93", "anchor_text": "Medium"}, {"url": "https://github.com/ChintanTrivedi", "anchor_text": "GitHub"}, {"url": "http://youtube.com/c/DeepGamingAI", "anchor_text": "YouTube channel"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d53f9afffbf6---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----d53f9afffbf6---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d53f9afffbf6---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d53f9afffbf6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-neural-networks?source=post_page-----d53f9afffbf6---------------deep_neural_networks-----------------", "anchor_text": "Deep Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&user=Chintan+Trivedi&userId=cba121ffc3f5&source=-----d53f9afffbf6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&user=Chintan+Trivedi&userId=cba121ffc3f5&source=-----d53f9afffbf6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd53f9afffbf6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d53f9afffbf6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d53f9afffbf6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chintan.t93?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@chintan.t93?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Chintan Trivedi"}, {"url": "https://medium.com/@chintan.t93/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.4K Followers"}, {"url": "http://medium.com/deepgamingai", "anchor_text": "medium.com/deepgamingai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcba121ffc3f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&user=Chintan+Trivedi&userId=cba121ffc3f5&source=post_page-cba121ffc3f5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff8a6ddbb7d3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6&newsletterV3=cba121ffc3f5&newsletterV3Id=f8a6ddbb7d3e&user=Chintan+Trivedi&userId=cba121ffc3f5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}