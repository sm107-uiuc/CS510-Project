{"url": "https://towardsdatascience.com/choose-the-right-transformer-framework-for-you-b7c51737d45", "time": 1682996760.411387, "path": "towardsdatascience.com/choose-the-right-transformer-framework-for-you-b7c51737d45/", "webpage": {"metadata": {"title": "Choose the Suitable Transformer Framework for Your Needs | by Xu LIANG | Towards Data Science", "h1": "Choose the Suitable Transformer Framework for Your Needs", "description": "If you are a researcher, Fairseq is flexible enough for customization. But if you are working on some real application and considering deployment, it would be better to choose Tensor2Tensor. A\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "\u201cAttention Is All You Need\u201d (Vaswani, et al, 2017)", "paragraph_index": 4}, {"url": "https://arxiv.org/abs/1812.02825", "anchor_text": "paper", "paragraph_index": 6}, {"url": "https://github.com/tensorflow/tensor2tensor#walkthrough", "anchor_text": "walkthrough", "paragraph_index": 7}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention Is All You Need", "paragraph_index": 7}, {"url": "http://www.realworldnlpbook.com/blog/building-seq2seq-machine-translation-models-using-allennlp.html", "anchor_text": "Building Seq2Seq Machine Translation Models using AllenNLP", "paragraph_index": 14}, {"url": "https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/neural_machine_translation/transformer", "anchor_text": "English", "paragraph_index": 16}, {"url": "http://paddlepaddle.org/documentation/models/en/1.3/fluid/PaddleNLP/neural_machine_translation/transformer/README_cn.html", "anchor_text": "Chinese", "paragraph_index": 16}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium", "paragraph_index": 22}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view", "paragraph_index": 22}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu", "paragraph_index": 22}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang", "paragraph_index": 22}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu", "paragraph_index": 22}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/", "paragraph_index": 24}], "all_paragraphs": ["Based on your preference for PyTroch or TensorFlow, I recommend using Fairseq or Tensor2Tensor.", "If you are a researcher, Fairseq is flexible enough for customization. But if you are working on some real application and considering deployment, it would be better to choose Tensor2Tensor.", "A sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.", "We can use encoder and decoder easily.", "Transformer model from \u201cAttention Is All You Need\u201d (Vaswani, et al, 2017).", "Library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research.", "You can try solving the problem with different transformer models and hyperparameters as described in the paper:", "Here is a walkthrough to implement the Transformer model from Attention Is All You Need on WMT data.", "An open-source (MIT) neural machine translation system. It is designed to be research friendly to try out new ideas in translation, summary, image-to-text, morphology, and many other domains.", "OpenNMT provides implementations in 2 popular deep learning frameworks:", "Extensible and fast implementation benefiting from PyTorch ease of use.", "Modular and stable implementation relying on the TensorFlow ecosystem.", "An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.", "AllenNLP supports a Transformer encoder, which is implemented as StackedSelfAttentionEncoder", "Recommend reading: Building Seq2Seq Machine Translation Models using AllenNLP", "PaddlePaddle (PArallel Distributed Deep LEarning) is an easy-to-use, efficient, flexible and scalable deep learning platform, which is originally developed by Baidu scientists and engineers for the purpose of applying deep learning to many products at Baidu.", "Implementation of the Transformer model in \u201cAttention is All You Need\u201d: English, Chinese", "Sequence-to-sequence framework with a focus on Neural Machine Translation based on Apache MXNet.", "Lingvo is a framework for building neural networks in Tensorflow, particularly sequence models.", "A widely used backend framework can assure that your model might be used by many people. And if there is some organization behind the frameworks, it is very possible that this framework can exist in a long time. So I collect the related information.", "The reader who might see this article mainly research and engineer. So I focus on the debug and deployment in the pros and cons.", "Based on your preference for PyTroch or TensorFlow, I recommend using Fairseq or Tensor2Tensor. If you are a researcher, Fairseq is flexible enough for customization. But if you are working on some real application and considering deployment, it would be better to choose Tensor2Tensor.", "Check out my other posts on Medium with a categorized view!GitHub: BrambleXuLinkedIn: Xu LiangBlog: BrambleXu", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m an engineer focusing on NLP and Data Science. I write stuff to repay the engineer community. You can find me on linkedin.com/in/xu-liang-99356891/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb7c51737d45&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b7c51737d45--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@bramblexu?source=post_page-----b7c51737d45--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4----b7c51737d45---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/pytorch/fairseq", "anchor_text": "Fairseq"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Vaswani et al. (2017): Attention Is All You Need"}, {"url": "https://github.com/pytorch/fairseq/blob/master/examples/scaling_nmt/README.md", "anchor_text": "Ott et al. (2018): Scaling Neural Machine Translation"}, {"url": "https://github.com/pytorch/fairseq/blob/master/examples/backtranslation/README.md", "anchor_text": "Edunov et al. (2018): Understanding Back-Translation at Scale"}, {"url": "https://github.com/pytorch/fairseq/blob/master/examples/language_model/transformer_lm/README.md", "anchor_text": "Baevski and Auli (2018): Adaptive Input Representations for Neural Language Modeling"}, {"url": "https://github.com/pytorch/fairseq/blob/master/examples/translation_moe/README.md", "anchor_text": "Shen et al. (2019): Mixture Models for Diverse Machine Translation: Tricks of the Trade"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "\u201cAttention Is All You Need\u201d (Vaswani, et al, 2017)"}, {"url": "https://fairseq.readthedocs.io/en/latest/models.html#fairseq.models.transformer.TransformerEncoder", "anchor_text": "TransformerEncoder"}, {"url": "https://fairseq.readthedocs.io/en/latest/models.html#fairseq.models.transformer.TransformerDecoder", "anchor_text": "TransformerDecoder"}, {"url": "https://github.com/tensorflow/tensor2tensor", "anchor_text": "Tensor2Tensor"}, {"url": "https://arxiv.org/abs/1812.02825", "anchor_text": "paper"}, {"url": "https://github.com/tensorflow/tensor2tensor#walkthrough", "anchor_text": "walkthrough"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Attention Is All You Need"}, {"url": "http://opennmt.net/", "anchor_text": "OpenNMT"}, {"url": "http://opennmt.net/OpenNMT-py", "anchor_text": "Documentation"}, {"url": "http://opennmt.net/Models-py", "anchor_text": "Pretrained models"}, {"url": "https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/decoders/transformer.py", "anchor_text": "transformer implementation code"}, {"url": "http://opennmt.net/OpenNMT-tf", "anchor_text": "Documentation"}, {"url": "http://opennmt.net/Models-tf", "anchor_text": "Pretrained models"}, {"url": "https://github.com/allenai/allennlp", "anchor_text": "AllenNLP"}, {"url": "http://www.realworldnlpbook.com/blog/building-seq2seq-machine-translation-models-using-allennlp.html", "anchor_text": "Building Seq2Seq Machine Translation Models using AllenNLP"}, {"url": "https://github.com/PaddlePaddle/Paddle", "anchor_text": "PaddlePaddle"}, {"url": "https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/neural_machine_translation/transformer", "anchor_text": "English"}, {"url": "http://paddlepaddle.org/documentation/models/en/1.3/fluid/PaddleNLP/neural_machine_translation/transformer/README_cn.html", "anchor_text": "Chinese"}, {"url": "https://github.com/awslabs/sockeye", "anchor_text": "Sockeye"}, {"url": "https://arxiv.org/abs/1706.03762", "anchor_text": "Vaswani et al"}, {"url": "https://github.com/awslabs/sockeye/blob/2f44099cd4f488bd8d348d74e9ae85095f72501e/sockeye/transformer.py", "anchor_text": "Implementation"}, {"url": "https://github.com/tensorflow/lingvo", "anchor_text": "Lingvo"}, {"url": "https://medium.com/@bramblexu", "anchor_text": "Medium"}, {"url": "https://bramblexu.com/posts/eb7bd472/", "anchor_text": "a categorized view"}, {"url": "https://github.com/BrambleXu", "anchor_text": "BrambleXu"}, {"url": "https://www.linkedin.com/in/xu-liang-99356891/", "anchor_text": "Xu Liang"}, {"url": "https://bramblexu.com", "anchor_text": "BrambleXu"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b7c51737d45---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----b7c51737d45---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----b7c51737d45---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/framework?source=post_page-----b7c51737d45---------------framework-----------------", "anchor_text": "Framework"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&user=Xu+LIANG&userId=ee86e6752cb4&source=-----b7c51737d45---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&user=Xu+LIANG&userId=ee86e6752cb4&source=-----b7c51737d45---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb7c51737d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b7c51737d45---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b7c51737d45--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b7c51737d45--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b7c51737d45--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b7c51737d45--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b7c51737d45--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@bramblexu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Xu LIANG"}, {"url": "https://medium.com/@bramblexu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1K Followers"}, {"url": "http://linkedin.com/in/xu-liang-99356891/", "anchor_text": "linkedin.com/in/xu-liang-99356891/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fee86e6752cb4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&user=Xu+LIANG&userId=ee86e6752cb4&source=post_page-ee86e6752cb4--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd5c245665a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoose-the-right-transformer-framework-for-you-b7c51737d45&newsletterV3=ee86e6752cb4&newsletterV3Id=d5c245665a2&user=Xu+LIANG&userId=ee86e6752cb4&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}