{"url": "https://towardsdatascience.com/working-with-text-data-from-quality-to-quantity-1e9d8aa773dd", "time": 1682993257.6031842, "path": "towardsdatascience.com/working-with-text-data-from-quality-to-quantity-1e9d8aa773dd/", "webpage": {"metadata": {"title": "Working with Text Data \u2014 From Quality to Quantity | by Sandeep Bhupatiraju | Towards Data Science", "h1": "Working with Text Data \u2014 From Quality to Quantity", "description": "Text processing and analysis is increasingly becoming ubiquitous due to the immense amount of text data available on the internet. From comparatively simple tasks like spell-checking to more ominous\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge", "anchor_text": "Toxic Comment Classification Challenge", "paragraph_index": 4}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle", "paragraph_index": 4}], "all_paragraphs": ["Text processing and analysis is increasingly becoming ubiquitous due to the immense amount of text data available on the internet. From comparatively simple tasks like spell-checking to more ominous tasks like surveilling web activity the fundamental project is to transform linguistic and philosophic particularities like meaning, connotation and context into meaningful mathematical objects, which can then be fed into ML algorithms.", "Lets scratch the surface of this to see basic approaches to this problem. Suppose we have a collection of documents (also called the corpus) to analyze. These documents could be tweets or sentences or even entire books. To convert documents into vectors, a naive attempt is to order all the words in our vocabulary, V, and have a document d represented by a vector v, where the i-th entry in this vector is 1 if d contains the i-th word in our vocabulary, and 0 otherwise. One obvious outcome of this procedure is that all the documents in our corpus are represented by vectors of the same size \u2014 |V|, the size of our vocabulary. The drawback here is that we have lost all linguistic structure, and quite aptly this is referred to as a bag of words model. What we have gained is a feature of the data from every word in our vocabulary. One method to regain some local structure of the documents is to enlarge our vocabulary by adding ngrams. These are just n consecutive words considered as a unit (it is more appropriate to call the units of our vocabulary \u2018tokens\u2019 instead of words) and this change allows us to take into account frequently co-occurring words.", "A slight improvement is to track the number of times the word occurs in the document, so instead of 1 in the formulation above we use the frequency of the word in the document, usually called the term frequency (TF). Now, it is possible that a word which is important appears frequently but it is not necessarily true that words which appear frequently are important; words like \u2018the\u2019 and \u2018of\u2019 rarely give information about the content of the document. To take care of this, instead of using just the TF value of the word we will use a weight which is inversely proportional to the frequency of the word in the corpus \u2014 this is usually called the inverse document frequency (IDF), and usually taken to be", "TF and IDF have opposing tendencies, if the word appears frequently in the document the TF value is large (by definition) and if that word appears very frequently across documents in the corpus the IDF weight is low. This is the formulation of the popular TF-IDF scheme.", "Let\u2019s play around with this concept and apply it to the Wikipedia comment data as part of the Toxic Comment Classification Challenge on Kaggle.", "The data here consists of text comments from Wikipedia, some of which have been tagged by one or more labels from \u2014 \u2018toxic\u2019, \u2018severe_toxic\u2019, \u2018obscene\u2019, \u2018threat\u2019, \u2018insult\u2019 and \u2018identity_hate\u2019. Here our documents are individual comments, and the aim is to learn some patterns and label a new comment with zero or more of the above labels. Lets see the TF-IDF features in action using sklearn in python.", "First, we import our data (two CSV files called test and train) and some python libraries:", "Text data generally requires some cleaning, but it is more important here if we wish to identify comments which contain insulting and toxic language using the above scheme. We shouldn\u2019t consider \u2018F***\u2019 and \u2018F**k\u2019 as different words since this would throw our TF values off. Despite this cautionary remark, lets be content with the following simple function str_clean() and clean the test and train document collections.", "In the above block we have replaced some punctuation by white spaces and deleted numbers and a few punctuation marks. Finally, we have used a particular \u2018stemmer\u2019 from the nltk package to change some words into their \u2018root form\u2019 \u2014 for instance, \u2018beep\u2019, \u2018beeping\u2019, and \u2018beeped\u2019 to \u2018beep\u2019. This allows us to disregard certain forms of a word as distinct words themselves.", "Scikit-Learn has an inbuilt function TfidfVectorizer which takes as input a corpus and outputs the TF-IDF vectors of the documents \u2014 just what we need. All we need to do now is apply the fit_transform method to get the required matrix. This function has multiple parameters which are useful to get better results; lowercase and strip_accents allows to clean up the raw text further, min_df and max_df allows us to restrict which words make it to our vocabulary. Another important way to control our vocabulary is to use the stop_words parameter which allows to drop words like \u2018is\u2019, \u2018at\u2019 and \u2018which\u2019.", "The max_features parameter allows to restrict our vocabulary to the most frequently occurring features; which assumes that the most frequent terms are the most important. Another option we have is to use the sublinear parameter, which returns 1+log(TF) instead of just TF. This can be used in cases where it is reasonable to assume that a token appearing n-times more than another token is not n times more important but roughly by a factor of log(n). Finally, the IDF weights are applied by default.", "Now, equipped with these features we can predict class labels for the comments in the test set. This is a multi-label problem so labels are not mutually exclusive. We will use logit in sklearn to obtain predictions for each of the classes in a loop. We will use 3-fold cross validation to check that the ROCAUC score (the evaluation metric for this challenge) doesn\u2019t fluctuate wildly.", "Although this is a very basic model with many parameter optimizations yet to be performed, it does quite well \u2014 a cross validation score of ~0.97. In a sense whether a comment contains an insult or is toxic or can be deemed as identity hate is actually captured in a large part by the words themselves. We needn\u2019t delve into the grammar of the comment or parse it in more complicated ways to determine which label to give, so the TF-IDF feature extraction is well suited here.", "Analysis here could well benefit from an improved vocabulary. People are exceptionally creative with insults and abuse, and we need better ways of seeing the various forms of the same insult or word. Perhaps a few hours of work with regular expressions can help improve the score greatly.", "Not all words with large IDF scores are discriminating between class labels. We could use some method of feature selection to reduce the dimension of vectors we are working with and use other algorithms for prediction. In a later post we will consider one such method of feature selection called bi-normal scaling (BNS) which adds weights to the term frequencies, similar to IDF weights, but takes into account the actual class labels of the documents to determine which feature matter for the predictions.", "Other features could be appended to out TF-IDF matrix. From a cursory glance at the comments it looks like comments classified as toxic tend to have more punctuation. Meta features like this could be gleaned from the data.", "In any case, to remain sane and functional, don\u2019t wade through too many toxic comments!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1e9d8aa773dd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sandeepbhupatiraju?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sandeepbhupatiraju?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Sandeep Bhupatiraju"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbcf9b1d8e0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&user=Sandeep+Bhupatiraju&userId=bcf9b1d8e0c9&source=post_page-bcf9b1d8e0c9----1e9d8aa773dd---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge", "anchor_text": "Toxic Comment Classification Challenge"}, {"url": "https://www.kaggle.com/", "anchor_text": "Kaggle"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1e9d8aa773dd---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----1e9d8aa773dd---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1e9d8aa773dd---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----1e9d8aa773dd---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&user=Sandeep+Bhupatiraju&userId=bcf9b1d8e0c9&source=-----1e9d8aa773dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&user=Sandeep+Bhupatiraju&userId=bcf9b1d8e0c9&source=-----1e9d8aa773dd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1e9d8aa773dd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1e9d8aa773dd---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1e9d8aa773dd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sandeepbhupatiraju?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sandeepbhupatiraju?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sandeep Bhupatiraju"}, {"url": "https://medium.com/@sandeepbhupatiraju/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "60 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbcf9b1d8e0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&user=Sandeep+Bhupatiraju&userId=bcf9b1d8e0c9&source=post_page-bcf9b1d8e0c9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6476fe608269&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fworking-with-text-data-from-quality-to-quantity-1e9d8aa773dd&newsletterV3=bcf9b1d8e0c9&newsletterV3Id=6476fe608269&user=Sandeep+Bhupatiraju&userId=bcf9b1d8e0c9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}