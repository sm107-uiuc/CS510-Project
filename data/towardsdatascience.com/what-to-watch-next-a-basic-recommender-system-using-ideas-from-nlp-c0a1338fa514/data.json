{"url": "https://towardsdatascience.com/what-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514", "time": 1683015430.000465, "path": "towardsdatascience.com/what-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514/", "webpage": {"metadata": {"title": "What to Watch Next? A Basic Recommender System Using Ideas from NLP. | by Tom Grubb | Towards Data Science", "h1": "What to Watch Next? A Basic Recommender System Using Ideas from NLP.", "description": "Congratulations! You\u2019ve just been hired as Netflix\u2019s new Chief Technical Officer. Your chief task? Increasing engagement and viewing time from your 180 million subscribers. Your team thinks that you\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Netflix_Prize", "anchor_text": "seriously", "paragraph_index": 1}, {"url": "https://www.amazon.science/the-history-of-amazons-recommendation-algorithm", "anchor_text": "Amazon recommending which product you should buy next", "paragraph_index": 1}, {"url": "https://mlconf.com/sessions/personalized-user-recommendations-at-tinder-the-t/", "anchor_text": "Tinder showing you the most compatible singles in your area", "paragraph_index": 1}, {"url": "https://www.blog.google/products/gmail/subject-write-emails-faster-smart-compose-gmail/", "anchor_text": "Google allows you to email faster using Smart Compose", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/heres-how-i-predicted-apple-s-stock-price-using-natural-language-processing-13a578c41b8e", "anchor_text": "how som", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/heres-how-i-predicted-apple-s-stock-price-using-natural-language-processing-13a578c41b8e", "anchor_text": "e financial companies are using social media sentiment to influence their trading algorithms", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Curse_of_dimensionality", "anchor_text": "very slow", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314", "anchor_text": "continuous bag of words", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Softmax_function", "anchor_text": "softmax", "paragraph_index": 14}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "stochastic gradient descent", "paragraph_index": 14}, {"url": "https://aclweb.org/aclwiki/Analogy_(State_of_the_art)", "anchor_text": "one can get computers to solve basic analogies", "paragraph_index": 16}, {"url": "https://www.netflixprize.com/assets/ProgressPrize2007_KorBell.pdf", "anchor_text": "Bell, Koren, and Volinsky\u2019s million dollar prize winning recommendation system", "paragraph_index": 19}, {"url": "https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429", "anchor_text": "Netflix\u2019s own technical blog on this subject", "paragraph_index": 20}, {"url": "http://web.stanford.edu/class/cs224n/", "anchor_text": "check out Chris Manning\u2019s CS 224 class on the topic,", "paragraph_index": 20}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "one of the original articles on the topic", "paragraph_index": 20}, {"url": "https://www.linkedin.com/in/thomas-grubb-70287780/", "anchor_text": "https://www.linkedin.com/in/thomas-grubb-70287780/", "paragraph_index": 22}], "all_paragraphs": ["Congratulations! You\u2019ve just been hired as Netflix\u2019s new Chief Technical Officer. Your chief task? Increasing engagement and viewing time from your 180 million subscribers. Your team thinks that you can achieve this by personalizing the home screen of each user. This raises a natural question: given the past viewing preferences of a given user, which shows should you highlight for them to watch next?", "The crux of this question is in designing a recommender system. Designing such systems is a million dollar industry: seriously. Whether it is Amazon recommending which product you should buy next, or Tinder showing you the most compatible singles in your area, modern companies dedicate significant amounts of time, money, and energy into creating more and more precise recommender systems.", "In this article we will discuss how one can create a basic recommender system using ideas from Natural Language Processing (NLP). This is not an exhaustive discussion of recommender systems in general, and the algorithm we describe is not necessarily the best way creating such a system. But it will be fun anyways!", "First things first: what is NLP? Natural Language Processing is a subfield of linguistics which aims to break down human language into information which is understandable by a computer. It\u2019s how Google allows you to email faster using Smart Compose, or how some financial companies are using social media sentiment to influence their trading algorithms. A key idea from NLP is word2vec: it is a method for embedding words into a high dimensional vector space in such a way that \u201csimilar\u201d words map to \u201csimilar\u201d vectors.", "A first pass at doing this would be the \u201cone-hot\u201d embedding. Let\u2019s take the ~200,000 words in the English language. We can order these words alphabetically. The one-hot embedding of these words would map the ith word in the dictionary to the vector (0,\u2026,0,1,0, \u2026,0) which has a single 1 in the ith entry, and 199,999 0\u2019s everywhere else.", "Unfortunately this embedding is too naive. First, it embeds the human language into a 200,000 dimensional vector space. This makes computations very slow. And remember: at the end of the day, we need to compute with this information for it to be useful! Second, it does not preserve similarity in any sense. For instance: in NLP we would hope that two synonyms, such as \u201chappy\u201d and \u201cjoyful,\u201d map to similar vectors. Just as importantly, antonyms such as \u201chappy\u201d and \u201csad\u201d need to map to dissimilar vectors. We usually measure the similarity of two vectors via their cosine similarity, which is related to the dot product of two vectors. But any two words in the one-hot embedding map to orthogonal vectors, with dot product zero!", "A much better way of embedding words into a vector space relies on the idea that similar words are used in similar contexts. As the old proverb goes, \u201ctell me your friends and I\u2019ll tell you who you are.\u201d", "One way of making this precise is given by the continuous bag of words (CBOW) method, introduced by Google engineers Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean in 2013 (we will use a slight \u201casymmetric\u201d variant, but the ideas are essentially identical). The idea is as follows. Imagine you were only allowed to read five words at a time. So to read the sentence \u201cMy new car is blue and fast,\u201d we would have to read three chunks: \u201cMy new car is blue,\u201d \u201cnew car is blue and,\u201d and \u201ccar is blue and fast.\u201d Now play the following game: given the first four words in a chunk, try to guess the last word.", "Clearly one can see that context clues tell us a lot in this game; for instance, the chunk \u201cMy new car is ___\u201d will certainly not finish with the word \u201chamburger.\u201d More subtly, it also probably doesn\u2019t end with \u201cugly,\u201d \u201cboring,\u201d or \u201cinefficient.\u201d", "This being said, context can only get us so far. The words \u201csleek,\u201d \u201celectric,\u201d or \u201cblue\u201d all make sense to finish the chunk, as well as many other adjectives. We cannot hope to finish this chunk with a unique word, but if we work hard enough we can supply a similar class of words, namely the \u201cwords that describe new cars,\u201d each of which could feasibly end this phrase.", "The CBOW method uses this idea to produce word vectors as follows. Let\u2019s assume that every word in our lexicon is mapped to a 50-dimensional vector. Initially these vectors are completely random. All we know is that the word \u201ccar\u201d is associated a vector v_car = (v_1, \u2026, v_50) of fifty real numbers to it, as well as \u201cnew,\u201d \u201cblue,\u201d and every other word we care about.", "Now assume we have an oracle. A magical, all-knowing machine, which lets you input in the list of random word vectors and a \u201cbag\u201d of four special words (the first four words in a chunk). Based on this information, the oracle outputs a probability distribution on the words in your language. To every word the oracle assigns a number between 0 and 1, telling you how likely it is that this specific word finishes your chunk.", "How can we use this oracle to obtain better word vectors? Take a huge body of English text. Popular choices are collections of news stories spanning multiple decades, or the over 6 million articles found on Wikipedia. We then tell a computer to scan our corpus of text chunk by chunk. For each chunk scanned, we iteratively update each word vector in order to maximize the likelihood of what we have seen thus far.", "What is happening in words? The computer starts by assigning \u201crandom\u201d similarities to each word in the English language. Every time it scans a chunk of text, say \u201cMy new car is blue,\u201d it updates the words in the chunk to \u201cbe more similar\u201d to one another. So from the above selection, it perturbs the \u201cblue\u201d word vector to be more similar to the \u201cMy,\u201d \u201cnew,\u201d \u201ccar,\u201d and \u201cis\u201d word vectors. After doing this for millions and millions and millions of chunks, the computer has shifted around the vectors in our space so that similar words (hopefully!) map to similar vectors.", "From a technical standpoint, this raises many questions. For example: where can we obtain such an oracle? How do we perturb the word vectors in space after each iteration of training? For now I will pass on the nitty gritty, but for those interested I will point to some references. The oracle in use is often taken to be a softmax of the dot product of the word vectors of interest (hence why cosine similarity appears: a higher dot product with the vectors of interest will lead to a larger softmax probability). Certainly other related functions could be used as well. As for the second question, the methodology described above is hinting at a stochastic gradient descent. In other words, perturb the vectors in such a way that we move most rapidly to the global minimum. In practice one usually uses a mini-batch descent to lower effects of noise, but again the implementation details are irrelevant here.", "The Continuous Bag of Words method and it\u2019s cousin, the Skip-Gram model, have had great success in recent years. For one, they map words to vectors of dimension 50, as opposed to the 200,000 dimension beasts from the one-hot encoding. This certainly is within the realms of modern computation. And most importantly, these methods work in practical tasks.", "As an amazing feat, one can get computers to solve basic analogies using these models. For example: if I asked you to fill in the analogy \u201cman is to king as woman is to ___,\u201d one would probably fill in \u201cqueen.\u201d One can also solve this using Natural Language Processing by searching for the word which is simultaneously most similar to \u201cking\u201d and \u201cwoman\u201d and most dissimilar to \u201cman.\u201d In other words, in properly trained models you can subtract the word vector of \u201cman\u201d from the vector of \u201cking,\u201d then add the word vector of \u201cwoman,\u201d and the closest vector to this result will correspond to \u201cqueen.\u201d Isn\u2019t that amazing?!", "Ok, back to our original question. How can one recommend a movie to a Netflix subscriber, based on their viewing history? Perhaps one can guess where we are going, based on the previous discussion. Let\u2019s use a \u201cContinuous Bag of Movies\u201d model. Namely, each movie will be assigned a 50 dimensional vector. We will scan through \u201cwindows\u201d of user viewing data, and at each step we will try to predict the fifth movie from the first four. After each step of training we update the movie vectors to get our \u201csoftmax oracle\u201d to better fit reality. For example: scanning the window \u201cPocahontas, The Jungle Book, Cinderella, Fantasia, Beauty and the Beast\u201d would cause our system to shift the \u201cBeauty and the Beast\u201d vector closer to \u201cPocahontas,\u201d etc.", "After doing this process for millions and millions and millions of data points, our recommendation system has (hopefully!) moved the Disney movies closer together, shifted the comedies away from the horror films, and grouped the Stallone flicks with the Chuck Norris ones. The result? Given a new viewer who has watched a few movies already, one can recommend a different movie (or group of movies) that they may enjoy watching next.", "As mentioned at the start, this is a very crude approximation of a recommender system that any modern company may use. For instance: why would we only care about the previous 4 movies, instead of the entire viewing history of a user? Why not employ user ratings of movies, instead of simply whether or not they watched something? Certainly these are data points which should be incorporated in order to form more and more accurate recommendations. As stated in Bell, Koren, and Volinsky\u2019s million dollar prize winning recommendation system, \u201cPredictive accuracy is substantially improved when blending multiple predictors. Our experience is that most efforts should be concentrated in deriving substantially different approaches, rather than refining a single technique. Consequently, our solution is an ensemble of many methods.\u201d In other words, ideas from NLP alone will not give perfect recommendations. But certainly they provide an interesting place to start!", "Given the nature of this article, surely I must end by providing further recommendations for related reading. If you are interested in recommender systems you might check out Netflix\u2019s own technical blog on this subject. If you are interested in technical aspects of NLP, check out Chris Manning\u2019s CS 224 class on the topic, which is taught yearly at Stanford and made available for public viewing. For the serious readers out there, one can\u2019t go wrong by looking through one of the original articles on the topic.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "4th year PhD student at UC San Diego interested in all things software, machine learning, and data science. https://www.linkedin.com/in/thomas-grubb-70287780/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc0a1338fa514&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tgrubb-41633.medium.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": ""}, {"url": "https://tgrubb-41633.medium.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Tom Grubb"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672f928c6a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&user=Tom+Grubb&userId=672f928c6a47&source=post_page-672f928c6a47----c0a1338fa514---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Netflix_Prize", "anchor_text": "seriously"}, {"url": "https://www.amazon.science/the-history-of-amazons-recommendation-algorithm", "anchor_text": "Amazon recommending which product you should buy next"}, {"url": "https://mlconf.com/sessions/personalized-user-recommendations-at-tinder-the-t/", "anchor_text": "Tinder showing you the most compatible singles in your area"}, {"url": "https://www.blog.google/products/gmail/subject-write-emails-faster-smart-compose-gmail/", "anchor_text": "Google allows you to email faster using Smart Compose"}, {"url": "https://towardsdatascience.com/heres-how-i-predicted-apple-s-stock-price-using-natural-language-processing-13a578c41b8e", "anchor_text": "how som"}, {"url": "https://towardsdatascience.com/heres-how-i-predicted-apple-s-stock-price-using-natural-language-processing-13a578c41b8e", "anchor_text": "e financial companies are using social media sentiment to influence their trading algorithms"}, {"url": "https://en.wikipedia.org/wiki/Word2vec", "anchor_text": "word2vec"}, {"url": "https://en.wikipedia.org/wiki/Curse_of_dimensionality", "anchor_text": "very slow"}, {"url": "https://en.wikipedia.org/wiki/Cosine_similarity", "anchor_text": "cosine similarity"}, {"url": "https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314", "anchor_text": "continuous bag of words"}, {"url": "https://en.wikipedia.org/wiki/Softmax_function", "anchor_text": "softmax"}, {"url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent", "anchor_text": "stochastic gradient descent"}, {"url": "https://aclweb.org/aclwiki/Analogy_(State_of_the_art)", "anchor_text": "one can get computers to solve basic analogies"}, {"url": "https://www.netflixprize.com/assets/ProgressPrize2007_KorBell.pdf", "anchor_text": "Bell, Koren, and Volinsky\u2019s million dollar prize winning recommendation system"}, {"url": "https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429", "anchor_text": "Netflix\u2019s own technical blog on this subject"}, {"url": "http://web.stanford.edu/class/cs224n/", "anchor_text": "check out Chris Manning\u2019s CS 224 class on the topic,"}, {"url": "https://arxiv.org/abs/1301.3781", "anchor_text": "one of the original articles on the topic"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c0a1338fa514---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c0a1338fa514---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/recommendation-system?source=post_page-----c0a1338fa514---------------recommendation_system-----------------", "anchor_text": "Recommendation System"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----c0a1338fa514---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&user=Tom+Grubb&userId=672f928c6a47&source=-----c0a1338fa514---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&user=Tom+Grubb&userId=672f928c6a47&source=-----c0a1338fa514---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc0a1338fa514&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c0a1338fa514---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c0a1338fa514--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c0a1338fa514--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c0a1338fa514--------------------------------", "anchor_text": ""}, {"url": "https://tgrubb-41633.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tgrubb-41633.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tom Grubb"}, {"url": "https://tgrubb-41633.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1 Follower"}, {"url": "https://www.linkedin.com/in/thomas-grubb-70287780/", "anchor_text": "https://www.linkedin.com/in/thomas-grubb-70287780/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672f928c6a47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&user=Tom+Grubb&userId=672f928c6a47&source=post_page-672f928c6a47--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F672f928c6a47%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-to-watch-next-a-basic-recommender-system-using-ideas-from-nlp-c0a1338fa514&user=Tom+Grubb&userId=672f928c6a47&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}