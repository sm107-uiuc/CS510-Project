{"url": "https://towardsdatascience.com/sparse-matrices-in-pytorch-be8ecaccae6", "time": 1682996873.9188302, "path": "towardsdatascience.com/sparse-matrices-in-pytorch-be8ecaccae6/", "webpage": {"metadata": {"title": "Sparse Matrices in Pytorch. This article will analyze runtimes of\u2026 | by Sourya Dey | Towards Data Science", "h1": "Sparse Matrices in Pytorch", "description": "This is part 1 of a series of articles which will analyze execution times of sparse matrices and their dense counterparts in Pytorch. Part 1 deals with CPU execution times, while part 2 extends to\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@souryadey/sparse-matrices-in-pytorch-part-2-gpus-fd9cc0725b71", "anchor_text": "part 2", "paragraph_index": 0}, {"url": "https://pytorch.org/", "anchor_text": "Pytorch", "paragraph_index": 1}, {"url": "https://ieeexplore.ieee.org/document/8689061", "anchor_text": "IEEE", "paragraph_index": 16}, {"url": "https://arxiv.org/abs/1812.01164", "anchor_text": "arXiv", "paragraph_index": 16}, {"url": "https://github.com/souryadey/speed-tests/tree/master/pytorch_sparse/part1_cpu_macbookpro", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://souryadey.github.io/", "anchor_text": "website", "paragraph_index": 20}, {"url": "https://souryadey.github.io/", "anchor_text": "https://souryadey.github.io/", "paragraph_index": 22}], "all_paragraphs": ["This is part 1 of a series of articles which will analyze execution times of sparse matrices and their dense counterparts in Pytorch. Part 1 deals with CPU execution times, while part 2 extends to GPUs. Let me first give a quick introduction to concepts before diving into the meat.", "Pytorch is a library for deep learning written in the Python programming language. Deep learning is a branch of science which is gaining a lot of prominence in recent years due to it powering \u2018smart\u2019 technologies such as self-driving cars, speech recognition, and so on. At the core of deep learning lies a lot of matrix multiplication, which is time-consuming and is the major reason why deep learning systems need significant amounts of computational power to become good. Not surprisingly, a key area of research is simplifying these systems so that they can be quickly deployed. One way to simplify them is by making the matrices sparse, such that most of their elements are 0s and can be ignored when doing math. For example, here\u2019s a sparse matrix which we\u2019ll call S:", "You might be wondering where and how such matrices occur. Matrices are generally used to depict interactions between entities. For example, the rows of S might indicate different people and the columns different places. The numbers indicate how many times each person visited each place in the last week. Having several 0s is explainable in the sense that each person visited only a particular place or two. The density of a sparse matrix is its fraction of non-zero elements, such as 1/3 in S. Now the question is, is there a better way to store sparse matrices to avoid all the 0s?", "There are several sparse formats, the one which Pytorch uses is called the COOrdinate format. It stores the indices, values, size, and number of non-zero elements (nnz) in a sparse matrix. Here\u2019s one way to construct S in Pytorch (outputs are in bold and comments in italics):", "Pytorch has the torch.sparse API for dealing with sparse matrices. This includes some functions identical to regular mathematical functions such as mm for multiplying a sparse matrix with a dense matrix:", "Now we come to the meat of this article. Does using sparse matrices and functions save time in Pytorch? In other words, how good is the torch.sparse API? The answer would depend on a) matrix size, and b) density. The CPU I used to measure runtimes is my mid 2014 Macbook Pro with a 2.2 GHz Intel Core i7 processor and 16 GB of RAM. So, let\u2019s dive in!", "A diagonal matrix is sparse since it contains non-zero elements only along the diagonal. The density will always be 1/n, where n is the number of rows (or columns). Here are my 2 experimental cases:", "All elements are taken from a random normal distribution. You can get this by typing torch.randn. Here are the runtimes for n varying through the powers of 2:", "Computation time for the dense case grows roughly on the order of O(n\u00b3). This shouldn\u2019t come as a surprise since matrix multiplication is O(n\u00b3). Calculating the order of growth for the sparse case is more tricky since we are multiplying 2 matrices with different orders of element growth. Every time n doubles, the number of nonzero elements quadruples for the dense matrix, but doubles for the sparse matrix. This gives an overall computation time on an order between O(n\u00b2) and O(n\u00b3).", "From the right hand figure, we see that initial growth for the sparse case is slow. This is because accessing overheads dominate the actual computation. However, beyond the n=64 (i.e. density \u2264 1.5%) mark is when sparse matrices compute faster than dense.", "Keep in mind that density of sparse diagonal matrices drops as size grows, since density = 1/n. A fairer comparison would be to keep the density constant. The following plots compare the 2 cases again, except now the sparse matrices have their density fixed at 1/8, i.e. 12.5%. So for example, the n=2\u00b9\u00b3 sparse case will have 2\u00b9\u00b3 x 2\u00b9\u00b3/8 = 2\u00b2\u00b3 elements.", "This time, as n doubles, the number of elements for both the sparse and dense matrices quadruples. The COO format needs some time to access elements based on their separate index-value pairs. This is why the sparse matrix computation times grow at greater than O(n\u00b3), leading to sparse computation times being always worse than their dense counterparts.", "Finally, let\u2019s investigate the effect of density on sparse matrix computation times while keeping size fixed at different values. The psuedo code here is:", "I kept n fixed at 4 different cases \u2014 16, 128, 1024 and 8192, and plotted computation time vs density for each case. Density can be obtained by dividing nnz by n\u00b2. I have marked the 2 previous experiments \u2014 diagonal matrix and 12.5% density \u2014 as vertical dashed lines in each plot. The time to multiply 2 dense matrices is the red horizontal dashed line.", "The n=16 case is a bit different since it is small enough for accessing overheads to dominate computation time. For the other 3 cases, computation time doubles as nnz doubles, i.e. O(nnz). This is not surprising since matrix size is the same, so the only growth comes from nnz.", "The major conclusion is that 2 dense matrices always multiply faster than a sparse and dense matrix unless the sparse matrix has very low density. \u2018Very low\u2019 seems to be 1.5% and below.", "So there you have it. Not a lot is to be gained really from using the sparse libraries in their current state in Pytorch, unless you are dealing with very sparse cases (like diagonal matrices of size greater than 100). My research deals with pre-defined sparsity in neural networks (IEEE, arXiv), where the weight matrix is sparse and the input matrix is dense. However, while pre-defined sparsity gives promising results at densities as low as 20%, performance does degrade at densities of 1.5% and below. So unfortunately Pytorch\u2019s sparse libraries aren\u2019t a great fit at the moment. Having said that, the Pytorch sparse API is experimental and is under active development, so here\u2019s hoping that new pull requests improve the performance of sparse libraries.", "The code and images for this article can be found on Github here.", "Tensors in Pytorch can be saved using torch.save(). The size of the resulting file is the size of an individual element multiplied by the number of elements. The dtype of a tensor gives the number of bits in an individual element. For example, a dense 1000x1000 matrix of data type float32 has size (32 bits x 1000 x 1000) = 4 MB. (Recall that 8 bits =1 byte)", "Unfortunately sparse tensors do not support the .save() feature. There are 2 workarounds to save them \u2014 (a) convert to dense and store that, or (b) store the indices(), values(), and size() in separate files and reconstruct the sparse tensor from these. For example, say spmat is a sparse diagonal matrix of size 1000x1000, i.e. it has 1000 non-zero elements. Assume the data type is float32. Using (a), the stored matrix has file size = (32 bits x 1000 x 1000) = 4 MB. Using (b), indices() are integers of data type int64, and there are 2000 indices (1 row and 1 column for each of the 1000 non-zero elements). The 1000 non-zero values() are all float32. The size() is of a special data type called torch.Size , which is a tuple of 2 integers. So the total file size is approximately = (64 x 2000) + (32 x 1000) + (64 x 2) = 20.2 KB. This is way less than 4 MB. More generally, the file size grows as O(n\u00b2) for (a), and O(nnz) for (b). But you need to reconstruct the sparse tensor every time when loading it from (b).", "Sourya Dey is pursuing a PhD at the University of Southern California. His research deals with exploring complexity reduction in deep learning. You can read more about him on his website.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Research Engineer, Galois. Loves football, machine learning and arbitrary thinking. Homepage: https://souryadey.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbe8ecaccae6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@souryadey?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@souryadey?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Sourya Dey"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb98b8c8fbd76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&user=Sourya+Dey&userId=b98b8c8fbd76&source=post_page-b98b8c8fbd76----be8ecaccae6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/predefined-sparsity", "anchor_text": "Predefined sparsity"}, {"url": "https://medium.com/@souryadey/sparse-matrices-in-pytorch-part-2-gpus-fd9cc0725b71", "anchor_text": "part 2"}, {"url": "https://pytorch.org/", "anchor_text": "Pytorch"}, {"url": "https://ieeexplore.ieee.org/document/8689061", "anchor_text": "IEEE"}, {"url": "https://arxiv.org/abs/1812.01164", "anchor_text": "arXiv"}, {"url": "https://github.com/souryadey/speed-tests/tree/master/pytorch_sparse/part1_cpu_macbookpro", "anchor_text": "here"}, {"url": "https://souryadey.github.io/", "anchor_text": "website"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----be8ecaccae6---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/sparse?source=post_page-----be8ecaccae6---------------sparse-----------------", "anchor_text": "Sparse"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----be8ecaccae6---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/runtime?source=post_page-----be8ecaccae6---------------runtime-----------------", "anchor_text": "Runtime"}, {"url": "https://medium.com/tag/predefined-sparsity?source=post_page-----be8ecaccae6---------------predefined_sparsity-----------------", "anchor_text": "Predefined Sparsity"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&user=Sourya+Dey&userId=b98b8c8fbd76&source=-----be8ecaccae6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&user=Sourya+Dey&userId=b98b8c8fbd76&source=-----be8ecaccae6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbe8ecaccae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----be8ecaccae6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----be8ecaccae6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----be8ecaccae6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----be8ecaccae6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@souryadey?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@souryadey?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sourya Dey"}, {"url": "https://medium.com/@souryadey/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "96 Followers"}, {"url": "https://souryadey.github.io/", "anchor_text": "https://souryadey.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb98b8c8fbd76&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&user=Sourya+Dey&userId=b98b8c8fbd76&source=post_page-b98b8c8fbd76--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fb98b8c8fbd76%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsparse-matrices-in-pytorch-be8ecaccae6&user=Sourya+Dey&userId=b98b8c8fbd76&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}