{"url": "https://towardsdatascience.com/logistic-regression-derived-from-intuition-d1211fc09b10", "time": 1682997258.385121, "path": "towardsdatascience.com/logistic-regression-derived-from-intuition-d1211fc09b10/", "webpage": {"metadata": {"title": "Logistic Regression- Derived from Intuition [Logistic Trilogy, part 1] | by Soumalya Nandi | Towards Data Science", "h1": "Logistic Regression- Derived from Intuition [Logistic Trilogy, part 1]", "description": "Logistic regression being very useful nowadays, lets understand the theory behind it."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["So currently two persons are interacting with each other. One is me, the writer and the other one is you, the reader. And at the end of the interaction, you will derive logistic regression from linear regression YOURSELF. Just one condition from my side, we will derive the regression setup having only one independent variable X.", "Let us start with Simple Linear Regression first. We have one dependent variable Y and only one independent variable X. Hence the Model looks as Y=a+bX+e where a and b are unknown coefficients and e is the error term. You know all about the assumptions of the model and the consequences of violation of any of those assumptions. The problem basically boils down to estimation of the unknown parameters a and b. There are two methods of doing so. Least square method and Maximum likelihood method. We are restricting ourselves to MLE only.", "Because after estimation, for testing purposes you need a distributional assumption. For least square estimation procedure you don\u2019t need any kind of probability distribution associated with it. But for MLE we need the assumption, that the error terms independently follow Normal distribution with mean 0 and a constant variance.", "Hence we now have the model to be Y=a+bX+e where Y follows normal distribution with mean a+bX and a having a constant variance. What does this lead to? It means that Y can take any value on the real line. My question is what if this assumption is violated? What if Y can take few restricted values only? What if Y can take only two values? Say it denotes the absence or presence of any event. How to tackle that? Any suggestions?", "One thing is for sure, the assumption of normality is invalid here. Because if error follows normal distribution then Y also follows normal distribution but since Y is discrete here, the assumption totally fails.", "Exactly, very much true. We have deviated from linear regression a little bit. We have a very disturbing equation at our hand now. Y=a+bX+e where the r.h.s can take any real value but the l.h.s can take only 0 or 1 (encoding presence as 1 and absence as 0). What to do?", "As a solution, let us change the equation a bit. What is the most logical part to change? Y or X or e? Let me give a hint. Suppose you have two quantities, one is stochastic and the other is non stochastic. Which one do you think is more controllable?", "Of course the non stochastic quantity. The stochastic quantity is being controlled by some natural law. We don\u2019t have much control to it.", "Very good answer reader. Then which one to change among Y,X and e? The non stochastic one, i.e. X. Well for our case it is actually a+bX. I say lets find a function f(.) such that f(a+bX) lies between 0 and 1 and choose a threshold c based on the data such that if f(a+bX)<c then Y=0 and if f(a+bX)\u2265c then Y=1. Are you convinced with this proposal?", "No, if at the end we need to choose a threshold then what is the need of converting a+bX into something that is bounded by 0 and 1. Can we not do something like if a+bX<d then Y=0 and if a+bX>d then Y=1?", "Very good question. Focus on simple linear regression again. Say after estimation you have the regression equation as Y=a+bX. For X=x0 you will get a value y0=a+b*x0. Every time you put X=x0 in the equation every time you will get Y=y0. But in reality if you have n observations having X value as x0, do you think Y would be y0 for each and every of those observations? Say Y be body weight and X be age in years. Do you think every 24 years old person has the same weight? Of course not.", "Here is the trick. Y follows normal with mean a+bX, Y is stochastic here. The Y values of n observations with X=x0 is nothing but a random sample of size n from a normal distribution with mean a+b*x0. What is the expected value of sample mean then? It is indeed a+b*x0=y0.", "Remember!!!!! In linear regression we don\u2019t predict Y, we estimate the expected value of Y i.e, E[Y]. Y is stochastic. For same X=x0 it should give different values but E[Y] would be fixed as it is non stochastic.", "Let us come back to our case now. Y can take only two values 0 and 1. What is the best probability distribution to describe such random variable?", "For logistic regression we choose the function to be sigmoid function. My question is there are plenty of functions whose range is (0,1), then why specifically sigmoid? Lets find out together, and for the time being consider a=0 and b=1 just for simplicity.", "There are plenty of such functions, say f(x)=|sin(x)| or f(x)=|x|/(|x|+1). Why are these not used as transformation functions for our case?", "Yes, indeed they lie between 0 and 1 but since later we need to maximize the likelihood function through optimization techniques, hence it is better to restrict to everywhere differentiable function. So I put one restriction on the functions, they should be differentiable everywhere and hence continuous. Now give me such functions.", "Yes. these are everywhere differentiable. But have you ever thought why logistic regression is called Generalized linear model and not non linear regression model? Y and X are linearly related means if X increases(decreases) by some amount then Y also increases(decreases) or decreases(increases). i.e, Y and X are directly proportional or inversely proportional and since we are dealing with generalized \u201clinear\u201d model that relation must be captured if not fully at least in some sense into the model.", "In the above functions this property is violated. In the second function if X increases from 4 to 5 then f(x) increases and also if X decreases from -4 to -5 then also f(x) increases. For sin function also it is trivial.", "So I am putting another restriction. Along with everywhere differentiable,continuous; the function should be monotonically increasing. (since we are actually working with a+bX, for decreasing function we will change sign of b accordingly).", "Can you give me a function which is continuous everywhere, differentiable everywhere and monotonically increasing, range is (0,1) and domain is the whole real line? Statistics has provided a bunch of such functions and they are very famous and useful actually. Striking anything?", "Cumulative Distribution Functions (CDFs) of continuous random variables", "Bravo!! Name some continuous random variables which can take any value on the whole real line? And lets focus on standard distributions i.e, with mean 0 and variance 1.", "Standard Normal distribution, Standard Logistic distribution.", "Nothing to mention for standard normal distribution, the pdf and cdf of standard logistic distribution are", "Lets look into another distribution, Generalized Gumbel Distribution for minimum, it is an extreme value distribution. Its pdf and cdf are as follows,", "Lets tackle one by one. For standard normal distribution we have our model as,", "Is it not the Probit model?", "For standard logistic distribution we get,", "Yes, its our very familiar logit model. (Hence the name logistic as it is derived from logistic distribution)", "And finally for the generalized Gumbel distribution for minimum,", "In all the above cases right hand side is linear in parameter. Hence Generalized \u201clinear\u201d model.", "Now for estimation purpose, first thing we need is a dataset (Y,X) of size=n. With the assumption that Yi~Bernoulli(\u03a0i) independently.", "replacing the same in the likelihood equation we can get the likelihood function L(a,b) and needs to maximize it through some optimization techniques.", "Congratulations!!!!! You have derived logistic regression from pure intuition.(and guess what, you have not used the term \u201clink function or inverse link function\u201d at all) Was it that hard? Hope you enjoyed the logical journey.", "If you are not convinced or have any question or doubt feel free to ask in the comment section. or contact me on my LinkedIn profile.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Associate Data Scientist @UHG, Masters in Statistics @IIT. Creative writer, Love to tell stories about Data Science."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd1211fc09b10&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jnandi17?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jnandi17?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Soumalya Nandi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d425612a5ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&user=Soumalya+Nandi&userId=5d425612a5ef&source=post_page-5d425612a5ef----d1211fc09b10---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.linkedin.com/in/soumalya-nandi-95176569/", "anchor_text": "SOUMALYA NANDI - Associate Data Scientist - UnitedHealth Group | LinkedInView SOUMALYA NANDI'S profile on LinkedIn, the world's largest professional community. SOUMALYA has 4 jobs listed on\u2026www.linkedin.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d1211fc09b10---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----d1211fc09b10---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----d1211fc09b10---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d1211fc09b10---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/classification?source=post_page-----d1211fc09b10---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&user=Soumalya+Nandi&userId=5d425612a5ef&source=-----d1211fc09b10---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&user=Soumalya+Nandi&userId=5d425612a5ef&source=-----d1211fc09b10---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd1211fc09b10&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d1211fc09b10---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d1211fc09b10--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d1211fc09b10--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d1211fc09b10--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jnandi17?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jnandi17?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Soumalya Nandi"}, {"url": "https://medium.com/@jnandi17/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "46 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5d425612a5ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&user=Soumalya+Nandi&userId=5d425612a5ef&source=post_page-5d425612a5ef--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5d425612a5ef%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-derived-from-intuition-d1211fc09b10&user=Soumalya+Nandi&userId=5d425612a5ef&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}