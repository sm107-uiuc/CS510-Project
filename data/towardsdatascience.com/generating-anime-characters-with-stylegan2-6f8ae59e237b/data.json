{"url": "https://towardsdatascience.com/generating-anime-characters-with-stylegan2-6f8ae59e237b", "time": 1683013894.462368, "path": "towardsdatascience.com/generating-anime-characters-with-stylegan2-6f8ae59e237b/", "webpage": {"metadata": {"title": "Generating Anime Characters with StyleGAN2 | by Fathy Rashad | Towards Data Science", "h1": "Generating Anime Characters with StyleGAN2", "description": "Generative Adversarial Network (GAN) is a generative model that is able to generate new content. The topic has become really popular in the machine learning community due to its interesting\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1812.04948", "anchor_text": "A Style-Based Architecture for GANs", "paragraph_index": 3}, {"url": "https://arxiv.org/abs/1710.10196", "anchor_text": "Progressive GAN", "paragraph_index": 4}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "NVIDIA's official paper", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "official paper", "paragraph_index": 12}, {"url": "https://medium.com/@jonathan_hui/gan-stylegan-stylegan2-479bdf256299", "anchor_text": "this article", "paragraph_index": 12}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431", "anchor_text": "this article", "paragraph_index": 12}, {"url": "https://www.gwern.net/Faces#stylegan-2", "anchor_text": "Gwern", "paragraph_index": 14}, {"url": "https://colab.research.google.com/drive/15EGSIv_jZxDvYWODNwEG-I4pV9i3RwlN?usp=sharing", "anchor_text": "Colab notebook", "paragraph_index": 16}, {"url": "https://github.com/NVlabs/stylegan2.git", "anchor_text": "https://github.com/NVlabs/stylegan2.git", "paragraph_index": 18}, {"url": "https://github.com/justinpinkney/awesome-pretrained-stylegan2", "anchor_text": "GitHub repo", "paragraph_index": 33}, {"url": "https://github.com/halcy/AnimeFaceNotebooks", "anchor_text": "Snow Halcy repo", "paragraph_index": 34}, {"url": "https://colab.research.google.com/github/halcy/AnimeFaceNotebooks/blob/master/colab/Stylegan2_Playground.ipynb", "anchor_text": "upyter notebook", "paragraph_index": 34}, {"url": "https://www.gwern.net/About", "anchor_text": "Gwern Branwen", "paragraph_index": 35}, {"url": "https://www.gwern.net/Faces#stylegan-2", "anchor_text": "extensive articles", "paragraph_index": 35}, {"url": "https://www.thiswaifudoesnotexist.net/", "anchor_text": "ThisWaifuDoesNotExists", "paragraph_index": 35}, {"url": "https://mfrashad.com", "anchor_text": "https://mfrashad.com", "paragraph_index": 39}, {"url": "https://medium.com/subscribe/@mfrashad", "anchor_text": "https://medium.com/subscribe/@mfrashad", "paragraph_index": 39}], "all_paragraphs": ["Generative Adversarial Network (GAN) is a generative model that is able to generate new content. The topic has become really popular in the machine learning community due to its interesting applications such as generating synthetic training data, creating arts, style-transfer, image-to-image translation, etc.", "GAN consisted of 2 networks, the generator, and the discriminator. The generator will try to generate fake samples and fool the discriminator into believing it to be real samples. The discriminator will try to detect the generated samples from both the real and fake samples. This interesting adversarial concept was introduced by Ian Goodfellow in 2014. There are already a lot of resources available to learn GAN, hence I will not explain GAN to avoid redundancy.", "I recommend reading this beautiful article by Joseph Rocca for understanding GAN.", "The StyleGAN paper, \u201cA Style-Based Architecture for GANs\u201d, was published by NVIDIA in 2018. The paper proposed a new generator architecture for GAN that allows them to control different levels of details of the generated samples from the coarse details (eg. head shape) to the finer details (eg. eye-color).", "StyleGAN also incorporates the idea from Progressive GAN, where the networks are trained on lower resolution initially (4x4), then bigger layers are gradually added after it\u2019s stabilized. By doing this, the training time becomes a lot faster and the training is a lot more stable.", "StyleGAN improves it further by adding a mapping network that encodes the input vectors into an intermediate latent space, w, which then will have separate values be used to control the different levels of details.", "Why add a mapping network? One of the issues of GAN is its entangled latent representations (the input vectors, z). For example, let\u2019s say we have 2 dimensions latent code which represents the size of the face and the size of the eyes. In this case, the size of the face is highly entangled with the size of the eyes (bigger eyes would mean bigger face as well). On the other hand, we can simplify this by storing the ratio of the face and the eyes instead which would make our model be simpler as unentangled representations are easier for the model to interpret.", "With entangled representations, the data distribution may not necessarily follow the normal distribution where we want to sample the input vectors z from. For example, the data distribution would have a missing corner like this which represents the region where the ratio of the eyes and the face becomes unrealistic.", "If we sample the z from the normal distribution, our model will try to also generate the missing region where the ratio is unrealistic and because there Is no training data that have this trait, the generator will generate the image poorly. Therefore, the mapping network aims to disentangle the latent representations and warps the latent space so it is able to be sampled from the normal distribution.", "Additionally, Having separate input vectors, w, on each level allows the generator to control the different levels of visual features. The first few layers (4x4, 8x8) will control a higher level (coarser) of details such as the head shape, pose, and hairstyle. The last few layers (512x512, 1024x1024) will control the finer level of details such as the hair and eye color.", "For full details on StyleGAN architecture, I recommend you to read NVIDIA's official paper on their implementation. Here is the illustration of the full architecture from the paper itself.", "StyleGAN also allows you to control the stochastic variation in different levels of details by giving noise at the respective layer. Stochastic variations are minor randomness on the image that does not change our perception or the identity of the image such as differently combed hair, different hair placement and etc. You can see the effect of variations in the animated images below.", "StyleGAN also made several other improvements that I will not cover in these articles such as the AdaIN normalization and other regularization. You can read the official paper, this article by Jonathan Hui, or this article by Rani Horev for further details instead.", "When there is an underrepresented data in the training samples, the generator may not be able to learn the sample and generate it poorly. To avoid this, StyleGAN uses a \u201ctruncation trick\u201d by truncating the intermediate latent vector w forcing it to be close to average.", "The \ud835\udebf (psi) is the threshold that is used to truncate and resample the latent vectors that are above the threshold. Hence, with higher \ud835\udebf, you can get higher diversity on the generated images but it also has a higher chance of generating weird or broken faces. For this network \ud835\udebf value of 0.5 to 0.7 seems to give a good image with adequate diversity according to Gwern. Though, feel free to experiment with the threshold value.", "I will be using the pre-trained Anime StyleGAN2 by Aaron Gokaslan so that we can load the model straight away and generate the anime faces. So, open your Jupyter notebook or Google Colab, and let\u2019s start coding.", "Note: You can refer to my Colab notebook if you are stuck", "So first of all, we should clone the styleGAN repo.", "If you are using Google Colab, you can prefix the command with \u2018!\u2019 to run it as a command: !git clone https://github.com/NVlabs/stylegan2.git", "Next, we would need to download the pre-trained weights and load the model. Make sure you are running with GPU runtime when you are using Google Colab as the model is configured to use GPU.", "Now, we need to generate random vectors, z, to be used as the input fo our generator. Let\u2019s create a function to generate the latent code, z, from a given seed.", "Then, we can create a function that takes the generated random vectors z and generate the images.", "Now, we can try generating a few images and see the results.", "The function will return an array of PIL.Image. In Google Colab, you can straight away show the image by printing the variable. Here is the first generated image.", "Let\u2019s show it in a grid of images, so we can see multiple images at one time.", "And then we can show the generated images in a 3x3 grid.", "One of the nice things about GAN is that GAN has a smooth and continuous latent space unlike VAE (Variational Auto Encoder) where it has gaps. Hence, when you take two points in the latent space which will generate two different faces, you can create a transition or interpolation of the two faces by taking a linear path between the two points.", "Let\u2019s implement this in code and create a function to interpolate between two values of the z vectors.", "Let\u2019s see the interpolation results. You can see that the first image gradually transitioned to the second image.", "Now that we\u2019ve done interpolation. We can finally try to make the interpolation animation in the thumbnail above. We will use the moviepy library to create the video or GIF file.", "When you run the code, it will generate a GIF animation of the interpolation. You can also modify the duration, grid size, or the fps using the variables at the top.", "If you made it this far, congratulations! You have generated anime faces using StyleGAN2 and learned the basics of GAN and StyleGAN architecture.", "Now that we have finished, what else can you do and further improve on? Here are a few things that you can do.", "Other DatasetsObviously, StyleGAN is not limited to anime dataset only, there are many available pre-trained datasets that you can play around such as images of real faces, cats, art, and paintings. Check out this GitHub repo for available pre-trained weights. On the other hand, you can also train the StyleGAN with your own chosen dataset.", "Conditional GANCurrently, we cannot really control the features that we want to generate such as hair color, eye color, hairstyle, and accessories. Conditional GAN allows you to give a label alongside the input vector, z, and hence conditioning the generated image to what we want. Alternatively, you can try making sense of the latent space either by regression or manually. If you want to go to this direction, Snow Halcy repo maybe be able to help you, as he done it and even made it interactive in this Jupyter notebook.", "I\u2019d like to thanks Gwern Branwen for his extensive articles and explanation on generating anime faces with StyleGAN which I strongly referred to in my article. I fully recommend you to visit his websites as his writings are a trove of knowledge. Additionally, check out ThisWaifuDoesNotExists website which hosts the StyleGAN model for generating anime faces and a GPT model to generate anime plot.", "If you enjoy my writing, feel free to check out my other articles!", "[1] Karras, T., Laine, S., & Aila, T. (2019). A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4401\u20134410).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance ML engineer specializing in generative arts. Available for hire. Visit me at https://mfrashad.com Subscribe: https://medium.com/subscribe/@mfrashad"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6f8ae59e237b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mfrashad?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mfrashad?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Fathy Rashad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff0a26b89e21a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&user=Fathy+Rashad&userId=f0a26b89e21a&source=post_page-f0a26b89e21a----6f8ae59e237b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29", "anchor_text": "Understanding Generative Adversarial Networks (GANs)Building, step by step, the reasoning that leads to GANs.towardsdatascience.com"}, {"url": "https://arxiv.org/abs/1812.04948", "anchor_text": "A Style-Based Architecture for GANs"}, {"url": "https://arxiv.org/abs/1710.10196", "anchor_text": "Progressive GAN"}, {"url": "https://towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2", "anchor_text": "[Source: Sarah Wolf]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "[Source: Paper]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "[Source: Paper]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "[Source: Paper]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "[Source: Paper]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "NVIDIA's official paper"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "[Source: A Style-Based Architecture for GANs Paper]"}, {"url": "https://www.youtube.com/watch?time_continue=241&v=kSLJriaOumA&feature=emb_title", "anchor_text": "[Source: Paper]"}, {"url": "https://www.youtube.com/watch?time_continue=241&v=kSLJriaOumA&feature=emb_title", "anchor_text": "[Source: Paper]"}, {"url": "https://arxiv.org/pdf/1812.04948.pdf", "anchor_text": "official paper"}, {"url": "https://medium.com/@jonathan_hui/gan-stylegan-stylegan2-479bdf256299", "anchor_text": "this article"}, {"url": "https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431", "anchor_text": "this article"}, {"url": "https://www.gwern.net/Faces#stylegan-2", "anchor_text": "Gwern"}, {"url": "https://colab.research.google.com/drive/15EGSIv_jZxDvYWODNwEG-I4pV9i3RwlN?usp=sharing", "anchor_text": "Colab notebook"}, {"url": "https://github.com/NVlabs/stylegan2.git", "anchor_text": "https://github.com/NVlabs/stylegan2.git"}, {"url": "https://github.com/ak9250/stylegan-art/blob/master/styleganportraits.ipynb", "anchor_text": "this notebook"}, {"url": "https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73", "anchor_text": "[Source: Joseph Rocca]"}, {"url": "https://github.com/justinpinkney/awesome-pretrained-stylegan2", "anchor_text": "GitHub repo"}, {"url": "https://github.com/halcy/AnimeFaceNotebooks", "anchor_text": "Snow Halcy repo"}, {"url": "https://colab.research.google.com/github/halcy/AnimeFaceNotebooks/blob/master/colab/Stylegan2_Playground.ipynb", "anchor_text": "upyter notebook"}, {"url": "https://www.gwern.net/About", "anchor_text": "Gwern Branwen"}, {"url": "https://www.gwern.net/Faces#stylegan-2", "anchor_text": "extensive articles"}, {"url": "https://www.thiswaifudoesnotexist.net/", "anchor_text": "ThisWaifuDoesNotExists"}, {"url": "https://towardsdatascience.com/animating-yourself-as-a-disney-character-with-ai-78af337d4081", "anchor_text": "Animating Yourself as a Disney Character with AISneak peek into the future of digital artstowardsdatascience.com"}, {"url": "https://towardsdatascience.com/generating-novel-content-without-dataset-544107da4cc8", "anchor_text": "Generating Novel Content without DatasetRewriting the rules in GAN: Copy & paste features contextuallytowardsdatascience.com"}, {"url": "https://www.gwern.net/Faces#stylegan-2", "anchor_text": "ttps://www.gwern.net/Faces#stylegan-2"}, {"url": "https://towardsdatascience.com/how-to-train-stylegan-to-generate-realistic-faces-d4afca48e705", "anchor_text": "https://towardsdatascience.com/how-to-train-stylegan-to-generate-realistic-faces-d4afca48e705"}, {"url": "https://towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2", "anchor_text": "https://towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6f8ae59e237b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6f8ae59e237b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6f8ae59e237b---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/art?source=post_page-----6f8ae59e237b---------------art-----------------", "anchor_text": "Art"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----6f8ae59e237b---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&user=Fathy+Rashad&userId=f0a26b89e21a&source=-----6f8ae59e237b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&user=Fathy+Rashad&userId=f0a26b89e21a&source=-----6f8ae59e237b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6f8ae59e237b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6f8ae59e237b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6f8ae59e237b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mfrashad?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mfrashad?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fathy Rashad"}, {"url": "https://medium.com/@mfrashad/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "664 Followers"}, {"url": "https://mfrashad.com", "anchor_text": "https://mfrashad.com"}, {"url": "https://medium.com/subscribe/@mfrashad", "anchor_text": "https://medium.com/subscribe/@mfrashad"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff0a26b89e21a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&user=Fathy+Rashad&userId=f0a26b89e21a&source=post_page-f0a26b89e21a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1d7ec65762ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-anime-characters-with-stylegan2-6f8ae59e237b&newsletterV3=f0a26b89e21a&newsletterV3Id=1d7ec65762ff&user=Fathy+Rashad&userId=f0a26b89e21a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}