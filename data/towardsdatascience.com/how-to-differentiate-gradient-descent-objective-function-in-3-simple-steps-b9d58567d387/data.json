{"url": "https://towardsdatascience.com/how-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387", "time": 1683012454.538377, "path": "towardsdatascience.com/how-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387/", "webpage": {"metadata": {"title": "How to Differentiate Gradient Descent Objective Function in 3 simple steps | by \u0141ukasz Gebel | Towards Data Science", "h1": "How to Differentiate Gradient Descent Objective Function in 3 simple steps", "description": "Nowadays we can learn about domains that were usually reserved for academic communities. From Artificial Intelligence to Quantum Physics, we can browse an enormous amount of information available on\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Nowadays we can learn about domains that were usually reserved for academic communities. From Artificial Intelligence to Quantum Physics, we can browse an enormous amount of information available on the Internet and benefit from it.", "However, the availability of information has some drawbacks. We need to be aware of a huge amount of unverified sources, full of factual errors (it\u2019s a topic for the whole different discussion). What\u2019s more, we can get used to getting answers with ease by googling it. As a result, we often take them for granted and use them without a better understanding.", "The process of discovering things on our own is an important part of learning. Let\u2019s take part in such an experiment and calculate derivatives behind Gradient Descent algorithm for a Linear Regression.", "Linear Regression is a statistical method that can be used to model the relationship between variables [1, 2]. It\u2019s described by a line equation:", "We have two parameters \u0398\u2080 and \u0398\u2081 and a variable x. Having data points we can find optimal parameters to fit the line to our data set.", "Ok, now the Gradient Descent [2, 3]. It is an iterative algorithm that is widely used in Machine Learning (in many different flavors). We can use it to automatically find optimal parameters of our line.", "To do this, we need to optimize an objective function defined by this formula:", "In this function, we iterate over each point (x\u02b2, y\u02b2) from our data set. Then we calculate the value of a function f for x\u02b2, and current theta parameters (\u0398\u2080, \u0398\u2081). We take a result and subtract y\u02b2. Finally, we square it and add it to the sum.", "Then in the Gradient Descent formula (which updates \u0398\u2080 and \u0398\u2081 in each iteration), we can find these mysterious derivatives on the right side of equations:", "These are derivatives of the objective function Q(\u0398). There are two parameters, so we need to calculate two derivatives, one for each \u0398. Let\u2019s move on and calculate them in 3 simple steps.", "Our objective function is a composite function. We can think of it as it has an \u201couter\u201d function and an \u201cinner\u201d function [1]. To calculate a derivative of a composite function we\u2019ll follow a chain rule:", "In our case, the \u201couter\u201d part is about raising everything inside the brackets (\u201cinner function\u201d) to the second power. According to the rule we need to multiply the \u201couter function\u201d derivative by the derivative of an \u201cinner function\u201d. It looks like this:", "The next step is calculating a derivative of a power function [1]. Let\u2019s recall a derivative power rule formula:", "Our \u201couter function\u201d is simply an expression raised to the second power. So we put 2 before the whole formula and leave the rest as it (2 -1 = 1, and expression raised to the first power is simply that expression).", "After the second step we have:", "We still need to calculate a derivative of an \u201cinner function\u201d (right side of the formula). Let\u2019s move to the third step.", "The last rule is the simplest one. It is used to determine a derivative of a constant:", "As a constant means, no changes, derivative of a constant is equal to zero [1]. For example f\u2019(4) = 0.", "Having all three rules in mind let\u2019s break the \u201cinner function\u201d down:", "The tricky part of our Gradient Descent objective function is that x is not a variable. x and y are constants that come from data set points. As we look for optimal parameters of our line, \u0398\u2080 and \u0398\u2081 are variables. That\u2019s why we calculate two derivatives, one with respect to \u0398\u2080 and one with respect to \u0398\u2081.", "Let\u2019s start by calculating the derivative with respect to \u0398\u2080. It means that \u0398\u2081 will be treated as a constant.", "You can see that constant parts were set to zero. What happened to \u0398\u2080? As it\u2019s a variable raised to the first power (a\u00b9=a), we applied the power rule. It resulted in \u0398\u2080 raised to the power of zero. When we raise a number to the power of zero, it\u2019s equal to 1 (a\u2070=1). And that\u2019s it! Our derivative with respect to \u0398\u2080 is equal to 1.", "Finally, we have the whole derivative with respect to \u0398\u2080:", "Now it\u2019s time to calculate a derivative with respect to \u0398\u2081. It means that we treat \u0398\u2080 as a constant.", "By analogy to the previous example, \u0398\u2081 was treated as a variable raised to the first power. Then we applied a power rule which reduced \u0398\u2081 to 1. However \u0398\u2081 is multiplied by x, so we end up with derivative equal to x.", "The final form of the derivative with respect to \u0398\u2081 looks like this:", "We calculated the derivatives needed by the Gradient Descent algorithm! Let\u2019s put them where they belong:", "By doing this exercise we get a deeper understanding of formula origins. We don\u2019t take it as a magic incantation we found in the old book, but instead, we actively go through the process of analyzing it. We break down the method to smaller pieces and we realize that we can finish calculations by ourselves and put it all together.", "From time to time grab a pen and paper and solve a problem. You can find an equation or method you already successfully use and try to gain this deeper insight by decomposing it. It will give you a lot of satisfaction and spark your creativity.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer by day, Machine Learning enthusiast at night. Tech conferences speaker. I love to learn, share, read, play football \u2014 in no particular order."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb9d58567d387&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b9d58567d387--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@luk.gebel?source=post_page-----b9d58567d387--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luk.gebel?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "\u0141ukasz Gebel"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feca79ff2b5d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&user=%C5%81ukasz+Gebel&userId=eca79ff2b5d0&source=post_page-eca79ff2b5d0----b9d58567d387---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@thisisengineering?utm_source=medium&utm_medium=referral", "anchor_text": "ThisisEngineering RAEng"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b9d58567d387---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----b9d58567d387---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b9d58567d387---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----b9d58567d387---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/education?source=post_page-----b9d58567d387---------------education-----------------", "anchor_text": "Education"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&user=%C5%81ukasz+Gebel&userId=eca79ff2b5d0&source=-----b9d58567d387---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&user=%C5%81ukasz+Gebel&userId=eca79ff2b5d0&source=-----b9d58567d387---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb9d58567d387&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b9d58567d387---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b9d58567d387--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b9d58567d387--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b9d58567d387--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b9d58567d387--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b9d58567d387--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luk.gebel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@luk.gebel?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "\u0141ukasz Gebel"}, {"url": "https://medium.com/@luk.gebel/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "140 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feca79ff2b5d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&user=%C5%81ukasz+Gebel&userId=eca79ff2b5d0&source=post_page-eca79ff2b5d0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fc58b6b6c505d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-differentiate-gradient-descent-objective-function-in-3-simple-steps-b9d58567d387&newsletterV3=eca79ff2b5d0&newsletterV3Id=c58b6b6c505d&user=%C5%81ukasz+Gebel&userId=eca79ff2b5d0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}