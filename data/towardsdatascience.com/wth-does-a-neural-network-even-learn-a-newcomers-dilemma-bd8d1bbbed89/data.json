{"url": "https://towardsdatascience.com/wth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89", "time": 1682988349.756544, "path": "towardsdatascience.com/wth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89/", "webpage": {"metadata": {"title": "\u201cWTH does a neural network even learn?\u201d \u2014 A newcomer\u2019s dilemma | by Nityesh Agarwal | Towards Data Science", "h1": "\u201cWTH does a neural network even learn?\u201d \u2014 A newcomer\u2019s dilemma", "description": "I think that the confusion was mostly because of the way in which most of the tutorials and beginner level books approach the subject."}, "outgoing_paragraph_urls": [{"url": "http://neuralnetworksanddeeplearning.com/about.html", "anchor_text": "Neural Networks and Deep Learning", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Multilayer_perceptron", "anchor_text": "MLPs", "paragraph_index": 20}, {"url": "https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw", "anchor_text": "3blue1brown", "paragraph_index": 22}, {"url": "https://www.nytimes.com/2018/01/03/magazine/the-dying-algorithm.html", "anchor_text": "article by an oncologist in The New York Times Magazine", "paragraph_index": 65}, {"url": "http://cs231n.github.io/neural-networks-2/#init", "anchor_text": "here", "paragraph_index": 75}, {"url": "https://www.linkedin.com/in/nityeshaga/", "anchor_text": "LinkedIn", "paragraph_index": 76}, {"url": "https://twitter.com/nityeshaga", "anchor_text": "Twitter", "paragraph_index": 76}, {"url": "https://twitter.com/nityeshaga", "anchor_text": "follow me on Twitter", "paragraph_index": 78}, {"url": "https://www.zeolearn.com/magazine/what-does-a-neural-network-even-learn-a-newcomers-dilemma", "anchor_text": "Zeolearn blog", "paragraph_index": 79}, {"url": "https://www.nityesh.com/", "anchor_text": "https://www.nityesh.com/", "paragraph_index": 81}], "all_paragraphs": ["I believe, we all have that psychologist/philosopher in our brains that likes to ponder upon how thinking happens.", "\u201cDeep networks have a hierarchical structure which makes them particularly well adapted to learn the hierarchies of knowledge that seem to be useful in solving real-world problems. Put more concretely, when attacking problems such as image recognition, it helps to use a system that understands not just individual pixels, but also increasingly more complex concepts: from edges to simple geometric shapes, all the way up through complex, multi-object scenes.\u201d", "- Michael Nielsen in his book Neural Networks and Deep Learning", "A simple, clear bird\u2019s eye view of what neural networks learn \u2014 they learn \u201cincreasingly more complex concepts\u201d.", "Doesn\u2019t that feel familiar? Isn\u2019t that how we learn anything at all?", "For instance, let\u2019s consider how we, as kids, probably learnt to recognise objects and animals \u2014", "So, neural networks learn like we do!", "It almost eases the mind to believe that we have this intangible sort of.. man-made \u201cthing\u201d that is analogous to the mind itself! It is especially appealing to someone who has just begun his/her Deep Learning journey.", "But NO. A neural network\u2019s learning is NOT ANALOGOUS to our own. Almost all the credible guides and \u2018starters packs\u2019 on the subject of deep learning come with a warning, something along the lines of:", "Disclaimer: Neural networks are only very loosely inspired by the brain. They do not represent the functioning of an actual human brain. Caution: Any claims of them doing so, in front of a neurologist, may spark an intense battle of words.", "..and that\u2019s where all the confusion begins!", "I think this was mostly because of the way in which most of the tutorials and beginner level books approach the subject.", "Let\u2019s see how Michael Nielsen describes what the hidden neurons are doing in his book \u2014 Neural Networks and Deep Learning:", "He, like many others, uses the analogy between neural networks and the human mind to try to explain a neural networks. The way lines and edges make loops, which then help in recognising some digits is what we would think of doing. Many other tutorials try to use a similar analogy to explain what it means to build a hierarchy of knowledge.", "I have to say that because of this analogy, I understand neural nets better.", "But it is one of the paradoxes, that the very analogy that makes a difficult concept intelligible to the masses, can also create an illusion of knowledge among them.", "Readers need to understand that it is just an analogy. Nothing more, nothing less. They need to understand that every simple analogy needs to be followed by more rigorous, seemingly difficult explanations.", "Now don\u2019t get me wrong. I am deeply thankful to Michael Nielsen for writing this book. It is one of the best books on the subject out there. He is careful in mentioning that this is \u201cjust for the sake of argument\u201d.", "But I took it to mean this \u2014 Maybe, the network won\u2019t use the same exact pieces. Maybe, it will figure out some other pieces and join them in some other way to recognise the digits. But the essence will be the same. Right? I mean each of those pieces has to be some kind of an edge or a line or some loopy structure. After all, it doesn\u2019t seem like there are other possibilities if you want to build a hierarchical structure to solve the problem of recognising digits.", "As I gained a better intuition about them and how they work, I understood that this view is obviously wrong. It hit me..", "Being able to identify a loop is essential for us humans to write digits- an 8 is two loops joined end-to-end, a 9 is loop with a tail under it and a 6 is loop with a tail up top. But when it comes to recognising digits in an image, features like loops seem difficult and infeasible for a neural network (Remember, I\u2019m talking about your vanilla neutral networks or MLPs here).", "I know its just a lot of \u201chand-wavy\u201d reasoning but I think it is enough to convince. Probably, the edges and all the other hand-engineered features will face similar problems.", "I had no clue about the answer or how to find it until 3blue1brown released a set of videos about neural networks. It was Grant Sanderson\u2019s take at explaining the subject to newcomers. Maybe even he felt that there were some missing pieces in the explanation by other people and that he could address them in his tutorials.", "Grant Sanderson of 3blue1brown, who uses a structure with 2 hidden layers, says \u2014", "Originally, the way I motivated the structure was by describing a hope that we might have that the 2nd layer might pick up on little edges, the 3rd layer would piece together those edges to recognise loops and longer lines and that those might be pieced together [in the final layer] to recognise digits.", "The very loops and edges that we ruled out above.", "Is this what our network is actually doing?", "Well for this one atleast \u2014 not at all!", "Instead of picking up on isolated little edges here and there, they look.. well, almost random(!) just but some very loose patterns in the middle", "They were not looking for loops or edges or anything even remotely close! They were looking for.. well something inexplicable.. some strange patterns that can be confused for random noise!", "I found those weight matrix images (in the above screenshot) really fascinating. I thought of them as a Lego puzzle.", "The weight matrix images were like the elementary Lego blocks and my task was to figure out a way to arrange them together so that I could create all 10 digits. This idea was inspired from the excerpt of Neural Networks and Deep Learning that I posted above. There we saw how we could assemble a 0 using hand-made features like edges and curves. So, I thought that, maybe, we could do the same with the features that the neural network actually found good.", "All I needed was those weight matrix images that were used in 3blue1brown\u2019s video. Now\u00a0the\u00a0problem\u00a0was\u00a0that Grant had put only 7 images in the video. So, I was gonna have to generate them on my own and create my very own set of Lego blocks!", "I imported the code used in Michael Nielsen\u2019s book to a Jupyter notebook. Then, I extended the Network class in there to include the methods that would help me visualise the weight matrices.", "One pixel for every connection in the network. One image for each neuron showing how much it \u2018likes\u2019(colour: blue) or \u2018dislikes\u2019(colour: red) the previous layer neurons.", "So, if I was to look at the image belonging to one of the neurons in the hidden layer, it would be like a heat map showing one feature, one basic Lego block that will be used to recognise digits. Blue pixels would represent connections that it \u201clikes\u201d whereas red ones would represent the connections that it \u201cdislikes\u201d.", "I trained a neural network that had:", "Notice that we will have 30 different types of basic Lego blocks for our Lego puzzle here because that\u2019s the size of our hidden layer.", "And.. here\u2019s what they look like! \u2014", "These are the features that we were looking for! The ones that are better than loops and edges according to the network.", "And here\u2019s how it classifies all 10 digits:", "And guess what?None of them make any sense!!", "None of the features seem to capture any isolated distinguishable feature in the input image. All of them can be mistaken to be just randomly shaped blobs at randomly chosen places.", "I mean, just look at how it identifies a \u20180':", "This is the weight matrix image for the output neuron that recognizes \u20180's:", "To be clear, the pixels in this image represent the weights connecting the hidden layer to the output neuron that recognises \u20180's.", "We shall take only a handful of the most useful features for each digit into account. To do that, we can visually select the most intense blue pixels and the most intense red pixels. Here, the blue ones should give us the most useful features and the red ones should give us the most dreaded ones (think of it as the neuron saying \u2014 \u201cThe image will absolutely *not* match this prototype if it is a 0\u201d).", "Indices of the three most intense blue pixels: 3, 6, 26Indices of the three most intense red pixels: 5, 18, 22", "Matrices 6 and 26 seem to capture something like a blue boundary of sorts that is surrounding inner red pixels \u2014 exactly what could actually help in identifying a \u20180\u2019.", "But what about matrix 3? It does not capture any feature we can even explain in words. The same goes for matrix 18. Why would the neuron not like it? It seems quite similar to matrix 3. And let\u2019s not even go into the weird blue \u2018S\u2019 in 22.", "Indices of the three most intense blue pixels: 0, 11, 16Indices of the top two most intense red pixels: 7, 20", "I have no words for this one! I won\u2019t even try to comment.", "In what world can THOSE be used to identify 1\u2019s !?", "Now, the much anticipated \u20188\u2019 (how will it represent the 2 loops in it??):", "Nope, this isn\u2019t any good either. There seem to be no loops like we were expecting it to have. But there is another interesting thing to notice in here \u2014 A majority of the pixels in the output layer neuron image (the one above the collage) are red. It seems like the network has figured out a way to recognise 8s using features that it does not like!", "So, NO. I couldn\u2019t put digits together using those features as Lego blocks. I failed real bad at the task.", "But to be fair to myself,\u200athose features weren\u2019t so much Lego-blocky either! Here\u2019s why\u2014", "So, there it is. Neural networks can be said to learn like us if you consider the way they build hierarchies of features just like we do. But when you see the features themselves, they are nothing like what we would use. The networks give you almost no explanation for the features that they learn.", "Neural networks are good function approximators. When we build and train one, we mostly just care about its accuracy \u2014 On what percentage of the test samples does it give positive results?", "This works incredibly well for a lot of purposes because modern neural nets can have remarkably high accuracies \u2014 upward of 98% is not uncommon (meaning that the chances of failure are just 1 in a 100!)", "But here\u2019s the catch \u2014 When they are wrong, there\u2019s no easy way to understand the reason why they are. They can\u2019t be \u201cdebugged\u201d in the traditional sense. For example, here\u2019s an embarrassing incident that happened with Google because of this:", "Understanding what neural networks learn is a subject of great importance. It is crucial to unleashing the true power of deep learning. It will help us in", "A few weeks ago The New York Times Magazine ran a story about how neural networks were trained to predict the death of cancer patients with a remarkable accuracy.", "Here\u2019s what the writer, an oncologist, said:", "So what, exactly, did the algorithm \u201clearn\u201d about the process of dying? And what, in turn, can it teach oncologists? Here is the strange rub of such a deep learning system: It learns, but it cannot tell us why it has learned; it assigns probabilities, but it cannot easily express the reasoning behind the assignment. Like a child who learns to ride a bicycle by trial and error and, asked to articulate the rules that enable bicycle riding, simply shrugs her shoulders and sails away, the algorithm looks vacantly at us when we ask, \u201cWhy?\u201d It is, like death, another black box.", "The Dying Algorithm, article by an oncologist in The New York Times Magazine", "I think I can strongly relate to this because of my little project. :-)", "During the little project that I described earlier, I stumbled upon a few other results that I found really cool and worth sharing. So here they are \u2014", "I wanted to see how low I could make the hidden layer size while still getting a considerable accuracy across my test set. It turns out that with 10 neurons, the network was able to classify 9343 out of 10000 test images correctly. That\u2019s 93.43% accuracy at classifying images that it has never seen with just 10 hidden neurons.", "Just 10 different types of Lego blocks to recognise 10 digits!!", "Of course, these weights don\u2019t make much sense either!", "Weight initialisation + regularisation makes a LOT of difference:", "Just regularising your network and using good initialisations for the weights can have a huge effect on what your network learns.", "I used the same network architecture, meaning same no. of layers and same no. of neurons in the layers. I then trained 2 Network objects- one without regularisation and using the same old np.random.randn() whereas in the other one I used regularisation along with np.random.randn()/sqrt(n). This is what I observed:", "(Note: I have shown the weight matrices associated with different index neurons in the above collage. This is because due to different initialisations, even the ones at the same index learn different features. So, I chose the ones that appear to make the effect most starking.)", "To know more about weight initialisation techniques in neural networks I recommend that you start here.", "If you want to discuss this article or any other project that you have in mind or really anything AI please feel free to comment below or drop me a message on LinkedIn or Twitter.", "I am a freelance writer. You can hire me to write similar indepth, passionate articles explaining an ML/DL technology for your company\u2019s blog. Shoot me an email at nityeshagarwal[at]gmail[dot]com to discuss our collaboration.", "Also, you can follow me on Twitter; I won\u2019t spam your feed ;-)", "Originally published on the Zeolearn blog.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Learning, Writing and Teaching at https://www.nityesh.com/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fbd8d1bbbed89&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@nityeshagarwal?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nityeshagarwal?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Nityesh Agarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f6f8fefbf72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&user=Nityesh+Agarwal&userId=5f6f8fefbf72&source=post_page-5f6f8fefbf72----bd8d1bbbed89---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/BCChEYrooGU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "ANDRIK LANGFIELD PETRIDES"}, {"url": "https://unsplash.com/search/photos/solution?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "http://neuralnetworksanddeeplearning.com/about.html", "anchor_text": "Neural Networks and Deep Learning"}, {"url": "https://en.wikipedia.org/wiki/Multilayer_perceptron", "anchor_text": "MLPs"}, {"url": "https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw", "anchor_text": "3blue1brown"}, {"url": "https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi", "anchor_text": "3blue1brown\u2019s video series"}, {"url": "https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/", "anchor_text": "When it comes to gorillas, Google Photos remains blind"}, {"url": "https://www.nytimes.com/2018/01/03/magazine/the-dying-algorithm.html", "anchor_text": "article by an oncologist in The New York Times Magazine"}, {"url": "http://cs231n.github.io/neural-networks-2/#init", "anchor_text": "here"}, {"url": "https://www.linkedin.com/in/nityeshaga/", "anchor_text": "LinkedIn"}, {"url": "https://twitter.com/nityeshaga", "anchor_text": "Twitter"}, {"url": "https://twitter.com/nityeshaga", "anchor_text": "follow me on Twitter"}, {"url": "https://www.zeolearn.com/magazine/what-does-a-neural-network-even-learn-a-newcomers-dilemma", "anchor_text": "Zeolearn blog"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----bd8d1bbbed89---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----bd8d1bbbed89---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/data-science?source=post_page-----bd8d1bbbed89---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----bd8d1bbbed89---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----bd8d1bbbed89---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&user=Nityesh+Agarwal&userId=5f6f8fefbf72&source=-----bd8d1bbbed89---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&user=Nityesh+Agarwal&userId=5f6f8fefbf72&source=-----bd8d1bbbed89---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fbd8d1bbbed89&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----bd8d1bbbed89---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----bd8d1bbbed89--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nityeshagarwal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@nityeshagarwal?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Nityesh Agarwal"}, {"url": "https://medium.com/@nityeshagarwal/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3K Followers"}, {"url": "https://www.nityesh.com/", "anchor_text": "https://www.nityesh.com/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f6f8fefbf72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&user=Nityesh+Agarwal&userId=5f6f8fefbf72&source=post_page-5f6f8fefbf72--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7cfd0c7426de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwth-does-a-neural-network-even-learn-a-newcomers-dilemma-bd8d1bbbed89&newsletterV3=5f6f8fefbf72&newsletterV3Id=7cfd0c7426de&user=Nityesh+Agarwal&userId=5f6f8fefbf72&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}