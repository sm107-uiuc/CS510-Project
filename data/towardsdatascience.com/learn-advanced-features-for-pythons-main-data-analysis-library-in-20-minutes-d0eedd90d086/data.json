{"url": "https://towardsdatascience.com/learn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086", "time": 1683000522.335525, "path": "towardsdatascience.com/learn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086/", "webpage": {"metadata": {"title": "A Comprehensive Guide to Pandas\u2019 Advanced Features in 20 Minutes | by Fabian Bosler | Towards Data Science", "h1": "A Comprehensive Guide to Pandas\u2019 Advanced Features in 20 Minutes", "description": "Learn Advanced Features like data types, accessors, merging, joining, grouping, pivoting, stacking and unstacking DataFrames for Python\u2019s main data analysis library in 20 Minutes"}, "outgoing_paragraph_urls": [{"url": "https://github.com/FBosler/you-datascientist", "anchor_text": "GitHub Repo", "paragraph_index": 4}, {"url": "https://en.wikipedia.org/wiki/Coordinated_Universal_Time", "anchor_text": "UTC", "paragraph_index": 14}, {"url": "https://www.programiz.com/python-programming/datetime/strftime#format-code", "anchor_text": "this link", "paragraph_index": 26}, {"url": "https://medium.com/@fabianbosler/membership", "anchor_text": "https://medium.com/@fabianbosler/membership", "paragraph_index": 79}], "all_paragraphs": ["I am going out on a limb here and assume that red pandas are smarter and thus more advanced than their black-and-white brethren. Hence, the cover picture.", "In Part I of this Pandas series, we explored the basics of Pandas, including:", "If those concepts are new to you, head back to Part I, and get a quick refresher.", "A Python environment (I suggest Jupyter Notebook). If you haven\u2019t set this up, don\u2019t worry. It is effortless and takes less than 10 minutes.", "Before doing any data manipulation, let\u2019s get some data. We will be using some fictitious sales data. This GitHub Repo holds the data and the code for this article.", "Create a new notebook and import Pandas (import pandas as pd). I tend to adjust my notebook settings a bit like this:", "These commands make the Notebookwider and thus utilize more space on the screen (typically the notebook has a fixed width, which sucks with wide screens).", "Before diving into the data, let\u2019s quickly summarize all the available Pandas data types. In total, there are seven types:", "After reading the data and running a quick invoices.sample(5) we observe that the dataset seems to be fairly large, but well structured.", "To get a feel for the data, I would usually follow a first sample up with info and describe, but we are here to learn about data types and will skip the typical exploration steps for now. Not surprisingly, there is a command to print out the data types of a DataFrame.", "We loaded the data without any type-conversion, so Pandas made its best guess when assigning types. We can see that all columns, but Meal Price and Super Hero Present are of the type object (i.e., string). From the quick inspection we did earlier, it seems like some of the columns could have been assigned a more explicit data type. So let\u2019s change that.", "There are two standard ways of converting pandas data types:", "astype is quick and works well with clean data and when the conversion is straight forward, e.g., from int64 to float64 (or vice versa). astype has to be called directly on the column that you want to convert. Like this:", "To validate the effect of our type conversion we just run invoices.dtypes again:", "Note: There is a bit of a difference between Pandas versions. For Pandas version 0.23.x it is possible to convert the Date of Meal column by using .astype('datetime64') and Pandas would then automatically convert into UTC. The UTC format is helpful because it is a standardized time format and allows us to subtract or add dates from other dates.", "However, this does not work any longer for Pandas version 0.25.x where we will get a ValueError that lets us know that Tz-aware (timezone-aware) datetimes can not be converted without further adjustment.", "There are three pd.to_<some_type> functions, but for me, only two of them come up frequently:", "Their main advantage over astype, is that it is possible to specify the behavior in case a value is encountered, that can not be converted. Both functions accept an additional parameter errors that defines how errors should be treated. We could choose to ignore errors by passingerrors='ignore' , or turn the offending values into np.nan values by passing errors='coerce'. The default behavior is to raise errors.", "I find that there is no cutty cutter solution, and I would typically investigate before making a decision. The fewer offending values compared to the number of observations you have, the more likely I am to coerce them.", "pd.to_numeric()For the sake of argument, let\u2019s mess up our data a bit:", "invoices['Meal Price'].astype(int) will now fail with a ValueError: invalid literal for int() with base 10: \u2018Me too.\u2019 Because there is no obvious way to convert the string into an integer. Whenever I encounter unexpected conversion errors, I typically check the values of the column explicitly to get a better understanding of the magnitude of the strange values.", "You could then identify the offending rows by doing this:", "From there on it is a quick step to either fix the values or make an informed decision about how you want to handle failing conversion.", "The example above is a prime example, where it would be very reasonable to just convert the values into np.nan by passing errors='coerce' to pd.to_numeric() like this:", "Now it should be noted that you will by construction have two np.nan value in your data, so it might be a good idea to handle them on the spot. The problem with the np.nan`s is that integer columns don\u2019t know how to handle them. Thus the column will be a float column.", "pd.to_datetime()Does what the name implies, the method converts a string into a datetime format. To call to_datetime on a column you would do: pd.to_datetime(invoices['Date of Meal']). Pandas will then guess the format and try to parse the date from the Input. And it does so impressively well:", "However, now and then you might encounter some atypical formatting, like the last example from the list above. In this case, you probably want to provide a custom format, which can you can do like this: pd.to_datetime('20190108',format='%Y%d%m'). Think of the format string as a mask to check against the date string, and if the mask fits, the conversion will take place. Check this link out for a list of all the possible date format components. One additional noteworthy parameter when working with custom formats is exact=False. print(pd.to_datetime('yolo 20190108', format='%Y%d%m', exact=False)) will work, while it would fail without the exact parameter. With exact=False Pandas tries to match the pattern anywhere in the date string.", "Before moving on let\u2019s convert our Date of Meal column, like this invoices['Date of Meal'] = pd.to_datetime(invoices['Date of Meal'], utc=True)", "If your only tool is a hammer, every problem looks like a nail.", "Think of a Pandas accessor as a property that acts as an interface to methods specific to the type you are trying to access. Those methods are highly specialized. They serve one job and one job only. However, they are excellent and extremely concise for that particular job.", "All of the methods are accessed by calling .<accessor>.method on the column of choice, like this: invoices['Date of Meal'].dt.date", "This one I think is the most useful and most straight forward of the accessor methods:", "We can use the results to filter our data down to only rows, where Date of Meal is at the month's end.", "The str accessor is also quite helpful, not because it enables additional functionality, but makes for much more readable code.", "In my opinion the least powerful of the three, or at least the one I use the most infrequently. cat provides access to a couple of categorial operations, like:", "Concatenating comes in handy when you have similar data (structurally and in terms of content) spread out across multiple files. You can concatenate data vertically (i.e., stack the data on top of each other) or horizontally (i.e., stack the data next to each other).", "As an example, imagine that a client provides you one file per month or year of data (because their reporting runs at months end, for example). Those files are conceptually identically and thus a prime example of vertical stacking.", "Let\u2019s have a look at how we can do this with Python\u2019s Pandas. Let\u2019s artificially split out invoices file by years.", "We use .copy() to make sure that the resulting DataFrames are going to be a copy of the data and not just a reference to the original DataFrame.", "Let\u2019s validate that the splitting worked.", "Now for concatenating the data into a unified DataFrame, we would call pd.concat(<LIST OF DATAFRAMES>) like this:", "pd.concat takes a couple of optional parameters next to the list of DataFrames that you call concat on:", "A use case for horizontal stacking is a case where you have multiple time series with overlapping but not identical indices. In which case, you wouldn\u2019t want to end up with a DataFrame with potentially thousands of columns, but much rather a DataFrame with thousands of rows.", "Running the following snippet in Python will result in the following screenshot:", "Note on Append :You might have seen the usage of appendto the same end asconcat. I advise against the usage of appendas it is just a special case of concatand does not provide a benefit over concatenating.", "Merging, as opposed to concatenating DataFrames together, allows us to combine two DataFrames in a more traditional SQL-query kind of way. When merging DataFrames, most of the time you want some information from one source and another piece of information from another source. Whereas when concatenating your DataFrames are structurally and in terms of content quite similar, and you want to combine them into one unified DataFrame.", "A simple example I like to use during interviews is something along the lines of:", "Suppose you have two tables. One table contains the names of your employees and a location id, the other table contains location ids and a city name. How can you get a list of every employee and the city they work in?", "Merging two DataFrames in Pandas is done with pd.merge. Let\u2019s have a look at the function`s signature (signature means a list of all the possible parameters for the function and typically also the output). I bolded the most relevant parameters.", "Let\u2019s go through the parameters one by one:", "Enough theory, let\u2019s have a look at some examples. To do this, we need some additional data to merge on.", "We see pretty much right away, that Order ID ,Company ID , and Date appear in multiple of the DataFrames and are thus good candidates to merge on.", "Let\u2019s merge invoices with order_data and experiment with the parameters a bit.", "If we do explicitly provide an on parameter this will override the default behavior and try to find the provided column in both DataFrames. Remaining duplicated columns that are not being used to merge on will be suffixed.", "In the following example, we only merge on Order Id. However, since the Date and Company Id columns are also present in both DataFrames. Those columns will be sufficed to indicate from which source DataFrame they are originating from as can be seen in the following example.", "You would typically use the left_on and right_on parameters when the columns are named differently in the two DataFrames.", "Note on Join :You might have seen the usage of jointo the same end asmerge. join by default merges on the index of both DataFrames. I advise against the usage of joinas it is just a special case of mergeand does not provide a benefit over merging.", "To wrap up the chapter on combining DataFrames, we should quickly talk about map. map can be called on a DataFrame column or its Index like this:", "The argument (in our case lookup) for map always has to be a series or a dictionary. While not precisely the same Pandas` series and regular dictionaries share a lot of functionalities and can often be used interchangeably. Like through a dictionary you could loop through a series by calling for k,v in series.items(): .", "Transposing a DataFrame means to swap the index and column. In other words, you are rotating the DataFrame around the origin. Transposing does not change the content of the DataFrame. The DataFrame only changes the orientation. Let\u2019s visualize this with an example:", "A DataFrame is transposed by simply calling .T on the DataFrame e.g.invoices.T).", "Melt transforms a DataFrame from wide format to long format. Melt gives flexibility around how the transformation should take place. In other words, melt allows grabbing columns and transforming them into rows while leaving other columns unchanged. Melt is best explained with an example. Let\u2019s create some sample data:", "Admittedly, this example is a bit contrived but illustrates the point. We turned the Type of Meal into columns and assigned the prices into the corresponding rows. Now to turn this back into a version where the Type of Meal is a column and the value is the price we could use pd.melt like this:", "Melt is useful to transform a DataFrame into a format where one or more columns are identifier variables (id_vars), while all other columns, considered measured variables (value_vars), are moved to the row axis, leaving just two non-identifier columns. For each column we melt (value_vars), the corresponding existing row is duplicated to accommodate fusing data into a single column and our DataFrame extends. After melting, we have three times as many rows as before (because we used three value_vars and thus triplicated every row).", "We discussed in the previous article, but a quick recap makes sense here, especially in the light of stacking and unstacking, which we will talk about later. Where transpose and melt leave the content of the DataFrame intact and \u201conly\u201d rearrange the appearance groupby and the following methods are aggregating the data in one form or another. Groupby will result in an aggregated DataFrame with a new index (the values of the columns, by which you are grouping). If you are grouping by more than one value, the resulting DataFrame will have a multi-index.", "Starting with pandas version 0.25.1, there are also named aggregation, which make groupby a little more readable.", "Resulting in virtually the same as the previous calculation. However, the column is renamed during the process.", "Pandas also incorporates a pivot_table functionality, not unlike Excel\u2019s Pivot Table. I must admit though, I never use pivot, as I don\u2019t see the advantage over groupby operations. Generally speaking, I think it makes sense to use what you are comfortable with and stick to that. I would advise against mixing different approaches when there is no necessity for doing so. The one good thing pivot_table has in its favor though is margin=True", "The result should look somewhat familiar, as we basically recreated the groupby functionality. However, we get the added benefit of getting the calculated value across all groups in addition to the individual group\u2019s results (as indicated by the last line).", "We can also specify the columns for the pivot table:", "Stack and unstack come in really handy when rearranging your columns and indices. Unstack will by default be called on the outmost level of the index as can be seen nicely in the following example, where calling unstack() turns the Heroes Adjustment Index into two columns.", "We can also unstack a specific level of the index, like in the following example, where we unstack the Type of Meal column", "Stacking, on the other hand, does the opposite. Stacking turns columns into rows, but also extends the index in the process (as opposed to melt). Let\u2019s have a look at an example.", "We have to build some data first where stacking would come in handy. Executing the following code snippet results in a multi-index, multi-level-columns DataFrame.", "If we want to stack this DataFrame, we would call stack_test.stack() and get:", "Here stack used the outmost level of our multi-level columns and turned it into an index. We now have only single-level columns. Alternatively, we could also call stack with level=0 and get the following result:", "In this article, you learned how to become a real Pandas Ninja. You learned how to convert data into desired types and between types. You learned how to use unique methods for those types to get access to functionalities, that would otherwise take lines and lines of code. You learned how to combine different DataFrames by just stacking them on top of each other, or logically extracting information from the DataFrames and combining them into something more meaningful. You learned how to flip your DataFrame around as if it were a pancake. You learned to rotate on its origin point, to move columns into rows, to aggregate data through pivot or groupby and then to stack and unstack the results.", "Good job, and thanks for reading!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "EX-Consultant turned tech geek! Business intelligence, marketing, advanced analytics, and machine learning. \ud83d\udc49 https://medium.com/@fabianbosler/membership \ud83d\udc48"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd0eedd90d086&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@fabianbosler?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabianbosler?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Fabian Bosler"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a2df7c24f4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&user=Fabian+Bosler&userId=1a2df7c24f4f&source=post_page-1a2df7c24f4f----d0eedd90d086---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@linneaherner?utm_source=medium&utm_medium=referral", "anchor_text": "Linnea Herner"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/how-to-master-pandas-8514f33f00f6", "anchor_text": "How to master Python\u2019s main data analysis library in 20 MinutesA code-along guide for essential Pandas functionalities.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/get-started-with-python-e50dc8c96589", "anchor_text": "So you want to be a Data Scientist?What the *&%$ is stopping you? Here is how to get started!towardsdatascience.com"}, {"url": "https://unsplash.com/@dylan_nolte?utm_source=medium&utm_medium=referral", "anchor_text": "dylan nolte"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/FBosler/you-datascientist", "anchor_text": "GitHub Repo"}, {"url": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/invoices.csv'", "anchor_text": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/invoices.csv'"}, {"url": "https://unsplash.com/@guibolduc?utm_source=medium&utm_medium=referral", "anchor_text": "Guillaume Bolduc"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Coordinated_Universal_Time", "anchor_text": "UTC"}, {"url": "https://www.programiz.com/python-programming/datetime/strftime#format-code", "anchor_text": "this link"}, {"url": "https://unsplash.com/@toddquackenbush?utm_source=medium&utm_medium=referral", "anchor_text": "Todd Quackenbush"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://pixabay.com/users/Pexels-2286921/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2178625", "anchor_text": "Pexels"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2178625", "anchor_text": "Pixabay"}, {"url": "http://www.datasciencemadesimple.com/join-merge-data-frames-pandas-python/", "anchor_text": "DataScienceMadeSimple"}, {"url": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/order_leads.csv',parse_dates=[3", "anchor_text": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/order_leads.csv', parse_dates=[3"}, {"url": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/sales_team.csv'", "anchor_text": "https://raw.githubusercontent.com/FBosler/you-datascientist/master/sales_team.csv'"}, {"url": "https://unsplash.com/@chrislawton?utm_source=medium&utm_medium=referral", "anchor_text": "Chris Lawton"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/programming?source=post_page-----d0eedd90d086---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/python?source=post_page-----d0eedd90d086---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/pandas?source=post_page-----d0eedd90d086---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d0eedd90d086---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----d0eedd90d086---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&user=Fabian+Bosler&userId=1a2df7c24f4f&source=-----d0eedd90d086---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&user=Fabian+Bosler&userId=1a2df7c24f4f&source=-----d0eedd90d086---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd0eedd90d086&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d0eedd90d086---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d0eedd90d086--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d0eedd90d086--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d0eedd90d086--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabianbosler?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@fabianbosler?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fabian Bosler"}, {"url": "https://medium.com/@fabianbosler/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.3K Followers"}, {"url": "https://medium.com/@fabianbosler/membership", "anchor_text": "https://medium.com/@fabianbosler/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a2df7c24f4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&user=Fabian+Bosler&userId=1a2df7c24f4f&source=post_page-1a2df7c24f4f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F85b3b5e26759&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flearn-advanced-features-for-pythons-main-data-analysis-library-in-20-minutes-d0eedd90d086&newsletterV3=1a2df7c24f4f&newsletterV3Id=85b3b5e26759&user=Fabian+Bosler&userId=1a2df7c24f4f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}