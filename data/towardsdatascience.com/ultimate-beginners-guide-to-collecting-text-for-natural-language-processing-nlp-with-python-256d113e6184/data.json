{"url": "https://towardsdatascience.com/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184", "time": 1683004375.342273, "path": "towardsdatascience.com/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184/", "webpage": {"metadata": {"title": "Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python \u2014 Twitter, Reddit, Genius and More | by Eric Kleppen | Towards Data Science", "h1": "Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python \u2014 Twitter, Reddit, Genius and More", "description": "How to collect text for data science. Collect and analyze text from Reddit twitter with Python. Use Python to scrape text from the internet. How to get text for NLP."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00", "anchor_text": "One of my first data science projects was using Google\u2019s Universal Sentence Encoder to produce wine recommendations", "paragraph_index": 0}, {"url": "https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/", "anchor_text": "powerful pre-trained language models like BERT and ELMo", "paragraph_index": 1}, {"url": "https://medium.com/datadriveninvestor/python-pandas-library-for-beginners-a-simplified-guide-for-getting-started-and-ditching-20992b7cd4da", "anchor_text": "Pandas", "paragraph_index": 2}, {"url": "https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2", "anchor_text": "SQLite", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/a-simple-git-workflow-for-github-beginners-and-everyone-else-87e39b50ee08", "anchor_text": "Add the config file to your gitignore file to prevent it from being pushed to your repo too!", "paragraph_index": 4}, {"url": "https://developer.twitter.com/en.html", "anchor_text": "you will need to register an app with Twitter to get API Keys", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/OAuth", "anchor_text": "OAuth1", "paragraph_index": 9}, {"url": "http://docs.tweepy.org/en/latest/auth_tutorial.html", "anchor_text": "official Tweepy Authentication Tutorial", "paragraph_index": 9}, {"url": "https://www.w3schools.com/sql/sql_create_table.asp", "anchor_text": "f you\u2019re not familiar with SQL tables or need a refresher, check this free site for examples", "paragraph_index": 10}, {"url": "https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2", "anchor_text": "my SQL tutorial", "paragraph_index": 10}, {"url": "https://developer.twitter.com/en/docs/basics/response-codes", "anchor_text": "documentation recommends", "paragraph_index": 15}, {"url": "https://www.reddit.com/dev/api/", "anchor_text": "Reddit has an API", "paragraph_index": 18}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/quick_start.html#", "anchor_text": "Python Reddit API Wrapper, or PRAW for short, offers a simplified experience", "paragraph_index": 18}, {"url": "https://old.reddit.com/prefs/apps/", "anchor_text": "use this link to go to your apps page", "paragraph_index": 20}, {"url": "https://old.reddit.com/", "anchor_text": "ttps://old.reddit.com/", "paragraph_index": 22}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/authentication.html#code-flow", "anchor_text": "Use http://localhost:8080 as the redirect uri", "paragraph_index": 24}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/installation.html", "anchor_text": "install PRAW is to use pip", "paragraph_index": 27}, {"url": "https://www.w3schools.com/python/python_dictionaries.asp", "anchor_text": "dictionary", "paragraph_index": 35}, {"url": "https://genius.com/Genius-about-genius-annotated", "anchor_text": "Genius.com", "paragraph_index": 41}, {"url": "http://127.0.0.1", "anchor_text": "http://127.0.0.1", "paragraph_index": 42}, {"url": "https://genius.com/discussions/277279-Get-the-lyrics-of-a-song", "anchor_text": "legal reasons", "paragraph_index": 43}, {"url": "https://medium.com/u/f27d15a817ec?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Ben Wallace", "paragraph_index": 43}, {"url": "https://medium.com/linebyline/mac-miller-a-lyrical-analysis-and-admiration-33f5d6575ee4", "anchor_text": "has provided us with a convenient wrapper for scraping the lyrics", "paragraph_index": 43}, {"url": "https://medium.com/u/e2f299e30cb9?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Will Koehrsen", "paragraph_index": 51}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "Kaggle", "paragraph_index": 52}, {"url": "http://pythondashboards.com", "anchor_text": "pythondashboards.com", "paragraph_index": 60}, {"url": "http://www.linkedin.com/in/erickleppen01/", "anchor_text": "www.linkedin.com/in/erickleppen01/", "paragraph_index": 60}], "all_paragraphs": ["I\u2019ve been fascinated by Natural Language Processing (NLP) since I got into data science a little over a year ago. Thanks to advancements in transfer learning, there has been some explosive progress in the field, and NLP products like Alexa and Siri have become household names. Since my background is technical writing and rhetorical theory, I was immediately drawn to projects involving text like sentiment analysis and topic extraction because I wanted to develop an understanding of how machine learning can provide insight into written language. One of my first data science projects was using Google\u2019s Universal Sentence Encoder to produce wine recommendations.", "I always wanted a guide like this one, breaking down how to extract data from popular social media platforms. With increasing accessibility to powerful pre-trained language models like BERT and ELMo, it is important to understand where to find and extract data. Luckily, social media is an abundant resource for collecting NLP data sets, and is easily accessible with a few lines of Python. At the end of the article, I also include a list of popular Kaggle NLP datasets, and link to Google Dataset Search, the new search engine.", "This article teaches you how to extract data from Twitter, Reddit, and Genius. I assume you already know some Python libraries Pandas and SQLite.", "Before getting into the code, it is important to stress the value of an API Key. If you\u2019re new to managing API keys, make sure to save them into a config.py file instead of hard-coding them in your app. Make sure not to include them in any code share online. API keys can be very valuable, and sometimes very expensive and must be protected. If you\u2019re worried your key has been leaked, most providers allow you to regenerate them.", "Add the config file to your gitignore file to prevent it from being pushed to your repo too!", "Twitter provides a plethora of data that is easy to access through their API. With the Tweepy Python library, easily pull a constant stream of tweets based on the desired topics. Twitter is great for mining trends and sentiment,", "For this tutorial, you will need to register an app with Twitter to get API Keys. Check out the official Twitter documentation if you\u2019re not familiar with their developer portal!", "Use pip to install Tweepy and unidecode.", "Save the following keys to a config file:", "Connecting Tweepy to Twitter uses OAuth1. If you\u2019re brand new to API authentication, check out the official Tweepy Authentication Tutorial.", "To save the data from the incoming stream, I find it easiest to save it to an SQLite database. If you\u2019re not familiar with SQL tables or need a refresher, check this free site for examples or check out my SQL tutorial.", "The function unidecode() takes Unicode data and tries to represent it in ASCII characters.", "I need to create the table to store the wine data. I use SQLite because it is lightweight and server-less. Plus I like keeping all the data in once place!", "Notice I use IF NOT EXISTS to make sure the table doesn\u2019t already exist in the database. Remember to commit the transaction using the conn.commit() call.", "Here is some boilerplate code to pull the tweet and a timestamp from the streamed twitter data and insert it into the database.", "Notice I slow the stream using time.sleep().Notice the code is wrapped in a try/except to prevent potential hiccups from disrupting the stream. Additionally, the documentation recommends using an on_error() function to act as a circuit-breaker if the app is making too many requests.Notice I wrap the stream object in a while condition. That way, it stops if it hits the 420 error.Notice the twitterstream.filter uses track to find keywords in tweets. If you want to follow a specific user\u2019s tweets, use .filter(follow=[\u201c\u201d]).", "Extract the data from the SQLite database", "Like Twitter, the social network Reddit contains a jaw dropping amount of information that is easy to scrape. It is a social network that works like an internet forum allowing users to post about whatever topic they want. Users form communities called subreddits, and they up-vote or down-vote posts in their communities to decide what gets viewed first and what sinks to the bottom.", "I\u2019ll explain how to get a Reddit API key and how to extract data from Reddit using the PRAW library. Although Reddit has an API, the Python Reddit API Wrapper, or PRAW for short, offers a simplified experience. PRAW supports Python 3.5+", "A user account to Reddit is required to use the API. It is completely free and only requires an email address!", "If there is a way to get here using the new Reddit UI, leave me a comment! If it is your first time, follow these steps to get an API key after signing into Reddit. If you already have a key, use this link to go to your apps page.", "Click the User Account droplist. User options display.", "Click Visit Old Reddit from the user options. The page will change and the URL will become https://old.reddit.com/", "Click the preferences link next to the logout button.Click the apps tab on the PREFERENCES screen.Click the are you a developer? create am app\u2026 button.", "Enter a name.Select the type of app.Enter a Description.Use http://localhost:8080 as the redirect uri.Click create app after populating the fields.", "The API information required to connect will display. I\u2019ll walk through connecting to the API using PRAW when I get into code.", "Congratulations on getting set up to scrape Reddit data!", "The recommended way to install PRAW is to use pip. The install the following packages to create the dashboard.", "Start by importing the libraries and the config file:", "Create a read-only Reddit instance. That means I don\u2019t need to enter Reddit credentials used to post responses or create new threads; the connection only reads data.", "PRAW uses OAuth authentication to connect to the Reddit API.", "Here is a list of examples I think would be fun to explore:", "news, datascience, learnmachinelearning, gaming, funny, politics", "Use the Subreddit class in PRAW to retrieve the data from the desired subreddit. It is possible to order the data based on the follow Reddit options:", "If you want to include multiple subreddits, use a + symbol:", "This returns an object that holds the data in an attribute. The attribute is like a key in a dictionary.", "The data is linked to an attributed owned by the object. If the attribute is the Key, the data is the Value. The attributes are dynamically generated, so it is best to check what is available using Python\u2019s built-in vars() function.", "Use this boilerplate code to see all the attributes owned by object representing the reddit post. It is a LONG list!", "Notice in the list the attributes of interest:", "title \u2014 Returns post title.score \u2014 Returns number of up-votes or down-votes.num_comments \u2014 Returns the number of comments on the thread.selftext \u2014 Returns the body of the post.created \u2014 Returns a timestamp for the post.pinned \u2014 Indicates whether the thread was pinned.total_awards_received \u2014 Returns number of awards received by the post.", "Now that the attributes have been identified, load them data into a pandas DataFrame or save them to an SQLite database like in the Twitter example. In this example, I\u2019ll save it to a pandas DataFrame.", "I have always been a fan of music, particularly heavy metal. In heavy metal, the lyrics can sometimes be quite difficult to understand, so I go to Genius to decipher them. The website Genius.com is a platform for annotating lyrics, and collecting trivia about music, albums and artists. Genius allows users to register an API Client.", "Either Sign up or Sign in. Click the Developers link.Click Create an API Client.Enter an App Name.Enter a website URL if you have one, otherwise http://127.0.0.1 will work.Click Save. The API Client will display.Click Generate Access Token to generate an access token.", "Surprisingly, due to legal reasons, the Genius API does not provide a way to download song lyrics. It is possible to search lyrics, but not download them. Lucky for everyone, Medium author Ben Wallace has provided us with a convenient wrapper for scraping the lyrics. Find his original code on GitHub too:", "I have modified his wrapper to make it easier to download an artist\u2019s complete works rather than code the albums I want to include, and I added an Artist column to store the artist name.", "The wrapper uses the API to get the URLs linking to the lyrics. From there, BeautifulSoup is used to parse the HTML for each URL. The process results in a dataframe that contains the Title, URL, Artist, Album and Lyrics:", "The wrapper is a class named GeniusArtistDataCollect(). Use it to connect to the API and retrieve song lyrics for a specified artist. In the example, I use one of my favorite metal bands, The Black Dahlia Murder.", "To use GeniusArtistDataCollect(), instantiate it, passing in the Client Access Token and the Artist name.", "Call get_artists_songs() from the GeniusArtistDataCollect object. This will return as a pandas DataFrame.", "Here is the modified wrapper I use in the example:", "The Genius Lyrics example uses Beautiful Soup to scrape the lyrics from the website. Web scraping is a useful technique that makes it easy to collect a variety of data. I walk through an additional web scraping example in a previous article. Check it out if you want more practice!", "Although I haven\u2019t yet used his methods, Medium writer Will Koehrsen has a walk through for scraping and parsing Wikipedia. Check out his work!", "Although I think it is fun to collect and create my own datasets, Kaggle and Google\u2019s Dataset Search offer convenient ways to find structured and labeled data. Kaggle is a popular competitive Data Science platform. Below is a list of popular datasets used for NLP projects.", "Determine whether news story is from the Onion or not:", "Wine Reviews. I use this in several articles and projects:", "A collection of amazon food reviews:", "News headlines for fake news detection:", "Twitter Airline Sentiment tweets for sentiment analysis", "As NLP becomes more mainstream, it is important to understand how to easily collect rich, text-based datasets. Getting into Natural Language Processing can be tough, so I wanted to share a guide that simplifies ways to collect text data. With a few lines of Python, the astounding amount of data available on Reddit, Twitter, and Genius everyone\u2019s fingertips! Thanks for reading, and check out my other NLP related articles if you want to use the data you know how to collect:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Product Manager at Kipsu. Learn dashboards at pythondashboards.com Top writer. www.linkedin.com/in/erickleppen01/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F256d113e6184&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://erickleppen.medium.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Eric Kleppen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e2ea32699c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&user=Eric+Kleppen&userId=1e2ea32699c9&source=post_page-1e2ea32699c9----256d113e6184---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral", "anchor_text": "Jason Leung"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00", "anchor_text": "One of my first data science projects was using Google\u2019s Universal Sentence Encoder to produce wine recommendations"}, {"url": "https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/", "anchor_text": "powerful pre-trained language models like BERT and ELMo"}, {"url": "https://medium.com/datadriveninvestor/python-pandas-library-for-beginners-a-simplified-guide-for-getting-started-and-ditching-20992b7cd4da", "anchor_text": "Pandas"}, {"url": "https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2", "anchor_text": "SQLite"}, {"url": "https://towardsdatascience.com/a-simple-git-workflow-for-github-beginners-and-everyone-else-87e39b50ee08", "anchor_text": "Add the config file to your gitignore file to prevent it from being pushed to your repo too!"}, {"url": "https://developer.twitter.com/en.html", "anchor_text": "you will need to register an app with Twitter to get API Keys"}, {"url": "https://en.wikipedia.org/wiki/OAuth", "anchor_text": "OAuth1"}, {"url": "http://docs.tweepy.org/en/latest/auth_tutorial.html", "anchor_text": "official Tweepy Authentication Tutorial"}, {"url": "https://www.w3schools.com/sql/sql_create_table.asp", "anchor_text": "f you\u2019re not familiar with SQL tables or need a refresher, check this free site for examples"}, {"url": "https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2", "anchor_text": "my SQL tutorial"}, {"url": "https://developer.twitter.com/en/docs/basics/response-codes", "anchor_text": "documentation recommends"}, {"url": "https://www.reddit.com/dev/api/", "anchor_text": "Reddit has an API"}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/quick_start.html#", "anchor_text": "Python Reddit API Wrapper, or PRAW for short, offers a simplified experience"}, {"url": "https://www.reddit.com/", "anchor_text": "https://www.reddit.com"}, {"url": "https://old.reddit.com/prefs/apps/", "anchor_text": "use this link to go to your apps page"}, {"url": "https://old.reddit.com/", "anchor_text": "ttps://old.reddit.com/"}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/authentication.html#code-flow", "anchor_text": "Use http://localhost:8080 as the redirect uri"}, {"url": "https://praw.readthedocs.io/en/latest/getting_started/installation.html", "anchor_text": "install PRAW is to use pip"}, {"url": "https://www.w3schools.com/python/python_dictionaries.asp", "anchor_text": "dictionary"}, {"url": "https://genius.com/Genius-about-genius-annotated", "anchor_text": "Genius.com"}, {"url": "https://genius.com/api-clients", "anchor_text": "https://genius.com/api-clients"}, {"url": "http://127.0.0.1", "anchor_text": "http://127.0.0.1"}, {"url": "https://genius.com/discussions/277279-Get-the-lyrics-of-a-song", "anchor_text": "legal reasons"}, {"url": "https://medium.com/u/f27d15a817ec?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Ben Wallace"}, {"url": "https://medium.com/linebyline/mac-miller-a-lyrical-analysis-and-admiration-33f5d6575ee4", "anchor_text": "has provided us with a convenient wrapper for scraping the lyrics"}, {"url": "https://github.com/benfwalla/MusicAnalysis", "anchor_text": "benfwalla/MusicAnalysisYou can't perform that action at this time. You signed in with another tab or window. You signed out in another tab or\u2026github.com"}, {"url": "https://genius.com/developers", "anchor_text": "https://genius.com/developers"}, {"url": "https://api.genius.com/'", "anchor_text": "https://api.genius.com/'"}, {"url": "https://towardsdatascience.com/web-scraping-board-game-descriptions-with-python-7b8f6a5be1f3", "anchor_text": "Web Scraping Board Game Descriptions with PythonHow I scraped board game descriptions from the web.towardsdatascience.com"}, {"url": "https://medium.com/u/e2f299e30cb9?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Will Koehrsen"}, {"url": "https://towardsdatascience.com/wikipedia-data-science-working-with-the-worlds-largest-encyclopedia-c08efbac5f5c", "anchor_text": "Wikipedia Data Science: Working with the World\u2019s Largest EncyclopediaHow to programmatically download and parse the Wikipediatowardsdatascience.com"}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "Kaggle"}, {"url": "https://www.kaggle.com/datasets", "anchor_text": "https://www.kaggle.com/datasets"}, {"url": "https://datasetsearch.research.google.com/", "anchor_text": "https://datasetsearch.research.google.com/"}, {"url": "https://www.kaggle.com/chrisfilo/onion-or-not", "anchor_text": "https://www.kaggle.com/chrisfilo/onion-or-not"}, {"url": "https://www.kaggle.com/datasnaek/youtube-new", "anchor_text": "https://www.kaggle.com/datasnaek/youtube-new"}, {"url": "https://www.kaggle.com/shivamb/netflix-shows", "anchor_text": "https://www.kaggle.com/shivamb/netflix-shows"}, {"url": "https://www.kaggle.com/zynicide/wine-reviews", "anchor_text": "https://www.kaggle.com/zynicide/wine-reviews"}, {"url": "https://www.kaggle.com/snap/amazon-fine-food-reviews", "anchor_text": "https://www.kaggle.com/snap/amazon-fine-food-reviews"}, {"url": "https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection", "anchor_text": "https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection"}, {"url": "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus", "anchor_text": "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"}, {"url": "https://www.kaggle.com/crowdflower/twitter-airline-sentiment", "anchor_text": "https://www.kaggle.com/crowdflower/twitter-airline-sentiment"}, {"url": "https://www.kaggle.com/yelp-dataset/yelp-dataset", "anchor_text": "https://www.kaggle.com/yelp-dataset/yelp-dataset"}, {"url": "https://medium.com/@erickleppen", "anchor_text": "follow me on Medium"}, {"url": "https://erickleppen.medium.com/membership", "anchor_text": "Get FULL ACCESS and help support my content by subscribing"}, {"url": "https://www.linkedin.com/in/erickleppen01/", "anchor_text": "LinkedIn"}, {"url": "https://pythondashboards.com/", "anchor_text": "website"}, {"url": "http://pythondashboards.com/", "anchor_text": "\u2014 Eric Kleppen"}, {"url": "https://towardsdatascience.com/analyzing-wine-descriptions-using-the-natural-language-toolkit-in-python-497ac1e228d5", "anchor_text": "Analyzing Wine Descriptions using the Natural Language Toolkit in PythonWhat words are used to describe wine?towardsdatascience.com"}, {"url": "https://medium.com/swlh/dashboards-in-python-for-beginners-and-everyone-else-using-dash-f0a045a86644", "anchor_text": "Dashboards in Python for Beginners and Everyone Else using DashBuild a basic and advanced dashboard with this beginner tutorial on Dash in Pythonmedium.com"}, {"url": "https://towardsdatascience.com/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd", "anchor_text": "Using FunctionTransformer and Pipeline in SkLearn to Predict Chardonnay RatingsAn example of transforming functions into usable pipeline code, and then predicting wine ratings by passing a dataframe\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----256d113e6184---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----256d113e6184---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/web-development?source=post_page-----256d113e6184---------------web_development-----------------", "anchor_text": "Web Development"}, {"url": "https://medium.com/tag/data-mining?source=post_page-----256d113e6184---------------data_mining-----------------", "anchor_text": "Data Mining"}, {"url": "https://medium.com/tag/nlp?source=post_page-----256d113e6184---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----256d113e6184---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----256d113e6184---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F256d113e6184&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----256d113e6184---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----256d113e6184--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----256d113e6184--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----256d113e6184--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----256d113e6184--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----256d113e6184--------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Eric Kleppen"}, {"url": "https://erickleppen.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.1K Followers"}, {"url": "http://pythondashboards.com", "anchor_text": "pythondashboards.com"}, {"url": "http://www.linkedin.com/in/erickleppen01/", "anchor_text": "www.linkedin.com/in/erickleppen01/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1e2ea32699c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&user=Eric+Kleppen&userId=1e2ea32699c9&source=post_page-1e2ea32699c9--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3968dec87f6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184&newsletterV3=1e2ea32699c9&newsletterV3Id=3968dec87f6a&user=Eric+Kleppen&userId=1e2ea32699c9&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}