{"url": "https://towardsdatascience.com/predicting-trump-tweets-with-a-rnn-95e7c398b18e", "time": 1683005323.563788, "path": "towardsdatascience.com/predicting-trump-tweets-with-a-rnn-95e7c398b18e/", "webpage": {"metadata": {"title": "Predicting Trump\u2019s Tweets With A Recurrent Neural Network | by Mikian Musser | Towards Data Science", "h1": "Predicting Trump\u2019s Tweets With A Recurrent Neural Network", "description": "Donald Trump\u2019s unique dialect is recognizable to every American; however, can we build a neural network to mimic Trump\u2019s \u2018covfefe\u2019 like vocabulary? In Andrej Karpathy\u2019s highly referenced blog post\u2026"}, "outgoing_paragraph_urls": [{"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks", "paragraph_index": 1}, {"url": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "anchor_text": "Recurrent Neural Networks (RNNs)", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1", "anchor_text": "Natural Language Processing (NLP)", "paragraph_index": 3}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf", "anchor_text": "the more the better", "paragraph_index": 4}, {"url": "http://www.trumptwitterarchive.com/archive", "anchor_text": "TrumpTwitterArchive", "paragraph_index": 5}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/preprocessing/clean.py", "anchor_text": "removing all of the emojis and URL\u2019s", "paragraph_index": 5}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/data/trump/tweets/clean/cleanTweets.txt", "anchor_text": "cleanTweets.txt", "paragraph_index": 5}, {"url": "https://github.com/unendin/Trump_Campaign_Corpus/blob/master/text/2015-06-17%2017.10.00%20(Complete%2C%20As%20spoken)%20Interview%20with%20Mark%20Halperin%2C%20John%20Heilemann%2C%20'With%20All%20Due%20Respect'%2C%20Bloomberg.txt", "anchor_text": "interview between Donald Trump and Mark Halperin", "paragraph_index": 10}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/data/trump/speeches/clean/cleanSpeech.txt", "anchor_text": "cleanSpeech.txt", "paragraph_index": 16}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/scraping/factbase.py", "anchor_text": "Selenium to scrape the data from FactBase", "paragraph_index": 18}, {"url": "https://medium.com/@jrodthoughts/knowledge-tuning-hyperparameters-in-machine-learning-algorithms-part-i-67a31b1f7c88", "anchor_text": "hyperparameters", "paragraph_index": 19}, {"url": "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly", "anchor_text": "data generators", "paragraph_index": 32}, {"url": "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/", "anchor_text": "hot encode", "paragraph_index": 37}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21", "anchor_text": "Long Short-Term Memory (LSTM) RNN", "paragraph_index": 39}, {"url": "https://keras.io/layers/core/", "anchor_text": "dense layers", "paragraph_index": 39}, {"url": "https://keras.io/activations/", "anchor_text": "Scaled Exponential Linear Unit (SELU)", "paragraph_index": 39}, {"url": "https://keras.io/layers/normalization/", "anchor_text": "batch normalization", "paragraph_index": 39}, {"url": "https://docs.google.com/spreadsheets/d/1cCwZOobNYFQY3109_VNJFzG3Ig-LpIAPvb02QzifCdY/edit?usp=sharing", "anchor_text": "several different options", "paragraph_index": 40}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks", "paragraph_index": 47}, {"url": "https://www.blog.google/products/gmail/subject-write-emails-faster-smart-compose-gmail/", "anchor_text": "like Gmail", "paragraph_index": 50}, {"url": "https://keras.io/layers/recurrent/", "anchor_text": "CuDNNLSTM", "paragraph_index": 52}, {"url": "https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf", "anchor_text": "Machine Learning Yearning", "paragraph_index": 53}, {"url": "https://github.com/minimaxir/textgenrnn", "anchor_text": "more complicated model", "paragraph_index": 53}, {"url": "https://machinelearningmastery.com/what-are-word-embeddings/", "anchor_text": "word embedding", "paragraph_index": 53}, {"url": "https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a", "anchor_text": "Keras\u2019s dataGenerator", "paragraph_index": 55}], "all_paragraphs": ["Donald Trump\u2019s unique dialect is recognizable to every American; however, can we build a neural network to mimic Trump\u2019s \u2018covfefe\u2019 like vocabulary?", "In Andrej Karpathy\u2019s highly referenced blog post, The Unreasonable Effectiveness of Recurrent Neural Networks, Karpathy shows that Recurrent Neural Networks (RNNs) can be used as very powerful generative models. He gives examples of RNNs generating plays by Shakespeare, Wikipedia articles about naturalism, and even Linux source code with realistic user comments.", "We are going to use a RNN to generate new Trump tweets.", "This is not an in-depth guide to Natural Language Processing (NLP) or RNNs but rather an overview of the project; nonetheless, all of the code is provided and there are plenty of links that can help expand upon the topics that are not thoroughly explained in this article.", "We start by gathering examples of Trump\u2019s vocabulary, the more the better. Luckily for us, there is no lack of data. Trump\u2019s thoughts are almost always preserved on Twitter, in a speech, or during an interview. We will use a combination of these tweets, speeches, and interviews to train the character prediction model.", "Trump\u2019s tweets are archived in several places. I downloaded around 50,000 of his tweets from TrumpTwitterArchive. I then cleaned up the data by removing all of the emojis and URL\u2019s from the tweets to help with prediction accuracy. The following is an excerpt from cleanTweets.txt:", "Thank you to our great American businesses for going above and beyond to keep our most vulnerable citizens safe!", "We will be by mutual consent temporarily closing our Northern Border with Canada to non-essential traffic. Trade will not be affected. Details to follow!", "Also according to the Daily Caller leading Sleepy Joe Biden in Florida 48% to 42%.", "Unfortunately, there isn\u2019t a central location for all of Trump\u2019s speeches, but there are several GitHub repositories out there with a subset of his speeches. Below are some examples of where you can get the data; however, I only used the first repository by unendin.", "Again, like the tweet data, this data needs to be cleaned. For the data from unendin\u2019s repository, we need to remove all of the text from speakers that are not Trump. The following is an excerpt from an interview between Donald Trump and Mark Halperin.", "MARK HALPERIN: People are really interested in your personality. A lot of people, I think you\u2019ve heard this, think you\u2019re arrogant or too confident. Some people say you\u2019re hopelessly insecure, and that\u2019s why you act the way you do. Are you insecure about anything?", "DONALD TRUMP: I don\u2019t know. Maybe it\u2019s a combination of both.", "We can remove all of Mark Halperin\u2019s side of the interview by writing a regular expression to match \u201cSPEAKER: TEXT\u201d then removing all of the SPEAKERS who are not Donald Trump.", "I also chose to remove all of the line feeds because I don\u2019t feel that they are important to the text prediction. The resulting transcript is only Trump\u2019s side of the interview.", "I don\u2019t know. Maybe it\u2019s a combination of both. Everyone is insecure.", "All of the speeches are then concatenated and placed in cleanSpeech.txt", "FactBase is an archive of Donald Trump's speeches and interviews. Sadly, FactBase has no easy way to download all of his speeches with one click; however, that doesn\u2019t matter because the data is easily scrapable.", "We can use Selenium to scrape the data from FactBase. Over time this will add all of Trump's new speeches to our database.", "To start training our model, we need to load and process the text data to be ready for the network. By doing so, we will define two important hyperparameters: sequence length and step size.", "Let\u2019s start by loading up our data into memory. We will read in the data and make all of the text lowercase. This way \u2018T\u2019 and \u2018t\u2019 are considered the same letter. The corpus length is the number of characters in our database.", "Models don\u2019t naturally understand text and punctuation like \u2018a\u2019 and \u2018?\u2019, but they do understand numbers. Thus, we need a way to translate all of our text into numbers.", "There are many ways to do this, but I chose to use two dictionaries. One to turn letters into numbers and the other to turn numbers into letters.", "The sequence length is how big of a context window our model gets.", "Sequence length defines how many letters, and how much context, we are going to give the model to predict the next character. The longer the sequence length the more context the model will have when it makes its prediction. An example of sequence length 20:", "You can probably guess that the next letter in this sequence will be \u2018e\u2019 and that the next word in the sentence is \u2018addressing.\u2019 This is what we want our model to predict.", "For our model, we will be using a sequence length of 80.", "The step size is how far we slide the context window each iteration.", "Step size defines how many letters to shift each iteration while making the training examples. Below is an example of sequence length 20 and step size 2 with the sentence \u201cToday I will be addressing the nation.\u201d:", "For our model, we will be using a Step Size 4.", "We want sequence length as long as possible so that the model has more context to predict the next character, however, a longer sequence length means a larger model and more processing time. I chose a sequence length of 80 because I am more concerned with the network\u2019s ability to piece together long strings of text than the network\u2019s processing time.", "The trade-off for step size is a lot more one-sided. It is always better to have a smaller step size. A smaller step size means more training examples and more correlated sentences, however, only a certain number of examples can fit into memory. We want to minimize step size while still fitting all of the sentences into memory.", "*** The step size trade-off is eliminated with the use of data generators ***", "Using the chosen sequence length and step size, we now make a sentences array to hold all of the split up sentences and a next character array to hold the next letter in the sequence.", "To be more readable, the examples I show are going to be for sequence length 20 and step size 2. The sentences array now looks like this:", "The next chars array holds the next letter in each of those sentences:", "This gives us a total number of training examples:", "Finally, we will hot encode these sequences to make them processable by the neural network.", "We now have (X, y) pairs for the network to process. As a reminder, 5835540 is the number of training examples, 80 is the sequence length, and 66 is the number of unique characters.", "Our model is going to be a Long Short-Term Memory (LSTM) RNN. The recurrent layer is followed by a few dense layers, activated with Scaled Exponential Linear Unit (SELU) and regularized by batch normalization.", "I made these decisions after exploring several different options.", "After just four epochs, we have a model that is 67.362% accurate on the validation data. The model performs well considering that random guessing would give us an accuracy of 1.51%. Thus, our model is 44 times more accurate than just guessing.", "The following table shows predictions for the sentence \u201cToday I \u201d.", "For the first character prediction, the model chooses \u201cw\u201d but it is not very confident in its decision. This is because there are a large number of reasonable possibilities that could follow \u201cToday I \u201d. Nonetheless, with 20.53% certainty the model turns \u201cToday I \u201d into \u201cToday I w\u201d.", "After the first prediction, we continue to ask the model for characters. The model becomes more confident as the number of possible options narrows down. \u201cToday I w\u201d becomes \u201cToday I wi\u201d then \u201cToday I wil\u201d. Eventually, the model is 99% confident that the last character is \u201cl\u201d resulting in the string \u201cToday I will\u201d.", "The following are examples of sentences generated by different models. All of the models are trained on the same data set but have different architectures. The models are able to understand twitter tags, punctuation, conjunctions, important dates, and even rhetorical questions.", "Disclosure: I added all of the capitalization in the output.", "We have created very realistic sentences that sound like they are really from Donald Trump\u2019s twitter. I feel confident in saying that this model is definitely another example of The Unreasonable Effectiveness of Recurrent Neural Networks. Throughout this process, I made a few important observations and have listed them below.", "It appears that each of the models has chosen a few phrases to keep reusing. Sometimes these phrases appear multiple times in one prediction. Model 1 keeps reusing the phrases, \u201cbut I want to talk about the problem now\u201d and \u201cfake new media.\u201d For model 2, everything happens in the Middle East. Model 3 always says that things are \u201cthe best in the country.\u201d Finally, Model 4 hates the state of Michigan. Although all of these phrases are part of Donald Trump\u2019s vocabulary, they appear too often in the predictions to be natural.", "An interesting observation is that models trained on the same data set can fixate on different phrases. This implies that the phrases a model chooses more frequently are independent of the data set.", "Beyond just entertainment value, RNNs have practical real-world value. Being able to generate text that is both author and task-specific, like tweets, is very useful. RNNs are able to help you write faster emails by giving you text suggestions, like Gmail. They can also help speechwriters more accurately match speaker vocabulary. The intersection between RNNs and NLP is very wide and the area for applications is huge.", "Training Time: Unfortunately, each epoch takes about an hour to complete so I limited the training to 4 epochs. Although improvements from epoch 3 to 4 were small, I think that training for a few more hours would result in a more accurate model.", "While writing this article I discovered CuDNNLSTM. Replacing LSTM with CuDNNLSTM reduces training time by 66%. I do not have results yet for how CuDNNLSTM affects model accuracy; however, I suspect that both CuDNNLSTM and LSTM will perform similarly.", "Reducing Bias: The model has a significant amount of both avoidable and unavoidable bias as defined by Andrew Ng in Machine Learning Yearning. Text prediction is a hard task even for humans and because of this we can expect a reasonably high unavoidable bias. There is also a high amount of avoidable bias. This is resolvable by using a more complicated model and adding word embedding.", "Reducing Variance: The more examples of Donald Trump\u2019s \u2018covfefe\u2019 like vocabulary the better. I would like to continue to get more tweets, speeches, and interviews. Although the variance is currently very low, as the model gets more complicated the variance will increase. Adding more data will help keep the variance in check.", "Keras dataGenerator: I have not implemented Keras\u2019s dataGenerator class for text data yet. Implementing this class would mean that our model can always have a step size of 1 without overflowing memory. This means that we can dramatically increase the size of the training database without worrying about it not fitting into memory.", "All of these improvements will make the model more accurate.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F95e7c398b18e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mikianmusser?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mikianmusser?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Mikian Musser"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6feed5ee9dbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&user=Mikian+Musser&userId=6feed5ee9dbd&source=post_page-6feed5ee9dbd----95e7c398b18e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/mm909/Predicting-Trump", "anchor_text": "mm909/Predicting-TrumpText prediction only trained on Trump's tweets, speeches, and interviews. - mm909/Predicting-Trumpgithub.com"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks"}, {"url": "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "anchor_text": "Recurrent Neural Networks (RNNs)"}, {"url": "https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1", "anchor_text": "Natural Language Processing (NLP)"}, {"url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf", "anchor_text": "the more the better"}, {"url": "http://www.trumptwitterarchive.com/archive", "anchor_text": "TrumpTwitterArchive"}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/preprocessing/clean.py", "anchor_text": "removing all of the emojis and URL\u2019s"}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/data/trump/tweets/clean/cleanTweets.txt", "anchor_text": "cleanTweets.txt"}, {"url": "https://github.com/unendin/Trump_Campaign_Corpus", "anchor_text": "unendin/Trump_Campaign_CorpusThe Trump Campaign Corpus consists of Donald Trump's speeches, interviews, debates, town halls, press conferences\u2026github.com"}, {"url": "https://github.com/PedramNavid/trump_speeches", "anchor_text": "PedramNavid/trump_speechesAll of Trump's Speeches from June 2015 to November 9, 2016 - PedramNavid/trump_speechesgithub.com"}, {"url": "https://github.com/ryanmcdermott/trump-speeches", "anchor_text": "ryanmcdermott/trump-speechesspeeches.txt: 1mb of text data taken from speeches made by Donald Trump at various points in his 2016 campaign for\u2026github.com"}, {"url": "https://github.com/alexmill/trump_transcripts", "anchor_text": "alexmill/trump_transcriptsThis is a semi-structured version of the transcripts of Donald Trump's campaign speeches and debate transcripts, as\u2026github.com"}, {"url": "https://github.com/unendin/Trump_Campaign_Corpus/blob/master/text/2015-06-17%2017.10.00%20(Complete%2C%20As%20spoken)%20Interview%20with%20Mark%20Halperin%2C%20John%20Heilemann%2C%20'With%20All%20Due%20Respect'%2C%20Bloomberg.txt", "anchor_text": "interview between Donald Trump and Mark Halperin"}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/data/trump/speeches/clean/cleanSpeech.txt", "anchor_text": "cleanSpeech.txt"}, {"url": "https://factba.se/transcripts", "anchor_text": "FactBase"}, {"url": "https://github.com/mm909/Predicting-Trump/blob/master/scraping/factbase.py", "anchor_text": "Selenium to scrape the data from FactBase"}, {"url": "https://medium.com/@jrodthoughts/knowledge-tuning-hyperparameters-in-machine-learning-algorithms-part-i-67a31b1f7c88", "anchor_text": "hyperparameters"}, {"url": "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly", "anchor_text": "data generators"}, {"url": "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/", "anchor_text": "hot encode"}, {"url": "https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21", "anchor_text": "Long Short-Term Memory (LSTM) RNN"}, {"url": "https://keras.io/layers/core/", "anchor_text": "dense layers"}, {"url": "https://keras.io/activations/", "anchor_text": "Scaled Exponential Linear Unit (SELU)"}, {"url": "https://keras.io/layers/normalization/", "anchor_text": "batch normalization"}, {"url": "https://docs.google.com/spreadsheets/d/1cCwZOobNYFQY3109_VNJFzG3Ig-LpIAPvb02QzifCdY/edit?usp=sharing", "anchor_text": "several different options"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "The Unreasonable Effectiveness of Recurrent Neural Networks"}, {"url": "https://www.blog.google/products/gmail/subject-write-emails-faster-smart-compose-gmail/", "anchor_text": "like Gmail"}, {"url": "https://keras.io/layers/recurrent/", "anchor_text": "CuDNNLSTM"}, {"url": "https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf", "anchor_text": "Machine Learning Yearning"}, {"url": "https://github.com/minimaxir/textgenrnn", "anchor_text": "more complicated model"}, {"url": "https://machinelearningmastery.com/what-are-word-embeddings/", "anchor_text": "word embedding"}, {"url": "https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a", "anchor_text": "Keras\u2019s dataGenerator"}, {"url": "https://github.com/mm909", "anchor_text": "mm909 - OverviewDismiss Sign up for your own profile on GitHub, the best place to host code, manage projects, and build software\u2026github.com"}, {"url": "https://medium.com/tag/donald-trump?source=post_page-----95e7c398b18e---------------donald_trump-----------------", "anchor_text": "Donald Trump"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----95e7c398b18e---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----95e7c398b18e---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/nlp?source=post_page-----95e7c398b18e---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----95e7c398b18e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&user=Mikian+Musser&userId=6feed5ee9dbd&source=-----95e7c398b18e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&user=Mikian+Musser&userId=6feed5ee9dbd&source=-----95e7c398b18e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F95e7c398b18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----95e7c398b18e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----95e7c398b18e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----95e7c398b18e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----95e7c398b18e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mikianmusser?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mikianmusser?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mikian Musser"}, {"url": "https://medium.com/@mikianmusser/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "42 Followers"}, {"url": "https://mm909.github.io/Mikian/", "anchor_text": "https://mm909.github.io/Mikian/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6feed5ee9dbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&user=Mikian+Musser&userId=6feed5ee9dbd&source=post_page-6feed5ee9dbd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3e605e0a367e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpredicting-trump-tweets-with-a-rnn-95e7c398b18e&newsletterV3=6feed5ee9dbd&newsletterV3Id=3e605e0a367e&user=Mikian+Musser&userId=6feed5ee9dbd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}