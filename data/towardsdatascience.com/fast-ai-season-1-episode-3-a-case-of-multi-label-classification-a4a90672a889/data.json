{"url": "https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889", "time": 1682993742.3271139, "path": "towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889/", "webpage": {"metadata": {"title": "\u201cA CASE OF MULTI-LABEL IMAGE CLASSIFICATION\u201d | by Ashis Kumar Panda | Towards Data Science", "h1": "\u201cA CASE OF MULTI-LABEL IMAGE CLASSIFICATION\u201d", "description": "Making up of a state of the art multi-label image classifier . Underlying Important topics explained are Stochastic Gradient descent with restarts, Freezing and unfreezing of layers,Learning rate"}, "outgoing_paragraph_urls": [{"url": "http://www.fast.ai/", "anchor_text": "Fastdotai", "paragraph_index": 0}, {"url": "https://twitter.com/jeremyphoward", "anchor_text": "Jeremy Howard", "paragraph_index": 0}, {"url": "https://twitter.com/math_rachel", "anchor_text": "Rachel Thomas", "paragraph_index": 0}, {"url": "https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "2.1", "paragraph_index": 2}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "2.2", "paragraph_index": 2}, {"url": "https://jamesmccaffrey.files.wordpress.com/2016/03/softmaxequation.jpg?w=640", "anchor_text": "Softmax Activation", "paragraph_index": 25}, {"url": "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data", "anchor_text": "Planet: Understanding the Amazon from Space", "paragraph_index": 28}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Episode 2.2", "paragraph_index": 43}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "episodes", "paragraph_index": 48}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Episode 2.1", "paragraph_index": 62}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Episode 2.1", "paragraph_index": 64}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Test Time Augmentation", "paragraph_index": 68}, {"url": "http://forums.fast.ai/", "anchor_text": "fast.ai forums", "paragraph_index": 86}, {"url": "https://twitter.com/ashiskumarpanda", "anchor_text": "@ashiskumarpanda", "paragraph_index": 86}, {"url": "https://github.com/CaptainAshis/Deep_Learning-Experiment/blob/master/Planet%20Earth%20Competition/Amazonian-multi-label.ipynb", "anchor_text": "here", "paragraph_index": 87}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Dog Vs Cat Image Classification", "paragraph_index": 88}, {"url": "https://www.buymeacoffee.com/AshisPanda", "anchor_text": "https://www.buymeacoffee.com/AshisPanda", "paragraph_index": 90}], "all_paragraphs": ["Welcome to the Third Episode of Fastdotai where we will take on the Case of Muti-Label Classification. Before we start , I would like to thank Jeremy Howard and Rachel Thomas for their efforts to democratize AI.", "To make best out of this blog post Series , feel free to explore the first Part of this Series in the following order:-", "For those who haven\u2019t seen previous episodes , please click here to check out 2.1 , 2.2 .", "Today we will deal with Multi-Label Classification, where we have more than one labels as target variable. Before going deep into Multi-Label Classification , let\u2019s understand:-", "HOW DOES A CNN (CONVOLUTIONAL NEURAL NETWORK) WORK?", "There are various parts to the CNN architecture . Lets discuss them in detail , post which , we will combine them and discuss about CNN architecture in detail. So lets start with the input i.e Image", "Initially, we have an image. An image is actually a grid of numbers. Looks something like this image:-", "On top of the image we have a kernel . A kernel / filter, in this case, is a 3 by 3 slice of a 3d tensor that helps us to perform convolution.", "This 3 by 3 slice kernel slides over the image and give rise to feature maps .", "A feature map is made up of activations. An activation is a number which is calculated by", "Assume that our network is trained and at the end of training it has created a Convolutional filter with the kernels values that have learned to recognize vertical and horizontal edges. Pytorch doesn\u2019t save these filters values as two different 9 digit arrays. It stores the values as tensor. A tensor is a high dimensional array. A Tensor has an additional axis which helps us to stack each of this filters together.", "All layer except the input layer and the output layer is known as the hidden layer . The layer that makes up the activation map is one such hidden layer. Its generally named as Conv1 and Conv2 and are the results of convolution of kernels.", "Then we have got a non-overlapping 2 by 2 Maxpooling . It halves the resolution by height and width. Generally, its named as Maxpool .", "On top of that, we have got dense layers /fully connected layers . For every single activation present in max-pool layer we create a weight corresponding to that which is known as the fully connected layer. Then do a sum product of every single activation with every single weight. This will give rise to a single number.", "Cons of using extra Fully Connected Layer :- It leads to overfitting and also slow processing.", "Note:- The dimension of the kernel and the dimension of the slice of image/activation map should always be the same. For Multi-channel input make multi-channel kernels. This helps in higher dimension linear combination.", "HOW THE KERNEL VALUES GETS UPDATED?", "Basically, we start with some random kernel values and then use stochastic gradient descent to update the kernel values during training so as to make sense of the values in the kernel . In this way after a couple of epochs, we reach to a position where initial layer kernels are detecting edges, corners and subsequently higher layer kernels are learning to recognize more important feature.", "MY TAKE ON SIMPLE CNN USING KERAS TO CLASSIFY MNIST DATASET", "SIMPLIFIED DIAGRAM REPRESENTING THE CODE (CNN IN A NUTSHELL)", "3. We use Non-Linear Function/ReLU activation function in deep learning . But why? Check out this Quora post below.", "4. Post that we used max-pooling to reduce the height and width of the kernel by a factor of 2.", "6. This (10,10,32) activation map is convolved with 10 number of kernels having a dimension (10,10) and the output dimension now as per the formulae", "7. Finally, we have reached to a point where we have (1,1,10) dimension of activation . Its the penultimate layer . It spits out 10 random numbers.", "8. We then use softmax activation on top of that to convert the numbers into probabilities.", "9. Softmax Activation returns probability values for 10 numbers ranging from (0,1,2,3,\u2026.9) and it also tend to pick up one thing particularly strongly. Softmax only occurs in the final layer. These will be our predicted values. As these are probability values so it adds up to result 1. We will compare these predicted values with our target values . Please check line #9 of the above attached code(keras.ipynb) to know how the target values are saved in One hot encoded form. The number 5 is represented as below.", "10. After that, we will try to minimize the loss between 10 predicted values and the 10 target values using Loss function. To compute the loss function we use the concept of Gradient Descent. Using Gradient Descent keep updating the parameters/kernel values.", "11. Finally, consider the parameters corresponding to the point of minimum loss. And use those parameters/kernel values during prediction on the test dataset. This is the concept for Single label classification like dogs vs cats or dog breed classification. Now let\u2019s see a case of Multi-Label Classification.", "A best example of Multi-Label Classification is the kaggle competition Planet: Understanding the Amazon from Space . So let\u2019s do it in couple of steps.", "1.DOWNLOAD THE DATA AND IMPORT THE PACKAGES REQUIRED .", "Use the below command to Download the data", "Import the Packages and check whether the files are present in the directory", "train_v2.csv file has the names of the files that are present in the training dataset and the labels corresponding to them.", "2. GET FAMILIAR WITH DATA USING PANDAS", "DIFFERENCE BETWEEN SINGLE AND MULTI-LABEL CLASSIFICATION", "In a Single label classification, the image is either a cat or a dog like the one below:-", "Lets check for the Multi-label Classification :-", "As we can see the output , in the case of Multi-Label classification, images are classified into two parts", "Primary stands for the primary rain forest .", "Agriculture stands for a cleared area used for agricultural land.", "Water stands for the river or lake.", "Basically, in multi-label classification, each image belongs to one or more classes. In the example shown above the 1st image belongs to two classes: haze and primary rainforest . The 2nd image belongs to 4 classes: Primary, clear, Agriculture and Water. Softmax isn\u2019t a good activation function to classify these images , as it has a tendency to classify an image into 1 category strongly and not multiple categories. Hence Softmax is good for Single Label Classification and not good for Multi-Label Classification.", "Fastai looks for the labels in the train_v2.csv file and if it finds more than 1 label for any sample, it automatically switches to Multi-Label mode.", "As discussed in Episode 2.2 , we create a validation dataset which is 20% of the training dataset . The below mentioned commands are used for the creation of validation dataset:-", "3. GET DATA IN FASTAI FORMAT", "These steps are the same as we did in the previous two episodes. get_data(sz) has two lines of code:-", "It helps in reading the files as per fastai format.", "The Concept of Data Loader vs Dataset in Pytorch :-", "A dataset which we came across in previous episodes, will return a single image and a data loader will return a mini batch of images. We can get only the next mini batch . To turn a data loader into an iterator we used a standard python function known as iter. That\u2019s an iterator . To fetch the next minibatch pass the iter to next. It will return the next minibatch of images and the labels. This has been described below:-", "The above command is a validation set data loader and will return a minibatch of images and labels. The y label gives the output below", "As we can see there are 17 labels in this minibatch of 64 samples. The bs=64 has been explicitly mentioned in the get_data(bs) function above. To make sense of what does these one hot encoded label means check out the code below:-", "The data.classes has the actual label names and y[0] gives the name of all the labels that particular sample belongs to .The output ,as shown above, represents that the 1st image has the labels agriculture, clear, primary and water . The one hot encoding representation of the labels has been represented in the below image. The one-hot encoding of Labels is internally handled by the Pytorch framework.", "This one hot encoded representation of the labels are the Actual values . The Neural Network spits 17 such values (in this case ) which are known as the Predicted values. We use the Concept of Loss function and Gradient Descent to minimize the error between the actual and predicted values .", "In some cases, the image isn\u2019t that clear . In such scenarios to get a hang of what all feature the image has, increase the brightness of the image by using a multiplication factor of 1.5/1.6/1.7 as shown below.", "The best part of working with this Planet data is that it\u2019s not similar to ImageNet . While working with data in real-world scenario, we don\u2019t have the data similar to ImageNet dataset.", "Here we start out by resizing data to (64,64) instead of it\u2019s original size (256,256) . We wouldn\u2019t start such small in case of Dogs vs Cats Classification as the pretrained resnet network starts off nearly perfect, so if we resize everything to (64,64) and retrain the weights, it will destroy the weights that were earlier pretrained to be good. Most ImageNet models are trained on top of (224,224) or (299,299). The main reason we are starting so small is that ImageNet images weren\u2019t similar to this Planet Competition dataset. The main takeaway from the Resnet network that has been trained on ImageNet dataset are the initial layers which can detect edges , corners ,textures and repeating patterns .", "4. SETUP THE NEURAL NETWORK AND LOOK FOR THE BEST LEARNING RATE", "The f2 metrics has been discussed later on in this blog post. Furthermore in this model since it\u2019s not mentioned precompute=True , hence by default it takes precompute=False. To know this click shift+Tab , and it will display all the parameters with their default values. At this point in time when precompute=False ,", "Now, let\u2019s look out for the best learning rate finder.", "As we see in the Loss vs Learning Rate Graph , the best learning can rate is somewhere near 0.2. How ?", "Now using the best learning rate 0.2 , lets train our model as shown in the below code.", "5. TRAIN LAST LAYER FROM PRECOMPUTED ACTIVATIONS FOR COUPLE OF EPOCHS.", "The concept of Cycle_len and Cycle_mult has been discussed in detail in Episode 2.1 . Until now we are training only the extra fully layers that we have connected at the end.", "To train all the layers until the end ,", "To learn a different set of features or to tell the learner that the convolution filters are needed to be changed , simply unfreeze all the layers .A frozen layer is one whose weights are not trained or updated. To know how unfreezing and freezing of layers work check out Episode 2.1 . Since the images in Planet competition are not like ImageNet Dataset :-", "6.UNFREEZE THE LAYERS AND TRAIN ALL OF THE LAYERS .", "Below we can see the major drop in Loss, after each cycle .", "7. IMPROVE OUR MODEL AND KEEP OVERFITTING AT BAY :-", "Finally we do a TTA(Test Time Augmentation) to get the .", "Voilaaaaaaa , we get an accuracy of 93.6% which is too good for Multi-label Classification.", "If you are with me until this point , give yourself a high-five.", "Qs 1:- What does data.resize() do in the command below?", "If the initial input is (1000,1000) reading that jpeg and resizing it to( 64,64) turns out to take more time than training the convnet does for each batch . What resize does is it says that it\u2019s not gonna use any image bigger than sz*1.3. So go through ones and create new jpegs of size=sz*1.3 . This step is not necessary but it speeds up the process.", "Qs 2:- Why metrics used here in Planet Satellite Image Competition is f2 instead of accuracy ?", "There are a lot of ways to turn the confusion matrix that we saw in dog vs cat classification into an accuracy score .Those are", "As per this competition criteria, the accuracy is judged on the basis of f-Beta score .In the f-Beta score , Beta says how much you weight false negatives vs false positives ? Here in f-Beta , Beta value is 2. We are passing this as a metrics when we are setting up the Neural Network. Check out the code below.", "Qs 3:- Difference between Multi-Label and Single-Label Classification?", "The output activation function for a single label classification problem is Softmax . But in case we have to predict multiple labels in a particular image as shown below in the last column:-", "Then Softmax is a terrible choice as it has a tendency to pick up a particular label strongly. For the multi-label classification problem, the activation function we use is Sigmoid . The fastai library automatically switches to Sigmoid if it observes a multi-label classification problem. Sigmoid formula is e^x/(1+e^x) . And Sigmoid graph looks like :-", "Basically what Sigmoid graph signifies is , if activation is less than 0.5 then Sigmoid will return a low probability value and if the activation >0.5 the Sigmoid will return a high probability value. That\u2019s how multiple things can have high probabilities.", "Qs 4:- How training of layers work?", "The layers are very important but the pre-trained weights in them aren\u2019t . So it\u2019s the later layers that we want to train the most. The earlier layer already is closer to what we want i.e detecting edges and corners.", "So in case of dogs vs cats , when we are creating a model from a pretrained model it returns a model where all the convolution layers are frozen and some randomly set fully connected layer that has been added to the end are unfrozen .So when we say fit, at first , it trains the randomly initialized fully connected layers at the end. If something is really close to Imagenet dataset , that\u2019s often what we need . As the earlier layers are already good at finding edges , gradients , repeating patterns etc. Then when we unfreeze we set the learning rate for the earlier layers to be really low as we don\u2019t want to change them much .", "Whereas in the Satellite data , the earlier layers are like better than the later layers but we still need to change them quite a bit and that\u2019s why our learning rate is just 9 times smaller than final learning rate rather than 1000 times smaller like in the previous case .", "Qs 5:- Why can\u2019t we directly start with unfreezing all the layer?", "We can do that , but it\u2019s going to take some more time . At first, by unfreezing the final layers and keeping the initial layers frozen, we are training the final layers to learn more important features . The convolutional layers contain pretrained weights so they are not random .For things that are close to ImageNet they are really good but if they aren\u2019t close to ImageNet they are better than nothing .All of our FC layers are totally random , so therefore you would always want to make the fully Connected layers better than random by training them a bit first , because otherwise if you go straight to unfreeze , then we would be fiddling around the early layer weights when later ones are still random.", "If you have any questions, feel free to reach out on the fast.ai forums or on Twitter:@ashiskumarpanda", "P.S. -This blog post will be updated and improved as I further continue with other lessons. In case you are interested for the source code check it out here .", "To make best out of this blog post Series , feel free to explore the first Part of this Series in the following order:-Dog Vs Cat Image Classification", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "https://www.buymeacoffee.com/AshisPanda .. Simplifying tough concepts in Machine Learning domain one at a time| Lifelong learner"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa4a90672a889&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://geneashis.medium.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": ""}, {"url": "https://geneashis.medium.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Ashis Kumar Panda"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdb480693773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&user=Ashis+Kumar+Panda&userId=bdb480693773&source=post_page-bdb480693773----a4a90672a889---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "http://www.fast.ai/", "anchor_text": "Fastdotai"}, {"url": "https://twitter.com/jeremyphoward", "anchor_text": "Jeremy Howard"}, {"url": "https://twitter.com/math_rachel", "anchor_text": "Rachel Thomas"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Dog Vs Cat Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Dog Breed Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889", "anchor_text": "Multi-label Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1", "anchor_text": "Time Series Analysis using Neural Network"}, {"url": "https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23", "anchor_text": "NLP- Sentiment Analysis on IMDB Movie Dataset"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269", "anchor_text": "Basic of Movie Recommendation System"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a", "anchor_text": "Collaborative Filtering from Scratch"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36", "anchor_text": "Collaborative Filtering using Neural Network"}, {"url": "https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c", "anchor_text": "Writing Philosophy like Nietzsche"}, {"url": "https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529", "anchor_text": "Performance of Different Neural Network on Cifar-10 dataset"}, {"url": "https://medium.com/hackernoon/single-object-detection-e65a537a1c31", "anchor_text": "ML Model to detect the biggest object in an image Part-1"}, {"url": "https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7", "anchor_text": "ML Model to detect the biggest object in an image Part-2"}, {"url": "https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "2.1"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "2.2"}, {"url": "https://www.quora.com/Why-does-deep-learning-architectures-only-use-the-non-linear-activation-function-in-the-hidden-layers", "anchor_text": "Why does deep learning/architectures only use the non-linear activation function in the hidden\u2026Answer (1 of 9): \"Why is a nonlinear activation function used?\" Without a nonlinear activation function, the neural\u2026www.quora.com"}, {"url": "https://jamesmccaffrey.files.wordpress.com/2016/03/softmaxequation.jpg?w=640", "anchor_text": "Softmax Activation"}, {"url": "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data", "anchor_text": "Planet: Understanding the Amazon from Space"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Episode 2.2"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "episodes"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "earlier"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Episode 2.1"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Episode 2.1"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Test Time Augmentation"}, {"url": "http://forums.fast.ai/", "anchor_text": "fast.ai forums"}, {"url": "https://twitter.com/ashiskumarpanda", "anchor_text": "@ashiskumarpanda"}, {"url": "https://github.com/CaptainAshis/Deep_Learning-Experiment/blob/master/Planet%20Earth%20Competition/Amazonian-multi-label.ipynb", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d", "anchor_text": "Dog Vs Cat Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60", "anchor_text": "Dog Breed Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889", "anchor_text": "Multi-label Image Classification"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1", "anchor_text": "Time Series Analysis using Neural Network"}, {"url": "https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23", "anchor_text": "NLP- Sentiment Analysis on IMDB Movie Dataset"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269", "anchor_text": "Basic of Movie Recommendation System"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a", "anchor_text": "Collaborative Filtering from Scratch"}, {"url": "https://towardsdatascience.com/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36", "anchor_text": "Collaborative Filtering using Neural Network"}, {"url": "https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c", "anchor_text": "Writing Philosophy like Nietzsche"}, {"url": "https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529", "anchor_text": "Performance of Different Neural Network on Cifar-10 dataset"}, {"url": "https://medium.com/hackernoon/single-object-detection-e65a537a1c31", "anchor_text": "ML Model to detect the biggest object in an image Part-1"}, {"url": "https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7", "anchor_text": "ML Model to detect the biggest object in an image Part-2"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a4a90672a889---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a4a90672a889---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/coding?source=post_page-----a4a90672a889---------------coding-----------------", "anchor_text": "Coding"}, {"url": "https://medium.com/tag/python?source=post_page-----a4a90672a889---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&user=Ashis+Kumar+Panda&userId=bdb480693773&source=-----a4a90672a889---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&user=Ashis+Kumar+Panda&userId=bdb480693773&source=-----a4a90672a889---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa4a90672a889&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a4a90672a889---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a4a90672a889--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a4a90672a889--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a4a90672a889--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a4a90672a889--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a4a90672a889--------------------------------", "anchor_text": ""}, {"url": "https://geneashis.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://geneashis.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ashis Kumar Panda"}, {"url": "https://geneashis.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "276 Followers"}, {"url": "https://www.buymeacoffee.com/AshisPanda", "anchor_text": "https://www.buymeacoffee.com/AshisPanda"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdb480693773&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&user=Ashis+Kumar+Panda&userId=bdb480693773&source=post_page-bdb480693773--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8cd32065fb44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889&newsletterV3=bdb480693773&newsletterV3Id=8cd32065fb44&user=Ashis+Kumar+Panda&userId=bdb480693773&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}