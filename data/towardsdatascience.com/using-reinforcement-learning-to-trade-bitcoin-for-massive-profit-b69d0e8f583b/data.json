{"url": "https://towardsdatascience.com/using-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b", "time": 1682996492.2387981, "path": "towardsdatascience.com/using-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b/", "webpage": {"metadata": {"title": "Optimizing deep learning trading bots using state-of-the-art techniques | by Adam King | Towards Data Science", "h1": "Optimizing deep learning trading bots using state-of-the-art techniques", "description": "This time we\u2019re going to step it up a notch and massively improve our model\u2019s profitability."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29", "anchor_text": "create Bitcoin trading bots that don\u2019t lose money", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315", "anchor_text": "TensorTrade", "paragraph_index": 3}, {"url": "https://github.com/notadamking/RLTrader", "anchor_text": "GitHub", "paragraph_index": 4}, {"url": "https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/", "anchor_text": "stationary", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test", "anchor_text": "Augmented Dickey-Fuller Test", "paragraph_index": 11}, {"url": "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html", "anchor_text": "StatsModels SARIMAX", "paragraph_index": 15}, {"url": "https://github.com/bukosabino/ta", "anchor_text": "ta", "paragraph_index": 16}, {"url": "https://github.com/bukosabino/ta", "anchor_text": "library", "paragraph_index": 16}, {"url": "https://github.com/quantopian/empyrical", "anchor_text": "empyrical", "paragraph_index": 31}, {"url": "https://github.com/quantopian/empyrical", "anchor_text": "library", "paragraph_index": 31}, {"url": "https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf", "anchor_text": "Tree-structured Parzen Estimators", "paragraph_index": 33}, {"url": "https://optuna.readthedocs.io/en/stable/tutorial/configurations.html#defining-parameter-spaces", "anchor_text": "The search space", "paragraph_index": 39}, {"url": "https://www.cryptodatadownload.com/data/northamerican/", "anchor_text": "CryptoDataDownload", "paragraph_index": 50}, {"url": "https://github.com/notadamking/Bitcoin-Trader-RL", "anchor_text": "what I\u2019ve built", "paragraph_index": 62}, {"url": "https://github.com/notadamking/RLTrader", "anchor_text": "GitHub", "paragraph_index": 64}, {"url": "https://twitter.com/notadamking", "anchor_text": "Twitter", "paragraph_index": 64}, {"url": "https://github.com/users/notadamking/sponsorship", "anchor_text": "Github Sponsors", "paragraph_index": 65}, {"url": "https://www.patreon.com/join/notadamking", "anchor_text": "Patreon", "paragraph_index": 65}, {"url": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/", "anchor_text": "\u201cRecurrent Neural Networks and LSTM Tutorial in Python and TensorFlow.\u201d Adventures in Machine Learning, 9 Oct. 2017.", "paragraph_index": 67}, {"url": "https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/", "anchor_text": "\u201cA Gentle Introduction to SARIMA for Time Series Forecasting in Python.\u201d Machine Learning Mastery, 12 May 2019.", "paragraph_index": 68}, {"url": "https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/", "anchor_text": "Singh, Aishwarya. \u201cA Gentle Introduction to Handling a Non-Stationary Time Series in Python.\u201d Analytics Vidhya, 7 May 2019.", "paragraph_index": 69}, {"url": "https://www.amazon.com/gp/product/1119482089/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1119482089&linkCode=as2&tag=notadamking-20&linkId=79754cdeac011b4af5c86464638f82f6", "anchor_text": "Prado Marcos Lo\u0301pez de. Advances in Financial Machine Learning. Wiley, 2018.", "paragraph_index": 70}, {"url": "https://www.patreon.com/notadamking", "anchor_text": "https://www.patreon.com/notadamking", "paragraph_index": 72}], "all_paragraphs": ["In the last article, we used deep reinforcement learning to create Bitcoin trading bots that don\u2019t lose money. Although the agents were profitable, the results weren\u2019t all that impressive, so this time we\u2019re going to step it up a notch and massively improve our model\u2019s profitability.", "As a reminder, the purpose of this series of articles is to experiment with state-of-the-art deep reinforcement learning technologies to see if we can create profitable Bitcoin trading bots. It seems to be the status quo to quickly shut down any attempts to create reinforcement learning algorithms, as it is \u201cthe wrong way to go about building a trading algorithm\u201d. However, recent advances in the field have shown that RL agents are often capable of learning much more than supervised learning agents within the same problem domain. For this reason, I am writing these articles to see just how profitable we can make these trading agents, or if the status quo exists for a reason.", "We will first improve our model\u2019s policy network and make the input data set stationary, so we can learn more from less data. Next, we will use advanced feature engineering to improve our agent\u2019s observation space and fine tune our reward function to produce more attractive strategies. Finally, we will use a technique called Bayesian optimization to zone in on the most profitable hyper-parameters, before training and testing the final agents profitablity. Hold on to your seats everyone, this is going to be a wild ride.", "When you\u2019ve read this article, check out TensorTrade \u2014 the successor framework to the codebase produced in this article.", "The first thing we need to do to improve the profitability of our model, is make a couple improvements on the code we wrote in the last article. If you do not yet have the code, you can grab it from my GitHub.", "The first change we need to make is to update our policy to use a recurrent, Long Short-Term Memory (LSTM) network, in place of our previous, Multi-Layer Perceptron (MLP) network. Since recurrent networks are capable of maintaining internal state over time, we no longer need a sliding \u201clook-back\u201d window to capture the motion of the price action. Instead, it is inherently captured by the recursive nature of the network. At each time step, the input from the data set is passed into the algorithm, along with the output from the last time step.", "This allows the LSTM to maintain an internal state that gets updated at each time step as the agent \u201cremembers\u201d and \u201cforgets\u201d specific data relationships.", "It was also pointed out to me on the last article that our time series data is not stationary, and therefore, any machine learning model is going to have a hard time predicting future values.", "A stationary time series is one whose mean, variance, and auto-correlation (lagged correlation with itself) are constant.", "The bottom line is that our time series contains an obvious trend and seasonality, which both impact our algorithms ability to predict the time series accurately. We can fix this by using differencing and transformation techniques to produce a more normal distribution from our existing time series.", "Differencing is the process of subtracting the derivative (rate of return) at each time step from the value at that time step. This has the desired result of removing the trend in our case, however, the data still has a clear seasonality to it. We can attempt to remove that by taking the logarithm at each time step before differencing, which produces the final, stationary time series, shown below on the right.", "We can verify the produced time series is stationary by running it through an Augmented Dickey-Fuller Test. Doing this gives us a p-value of 0.00, allowing us to reject the test\u2019s null hypothesis and confirm our time series is stationary.", "Now that we\u2019ve got that out of the way, we are going to further update our observation space using a bit of feature engineering.", "To further improve our model, we are going to be doing a bit of feature engineering.", "Feature engineering is the process of using domain-specific knowledge to create additional input data that improves a machine learning model.", "In our case, we are going to be adding some common, yet insightful technical indicators to our data set, as well as the output from the StatsModels SARIMAX prediction model. The technical indicators should add some relevant, though lagging information to our data set, which will be complimented well by the forecasted data from our prediction model. This combination of features should provide a nice balance of useful observations for our model to learn from.", "To choose our set of technical indicators, we are going to compare the correlation of all 32 indicators (58 features) available in the ta library. We can use pandas to find the correlation between each indicator of the same type (momentum, volume, trend, volatility), then select only the least correlated indicators from each type to use as features. That way, we can get as much benefit out of these technical indicators as possible, without adding too much noise to our observation space.", "It turns out that the volatility indicators are all highly correlated, as well as a couple of the momentum indicators. When we remove all duplicate features (features with an absolute mean correlation > 0.5 within their group), we are left with 38 technical features to add to our observation space. This is perfect, so we\u2019ll create a utility method named add_indicators to add these features to our data frame, and call it within our environment\u2019s initialization to avoid having to calculate these values on each time step.", "Next we need to add our prediction model. We\u2019ve chosen to use the Seasonal Auto Regressive Integrated Moving Average (SARIMA) model to provide price predictions because it can be calculated very quickly at each step, and it is decently accurate on our stationary data set. As a bonus, it\u2018s pretty simple to implement and it allows us to create a confidence interval for its future predictions, which is often much more insightful than a single value. For example, our agent can be learn to be more cautious trusting predictions when the confidence interval is small and take more risk when the interval is large.", "Now that we\u2019ve updated our policy to use a more applicable, recurrent network and improved our observation space through contextual feature engineering, it\u2019s time to optimize all of the things.", "One might think our reward function from the previous article (i.e. rewarding incremental net worth gains) is the best we can do, however, further inspection shows this is far from the truth. While our simple reward function from last time was able to profit, it produced volatile strategies that often lead to stark losses in capital. To improve on this, we are going to need to consider other metrics to reward, besides simply unrealized profit.", "A simple improvement to this strategy, as mentioned by Sean O\u2019Gordman in the comments of my last article, is to not only reward profits from holding BTC while it is increasing in price, but also reward profits from not holding BTC while it is decreasing in price. For example, we could reward our agent for any incremental increase in net worth while it is holding a BTC/USD position, and again for the incremental decrease in value of BTC/USD while it is not holding any positions.", "While this strategy is great at rewarding increased returns, it fails to take into account the risk of producing those high returns. Investors have long since discovered this flaw with simple profit measures, and have traditionally turned to risk-adjusted return metrics to account for it.", "The most common risk-adjusted return metric is the Sharpe ratio. This is a simple ratio of a portfolio\u2019s excess returns to volatility, measured over a specific period of time. To maintain a high Sharpe ratio, an investment must have both high returns and low volatility (i.e. risk). The math for this goes as follows:", "This metric has stood the test of time, however it too is flawed for our purposes, as it penalizes upside volatility. For Bitcoin, this can be problematic as upside volatility (wild upwards price movement) can often be quite profitable to be a part of. This leads us to the first rewards metric we will be testing with our agents.", "The Sortino ratio is very similar to the Sharpe ratio, except it only considers downside volatility as risk, rather than overall volatility. As a result, this ratio does not penalize upside volatility. Here\u2019s the math:", "The second rewards metric that we will be testing on this data set will be the Calmar ratio. All of our metrics up to this point have failed to take into account drawdown.", "Drawdown is the measure of a specific loss in value to a portfolio, from peak to trough.", "Large drawdowns can be detrimental to successful trading strategies, as long periods of high returns can be quickly reversed by a sudden, large drawdown.", "To encourage strategies that actively prevent large drawdowns, we can use a rewards metric that specifically accounts for these losses in capital, such as the Calmar ratio. This ratio is identical to the Sharpe ratio, except that it uses maximum drawdown in place of the portfolio value\u2019s standard deviation.", "Our final metric, used heavily in the hedge fund industry, is the Omega ratio. On paper, the Omega ratio should be better than both the Sortino and Calmar ratios at measuring risk vs. return, as it is able to account for the entirety of the risk over return distribution in a single metric. To find it, we need to calculate the probability distributions of a portfolio moving above or below a specific benchmark, and then take the ratio of the two. The higher the ratio, the higher the probability of upside potential over downside potential.", "While writing the code for each of these rewards metrics sounds really fun, I have opted to use the empyrical library to calculate them instead. Luckily enough, this library just happens to include the three rewards metrics we\u2019ve defined above. Getting a ratio at each time step is as simple as providing the list of returns and benchmark returns for a time period to the corresponding Empyrical function.", "Now that we\u2019ve decided how to measure a successful trading strategy, it\u2019s time to figure out which of these metrics produces the most appealing results. Let\u2019s plug each of these reward functions into Optuna and use good old Bayesian optimization to find the best strategy for our data set.", "Any great technician needs a great toolset. Instead of re-inventing the wheel, we are going to take advantage of the pain and suffering of the programmers that have come before us. For today\u2019s job, our most important tool is going to be the optuna library, which implements Bayesian optimization using Tree-structured Parzen Estimators (TPEs). TPEs are parallelizable, which allows us to take advantage of our GPU, dramatically decreasing our overall search time. In a nutshell,", "Bayesian optimization is a technique for efficiently searching a hyperspace to find the set of parameters that maximize a given objective function.", "In simpler terms, Bayesian optimization is an efficient method for improving any black box model. It works by modeling the objective function you want to optimize using a surrogate function, or a distribution of surrogate functions. That distribution improves over time as the algorithm explores the hyperspace and zones in on the areas that produce the most value.", "How does this apply to our Bitcoin trading bots? Essentially, we can use this technique to find the set of hyper-parameters that make our model the most profitable. We are searching for a needle in a haystack and Bayesian optimization is our magnet. Let\u2019s get started.", "Optimizing hyper-parameters with Optuna is fairly simple. First, we\u2019ll need to create an optuna study, which is the parent container for all of our hyper-parameter trials. A trial contains a specific configuration of hyper-parameters and its resulting cost from the objective function. We can then call study.optimize() and pass in our objective function, and Optuna will use Bayesian optimization to find the configuration of hyper-parameters that produces the lowest cost.", "In this case, our objective function consists of training and testing our PPO2 model on our Bitcoin trading environment. The cost we return from our function is the average reward over the testing period, negated. We need to negate the average reward, because Optuna interprets lower return value as better trials. The optimize function provides a trial object to our objective function, which we then use to specify each variable to optimize.", "The optimize_ppo2() and optimize_envs() methods take in a trial object and return a dictionary of parameters to test. The search space for each of our variables is defined by the specific suggest function we call on the trial, and the parameters we pass in to that function.", "Later, after running our optimization function overnight with a decent CPU/GPU combination, we can load up the study from the sqlite database we told Optuna to create. The study keeps track of the best trial from its tests, which we can use to grab the best set of hyper-parameters for our environment.", "We\u2019ve revamped our model, improved our feature set, and optimized all of our hyper-parameters. Now it\u2019s time to see how our agents do with their new reward mechanisms. I have trained an agent to optimize each of our four return metrics: simple profit, the Sortino ratio, the Calmar ratio, and the Omega ratio. Let\u2019s run each of these optimized agents on a test environment, which is initialized with price data they\u2019ve not been trained on, and see profitable they are.", "Before we look at the results, we need to know what a successful trading strategy looks like. For this treason, we are going to benchmark against a couple common, yet effective strategies for trading Bitcoin profitably. Believe it or not, one of the most effective strategies for trading BTC over the last ten years has been to simply buy and hold. The other two strategies we will be testing use very simple, yet effective technical analysis to create buy and sell signals.", "The idea is to buy as much as possible and Hold On for Dear Life (HODL). While this strategy is not particularly complex, it has seen very high success rates in the past.", "When consecutive closing price continues to rise as the RSI continues to drop, a negative trend reversal (sell) is signaled. A positive trend reversal (buy) is signaled when closing price consecutively drops as the RSI consecutively rises.", "3. Simple Moving Average (SMA) Crossover", "When the longer-term SMA crosses above the shorter-term SMA, a negative trend reversal (sell) is signaled. A positive trend reversal (buy) is signaled when the shorter-term SMA crosses above the longer-term SMA.", "The purpose of testing against these simple benchmarks is to prove that our RL agents are actually creating alpha over the market. If we can\u2019t beat these simple benchmarks, then we are wasting countless hours of development time and GPU cycles, just to make a cool science project. Let\u2019s prove that this is not the case.", "I must preface this section by stating that the positive profits in this section are the direct result of incorrect code. Due to the way dates were being sorted at the time, the agent was able to see the price 12 hours in advance at all times, an obvious form of look-ahead bias. This has since been fixed, though the time has yet to be invested to replace each of the result sets below. Please understand that these results are completely invalid and highly unlikely to be reproduced.", "That being said, there is still a large amount of research that went into this article and the purpose was never to make massive amounts of money, rather to see what was possible with the current state-of-the-art reinforcement learning and optimization techniques. So in attempt to keep this article as close to the original as possible, I will leave the old (invalid) results here until I have the time to replace them with new, valid results.", "The agents were trained on the first 80% of the data set (hourly OHCLV data from CryptoDataDownload), and tested on the final 20% to see how the strategies generalize to fresh data. This simple cross validation is enough for what we need, as when we eventually release these algorithms into the wild, we can train on the entire data set and treat new incoming data as the new test set.", "Let\u2019s quickly move through the losers so we can get to the good stuff. First, we\u2019ve got the Omega strategy, which ends up being fairly useless trading against our data set.", "Watching this agent trade, it was clear this reward mechanism produces strategies that over-trade and are not capable of capitalizing on market opportunities.", "The Calmar-based strategies came in with a small improvement over the Omega-based strategies, but ultimately the results were very similar. It\u2019s starting to look like we\u2019ve put in a ton of time and effort, just to make things worse\u2026", "Remember our old friend, simple incremental profit? While this reward mechanism didn\u2019t prove to be too successful in our last article, all the modifications and optimizations we\u2019ve done seem to have massively improved the success of the agents.", "The average profit is just over 350% of the initial account balance, over our four month test period. If you are unaware of average market returns, these kind of results would be absolutely insane. Surely this is the best we can do with reinforcement learning\u2026 right?", "Wrong. The average profit produced by agents rewarded by the Sortino ratio was nearly 850%. When I saw the success of these strategies, I had to quickly check to make sure there were no bugs. [editors note: Brace yourself for the irony of the following sentence.] After a thorough inspection, it is clear that the code is bug free and these agents are just very good at trading Bitcoin.", "Instead of over-trading and under-capitalizing, these agents seem to understand the importance of buying low and selling high, while minimizing the risk of holding BTC. Regardless of what specific strategy the agents have learned, our trading bots have clearly learned to trade Bitcoin profitably. If you don\u2019t believe me, see for yourself.", "Now, I am no fool. I understand that the success in these tests may not [read: will not] generalize to live trading. That being said, these results are far more impressive than any algorithmic trading strategies I\u2019ve seen to date (this should have been the first clue that something was wrong\u2026). It is truly amazing considering these agents were given no prior knowledge of how markets worked or how to trade profitably, and instead learned to be massively successful through trial and error alone (along with some good old look-ahead bias). Lots, and lots, of trial and error.", "In this article, we\u2019ve optimized our reinforcement learning agents to make even better decisions while trading Bitcoin, and therefore, make a ton more money! It took quite a bit of work, but we\u2019ve managed to accomplish it by doing the following:", "A highly profitable trading bot is great, in theory. However, I\u2019ve received quite a bit of feedback claiming these agents are simply learning to fit a curve, and therefore, would never be profitable trading on live data. While our method of training/testing on separate data sets should address this issue, it is true that our model could be overfitting to this data set and might not generalize to new data very well. That being said, I\u2019ve got a feeling these agents are learning quite a bit more than simple curve fitting, and as a result, will be able to profit in live trading situations.", "To experiment on this hypothesis, with the help of the community I\u2019ve built a fully-fledged reinforcement learning framework for trading stocks, forex, cryptocurrency, and any other financial instrument with an API. Check it out below.", "As an aside, there is still much that could be done to improve the performance of these agents, however I only have so much time and I have already been working on this article for far too long to delay posting any longer. If you\u2019re interested, take what I\u2019ve built and improve on it! If you can beat my results, send me what you\u2019ve got and let\u2019s talk.", "It is important to understand that all of the research documented in this article is for educational purposes, and should not be taken as trading advice. You should not trade based on any algorithms or strategies defined in this article, as you are likely to lose your investment.", "Thanks for reading! As always, all of the code for this tutorial can be found on my GitHub. Leave a comment below if you have any questions or feedback, I\u2019d love to hear from you! I can also be reached on Twitter at @notadamking.", "You can also sponsor me on Github Sponsors or Patreon via the links below.", "Github Sponsors is currently matching all donations 1:1 up to $5,000!", "[1.] \u201cRecurrent Neural Networks and LSTM Tutorial in Python and TensorFlow.\u201d Adventures in Machine Learning, 9 Oct. 2017.", "[2.] \u201cA Gentle Introduction to SARIMA for Time Series Forecasting in Python.\u201d Machine Learning Mastery, 12 May 2019.", "[3.] Singh, Aishwarya. \u201cA Gentle Introduction to Handling a Non-Stationary Time Series in Python.\u201d Analytics Vidhya, 7 May 2019.", "[5.] Prado Marcos Lo\u0301pez de. Advances in Financial Machine Learning. Wiley, 2018.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Co-Founder, Software Architect, and Deep Learning Enthusiast \u2014 Judge me by my age, I dare you https://www.patreon.com/notadamking"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb69d0e8f583b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@notadamking?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@notadamking?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Adam King"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e3a5234f1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&user=Adam+King&userId=6e3a5234f1cc&source=post_page-6e3a5234f1cc----b69d0e8f583b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/creating-bitcoin-trading-bots-that-dont-lose-money-2e7165fb0b29", "anchor_text": "create Bitcoin trading bots that don\u2019t lose money"}, {"url": "https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315", "anchor_text": "Trade and Invest Smarter \u2014 The Reinforcement Learning WayA deep dive into TensorTrade \u2014 an open source Python framework for training, evaluating, and deploying robust trading\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315", "anchor_text": "TensorTrade"}, {"url": "https://github.com/notadamking/RLTrader", "anchor_text": "GitHub"}, {"url": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/", "anchor_text": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/"}, {"url": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/", "anchor_text": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/"}, {"url": "https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/", "anchor_text": "stationary"}, {"url": "https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test", "anchor_text": "Augmented Dickey-Fuller Test"}, {"url": "https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html", "anchor_text": "StatsModels SARIMAX"}, {"url": "https://github.com/bukosabino/ta", "anchor_text": "ta"}, {"url": "https://github.com/bukosabino/ta", "anchor_text": "library"}, {"url": "https://github.com/quantopian/empyrical", "anchor_text": "empyrical"}, {"url": "https://github.com/quantopian/empyrical", "anchor_text": "library"}, {"url": "https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf", "anchor_text": "Tree-structured Parzen Estimators"}, {"url": "https://optuna.readthedocs.io/en/stable/tutorial/configurations.html#defining-parameter-spaces", "anchor_text": "The search space"}, {"url": "https://www.cryptodatadownload.com/data/northamerican/", "anchor_text": "CryptoDataDownload"}, {"url": "https://towardsdatascience.com/trade-smarter-w-reinforcement-learning-a5e91163f315", "anchor_text": "Trade and Invest Smarter \u2014 The Reinforcement Learning WayA deep dive into TensorTrade \u2014 an open source Python framework for training, evaluating, and deploying robust trading\u2026towardsdatascience.com"}, {"url": "https://github.com/notadamking/Bitcoin-Trader-RL", "anchor_text": "what I\u2019ve built"}, {"url": "https://github.com/notadamking/RLTrader", "anchor_text": "GitHub"}, {"url": "https://twitter.com/notadamking", "anchor_text": "Twitter"}, {"url": "https://github.com/users/notadamking/sponsorship", "anchor_text": "Github Sponsors"}, {"url": "https://www.patreon.com/join/notadamking", "anchor_text": "Patreon"}, {"url": "https://github.com/users/notadamking/sponsorship", "anchor_text": "Sponsor @notadamking on GitHub SponsorsHi, I\u2019m Adam. I\u2019m a developer, writer, and entrepreneur, specifically interested in financial applications of deep\u2026github.com"}, {"url": "https://patreon.com/notadamking", "anchor_text": "Adam King is creating World Changing Content | PatreonHi, I\u2019m Adam. I\u2019m a developer, writer, and entrepreneur, specifically interested in financial applications of deep\u2026patreon.com"}, {"url": "https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/", "anchor_text": "\u201cRecurrent Neural Networks and LSTM Tutorial in Python and TensorFlow.\u201d Adventures in Machine Learning, 9 Oct. 2017."}, {"url": "https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/", "anchor_text": "\u201cA Gentle Introduction to SARIMA for Time Series Forecasting in Python.\u201d Machine Learning Mastery, 12 May 2019."}, {"url": "https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/", "anchor_text": "Singh, Aishwarya. \u201cA Gentle Introduction to Handling a Non-Stationary Time Series in Python.\u201d Analytics Vidhya, 7 May 2019."}, {"url": "https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf", "anchor_text": "\u201cAlgorithms for Hyper-Parameter Optimization.\u201d Advances in Neural Information Processing Systems 24 (NIPS 2011), 2011."}, {"url": "https://www.amazon.com/gp/product/1119482089/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1119482089&linkCode=as2&tag=notadamking-20&linkId=79754cdeac011b4af5c86464638f82f6", "anchor_text": "Prado Marcos Lo\u0301pez de. Advances in Financial Machine Learning. Wiley, 2018."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b69d0e8f583b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/bitcoin?source=post_page-----b69d0e8f583b---------------bitcoin-----------------", "anchor_text": "Bitcoin"}, {"url": "https://medium.com/tag/trading?source=post_page-----b69d0e8f583b---------------trading-----------------", "anchor_text": "Trading"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----b69d0e8f583b---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/tag/cryptocurrency?source=post_page-----b69d0e8f583b---------------cryptocurrency-----------------", "anchor_text": "Cryptocurrency"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&user=Adam+King&userId=6e3a5234f1cc&source=-----b69d0e8f583b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&user=Adam+King&userId=6e3a5234f1cc&source=-----b69d0e8f583b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb69d0e8f583b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b69d0e8f583b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b69d0e8f583b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@notadamking?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@notadamking?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Adam King"}, {"url": "https://medium.com/@notadamking/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "2.7K Followers"}, {"url": "https://www.patreon.com/notadamking", "anchor_text": "https://www.patreon.com/notadamking"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e3a5234f1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&user=Adam+King&userId=6e3a5234f1cc&source=post_page-6e3a5234f1cc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F77c80e888452&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b&newsletterV3=6e3a5234f1cc&newsletterV3Id=77c80e888452&user=Adam+King&userId=6e3a5234f1cc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}