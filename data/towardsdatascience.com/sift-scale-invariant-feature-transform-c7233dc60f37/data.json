{"url": "https://towardsdatascience.com/sift-scale-invariant-feature-transform-c7233dc60f37", "time": 1682995714.825494, "path": "towardsdatascience.com/sift-scale-invariant-feature-transform-c7233dc60f37/", "webpage": {"metadata": {"title": "SIFT(Scale-invariant feature transform) | by Minghao Ning | Towards Data Science", "h1": "SIFT(Scale-invariant feature transform)", "description": "SIFT is proposed by David G. Lowe in his paper. ( This paper is easy to understand, I recommend you to have a look at it ). As its name shows, SIFT has the property of scale invariance, which makes\u2026"}, "outgoing_paragraph_urls": [{"url": "https://people.eecs.berkeley.edu/~malik/cs294/lowe-ijcv04.pdf", "anchor_text": "paper", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Harris_Corner_Detector", "anchor_text": "Harris", "paragraph_index": 4}, {"url": "https://people.kth.se/~tony/papers/scsptheory-review.jas94.pdf", "anchor_text": "Tony Lindeberg\u2019s paper", "paragraph_index": 5}, {"url": "https://medium.com/lis-computer-vision-blogs/scale-invariant-feature-transform-sift-detector-and-descriptor-14165624a11", "anchor_text": "Li Yin\u2019s article", "paragraph_index": 10}, {"url": "http://www.cim.mcgill.ca/~langer/558/2009/lecture11.pdf", "anchor_text": "this tutorial pdf", "paragraph_index": 17}, {"url": "https://people.kth.se/~tony/papers/scsptheory-review.jas94.pdf", "anchor_text": "page 11", "paragraph_index": 31}, {"url": "https://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/IB-SIFT-extra-material.pdf", "anchor_text": "N Campbell\u2019s article", "paragraph_index": 36}, {"url": "https://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf", "anchor_text": "this pdf", "paragraph_index": 41}, {"url": "https://www.math.union.edu/~jaureguj/principal_curvatures.pdf", "anchor_text": "This pdf", "paragraph_index": 43}, {"url": "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c", "anchor_text": "blog about PCA", "paragraph_index": 46}], "all_paragraphs": ["I hope you will understand these after your reading\ud83e\udd14:", "SIFT is proposed by David G. Lowe in his paper. ( This paper is easy to understand, I recommend you to have a look at it ).", "In general, SIFT algorithm can be decomposed into four steps:", "And this article will also follow these steps.", "As its name shows, SIFT has the property of scale invariance, which makes it better than Harris. Harris is not scale-invariant, a corner may become an edge if the scale changes, as shown in the following image.", "So what is scale, and what does scale invariance mean?An excellent explanation is given in Tony Lindeberg\u2019s paper:", "An inherent property of objects in the world is that they only exist as meaningful entities over certain ranges of scale. A simple example is the concept of a branch of a tree, which makes sense only at a scale from, say, a few centimeters to at most a few meters. It is meaningless to discuss the tree concept at the nanometer or the kilometer level. At those scales it is more relevant to talk about the molecules that form the leaves of the tree, or the forest in which the tree grows. Similarly, it is only meaningful to talk about a cloud over a certain range of coarse scales. At finer scales it is more appropriate to consider the individual droplets, which in turn consist of water molecules, which consist of atoms, which consist of protons and electrons etc.", "The scale of an image landmark is its (rough) diameter in the image. It is denoted by \u03c3, which is measured in pixels, you can think scale invariance as that we can detect similar landmarks even if their scale is different.", "So how does SIFT achieves scale invariance?Do you still remember the pyramids?", "We can find the features under various image sizes.Besides, we can also use the Laplacian of Gaussian(LoG) with different \u03c3 to achieve this.", "Let\u2019s first have a look at LoG.As Li Yin\u2019s article indicates, the LoG operation goes like this. You take an image, and blur it a little (using Gaussian kernel). And then, you calculate the sum of second-order derivatives on it (or, the \u201cLaplacian\u201d). This locates edges and corners on the image. These edges and corners are good for finding keypoints (note that we want a keypoint detector, which means we will do some extra operations to suppress the edge). LoG is often used for blob detection (I will explain it later).Remember the relationship between convolution and differentiation.", "We can just convolve the image with the second derivatives of Gaussian, and sum them (or just convolve using LoG).", "Take a 1-D example, f is a scanline of an image (i.e. the pixel array from a line of an image).", "You can see that if we use LoG to detect the edge, we need to find the zero crossing the LoG response. Instead of finding the zero crossing, we can use LoG to detect the blob as we said above.", "Aha! We don\u2019t need to find the zero crossing anymore, we can find the extrema (maxima and minima) instead.However, the LoG is not truly scale invariant, you can find that: Laplacian response decays as scale increases:", "I will give you two ways to explain that:", "If you are satisfied with the above explanation and you are tired of struggling with some mathematical concepts, feel free to skip the following explanation.", "Another explanation is from this tutorial pdf.", "Consider a noise-free image edge I(x) = u(x \u2212 x0), u is the unit step function. To detect edges previously, we convolved them with a derivative of Gaussian and then looked for a peak in the response. Suppose we define a scale space by convolving I(x) with a family of the first derivative of Gaussian filters, where a family means we have a family of \u03c3.", "At the location of the edge x = x0, we have", "If we have a 2D image, then we define the normalized derivative filter in the same way, namely", "and similarly for y. Exactly the same arguments as above are used to show that thevalue at a horizontal or vertical edge will be independent of \u03c3. Using these filters, one defines the normalized gradient scale space in the obvious way, and one will find that the gradient at an edge of arbitrary orientation will be independent of \u03c3.Now here comes the second derivatesWe know that if we filter a (noise-free) edge, I(x) = u(x \u2212 x0), with the first derivative of a Gaussian then we get a peak response at the location of the edge. It follows immediately that if we were to filter the edge with the second derivative of a Gaussian", "then the response would be zero at the location of the edge.The second derivative of a Gaussian filter, and its 2D equivalent, have been very important in computer vision as well as in human vision modeling, and was the basis for an influential early theory of edge detection. The response of this filter to the edge image is:", "and note that the response is indeed 0 when x = x0, as we expect.Where do the peaks occur? Taking the derivative we get", "and set it to 0. The peak thus occurs when", "that is, x=x0\u00b1\u03c3. Substituting, we see that the value of the peak is", "As we did with the first derivative filter, we can normalize the second derivative filter by multiplying by \u03c32, so the normalized second derivative filter is defined.", "This cancels the \u03c3^(\u22122) dependence in the height of the peaks. Thus we see that if we filter an edge with a normalized second derivative of a Gaussian (as defined above), then there is a zero-crossing at the location of the edge and there are peaks (positive and negative) at a distance \u00b1\u03c3 away from the edge, but the height of the peaks doesn\u2019t depend on \u03c3.", "In summary, we need to multiply the LoG with \u03c32 to get the true scale invariance. Following is the result:", "Now we can detect the landmark at appropriate scale, it\u2019s really important because we need to describe this region in later steps, and we need to choose its surrounding region based on that scale, as shown in following:", "In practice, the Laplacian is approximated using a Difference of Gaussian (DoG).", "The relationship between DoG and \u03c32LoG can be understood from the heat diffusion equation (parameterized in terms of \u03c3 rather than the more usual t = \u03c32, you can see page 11 for more details:", "From this, we see that LoG can be computed from the finite difference approximation to \u2202G/\u2202\u03c3, using the difference of nearby scales at k\u03c3 and \u03c3:", "This shows that when the DoG function has scales differing by a constant factor it already incorporates the \u03c32 scale normalization required for the scale-invariant Laplacian. The factor (k \u2212 1) in the equation is a constant over all scales and therefore does not influence extrema location.", "Above all, SIFT combines the pyramids and different \u03c3-space to detect blobs under different scales.", "Note that the extrema are the maxima or minima around 3 dimensions (i.e. x,y,\u03c3).", "This part is mainly from N Campbell\u2019s article.After step 1, we detect some key-points which are coarsely localized, at best to the nearest pixel, dependent upon where the features were found in the scale-space. They are also poorly localized in scale since \u03c3 is quantized into relatively few steps in the scale-space. The second stage in the SIFT algorithm refines the location of these feature points to sub-pixel accuracy whilst simultaneously removing any poor features. The sub-pixel localization proceeds by fitting a Taylor expansion to fit a 3D quadratic surface (in x,y, and \u03c3) to the local area to interpolate the maxima or minima. Neglecting terms above the quadratic term, the expansion of the DoG is given in following where the derivatives are evaluated at the proposed point z0=[x0,y0,\u03c30]T and z=[\u03b4x,\u03b4y,\u03b4\u03c3]T is the offset from this point.", "The location of the extremum z\u02c6 is then determined by setting the derivative with respect to z equal to zeros:", "The parameters may be estimated using standard difference approximations from neighbouring sample points in the DoG resulting in a 3 \u00d7 3 linear system which may be solved efficiently. The process may need to be performed iteratively since if any of the computed offset values move by more than half a pixel it becomes necessary to reevaluate z^ since the appropriate neighborhood for the approximation will have changed. Points which to not converge quickly are discarded as unstable.The value at the localized extremum may be interpolated,", "and any points with a value below a certain threshold rejected as low contrast points.A final test is performed to remove any features located on edges in the image since these will suffer an ambiguity if used for matching purposes. A peak located on a ridge in the DoG (which corresponds to an edge in the image) will have a large principle curvature across the ridge and a low one along with it whereas a well-defined peak (blob) will have a large principle curvature in both directions. The Hessian H in x and y", "is evaluated for the feature point, again using a local difference approximation, and the ratio of the eigenvalues \u03bb1 and \u03bb2, which correspond to the principal curvatures, compared to a threshold ratio r as in", "and high ratio points rejected.This is a little similar to Harris, which cares about the derivate distribution of the region around the chosen point. (You can get more information from this pdf)", "However, the eigenvalues of Hessian H correspond to the principal curvatures. So how?", "This pdf gives an excellent explanation.Let\u2019s assume we have a surface M in R\u00b3 that is given by the graph of a smooth function z = f(x,y). Assume that M passes through the origin, p, and its tangent plane there is the {z = 0} plane (it\u2019s almost true for the detected blob, think about the sunflowers). Let N = (0,0,1), a unit normal to M at p.", "Let v be a unit vector in TpM, say v = (v1,v2,0). Let c be the parameterized curve given by slicing M through the plane spanned by v and N:", "Now we can calculate the curvature of c along the v = (v1,v2,0) direction. \u03bav is the reciprocal of the radius of the osculating circle to c at p.", "The principal curvatures of the surface at p will be the largest and smallest possible values \u03bb1,\u03bb2 of \u03bav (as v ranges over the possible unit tangent vectors). If you don\u2019t understand this argument, you can have a look at the excellent blog about PCA.", "Of course, we will use the Histogram of Oriented Gradient (HOG)", "An orientation histogram is formed from the gradient orientations of sample points within a region around the keypoint. The orientation histogram has 36 bins covering the 360-degree range of orientations. Each sample added to the histogram is weighted by its gradient magnitude and by a Gaussian-weighted circular window with a \u03c3 that is 1.5 times that of the scale of the keypoint.", "The final stage of the SIFT algorithm is to generate the descriptor which consists of a normalized 128-dimensional vector. At this stage of the algorithm, we are provided with a list of feature points which are described in terms of location, scale, and orientation. This allows us to construct a local coordinate system around the feature point which should be similar across different views of the same feature.The descriptor itself is a histogram formed from the gradient of the grayscale image. A 4\u00d74 spatial grid of gradient angle histograms is used. The dimensions of the grid are dependent on the feature point scale and the grid is centered on the feature point and rotated to the orientation determined for the keypoint. Each of the spatial bins contains an angle histogram divided into 8. (128=4\u00d74\u00d78). The image gradient magnitude and angle are again generated from the scale-space.", "The gradient angle at each pixel is then added to the corresponding angle bin in the appropriate spatial bin of the grid. The weight of each pixel is given by the magnitude of the gradient as well as a scale-dependent Gaussian (\u03c3 equal to one half the width of the descriptor window) centered on the feature point as shown as the blue circle. The purpose of this Gaussian window is to avoid sudden changes in the descriptor with small changes in the position of the window, and to give less emphasis to gradients that are far from the center of the descriptor, as these are most affected by misregistration errors.", "During the histogram formation, trilinear interpolation is used to add each value, that is an interpolation in x, y and \u03b8. This consists of interpolation of the weight of the pixel across the neighboring spatial bins based on distance to the bin centers as well as interpolation across the neighboring angle bins. The effect of the interpolation is demonstrated in the following figure.", "It is used to avoid all boundary effects in which the descriptor abruptly changes as a sample shifts smoothly from being within one histogram to another or from one orientation to another. Therefore, trilinear interpolation is used to distribute the value of each gradient sample into adjacent histogram bins. In other words, each entry into a bin is multiplied by a weight of 1 \u2212 d for each dimension, where d is the distance of the sample from the central value of the bin as measured in units of the histogram bin spacing.", "Finally, the feature vector is modified to reduce the effects of illumination change. First, the vector is normalized to unit length. A change in image contrast in which each pixel value is multiplied by a constant will multiply gradients by the same constant, so this contrast change will be canceled by vector normalization. A brightness change in which a constant is added to each image pixel will not affect the gradient values, as they are computed from pixel differences. Therefore, the descriptor is invariant to affine changes in illumination. However, non-linear illumination changes can also occur due to camera saturation or due to illumination changes that affect 3D surfaces with differing orientations by different amounts. These effects can cause a large change in relative magnitudes for some gradients, but are less likely to affect the gradient orientations. Therefore, we reduce the influence of large gradient magnitudes by thresholding the values in the unit feature vector to each be no larger than 0.2, and then renormalizing to unit length. This means that matching the magnitudes for large gradients is no longer as important, and that the distribution of orientations has greater emphasis. The value of 0.2 was determined experimentally using images containing differing illuminations for the same 3D objects.", "That\u2019s all, I really hope that this article will help you understand the SIFT algorithm. Because I am still a learner of Computer Vision, if you have any questions or suggestions, feel free to contact me. I will be really happy if you can point out my mistake. \ud83e\udd2a", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "The top is still spinning perfectly, as if it will never topple."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc7233dc60f37&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@MinghaoNing?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MinghaoNing?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Minghao Ning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b4ecb9c2828&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&user=Minghao+Ning&userId=5b4ecb9c2828&source=post_page-5b4ecb9c2828----c7233dc60f37---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://people.eecs.berkeley.edu/~malik/cs294/lowe-ijcv04.pdf", "anchor_text": "paper"}, {"url": "https://en.wikipedia.org/wiki/Harris_Corner_Detector", "anchor_text": "Harris"}, {"url": "https://people.kth.se/~tony/papers/scsptheory-review.jas94.pdf", "anchor_text": "Tony Lindeberg\u2019s paper"}, {"url": "https://medium.com/lis-computer-vision-blogs/scale-invariant-feature-transform-sift-detector-and-descriptor-14165624a11", "anchor_text": "Li Yin\u2019s article"}, {"url": "http://www.cim.mcgill.ca/~langer/558/2009/lecture11.pdf", "anchor_text": "this tutorial pdf"}, {"url": "https://people.kth.se/~tony/papers/scsptheory-review.jas94.pdf", "anchor_text": "page 11"}, {"url": "https://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/IB-SIFT-extra-material.pdf", "anchor_text": "N Campbell\u2019s article"}, {"url": "https://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf", "anchor_text": "this pdf"}, {"url": "https://www.math.union.edu/~jaureguj/principal_curvatures.pdf", "anchor_text": "This pdf"}, {"url": "https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c", "anchor_text": "blog about PCA"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----c7233dc60f37---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/feature-detection?source=post_page-----c7233dc60f37---------------feature_detection-----------------", "anchor_text": "Feature Detection"}, {"url": "https://medium.com/tag/sift?source=post_page-----c7233dc60f37---------------sift-----------------", "anchor_text": "Sift"}, {"url": "https://medium.com/tag/feature-description?source=post_page-----c7233dc60f37---------------feature_description-----------------", "anchor_text": "Feature Description"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----c7233dc60f37---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&user=Minghao+Ning&userId=5b4ecb9c2828&source=-----c7233dc60f37---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&user=Minghao+Ning&userId=5b4ecb9c2828&source=-----c7233dc60f37---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc7233dc60f37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c7233dc60f37---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c7233dc60f37--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c7233dc60f37--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c7233dc60f37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MinghaoNing?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@MinghaoNing?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Minghao Ning"}, {"url": "https://medium.com/@MinghaoNing/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "102 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5b4ecb9c2828&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&user=Minghao+Ning&userId=5b4ecb9c2828&source=post_page-5b4ecb9c2828--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5d4e3f36a8fb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsift-scale-invariant-feature-transform-c7233dc60f37&newsletterV3=5b4ecb9c2828&newsletterV3Id=5d4e3f36a8fb&user=Minghao+Ning&userId=5b4ecb9c2828&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}