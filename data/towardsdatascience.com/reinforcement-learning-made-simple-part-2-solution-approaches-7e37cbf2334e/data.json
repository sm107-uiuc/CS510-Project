{"url": "https://towardsdatascience.com/reinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e", "time": 1683015612.523194, "path": "towardsdatascience.com/reinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e/", "webpage": {"metadata": {"title": "Reinforcement Learning Made Simple (Part 2): Solution Approaches | by Ketan Doshi | Towards Data Science", "h1": "Reinforcement Learning Made Simple (Part 2): Solution Approaches", "description": "A Gentle Overview of Model-based and Model-free solutions, as well as RL Prediction and Control. Key insights about the Bellman Equation, in Plain English."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["This is the second article in my series on Reinforcement Learning (RL). Now that we understand what an RL Problem is, let\u2019s look at the approaches used to solve it.", "Here\u2019s a quick summary of the previous and following articles in the series. My goal throughout will be to understand not just how something works but why it works that way.", "\u2018Solving\u2019 a Reinforcement Learning problem basically amounts to finding the Optimal Policy (or Optimal Value). There are many algorithms, which we can group into different categories.", "Model-based approaches are used when the internal operation of the environment is known. In other words, we can reliably say what Next State and Reward will be output by the environment when some Action is performed from some Current State.", "Model-free approaches are used when the environment is very complex and its internal dynamics are not known. They treat the environment as a black-box.", "Another high-level distinction is between Prediction and Control.", "With a Prediction problem, we are given a Policy as input, and the goal is to output the corresponding Value function. This could be any Policy, not necessarily an Optimal Policy.", "With a Control problem, no input is provided, and the goal is to explore the policy space and find the Optimal Policy.", "Most practical problems are Control problems, as our goal is to find the Optimal Policy.", "The most common RL Algorithms can be categorized as below:", "Most interesting real-world RL problems are model-free control problems. So we will not explore model-based solutions further in this series other than briefly touching on them below. Everything we discuss from here on pertains only to model-free control solutions.", "Because they can produce the exact outcome of every state and action interaction, model-based approaches can find a solution analytically without actually interacting with the environment.", "As an example, with a model-based approach to play chess, you would program in all the rules and strategies of the game of chess. On the other hand, a model-free algorithm would know nothing about the game of chess itself. Its only knowledge would be generic information such as how states are represented and what actions are possible. It learns about chess only in an abstract sense by observing what reward it obtains when it tries some action.", "Most real-world problems are model-free because the environment is usually too complex to build a model.", "Model-free solutions, by contrast, are able to observe the environment\u2019s behavior only by actually interacting with it.", "Since the internal operation of the environment is invisible to us, how does the model-free algorithm observe the environment\u2019s behavior?", "We learn how it behaves by interacting with it, one action at a time. The algorithm acts as the agent, takes an action, observes the next state and reward, and repeats.", "The agent acquires experience through trial and error. It tries steps and receives positive or negative feedback. This is much the same as a human would learn.", "As the agent takes each step, it follows a path (ie. trajectory).", "The agent\u2019s trajectory becomes the algorithm\u2019s \u2018training data\u2019.", "Before we get into the algorithms used to solve RL problems, we need a little bit of math to make these concepts more precise.", "The math is actually quite intuitive \u2014 it is all based on one simple relationship known as the Bellman Equation.", "This relationship is the foundation for all the RL algorithms. This equation has several forms, but they are all based on the same basic idea. Let\u2019s go through this step-by-step to build up the intuition for it.", "Consider the reward by taking an action from a state to reach a terminal state.", "The return from that state is the same as the reward obtained by taking that action. Remember that Reward is obtained for a single action, while Return is the cumulative discounted reward obtained from that state onward (till the end of the episode).", "Now consider the previous state S6. The return from S6 is the reward obtained by taking the action to reach S7 plus any discounted return that we would obtain from S7. The important thing is that we no longer need to know the details of the individual steps taken beyond S7.", "In general, the return from any state can be decomposed into two parts \u2014 the immediate reward from the action to reach the next state, plus the Discounted Return from that next state by following the same policy for all subsequent steps. This recursive relationship is known as the Bellman Equation.", "Return is the discounted reward for a single path. State Value is obtained by taking the average of the Return over many paths (ie. the Expectation of the Return).", "So State Value can be similarly decomposed into two parts \u2014 the immediate reward from the next action to reach the next state, plus the Discounted Value of that next state by following the policy for all subsequent steps.", "Similarly, the State-Action Value can be decomposed into two parts \u2014 the immediate reward from that action to reach the next state, plus the Discounted Value of that next state by following the policy for all subsequent steps.", "There are two key observations that we can make from the Bellman Equation.", "The first point is that, in order to compute the Return, we don\u2019t have to go all the way to the end of the episode. Episodes can be very long (and expensive to traverse), or they could be never-ending. Instead, we can use this recursive relationship.", "If we know the Return from the next step, then we can piggy-back on that. We can take just a single step, observe that reward, and then re-use the subsequent Return without traversing the whole episode beyond that.", "The second point is that there are two ways to compute the same thing:", "Since it is very expensive to measure the actual Return from some state (to the end of the episode), we will instead use estimated Returns. Then we compute these estimates in two ways and check how correct our estimates are by comparing the two results.", "Since these are estimates and not exact measurements, the results from those two computations may not be equal. The difference tells us how much \u2018error\u2019 we made in our estimates. This helps us improve our estimates by revising them in a way that reduces that error.", "Hang on to both these ideas because all the RL algorithms will make use of them.", "Now that we have an overall idea about what an RL problem is, and the broad landscape of approaches used to solve them, we are ready to go deeper into the techniques used to solve them. Since real-world problems are most commonly tackled with model-free approaches, that is what we will focus on. They will be the topic of the next article.", "And finally, if you liked this article, you might also enjoy my other series on Transformers as well as Audio Deep Learning."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7e37cbf2334e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://ketanhdoshi.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Ketan Doshi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54f9ca55ed47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=post_page-54f9ca55ed47----7e37cbf2334e---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e37cbf2334e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----7e37cbf2334e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e37cbf2334e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=-----7e37cbf2334e---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://unsplash.com/@drscythe?utm_source=medium&utm_medium=referral", "anchor_text": "Dominik Scythe"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/reinforcement-learning-made-simple-part-1-intro-to-basic-concepts-and-terminology-1d2a87aa060", "anchor_text": "Intro to Basic Concepts and Terminology"}, {"url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-3-model-free-solutions-step-by-step-c4bbb2b72dcf", "anchor_text": "Model-free algorithms"}, {"url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-4-q-learning-step-by-step-b65efb731d3e", "anchor_text": "Q-Learning"}, {"url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b", "anchor_text": "Deep Q Networks"}, {"url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-6-policy-gradients-step-by-step-f9f448e73754", "anchor_text": "Policy Gradient"}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452", "anchor_text": "Transformers Explained Visually (Part 1): Overview of FunctionalityA Gentle Guide to Transformers for NLP, and why they are better than RNNs, in Plain English. How Attention helps\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504", "anchor_text": "Audio Deep Learning Made Simple (Part 1): State-of-the-Art TechniquesA Gentle Guide to the world of disruptive deep learning audio applications and architectures. And why we all need to\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----7e37cbf2334e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7e37cbf2334e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7e37cbf2334e---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7e37cbf2334e---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----7e37cbf2334e---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e37cbf2334e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----7e37cbf2334e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e37cbf2334e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----7e37cbf2334e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e37cbf2334e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54f9ca55ed47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=post_page-54f9ca55ed47----7e37cbf2334e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fae94feabe1c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&newsletterV3=54f9ca55ed47&newsletterV3Id=ae94feabe1c9&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----7e37cbf2334e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Written by Ketan Doshi"}, {"url": "https://ketanhdoshi.medium.com/followers?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "4K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F54f9ca55ed47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&user=Ketan+Doshi&userId=54f9ca55ed47&source=post_page-54f9ca55ed47----7e37cbf2334e---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fae94feabe1c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e&newsletterV3=54f9ca55ed47&newsletterV3Id=ae94feabe1c9&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----7e37cbf2334e---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Ketan Doshi"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Transformers Explained Visually (Part 3): Multi-head Attention, deep diveA Gentle Guide to the inner workings of Self-Attention, Encoder-Decoder Attention, Attention Score and Masking, in Plain English."}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "11 min read\u00b7Jan 17, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c1ff1024853&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----1c1ff1024853----0-----------------clap_footer----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853?source=author_recirc-----7e37cbf2334e----0---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "19"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c1ff1024853&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853&source=-----7e37cbf2334e----0-----------------bookmark_preview----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----7e37cbf2334e----1---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----7e37cbf2334e----1-----------------bookmark_preview----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----7e37cbf2334e----2---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----7e37cbf2334e----2-----------------bookmark_preview----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Ketan Doshi"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "Transformers Explained Visually (Part 1): Overview of FunctionalityA Gentle Guide to Transformers for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance."}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": "10 min read\u00b7Dec 13, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95a6dd460452&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-explained-visually-part-1-overview-of-functionality-95a6dd460452&user=Ketan+Doshi&userId=54f9ca55ed47&source=-----95a6dd460452----3-----------------clap_footer----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452?source=author_recirc-----7e37cbf2334e----3---------------------0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "10"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95a6dd460452&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-explained-visually-part-1-overview-of-functionality-95a6dd460452&source=-----7e37cbf2334e----3-----------------bookmark_preview----0c6156f5_b77e_4b92_aacf_b34f6ad7e48d-------", "anchor_text": ""}, {"url": "https://ketanhdoshi.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "See all from Ketan Doshi"}, {"url": "https://towardsdatascience.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----7e37cbf2334e----0-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----1-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----7e37cbf2334e----1-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Trust Region Policy Optimization (TRPO) ExplainedThe Reinforcement Learning algorithm TRPO builds upon natural policy gradient algorithms, ensuring updates remain within \u2018trustworthy\u2019\u2026"}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b712 min read\u00b7Oct 12, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----4b56bd206fc2----0-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/trust-region-policy-optimization-trpo-explained-4b56bd206fc2?source=read_next_recirc-----7e37cbf2334e----0---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4b56bd206fc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrust-region-policy-optimization-trpo-explained-4b56bd206fc2&source=-----7e37cbf2334e----0-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----7e37cbf2334e----1---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----7e37cbf2334e----1-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----2-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----7e37cbf2334e----2---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----7e37cbf2334e----2-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----3-----------------clap_footer----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----7e37cbf2334e----3---------------------bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----7e37cbf2334e----3-----------------bookmark_preview----bed44a5d_5c9a_4744_8ab2_cb869a0bf18c-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----7e37cbf2334e--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}