{"url": "https://towardsdatascience.com/bidirectional-attention-flow-model-for-machine-comprehension-d533f5600007", "time": 1683003755.109427, "path": "towardsdatascience.com/bidirectional-attention-flow-model-for-machine-comprehension-d533f5600007/", "webpage": {"metadata": {"title": "BiDirectional Attention Flow Model for Machine Comprehension | by Praphul Singh | Towards Data Science", "h1": "BiDirectional Attention Flow Model for Machine Comprehension", "description": "Question Answering has been a major area of work in Natural Language Processing. I will be discussing as well as implementing the key elements of a research paper which does significantly well on QA\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1611.01603.pdf", "anchor_text": "Bidirectional Attention Flow For Machine Comprehension", "paragraph_index": 1}], "all_paragraphs": ["Question Answering has been a major area of work in Natural Language Processing. I will be discussing as well as implementing the key elements of a research paper which does significantly well on QA related problems. So, What do we do in Question Answering? We are given a context and a query is asked based on that context. The task of the model is to find an accurate answer to the problem. The answer may or may not be present in the context itself. If it is present, the task can be formulated as a classification problem and if it is not present, then we move to a much tougher text-generation problem. But for all of that, we need a fine feature vector which contains the information from context and query and their relationship.", "The paper which I will be talking about is Bidirectional Attention Flow For Machine Comprehension by Minjoon Seo et al. We will be discussing mainly the technical segments of the architecture and will be implementing those sections sequentially. Overall, it will mostly be code writing with lesser text here. Given below is the architecture of BiDAF.", "As given in the figure, the text representation in the model is done by first using a character level embedding layer and then word-level embeddings like Glove or Word2vec. Finally, both the representations are concatenated together to get the final representation. For simplicity, we can only use word-level Glove Embeddings in the code.", "Once we get the vector representation for each word in the text sequence, we will feed the sequence in a bidirectional LSTM layer to get fine contextual representations. One important thing which is not shown in the figure is the Highway Networks. Since I have not mentioned this term in any of my previous blogs, we will discuss it briefly before moving to the implementation part.", "Imagine a network having a very deep structure including multiple stacks of NN Layers. Optimizing a model with a larger depth is difficult with gradient descent. Also, if multiple stacks are used information loss is observed because of multiplication of too many variables having absolute values less than 1. Thus, increasing the depth of the model beyond a certain point did not benefit the results earlier.", "Inspired by LSTMs, Highway Networks was proposed in which a gating mechanism is used to propagate information directly to the next layers(thus the term HIGHWAY). The structure for the same is shown below:", "A transform gate, T is introduced which is nothing but a neural network followed by a sigmoid activation. It means the transform gate will produce a probability which gets multiplied with the output of the current layer and is propagated to the next layer. The linear gate, C is nothing but 1-T, which is the probability to be multiplied with the input of the current layer and passed in the next layer. A variant of Highway Networks, Residual Networks where C and T both are equal to 1, is used in the famous image classification model by Microsoft, ResNet. Results show that it is now possible to have a model with 100s of layers using Highway Networks for complex problems.", "In this blog, we will also be using Highway Networks for each bidirectional LSTM to have a robust information flow.", "Normally, Attention Mechanism is used to summarize the context vector for the query. But here, a shared Similarity Matrix is computed by using the context and query representation and instead of computing single attention for the query, Attention in both direction, i.e., Context2Query and Query2Context is computed for maximizing the information gain. Similarity Matrix is a matrix of shape TxJ where T is the sequence length of Context and J is the sequence length of Query. Both the attentions can be computed by the shared Similarity Matrix. The entire computing mechanism is shown in the figure below:", "It can be seen that to compute S_ij, the input is C_i and Q_j and the formula for that is as follows:", "where [;] is the concatenation operation across the row and [o] is element-wise multiplication operation and W_ij is a trainable weight vector of size [1 x 3 * dim].", "Context2Query Attention signifies the important words in the query sentence for each context word. That means the Context2Query should be of a shape, [TxJ] which can be done just by taking the softmax of similarity Matrix row-wise:", "Query2Context Attention signifies the most similar words in the context sentence for each query word. This is obtained by first taking a maximum element from the Similarity matrix and then applying softmax on it. Thus the final output is a probability vector of shape = [Tx1].", "Attended Context = Q2C TContext, shape=[1xdim]", "The final Attended Context, AC = tile(Attended Context, T), shape = [Txdim]", "This operation is used to combine the information obtained by the attentions C2Q and Q2C. The merge operation takes the original context(OC), attended query and attended context as inputs and gives a final representation as shown below:", "Merge(OC, AQ, AC) = [OC ; AQ ; OC o AQ ; OC o AC] , where [;] is row-wise concatenation and [o] is element-wise multiplication.", "Merger Layer gives us an output of shape = [T x 4 * dim], which can be further used to feed into another set of bidirectional LSTMs followed by a softmax to get the start and end probabilities of the answer. The start and end probabilities are the probabilities of start and end index of the answer in the given paragraph. As earlier discussed, the concept of start and end probabilities will work only if the answer lies within the paragraph. If it does not, we have feed the final representation to a decoder to make it a sequence generation problem.", "Whoo! I did not keep my promise of keeping the discussion short and sticking mainly to the coding part \ud83d\ude00. Anyways, let us do some PYTHONING now(Google\u2019s Meena told me about this word).", "The only thing remains now is to apply these snippets into one\u2019s use case. I hope I did not bore you(definitely not, if you are reading this line).", "We have now discussed the technical aspects and implementation of various sections of a BiDAF model. Now, let us wade through an example of how this attention mechanism comes up with the answers for a particular question.", "In the image shown above, the blocks given is the attention matrix visualisation of two questions. Each column of the matrix denotes the context words in the paragraph while each row represents the words in the question vector. The bolder the block, the more its attention weights are. In the block 1, it is clearly visible that for the word, \u201cWhere\u201d in the question, more weights are given to the words, \u201cat, the, stadium, Levi, in, Santa, Ana\u201d. Even it can focus on the question mark, \u2018?\u2019 which attends more on the \u201cinitiatives\u201d word.", "From the results perspective, BiDAF was tested against SQUAD, CNN/DailyMail datasets and the results were outstanding as follows:", "If you wish to read more about the topics, there is nothing better than the research papers themselves.", "I hope you liked the blog and if you have any suggestions for me or you feel like connecting, you can click on the links below:", "Now its time for the signature Line,", "Deep Learning Engineer, Oracle, IIT Kanpur"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd533f5600007&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://praps.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Praphul Singh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc7195a3db54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=post_page-c7195a3db54d----d533f5600007---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd533f5600007&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=-----d533f5600007---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd533f5600007&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=-----d533f5600007---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/pdf/1611.01603.pdf", "anchor_text": "Bidirectional Attention Flow For Machine Comprehension"}, {"url": "https://allenai.github.io/bi-att-flow/BiDAF.png", "anchor_text": "https://allenai.github.io/bi-att-flow/BiDAF.png"}, {"url": "https://miro.medium.com/max/1120/1*qHf_AHv8yJJsKQok4KS4Jw.png", "anchor_text": "https://miro.medium.com/max/1120/1*qHf_AHv8yJJsKQok4KS4Jw.png"}, {"url": "https://arxiv.org/pdf/1611.01603.pdf", "anchor_text": "https://arxiv.org/pdf/1611.01603.pdf"}, {"url": "https://arxiv.org/abs/1505.00387", "anchor_text": "https://arxiv.org/abs/1505.00387"}, {"url": "https://www.linkedin.com/in/spraphul555/", "anchor_text": "https://www.linkedin.com/in/spraphul555/"}, {"url": "https://spraphul.github.io/blog/bidaf", "anchor_text": "https://spraphul.github.io"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d533f5600007---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----d533f5600007---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d533f5600007---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/attention?source=post_page-----d533f5600007---------------attention-----------------", "anchor_text": "Attention"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd533f5600007&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=-----d533f5600007---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd533f5600007&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=-----d533f5600007---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd533f5600007&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc7195a3db54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=post_page-c7195a3db54d----d533f5600007---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fc7195a3db54d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=-----d533f5600007---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Written by Praphul Singh"}, {"url": "https://praps.medium.com/followers?source=post_page-----d533f5600007--------------------------------", "anchor_text": "7 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc7195a3db54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=post_page-c7195a3db54d----d533f5600007---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fc7195a3db54d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbidirectional-attention-flow-model-for-machine-comprehension-d533f5600007&user=Praphul+Singh&userId=c7195a3db54d&source=-----d533f5600007---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Praphul Singh"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/generating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Generating Handwritten Sequences Using LSTMs and Mixed Density NetworksAs everyone comes up with a resolution at the start of the year, I would be trying to be more infrequent in my blog postings\ud83d\ude00. As it has\u2026"}, {"url": "https://towardsdatascience.com/generating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "7 min read\u00b7Jan 25, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc3a2b4a65539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539&user=Praphul+Singh&userId=c7195a3db54d&source=-----c3a2b4a65539----0-----------------clap_footer----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/generating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539?source=author_recirc-----d533f5600007----0---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc3a2b4a65539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerating-handwritten-sequences-using-lstms-and-mixed-density-networks-c3a2b4a65539&source=-----d533f5600007----0-----------------bookmark_preview----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----d533f5600007----1---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----d533f5600007----1-----------------bookmark_preview----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----d533f5600007----2---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d533f5600007----2-----------------bookmark_preview----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/decide-better-subconsciously-8be5a458745c?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Praphul Singh"}, {"url": "https://praps.medium.com/decide-better-subconsciously-8be5a458745c?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "Decide better, SubconsciouslyIntroduction"}, {"url": "https://praps.medium.com/decide-better-subconsciously-8be5a458745c?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": "5 min read\u00b7Jan 16, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F8be5a458745c&operation=register&redirect=https%3A%2F%2Fpraps.medium.com%2Fdecide-better-subconsciously-8be5a458745c&user=Praphul+Singh&userId=c7195a3db54d&source=-----8be5a458745c----3-----------------clap_footer----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/decide-better-subconsciously-8be5a458745c?source=author_recirc-----d533f5600007----3---------------------205db85a_afc1_439f_99d1_dbc69871bf01-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8be5a458745c&operation=register&redirect=https%3A%2F%2Fpraps.medium.com%2Fdecide-better-subconsciously-8be5a458745c&source=-----d533f5600007----3-----------------bookmark_preview----205db85a_afc1_439f_99d1_dbc69871bf01-------", "anchor_text": ""}, {"url": "https://praps.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "See all from Praphul Singh"}, {"url": "https://towardsdatascience.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----d533f5600007----0-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----d533f5600007----1-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----0-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----d533f5600007----0---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----d533f5600007----0-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----1-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----d533f5600007----1---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----d533f5600007----1-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----d533f5600007----2---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----d533f5600007----2-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----3-----------------clap_footer----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----d533f5600007----3---------------------93145e16_8eda_4829_a15c_4741f8caac04-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----d533f5600007----3-----------------bookmark_preview----93145e16_8eda_4829_a15c_4741f8caac04-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d533f5600007--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----d533f5600007--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}