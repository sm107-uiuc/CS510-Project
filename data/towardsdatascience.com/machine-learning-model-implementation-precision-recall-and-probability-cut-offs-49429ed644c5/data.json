{"url": "https://towardsdatascience.com/machine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5", "time": 1683013308.544139, "path": "towardsdatascience.com/machine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5/", "webpage": {"metadata": {"title": "Machine Learning Model Implementation: Precision/Recall and Probability Cut-offs | by Katey Durham | Towards Data Science", "h1": "Machine Learning Model Implementation: Precision/Recall and Probability Cut-offs", "description": "Congratulations on completing your Machine Learning (ML) pipeline! In the second part of this series, I\u2019ll talk about some metrics and graphics beyond the area under the ROC curve that can be helpful\u2026"}, "outgoing_paragraph_urls": [{"url": "https://vivapredict.com", "anchor_text": "https://vivapredict.com", "paragraph_index": 12}, {"url": "https://vivajams.com", "anchor_text": "https://vivajams.com", "paragraph_index": 12}, {"url": "https://vivamash.com", "anchor_text": "https://vivamash.com", "paragraph_index": 12}], "all_paragraphs": ["Congratulations on completing your Machine Learning (ML) pipeline! In the second part of this series, I\u2019ll talk about some metrics and graphics beyond the area under the ROC curve that can be helpful in choosing which model or models we\u2019d like to move forward and implement in practice, keeping our project\u2019s objectives in mind. Specifically, in this article we\u2019ll:", "1. Discuss why the Precision/Recall trade-off might be the optimal framework for many problems, and2. Display graphics and summaries that can turn a predictive modeling exercise into something highly impactful for decision making in practice.", "It\u2019s likely you\u2019ve seen Recall before if you have been working with classification problems, because it\u2019s also known as Sensitivity. To review, say we are interested in predicting a 2-class event, Win or Lose. Then Recall = Sensitivity = the probability that a true Win is predicted as a Win; essentially it\u2019s the proportion of true Wins that we successfully capture in the predicted Win bucket. Next, Precision is aka Positive Predicted Value (PPV), which I find a bit more descriptive. For PPV we\u2019re flipping things around, saying: Okay, of the predicted Wins that I have in that bucket, which ones are actually true Wins. Of course both of these are important: we\u2019d like to capture all the true Wins in our predicted Win bucket, and also for all the predicted Wins to turn out to be true Wins. But as you\u2019d expect, these will be somewhat at odds with each other, and their trade-off is captured in the Precision \u2014 Recall (PR) curve. We can compute the area under this curve (AUC) just as we compute the AUC for the ROC curve. While the ROC curve has a reference diagonal line from 0 to 1, indicating a model performance equal to flipping a coin, the reference for the AUC PR curve is a horizontal line representing the frequency of true Wins.", "Now that we understand the Precision \u2014 Recall trade-off, why would it be important? In many classification problems, there is an event of greater interest, or one that is associated with a greater cost or reward, than the other outcome. So while the AUC ROC curve is important, the AUC PR curve may be more germane to model performance and selection for many prediction problems. At this point you might say, \u2018You\u2019ve been talking about a trade-off, but how do I make these trades?\u2019 It is by varying the probability cut-off level that we require to call something a \u2018Win.\u2019 The lower this level is set, the higher the Sensitivity/Recall (\u2018We\u2019ve correctly captured most of the true Wins as predicted Wins\u2019) but there may be many false-positives. The higher the cut-off, the higher the Precision/PPV (\u2018Most of the predicted Wins are actually true Wins\u2019) but a large number of true Wins will not be classified as such (false-negatives). Alright, before this discussion becomes too abstract, let\u2019s continue with an example.", "In this article I\u2019ll be using results from 7 Machine Learning (ML) models that analyzed the German Credit classification data available in the R caret package. It consists of 1000 observations of individuals determined to have either Good (n=700) or Bad (n=300) credit. The are 61 predictors that cover a variety of factors that may have to do with credit, such as loan features, banking information, demographics, employment, etc. The data were separated into a 70%-30% training-test split, preserving the 70% Good credit frequency in both. The training set was split into 5 CV sets, repeated 5 times, to determine optimal tuning parameters. Modeling was done using the caret package in R. The models fit were the following:", "* Linear Discriminant Analysis (LDA)* Partial Least Squares (PLS)* Support Vector Machines (SVM, with radial kernel function)* Neural Network (NN)* Recursive Partitioning (Rpart, single tree) * Random Forests (RF)* Gradient Boosting Machines (GBM)", "Below are both the AUC ROC and AUC PR curves for the seven ML learning fits applied to the hold-out test set (i.e. not involved in the model cross-validation). With the exception of the single tree Rpart model, the model performance in the test set is similar across the fits. Looking at an actual Precision \u2014 Recall curve, the trade-off becomes apparent: when our Recall or Sensitivity is low, we are not correctly predicting many of the Good credit subjects, but those we are classifying as Good are mostly actually Good. This corresponds to using a high value for the probability cut-off for \u2018Good\u2019. As we decrease the probability cut-off, the Sensitivity/Recall improves, but at the cost of the Precision/PPV (Many of the predicted Good credit subjects actually have Bad Credit).", "The data in the German Credit problem is an example of a lopsided classification penalty structure. In this case, it\u2019s worse to classify a subject as having Good credit when their credit is actually Bad. This may result in someone receiving a loan or credit card on which they are likely to default. On the other hand, it is profitable to make loans and issue credit to those who are capable of fulfilling the credit terms, but not as much is made from a successful loan as is lost from an unsuccessful one.", "Another intuitive way to visualize the effects of different cut-offs on the necessary trade-offs is to examine the distributions of predicted probabilities on our test data by their ground truth. An example is shown below; the Rpart model has been removed to improve the figure scaling, and the vertical green line represents a potential cut-off that could be used to determine model-predicted positives (here it\u2019s 0.7). This type of figure allows regions of true and false positives to be displayed in a way that is easily digestible. It\u2019s clear from the plot that the models will require different probability cut-offs to achieve the same performance. For example, the PLS model will require lower cut-offs to achieve similar Sensitivity and PPV as the others. Another insight from this figure is that all but the highest cut-offs will retain some false-positives, and for some models they may be impossible to eliminate completely.", "After we have the big picture, we can dive a bit more into the details, examining the models for the desired sweet spot to meet our objectives. For example, if a PPV value of 76% were tolerable (i.e. 24% false positives), the RF model indicates this could be achieved at a Sensitivity of 93% using a cut-off of 0.5. (Note that these values should be viewed as estimates, taken from the one test sample. An alternative could involve computing these for each CV holdout sample and examining their distribution). However, this false positive rate may be too high, and if we\u2019re less concerned with missing out on the true positives, we might prefer the other end of the spectrum. The PLS model at a cut-off of 0.7 would only capture 22% of the true positives, but 95% of those classified as positive would truly be so. The nature of our risk function along with the practical constraints associated with our model implementation can lead us to the optimal choice. In the credit example, expected gains and losses in dollars (or euros) could be assumed for Good and Bad credit and computed for each cut-off option.", "In conclusion, strategically considering Precision-Recall, predicted probability distributions and an analysis of model performance at different cut-offs together with how the model we develop will be used in practice will lead to machine learning pipelines that have a real opportunity to impact larger business goals and objectives.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Predictive Analyst who uses models and intuition https://vivapredict.com ~ NFT jams https://vivajams.com ~ Mashing it all up at https://vivamash.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F49429ed644c5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://vivamashup.medium.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": ""}, {"url": "https://vivamashup.medium.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Katey Durham"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F218a7a5db639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&user=Katey+Durham&userId=218a7a5db639&source=post_page-218a7a5db639----49429ed644c5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----49429ed644c5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----49429ed644c5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-science-training?source=post_page-----49429ed644c5---------------data_science_training-----------------", "anchor_text": "Data Science Training"}, {"url": "https://medium.com/tag/statistical-learning?source=post_page-----49429ed644c5---------------statistical_learning-----------------", "anchor_text": "Statistical Learning"}, {"url": "https://medium.com/tag/r?source=post_page-----49429ed644c5---------------r-----------------", "anchor_text": "R"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&user=Katey+Durham&userId=218a7a5db639&source=-----49429ed644c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&user=Katey+Durham&userId=218a7a5db639&source=-----49429ed644c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F49429ed644c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----49429ed644c5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----49429ed644c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----49429ed644c5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----49429ed644c5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----49429ed644c5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----49429ed644c5--------------------------------", "anchor_text": ""}, {"url": "https://vivamashup.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://vivamashup.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Katey Durham"}, {"url": "https://vivamashup.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "135 Followers"}, {"url": "https://vivapredict.com", "anchor_text": "https://vivapredict.com"}, {"url": "https://vivajams.com", "anchor_text": "https://vivajams.com"}, {"url": "https://vivamash.com", "anchor_text": "https://vivamash.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F218a7a5db639&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&user=Katey+Durham&userId=218a7a5db639&source=post_page-218a7a5db639--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F7eed018d11f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-model-implementation-precision-recall-and-probability-cut-offs-49429ed644c5&newsletterV3=218a7a5db639&newsletterV3Id=7eed018d11f8&user=Katey+Durham&userId=218a7a5db639&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}