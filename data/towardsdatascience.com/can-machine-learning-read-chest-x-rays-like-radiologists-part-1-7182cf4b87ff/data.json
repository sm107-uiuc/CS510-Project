{"url": "https://towardsdatascience.com/can-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff", "time": 1682996809.8239748, "path": "towardsdatascience.com/can-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff/", "webpage": {"metadata": {"title": "Can AI Read Chest X-rays like Radiologists? | by David W. Dai | Towards Data Science", "h1": "Can AI Read Chest X-rays like Radiologists?", "description": "Today, only about 10% of 7B population in the world have access to good healthcare service, and half of the world don\u2019t even access to essential health services. Even among the developed countries\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.who.int/news-room/detail/13-12-2017-world-bank-and-who-half-the-world-lacks-access-to-essential-health-services-100-million-still-pushed-into-extreme-poverty-because-of-health-expenses", "anchor_text": "half of the world", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1703.08770", "anchor_text": "paper", "paragraph_index": 2}, {"url": "https://radiopaedia.org/articles/chest-radiograph-assessment-using-abcdefghi?lang=us", "anchor_text": "ABCDEFGHI", "paragraph_index": 6}, {"url": "https://www.rcr.ac.uk/system/files/publication/field_publication_files/clinical-radiology-uk-workforce-census-report-2018.pdf", "anchor_text": "report", "paragraph_index": 8}, {"url": "https://my.clevelandclinic.org/health/diseases/17373-pleural-effusion-causes-signs--treatment", "anchor_text": "pleural effusion", "paragraph_index": 10}, {"url": "https://link.springer.com/chapter/10.1007/978-3-030-00934-2_61", "anchor_text": "follow-up work", "paragraph_index": 14}, {"url": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10134/101340K/Automatic-estimation-of-heart-boundaries-and-cardiothoracic-ratio-from-chest/10.1117/12.2254136.short?SSO=1", "anchor_text": "Dallal et al 2017", "paragraph_index": 14}, {"url": "https://openreview.net/forum?id=Bygh9j09KX", "anchor_text": "rich textures", "paragraph_index": 19}, {"url": "https://towardsdatascience.com/can-machine-learning-read-chest-x-rays-like-radiologists-part-2-aa77dba219f0", "anchor_text": "Part 2", "paragraph_index": 26}, {"url": "https://www.apple.com/", "anchor_text": "Apple", "paragraph_index": 27}, {"url": "http://wayfinder.ai", "anchor_text": "Wayfinder AI", "paragraph_index": 27}, {"url": "http://petuum.com", "anchor_text": "Petuum", "paragraph_index": 27}, {"url": "https://twitter.com/daiwei89", "anchor_text": "@daiwei89", "paragraph_index": 27}, {"url": "https://medium.com/@davidwdai", "anchor_text": "Medium", "paragraph_index": 27}, {"url": "http://Wayfair.ai", "anchor_text": "Wayfair.ai", "paragraph_index": 29}, {"url": "http://Petuum.com", "anchor_text": "Petuum.com", "paragraph_index": 29}], "all_paragraphs": ["Today, only about 10% of 7B population in the world have access to good healthcare service, and half of the world don\u2019t even access to essential health services. Even among the developed countries, healthcare system is under strain, with rising cost and long wait time. To train up enough physicians and care providers for the growing demands within a short period of time is impractical, if not impossible. The solution has to involve technological breakthroughs.", "And that\u2019s where Machine Learning (ML) and Artificial Intelligence (AI) can make a big impact.", "In this post, I will introduce a simple but extremely effective Deep Learning approach I developed to understand chest x-ray images. More details can be found in the original paper.", "CXRs are the most common type of medical imaging, often 2x-10x more than other advanced imaging methods such as MRI, CT scans, PET scans:", "Some reasons that CXRs are popular include: (1) lower dose of radiation; (2) lower cost; (3) it needs only less than a minute to take an image (compared with, say, an hour or more for a CT scan). As the result, CXRs are widely used as a screening tool. If there\u2019s something wrong in your lungs that requires more evidence to diagnose, your doctor usually first prescribe a CXR. CXR provides a low fidelity view that paves the way to other more sophisticated imaging methods.", "From talking to radiologists I learned that a sizable hospital can generate hundreds if not thousands of CXR a day, all of which need to be read by a radiologist or, less preferably, other physicians. And it is often paramount for the reading to be done in hours to detect urgent conditions (such as those developed by in-patients). In short, reading CXR is quite a demanding task for radiologists and physicians alike.", "The average time it takes a well trained radiologist to read a CXR is about 1\u20132 minutes. It is hard to speed that up because CXR reading is a very systematic process. One popular mnemonic for CXR reading is the following: ABCDEFGHI. A for airways, B for bones, C for cardiac\u2026 you get the idea. It\u2019s not exactly short, and taking shortcuts means risking overlooking important findings.", "From working on CXR I also realize that reading CXR is actually very hard. I had brought CXRs with tuberculosis diagnosis to a general physician and he cannot tell for most part which patient is TB (tuberculosis) positive. The radiology resident I spoke to told me that during their residency program they will read about 10,000 CXR images to get proficient at it. This reminds me that most professional baseball batters in MLB need to swing 10,000 times to be able to hit the ball. It seems that it takes that amount of training data for humans to start recognizing the patterns in CXRs. This steep learning curve might be due to the fact that CXR is so different from natural images we are trained on throughout our lives. This turned out to be a hurdle for AI system as well, which we shall revisit later.", "We are only talking about CXRs. As CT scans and other imaging technology becomes more popular, radiologists\u2019 workloads will increase dramatically. The chronic shortage of radiologists in the developed world is well documented. For example, the UK publishes reports on clinical radiology in UK and the main finding for several years has been the \u201cincreased workforce shortages and spiraling costs. The radiology workforce is showing signs of stress and burnout\u201d. The shortage of trained radiologists is even more severe in developing countries where the healthcare infrastructure lags behind.", "A fundamental task in understanding CXR is to recognize the lung fields and the heart regions:", "There is actually a lot of information you can get from the lung contour: an abnormally large heart might suggest cardiomegaly (the abnormal enlargement of the heart); the blunting of costophrenic angle (#3 in the image below) might suggest pleural effusion. It can also be helpful to isolate the diagnostic AI algorithms to only the lung field, minimizing spurious signals from other parts of the images. (This is a known issue as neural net classifiers can sometimes exploits artifacts in the CXR such as exposure and texts.)", "In addition to assisting computer-aided diagnosis, CXR segmentation directly leads to automated calculation of cardiothoracic ratio (CTR). CTR is simply the width of the heart divided by the width of the lung (see image below).", "CTR is a key clinical indicator. CTR > 0.5 suggests cardiomegaly, or the enlargement of heart, which is often resulted from heart diseases or prior heart attacks. Measuring CTR is very tedious. It involves pinpointing the left and right most points of the heart and lung, and actually taking the measurement. As a result, most radiologists simply skip this measurement and just eyeball whether the heart is too large. In some countries like China CXR readers are required to take explicit CTR measurements, which can significantly increases radiologist workloads.", "It\u2019s easy to see that high quality lung segmentation can lead to an automated CTR calculation:", "These are CTR measurement lines computed from the lung masks generated by our method (to be introduced in part 2). Indeed, in our follow-up work we find that our CTR calculation is highly accurate, with only 6% in root mean square error (RMSE), which is comparable, and possibly better than, existing works like (Dallal et al 2017)^.", "^The numbers aren\u2019t directly comparable as we don\u2019t have access to their dataset.", "Because CXR is a 2-D projection of a 3-D human body many physiological structures lie on top of each other in the image, and a lot of time it is a judgement call on where you draw the boundary. Take the following case as an example:", "The image exhibits some scarring in the left lower lobe (the right side of the image) as well as in the apex of the left lung. They blur the lung contour substantially. Therefore the red contour has to be drawn by inferring the lung shape using medical knowledge. The segmentation model must acquire a global concept of contour shape in order to resolve the local ambiguity around the blurred boundaries and produce the correct contour like those by human labelers.", "CXR images look nothing like the natural images we see in everyday life:", "Most existing computer vision neural networks are designed for colorful natural images and takes advantage of the rich textures present in them. This makes it hard to directly apply off-the-shelf solutions on CXR.", "Public medical images for CXR are much smaller than natural images due to privacy concerns and administrative barriers, among other reasons. Furthermore, unlike natural images that can be labeled by any annotator, medical image labeling can only be done by doctors and trained professionals, incurring high label acquisition cost.", "To my knowledge, there are only two publicly available CXR dataset with pixel -level labels of the lung fields, one with 247 images, and the other 138. This is at least 3000 times smaller than the ImageNet challenge, which has anywhere from 1.2 million to 14 million labeled images. In fact, the neural nets trained on ImageNet dataset is so powerful that practically all existing neural net segmentation models are initialized with parameters learned on the ImageNet challenge (such as from ResNet or VGG). It\u2019s not clear a priori if such a small dataset is enough for data hungry neural nets with millions to hundreds of millions parameters.", "In Part 2 of the series we design our models to address each of the challenges above. Here\u2019s a quick preview:", "Unlike natural images, CXRs are grayscale and are highly standardized (challenge #2). This observation led us to design the segmentation network to use much fewer convolutional channels compared with networks used on the ImageNet dataset with diverse colors and shapes. This change unfortunately makes it impractical to do transfer learning from ImageNet-trained models. However, by using fewer filters, our model has very few parameters (small model capacity) which minimize the risk of overfitting prone to happen on small training data (challenge #3).", "Finally, perhaps the most challenging, is how to teach the segmentation model the medical knowledge humans possess (challenge #1). The key insight here is to use adversarial learning to guide the segmentation model to generate more natural images, which we will show in Part 2 to be highly effective.", "The architecture of the final solution that addresses all of the challenges looks like this:", "This is Part 1 of a two part series. See Part 2 for details of the model design and performance.", "About the author: David Dai is Senior Machine Learning Engineer at Apple, advisor at Wayfinder AI, and former Senior Director of Engineering at Petuum. He holds PhD in Machine Learning from Carnegie Mellon University, and was named Pittsburgh\u2019s 30 Under 30. @daiwei89 | Medium | david@wayfinder.ai.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Sr. Machine Learning Engineer @ Apple, Advisor at Wayfair.ai, PhD in ML (Carnegie Mellon U), Former Sr. Director of Engineering @ Petuum.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7182cf4b87ff&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@davidwdai?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidwdai?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "David W. Dai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f430f00f54c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&user=David+W.+Dai&userId=5f430f00f54c&source=post_page-5f430f00f54c----7182cf4b87ff---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.who.int/news-room/detail/13-12-2017-world-bank-and-who-half-the-world-lacks-access-to-essential-health-services-100-million-still-pushed-into-extreme-poverty-because-of-health-expenses", "anchor_text": "half of the world"}, {"url": "https://arxiv.org/abs/1703.08770", "anchor_text": "paper"}, {"url": "https://www.england.nhs.uk/statistics/statistical-work-areas/diagnostic-imaging-dataset/", "anchor_text": "source"}, {"url": "https://radiopaedia.org/articles/chest-radiograph-assessment-using-abcdefghi?lang=us", "anchor_text": "ABCDEFGHI"}, {"url": "https://www.rcr.ac.uk/system/files/publication/field_publication_files/clinical-radiology-uk-workforce-census-report-2018.pdf", "anchor_text": "report"}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/10628457", "anchor_text": "Japanese Society of Radiology Technology"}, {"url": "https://my.clevelandclinic.org/health/diseases/17373-pleural-effusion-causes-signs--treatment", "anchor_text": "pleural effusion"}, {"url": "https://link.springer.com/chapter/10.1007/978-3-030-00934-2_61", "anchor_text": "follow-up work"}, {"url": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10134/101340K/Automatic-estimation-of-heart-boundaries-and-cardiothoracic-ratio-from-chest/10.1117/12.2254136.short?SSO=1", "anchor_text": "Dallal et al 2017"}, {"url": "https://lhncbc.nlm.nih.gov/system/files/pub9356.pdf", "anchor_text": "Source"}, {"url": "https://openreview.net/forum?id=Bygh9j09KX", "anchor_text": "rich textures"}, {"url": "https://towardsdatascience.com/can-machine-learning-read-chest-x-rays-like-radiologists-part-2-aa77dba219f0", "anchor_text": "Part 2"}, {"url": "https://www.apple.com/", "anchor_text": "Apple"}, {"url": "http://wayfinder.ai", "anchor_text": "Wayfinder AI"}, {"url": "http://petuum.com", "anchor_text": "Petuum"}, {"url": "https://twitter.com/daiwei89", "anchor_text": "@daiwei89"}, {"url": "https://medium.com/@davidwdai", "anchor_text": "Medium"}, {"url": "https://arxiv.org/abs/1703.08770", "anchor_text": "SCAN: Structure Correcting Adversarial Network for Organ Segmentation in Chest X-rays"}, {"url": "https://www.who.int/news-room/detail/13-12-2017-world-bank-and-who-half-the-world-lacks-access-to-essential-health-services-100-million-still-pushed-into-extreme-poverty-because-of-health-expenses", "anchor_text": "World Bank and WHO: Half the world lacks access to essential health services, 100 million still pushed into extreme poverty because of health expenses"}, {"url": "https://www.england.nhs.uk/statistics/statistical-work-areas/diagnostic-imaging-dataset/", "anchor_text": "Diagnostic Imaging Dataset by National Health Service, UK"}, {"url": "https://radiopaedia.org/articles/chest-radiograph-assessment-using-abcdefghi?lang=us", "anchor_text": "Chest radiograph assessment using ABCDEFGHI"}, {"url": "https://www.rcr.ac.uk/system/files/publication/field_publication_files/clinical-radiology-uk-workforce-census-report-2018.pdf", "anchor_text": "Clinical radiology UK workforce census 2018 report"}, {"url": "https://link.springer.com/chapter/10.1007/978-3-030-00934-2_61", "anchor_text": "Unsupervised Domain Adaptation for Automatic Estimation of Cardiothoracic Ratio"}, {"url": "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10134/101340K/Automatic-estimation-of-heart-boundaries-and-cardiothoracic-ratio-from-chest/10.1117/12.2254136.short?SSO=1", "anchor_text": "Automatic estimation of heart boundaries and cardiothoracic ratio from chest x-ray images"}, {"url": "https://openreview.net/forum?id=Bygh9j09KX", "anchor_text": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness"}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/10628457", "anchor_text": "Development of a digital image database for chest radiographs with and without a lung nodule: receiver operating characteristic analysis of radiologists\u2019 detection of pulmonary nodules."}, {"url": "https://lhncbc.nlm.nih.gov/system/files/pub9356.pdf", "anchor_text": "Two public chest X-ray datasets for computer-aided screening of pulmonary diseases"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7182cf4b87ff---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----7182cf4b87ff---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/health?source=post_page-----7182cf4b87ff---------------health-----------------", "anchor_text": "Health"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----7182cf4b87ff---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/image-recognition?source=post_page-----7182cf4b87ff---------------image_recognition-----------------", "anchor_text": "Image Recognition"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&user=David+W.+Dai&userId=5f430f00f54c&source=-----7182cf4b87ff---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&user=David+W.+Dai&userId=5f430f00f54c&source=-----7182cf4b87ff---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7182cf4b87ff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7182cf4b87ff---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7182cf4b87ff--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidwdai?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@davidwdai?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "David W. Dai"}, {"url": "https://medium.com/@davidwdai/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "178 Followers"}, {"url": "http://Wayfair.ai", "anchor_text": "Wayfair.ai"}, {"url": "http://Petuum.com", "anchor_text": "Petuum.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5f430f00f54c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&user=David+W.+Dai&userId=5f430f00f54c&source=post_page-5f430f00f54c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff1ec85144ed6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-machine-learning-read-chest-x-rays-like-radiologists-part-1-7182cf4b87ff&newsletterV3=5f430f00f54c&newsletterV3Id=f1ec85144ed6&user=David+W.+Dai&userId=5f430f00f54c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}