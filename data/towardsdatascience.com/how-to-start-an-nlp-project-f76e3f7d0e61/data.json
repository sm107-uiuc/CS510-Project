{"url": "https://towardsdatascience.com/how-to-start-an-nlp-project-f76e3f7d0e61", "time": 1683008661.475777, "path": "towardsdatascience.com/how-to-start-an-nlp-project-f76e3f7d0e61/", "webpage": {"metadata": {"title": "How to Start An NLP Project. Considerations and basic exploratory\u2026 | by Lily Hughes-Robinson | Towards Data Science", "h1": "How to Start An NLP Project", "description": "Natural Language Processing is an exciting niche in artificial intelligence. Its applications are extensive, spanning from understanding sentiment to topic analysis, even generating original texts\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/gentle-start-to-natural-language-processing-using-python-6e46c07addf3", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff", "anchor_text": "here", "paragraph_index": 1}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe word embeddings", "paragraph_index": 3}, {"url": "https://github.com/praw-dev/praw", "anchor_text": "praw", "paragraph_index": 5}, {"url": "https://en.wikipedia.org/wiki/Stop_words", "anchor_text": "stop words", "paragraph_index": 7}, {"url": "https://spacy.io/", "anchor_text": "spaCy library", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Lemmatisation", "anchor_text": "lemmatisation", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Stemming", "anchor_text": "stemming", "paragraph_index": 8}, {"url": "https://spacy.io/api/token#attributes", "anchor_text": "Here is a list of token attributes that spaCy provides", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Regular_expression", "anchor_text": "regular expressions", "paragraph_index": 9}, {"url": "https://www.reddit.com/r/help/comments/1ttv80/what_are_the_valid_usernamecharacters/", "anchor_text": "a post on r/help", "paragraph_index": 11}, {"url": "https://notebooks.azure.com/oaguy1/projects/nlp-text-eda", "anchor_text": "azure notebooks", "paragraph_index": 12}], "all_paragraphs": ["Natural Language Processing is an exciting niche in artificial intelligence. Its applications are extensive, spanning from understanding sentiment to topic analysis, even generating original texts for human consumption and beyond. However, before one can start implementing some of these analyses, basic preparations that have to be made in order to ensure a project\u2019s success. This includes choosing what text to ingest, as well as some necessary word transformation to make your text ready for further investigation.", "A quick note: This is not an introduction to NLP as a topic, or how to start a basic project. One can find excellent guides to starting learning NLP here and here.", "First, one needs to decide what text they want to analyze. This may seem obvious at first, but there are a number of finer technical considerations that need to be made. For some, the answers to these questions will be necessitated by their desired outcome. For example, when examining free-text survey input, it is obvious that the survey responses are going to make up your corpus. In other cases, this may be less well defined.", "There are a few useful terms to explain here. Corpus refers to a collection of text examined in an analysis. This term can scale from a single sentence to every word ever know in every language ever spoken. Sometimes a corpus can be subdivided into documents, which are smaller corpora that usually encapsulate a single idea or topic. A document can be as small as a tweet or as large as a book. Dividing a corpus into documents isn\u2019t strictly necessary for every NLP task, but it is useful for comparing different documents against each other. The smallest unit of measure in NLP is a token. A token is an individual word within a document. A vocabulary is the number of distinct tokens present within a corpus. Some techniques, such as GloVe word embeddings, grow in time complexity as the vocabulary grows while others increase in complexity with a larger corpus. One\u2019s use case will drive which analysis and corpus size make the most sense.", "Unless you have a large compute cluster and infinite amounts of time, you cannot look at every tweet ever made. What makes sense is to choose a time period to base your analysis on. One\u2019s choice in time period is going to be based around a few factors: the size of your time window and when it starts. Both of these parameters affect the number of words/documents included in your analysis. Most likely you won\u2019t know the distribution of word sizes over time without doing some exploratory data analysis that can reveal how the corpus size grows as you add more time to the analysis. Once you know how the corpus size grows you will be able to make an educated decision based on your available compute resources.", "I performed a sample analysis to measure corpus and vocabulary growth. I dug into my favorite data set for pet projects: Reddit. I used library called praw to grab comments from the Reddit API. I then plotted the growth as a series. Below is a gist I wrote to track the number of words as explore more posts. I also include the outputted graph when I ran the code around the time of publishing.", "Looking at the graph above, we can see that the corpus grows in a roughly linear manner while the vocabulary is much more logarithmic. Using this knowledge, one can now make an educated decision about how many Reddit posts to include in one\u2019s analysis. One way this analysis could be taken further is to calculate these values across several different subreddits, to see which community has the richest vocabulary and which is the most verbose.", "Once one has solidified the parameters to create their corpus, there are preprocessing steps that need to be taken before analysis can begin. Raw natural language has a number of properties that can muddy analysis down the line. A common first step is to remove stop words; common words that do not offer rich semantic meaning and instead add more noise than signal. Most NLP libraries come with a list of stop words you can utilize to clean your corpus. Below is an example of removing stop words using the spaCy library.", "This example has spaCy ingest each comment, which then get turned into a pared document containing tokens. Iterating over the document yields individual tokens, which we can examine to see if they should be considered in the analysis. The gist above removes stop words, but one could just as easily remove numbers or do basic text transformations such as lemmatisation or stemming. SpaCy performs much of this analysis when it first parses each document. Here is a list of token attributes that spaCy provides.", "Another common step involves dealing with numerical data within your text. In general, it is common to remove numbers as they usually do not provide any semantic meaning on their own. To remove numbers as well as stop words, you can use regular expressions (regexes) or built in functions most NLP libraries. For example, in spaCy, tokens have a property \u201cis_alpha\u201d one can filter on, similarly to stop words in the above gist.", "However, it is possible that numbers have a specific context you want to preserve. For example, some numerical sequences have a specific meaning, such as IP addresses or MAC addresses. If the data set contains such information, one can use masking to replace all instances of numerical entities with a predetermined token, such as \u201cIP_ADDRESS.\u201d This will preserve the semantic meaning of the numerical entity while removing the noise numbers. Often a simple regex replace is the best tool of the job here.", "Masking is useful for more than just numerical entities. It can be used for any entity you want to preserve syntactic meaning while removing specific detail. This can be done to remove personally identifying information (PII) from your data, which may be a legal or regulatory requirement depending on your data set. Looking back at Reddit, I am going to demonstrate masking usernames with the token \u201cUSERNAME\u201d. Luckily, a post on r/help explains that usernames can consist of any alphanumeric (plus dash and underscore) 3 to 20 characters long and are usually prefixed with \u201cu/.\u201d In the gist below, I use python\u2019s built in regular expression library to find and replace all Reddit usernames with our token.", "These steps will set the stage for a successful NLP project. There are a myriad of tools and techniques one could use to summarize, extract meaning, or any number of other NLP tasks. I have provided a notebook with all the code listed in the gists in a jupyter notebook on azure notebooks.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Lily is a data scientist at a large financial institution. When she isn\u2019t solving business problems, she is hanging out with her wife in New York City."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff76e3f7d0e61&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@oaguy1?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oaguy1?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Lily Hughes-Robinson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5389e25ca1bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&user=Lily+Hughes-Robinson&userId=5389e25ca1bb&source=post_page-5389e25ca1bb----f76e3f7d0e61---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/gentle-start-to-natural-language-processing-using-python-6e46c07addf3", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff", "anchor_text": "here"}, {"url": "https://unsplash.com/@bradencollum?utm_source=medium&utm_medium=referral", "anchor_text": "Braden Collum"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe word embeddings"}, {"url": "https://github.com/praw-dev/praw", "anchor_text": "praw"}, {"url": "https://en.wikipedia.org/wiki/Stop_words", "anchor_text": "stop words"}, {"url": "https://spacy.io/", "anchor_text": "spaCy library"}, {"url": "https://spacy.io", "anchor_text": "spaCy"}, {"url": "https://en.wikipedia.org/wiki/Lemmatisation", "anchor_text": "lemmatisation"}, {"url": "https://en.wikipedia.org/wiki/Stemming", "anchor_text": "stemming"}, {"url": "https://spacy.io/api/token#attributes", "anchor_text": "Here is a list of token attributes that spaCy provides"}, {"url": "https://en.wikipedia.org/wiki/Regular_expression", "anchor_text": "regular expressions"}, {"url": "https://www.reddit.com/r/help/comments/1ttv80/what_are_the_valid_usernamecharacters/", "anchor_text": "a post on r/help"}, {"url": "https://notebooks.azure.com/oaguy1/projects/nlp-text-eda", "anchor_text": "azure notebooks"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f76e3f7d0e61---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f76e3f7d0e61---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----f76e3f7d0e61---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/business?source=post_page-----f76e3f7d0e61---------------business-----------------", "anchor_text": "Business"}, {"url": "https://medium.com/tag/programming?source=post_page-----f76e3f7d0e61---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&user=Lily+Hughes-Robinson&userId=5389e25ca1bb&source=-----f76e3f7d0e61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&user=Lily+Hughes-Robinson&userId=5389e25ca1bb&source=-----f76e3f7d0e61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff76e3f7d0e61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f76e3f7d0e61---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f76e3f7d0e61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oaguy1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@oaguy1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Lily Hughes-Robinson"}, {"url": "https://medium.com/@oaguy1/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "34 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5389e25ca1bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&user=Lily+Hughes-Robinson&userId=5389e25ca1bb&source=post_page-5389e25ca1bb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F5389e25ca1bb%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-start-an-nlp-project-f76e3f7d0e61&user=Lily+Hughes-Robinson&userId=5389e25ca1bb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}