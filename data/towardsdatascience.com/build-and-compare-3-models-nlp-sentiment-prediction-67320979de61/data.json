{"url": "https://towardsdatascience.com/build-and-compare-3-models-nlp-sentiment-prediction-67320979de61", "time": 1683001313.149804, "path": "towardsdatascience.com/build-and-compare-3-models-nlp-sentiment-prediction-67320979de61/", "webpage": {"metadata": {"title": "Build and Compare 3 Models \u2014 NLP Prediction | by Rohan Gupta | Towards Data Science", "h1": "Build and Compare 3 Models \u2014 NLP Prediction", "description": "This project was created in an attempt to learn and understand how various classification algorithms work within a Natural Language Processing Model. Natural Language Processing, which I will now\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/yelp-dataset/yelp-dataset/version/6", "anchor_text": "|Link to the dataset|", "paragraph_index": 2}], "all_paragraphs": ["This project was created in an attempt to learn and understand how various classification algorithms work within a Natural Language Processing Model. Natural Language Processing, which I will now refer to as NLP, is a branch of machine learning that focuses on enabling computers to interpret and process human languages in both speech and text forms.", "In this pipeline, I go through the following steps:", "For this project, I will be using a dataset sourced from Kaggle, which contains 1000 reviews for a pizzeria by different users. |Link to the dataset|", "Humans can read a review and tell whether it is positive or negative. What if we could create a model to classify them as positive or negative? What\u2019s the best way to do this?", "First, let\u2019s talk about the process. We start off by pre-processing the data, removing unnecessary words that don\u2019t help our prediction. Then, we take important words in their stemmed forms (e.g lov is the stem for loved, loving, or lovely). We then train the machine to learn which reviews are positive based on their word stems. After that we test the data using similar information, to see how accurately our machine can predict whether a review is positive or negative (1 or 0).", "Here, we import all the libraries required for this model to work. Before you begin, make sure you have all the dependencies installed. We will be working mainly with pandas, numpy, re, nltk, matplotlib, and sci-kit learn.", "Make sure to pip installon the command line all the libraries mentioned right above.", "In the code above, I am using a .tsv file, rather than a .csv file. The difference is easier to tell when we break down the acronyms. A .tsv (tab-separated values) is separated by spaces in the text file, whereas a .csv (comma separated values) uses commas to separate the different values.", "pd.read_csv can be used for both, but to specify a tsv file, I added the \u2018\\t\u2019 in the delimiter to tell the machine that values are separated by tabs and not commas. Quoting has been set to 3 since our reviews contain some double quotes, and the machine would not be able to interpret them as regular text if we didn\u2019t add this line.Below we can see the first 10 reviews of our dataset and the outcome: positive(1) or negative(0)", "The code above shows the most important step of this model. I started by importing Regex as re. This class allows us to match and search for string objects. I used the sub-function of re to allow the machine to include the elements of the data we require, which are letters A-Z in upper and lower case.", "I also imported nltk which stands for Natural Language Toolkit. From nltk, I imported 2 classes: the stopwords class, and the PorterStemmer class.", "stopwords allow us to remove words that would not help our model (such as \u201cthe\u201d, \u201can\u201d, \u201cthis\u201d etc). The stopwords class already contains these words, so I didn\u2019t have to manually enter them. I used a for loop to specify to the machine that we need to take out the word if it doesn\u2019t exist in the stopwords class.", "PorterStemmer allows us to take the stem of a word and classify it as a common predictor for similar words. For example, in the first review, \u201cLov\u201d is the stem for words such as \u201cloving\u201d or \u201cloved\u201d, which would both essentially translate to a positive review, thus allowing our model to have fewer words.", "Finally, to apply the preprocessing steps to all the 1000 reviews in our dataset, I added another for loop before the text-processing steps.", "The Bag of Words model allows us to extract features from our textual data and in this example, we take out all the words from each of the observations and pool them together in a sort of \u201cbag\u201d to reduce redundancy by not counting duplicates. I did this by importing the CountVectorizer class from sklearn.", "Each word forms its own column in a way, and since there are so many words, we could have a huge number of columns. However, I specified the maximum number of columns using the max_features parameter of the CountVectorizer class.", "Then all I had to do was fit the column of words to the X (input) variable and specified y (output) variable as our second column in the dataset, which gives you a 1 or 0, depending on whether the review was positive or negative respectively.", "I then had to split the dataset into a training set and a test set, and used a test size of 0.2, so that we have 800 values to train our dataset and 200 values to test it with.", "Code below shows us what Train & Test sets look like", "Now that I\u2019m done with all the pre-processing steps, I\u2019m going to start applying some classification algorithms to model to help it predict reviews.", "The first model I use is the Naive Bayes Model. In machine learning, naive Bayes classifiers are a family of simple \u201cprobabilistic classifiers\u201d based on applying Bayes\u2019 theorem with strong (naive) independence assumptions between the features.", "All naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. In our model, the naive Bayes algorithm looks at particular keywords of a review to describe whether it is positive or negative, depending on the output set.", "In the code below, I imported the GaussianNB class, which assumes that our data is normally distributed (with a Gaussian Bell Curve).", "I created y_pred_NB, which is where our model\u2019s predictions would be stored. The output below shows us what the prediction matrix looks like. It\u2019s a bunch of 1s and 0s, like our y_train dataset. These are the predictions made by our model. y_pred_NB can be compared to y_test and determine how accurate our model is.", "The confusion matrix for Naive Bayes shows us our True Negatives on the top left, False Negatives on the top right, True Positives on the bottom right, and False Positives on the bottom left.", "Below, I\u2019ve coded the numbers for each with acronyms using T for True, F for False, N for negative, P for positive.", "Below, I will use the True/False Positives and Negatives to calculate the Accuracy, Precision, Recall, and F1 scores.", "Accuracy is as the name goes. It measures the accuracy by adding True predictions and dividing them by the total number of predictions.", "Precision refers to the closeness of two or more measurements to each other. It\u2019s calculated by dividing True Positives from Total Positives", "Recall is the ratio of correctly predicted positive observations to all observations in the actual class. Divide True positive by the sum of True Positives and False Negatives.", "The F1 Score is the weighted average of Precision and Recall. F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution. It is calculated by multiplying the Precision and Recall, dividing the result by the sum of Precision and Recall, and multiplying the final result by 2.", "The next algorithm I used is the decision tree. Decision trees allow you to develop classification systems that predict or classify future observations based on a set of decision rules.", "Finally, I used the Random Forest algorithm, which is just a combination of a number of decision trees. In my example, I chose to use 300 trees, but I could change that number depending on the kind of accuracy I want from the model.", "In this last section, I will compare the accuracy, precision, recall, and F1 Scores of each algorithm I used. I will plot them on bar charts to give us a graphical representation of how the different models compare to each other.", "As we can see in the barplot above, Naive Bayes has the highest accuracy of all of the algorithms with 73% correct predictions. Decision Trees and Random Forest algorithms are also close with 71% and 71.5% accuracy respectively.", "Naive Bayes is the most precise model, with a precision of 88.35%, whereas Decision Trees have a precision of 66%. Random Forests have the lowest precision rate of about 54.4%.", "Random Forests have the highest recall of about 84.8%, whereas Decision Trees have a recall of 74.7%. Naive Bayes had the lowest recall with 68.4%", "On average our models are about 71.8% accurate. While this may mean that the machine cannot predict every review with accuracy, it also shows us evidence that our models are not overfitting the data. Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points. Overfitting the model generally occurs when using an overly complex model to explain idiosyncrasies in the data. However, since our model is being trained to think like a human brain, it is fair to assume that even humans may not be able to predict 100% of the time whether a review is positive or negative. It can really depend on the data and how it has been processed.", "So which was the best algorithm for this model?Out of the 3 used in this project, the most accurate and precise was the Naive Bayes algorithm.", "However, the recall for our Random Forest algorithm was the highest. This means that the Random Forest algorithm actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive). This would be a good metric we use to select our best model when there is a high cost associated with False Negative.", "The truth lies within our F1 scores, which may actually be the best predictor of which model is the best amongst the chosen three. The Naive Bayes algorithm has the highest F1 score, which means that it defines a relationship between Recall and Precision of a particular model. F1 Scores might be a better measure to use if we need to seek a balance between Precision and Recall AND if there is an uneven class distribution (a large number of Actual Negatives).", "Thanks for the read! Hope you learned something useful.", "Follow Rohan Gupta for more content related Data Science and Machine Learning", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist/Analyst/Writer \u2014 I love spreading knowledge."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F67320979de61&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----67320979de61--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----67320979de61--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rohanguptaa33?source=post_page-----67320979de61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohanguptaa33?source=post_page-----67320979de61--------------------------------", "anchor_text": "Rohan Gupta"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff463f1bf80e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&user=Rohan+Gupta&userId=f463f1bf80e2&source=post_page-f463f1bf80e2----67320979de61---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@impatrickt?utm_source=medium&utm_medium=referral", "anchor_text": "Patrick Tomasso"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://unsplash.com/@zulmaury?utm_source=medium&utm_medium=referral", "anchor_text": "Zulmaury Saavedra"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/yelp-dataset/yelp-dataset/version/6", "anchor_text": "|Link to the dataset|"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----67320979de61---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----67320979de61---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----67320979de61---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/predictions?source=post_page-----67320979de61---------------predictions-----------------", "anchor_text": "Predictions"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----67320979de61---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&user=Rohan+Gupta&userId=f463f1bf80e2&source=-----67320979de61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&user=Rohan+Gupta&userId=f463f1bf80e2&source=-----67320979de61---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----67320979de61--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F67320979de61&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----67320979de61---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----67320979de61--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----67320979de61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----67320979de61--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----67320979de61--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----67320979de61--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----67320979de61--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----67320979de61--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----67320979de61--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohanguptaa33?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohanguptaa33?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rohan Gupta"}, {"url": "https://medium.com/@rohanguptaa33/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "567 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff463f1bf80e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&user=Rohan+Gupta&userId=f463f1bf80e2&source=post_page-f463f1bf80e2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffa9b9e13a272&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-and-compare-3-models-nlp-sentiment-prediction-67320979de61&newsletterV3=f463f1bf80e2&newsletterV3Id=fa9b9e13a272&user=Rohan+Gupta&userId=f463f1bf80e2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}