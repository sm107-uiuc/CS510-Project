{"url": "https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a", "time": 1683013008.868421, "path": "towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a/", "webpage": {"metadata": {"title": "Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras | by Emil Lykke Jensen | Towards Data Science", "h1": "Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras", "description": "The internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Huggingface Transformers", "paragraph_index": 1}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT", "paragraph_index": 1}, {"url": "https://www.tensorflow.org/guide/keras/", "anchor_text": "Tensorflow Keras", "paragraph_index": 1}, {"url": "https://www.consumerfinance.gov/data-research/consumer-complaints/", "anchor_text": "\u2018Consumer Complaint Database\u2019", "paragraph_index": 4}, {"url": "https://towardsdatascience.com/nlp-part-3-exploratory-data-analysis-of-text-data-1caa8ab3f79d", "anchor_text": "NLP Part 3 | Exploratory Data Analysis of Text Data", "paragraph_index": 6}, {"url": "https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a", "anchor_text": "A Complete Exploratory Data Analysis and Visualization for Text Data", "paragraph_index": 6}, {"url": "https://huggingface.co/transformers/model_doc/bert.html#berttokenizer", "anchor_text": "pretty well documented", "paragraph_index": 12}, {"url": "https://huggingface.co/transformers/pretrained_models.html", "anchor_text": "the 12-layer bert-base-uncased", "paragraph_index": 13}, {"url": "https://huggingface.co/transformers/model_doc/bert.html", "anchor_text": "different BERT classification models to use", "paragraph_index": 14}, {"url": "https://huggingface.co/transformers/_modules/transformers/modeling_tf_bert.html#TFBertForSequenceClassification", "anchor_text": "found here", "paragraph_index": 15}, {"url": "https://medium.com/analytics-vidhya/understanding-bert-architecture-3f35a264b187", "anchor_text": "take a look here", "paragraph_index": 18}, {"url": "https://huggingface.co/transformers/glossary.html#attention-mask", "anchor_text": "look here", "paragraph_index": 24}], "all_paragraphs": ["The internet is full of text classification articles, most of which are BoW-models combined with some kind of ML-model typically solving a binary text classification problem. With the rise of NLP, and in particular BERT (take a look here, if you are not familiar with BERT) and other multilingual transformer based models, more and more text classification problems can now be solved.", "However, when it comes to solving a multi-label, multi-class text classification problem using Huggingface Transformers, BERT, and Tensorflow Keras, the number of articles are indeed very limited and I for one, haven\u2019t found any\u2026 Yet!", "Therefore, with the help and inspiration of a great deal of blog posts, tutorials and GitHub code snippets all relating to either BERT, multi-label classification in Keras or other useful information I will show you how to build a working model, solving exactly that problem.", "And why use Huggingface Transformers instead of Googles own BERT solution? Because with Transformers it is extremely easy to switch between different models, that being BERT, ALBERT, XLnet, GPT-2 etc. Which means, that you more or less \u2018just\u2019 replace one model for another in your code.", "With data. Looking for text data I could use for a multi-label multi-class text classification task, I stumbled upon the \u2018Consumer Complaint Database\u2019 from data.gov. Seems to do the trick, so that\u2019s what we\u2019ll use.", "Next up is the exploratory data analysis. This is obviously crucial to get a proper understanding of what your data looks like, what pitfalls there might be, the quality of your data, and so on. But I\u2019m skipping this step for now, simply because the aim of this article is purely how to build a model.", "If you don\u2019t like googling around take a look at these two articles on the subject: NLP Part 3 | Exploratory Data Analysis of Text Data and A Complete Exploratory Data Analysis and Visualization for Text Data.", "We have our data and now comes the coding part.", "First, we\u2019ll load the required libraries.", "Then we will import our data and wrangle it around so it fits our needs. Nothing fancy there. Note that we will only use the columns \u2018Consumer complaint narrative\u2019, \u2018Product\u2019 and \u2018Issue\u2019 from our dataset. \u2018Consumer complaint narrative\u2019 will serve as our input for the model and \u2018Product\u2019 and \u2018Issue\u2019 as our two outputs.", "Next we will load a number of different Transformers classes.", "Here we first load a BERT config object that controls the model, tokenizer and so on.", "Then, a tokenizer that we will use later in our script to transform our text input into BERT tokens and then pad and truncate them to our max length. The tokenizer is pretty well documented so I won\u2019t get into that here.", "Lastly, we will load the BERT model itself as a BERT Transformers TF 2.0 Keras model (here we use the 12-layer bert-base-uncased).", "We are ready to build our model. In the Transformers library, there are a number of different BERT classification models to use. The mother of all models is the one simply called \u2018BertModel\u2019 (PyTorch) or \u2018TFBertModel\u2019 (TensorFlow) and thus the one we want.", "The Transformers library also comes with a prebuilt BERT model for sequence classification called \u2018TFBertForSequenceClassification\u2019. If you take a look at the code found here you\u2019ll see, that they start by loading a clean BERT model and then they simply add a dropout and a dense layer to it. Therefore, what we\u2019ll do is simply to add two dense layers instead of just one.", "Here what our model looks like:", "And a more detailed view of the model:", "If you want to know more about BERTs architecture itself, take a look here.", "Now that we have our model architecture, all we need to do is write it in code.", "Then all there is left to do is to compile our new model and fit it on our data.", "Once the model is fitted, we can evaluate it on our test data to see how it performs.", "As it turns out, our model performs fairly okay and has a relatively good accuracy. Especially considering the fact that our output \u2018Product\u2019 consists of 18 labels and \u2018Issue\u2019 consists of 159 different labels.", "There are, however, plenty of things you could do to increase performance of this model. Here I have tried to do it as simple as possible, but if you are looking for better performance consider the following:", "(remember to add attention_mask when fitting your model and set return_attention_mask to True in your tokenizer. For more info on attention masks, look here. Also I have added attention_mask to the gist below and commented it out for your inspiration.)", "That\u2019s it \u2014 hope you like this little walk-through of how to do a \u2018Multi-Label, Multi-Class Text Classification with BERT, Transformer and Keras\u2019. If you have any feedback or questions, fire away in the comments below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc6355eccb63a&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@emillykkejensen?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@emillykkejensen?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Emil Lykke Jensen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F641925705621&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&user=Emil+Lykke+Jensen&userId=641925705621&source=post_page-641925705621----c6355eccb63a---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Huggingface Transformers"}, {"url": "https://www.tensorflow.org/guide/keras/", "anchor_text": "Tensorflow Keras API"}, {"url": "https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270", "anchor_text": "here"}, {"url": "https://huggingface.co/transformers/", "anchor_text": "Huggingface Transformers"}, {"url": "https://github.com/google-research/bert", "anchor_text": "BERT"}, {"url": "https://www.tensorflow.org/guide/keras/", "anchor_text": "Tensorflow Keras"}, {"url": "https://www.consumerfinance.gov/data-research/consumer-complaints/", "anchor_text": "\u2018Consumer Complaint Database\u2019"}, {"url": "https://towardsdatascience.com/nlp-part-3-exploratory-data-analysis-of-text-data-1caa8ab3f79d", "anchor_text": "NLP Part 3 | Exploratory Data Analysis of Text Data"}, {"url": "https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a", "anchor_text": "A Complete Exploratory Data Analysis and Visualization for Text Data"}, {"url": "https://huggingface.co/transformers/model_doc/bert.html#berttokenizer", "anchor_text": "pretty well documented"}, {"url": "https://huggingface.co/transformers/pretrained_models.html", "anchor_text": "the 12-layer bert-base-uncased"}, {"url": "https://huggingface.co/transformers/model_doc/bert.html", "anchor_text": "different BERT classification models to use"}, {"url": "https://huggingface.co/transformers/_modules/transformers/modeling_tf_bert.html#TFBertForSequenceClassification", "anchor_text": "found here"}, {"url": "https://medium.com/analytics-vidhya/understanding-bert-architecture-3f35a264b187", "anchor_text": "take a look here"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/Model", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/keras/Model"}, {"url": "https://github.com/huggingface/transformers/tree/master/examples/language-modeling", "anchor_text": "have a look here to see how"}, {"url": "https://huggingface.co/transformers/glossary.html#attention-mask", "anchor_text": "look here"}, {"url": "https://huggingface.co/transformers/model_summary.html", "anchor_text": "here"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----c6355eccb63a---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/keras?source=post_page-----c6355eccb63a---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/tag/bert?source=post_page-----c6355eccb63a---------------bert-----------------", "anchor_text": "Bert"}, {"url": "https://medium.com/tag/transformers?source=post_page-----c6355eccb63a---------------transformers-----------------", "anchor_text": "Transformers"}, {"url": "https://medium.com/tag/nlp?source=post_page-----c6355eccb63a---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&user=Emil+Lykke+Jensen&userId=641925705621&source=-----c6355eccb63a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&user=Emil+Lykke+Jensen&userId=641925705621&source=-----c6355eccb63a---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc6355eccb63a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c6355eccb63a---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c6355eccb63a--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c6355eccb63a--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c6355eccb63a--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@emillykkejensen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@emillykkejensen?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Emil Lykke Jensen"}, {"url": "https://medium.com/@emillykkejensen/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "52 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F641925705621&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&user=Emil+Lykke+Jensen&userId=641925705621&source=post_page-641925705621--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd71d8d35f459&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmulti-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a&newsletterV3=641925705621&newsletterV3Id=d71d8d35f459&user=Emil+Lykke+Jensen&userId=641925705621&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}