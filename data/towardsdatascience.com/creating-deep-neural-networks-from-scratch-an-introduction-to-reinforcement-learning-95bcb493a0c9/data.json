{"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9", "time": 1683006078.5816388, "path": "towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9/", "webpage": {"metadata": {"title": "Creating Deep Neural Networks from Scratch, an Introduction to Reinforcement Learning | by Abhav Kedia | Towards Data Science", "h1": "Creating Deep Neural Networks from Scratch, an Introduction to Reinforcement Learning", "description": "At the end of the last section, we had finished the implementation of our Cartpole agent. Time to see the results and the agent\u2019s performance over time! Let\u2019s take a full training run and follow the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://gym.openai.com/envs/CartPole-v1/", "anchor_text": "cartpole problem", "paragraph_index": 0}, {"url": "https://github.com/abhavk/dqn_from_scratch", "anchor_text": "here", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-part-i-549ef7b149d2", "anchor_text": "Part I", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-6bba874019db", "anchor_text": "Part II", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-6bba874019db", "anchor_text": "Part II", "paragraph_index": 10}, {"url": "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/", "anchor_text": "Adam optimization technique", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "anchor_text": "this post", "paragraph_index": 21}, {"url": "https://arxiv.org/abs/1412.6980", "anchor_text": "original paper", "paragraph_index": 29}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-part-i-549ef7b149d2", "anchor_text": "Part I", "paragraph_index": 30}, {"url": "https://github.com/abhavk/dqn_from_scratch", "anchor_text": "here", "paragraph_index": 34}, {"url": "https://arxiv.org/pdf/1709.06560.pdf", "anchor_text": "informative paper", "paragraph_index": 34}], "all_paragraphs": ["This is the third and final post in a series designed to give a complete walkthrough to a solution for the cartpole problem on OpenAI gym, built from scratch without using standard machine learning frameworks like Pytorch or Tensorflow. The full code can be found here. Part I laid the foundations. In it we discussed the neural net architecture and implemented the forward propagation to calculate values for the agent\u2019s actions.", "Part II delved into the details of reinforcement learning theory, formalizing the notions of Q-values and DQN\u2019s. We also implemented backpropagation in Part II.", "Part III will contain visualizations and reflections for the agent\u2019s performance with a few different configurations. This final part will also complete the implementation and add enhancements like the Adam optimizer. Here we focus less on the rigor behind hyperparameter choices and more on the exploration of configurations that can be tweaked for model improvement.", "At the end of the last section, we had finished the implementation of our Cartpole agent. Time to see the results and the agent\u2019s performance over time!", "Let\u2019s take a full training run and follow the agent from random initialization to then end when it has learned the art of balancing the pole. This training run took 141 episodes to achieve its goal (an average score of 195 over 100 consecutive episodes).", "First, here\u2019s the graph of the scores \u2014", "Let\u2019s see now how the agent performs over 3 different periods in the course of its training. The first 5 runs the agent is pretty bad,", "Midway through its training, we can see the agent has made progress, although there is still room for improvement. Here\u2019s episodes 75 & 76,", "Finally, towards the end of training the agent is able to balance the pole almost perfectly. Here\u2019s the 138th run,", "We can see that the agent is pretty good by the end!", "In Part II\u2019s section on Cumulative Reward and Action Values, we talked about how we were using a simplified version of the complete implementation of DQN by using the same weights to calculate both the predicted action values and the target values. Instead, we need to have a fixed weight network while calculating the target action values (experimental_values in the RLAgent.experience_replay method). Let\u2019s go ahead and implement that. First, we add the initialization of the stored_weights parameter in the NNLayer.init function,", "Remember the calculation of the experimental_values (through the next_action_values calculation) passed in the parameter remember_for_backprop=False. This parameter can indeed be reused to tell the network to use the stored weights rather than the current network weights. Edit the NNLayer.forward function:", "Finally, after every experience replay, we will update the stored_weights to the new network weights. Add the boldface line to the last bit of the experience_replay method:", "Great, this relatively simple fix means that our target network calculation does not depend on our current weights.", "Great, now that we have gone through a typical run, time to see how quickly the agent learns over many different training runs. To do this, we initialize a new agent from scratch over many runs and see how many episodes it takes to achieve the average reward threshold.", "Here\u2019s the data over 50 runs.", "Apart from two runs that got stuck in local minima for a long time and took over 2000 time steps to solve, almost all the other runs took under 200 episodes to converge. The average number of episodes to solve over the 50 runs was 240.84. This includes the two anomalous runs.", "This plot shows how varying the batch sizes impacts the average episodes to solution (over 20 runs on each batch size). I have tested with 4 different values \u2014 5,10,20 and 40. The best performing in terms of average number of episodes to solve was batch size 20, which had an average of about 173 episodes to solution. However, accounting for the fact that we did half the updates to our algorithm with batch size 10, we were still able to get an average of only 304 episodes to solution. This is about 15% lower than double. In the case of batch size 40, although most of the times the algorithm converged extremely quickly (over 50% solutions were at the lowest possible 100 episode mark), the algorithm was highly unstable in some episodes and did not converge until well over 3000 episodes.", "Going forward we will use batch size 10 for the rest of these enhancements.", "So far, after calculating the gradients, our NNLayer.update_weights function updates the layer weights using a learning rate that is continuously decreased over time, until a minimum threshold is reached.", "Our current weight updates have the same learning rate for each of the parameters in the weight matrix. We will now instead, use the Adam optimization technique and see if that can improve the results. Adam works by keeping a track of individual learning rates for every parameter in the network, using estimates of the first and second moments of the gradient with respect to that parameter. This often leads to faster convergence.", "Refer to this post to understand the details following code. If you would like to go directly to hyperparameter configurations, feel free to skip the rest of this section on the implementation of Adam.", "Let\u2019s begin. We will change the update_weights method in NNLayer as follows:", "The beta_1, beta_2 and adam_epsilon parameters are constants that are used in the implementation of the Adam optimizer. They are almost never changed. The matrices m and v and the time parameter are variables that are updated over the course of training. They are all initialized in the layer\u2019s init method:", "We also replace the reduction of the layer learning rates with an increase in the time parameter for Adam. Adam automatically reduces the learning rate over time using time. Update the last 3 lines of the experience_replay method as such:", "The update_time() implementation just increases the time parameter by 1 each time.", "Compare our implementation with the article linked at the start of this code to verify it is indeed accurate!", "Great, now that it is implemented time to see if it actually performs better! Here\u2019s the graph of number of episodes to solution over 50 runs (batch size is 10):", "Although there is still some instability with this, it performs about 17% better (261 against 304) compared to our old optimizer.", "Although this is not conclusive and the number of trials is quite small, it shows that Adam can be an effective technique in certain situations. A full analysis of the performance of Adam, along with notes on when to use this versus the other optimization techniques can be found in the original paper.", "The size of the hidden layer also makes a difference. Here\u2019s the average episodes to solution over 4 different hidden layer sizes \u2014 12, 24, 48 & 96. There are 2 hidden layers in each of these experiments depicted by the neural network diagram in Part I,", "There\u2019s a downward trend in this map, and the best performance is for the layer size 96. Again, the small number of runs doesn\u2019t provide conclusive evidence but it suggests more parameters generally improve the performance of the agent. The tradeoff, of course is that the time and memory requirements in training larger networks is often much greater.", "So far, all our experiments have been with 2 hidden layers. Trying instead with 1 and 3 layers gives us the following results over 20 runs with 96 hidden units each \u2014", "Unfortunately, hardware limitations prevent me from doing a more thorough analysis of deeper neural networks.", "In this part we concluded and completed the implementation of the algorithm to train our cartpole agent. Updated code including Target Network implementation and Adam can be found here. I intentionally did not do a full analysis of the various hyperparameter configurations for this particular problem because of low generalizability, but here is an informative paper that looks at the effects of changing configurations of DQNs in great detail.", "To summarize, here is what we have done in this part.", "If you\u2019ve got this far, you now have a complete implementation of the cartpole problem! You may want to:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science, FinTech and the future of Technology. MA CompSci & Math, University of Oxford."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F95bcb493a0c9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://abhavkedia.medium.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": ""}, {"url": "https://abhavkedia.medium.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Abhav Kedia"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F634761ec89d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&user=Abhav+Kedia&userId=634761ec89d3&source=post_page-634761ec89d3----95bcb493a0c9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@bantersnaps?utm_source=medium&utm_medium=referral", "anchor_text": "bantersnaps"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://gym.openai.com/envs/CartPole-v1/", "anchor_text": "cartpole problem"}, {"url": "https://github.com/abhavk/dqn_from_scratch", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-part-i-549ef7b149d2", "anchor_text": "Part I"}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-6bba874019db", "anchor_text": "Part II"}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-6bba874019db", "anchor_text": "Part II"}, {"url": "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/", "anchor_text": "Adam optimization technique"}, {"url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "anchor_text": "this post"}, {"url": "https://arxiv.org/abs/1412.6980", "anchor_text": "original paper"}, {"url": "https://towardsdatascience.com/creating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-part-i-549ef7b149d2", "anchor_text": "Part I"}, {"url": "https://en.wikipedia.org/wiki/Vanishing_gradient_problem", "anchor_text": "vanishing gradients problem"}, {"url": "https://github.com/abhavk/dqn_from_scratch", "anchor_text": "here"}, {"url": "https://arxiv.org/pdf/1709.06560.pdf", "anchor_text": "informative paper"}, {"url": "https://gym.openai.com/", "anchor_text": "OpenAI gym"}, {"url": "https://gym.openai.com/envs/MountainCarContinuous-v0/", "anchor_text": "MountainCar"}, {"url": "https://openai.com/progress/", "anchor_text": "their blog"}, {"url": "https://arxiv.org/abs/1709.06560", "anchor_text": "Deep Reinforcement Learning that Matters"}, {"url": "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "anchor_text": "Adam \u2014 latest trends in deep reinforcement learning"}, {"url": "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/", "anchor_text": "Gentle introduction to Adam optimization technique"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----95bcb493a0c9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----95bcb493a0c9---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----95bcb493a0c9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----95bcb493a0c9---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/hyperparameter-tuning?source=post_page-----95bcb493a0c9---------------hyperparameter_tuning-----------------", "anchor_text": "Hyperparameter Tuning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&user=Abhav+Kedia&userId=634761ec89d3&source=-----95bcb493a0c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&user=Abhav+Kedia&userId=634761ec89d3&source=-----95bcb493a0c9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F95bcb493a0c9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----95bcb493a0c9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----95bcb493a0c9--------------------------------", "anchor_text": ""}, {"url": "https://abhavkedia.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://abhavkedia.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Abhav Kedia"}, {"url": "https://abhavkedia.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "116 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F634761ec89d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&user=Abhav+Kedia&userId=634761ec89d3&source=post_page-634761ec89d3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5fb20815f9f8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-deep-neural-networks-from-scratch-an-introduction-to-reinforcement-learning-95bcb493a0c9&newsletterV3=634761ec89d3&newsletterV3Id=5fb20815f9f8&user=Abhav+Kedia&userId=634761ec89d3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}