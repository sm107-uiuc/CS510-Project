{"url": "https://towardsdatascience.com/unsupervised-creation-of-interpretable-sentence-representations-851e74921cf9", "time": 1683010371.4622731, "path": "towardsdatascience.com/unsupervised-creation-of-interpretable-sentence-representations-851e74921cf9/", "webpage": {"metadata": {"title": "Unsupervised creation of interpretable sentence representations | by Ajit Rajasekharan | Towards Data Science", "h1": "Unsupervised creation of interpretable sentence representations", "description": "To date, models learn fixed size representation of sentences, typically with some form of supervision, which are then used for sentence similarity or other downstream tasks. Examples of this are\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1803.11175.pdf", "anchor_text": "Google\u2019s Universal sentence encoder (2018)", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/1908.10084.pdf", "anchor_text": "Sentence transformers (2019)", "paragraph_index": 0}, {"url": "https://arxiv.org/pdf/2002.06652.pdf", "anchor_text": "(SBERT-WK, June 2020)", "paragraph_index": 0}, {"url": "https://github.com/hanxiao/bert-as-service", "anchor_text": "pooling of word vectors across layers", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/examining-berts-raw-embeddings-fd905cb22df7", "anchor_text": "an earlier post", "paragraph_index": 4}, {"url": "https://github.com/facebookresearch/fastText", "anchor_text": "Fasttext data", "paragraph_index": 14}, {"url": "https://github.com/ajitrajasekharan/unsupervised_sentence_representations.git", "anchor_text": "available on Github", "paragraph_index": 20}, {"url": "https://openreview.net/pdf?id=SyK00v5xx", "anchor_text": "A baseline model for evaluating sentence embeddings", "paragraph_index": 22}, {"url": "https://qr.ae/pNKmJ7", "anchor_text": "https://qr.ae/pNKmJ7", "paragraph_index": 29}], "all_paragraphs": ["To date, models learn fixed size representation of sentences, typically with some form of supervision, which are then used for sentence similarity or other downstream tasks. Examples of this are Google\u2019s Universal sentence encoder (2018) and Sentence transformers (2019). Supervised learning of fixed size representations tends to outperform unsupervised creation of sentence representations, with few exceptions such as a recently published work (SBERT-WK, June 2020) in which fixed sentence representations are created by an information content-driven weighted average of word vectors extracted from different layers of a BERT model (there have been similar prior approaches of pooling of word vectors across layers that have not comparatively performed well in tasks, however).", "For the specific task of sentence similarity, an alternate simple approach described below represents a sentence as an unordered set of word representations, and uses the set as is, without converting it into a fixed size vector. The word representations are learned by BERT during pre-training/fine tuning without any labeled data. This simple set representation of a sentence, which apparently seems to be like a bag-of-words representation, performs almost as well as the models mentioned above for short sentences and even better than them qualitatively (needs to quantified with a full test) as sentence length increases. This is perhaps in part because, the words (\u201cwords\u201d here is used for full words and subword tokens in BERT\u2019s vocabulary) composing a sentence, all of which are drawn from BERT\u2019s fixed-size vocabulary of 30,000 words and whose learned vectors are context insensitive (e.g. all senses of the word \u201ccell\u201d is collapsed into one vector), can still be used represent context sensitive aspects of a word by mapping those words to other words within the BERT\u2019s vocabulary that captures their sense in a sentence \u2014 this mapping being accomplished by a BERT model with a Masked language model (MLM) head.", "The advantages of this approach are", "The simplicity of this approach not only enables us perform similarity tasks without labeled data, but also serve as a baseline performance to benchmark future models that output fixed size sentence representations and can potentially outperform this simple approach.", "As examined in an earlier post, BERT\u2019s raw embeddings capture distinct and separable information about any word, either standalone or in the context of a sentence (using BERT MLM head), in terms of words and subwords in its fixed size vocabulary. This is used to create a sentence signature composed of a subset of these words for sentence similarity tasks.", "For instance, consider the longer sentence below, \u201cConnan went to prison cell with a cellphone to draw blood cell samples from inmates\u201d. The tokenized version of this maps this sentence to BERT\u2019s vocabulary of ~30,000 tokens (bert-large-cased). With the exception of two input terms \u201cConnan\u201d and \u201ccellphone\u201d, the rest are all one-to-one mappings. The key point here being the tokenized version of input can be used to find corresponding learned vectors in BERT\u2019s vocabulary.", "These token vectors when passed through BERT\u2019s model (MLM head) get transformed to vectors that represent context sensitive meaning of those words. This is best illustrated by examining the word \u201ccell\u201d used in the above sentence. The top 3 neighbors (this choice is arbitrary \u2014 we can pick top k neighbors so long as they are from the distribution tail) of the word \u201ccell\u201d map to different words in BERT\u2019s vocabulary once they pass through the model. The \u201ccell\u201d representing prison has the meaning of a room, whereas the \u201ccell\u201d used in cellphone context captures the notion of a car. The meaning of the word \u201ccell\u201d in biological context has the notion of biological cell (the fifth neighbor not shown is tissue). In essence, even though the meaning of the word \u201ccell\u201d changes with context, we can still find corresponding vectors capturing its context sensitive sense in BERT\u2019s learned vocabulary. Given this, we can use the vectors for the tokenized text as well as the top k neighbors for each token after it passes through BERT model (MLM head) to be the signature of this sentence.", "When picking the top k neighbors, single character tokens such as punctuation that show up as predictions are ignored. We can safely do this so long as the tail has sufficient tokens to choose from, which is indeed the case in practice.", "In essence, given a sentence of length N, assuming the tokenized version is of length M, the signature for the sentence would M*(1 + k), where k is the number of top neighbors we pick after passing the sentence through BERT. The signature of the sentence would be a matrix with M*(1+k) rows and D columns, where D is the dimension (1024 for bert-large-cased).", "Once the signature of a sentence is computed as described above, we can compute the similarity score between two sentences as shown below in the prototype/reference implementation", "When computing the similarity of an input sentence with a known set of sentences (e.g. document titles), the pairwise scores computed above is used to compute a relative score of closeness of the input sentence to all sentences in the known set.", "The weighting function in the score computation above is based on the occurrence frequency of terms in a reference corpus. Essentially the contribution of cosine similarity between word pairs created from two sentence signatures is weighted by the importance of that score to the similarity computation as a function of the occurrences of those terms in a reference corpus. This ensures glue words like \u201cthe\u201d, \u201cof\u201d that occur in a sentence contribute less than words that truly capture meaning. The relative lengths of the sentence pairs are also factored in the score computation to ensure short sentences pick longer sentences that are similar as opposed to the other way around. This is particularly useful when using this approach for document search where sentences in the document are converted to sentence signatures.", "Two sets of sentences characterizing short (average sentence length 8 words) and long sentences (average sentence length 51 words) are used to qualitatively compare the three models (Universal sentence encoder- USE, sentence transformer, and SBERT-WK) with the similarity computation approach described above.", "The short sentence set is largely composed of test sentences showcased by USE and sentence transformers in their publications.", "The long sentence set is extracted from Fasttext data where humans have labeled sentences into 14 categories. These categories are not strict categories \u2014 a sentence could potentially belong to multiple categories in some cases. Also, some of the test sentences are multiple sentences \u2014 almost representing a mini paragraph.", "Three sentences belonging to a single cluster/category are used to represent a group, with a total of 42 sentences belonging to 14 clusters (with the caveat mentioned earlier about the longer sentences set having some sentences belonging to multiple clusters). Few clusters from both these tests are shown below.", "A few unique aspects of the sentence signature approach in contrast to the other three models", "A quantitative comparison of models on a benchmark test set for sentence similarity task remains to be done.", "One of the untapped potential of transformer based models like BERT is the fixed set of learned vectors representing its vocabulary. Though these vectors are no different in spirit from word vectors learned by models like word2vec, these models have two distinct advantages", "These two facts, enable even a bag of signature words that only indirectly captures sequence information using context sensitive words, to perform almost as well on short sentences, and even better on long sentences than other models.", "Prototype reference implementation available on Github.", "The three models used to qualitatively benchmark the current approach. All three have reference implementations on Github", "A baseline model for evaluating sentence embeddings(2016) using models like word2vec. This simple model outperformed sequence models (RNNS/LSTMs) in sentence similarity tasks.", "The sentence pairs that led to light shaded cells away from the diagonal in the long sentence test ( ~51 words per sentence) is examined below. The figure below is a magnified version of Figure 10, right side heat map. The white colored cells are sentence pairs with a score of 1 (the score is a relative measure score unlike cosine distance measures where we would typically only have a score of 1 for two sentences that are verbatim the same sentence)", "The corresponding sentence pairs for the white squares away from the diagonal are shown below.", "The highest contribution pairs from the sentence signatures three false sentence pairs are examined below. These offer insight into why these sentences matched and could serve as a means to filter sentence pairs.", "The first sentence pair and its top matching descriptors in sentence signatures", "The second sentence pair and its top matching descriptors in sentence signatures. The reason for these sentences coming close is quite evident from the descriptor pairs\u2014 the concept of wings that is common to butterflies and the plane played a dominant role by several weak pairwise interactions adding up to a signal.", "In the last sentence pair, the pairs do not have as much explanatory value as in the previous one other than the fact, other than the fact that the pairs are not of much interest, to begin with.", "This article was manually imported from Quora https://qr.ae/pNKmJ7"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F851e74921cf9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://ajitrajasekharan.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Ajit Rajasekharan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffd04a90b4be7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=post_page-fd04a90b4be7----851e74921cf9---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F851e74921cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----851e74921cf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F851e74921cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=-----851e74921cf9---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/pdf/1803.11175.pdf", "anchor_text": "Google\u2019s Universal sentence encoder (2018)"}, {"url": "https://arxiv.org/pdf/1908.10084.pdf", "anchor_text": "Sentence transformers (2019)"}, {"url": "https://arxiv.org/pdf/2002.06652.pdf", "anchor_text": "(SBERT-WK, June 2020)"}, {"url": "https://github.com/hanxiao/bert-as-service", "anchor_text": "pooling of word vectors across layers"}, {"url": "https://arxiv.org/pdf/2002.06652.pdf", "anchor_text": "SBERT-WK"}, {"url": "https://towardsdatascience.com/examining-berts-raw-embeddings-fd905cb22df7", "anchor_text": "an earlier post"}, {"url": "https://towardsdatascience.com/examining-berts-raw-embeddings-fd905cb22df7", "anchor_text": "BERT\u2019s raw word embeddings capture useful and separable information"}, {"url": "https://github.com/facebookresearch/fastText", "anchor_text": "Fasttext data"}, {"url": "https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a", "anchor_text": "unsupervised NER"}, {"url": "https://github.com/ajitrajasekharan/unsupervised_sentence_representations.git", "anchor_text": "available on Github"}, {"url": "https://arxiv.org/pdf/1803.11175.pdf", "anchor_text": "Universal Sentence encoder, 2018"}, {"url": "https://arxiv.org/pdf/1908.10084.pdf", "anchor_text": "Sentence transformer, 2019"}, {"url": "https://arxiv.org/pdf/2002.06652.pdf", "anchor_text": "SBERT-WK, 2020"}, {"url": "https://openreview.net/pdf?id=SyK00v5xx", "anchor_text": "A baseline model for evaluating sentence embeddings"}, {"url": "https://qr.ae/pNKmJ7", "anchor_text": "https://qr.ae/pNKmJ7"}, {"url": "https://medium.com/tag/naturallanguageprocessing?source=post_page-----851e74921cf9---------------naturallanguageprocessing-----------------", "anchor_text": "Naturallanguageprocessing"}, {"url": "https://medium.com/tag/nlp?source=post_page-----851e74921cf9---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----851e74921cf9---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----851e74921cf9---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----851e74921cf9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F851e74921cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----851e74921cf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F851e74921cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----851e74921cf9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F851e74921cf9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffd04a90b4be7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=post_page-fd04a90b4be7----851e74921cf9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F974aed893170&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&newsletterV3=fd04a90b4be7&newsletterV3Id=974aed893170&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----851e74921cf9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Written by Ajit Rajasekharan"}, {"url": "https://ajitrajasekharan.medium.com/followers?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "779 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffd04a90b4be7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=post_page-fd04a90b4be7----851e74921cf9---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F974aed893170&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-creation-of-interpretable-sentence-representations-851e74921cf9&newsletterV3=fd04a90b4be7&newsletterV3Id=974aed893170&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----851e74921cf9---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Ajit Rajasekharan"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Unsupervised NER using BERTTL;DR"}, {"url": "https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "\u00b721 min read\u00b7Feb 28, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d7af5f90b8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-ner-using-bert-2d7af5f90b8a&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----2d7af5f90b8a----0-----------------clap_footer----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a?source=author_recirc-----851e74921cf9----0---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d7af5f90b8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-ner-using-bert-2d7af5f90b8a&source=-----851e74921cf9----0-----------------bookmark_preview----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----851e74921cf9----1---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----851e74921cf9----1-----------------bookmark_preview----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----851e74921cf9----2---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----851e74921cf9----2-----------------bookmark_preview----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/semantic-search-using-bert-embeddings-511c5d78348e?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Ajit Rajasekharan"}, {"url": "https://ajitrajasekharan.medium.com/semantic-search-using-bert-embeddings-511c5d78348e?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "Semantic search using BERT embeddingsBERT output which is essentially context sensitive word vectors, has been used for state of art results in downstream tasks like\u2026"}, {"url": "https://ajitrajasekharan.medium.com/semantic-search-using-bert-embeddings-511c5d78348e?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": "9 min read\u00b7Mar 23, 2019"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F511c5d78348e&operation=register&redirect=https%3A%2F%2Fajitrajasekharan.medium.com%2Fsemantic-search-using-bert-embeddings-511c5d78348e&user=Ajit+Rajasekharan&userId=fd04a90b4be7&source=-----511c5d78348e----3-----------------clap_footer----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/semantic-search-using-bert-embeddings-511c5d78348e?source=author_recirc-----851e74921cf9----3---------------------8b1c2fe2_745c_4eb9_9ebd_11061995df54-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F511c5d78348e&operation=register&redirect=https%3A%2F%2Fajitrajasekharan.medium.com%2Fsemantic-search-using-bert-embeddings-511c5d78348e&source=-----851e74921cf9----3-----------------bookmark_preview----8b1c2fe2_745c_4eb9_9ebd_11061995df54-------", "anchor_text": ""}, {"url": "https://ajitrajasekharan.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "See all from Ajit Rajasekharan"}, {"url": "https://towardsdatascience.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://medium.com/@marcellusruben?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Ruben Winastwan"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Semantic Textual Similarity with BERTHow to use BERT to calculate the semantic similarity between two texts"}, {"url": "https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b711 min read\u00b7Feb 15"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffc800656e7a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-textual-similarity-with-bert-fc800656e7a3&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----fc800656e7a3----0-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/semantic-textual-similarity-with-bert-fc800656e7a3?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffc800656e7a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsemantic-textual-similarity-with-bert-fc800656e7a3&source=-----851e74921cf9----0-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://erickleppen.medium.com/?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Eric Kleppen"}, {"url": "https://python.plainenglish.io/?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Python in Plain English"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Topic Modeling For Beginners Using BERTopic and PythonHow to make sense of your text data by reducing it to topics"}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b711 min read\u00b7Feb 12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fpython-in-plain-english%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&user=Eric+Kleppen&userId=1e2ea32699c9&source=-----aaf1b421afeb----1-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://python.plainenglish.io/topic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faaf1b421afeb&operation=register&redirect=https%3A%2F%2Fpython.plainenglish.io%2Ftopic-modeling-for-beginners-using-bertopic-and-python-aaf1b421afeb&source=-----851e74921cf9----1-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/advanced-topic-modeling-with-bertopic-85fb8a90369e?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "James Briggs"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/advanced-topic-modeling-with-bertopic-85fb8a90369e?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Advanced Topic Modeling with BERTopicHow do we organize the world\u2019s most unorganizable data?"}, {"url": "https://towardsdatascience.com/advanced-topic-modeling-with-bertopic-85fb8a90369e?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b712 min read\u00b7Dec 19, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F85fb8a90369e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-topic-modeling-with-bertopic-85fb8a90369e&user=James+Briggs&userId=b9d77a4ca1d1&source=-----85fb8a90369e----0-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/advanced-topic-modeling-with-bertopic-85fb8a90369e?source=read_next_recirc-----851e74921cf9----0---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F85fb8a90369e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-topic-modeling-with-bertopic-85fb8a90369e&source=-----851e74921cf9----0-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://medium.com/@arthurmello_?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Arthur Mello"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Exploratory Data Analysis: The Ultimate WorkflowExplore the true potential of your data with Python"}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b716 min read\u00b7Apr 20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&user=Arthur+Mello&userId=9d32d5e0ac40&source=-----a82b1d21f747----1-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/exploratory-data-analysis-the-ultimate-workflow-a82b1d21f747?source=read_next_recirc-----851e74921cf9----1---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa82b1d21f747&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fexploratory-data-analysis-the-ultimate-workflow-a82b1d21f747&source=-----851e74921cf9----1-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----2-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----851e74921cf9----2---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----851e74921cf9----2-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/let-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://joshnjuny.medium.com/?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://joshnjuny.medium.com/?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Seungjun (Josh) Kim"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/let-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "Let us Extract some Topics from Text Data \u2014 Part IV: BERTopicLearn more about the family member of BERT for topic modelling"}, {"url": "https://towardsdatascience.com/let-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": "\u00b710 min read\u00b7Dec 19, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F46ddf3c91622&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flet-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622&user=Seungjun+%28Josh%29+Kim&userId=d34abe9e1001&source=-----46ddf3c91622----3-----------------clap_footer----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/let-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622?source=read_next_recirc-----851e74921cf9----3---------------------0655a1ea_063e_4eae_9c68_b5518a58cb27-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F46ddf3c91622&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flet-us-extract-some-topics-from-text-data-part-iv-bertopic-46ddf3c91622&source=-----851e74921cf9----3-----------------bookmark_preview----0655a1ea_063e_4eae_9c68_b5518a58cb27-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----851e74921cf9--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----851e74921cf9--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}