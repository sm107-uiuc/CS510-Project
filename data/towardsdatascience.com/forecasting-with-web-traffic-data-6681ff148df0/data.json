{"url": "https://towardsdatascience.com/forecasting-with-web-traffic-data-6681ff148df0", "time": 1683012205.342832, "path": "towardsdatascience.com/forecasting-with-web-traffic-data-6681ff148df0/", "webpage": {"metadata": {"title": "Forecasting with web traffic data | by Sheenal Srivastava | Towards Data Science", "h1": "Forecasting with web traffic data", "description": "Typically, when you have access to time series data, in this case, we are going to look at an example where we have one week\u2019s worth of web traffic data, it is instinctive to apply a time series\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Typically, when you have access to time series data, in this case, we are going to look at an example where we have one week\u2019s worth of web traffic data, it is instinctive to apply a time series model. However, this does not always need to be the case and I will demonstrate why further in this blog post.", "In this post, you will learn how to:", "Data Problem: Predict whether a website user will become a lead the next day?", "Dataset: A dataset of a 1 week sample of website traffic was provided consisting of three variables: user_id, event (\u201cview\u201d, \u201csearch\u201d, or \u201clead\u201d) and timestamp (date and time)", "Proposed method: In order to predict the likelihood of whether a user will submit a lead the next day, we need to understand the user\u2019s previous day\u2019s or previous several days\u2019 activities as well as aggregated activity on the website. For this we need to create features.", "Once the dataset is loaded, it always helps to view the dataset to ensure it has been read in correctly. As shown below, we can see that the dataset consists of four columns: the type of event (\u201cview\u201d, \u201csearch\u201d or \u201clead\u201d) , the user id (unique identifier), timestamp (time and date when user accessed the website) and just the date.", "Time variables and unique identifiers are what I like to call \u201cjunk\u201d variables. They do not assist the model in prediction. However, time is an important feature in our case as we want to know whether a user will become a lead the next day. An individual user id is also important. So, how can we still use this information.", "This brings me to the next part of modelling \u2014 feature engineering.", "As a user may view or search a website one or more times a day, it makes sense to aggregate this information to reduce the number of records per user but also to be able to create a daily dataset \u2014 i.e. one record per day per user. This can be done using R\u2019s dplyr package or sqldf (writing SQL code in R).", "In the below code snippet, I have grouped the dataset by date and userid to calculate the number of views, number of searches and number of leads per day per user.", "Next, in order to use the date variable meaningfully, we can create time-related variables such as day when website was accessed, hour when it was accessed, month of access and week of access. Since, we only have one week\u2019s worth of day, only day of access (i.e. Sun vs. Mon) may be useful. The below code can be used to create time-related variables.", "Now, because we want to predict whether a user will become a lead the next day, we want to know about the user\u2019s previous activity. For instance, did the user view the website the previous day, or the day before, three days before? Did they also search the website previously?", "To use previous activity in order to predict future activity, we need to create lag variables. As we want to predict whether a user will become a lead the next day, we use the previous day\u2019s activity to predict the next day\u2019s activity.", "Firstly, you need to order the data by date. Then, you want to group the data by userid as you want to predict whether a given user will become a lead the next day.", "To predict whether a user becomes a lead the next day, we need to know whether the customer was a lead the previous day (lag num_leads by 1), whether they viewed and searched the website the previous day (lag num_views and num_searches by 1), and total number of views and searches to current date (cum_sum_views and cum_views_searches).", "In temporal data, it is common to create variables such as rolling mean averages, rolling median averages, and various lag variables, but since we have access to only one week\u2019s worth of data, these variables do not seem reasonable.", "Now, we can only predict whether a user becomes a lead the next day if we have previous day information of the user. For instance, if the user only shows up in the dataset at the end of the week (the 7th day), it is difficult to test our model accuracy for this user as we do not have information on whether this user became a lead. Hence, such records were removed from the dataset.", "The second thing to do is to then decide on a model. As the problem is to determine whether or not a user a becomes a lead the next day, it is a binary problem and also a classification problem \u2014 i.e. user becomes a lead = Success = \u201c1\u201d, user does not become a lead = Failure = \u201c0\u201d. To model this problem, we need to feature engineer this target variable as follows.", "We have removed duplicate records, created a daily dataset with one record per user per day, and created time-dependent and our target variable (what we want to predict).", "The next step is to now decide how we are going to train and test our model. In most cases, it makes sense to split the data at random \u2014 i.e. a random subset of rows become the training set and the remainder become the test set. This way your model is trained on a dataset on which it learns and then tested for accuracy on data it has never seen.", "However, when you have temporal data, you are predicting for a time in the future, so the dataset should be split based on time, i.e. first 75% of the dataset is used for training (i.e. Monday to Thursday) and the remainder is used for test (Friday to Sunday). As our dataset is for only one week, this split does not seem reasonable.", "In our example, we want to predict whether a particular user will become a lead. So, it makes sense to split the dataset by userids, where the model is trained on a particular set of users and then tested for accuracy on users it has never encountered. To split the data in this way, the following code was written.", "Once you have your training set and test, you can now start modelling! :)", "For binary classification, you need a classification model. Tree-based methods are commonly used in binary classification. A popular tree-based method is xgboost that learns from each new tree (iteration) that is created by trying to reduce the percentage of error. Unlike a random forest, where the final result is an ensemble of trees or an average weighted tree, the final xgboost decision tree is one that has the lowest error rate out of all its rounds.", "Both randomforest and xgboost are known to overfit data as they try to improve on previous iterations; however, it is up to the modeller to determine whether the variables provided to the model are independent (not correlated), informative and not biasing the results in any way.", "The xgboost model in R requires a matrix and defined parameters as shown in the below code snippet.", "The following steps are required for an xgboost model:", "While your model is training, you can test its accuracy using a method called cross-validation. In cross-validation, you run multiple different training test splits and then average the results, instead of relying entirely on a single particular training set. The most common type of cross-validation is k-fold cross-validation most commonly with K set to 5 or 10. For example, to do five-fold cross-validation, the original dataset is partitioned into five parts of equal or close to equal size. Each of these parts is called a \u201cfold\u201d. Then a series of five models is trained one per fold. The first model: Model one, is trained using folds 2 through 5 as the training set and evaluated using fold 1 as the test set. The second model: Model 2, is trained using Folds 1, 3, 4, and 5 as the training set, and evaluated using Fold 2 as the test set, and so on. When this process is done, we have five accuracy values, one per fold. It is common to take the average of the accuracy scores.", "You can set up your model for cross-fold validation as follows. Here we have specified five rounds of cross-validation, told the model to run 1000 iterations but to stop early (at the 20th round) if it no longer shows any improvement in accuracy.", "The final line tells us at which iteration did the model produce a tree with lowest error. The output in our case is the 40th iteration.", "Now, we can use this information to run our model on the training set and get it to stop at the 40th iteration. We have also told our model to use the built-in error metric to evaluate the tree as well as the logloss metric.", "A feature importance plot tells us how the variables in the model were used to predict whether or not a user will become a lead the next day.", "Here, we can see that the number of views and number of searches on the day are the most important predictors in predicting whether or not a customer will become a lead on the same day. We can also see that despite creating lag and cumulative variables, they are not very useful. However, this was expected as the dataset covers a very short timeframe of one week.", "The next step is to test for model accuracy. This requires setting up the test dataset as a matrix and running the command \u201cpredict\u201d on the test set using the trained model.", "To test for model accuracy, here we compare how many of the lead_indicator values were classified correctly as \u201c0\u201d or \u201c1\u201d by the model. The \u201cpred\u201d dataset is recoded as the model outputs probabilities. Any probability greater than 0.5 is converted to \u201c1\u201d (is a lead) and any value less than 0.5 is converted to \u201c0\u201d (not a lead). We sum all the instances where the predicted value (\u201cprediction\u201d) is equal to the original value in the test set (testMatrix$label), and divide it by the size of the test set.", "Here, we get an accuracy rate of 97.53%, or an error rate of 0.03, which means that 97.53% of all users in the test set were classified correctly as whether or not they will become a lead the next day.", "If you like me can\u2019t believe your eyes, it is helpful to combine the test set with the predictions to see the information side by side as follows. In the below image, you can see that for the 15th of January 2019, all users did not become leads on this day and the prediction is \u201c0\u201d (non-lead) for these users.", "If our model had shown reduced accuracy, we can play with the xgboost parameters such as tree depth, number of rounds, minimum number of rows used for tree branch splitting. However, in this case, with such good accuracy, this was not required.", "Hopefully, you now have a good understanding of how to model time-series data of a classification nature! Any questions, please comment below.", "The full code file can be found here:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6681ff148df0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----6681ff148df0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sheenalsrivastava?source=post_page-----6681ff148df0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Sheenal Srivastava"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42bf180d6f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&user=Sheenal+Srivastava&userId=42bf180d6f14&source=post_page-42bf180d6f14----6681ff148df0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://gist.github.com/shedoesdatascience/fbdd1b52c5089d3b80ba512f969e704c", "anchor_text": "https://gist.github.com/shedoesdatascience/fbdd1b52c5089d3b80ba512f969e704c"}, {"url": "https://medium.com/tag/r-programming?source=post_page-----6681ff148df0---------------r_programming-----------------", "anchor_text": "R Programming"}, {"url": "https://medium.com/tag/time-series-forecasting?source=post_page-----6681ff148df0---------------time_series_forecasting-----------------", "anchor_text": "Time Series Forecasting"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----6681ff148df0---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/gbm?source=post_page-----6681ff148df0---------------gbm-----------------", "anchor_text": "Gbm"}, {"url": "https://medium.com/tag/gradient-boosting?source=post_page-----6681ff148df0---------------gradient_boosting-----------------", "anchor_text": "Gradient Boosting"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&user=Sheenal+Srivastava&userId=42bf180d6f14&source=-----6681ff148df0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&user=Sheenal+Srivastava&userId=42bf180d6f14&source=-----6681ff148df0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F6681ff148df0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----6681ff148df0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----6681ff148df0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6681ff148df0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6681ff148df0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----6681ff148df0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----6681ff148df0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sheenalsrivastava?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sheenal Srivastava"}, {"url": "https://medium.com/@sheenalsrivastava/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "67 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F42bf180d6f14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&user=Sheenal+Srivastava&userId=42bf180d6f14&source=post_page-42bf180d6f14--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1966e1e5a2c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-with-web-traffic-data-6681ff148df0&newsletterV3=42bf180d6f14&newsletterV3Id=1966e1e5a2c8&user=Sheenal+Srivastava&userId=42bf180d6f14&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}