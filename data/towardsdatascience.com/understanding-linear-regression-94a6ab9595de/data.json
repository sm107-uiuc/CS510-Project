{"url": "https://towardsdatascience.com/understanding-linear-regression-94a6ab9595de", "time": 1683015329.415447, "path": "towardsdatascience.com/understanding-linear-regression-94a6ab9595de/", "webpage": {"metadata": {"title": "Understanding Linear Regression. The Workhorse Of Data Science | by Tony Yiu | Towards Data Science", "h1": "Understanding Linear Regression", "description": "Despite the prevalence of more complicated and fancier models in recent years, linear regression remains hard to beat because of its versatility, robustness, and explainability. It\u2019s a simple but\u2026"}, "outgoing_paragraph_urls": [{"url": "https://tonester524.medium.com/membership", "anchor_text": "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!", "paragraph_index": 32}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership", "paragraph_index": 34}], "all_paragraphs": ["Despite the prevalence of more complicated and fancier models in recent years, linear regression remains hard to beat because of its versatility, robustness, and explainability.", "It\u2019s a simple but powerful model that just gets the job done. And if you want to go into a quantitative field, you will need to understand how it works.", "Linear regression is basically line fitting. It asks the question \u2014 \u201cWhat is the equation of the line that best fits my data?\u201d Nice and simple.", "The equation of a line is:", "Y, the target variable, is the thing we are trying to model. We want to understand (a.k.a. explain) its variance. In statistics, variance is a measure of uncertainty. It\u2019s the tendency of a value to whip about its mean.", "The graphic to the left illustrates this. The green variable has a high variance and thus a large cone of uncertainty around its mean (the center of the cone). The red variable has a lower variance. Knowing nothing else about the variables, we would feel much more confident in our ability to not be too far off when guessing the value of the red variable.", "But in data science and statistics in general, we\u2019re not worried about variance, we\u2019re only worried about variance that cannot be explained. That is, if we can find some other variable (the feature variable, X), that explains much of the variance in Y, then we are good.", "With such a feature variable, if someone were to ask me for my prediction of Y, I just need to look up what X is equal to, and I can be reasonably certain of what Y will be. Much of Y\u2019s variance has been explained by incorporating X.", "So why does line fitting help us explain the variance? Think about what the line\u2019s equation represents. It defines the relationship between X and Y. By multiplying X by b1 and summing with b0 (b0 + b1*X), we get our prediction of Y based on a given value of X.", "Of course, this only works if X and Y are correlated (either positively or negatively). Correlation measures the tendency of two things to move together (or opposite of each other in the case of a negative correlation). For example, people\u2019s height and weight are positively correlated. The taller you are, the more you tend to weigh.", "So line fitting allows us to infer the value of something we don\u2019t know, Y, from the value of something that we do know, X, thanks to the correlation between X and Y.", "We are explaining the variance of Y using the X variables in our linear regression equation. By attributing (a.k.a. explaining) variance this way, we are in effect reducing it \u2014 explained variance is variance that we no longer have to worry about.", "The lynchpin assumption is that the X variables are readily measurable, understood, and not themselves a mystery. A common modeling mistake is to forecast something using variables that are themselves not observable in real-time. A model that forecasts the future using data from the future is no good.", "Let\u2019s see how this process works. When we start out with just a Y variable, all we know about it is its distribution. In the figure below, all the variance (the green cone) is unexplained and our best guess of the future value of Y is its mean.", "Now let\u2019s say we\u2019ve found a feature variable, X, with a positive correlation to Y. The figure below shows how X helps to explain variance. We can segment the observations of Y into two sections based on their X values. For low values of X, Y has an expected value of Mean 1 and a variance approximated by the left red cone. For high values of X, Y has an expected value of Mean 2 and a variance approximated by the right red cone.", "Notice how by segmenting this way, the variance (the red cones) has been reduced relative to the original green cone. And our new prediction of Y, either Mean 1 or Mean 2 depending on what X is, is significantly more precise than our previous naive prediction (the mean of Y).", "But why stop at two segmentations? If we drew more blue dashed vertical lines, and broke the data into even more buckets, we could explain even more variance and generate even more precise predictions.", "And that\u2019s what linear regression does. In effect, it draws tons and tons of vertical lines that break the data into numerous tiny segmentations. This maximizes both the variance explained and the precision around our prediction.", "Let\u2019s quickly cover how linear regression finds the line of best fit. While there is an analytical solution, you can think of it as an optimization problem. The linear regression algorithm wants to:", "Error is the distance between the data (black dots) and the blue line \u2014 in the picture below, the red arrows denote error. We square the error because it can be either positive or negative.", "Now that we know that error is the difference between the actual observations (Y, the black dots) and our prediction (the blue line), we can write out our optimization problem in more detail:", "So to calculate the sum of squared errors, we take every vertical distance between a black dot and the blue line, square them, and sum them up. Finding the values of b0 and b1 that minimize this sum of squared errors gets us to the line of best fit.", "The parameters (b0, b1, etc.), known as betas, that fall out of a regression are important. In our earlier example, we had just a single feature variable. But say we had three feature variables:", "A key assumption for the interpretation of the betas is that you can hold the other feature variables constant. In some cases, it might be extremely hard to shift one feature without changing another. In this case, we would want to include these interaction effects (a topic for another post).", "Finally, we want to figure out how much of the original variance we were able to explain (since the goal is to explain, and therefore reduce variance).", "We can do that by calculating the R\u00b2:", "The residual (a.k.a. error) sum of squares is proportional to the variance of our prediction errors (the vertical distances between the black dots and the blue line). Prediction error is the difference between the actual observation and our model\u2019s prediction of it. It is a measure of unexplained variance.", "Total sum of squares is proportional to the total variance (of Y) that we are trying to explain \u2014 it\u2019s actually the numerator of the formula for the variance of Y.", "The ratio of residual sum of squares to total sum of squares measures the proportion of variance left unexplained after running the linear regression. In other words, it\u2019s the proportion of uncertainty that we could not make vanish with our linear regression.", "Since R\u00b2 is one minus that ratio, it can be thought of as the proportion of variance explained:", "So if after running our regression, we see an R\u00b2 of 0.90, that means the X variables we included in our model helped explain 90% of the variance observed in Y. In other words, we successfully explained away much of uncertainty around the variable we are interested in.", "In future posts, we will do some examples as well as look at what happens when some of the assumptions that underpin linear regression are violated. Until then, cheers!", "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist. Founder Alpha Beta Blog. Doing my best to explain the complex in plain English. Support my writing: https://tonester524.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F94a6ab9595de&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://tonester524.medium.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7----94a6ab9595de---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@drew_beamer?utm_source=medium&utm_medium=referral", "anchor_text": "Drew Beamer"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "If you liked this article and my writing in general, please consider supporting my writing by signing up for Medium via my referral link here. Thanks!"}, {"url": "https://towardsdatascience.com/the-art-of-forecasting-d2a8806b7aa0", "anchor_text": "The Art of ForecastingWhat Really Happens Under The Hood When We Attempt To Forecast The Futuretowardsdatascience.com"}, {"url": "https://towardsdatascience.com/understanding-logistic-regression-using-a-simple-example-163de52ea900", "anchor_text": "Understanding Logistic Regression Using a Simple ExampleLogistic regression is one of the foundational tools for making classifications. And as a future data scientist, I\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/understanding-maximum-likelihood-estimation-mle-7e184d3444bd", "anchor_text": "Understanding Maximum Likelihood Estimation (MLE)What Is It? And What Is It Used For?towardsdatascience.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----94a6ab9595de---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----94a6ab9595de---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/statistics?source=post_page-----94a6ab9595de---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/analytics?source=post_page-----94a6ab9595de---------------analytics-----------------", "anchor_text": "Analytics"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----94a6ab9595de---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&user=Tony+Yiu&userId=840a3210fbe7&source=-----94a6ab9595de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&user=Tony+Yiu&userId=840a3210fbe7&source=-----94a6ab9595de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F94a6ab9595de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----94a6ab9595de---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----94a6ab9595de--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----94a6ab9595de--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----94a6ab9595de--------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://tonester524.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tony Yiu"}, {"url": "https://tonester524.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "102K Followers"}, {"url": "https://tonester524.medium.com/membership", "anchor_text": "https://tonester524.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840a3210fbe7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&user=Tony+Yiu&userId=840a3210fbe7&source=post_page-840a3210fbe7--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F78d3e392d884&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-linear-regression-94a6ab9595de&newsletterV3=840a3210fbe7&newsletterV3Id=78d3e392d884&user=Tony+Yiu&userId=840a3210fbe7&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}