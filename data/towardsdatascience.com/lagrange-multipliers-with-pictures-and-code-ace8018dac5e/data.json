{"url": "https://towardsdatascience.com/lagrange-multipliers-with-pictures-and-code-ace8018dac5e", "time": 1682996286.7343118, "path": "towardsdatascience.com/lagrange-multipliers-with-pictures-and-code-ace8018dac5e/", "webpage": {"metadata": {"title": "Lagrange multipliers with visualizations and code | by Rohit Pandey | Towards Data Science", "h1": "Lagrange multipliers with visualizations and code", "description": "In this story, we\u2019re going to take an aerial tour of optimization with Lagrange multipliers. When do we need them? Whenever we have an optimization problem with constraints. Here are some examples\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@rohitpandey576/solving-systems-of-polynomial-equations-with-object-oriented-programming-797eb8add0fc", "anchor_text": "here", "paragraph_index": 32}], "all_paragraphs": ["In this story, we\u2019re going to take an aerial tour of optimization with Lagrange multipliers. When do we need them? Whenever we have an optimization problem with constraints. Here are some examples:", "We can see that constrained optimization can solve many practical, real world problems arising in domains from logistics to finance. In the rest of the blog, we will start with vanilla optimization without constraints. Then, we will add equality constraints. Then, we will describe the solution to completely general constrained optimization problem with both equality and inequality constraints (the conditions are called KKT \u2014 Karush, Kuhn, Tucker conditions). Finally, we demonstrate the power of these conditions on some toy problems. Many people consider the book by Nocedal and Wright the bible of numerical optimization and we will roughly follow chapter 13, side-stepping rigorous proofs (which can always be read from the text) and focusing more on visual intuition.", "In this scenario, we have some variables in our control and an objective function that depends on them. There is no constraint on the variables and the objective function is to be minimized (if it were a maximization problem, we could simply negate the objective function and it would then become a minimization problem).", "At any point, for a one dimensional function, the derivative of the function points in a direction that increases it (at least for small steps). Meaning that if we have a function f(x) and the derivative f\u2019(x) is positive, then increasing x will increase f(x) and decreasing it will decrease f(x). If we were minimizing f(x), we would just take a small step opposite to the sign of f\u2019(x) to decrease f(x). What if we\u2019re at a point where f\u2019(x)=0? Then, we might have reached an optima of f(x) since there\u2019s no where else to go.", "If there are multiple variables (say x and y), we can have a derivative with each of them. If we take these two numbers and construct a 2-d vector from them, we get the gradient of the function. Now, moving along the direction of the gradient will increase the function while moving opposite to it will decrease it (for small steps).", "This means that as long as the gradient is non-zero, we can\u2019t be at a minima since we can simply take a small step along the direction opposite to the gradient and decrease the function further. This means that a necessary (but not sufficient) condition for a point minimizing the function is that the gradient must be zero at that point.", "Let\u2019s take a concrete example so we can visualize what this looks like. Consider the function f(x,y) = x\u00b2+y\u00b2. This is a paraboloid and minimized when x=0 and y=0. The derivatives with respect to x and y become 2x and 2y respectively. So, the gradient becomes the vector \u2207f = [2x,2y]. We can see that this is zero only when x=0 and y=0. Otherwise, the gradient points in a direction where f(x,y) will increase. So, the direction opposite the gradient will decrease f(x,y). This is shown in the figure below. The pink curve is the objective function f(x,y) which is minimized at the green point (0,0). The purple arrows are the gradients, which point in the direction where f(x,y) will increase. So to decrease it, we move in the opposite direction until we reach the green point.", "To summarize, when optimizing a function, f in an unconstrained optimization problem, a necessary (but not sufficient) condition to be at a local optima is:", "It\u2019s like when you\u2019re at the top of a mountain (which would be a maxima). How do you know you\u2019re at the top? No matter which direction you step along, you end up decreasing your altitude. So you\u2019re definitely at an optima in your local neighborhood. Now, there might be another mountain right next to you which is even higher. So, you might not be at the global optima. In fact, if we consider the surface of the Earth as our domain (and height above sea level as our objective function), you\u2019re at a local optima if you\u2019re at the top of any old mountain (or building) but the global optima only if that mountain is Everest. In this article, we\u2019re going to be content with finding a local optima.", "Now what if we wanted to stay within the confines of a country? That would mean constraining the space in which we can search for our optima, making this an example of constrained optimization. In a way, un-constrained optimization is just a special case of constrained optimization.", "For unconstrained minimization/maximization problems, we simply look for a point where the gradient is the zero vector. If the gradient is not zero, we just take a small step in the direction opposite to where it is pointing (if we\u2019re minimizing; along it if we\u2019re maximizing) and keep doing this until we do get to a point where it is zero and hence, there is no where else to go (this optimization method is called gradient descent). Note that we don\u2019t have to move exactly along the gradient. As long as we move in a direction that has a positive projection (shadow) along the gradient, we end up increasing the objective function (and decreasing if we have a positive projection along the negative gradient). The figure below illustrates this. The green arrow is the gradient of the blue plane (and hence perpendicular to it) and the red arrow is the negative gradient. Since the light-blue arrows lie on the plane, the equation of the plane will yield 0 if we take a step along them. The yellow arrows have a positive shadow (projection) along the green one. So, moving along them will result in points that yield positive numbers when plugged into the equation of the plane (\u201cincrease\u201d it). Similarly, the pink arrows have a positive shadow along the red one (reverse gradient). So, moving along them will result in points that yield negative numbers when plugged into the equation of the plane (\u201cdecrease\u201d it).", "For un-constrained minimization, we looked for a point where the gradient was zero. This was because if it wasn\u2019t, we could decrease the objective function by going opposite to the gradient.", "The same idea can be extended to the case when we have equality constraints. Like before, we need to find a point where we can\u2019t find any possible direction to move where the objective function decreases. For unconstrained optimization, this simply meant that no such direction exists. When we have a constraint, there is another possibility. What if a direction that decreases the objective function exists, but the constraints forbid us from taking any step along it.", "Let\u2019s say you want to maximize the amount of money in your bank account. One way to immediately boost your earnings is to sell a kidney. But you probably have a constraint saying you\u2019re not going to lose a vital organ. So, even though an easy path to increasing your earnings exists, your constraint prevents you from accessing it.", "This means that the presence of the equality constraint actually reduces the strictness of the condition on the gradient. While it needed to be zero for a local optima without the equality constraint, it\u2019s now okay for it to be non-zero as long as moving in any direction that has a positive shadow along it causes us to violate the constraint. This can only happen when the plane of the constraint is perpendicular to the gradient (like the plane and green arrow in figure 2).", "Let\u2019s go back to our objective function f(x,y)=x\u00b2+y\u00b2. Let\u2019s add an equality constraint, y=1. This is a plane. In figure 3 below, the objective function is in pink and the plane is blue. Since we\u2019re constrained to stay on the plane, we can\u2019t move in any direction that has a positive or negative shadow along the gradient of the plane (blue arrows in the figure below) since that would increase or decrease the equation of the constraint, while we want to keep it constant. The plane intersects the equation of our objective function (pink paraboloid) in a curve which is a parabola. The pink arrows in the figure below are the gradients of the objective function at various points along this parabola. If the pink arrow has a projection along the blue plane, we can just move in the direction opposite to the vector corresponding to that projection. This will keep us on the plane, ensuring we don\u2019t violate the constraint while still reducing the objective function. However, at the green point in figure 3 below, the pink arrow (gradient of objective function) has no projection whatsoever along the blue plane. In other words, the pink arrow is parallel to the blue arrow (which is the gradient of the constraint plane).", "To decrease the objective function, we need to move in a direction that has a shadow along the negative gradient. But as soon as we do that, we\u2019ll end up leaving the plane of the constraint. So, the constraint makes it impossible to decrease the objective function further at the green point. This means it must be a local minima. An easy way to check this condition is to require that the pink gradient of the objective function is parallel to the blue gradient of the constraint plane. And if two vectors are parallel, we can write one as a multiple of the other. Let\u2019s call this multiple \u03bb. If the gradient of the objective function is \u2207f and that of the constraint is \u2207c, the condition above is:", "The \u03bb above is called the Lagrange multiplier. So, we now have a concrete condition to check for when looking for the local optima of a constrained optimization problem.", "Inequality constraints mean you have to stay on one side of a boundary defining a constraint function as opposed to on it (which was the case for equality constraints). For example, staying inside the boundary of a fence. If we know how to deal with inequality constraints, we can solve any constrained optimization problem. This is because equality constraints can be converted to inequality constraints. Let\u2019s say we require: c(x) = 0. Another way to express this is: c(x)\u22650 and c(x)\u2264 0. So, each equality constraint can always be replaced with two inequality constraints.", "Just as constrained optimization with equality constraints can be handled with Lagrange multipliers as described in the previous section, so can constrained optimization with inequality constraints. What sets the inequality constraint conditions apart from equality constraints is that the Lagrange multipliers for inequality constraints must be positive. To see why, again consider taking a small step in a direction that has a positive component along the gradient. If we can take a step along this direction (if we are maximizing; opposite to it if we are minimizing); we can\u2019t be at a maxima/minima. For inequality constraints, this translates to the Lagrange multiplier being positive. To see why, let\u2019s go back to the constrained optimization problem we considered earlier (figure 3).", "Now, let\u2019s change the equality constraint to inequality. This can be done in two ways with completely different results. We can either require:", "c(x,y) = y-1 \u22650. In this case, the constraint allows for anything in front of the blue plane in figure 3. It is easy to see that the green point in figure 3 continues to be a local optima. Also, since the blue arrow representing the constraints gradient and the pink arrow representing the objective function\u2019s gradient point in the same direction, we have:", "The other possibility is, c(x,y) = y-1\u22640. Now, the feasible region becomes everything behind the blue plane. The constraint gradients will flip. So, figure 3 will end up looking like this:", "So, it is clear that for an inequality constraint, the condition \u2207f=\u03bb \u2207c indicates we\u2019re at a local optima only when \u03bb>0.", "Putting all of this together, for a general optimization problem:", "We get the full suite of conditions required to be at a local optima:", "Where i \u2208 Equality and j \u2208 Inequality constraints.", "Also note that for the two inequality constraint problems we considered, when we had y-1\u22650, the green point in figure 3 was the solution. At this point, we were on the constraint plane (y-1=0). So, we actually had c(x)=0 and \u03bb>0.", "When we considered y-1\u22640 on the other hand, the yellow point (x=0,y=0) in figure 4 became the local minima. This point was also the solution to the un-constrained problem. So, we simply had \u2207f=0 here. Since the Lagrange condition requires \u2207f = \u03bb \u2207c, we get \u03bb \u2207c = 0. Now, \u2207c \u22600 at this point, which means we must have had: \u03bb=0.", "This means that if the constraint is active (c(x)=0), we should have \u03bb\u22650 while if it is not (c(x)\u2260 0) we should have \u03bb=0. So, one of them should be zero in all cases. This leads to the final condition (the complimentarity condition):", "Equations (1) through (5) are called the KKT conditions. Note that we haven\u2019t really provided rigorous proofs for them, just constructing them based on the simple example. For a proof, the reader should refer to chapter 13 of the book by Nocedal and Wright.", "A lot of people when they see these five equations feel like the problem has become even more complicated. How do these equations actually help us solve constrained optimization problems. The best way to get a feel for this is to go through some concrete examples. In the next section, we take a sample problem to which we know the answer in advance and see how the KKT conditions help us correctly identify all local optima.", "Special cases of the generalized optimization problem involve a linear objective function and linear constraints. This is called a linearly constrained linear program (LCLP). The objective function and constraints can also be quadratic and an optimization problem like this is called a quadratically constrained quadratic program (QCQP). There are software packages that are capable of solving these kinds of optimization problems for an obscenely large number of constraints (in the millions). For simpler problems with a more manageable number of constraints however, we can leverage algorithms that can solve most (more general) polynomially constrained polynomial programs. Which means that the objective function and constraints can be arbitrary polynomial functions. This is because there is a general framework for solving systems of polynomial equations called \u201cBuchberger\u2019s algorithm\u201d and the KKT conditions described above can be reduced to a system of polynomial equations. I wrote a detailed blog on Buchberger\u2019s algorithm for solving systems of polynomial equations here. There is a python library called \u201csympy\u201d that uses algorithms like this behind the scenes and solves general systems of polynomial equations. So without further ado, let\u2019s frame our first constrained optimization problem.", "Notice that the constraint (x\u00b2+y\u00b2=1) implies we\u2019re on the boundary of a circle with unit radius. So, we can say: x=cos(t), y=sin(t). The objective function then becomes: sin\u00b3(t)+cos\u00b3(t). If we plot this with t, we get the following graph:", "We can see that t=0, \u03c0/2 and 5\u03c0/4 correspond to local maxima while t=\u03c0/4, \u03c0 and 3\u03c0/2 correpond to local maxima. Now that we know the answer in advance, let\u2019s see if the KKT conditions described above can find these as well.", "Equation (1) gives (taking derivatives of objective function and constraint):", "Equating the two components of the vectors on the two sides leads to the two equations:", "Equation (2) simply requires that the equality constraint be satisfied:", "And since there are no inequality constraints, we don\u2019t need equations (3) to (6). Now, we can enter the three equations above into the symbolic equation solver the python library sympy provides.", "This leads to the following result (all possible solutions to the system above with values of x, y and \u03bb in that order):", "(-1,0) corresponds to t=\u03c0; (0,-1) corresponds to t=3\u03c0/2; (-sqrt(2)/2,-sqrt(2)/2) corresponds to t=5\u03c0/4 and (sqrt(2)/2,sqrt(2)/2) corresponds to t=\u03c0/4. So, we can see that all the local maxima and local minima we identified above have been identified by the KKT conditions. Now, we can simply find the maximum and minimum values of the objective function at these candidate points.", "Now, let\u2019s change our equality constraint from the problem above to an inequality constraint and see how that changes our solution.", "Where the constraint implied we could only be on the boundary of the unit circle in the previous case, we can now be anywhere inside it.", "The full heat-map of the objective function within the constraint disk is plotted below (looks like a planet with a star somewhere around the top-right corner). The red arrows are the gradients of the boundary of the constraint while the black ones are the gradients of the objective function.", "While the equality constrained problem was a one dimensional problem, this inequality constrained optimization problem is two dimensional. While there are only two ways to approach a point in one dimension (from left or right); there are an infinite number of ways to approach it in two dimensions. This means we need to beware of saddle points. These are points which qualify to be optima, but are not really optima since they are maxima when you approach them from one direction but minima when you approach them from another. The figure below shows what a saddle point looks like.", "So, we need to re-evaluate all the points that were local minima or maxima in the case of the equality constraint and make sure none of them become saddle points.", "Figure 5 tells us that t=0 (x=1,y=0) is a local maxima when approached along the boundary. And when we approach the point from inside the disk as well (say along the line joining x=0,y=0 to this point), the value of the objective function increases as we approach it. So, t=0 is a local maxima no matter where we approach it from. Using similar arguments (or noting the symmetry in x and y), so is t=\u03c0/2.", "Similarly we can argue that t=\u03c0 and t=3\u03c0/2 are local minima no matter where we approach them from inside the feasible region.", "Looking at t=\u03c0/4 however, we note from figure 5 that approaching it along the boundary makes it a local minima. However, approaching it from inside the disk (along the line joining the origin to this point for example) makes it a local maxima. So, it is overall neither a local maxima nor a local minima. Such a point is called a saddle point. Using similar arguments, t=5\u03c0/4 is also a saddle point.", "Now, let\u2019s see what the KKT conditions say for our problem. Plugging the objective function and constraints into the KKT equations (1) through (5) we get:", "To leverage polynomial equation solvers, we need to convert these to a system of polynomial equations. The first two conditions (6-(a) and (b))are already equations. The third one, x\u00b2+y\u00b2\u22641 (6-(c)) is an inequality. But we can convert it into an equality by introducing a slack variable, k; x\u00b2+y\u00b2+k\u00b2=1. The last equation, \u03bb\u22650 is similarly an inequality, but we can do away with it if we simply replace \u03bb with \u03bb\u00b2. Now, we demonstrate how to enter these into the symbolic equation solving library python provides.", "This produces the following result (the various solutions of the system above with variables x,y,\u03bb,k in order):", "The capital \u2018I\u2019 in the solutions above refers to the square root of unity. We want to reject these solutions since we require \u03bb\u00b2\u22650. This means that the points that satisfy the KKT conditions are: (-1,0); (0,-1); (0,0); (-1/sqrt(2),-1/sqrt(2)). As mentioned earlier, the points (-1,0) (corresponding to t=\u03c0) and (0,-1) (corresponding to t=3\u03c0/2) are the minima. (0,0) and (-1/sqrt(2),-1/sqrt(2)) are saddle points that are also caught in the net. But note that none of the local maxima are caught. I\u2019ll leave you with a small challenge. Change the code above so that it catches the maxima instead of the minima.", "If you liked the story, become a referred member :)", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I like to explain data science concepts through words, visualizations and code in the hope one of them will click. For my day job, I work at Microsoft Azure."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Face8018dac5e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@rohitpandey576?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohitpandey576?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Rohit Pandey"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa743c5fec8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&user=Rohit+Pandey&userId=a743c5fec8cd&source=post_page-a743c5fec8cd----ace8018dac5e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/ryu577/pyray", "anchor_text": "https://github.com/ryu577/pyray"}, {"url": "https://github.com/ryu577/pyray", "anchor_text": "https://github.com/ryu577/pyray"}, {"url": "https://github.com/ryu577/pyray", "anchor_text": "https://github.com/ryu577/pyray"}, {"url": "https://medium.com/@rohitpandey576/solving-systems-of-polynomial-equations-with-object-oriented-programming-797eb8add0fc", "anchor_text": "here"}, {"url": "https://medium.com/@rohitpandey576/membership", "anchor_text": "https://medium.com/@rohitpandey576/membership"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ace8018dac5e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/math?source=post_page-----ace8018dac5e---------------math-----------------", "anchor_text": "Math"}, {"url": "https://medium.com/tag/optimization?source=post_page-----ace8018dac5e---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/constraints?source=post_page-----ace8018dac5e---------------constraints-----------------", "anchor_text": "Constraints"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----ace8018dac5e---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&user=Rohit+Pandey&userId=a743c5fec8cd&source=-----ace8018dac5e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&user=Rohit+Pandey&userId=a743c5fec8cd&source=-----ace8018dac5e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Face8018dac5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ace8018dac5e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ace8018dac5e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ace8018dac5e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ace8018dac5e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohitpandey576?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@rohitpandey576?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rohit Pandey"}, {"url": "https://medium.com/@rohitpandey576/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "404 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa743c5fec8cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&user=Rohit+Pandey&userId=a743c5fec8cd&source=post_page-a743c5fec8cd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F3cd69f24197&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flagrange-multipliers-with-pictures-and-code-ace8018dac5e&newsletterV3=a743c5fec8cd&newsletterV3Id=3cd69f24197&user=Rohit+Pandey&userId=a743c5fec8cd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}