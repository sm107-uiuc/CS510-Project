{"url": "https://towardsdatascience.com/model-selection-101-using-r-c8437b5f9f99", "time": 1682994004.064037, "path": "towardsdatascience.com/model-selection-101-using-r-c8437b5f9f99/", "webpage": {"metadata": {"title": "Model selection 101, using R. Quick and dirty markup of simple model\u2026 | by Peter Nistrup | Towards Data Science", "h1": "Model selection 101, using R", "description": "A quick and simply guide on how to do model selection in R"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@peter.nistrup", "anchor_text": "follow my profile", "paragraph_index": 2}, {"url": "https://www.rdocumentation.org/packages/car/versions/1.0-2", "anchor_text": "https://www.rdocumentation.org/packages/car/versions/1.0-2", "paragraph_index": 33}, {"url": "https://github.com/pela15ae/statmod/blob/master/employment_data.txt", "anchor_text": "https://github.com/pela15ae/statmod/blob/master/employment_data.txt", "paragraph_index": 55}, {"url": "https://medium.com/@peter.nistrup", "anchor_text": "follow me on Medium", "paragraph_index": 57}, {"url": "https://twitter.com/peternistrup", "anchor_text": "Twitter", "paragraph_index": 57}, {"url": "http://www.linkedin.com/in/peter-nistrup/", "anchor_text": "www.linkedin.com/in/peter-nistrup/", "paragraph_index": 59}], "all_paragraphs": ["Since this is a very introductory look at model selection we assume the data you\u2019ve acquired has already been cleaned, scrubbed and ready to go. Data cleaning is a whole subject in and of itself and is actually the primary time-sink of any Data Scientist. Go to the end of this article if you want to download the data for yourself and follow along!", "Edit: I\u2019ve made a \u201csequel\u201d to this article about visualizing and plotting the model we find if you want to check that out after reading this one!:", "Make sure to follow my profile if you enjoy this article and want to see more!", "This is the skeleton I use for creating a simple LM or GLM:", "Lets start by setting up a workspace and loading our data. In this example we\u2019re working on a dataset describing employment-status of women based on whether or not you\u2019re a foreigner, the amount of government-entitled support (log-transformed), age, years of education and the number of children (spread in two categorical variables \u2018young.children\u2019 and \u2018school.children\u2019):", "The first thing we notice is that our response-variable is binomial (obviously) suggesting that we have a binomial distribution which means we\u2019ll have to fit a GLM instead of a traditional LM:", "This fit is the most general fit we can use by default, it fits a binomial model (family = binomial) with respect to the response-variable \u201cemployed\u201d having a value \u201cyes\u201d, using every variable in the dataset (~ .) giving us the following output:", "Right, so a few problems right off the bat, we don\u2019t like seeing p-values above 0.05, much less above 0.1, but before we recklessly remove them lets check for variable interactions and power-transformations first!", "Lets consider the possibility that there\u2019s a categorical difference between not having any children and actually having any number of children larger than zero, thus we add the categorical variables for having 0 children: \u2018factor(young.children == 0)\u2019, \u2018factor(school.children == 0)\u2019 and a combined factor for not having any children at all \u2018factor(young.children + school.children == 0)\u2019", "We can update our fit with the new variables:", "So we\u2019ve already improved our model a bit in terms of AIC from 1066.8 to 1050.2! Lets take a look at our continuous variables and watch for possible power-transformations:", "A neat way to look for potential power-transformations of a binomial distribution is using this custom function:", "It\u2019s actually decently simple, it plots the link(E[y|x]) against x with E[y|x] estimated using a Nadaraya-Watson kernel regression estimate:", "This take the following arguments:x \u2014 Your explanatory variablesy \u2014 The binary outcome variableh \u2014 Bandwidth for the Nadaraya-Watson kernel regression estimatedata \u2014 Self explanatory\u2026 \u2014 Whatever additional arguments you want to pass to plot()", "Using this function iterating over different bandwidths we get the following kinds of plot:", "In this example with \u2018age\u2019 we can see that the function begins smoothing around a bandwidth around 7, the graph could approximate a 2. or maybe 3. degree polynomial, the same is true for \u2018education\u2019 and \u2018gov.support\u2019 but for simplicity we\u2019ll consider the case of all three taking shape as 2. degree polynomials:", "Quite the improvement in terms of AIC, from 1050.2 to 1017.7! Lots of insignificant variables though!", "This is our first attempt at a \u201cfull\u201d model, so lets define this as our \u2018fit.2\u2019 and continue.", "The easiest way to check for variable interaction is using the R-function \u2018add1\u2019, this is simply the case of defining a scope to test and which test to use when testing relative to the original model. F-tests are usually only relevant for LM and AOV models so we can \u2018safely\u2019 ignore that testing criteria, we\u2019ll instead be using a \u03c7\u00b2-test (Chisq or Chi\u00b2):", "This scope is simply asking to test the current model (.~.) plus interaction between existing variables (+ .^2), this will output a lot of interactions, some with statistically significant P-values, but it can be annoying to manually sort through, so lets sort the list so we get the lowest P-values on the top:", "Right, so it seems like there might be an interaction between the foreigner and age variables. One thing to consider before simply adding the interaction with the lowest P-value is whether or not this makes sense in context of our current model, right now age\u00b2 is actually the most significant variable in our model so we might argue that adding the interaction between foreigner and age\u00b2 is more intuitive, for simplicity we\u2019ll stick with the foreigner:age interaction.", "Lets test for more interactions after adding the variable interaction foreigner:age:", "Now it seems like there\u2019s a significant interaction in foreigner:factor(young.children + school.children == 0)", "After a few rounds of this we end up seeing no new statistically significant interactions, by the end we\u2019ve added the following interactions: + foreigner:age + foreigner:factor(young.children + school.children == 0) + age:school.children + gov.support:factor(young.children == 0)", "So lets update our fit with the new variable interactions as follows:", "This process is quite similar to the last one in step 4. We\u2019ll simply be using the drop1 function in R now instead of add1, and due to us seeking to remove instead of appending variables we seek the highest P-value instead of the lowest (we\u2019ll still use \u03c7\u00b2-test as our criteria):", "This tells us mostly the same as our model-summary, gov.support\u00b2 definitely dosn\u2019t seem to be statistically significant, so we\u2019ll remove that first and so on and so forth, we end up removing the following variables:- gov.support\u00b2- young.children- education- education\u00b2", "After those have been removed we see that all the remaining variables are statistically significant, so lets update our fit by removing the variables listed above:", "Nice, another improvement in AIC although marginal and insignificant, the main advantage of this model over our previous is the added simplicity inherent in the reduced number of explanatory variables!", "One might wonder \u201cWhy aren\u2019t we removing the gov.support variable? It\u2019s clearly insignificant when looking at the summary of our model!\u201d this is due to the principle of marginality which prohibits us from removing an insignificant variable if said variable has a significant interaction with another, like gov.support:factor(young.children == 0).", "You might argue that removing gov.support would be beneficial to the simplicity of the model given that it\u2019s clearly insignificant and that the interaction with the young.children == 0 variable is only marginally significant (p = 0.435), however upon further inspection when removing gov.support from the model the variable-interaction splits into two variables for TRUE and FALSE, thus not giving us any added simplicity, the AIC, all other coefficients as well as the null- and residual deviance stays the exact same and by that account I close to leave it in the model.", "Doing an add1 and a drop1 test on our new and improved model shows us there\u2019re no new interactions that are significant and that all current variables are significant so we\u2019re done! The final fit is:", "So now that we have a model we\u2019re satisfied with we can look for outliers that negatively effect the model.", "Using the \u201ccar\u201d package https://www.rdocumentation.org/packages/car/versions/1.0-2 we can use the influencePlot() and outlierTest() functions to find potential outlier:", "We see that the datapoint 416 is classified as an outlier in both tests, we can take a look at the point in a few of our plots to gauge whether or not to remove it:", "It seems like this could very well be screwing a bit with our model, note that we should actually be using pearson residuals to gauge our models fit so the fact that we don\u2019t have anything close to a straight line in the upper left plot is fine, Q-Q plots are irrelevant for this kind of model as well.", "Lets try removing the point and take a look at the new fit:", "Down to almost 1000 AIC from the original 1067, this isn\u2019t really a relevant measure of performance when comparing the AIC of two different sets of data (since we removed point 416), we would actually have to conclude that 416 was an outlier in the initial model as well, remove it and then compare the AIC value of the initial model without point 416 to our final fit without point 416 as well.", "Looking at another round of influencePlot() and outlierTest() we find that datapoint 329 is acting out as well, however looking at the actual plots we see that we can\u2019t really justify a removal of the data like we could with 416. This is our final fit.", "So now that we have a final fit where we can\u2019t confidently add or remove any interactions variables and other transformations it\u2019s time to evaluate if our model actually fits our data and if there\u2019s even a statistically significant difference between our final fit and the first \u201cnaive\u201d fit.", "Lets start by taking a look at our fitted values vs. the Pearson residuals:", "This is a pretty decent fit, lets take a look at the fit for the major explanatory variables as well:", "With the exception of \u2018gov.support\u2019 everything looks quite nice, also the reason for the bend in \u2018gov.support\u2019 seems to be a single outlier in which someone was granted a substantially lower amount of support compared to all our other points of data.", "Overfitting is the bane of all statistical modelling, how can you make sure your model isn\u2019t just fitting to the exact data you fed it? The goal is to make a model which generalizes and doesn\u2019t just cater to the current data at hand. So how do we test if our model is overfitting on our data?", "A popular metric to test is the delta value generated through Cross-Validation, we can calculated these by using the cv.glm function from the \u2018boot\u2019 package and compare our final fit to our first!", "In the code above we\u2019re using k-fold cross-validation with k = 13 (since 13 is a factor of 871 which is the length of our data after removing the outlier) this means we\u2019re splitting our data in 13 \u2018chunks\u2019.", "The delta values is a vector wherein the first component is the raw cross-validation estimate of prediction error and the second component is the adjusted cross-validation estimate (designed to compensate for the bias introduced by not using an exhaustive testing methods such as leave-one-out)", "Running the code above yields the following delta-values, note that these are subject to some random variance so you might not get the exact same values:", "The prediction error is lower for the final fit, even when testing with cross-validation. Thus we can assume that our model hasn\u2019t been overfitting on our data!", "So now we\u2019ve concluded that our model is actually a pretty decent fit for our data, but is it a statistically significant difference from the \u201cnaive\u201d model without any transformations and variable interactions? We can use an ANOVA test for this, we just have to remove the same point of data in both fits:", "There\u2019s definitely a significant difference between the two fits, we can happily conclude that our hard work has paid off!", "Now that we\u2019ve gotten ourselves a model, how do we actually visualize and interpret what it says about the relationships in our data?", "Take a look at the following walk-trough which uses the same data and model as this article!:", "Please keep in mind that this is purely introductory and that this isn\u2019t an exhaustive analysis or conclusion! If we were more rigorous in our pursuit we would\u2019ve incorporated Cross-Validation tests and ANOVA tests on each new iteration of our model, ie. whenever we add a new variable, interaction or power-transformation.", "Feel free to message me if you have any questions and please correct me if you feel like I missed something or did something wrong, do keep in mind that this is suppose to serve as an introduction to modelling in R, I\u2019m well aware that this process is highly simplified compared to more advanced methods!", "If you want to try your luck with this same dataset give it a go here: https://github.com/pela15ae/statmod/blob/master/employment_data.txt", "The data is Danish so to convert the headers and categorical values to English run this piece of code:", "If you want to see and learn more, be sure to follow me on Medium\ud83d\udd0d and Twitter \ud83d\udc26", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "DATA SCIENCE, STATISTICS & AI \u2026 Twitter: @PeterNistrup, LinkedIn: www.linkedin.com/in/peter-nistrup/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc8437b5f9f99&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@peter.nistrup?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.nistrup?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Peter Nistrup"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93675cf59306&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&user=Peter+Nistrup&userId=93675cf59306&source=post_page-93675cf59306----c8437b5f9f99---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/@peter.nistrup/visualizing-models-101-using-r-c7c937fc5f04", "anchor_text": "Visualizing models 101, using RSo you\u2019ve got yourself a model, now what?medium.com"}, {"url": "https://medium.com/@peter.nistrup", "anchor_text": "follow my profile"}, {"url": "https://www.rdocumentation.org/packages/car/versions/1.0-2", "anchor_text": "https://www.rdocumentation.org/packages/car/versions/1.0-2"}, {"url": "https://medium.com/@peter.nistrup/visualizing-models-101-using-r-c7c937fc5f04", "anchor_text": "Visualizing models 101, using RSo you\u2019ve got yourself a model, now what?medium.com"}, {"url": "https://github.com/pela15ae/statmod/blob/master/employment_data.txt", "anchor_text": "https://github.com/pela15ae/statmod/blob/master/employment_data.txt"}, {"url": "https://medium.com/@peter.nistrup", "anchor_text": "follow me on Medium"}, {"url": "https://twitter.com/peternistrup", "anchor_text": "Twitter"}, {"url": "https://medium.com/@peter.nistrup", "anchor_text": "Peter Nistrup - MediumRead writing from Peter Nistrup on Medium. DATA SCIENCE, STATISTICS & AI ... Twitter: @PeterNistrup, LinkedIn\u2026medium.com"}, {"url": "https://medium.com/tag/data-science?source=post_page-----c8437b5f9f99---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/statistics?source=post_page-----c8437b5f9f99---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/programming?source=post_page-----c8437b5f9f99---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&user=Peter+Nistrup&userId=93675cf59306&source=-----c8437b5f9f99---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&user=Peter+Nistrup&userId=93675cf59306&source=-----c8437b5f9f99---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc8437b5f9f99&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c8437b5f9f99---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c8437b5f9f99--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.nistrup?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@peter.nistrup?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Peter Nistrup"}, {"url": "https://medium.com/@peter.nistrup/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.2K Followers"}, {"url": "http://www.linkedin.com/in/peter-nistrup/", "anchor_text": "www.linkedin.com/in/peter-nistrup/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93675cf59306&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&user=Peter+Nistrup&userId=93675cf59306&source=post_page-93675cf59306--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe865b04cbe54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-selection-101-using-r-c8437b5f9f99&newsletterV3=93675cf59306&newsletterV3Id=e865b04cbe54&user=Peter+Nistrup&userId=93675cf59306&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}