{"url": "https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b", "time": 1683017100.804909, "path": "towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b/", "webpage": {"metadata": {"title": "Sentiment Analysis using Logistic Regression and Naive Bayes | by Atharva Mashalkar | Towards Data Science", "h1": "Sentiment Analysis using Logistic Regression and Naive Bayes", "description": "In supervised machine learning, you usually have an input X, which goes into your prediction function to get your Y^. You can then compare your prediction with the true value Y. This gives you your\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Additive_smoothing", "anchor_text": "wiki article", "paragraph_index": 34}, {"url": "https://www.linkedin.com/in/atharva-mashalkar", "anchor_text": "https://www.linkedin.com/in/atharva-mashalkar", "paragraph_index": 47}], "all_paragraphs": ["In supervised machine learning, you usually have an input X, which goes into your prediction function to get your Y^. You can then compare your prediction with the true value Y. This gives you your cost which you use to update the parameters \u03b8.", "Sentiment analysis (also known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.", "So, let's start sentiment analysis using Logistic Regression", "We will be using the sample twitter data set for this exercise.", "Given a tweet, or some text, we can represent it as a vector of dimension V, where V corresponds to our vocabulary size. For example: If you had the tweet \u201cI am learning sentiment analysis\u201d, then you would put a 1 in the corresponding index for any word in the tweet, and a 0 otherwise. As we can see, as V gets larger, the vector becomes more sparse. Furthermore, we end up having many more features and end up training \u03b8 V parameters. This could result in larger training time and large prediction time. Hence, we will extract frequencies of every word and making a frequency dictionary.", "The idea here is to divide the training set into positive and negative tweets. Count all the words and make a python dictionary of their frequencies in positive and negative tweets.", "For every tweet make a vector of bias unit, sum of all the positive frequencies(words from positive tweets) of all the words and also their negative frequencies. We will go into detail regarding this in further paragraphs.", "When preprocessing, you have to perform the following:", "In order to carry out the above steps follow the below-given code snippets:", "Import the libraries and sample twitter data set provided by nltk (Natural Language Toolkit) package, which contains 5000 positive and 5000 negative tweets. Also, let's import some additional libraries which will help us in carrying out Regular Expression in python.", "Here we remove stopwords (words which don\u2019t and any value to the model, without these words the model will provide the same accuracy, ex: \u2018the\u2019, \u2018is\u2019, \u2018are\u2019, etc.) and carry out stemming (removing suffix of few words in order to reduce the vocabulary size). We also import English stopwords from nltk library", "Note: Here we are also tokenizing the string into a list of words after removing retweets, hashtags, URLs.", "Now, we will create a function that will take tweets and their labels as input, go through every tweet, preprocess them, count the occurrence of every word in the data set and create a frequency dictionary.", "Note: The squeeze function is necessary or the list ends up with one element.", "The required functions for processing tweets are ready, now let's build our logistic regression model.", "Logistic regression makes use of the sigmoid function which outputs a probability between 0 and 1. The sigmoid function with some weight parameter \u03b8 and some input x^{(i)}x(i) is defined as follows:-", "The sigmoid function gives values between -1 and 1 hence we can classify the predictions depending on a particular cutoff. (say : 0.5)", "Note that as (\u03b8^T)x(i) gets closer and closer to \u2212\u221e the denominator of the sigmoid function gets larger and larger and as a result, the sigmoid gets closer to 0. On the other hand, (\u03b8^T)x(i) gets closer and closer to \u221e the denominator of the sigmoid function gets closer to 1 and as a result the sigmoid also gets closer to 1.", "As we have understood the sigmoid function now let's code it!", "Note: The function should work for a scalar as well as an array", "The logistic regression cost function is defined as", "We aim to reduce cost by improving the theta using the following equation:", "Here, \u03b1 is called the learning rate. The above process of making hypothesis (h) using the sigmoid function and changing the weights (\u03b8) using the derivative of cost function and a specific learning rate is called the Gradient Descent Algorithm.", "Note: You initialize your parameter \u03b8, that you can use in your sigmoid, you then compute the gradient that you will use to update \u03b8, and then calculate the cost. You keep doing so until good enough.", "Now, let's create a function that will extract features from a tweet using the \u2018freqs\u2019 dictionary and above defined preprocessing function (process_tweet).", "Now, we will import the data set from nltk and break it into a training set and test set", "As all the required functions are ready we can finally train our model using the training data set and test it on the test data set", "J is the final cost and \u201ctheta\u201d are the final weights after training the model.", "In order to check it before testing on the test data set.", "Lets, write two more functions which given a tweet will predict the result using the \u2018freqs\u2019 dictionary and theta. The second function will use the predict function and provide the accuracy of the model on the given testing data set.", "On testing the model using the test data set we get an accuracy of 99.5%", "Naive Bayes algorithm is based on the Bayes rule, which can be represented as follows:", "Here, the process up to creating a dictionary of frequencies (importing libraries, preprocessing, etc.) is the same. The way the algorithm works is as follows:-", "2. Instead of keeping the frequencies of each word with the positive and negative labels we take the ratio of their frequency in that label by the total number of frequencies in that label. This will give the probability of occurrence of that word given the tweet is positive/negative.", "3. Then we make another property called loglikelihood. It is the log of the ratio of Positive probability to that of the negative probability of a particular word. But what if the probability of the word is zero ( frequency is zero in either positive or negative case) the log may become +/- infinity. Hence to overcome this we use additive smoothing. This wiki article explains more about additive smoothing.", "Therefore, to compute the positive probability and the negative probability for a specific word in the vocabulary, we\u2019ll use the following inputs:", "We\u2019ll use these to compute the positive and negative probability for a specific word using this formula:", "Notice that we add the \u201c+1\u201d in the numerator for additive smoothing.", "And the loglikelihood can be represented as:-", "That's it! We just need to code the above written in order to train our Naive Bayes function. So, first, let's write a function that does all the above work.", "In order to predict the sentiment of a tweet we simply have to sum up the loglikelihood of the words in the tweet along with the logprior. If the value is positive then the tweet shows positive sentiment but if the value is negative then the tweet shows negative sentiment.", "So let's write the predicting ( takes in a tweet, loglikelihood, and logprior and returns the prediction) and a testing function ( to test the model using the test data set).", "On testing the model on the test data set we get an accuracy of 99.4%. which is slightly less may be due to the assumptions that the Naive Bayes algorithm makes. In fact, it called \u201cNaive\u201d due to its assumptions.", "In the first image, you can see the word sunny and hot tend to depend on each other and are correlated to a certain extent with the word \u201cdesert\u201d. Naive Bayes assumes independence throughout. Furthermore, if you were to fill in the sentence on the right, this naive model will assign equal weight to the words \u201cspring, summer, fall, winter\u201d.", "On Twitter, there are usually more positive tweets than negative ones. However, some \u201cclean\u201d datasets you may find are artificially balanced to have the same amount of positive and negative tweets. Just keep in mind, that in the real world, the data could be much noisier.", "From the above results, we can see that the Logistic Regression algorithm has performed relatively well as compared to the Naive Bayes algorithm. This can be due to the fact that the Logistic Regression algorithm doesn\u2019t make as many assumptions as that of the Naive Bayes algorithm.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Science and Software Enthusiast | Upcoming Data Science Summer Intern at American Express. https://www.linkedin.com/in/atharva-mashalkar"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F16b806eb4c4b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://atharva-mashalkar.medium.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": ""}, {"url": "https://atharva-mashalkar.medium.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Atharva Mashalkar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F74364fb0955f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&user=Atharva+Mashalkar&userId=74364fb0955f&source=post_page-74364fb0955f----16b806eb4c4b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@raphaelphotoch?utm_source=medium&utm_medium=referral", "anchor_text": "Raphael Schaller"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Additive_smoothing", "anchor_text": "wiki article"}, {"url": "https://medium.com/tag/data-science?source=post_page-----16b806eb4c4b---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----16b806eb4c4b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----16b806eb4c4b---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/tag/sentiment-analysis?source=post_page-----16b806eb4c4b---------------sentiment_analysis-----------------", "anchor_text": "Sentiment Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&user=Atharva+Mashalkar&userId=74364fb0955f&source=-----16b806eb4c4b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&user=Atharva+Mashalkar&userId=74364fb0955f&source=-----16b806eb4c4b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F16b806eb4c4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----16b806eb4c4b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----16b806eb4c4b--------------------------------", "anchor_text": ""}, {"url": "https://atharva-mashalkar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://atharva-mashalkar.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Atharva Mashalkar"}, {"url": "https://atharva-mashalkar.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "16 Followers"}, {"url": "https://www.linkedin.com/in/atharva-mashalkar", "anchor_text": "https://www.linkedin.com/in/atharva-mashalkar"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F74364fb0955f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&user=Atharva+Mashalkar&userId=74364fb0955f&source=post_page-74364fb0955f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fef2aaeaa3143&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b&newsletterV3=74364fb0955f&newsletterV3Id=ef2aaeaa3143&user=Atharva+Mashalkar&userId=74364fb0955f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}