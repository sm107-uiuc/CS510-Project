{"url": "https://towardsdatascience.com/using-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998", "time": 1683009515.227084, "path": "towardsdatascience.com/using-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998/", "webpage": {"metadata": {"title": "Using machine learning to predict NBA All-Stars, Part 2: Modelling | by Cameron Porteous | Towards Data Science", "h1": "Using machine learning to predict NBA All-Stars, Part 2: Modelling", "description": "This is Part 2 of a two-part series in which our goal is to apply data science methodology to the NBA All-Star selection process. In Part 1, we used web scraping techniques to collect this data using\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@cjporteo/using-machine-learning-to-predict-nba-all-stars-part-1-data-collection-9fb94d386530", "anchor_text": "Part 1", "paragraph_index": 0}, {"url": "https://github.com/cjporteo/ml-NBA-asg-predictor", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://en.wikipedia.org/wiki/Outlier#Tukey's_fences", "anchor_text": "Tukey outlier detection", "paragraph_index": 8}, {"url": "https://github.com/cjporteo/ml-NBA-asg-predictor", "anchor_text": "in the notebook", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "Principal Component Analysis", "paragraph_index": 20}, {"url": "https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#SMOTE", "anchor_text": "SMOTE", "paragraph_index": 30}, {"url": "https://xgboost.readthedocs.io/en/latest/tutorials/model.html", "anchor_text": "here", "paragraph_index": 33}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "ROC", "paragraph_index": 35}, {"url": "https://shap.readthedocs.io/en/latest/", "anchor_text": "SHAP values", "paragraph_index": 54}, {"url": "http://cjporteo.github.io", "anchor_text": "cjporteo.github.io", "paragraph_index": 77}], "all_paragraphs": ["This is Part 2 of a two-part series in which our goal is to apply data science methodology to the NBA All-Star selection process. In Part 1, we used web scraping techniques to collect this data using BeautifulSoup and Selenium.", "In this part, we will explore model construction, evaluation, and interpretation. Although building an accurate and precise model is our main agenda, we ultimately want to be able to derive some level of explainability from the system and see what it sees, so to speak.", "I\u2019ll go over many of the key concepts here in this article, but for the sake of brevity, I won\u2019t be covering every single line of code. The full notebook (with detailed comments) can be found here on my GitHub.", "Our first order of business will be to address statistical outliers in the training data. In this case, an outlier is any player whose selection decision was not justified by their performance that season, often resulting in widespread disapproval from fans and media.", "If left in the training set, these records can possibly confuse the model and negatively impact our predictions and insights.", "These players fall into the following two categories (or both):", "A: the player had a long, illustrious career and was selected in their twilight years as a sort of farewell, despite not playing at what would be considered an All-Star level (e.g. Dirk Nowitzki\u2019s selection for the 2019 ASG \u2014 very much a respect/tribute pick)", "B: the player sat out way too many games in the season and was only selected due to overpowering fan favoritism (e.g. Yao Ming in the 2010\u20132011 season, who only participated in 5 out of a possible 44 games)", "All-Stars in the training data that match either of these criteria (signaled by an uncharacteristically low PIE score or number of games played) are purged from the training set. Since the dataset is pretty small, this is something we can perform manually \u2014 otherwise we would resort to something like Tukey outlier detection.", "In total, 13 player-seasons were dropped \u2014 the full list (with rationales) can be found in the notebook.", "By nature, this isn\u2019t a time series forecasting problem, but we still have some features that aren\u2019t stationary with time. This has the potential to distort the model and lead to poorer results if left unchecked.", "Average pace is defined by the number of possessions a team uses per game, and this varies across different NBA eras (e.g. 90 in \u201804 versus 100 in \u201818). Consequently, a player averaging 30ppg in 2018 should be held to the same standard as a player averaging 27ppg in 2004.", "So, we divide all the pace-dependent features (points, rebounds, assists, steals, blocks, turnovers, 3pm) by the league average pace in that season to rectify this issue. This way, we aren\u2019t comparing apples to oranges.", "It\u2019s at this point where we create the Play Pct. feature, by dividing the individual\u2019s games played for the season by the team\u2019s. We also drop all records with less than 7 games played for the season, since these can give rise to extreme values for other game stats, possibly throwing off the model.", "We now have 15 candidate features to use for modelling. As a spoiler, not all of these 15 proved to be helpful predictors, but I\u2019ll list them all here for completeness. Unbolded features were ultimately dropped in the final model.", "Before we begin to apply machine learning algorithms to this problem, it\u2019s important to get to know our data. This involves things like comparing attribute distributions between All-Stars and non-All-Stars, and seeing how different variables interact with each other.", "To look at each feature in isolation, we can use the violinplot method from the seaborn library. I\u2019ll show 2 of the 15 plots, along with the code used to generate them.", "Something immediately interesting here is that team rank definitely matters. Players who are selected for the All-Star game are more likely to come from a good team than a bad one.", "In theory, this seems reasonable. A \u201cstar\u201d player should be expected to be able convert their talent into team success, but this line of thinking can expose us to being overcritical towards a player about things that are out of their control, like teammates and coaching. Navigating this disagreement of individual and team success is the subject of much debate among NBA fans, particularly when trying to agree upon a league MVP.", "We can use a pairwise scatter matrix to see how our features interact with each other. For this, we use pairplot.", "Finally, we can use Principal Component Analysis to roughly see how distinct our two classes actually are. We apply PCA to reduce the dimensionality of our feature space from 15 to 2 while retaining as much information and variability as possible. Plotting these 2 principal components uncovers some of the innate structure and class separation within our data.", "We use the pca method from sklearn to achieve this. To make the principal components less arbitrary, we scale our input features to unit variance and remove the mean.", "Using just 2 principal components, we were still able to retain over half of the total variability from the 15 original features. From this 2-dimensional projection, the 2 classes appear to be reasonably separated from each other.", "To clarify, we\u2019re only using PCA here for data visualization purposes \u2014 we won\u2019t use these principal components for modelling. PCA can be used to increase model training speed, since there are less features, but since our dataset is relatively small, training runtime wont be an issue here.", "We will split the labeled dataset into 3 groups: train, validation, and test.", "Training data is what the model will directly use to tune its internal parameters. Validation data will be used to guide this procedure, monitor the learning process, and assist in avoiding overfitting. Then, once the model is frozen, we can turn to the testing data to evaluate the model and calculate different benchmarks.", "When dealing with any classification problem, we have to make sure our classes are balanced. If we don\u2019t account for class imbalance, the model will develop an inherent bias towards the majority class \u2014 something we definitely want to discourage.", "In the training partition of our dataset, we have 368 All-Stars and 5409 non-All-Stars. It follows that a crude blanket strategy labeling every player as a non-All-Star would still achieve 93.6% accuracy. We obviously want to dissuade the model from behaving like this, so we should balance the 2 classes.", "To do this, we have three choices:", "Performance-wise, there actually isn\u2019t a lot of difference between these techniques, but oversampling is the most common approach in practice.", "For this case, we will employ a method called SMOTE \u2014 Synthetic Minority Oversampling Technique. SMOTE creates synthetic data points within a class by linearly interpolating between a random data point and a nearby neighbor. This process is repeated until the classes are balanced. We will actually be using a variation of SMOTE called Borderline SMOTE that focuses on oversampling data points near the class border.", "This will hopefully coax the model into discriminating edge cases more precisely.", "It is crucial that we only oversample the training data, and leave the validation and test sets untouched. Oversampling before the split will cause information to leak between our three partitions and lead to a model with inflated accuracy metrics.", "The machine learning algorithm that we will call upon for this supervised learning problem is XGBoost, an implementation of gradient boosted decision trees. For datasets involving unstructured data, artificial neural networks will generally outperform other algorithms. But for smaller datasets involving tabular data (like this one), decision tree frameworks like XGBoost typically reign supreme. Documentation for XGBoost can be found here.", "XGBoost, as with many other MLA\u2019s, requires several different hyperparameters that will control the learning process, such as learning rate, maximum tree depth, and number of trees. We will apply a simple grid search to find the optimal learning rate, and use early stopping rounds to combat overfitting. For this problem, we set the patience parameter to 10. If the validation AUC score goes 10 epochs without improving, we terminate training on that learning rate and record the highest AUC.", "AUC is a comprehensive performance metric for binary classification problems. AUC stands for area under curve, specifically the ROC (receiver operating characteristic) curve. The ROC curve compares TPR (true positive rate) and FPR (false positive rate) at various threshold settings, illustrating a classifier\u2019s diagnostic ability at different levels of discrimination.", "AUC can assume values in the range [0,1]. An AUC of 1 indicates that the model is able to perfectly discriminate positive and negative classes, while an AUC of 0.5 is what we would expect from a model that makes random guesses \u2014 it has no discrimination capacity. An AUC of 0 means that the model is consistently inverting the classes (discriminating perfectly but in the wrong direction).", "We want our model to achieve an AUC as close to 1 as possible.", "The model does a better job at classifying data points in the training set, since this is the data that is directly learning from. Validation performance gives insight to how well the model will fare with data it has never seen before.", "However, the validation set still affects decisions we make in the model tuning process (via early stopping rounds). When we calculate our classification metrics like F1 Score, we want to use data that was completely isolated during training \u2014 this is where the test set comes into play. These metrics will be representative of how the model will generalize to data \u201cin the wild\u201d.", "Running the model on the testing dataset, we obtain the following confusion matrix, ROC curve, and classification metrics:", "The dashed blue line indicates the expected performance of a model with zero predictive ability (random guesses). The red curve illustrates our tuned XGB model\u2019s diagnostic power at various threshold levels. Since our AUC is very close to 1, our model is very strong at differentiating between the two classes.", "These metrics were calculated using a binary classification threshold of 0.835 (optimized for maximum F1 Score).", "Now that we have a working model, we can apply it to the dataset of players from the current season. The classification schema employed here is slightly different \u2014 we\u2019ll select the 12 players from each conference with the highest predicted probabilities of being selected, instead of using our static threshold of 0.835.", "Small detail: In actuality, the breakdown of positions among these 12 roster spots has a restriction: 6 frontcourt players (F/C), 4 guards (G), and 2 wildcards. However, with these 2 wildcard spots in addition to the ever-increasing fluidity between player positions, this restriction is pretty immaterial. Slotting 12 players into these roles is almost always possible.", "Without further ado, here are the predictions:", "Since the 2020 All-Star Game has long since passed, we can see how many picks we got right.", "In each conference, we got eleven picks correct, and one pick wrong.", "In the East, our model erroneously picked Zach LaVine as an All-Star, which would have been his first ever selection. Instead, Trae Young was selected. Interestingly, our model really didn\u2019t like Trae\u2019s prospects of being picked, ranking him 21st in the conference \u2014 even below the likes of Tobias Harris and Nikola Vucevic. We\u2019ll look into this in the next section.", "Looking at the predictions in the West, the model chose Paul George for a roster spot and missed Chris Paul. Actually, if we look at Chris Paul\u2019s projected probability, the model really didn\u2019t think he\u2019d be selected. Again, we\u2019ll explore these decisions in the next step.", "So overall, we got 22/24 picks correct, which is good for 91.67%. Not terrible, considering we didn\u2019t incorporate things like social media metrics or a player\u2019s narrative for that season.", "We have a model we\u2019re satisfied with, and it seems to make decently accurate predictions. But so far, the model itself is fairly opaque. We can observe its final output probabilities, but how is the model actually working under the hood? Which features are playing the biggest role in determining the output? Why exactly did the model dislike the All-Star prospects of Chris Paul and Trae Young?", "By nature, some models are easier to directly interpret than others. For example, with linear regression models, each feature\u2019s impact is represented by its beta coefficient. But with more complex models, like XGBoost, it\u2019s not as straightforward.", "Thankfully, well-developed techniques exist to estimate each feature\u2019s impact in models like these.", "The one we\u2019ll use here is SHAP values. SHAP (SHapley Additive exPlanations) is \u201ca game theoretic approach to explain the output of any machine learning model\u201d. We will supplement this analysis with PDP (partial dependency plots) to see how exactly different features alter predictions when we hold other inputs constant.", "Not surprisingly, the PIE (Player Impact Estimator) score has the greatest average impact on predictions. Points come in at a close second, which just goes to show how important scoring is in attaining \u201cstar\u201d status in the NBA.", "But the really interesting thing here is the Team Conference Rank feature. To NBA fans, its no secret that a player\u2019s team success plays a significant role in how they are perceived, especially when comparing them to other players. If Player X and Player Y both put up identical stats but X\u2019s team is 1st in the conference and Y\u2019s is 13th, it would be difficult to justify the case that Y is the better player. Obviously this is a broad generalization, but the point still stands.", "The fascinating part (at least to me) is the sheer weight that this feature carries on determining All-Star status. Maybe we shouldn\u2019t condemn star players on underachieving teams the way we do when they voice their wishes to play for a better team. Loyalty to a fanbase is important, but should that really take precedence over a player striving for the recognition they undeniably deserve?", "This finding (among others) is further bolstered in the SHAP detail and the partial dependency plots.", "Each player in the testing dataset adds one dot to every row in this plot. The color of the dot denotes whether that player\u2019s attribute was high or low, and the lateral position is how impactful this attribute value was on the predicted probability.", "The increase in model impact between a PIE score of 10 and 13 is very significant. This range serves as a \u201chump\u201d, so to speak, in becoming an All-Star.", "All-Star selection probability tapers off pretty quickly as Team Conference Rank gets worse and worse.", "The plot above is really telling. Controlling for all other features, the model will handle the following two players roughly the same way:", "Of course, these two features aren\u2019t completely independent; putting up a higher PIE should help your team climb the standings, and I think this is the logic that voters and journalists subconsciously cling to when overlooking players on bad teams \u2014 \u201cif they truly were a star, their team wouldn\u2019t be in 15th.\u201d I think this thesis is correct, but it has the potential to be over-applied. A lot of snubs in recent memory fall into this category, a prime example being Devin Booker the past few years. (Yes, he participated in the game this year, but wasn\u2019t chosen initially \u2014 only as an injury replacement.)", "Going back to our model, this is why Trae Young was ranked so unfavorably in our Eastern Conference predictions. The Atlanta Hawks were ranked dead last in the East, and historically bottom feeders like these very seldom yield All-Stars.", "Trae Young, though, is a very unique case that the model hasn\u2019t accounted for. The Hawks were plagued with injuries in the first half of the season, and John Collins\u2019 25-game suspension for PED usage didn\u2019t help either. Add all this onto the underlying fact that the Hawks are a young, inexperienced team, and an overwhelming slew of losses seems all but inevitable. Swap out Trae Young with pretty much any other non S-tier star in the league and it\u2019s unlikely they would do much better.", "Trae Young\u2019s All-Star selection this year was met with near-unanimous approval, but for reasons stated above, this is why the model missed him.", "We can extend SHAP analysis even further, and investigate model decisions for specific players. By using force plots, we can generate personalized report cards for each player in the league, outlining which aspects of their season either helped or hindered their projected All-Star probability.", "These are most insightful for edge cases \u2014 players near the All-Star border where it\u2019s possible to make a case for them either way.", "There\u2019s no denying that Chris Paul is a great player. While he\u2019s nearing the twilight years of his career, he still consistently adds significant value to any team he suits up for. Many analysts had Paul on their shortlist for the Western Conference All-Star reserves, and they were right \u2014 he got a well deserved spot. But his performance and value historically struggle to cross over to the stat sheet \u2014 so, on paper, his numbers usually aren\u2019t exceedingly impressive. Since \u201cnumbers\u201d are pretty much all that our model sees, it\u2019s not a huge surprise that his selection probability is quite low.", "Furthermore, there was a compelling narrative surrounding Chris Paul this season. When he was traded from the Houston Rockets to the OKC Thunder in exchange for Russell Westbrook in July, everybody instantly wrote off the Thunder\u2019s season. It was expected that the Thunder were entering an era of rebuilding and retooling and would tank for the next few years.", "But that didn\u2019t happen. Instead, Chris Paul led the Thunder to being one of the better teams in the notoriously unforgiving Western Conference and was justly met with widespread praise. Sure, the entire team and organization deserves credit for this accomplishment, but Paul definitely played chief commander in flipping the script for the Thunder\u2019s season.", "The predictive model we developed here will obviously fail to capture underdog narratives like this one. While the model is generally accurate, it\u2019s important to be aware of its shortcomings and identify where things can go wrong.", "This entire project stemmed from mere curiosity. As a longtime NBA fan, the announcement of the All-Star rosters is something I look forward to every season. But throughout the years, some of the picks (and non-picks) have left me scratching my head and wanting answers. This curiosity ultimately reached a breaking point and that\u2019s when I decided to frame this into a data science problem and shed some light on the situation.", "This project served as a great learning experience, personally, particularly when it came to model interpretation and explainability. Applying techniques to break down the \u201cblack box\u201d model into something more meaningful and understandable was a very worthwhile endeavor and really enriched the insights it provided. Scraping data from the dynamic webpages also served as an interesting challenge.", "Thank you for taking the time to read this article and follow along as I took this problem from end-to-end. If you have any questions about this project, or suggestions for potential improvements, please let me know in the comment section \u2014 I\u2019m always eager to broaden my data science skill set and explore new ideas.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Scientist @ Aviva Canada, MSCS Student @ Georgia Tech, cjporteo.github.io"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa66e6b534998&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a66e6b534998--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@cjporteo?source=post_page-----a66e6b534998--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cjporteo?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Cameron Porteous"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcdf6f519eef5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&user=Cameron+Porteous&userId=cdf6f519eef5&source=post_page-cdf6f519eef5----a66e6b534998---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/@cjporteo/using-machine-learning-to-predict-nba-all-stars-part-1-data-collection-9fb94d386530", "anchor_text": "Part 1"}, {"url": "https://github.com/cjporteo/ml-NBA-asg-predictor", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Outlier#Tukey's_fences", "anchor_text": "Tukey outlier detection"}, {"url": "https://github.com/cjporteo/ml-NBA-asg-predictor", "anchor_text": "in the notebook"}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "Principal Component Analysis"}, {"url": "https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#SMOTE", "anchor_text": "SMOTE"}, {"url": "https://xgboost.readthedocs.io/en/latest/tutorials/model.html", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Receiver_operating_characteristic", "anchor_text": "ROC"}, {"url": "https://shap.readthedocs.io/en/latest/", "anchor_text": "SHAP values"}, {"url": "https://medium.com/tag/data-science?source=post_page-----a66e6b534998---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----a66e6b534998---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nba?source=post_page-----a66e6b534998---------------nba-----------------", "anchor_text": "NBA"}, {"url": "https://medium.com/tag/data-analysis?source=post_page-----a66e6b534998---------------data_analysis-----------------", "anchor_text": "Data Analysis"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&user=Cameron+Porteous&userId=cdf6f519eef5&source=-----a66e6b534998---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&user=Cameron+Porteous&userId=cdf6f519eef5&source=-----a66e6b534998---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa66e6b534998&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a66e6b534998---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a66e6b534998--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a66e6b534998--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a66e6b534998--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a66e6b534998--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a66e6b534998--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cjporteo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@cjporteo?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Cameron Porteous"}, {"url": "https://medium.com/@cjporteo/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "135 Followers"}, {"url": "http://cjporteo.github.io", "anchor_text": "cjporteo.github.io"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcdf6f519eef5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&user=Cameron+Porteous&userId=cdf6f519eef5&source=post_page-cdf6f519eef5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fcdf6f519eef5%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-machine-learning-to-predict-nba-all-stars-part-2-modelling-a66e6b534998&user=Cameron+Porteous&userId=cdf6f519eef5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}