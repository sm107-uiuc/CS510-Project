{"url": "https://towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0", "time": 1683015932.9058812, "path": "towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0/", "webpage": {"metadata": {"title": "Logistic Regression in Classification model using Python: Machine Learning | by Kaushik Katari | Towards Data Science", "h1": "Logistic Regression in Classification model using Python: Machine Learning", "description": "Logistic regression is a commonly used model in various industries such as banking, healthcare because when compared to other classification models, the logistic regression model is easily\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression model", "paragraph_index": 3}, {"url": "https://www.kaggle.com/bandiatindra/telecom-churn-prediction/data?select=WA_Fn-UseC_-Telco-Customer-Churn.csv", "anchor_text": "Kaggle", "paragraph_index": 5}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression model", "paragraph_index": 13}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression", "paragraph_index": 72}], "all_paragraphs": ["Logistic regression is a commonly used model in various industries such as banking, healthcare because when compared to other classification models, the logistic regression model is easily interpreted.", "Binary classification is the most commonly used logistic regression. Some of the examples of binary classification problems are:", "The binary classification always has only two possible outcomes, either \u2018yes\u2019 & \u2018no\u2019 or \u20181\u2019 & \u20180\u2019 etc.", "Like in the previous article \u201cMultiple Linear Regression model, \u201c one independent variable is often not enough to capture all the uncertainties of the logistic regression\u2019s target variable.", "Let\u2019s now build a logistic regression model using python in the Jupyter notebook.", "For the entire article, we use the dataset from Kaggle.", "We\u2019ll be looking at the telecom churn prediction dataset. It has 21 variables related to customer behavior to predict whether a particular customer will switch to another telecom provider or not (i.e., churn or not).", "First, we\u2019ll start by importing the necessary libraries to the notebook and convert the .csv file to the pandas data frame.", "Our target variable in the above dataset is the Churn column.", "Let\u2019s inspect the dataframe using .shape, .describe and .info methods.", "The output for the code will be,", "As we can see, there are 7043 rows and 21 columns in the dataset, there is also no significant jump in the values for the numeric variables from minimum to maximum, and the dataset has no null values.", "The dataset looks like this after mapping the values.", "Create Dummy VariablesFor the columns having more than two values, we\u2019ll create dummy variables similar to the one we did in the \u201cMultiple Linear Regression model\u201d article.", "If we observe the above dataset, the number of columns increased from 21 columns to 29 columns.", "We are creating dummy variables for the remaining categorical variables.", "The dataset after creating dummy variables for all the variables will be,", "Drop the original variablesNow we\u2019ll drop the variables for which we created the dummy ones, and we\u2019ll convert the datatype of the columns if there are any discrepancies in them.", "The info for the dataset looks like,", "Outliers and Missing ValuesNow let\u2019s check once more for the outliers and null values in the dataset before proceeding to model building.", "From the distribution data, we can see that there are no outliers in the data. There is a gradual increase in the numbers.", "Now let\u2019s check for missing values in the dataset and handle the data.", "Let\u2019s check the percentage of null values in the columns to make an informed decision on how to handle those values.", "If we observe, the Total Charges column has less than 0.2% null values. So, it is better to remove the rows instead of inputting some values into them.", "The output after handling the null values will be,", "Since we have handled the null values, now let\u2019s move on to the model building.", "Before building the model, we\u2019ll split the data into train and test data, similar to the linear regression model. So that we\u2019ll make the model using train data and evaluate the model on test data.", "By using the sklearn library, we\u2019ll import the test_train_split to split the data. But before splitting the data, we\u2019ll divide the dataset into two dataframes X and y.", "We\u2019ll drop the customerID column since it is of no use to our model and the churn column since it is our target variable. The test data looks like this,", "Let\u2019s assign the target variable to y and split the data into test and train sets.", "The \u2018y\u2019 dataset looks like this,", "If we observe the data, all the numeric values in the dataset are in different ranges. One is in the range below 100, one is in the range of 200, and another is more than 1500. If we build the model using these values, the model\u2019s coefficients will be of different units, so it isn\u2019t easy to compare them to make an informed decision.", "To do that, we\u2019ll re-scale all the continuous variables. To do that, we\u2019ll use the StandardScaler method from sklearn.", "The dataset after scaling the features,", "Let\u2019s check the percentage of customers who are churned from the dataset to know how many customers have transferred to other networks.", "Let\u2019s look at the correlation between the variables. Suppose the correlation is high between the variables. In that case, we can remove the columns because if two variables are highly correlated, then there is no need to build the model using both the variables. We can explain the target variable using one of these two variables.", "The correlation heatmap between the variables will look like this,", "If we observe the heatmap, some of the variables are highly correlated with each other. So we\u2019ll drop those variables from the dataset.", "Dropping highly correlated dummy variablesWe\u2019ll drop the highly correlated variables from the X_train and X_test datasets we\u2019ve created above.", "Now, let\u2019s recheck the correlation in the X_train dataset.", "The correlation heatmap after dropping the variables,", "There are still some variables with high correlation, but we can remove them while building the model. Let\u2019s do that.", "We\u2019ll use the stasmodel library to build our first model. Let\u2019s see how our model looks like if we consider all the variables.", "The statistics of our first model is,", "The above model is not a good one because some variables have high p-values, which means the variables are insignificant. Instead of removing variables one at a time and building a model, again and again, we\u2019ll use a method called RFE to select the top 15 variables for the model and remove the less significant variables based on p-values and VIF values.", "We\u2019ll select the top 15 variables, which helps in building the model in our logistic regression.", "The variables having showing True are the ones we are interested in, and if we want to add more than 15 variables, we can add them one by one based on their respective ranks.", "Build the model using the above 15 variablesLet\u2019s build our second model using the 15 variables we got from RFE.", "Here we are using the GLM (Generalized Linear Models) method from the statsmodels.api library. Binomial in the family argument tells the statsmodels that it needs to fit a logit curve to binomial data (i.e., the target variable will have only two values, in this case, \u2018Churn\u2019 and \u2018Non-Churn\u2019).", "A sample logit curve looks like this,", "Predicting the output probabilitiesThe logistic regression curve gives us the probabilities of churning and not churning. We can get these probabilities by simply using the \u2018predict\u2019 function.", "Now, let\u2019s create a dataframe with the actual churn column and the predicted probabilities.", "The dataframe for the above program will be as follows.", "Since the logistic curve gives us the probabilities and not the actual classification of \u2018Churn\u2019 and \u2018Non-Churn,\u2019 we need to find a threshold probability to classify customers as \u2018churn\u2019 and \u2018non-churn.\u2019", "Here, let\u2019s choose 0.5 as an arbitrary cutoff wherein if the probability of a particular customer churning is less than 0.5, we\u2019d classify it as \u2018Non-Churn,\u2019 and if it\u2019s greater than 0.5, we will classify it as \u2018Churn.\u2019", "Creating a new columnThe choice of 0.5 is entirely arbitrary at this stage, and we\u2019ll learn how to find the optimal cutoff in \u2018Model Evaluation.\u2019", "The dataframe looks like this after choosing an arbitrary cutoff.", "Here, we used a cutoff of 0.5 to classify the customers as \u2018Churn\u2019 and \u2018Non-churn.\u2019 Now, since these are the probabilities, there are bound to be errors.", "We\u2019ll encounter two types of errors:", "To find these errors and the model\u2019s wellness, we\u2019ll use a phenomenon called \u2018Confusion Matrix.\u2019", "A typical confusion matrix looks like the following.", "Note: The values shown in the above matrix is just a sample", "If we observe the above matrix:", "We can create this confusion matrix in python by importing the metrics library from the sklearn.", "The confusion matrix for the above code looks like the following.", "There are many ways to evaluate the model; one of the metrics we measure for the above model is accuracy.", "Accuracy is the percentage of correctly predicted labels. The correctly predicted labels from the matrix would be:", "Accuracy = (Correctly predicted labels)/(Total number of labels)", "The model we have built is approximately 81% accurate.", "We can calculate the accuracy using python directly,", "The accuracy we get by the above code is", "Now let\u2019s check the VIF values for the above model to see whether any of the variables are highly correlated.", "I\u2019ve already explained VIF and it\u2019s workings in my previous article, \u201cMultiple Linear Regression.\u201d We\u2019ll be following the same procedure here.", "Let\u2019s see the VIF values for the variables in our model.", "There are a few variables with high VIF. It\u2019s best to drop these variables. The variable PhoneService has the highest VIF. So let\u2019s start by dropping that and build the model again.", "The model for the above code is,", "Next, we\u2019ll predict the values and print the dataframe consisting of original churn values and predicted values.", "Let\u2019s check the accuracy of the model.", "The accuracy of the model will be", "Which is not a massive drop to the original one. We have to recheck the VIF values, drop the variables, build the model, and calculate the accuracy. We\u2019ll follow this till the VIF values we get for every variable is less than 5.", "For the final model, after following the above process again and again, the confusion matrix we get is,", "Now, the question that arises is \u2014 is accuracy the only metric that we use to assess the goodness of the model we\u2019ve built?The answer is No.", "Consider an example: Suppose we are trying to build a logistic regression model for cancer patients, where 1\u2019s for patients\u2019 having cancer\u2019 and 0\u2019s for patients are \u2018not having cancer.\u2019 In this case, if we incorrectly predict some of the patients as \u2018not having cancer,\u2019 it\u2019ll be very risky. In this type of instance, instead of looking at the overall accuracy, we\u2019ll be looking to predict the 1\u2019s correctly.", "In another case, if we are building a model for a bank to block the customers to identify frauds, where 1 represents blocking and 0 as not blocking, we care more about getting the 0\u2019s right. It is because we don\u2019t want to block the good customers.", "It is crucial to understand the overall business problem we are trying to solve, to see which metric we want to use.", "So, apart from Accuracy, we have another three more important metrics:", "For cancer types of problems, we use sensitivity. So we should build a model, which results in high sensitivity, i.e., the value of FN(False Negative) should be as low as possible.", "For fraudulent transaction types of cases, we build a model having high specificity, i.e., the value of FP(False Positive) should be as low as possible.", "If we want to build a model to predict whether an email is spam or not, we\u2019ll use the Precision metric. In this type of case, we have to develop the model having high precision, i.e., the value of FP(False Positive) should be as low as possible.", "Now, let\u2019s find out the values of Sensitivity and Specificity for our final model, which we have built earlier.", "First, we\u2019ll assign the TP, TN, FP, and FN values from our final matrix.", "Here, confusion is the name of the matrix we created earlier.", "Now, let\u2019s find out the values of our different metrics.", "The sensitivity and specificity values for the above code is,", "So our model has high accuracy (80.4%) and high specificity (89.9%) but low sensitivity (53.7%), and we are interested in identifying the customers who might churn, so we need to deal with this. But what was the cause of such low sensitivity?", "If we remember, while predicting the model as 0 and 1, we chose a cutoff of 0.5, this cutoff is selected at random, and there was no particular logic to it.", "The predicted labels depend entirely on the cutoff we have chosen. For low cutoff, we\u2019d have a higher number of customers predicted as 1, which means the higher number of customers being identified as \u2018Churn.\u2019 Similarly, for high cutoff, we\u2019d have a low number of customers predicted as 0, that means the higher number of customers being identified as \u2018Non-churn.\u2019", "In our problem, we are trying to find the optimal cutoff where there will be a balance between sensitivity and specificity. To do that first, we\u2019ll find the predicted values for different cutoffs from 0.1 to 0.9", "The churn probability at different cutoff values looks like,", "Now, let\u2019s calculate the accuracy, sensitivity, and specificity of these cutoff values.", "The different values of the metrics will be,", "Let\u2019s plot a line graph and see how the accuracy, sensitivity, and specificity behave at those probabilities.", "The line graph looks like the following,", "From the curve above, 0.3 or slightly more is the optimum point to take it as a cutoff probability. We\u2019ll consider 0.3 as the cutoff for ease of understanding.", "Let\u2019s predict the model using this 0.3 as the final cutoff.", "Let\u2019s find out the accuracy, specificity, sensitivity, and confusion matrix as well.", "The outputs for the above code is:", "Since we have our final model, let\u2019s evaluate our model on the test data.", "Let\u2019s make predictions on the test data using our final model. First, we\u2019ll scale the test data similar to the one we did on train data after splitting.", "The test set looks like this,", "Let\u2019s make predictions now on test data, follow the below code carefully; we are making many changes to the datasets.", "The final dataset is for after all the changes are,", "Let\u2019s rename the column and rearrange them for ease of understanding.", "Let\u2019s predict the model using 0.3 as cutoff, which we got earlier on the train dataset.", "The predicted values for the test set is,", "Let\u2019s check the accuracy, sensitivity, and specificity values for the test data and compare it.", "The values of the test set are:", "If we compare the training dataset\u2019s accuracy, sensitivity, and specificity values, there is not that much of a change. So the model we have built is good enough to predict any future telecom data.", "To summarize, we have seen the steps we need to take to build a basic logistic regression model. There are some more concepts we can learn like the ROC curve, Precision, Recall, etc. But to build a basic logistic regression model, the process we have seen in this article is good enough. Once we master this process, we can explore more things in this model.", "Thank you for reading and happy coding!!!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer | Python | Machine Learning | Writer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdc9573e971d0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@kaushikvarma.katari?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kaushikvarma.katari?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Kaushik Katari"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6c8e045892b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&user=Kaushik+Katari&userId=6c8e045892b3&source=post_page-6c8e045892b3----dc9573e971d0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markuswinkler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Markus Winkler"}, {"url": "https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression model"}, {"url": "https://www.kaggle.com/bandiatindra/telecom-churn-prediction/data?select=WA_Fn-UseC_-Telco-Customer-Churn.csv", "anchor_text": "Kaggle"}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression model"}, {"url": "https://commons.wikimedia.org/w/index.php?curid=92801334", "anchor_text": "https://commons.wikimedia.org/w/index.php?curid=92801334"}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression"}, {"url": "https://towardsdatascience.com/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a", "anchor_text": "Multiple Linear Regression model using Python: Machine Learning"}, {"url": "https://towardsdatascience.com/simple-linear-regression-model-using-python-machine-learning-eab7924d18b4", "anchor_text": "Simple Linear Regression Model using Python: Machine Learning"}, {"url": "https://towardsdatascience.com/exploratory-data-analysis-eda-python-87178e35b14", "anchor_text": "Exploratory Data Analysis(EDA): Python"}, {"url": "https://towardsdatascience.com/central-limit-theorem-clt-data-science-19c442332a32", "anchor_text": "Central Limit Theorem(CLT): Data Science"}, {"url": "https://towardsdatascience.com/inferential-statistics-data-analysis-e59adc75c6eb", "anchor_text": "Inferential Statistics: Data Analysis"}, {"url": "https://towardsdatascience.com/seaborn-python-8563c3d0ad41", "anchor_text": "Seaborn: Python"}, {"url": "https://levelup.gitconnected.com/pandas-python-e69f4829fee1", "anchor_text": "Pandas: Python"}, {"url": "https://levelup.gitconnected.com/matplotlib-python-ecc7ba303848", "anchor_text": "Matplotlib: Python"}, {"url": "https://medium.com/coderbyte/numpy-python-f8c8f2bbd13e", "anchor_text": "NumPy: Python"}, {"url": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_classification_algorithms_logistic_regression.htm", "anchor_text": "https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_classification_algorithms_logistic_regression.htm"}, {"url": "https://machinelearningmastery.com/logistic-regression-for-machine-learning/", "anchor_text": "https://machinelearningmastery.com/logistic-regression-for-machine-learning/"}, {"url": "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html", "anchor_text": "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html"}, {"url": "https://kambria.io/blog/logistic-regression-for-machine-learning/", "anchor_text": "https://kambria.io/blog/logistic-regression-for-machine-learning/"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----dc9573e971d0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----dc9573e971d0---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/sensitivity?source=post_page-----dc9573e971d0---------------sensitivity-----------------", "anchor_text": "Sensitivity"}, {"url": "https://medium.com/tag/python?source=post_page-----dc9573e971d0---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/classification?source=post_page-----dc9573e971d0---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&user=Kaushik+Katari&userId=6c8e045892b3&source=-----dc9573e971d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&user=Kaushik+Katari&userId=6c8e045892b3&source=-----dc9573e971d0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdc9573e971d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dc9573e971d0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dc9573e971d0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dc9573e971d0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dc9573e971d0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kaushikvarma.katari?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@kaushikvarma.katari?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kaushik Katari"}, {"url": "https://medium.com/@kaushikvarma.katari/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "434 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6c8e045892b3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&user=Kaushik+Katari&userId=6c8e045892b3&source=post_page-6c8e045892b3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fda750799846d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flogistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0&newsletterV3=6c8e045892b3&newsletterV3Id=da750799846d&user=Kaushik+Katari&userId=6c8e045892b3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}