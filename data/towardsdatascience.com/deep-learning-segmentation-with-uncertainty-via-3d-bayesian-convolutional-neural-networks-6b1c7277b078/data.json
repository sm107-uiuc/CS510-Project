{"url": "https://towardsdatascience.com/deep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078", "time": 1683003583.0376341, "path": "towardsdatascience.com/deep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078/", "webpage": {"metadata": {"title": "Uncertainty via 3D Bayesian Deep Learning | Towards Data Science", "h1": "Deep Learning Segmentation with Uncertainty via 3D Bayesian Convolutional Neural Networks", "description": "Uncertainty quantification in deep learning segmentation is difficult, but our novel 3D Bayesian CNN provides theoretically-grounded geometric uncertainty maps."}, "outgoing_paragraph_urls": [{"url": "https://www.tensorflow.org/probability", "anchor_text": "TensorFlow Probability", "paragraph_index": 21}, {"url": "https://www.tensorflow.org/probability", "anchor_text": "TensorFlow Probability", "paragraph_index": 28}, {"url": "https://github.com/keras-team/keras/issues/11434", "anchor_text": "Keras bug", "paragraph_index": 31}, {"url": "https://github.com/sandialabs/bcnn/blob/master/dataset.py", "anchor_text": "https://github.com/sandialabs/bcnn/blob/master/dataset.py", "paragraph_index": 32}, {"url": "https://github.com/sandialabs/bcnn/blob/master/test.py", "anchor_text": "https://github.com/sandialabs/bcnn/blob/master/test.py", "paragraph_index": 35}, {"url": "https://arxiv.org/pdf/1910.10793.pdf", "anchor_text": "https://arxiv.org/pdf/1910.10793.pdf", "paragraph_index": 37}, {"url": "https://github.com/sandialabs/bcnn", "anchor_text": "https://github.com/sandialabs/bcnn", "paragraph_index": 37}, {"url": "https://arxiv.org/abs/1505.05424", "anchor_text": "https://arxiv.org/abs/1505.05424", "paragraph_index": 38}, {"url": "https://arxiv.org/abs/1606.06650", "anchor_text": "https://arxiv.org/abs/1606.06650", "paragraph_index": 39}, {"url": "https://arxiv.org/abs/1506.02142", "anchor_text": "https://arxiv.org/abs/1506.02142", "paragraph_index": 40}, {"url": "https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks", "anchor_text": "https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks", "paragraph_index": 41}, {"url": "https://www.cs.toronto.edu/~hinton/absps/colt93.html", "anchor_text": "https://www.cs.toronto.edu/~hinton/absps/colt93.html", "paragraph_index": 42}, {"url": "https://arxiv.org/abs/1506.02557", "anchor_text": "https://arxiv.org/abs/1506.02557", "paragraph_index": 43}, {"url": "https://arxiv.org/abs/1606.04797", "anchor_text": "https://arxiv.org/abs/1606.04797", "paragraph_index": 44}, {"url": "https://pdfs.semanticscholar.org/dde4/b95be20a160253a6cc9ecd75492a13d60c10.pdf", "anchor_text": "https://pdfs.semanticscholar.org/dde4/b95be20a160253a6cc9ecd75492a13d60c10.pdf", "paragraph_index": 45}, {"url": "https://arxiv.org/abs/1803.04386", "anchor_text": "https://arxiv.org/abs/1803.04386", "paragraph_index": 46}], "all_paragraphs": ["\u00b7 Measuring uncertainty is not possible in a regular deep neural network, but it is extremely important for interpretability and validation", "\u00b7 Bayesian neural networks learn probability distributions rather than point estimates, allowing them to measure uncertainty", "\u00b7 We designed the first-ever successful Bayesian convolutional neural network (BCNN) architecture for 3D segmentation", "\u00b7 Our BCNN beats the current state-of-the-art neural network in uncertainty quantification while achieving equal or better segmentation accuracy", "\u00b7 Our academic paper and full open-source code implementation are available online", "Consider this scenario: a certain aircraft manufacturing company produces safety-critical engine parts for commercial aircraft. Since the engine parts must be guaranteed to work, the company validates each of them in a painstaking, months-long process wherein they take a 3D CT scan of the part, annotate the hundreds of millions of voxels by hand, and use the annotated scan to analyze the part for defects.", "This is not time- or cost-effective, so the company hires a team of data scientists to design a deep neural network which automatically validates the parts using state-of-the-art volumetric segmentation techniques. The neural network is seemingly successful, but one day a part verified by the neural network inexplicably fails during usage, causing engine failure in the aircraft and leading to hundreds of fatalities and billions of dollars lost for the company.", "So what went wrong? Well, deep neural networks are well-known for making accurate predictions, but one of their greatest weaknesses is that they lack the capacity for measuring uncertainty within their predictions. Thus, the deep learning system had no capacity to distinguish between a part that was 100% certified, and a part that just barely made the cut.", "One may think that the value of the sigmoid output is usable as a measure of uncertainty, but this is not true because these values are dependent on the inferred sample being \u201cclose\u201d to the training distribution. If one infers on a sample far from the training distribution (i.e., a part with a defect in it), the sigmoid output cannot be used as a proxy for model uncertainty\u00b3.", "In other words, deep neural networks perform best when the test set is \u201csimilar\u201d to the training set; in other words, there may be examples in the test set which the neural network is unsure about because there were no similar training examples. But because there is no \u201cI don\u2019t know\u201d output available, defective parts can end up verified by the deep learning system and moved to production.", "This example illustrates the critical importance of uncertainty quantification in deep neural networks, the research and development of which has skyrocketed in the last five years. Recent techniques cast neural networks, usually pointwise estimators, as probabilistic or Bayesian models. The two most common neural network architectures for this purpose are Monte Carlo dropout networks\u00b3 (MCDNs) and Bayesian convolutional neural networks\u00b9 (BCNNs).", "MCDNs use dropout layers to approximate deep Gaussian processes, and while easy to implement, their statistical soundness has been called into question\u2079. BCNNs use variational inference to learn the posterior distribution of the weights given the dataset and are much more difficult to implement but give greatly improved uncertainty results.", "It has been postulated that Bayesian neural networks for large problems, including in the 3D image segmentation space, are infeasible due to prohibitive computational costs\u00b3. Here, we refute that claim and present the first-ever successful implementation of a 3D BCNN for uncertainty quantification in volumetric segmentation, detail how it works, and explain some sections of the open-source codebase.", "In particular, this novel neural network architecture provides improved uncertainty quantification as compared to MCDNs while achieving equal or better segmentation accuracy. Through experimentation on CT scans of battery electrode and laser-welded metals, we show that the uncertainty maps generated by the BCNN capture continuity and visual gradients, making them interpretable as confidence intervals for segmentation.", "While most neural networks learn pointwise estimates of their weights, the more rigorous view is that these estimates do not fully encapsulate the uncertainty inherent in the values of the weights. Instead, in a BCNN, the weights are each implicitly described as (multivariate) probability distributions.", "Describing the weights of the neural networks as probability distributions has several consequences. First, it makes the neural network nondeterministic; every time we compute a forward pass, we must sample from each weight distribution to obtain a point estimate which can be used for inference. Repeated applications of this sampling technique, called Monte Carlo sampling, will result in different predictions which can then be analyzed for uncertainty. Second, it changes the backpropagation algorithm since we cannot backpropagate through a sampling operation (it has no gradient). In a later section, we will discuss how to fix this problem using the Bayes by Backprop algorithm. Finally, it makes the neural network much more difficult to reliably train, especially in 3D, and susceptible to vanishing/exploding gradients. We use a clever normalization technique called group normalization to solve this problem, also detailed in a later section.", "How exactly do we get distributions over the weights? Well, in a perfect world, we could use Bayes\u2019 Rule to calculate them precisely. To do this, we would begin with a prior distribution over the weights; this is our \u201cinitial guess\u201d of what a weight distribution would look like. It is denoted p(w) and is generally a standard normal distribution. Then, we would use our data to calculate the posterior distributions of the weights given the dataset, denoted p(w|D). This is equivalent to finding a w that maximizes the likelihood of the dataset given those weights, denoted p(D|w), and we can perform this calculation via Bayes\u2019 Rule:", "However, due to the extreme overparameterization found in neural networks, the integral in the denominator is generally intractable. So, we need to learn the posterior distribution rather than calculate it exactly. Previous work by Hinton and Van Camp\u2075 and Graves\u2074 proposed variational learning (also called variational inference) as a method to approximate the posterior distribution. Variational learning finds the parameters \u03b8 of the distribution p(w|\u03b8), called the variational distribution, via the minimization of the variational free energy cost function F, often called the expected lower bound (ELBO).", "The variational free energy consists of the sum of the Kullback-Leibler (KL) divergence, which measures the distance between the prior and variational distributions, and the negative log-likelihood, which measures the goodness-of-fit of the model. Blundell et al.\u00b9 explains the variational free energy loss function as a tradeoff between satisfying the simplicity prior (represented by the KL term) and satisfying the complexity of the dataset (represented by the NLL term):", "The longer we train the neural network, the closer we will get to minimizing this cost function, and the closer our variational distribution will get to the true posterior distribution. In practice, the KL term has a regularizing effect on the output of the neural network, preventing the learned distribution from overfitting at the cost of a lower NLL term in the training set.", "This loss function is amenable to mini-batch optimization by scaling the cost for mini-batch i as follows, essentially spreading out the KL divergence penalty across the entire dataset\u00b9:", "If a Bayesian neural network is implemented in TensorFlow Probability, the below is a valid Python implementation of the variational free energy loss (note that binary cross-entropy is just negated NLL):", "Variational Bayesian learning is generally considered more statistically sound than, for example, approximate Bayesian inference via dropout layers\u2079. However, this comes at the cost of several computational challenges.", "First, a random variable sampled from a distribution has no gradient, so Bayesian neural networks seem incompatible with backpropagation. However, Kingma et al.\u2076 showed that it is possible to reparametrize the random variable as a deterministic variable for computation. As an example, let a weight w be sampled from a normal distribution with mean \u03bc and variance \u03c3\u00b2. Then, a valid reparameterization is w=\u03bc+\u03c3\u03f5 where \u03f5 is an auxiliary noise variable sampled from a standard normal distribution. Now, instead of a sampling operation, we have an affine combination, which is easily utilized in backpropagation. More complex calculations are needed to efficiently scale this computation; see Kingma\u2019s paper for more. This is often called the local reparameterization trick.", "Next, Bayesian learning was previously considered computationally infeasible due to the massive number of weight updates necessary if trained using an ensemble method. To solve this, Blundell et al.\u00b9 designed the Bayes by Backprop algorithm. Previous work focused on training stochastic hidden units, but there are easily two orders of magnitude more weights than hidden units, and Bayes by Backprop was the first algorithm to effectively train probabilistic weights in a neural network. Bayes by Backprop works by using the gradients calculated in backpropagation to \u201cscale and shift\u201d the variational parameters of the posterior, thus updating the posterior with minimal additional computation.", "Since 3D training volumes can be quite large, our batch size is constrained by the amount of available GPU memory, resulting in a batch size too small for batch normalization to accurately compute batch statistics. Thus, we use a technique proposed by Wu and He\u00b9\u00b2 called group normalization, which normalizes groups of channels and is shown to have accurate performance independent of batch size. Proper normalization was observed to be a critical factor in the convergence of our model since it helps avoid vanishing/exploding gradients; by tuning the number of groups used in the group normalization layers, we found that the BCNN converged most reliably when using 4 groups.", "Finally, one challenge associated with probabilistic weights is that all examples in a mini-batch typically have similarly sampled weights, limiting the variance reduction effect of large mini-batches. One side effect of the local reparameterization trick\u2076 mentioned above is that it greatly reduces the variance of stochastically sampled weights by transforming global weight uncertainty into independent local noise across examples in the mini-batch. In a similar vein, Wen et al.\u00b9\u00b9 proposed the Flipout estimator, which empirically achieves ideal variance reduction by sampling weights pseudo-independently for each example. An important difference is that local reparametrization works only for fully connected networks, while Flipout can be used effectively in fully-connected, convolutional, and recurrent networks.", "Our 3D BCNN architecture draws from the image segmentation literature by utilizing the common encoder-decoder setup seen in V-Net\u2077 and 3D U-Net\u00b2 , deep neural networks originally used for 3D segmentation of human prostates and frog kidneys, respectively. In this architecture, the encoder half (left) of the network compresses the input into a latent space while the decoder half (right) decompresses the latent representation of the input into a segmentation map.", "The encoder half of the BCNN uses typical 3D convolutions to maximize information transfer between the original volume and the latent space, but the decoder half of the network uses 3D Bayesian convolutional layers. Each of these is initialized with a standard normal prior and employs the aforementioned Flipout estimator\u00b9\u00b9 to approximate the distribution during forward passes. Note the skip connections in yellow, which assist in feature-forwarding throughout the network. Our implementation draws from the Bayesian Layers library\u00b9\u2070 included in TensorFlow Probability, which keeps track of losses representing the KL divergence of the layer\u2019s posterior distribution with respect to its prior and makes computing the variational free energy loss simple.", "Using a BCNN in practice brings with it a few peculiarities that can be difficult to effectively implement. First, it is currently impossible to save the architecture and weights of a model that combines, say, Keras layers and Bayesian layers. Instead, one must save the weights only and then load them into an instantiated architecture. This gets worse when the models are designated as multi-GPU, which is virtually necessary when working with many 3D datasets. When a multi-GPU model is saved as weights only, it is difficult to re-load the model because the neural network architecture expects single-GPU weights to be imported. A clever solution is to re-save the multi-GPU weights as single-GPU by extracting the weights of the second-to-last layer in the multi-GPU model. The below code provides an example:", "In addition, 3D dataset management can become overwhelming very quickly. Many CT and MRI scans can be of dimension 1000 x 1000 x 1000 or even larger, which is infeasible to perform inference on all at once. Instead, a \u201cchunking\u201d technique is required, which separates the large volume into overlapping chunks for feeding into the BCNN. The neural network is then trained on the chunks and predicts on chunks of the same size, which can be reconstructed to obtain a fully-inferred complete volume by reversing the chunking process.", "The chunking process involves passing a sliding rectangular prism \u201cwindow\u201d across the original volume at a certain ratio of overlap, called the \u201cstep size\u201d. We have to be careful to avoid off-by-one errors, and we also need to save the coordinates of each chunk to use during reconstruction. The output of the algorithm is an enormous 5D numpy array which contains all of the chunks in the dataset. Furthermore, there is a Keras bug that causes an error whenever the last batch in an epoch is not divisible across all GPUs; avoiding this bug requires truncating the end of the array.", "An implementation of this algorithm is in the \u201cchunks\u201d method here: https://github.com/sandialabs/bcnn/blob/master/dataset.py.", "Recall that BCNNs are nondeterministic, so when predicting on a chunk multiple times, one will obtain many different (and possibly very wrong) predictions. In order to obtain an accurate prediction as well as uncertainty maps, we must predict many times on each chunk to obtain a distribution of sigmoid values. This is called Monte Carlo sampling. This process is heavily customizable, but here we represent the segmentation as the average of all sigmoid values (casting to 0 and 1 for binary segmentations), and the uncertainty map as the difference between the 20th and 80th percentiles.", "Critically, the chunking reconstruction process can lead to heavy artifacts in the output segmentation volumes. This is because the neural network does not have enough spatial context to predict effectively on the edges of every chunk; instead, we discard a certain percentage around each chunk (about 5%) to ensure that we only keep justified predictions.", "An implementation of this algorithm is in the \u201cpredict\u201d method here: https://github.com/sandialabs/bcnn/blob/master/test.py.", "The BCNN is the new state-of-the-art in uncertainty quantification for volumetric segmentation; in particular, we validated the BCNN using CT scans of graphite electrodes for lithium-ion batteries and laser-welded metal joints. The BCNN provides greatly improved uncertainty maps as compared to the previously superior MCDN while achieving an equal or better segmentation accuracy. See below for a sample image from our paper which highlights the continuity and visual gradients of the BCNN uncertainty map, while the MCDN generates an uninterpretable pointwise uncertainty map.", "Furthermore, we employ the PAvPU metric\u2078, a recent measure designed to validate uncertainty results, and find that the BCNN consistently and vastly outperforms the MCDN at encoding the relationship between uncertainty and accuracy. See our paper at https://arxiv.org/pdf/1910.10793.pdf for an in-depth analysis and validation of the BCNN and its advantages over the MCDN, and feel free to utilize and fork the open-source codebase at https://github.com/sandialabs/bcnn. While our novel contribution is in the 3D space, we also provide a 2D implementation for typical image segmentation.", "[1] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural networks. In Proceedings of the 32nd International Conference on Machine Learning, 2015. https://arxiv.org/abs/1505.05424", "[2] Ozgun Cicek, Ahmed Abdulkadir, Soeren S. Lienkamp, Thomas Brox, and Olaf Ronneberger. 3d u-net: Learning dense volumetric segmentation from sparse annotation. In Proceedings of the 19th International Conference on Medical Image Computing and Computer-Assisted Intervention, 2016. https://arxiv.org/abs/1606.06650", "[3] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In Proceedings of the 33rd International Conference on Machine Learning, 2016. https://arxiv.org/abs/1506.02142", "[4] Alex Graves. Practical variational inference for neural networks. In Proceedings of the 24th Conference on Advances in Neural Information Processing Systems, 2011. https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks", "[5] Geoffrey E. Hinton and Drew Van Camp. Keeping neural networks simple by minimizing the description length of the weights. In Proceedings of the 16th Conference on Learning Theory, 1993. https://www.cs.toronto.edu/~hinton/absps/colt93.html", "[6] Diederik P. Kingma, Tim Salimans, and Max Welling. Variational Dropout and the Local Reparameterization Trick. In Proceedings of the 28th Conference on Advances in Neural Information Processing Systems, 2015. https://arxiv.org/abs/1506.02557", "[7] Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In Proceedings of the 4th International Conference on 3D Vision, 2016. https://arxiv.org/abs/1606.04797", "[9] Ian Osband. Risk versus uncertainty in deep learning: Bayes, bootstrap and the dangers of dropout. In Proceedings of the 29th Conference on Advances in Neural Information Processing Systems: Workshop on Bayesian Deep Learning, 2016. https://pdfs.semanticscholar.org/dde4/b95be20a160253a6cc9ecd75492a13d60c10.pdf", "[11] Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Train, and Roger Grosse. Flipout: Efficient pseudo-independent weight perturbations on mini-batches. In Proceedings of the 6th International Conference on Learning Representations, 2018. https://arxiv.org/abs/1803.04386", "This work was produced during the author\u2019s internship at Sandia National Laboratories. Sandia National Laboratories is a multimission laboratory managed and operated by National Technology & Engineering Solutions of Sandia, LLC, a wholly owned subsidiary of Honeywell International Inc., for the U.S. Department of Energy\u2019s National Nuclear Security Administration under contract DE-NA0003525. SAND2020\u20131419 S.", "Machine Learning PhD at Georgia Tech | Prev. Microsoft Research, Google X, USC"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F6b1c7277b078&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@tmlabonte?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Tyler LaBonte"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f3d07df4e4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=post_page-4f3d07df4e4d----6b1c7277b078---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6b1c7277b078&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----6b1c7277b078---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6b1c7277b078&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=-----6b1c7277b078---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/abs/1910.10793", "anchor_text": "https://arxiv.org/abs/1910.10793"}, {"url": "https://github.com/sandialabs/bcnn", "anchor_text": "https://github.com/sandialabs/bcnn"}, {"url": "https://unsplash.com/@pixtolero2?utm_source=medium&utm_medium=referral", "anchor_text": "Daniel Eledut"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.tensorflow.org/probability", "anchor_text": "TensorFlow Probability"}, {"url": "https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1803.08494", "anchor_text": "here"}, {"url": "https://www.tensorflow.org/probability", "anchor_text": "TensorFlow Probability"}, {"url": "https://github.com/sandialabs/bcnn/blob/master/bayesian_vnet.py", "anchor_text": "https://github.com/sandialabs/bcnn/blob/master/bayesian_vnet.py"}, {"url": "https://github.com/keras-team/keras/issues/11434", "anchor_text": "Keras bug"}, {"url": "https://github.com/sandialabs/bcnn/blob/master/dataset.py", "anchor_text": "https://github.com/sandialabs/bcnn/blob/master/dataset.py"}, {"url": "https://github.com/sandialabs/bcnn/blob/master/test.py", "anchor_text": "https://github.com/sandialabs/bcnn/blob/master/test.py"}, {"url": "https://arxiv.org/pdf/1910.10793.pdf", "anchor_text": "https://arxiv.org/pdf/1910.10793.pdf"}, {"url": "https://github.com/sandialabs/bcnn", "anchor_text": "https://github.com/sandialabs/bcnn"}, {"url": "https://arxiv.org/abs/1505.05424", "anchor_text": "https://arxiv.org/abs/1505.05424"}, {"url": "https://arxiv.org/abs/1606.06650", "anchor_text": "https://arxiv.org/abs/1606.06650"}, {"url": "https://arxiv.org/abs/1506.02142", "anchor_text": "https://arxiv.org/abs/1506.02142"}, {"url": "https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks", "anchor_text": "https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks"}, {"url": "https://www.cs.toronto.edu/~hinton/absps/colt93.html", "anchor_text": "https://www.cs.toronto.edu/~hinton/absps/colt93.html"}, {"url": "https://arxiv.org/abs/1506.02557", "anchor_text": "https://arxiv.org/abs/1506.02557"}, {"url": "https://arxiv.org/abs/1606.04797", "anchor_text": "https://arxiv.org/abs/1606.04797"}, {"url": "https://arxiv.org/abs/1811.12709", "anchor_text": "https://arxiv.org/abs/1811.12709"}, {"url": "https://pdfs.semanticscholar.org/dde4/b95be20a160253a6cc9ecd75492a13d60c10.pdf", "anchor_text": "https://pdfs.semanticscholar.org/dde4/b95be20a160253a6cc9ecd75492a13d60c10.pdf"}, {"url": "https://arxiv.org/abs/1812.03973", "anchor_text": "https://arxiv.org/abs/1812.03973"}, {"url": "https://arxiv.org/abs/1803.04386", "anchor_text": "https://arxiv.org/abs/1803.04386"}, {"url": "https://arxiv.org/abs/1803.08494", "anchor_text": "https://arxiv.org/abs/1803.08494"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----6b1c7277b078---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/data-science?source=post_page-----6b1c7277b078---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----6b1c7277b078---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/uncertainty?source=post_page-----6b1c7277b078---------------uncertainty-----------------", "anchor_text": "Uncertainty"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----6b1c7277b078---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6b1c7277b078&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----6b1c7277b078---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6b1c7277b078&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----6b1c7277b078---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6b1c7277b078&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f3d07df4e4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=post_page-4f3d07df4e4d----6b1c7277b078---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F4f3d07df4e4d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----6b1c7277b078---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Written by Tyler LaBonte"}, {"url": "https://medium.com/@tmlabonte/followers?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "60 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4f3d07df4e4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=post_page-4f3d07df4e4d----6b1c7277b078---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F4f3d07df4e4d%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----6b1c7277b078---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Tyler LaBonte"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Serving Image-Based Deep Learning Models with TensorFlow-Serving\u2019s RESTful APIHow do you serve an end-to-end Tensorflow Model across a network?"}, {"url": "https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "7 min read\u00b7Jul 18, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd365c16a7dc4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----d365c16a7dc4----0-----------------clap_footer----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=author_recirc-----6b1c7277b078----0---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd365c16a7dc4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fserving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4&source=-----6b1c7277b078----0-----------------bookmark_preview----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----6b1c7277b078----1---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----6b1c7277b078----1-----------------bookmark_preview----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----6b1c7277b078----2---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6b1c7277b078----2-----------------bookmark_preview----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Tyler LaBonte"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "Integrating TensorFlow Distributed Image Serving with the TensorFlow Object Detection APIServing your TensorFlow object detection model across a network"}, {"url": "https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": "6 min read\u00b7Jul 25, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f62d80bce4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c&user=Tyler+LaBonte&userId=4f3d07df4e4d&source=-----5f62d80bce4c----3-----------------clap_footer----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=author_recirc-----6b1c7277b078----3---------------------30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f62d80bce4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c&source=-----6b1c7277b078----3-----------------bookmark_preview----30b3558c_c3cc_4a1e_8907_b4249fe7ff4d-------", "anchor_text": ""}, {"url": "https://medium.com/@tmlabonte?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "See all from Tyler LaBonte"}, {"url": "https://towardsdatascience.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Understanding NeRFsA massive breakthrough in scene representation"}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b711 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----2a082e13c6eb----0-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&source=-----6b1c7277b078----0-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----6b1c7277b078----1-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----6b1c7277b078----0---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----6b1c7277b078----0-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://erdogant.medium.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Erdogan Taskesen"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "From Data to Clusters; When is Your Clustering Good Enough?Sensible clusters and hidden gems can be found using clustering approaches but you need the right cluster evaluation method!"}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b717 min read\u00b76 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&user=Erdogan+Taskesen&userId=4e636e2ef813&source=-----5895440a978a----1-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a?source=read_next_recirc-----6b1c7277b078----1---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5895440a978a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a&source=-----6b1c7277b078----1-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jvision.medium.com/?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://jvision.medium.com/?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Joseph Robinson, Ph.D."}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "From Basic Gates to Deep Neural Networks: The Definitive Perceptron TutorialDemystifying Mathematics, Binary Classification, and Logic Gates"}, {"url": "https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b721 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffd384eb93382&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-definitive-perceptron-guide-fd384eb93382&user=Joseph+Robinson%2C+Ph.D.&userId=8049fa781539&source=-----fd384eb93382----2-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-definitive-perceptron-guide-fd384eb93382?source=read_next_recirc-----6b1c7277b078----2---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd384eb93382&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-definitive-perceptron-guide-fd384eb93382&source=-----6b1c7277b078----2-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----3-----------------clap_footer----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----6b1c7277b078----3---------------------44edaa42_6c51_4c76_b171_be9bbc3b12af-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----6b1c7277b078----3-----------------bookmark_preview----44edaa42_6c51_4c76_b171_be9bbc3b12af-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----6b1c7277b078--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}