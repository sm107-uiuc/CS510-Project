{"url": "https://towardsdatascience.com/reinforcement-learning-implement-grid-world-from-scratch-c5963765ebff", "time": 1682996057.176586, "path": "towardsdatascience.com/reinforcement-learning-implement-grid-world-from-scratch-c5963765ebff/", "webpage": {"metadata": {"title": "Reinforcement Learning \u2014 Implement Grid World | by Jeremy Zhang | Towards Data Science", "h1": "Reinforcement Learning \u2014 Implement Grid World", "description": "When you try to get your hands on reinforcement learning, it\u2019s likely that Grid World Game is the very first problem you meet with. It is the most basic as well as classic problem in reinforcement\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/MJeremy2017/RL/blob/master/GridWorld/gridWorld.py", "anchor_text": "full code", "paragraph_index": 2}, {"url": "https://github.com/MJeremy2017/RL/blob/master/GridWorld/gridWorld.py", "anchor_text": "here", "paragraph_index": 14}, {"url": "https://medium.com/@zhangyue9306/implement-grid-world-with-q-learning-51151747b455", "anchor_text": "non-deterministic game playing and Q-learning", "paragraph_index": 15}], "all_paragraphs": ["When you try to get your hands on reinforcement learning, it\u2019s likely that Grid World Game is the very first problem you meet with. It is the most basic as well as classic problem in reinforcement learning and by implementing it on your own, I believe, is the best way to understand the basis of reinforcement learning. Meanwhile, it is super fun to implement your own game and see how a robot manage to learn on its own!", "The rule is simple. Your agent/robot starts at the left-bottom corner(the \u2018start\u2019 sign) and ends at either +1 or -1 which is the corresponding reward. At each step, the agent has 4 possible actions including up, down, left and right, whereas the black block is a wall where your agent won\u2019t be able to penetrate through. In order to make it more straight forward, our first implementation assumes that each action is deterministic, that is, the agent will go where it intends to go. For instance, when the agent decides to take action up at (2, 0), it will land in (1, 0) rather than (2, 1) or elsewhere. (We will add uncertainty in out second implementation) However, it the agents hit the wall, it will remain at the same position.", "So let\u2019s get cracking on the code! Firstly, let\u2019s set up some global rules of the board. (full code)", "And as a grid game, it needs a State to justify each state(position) of our agent, giving reward according to its state.", "When our agent takes an action, the State should have a function to accept an action and return a legal position of next state.", "This is the artificial intelligence part, as our agent should be able to learn from the process and thinks like a human. The key of the magic is value iteration.", "What our agent will finally learn is a policy, and a policy is a mapping from state to action, simply instructs what the agent should do at each state. In our case, instead of learning a mapping from state to action, we will leverage value iteration to firstly learn a mapping of state to value(which is the estimated reward) and based on the estimation, at each state, our agent will choose the best action that gives the highest estimated reward.", "There is not going to be any cranky, head-scratching math involved, as the core of value iteration is amazingly concise.", "This is the essence of value iteration, super neat, right? This formula almost applies to all reinforcement learning problems, let me explain how our agent evolves from an infant to expert based on this line of formula. Value iteration, just as its name, update its value(estimated reward) at each iteration(end of game).", "At first, our gent knows nothing about the grid world(environment), so it would simply initialises all reward as 0. Then, it starts to explore the world by randomly walking around, surely it will endure lots of failure at the beginning, but that is totally fine. Once it reaches end of the game, either reward +1 or reward -1, the whole game reset and the reward propagates in a backward fashion and eventually the estimated value of all states along the way will be updated based on the formula above.", "Let\u2019s take a closer look at the formula. The V(St) on the left is the updated value of that state, and the right one is the current non-updated value and \u03b1 is learning rate. The formula is simply saying that the updated value of a state equals to the current value plus a temporal difference, which is what the agent learned from this iteration of game playing minus the previous estimate. For example, let\u2019s say there are 2 states, S1and S2, both of which has an estimated value 0, and at this round of playing, our agent moves from S1 to S2 and gets reward 1, then the new estimate of S1 = S1 + \u03b1(S2 - S1), which is 0 + 0.1(1-0) = 0(assume \u03b1 is 0.1 and reward at S1 is 0)", "We record all states of our agent, and at the end of the game, we will update estimates in reversed fashion.", "There is one last thing we need to talk about. Once our agent finds a path to get reward +1, should it sticks to it and forever follows that path (exploitation) or should it gives other path a chance(exploration) and expects a shorter path? In actual, we will balance exploration and exploitation in order to avoid our agent stuck in local optimal. Here our agent will choose action based on certain exploration_rate", "That\u2019s it! These are all we need for a grid world game. We can start and let our agent play the game!", "This is the estimates of each state after playing 50 rounds of game. As our action is deterministic, we can get best action at each state by following the highest estimate! Full code is here, go play with it and welcome to contribute if you find any to update!", "For now, we are all focusing on value iteration and deterministic game world. However, in real situation the agent will not always lands in a position where it hopes to go. Let us explore deeper on non-deterministic game playing and Q-learning.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Hmm\u2026I am a data scientist looking to catch up the tide\u2026"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc5963765ebff&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://meatba11.medium.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26----c5963765ebff---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/MJeremy2017/RL/blob/master/GridWorld/gridWorld.py", "anchor_text": "full code"}, {"url": "https://github.com/MJeremy2017/RL/blob/master/GridWorld/gridWorld.py", "anchor_text": "here"}, {"url": "https://medium.com/@zhangyue9306/implement-grid-world-with-q-learning-51151747b455", "anchor_text": "non-deterministic game playing and Q-learning"}, {"url": "https://www.cs.swarthmore.edu/~bryce/cs63/s16/slides/3-21_value_iteration.pdf", "anchor_text": "https://www.cs.swarthmore.edu/~bryce/cs63/s16/slides/3-21_value_iteration.pdf"}, {"url": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction", "anchor_text": "https://github.com/JaeDukSeo/reinforcement-learning-an-introduction"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c5963765ebff---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----c5963765ebff---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/python?source=post_page-----c5963765ebff---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----c5963765ebff---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&user=Jeremy+Zhang&userId=f37783fc8c26&source=-----c5963765ebff---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc5963765ebff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c5963765ebff---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c5963765ebff--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c5963765ebff--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c5963765ebff--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c5963765ebff--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c5963765ebff--------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://meatba11.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jeremy Zhang"}, {"url": "https://meatba11.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.1K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff37783fc8c26&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&user=Jeremy+Zhang&userId=f37783fc8c26&source=post_page-f37783fc8c26--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcdbd8b83c584&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-implement-grid-world-from-scratch-c5963765ebff&newsletterV3=f37783fc8c26&newsletterV3Id=cdbd8b83c584&user=Jeremy+Zhang&userId=f37783fc8c26&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}