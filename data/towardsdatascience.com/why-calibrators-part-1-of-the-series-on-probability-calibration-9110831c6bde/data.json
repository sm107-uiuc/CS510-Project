{"url": "https://towardsdatascience.com/why-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde", "time": 1683014686.249661, "path": "towardsdatascience.com/why-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde/", "webpage": {"metadata": {"title": "Why Calibrators? Part 1 of the Series on Probability Calibration | by Jason Yonglin Wu | Towards Data Science", "h1": "Why Calibrators? Part 1 of the Series on Probability Calibration", "description": "The topic of this series is something that appears sparingly in standard ML courses but frequently in the industry \u2014 probability calibration. In the first post of the series, I will give a general\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.vegasinsider.com/soccer/story.cfm/story/1892706", "anchor_text": "VegasInsider.com", "paragraph_index": 3}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html", "anchor_text": "sklearn\u2019s calibration_cruve", "paragraph_index": 5}, {"url": "https://scikit-learn.org/stable/modules/calibration.html", "anchor_text": "here", "paragraph_index": 6}, {"url": "https://developers.google.com/machine-learning/crash-course/classification/prediction-bias", "anchor_text": "Machine Learning Crash Course \u2014 Classification: Prediction Bias", "paragraph_index": 8}, {"url": "https://scikit-learn.org/stable/modules/calibration.html", "anchor_text": "scikit-learn\u2019s guide on probability calibration", "paragraph_index": 16}, {"url": "https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf", "anchor_text": "This paper", "paragraph_index": 19}, {"url": "https://d2l.ai/chapter_multilayer-perceptrons/environment.html#label-shift", "anchor_text": "one type of distribution shift in machine learning", "paragraph_index": 20}, {"url": "https://www.chrisstucchio.com/blog/2020/calibrated_classifier_base_rates.html", "anchor_text": "This blogpost", "paragraph_index": 20}, {"url": "https://tech.affirm.com/exploration-for-machine-learning-at-affirm-632ea5930f54", "anchor_text": "exploration", "paragraph_index": 22}], "all_paragraphs": ["The topic of this series is something that appears sparingly in standard ML courses but frequently in the industry \u2014 probability calibration. In the first post of the series, I will give a general introduction to probability calibration for classifiers and discuss when it makes sense to use calibrators.", "In machine learning, sometimes probabilistic classifiers are needed \u2014 classifiers that not only return the most likely class label, but also the probability of that class. A probabilistic classifier is well-calibrated when the predicted probability matches the true probability of the event of interest. For example, if a fraud classifier returns 0.1, or 10%, for the likelihood of a particular credit card application to be fraudulent, this number is considered well-calibrated if similar types of applications are truly fraudulent on average in 1 of 10 samples.", "This is important when the absolute value of the predicted probability, instead of just the rank order, matters for the modeler. An example of this is sports betting.", "Before the 2018 World Cup, VegasInsider.com posted 5/1 odds of Germany winning the tournament, which means for every dollar, you get $6 back (original dollar plus $5 payout) if Germany wins and $0 otherwise. So if you want to bet on Germany, you\u2019d better be sure that Germany has more than \u2159 chance of winning. If you built a classifier to predict the winning probability of each team, and its output is Germany: 0.25 and England: 0.1, you want to make sure that classifier is telling you Germany has a 25% chance of winning, instead of merely saying Germany has a better chance than England.", "A calibration plot is a standard way to check how calibrated a classifier is on a given set of data with known outcomes. (It only works with binary classifiers; for multi-class classifiers, a separate calibration plot is needed for each class) To create the calibration plot, the following steps are followed.", "Let\u2019s make a calibration plot on a real dataset, using sklearn\u2019s calibration_cruve", "A perfectly calibrated classifier has a calibration curve in the form of y = x, as shown as the blue dotted line in the graph. Comparing the calibration curve for the SVC classifier against the perfect curve, we can see that it predicts a probability that\u2019s too low on the lower end, and too high on the higher end. This is typical for maximum-margin methods; a thorough explanation can be found here.", "When outputs from out-of-the-box classifiers are not well-calibrated, which is the case in our example above, a calibrator can be trained to correct that. It is a mapping from the raw classifier outputs to the calibrated probabilistic scores. How to train such calibrators is a topic for the next blog post, however, before training the calibrator, we should first ask ourselves whether a calibrator is absolutely necessary. It is also worth noting that in real life, we can never achieve a \u2018perfectly calibrated\u2019 classifier, even with a calibrator. How close we need our calibration curve to match the perfect line is highly dependent on the specific use case.", "Google engineers expressed pretty strong views against calibrators in their Machine Learning Crash Course \u2014 Classification: Prediction Bias:", "You might be tempted to correct prediction bias by post-processing the learned model \u2014 that is, by adding a calibration layer that adjusts your model\u2019s output to reduce the prediction bias. For example, if your model has +3% bias, you could add a calibration layer that lowers the mean prediction by 3%. However, adding a calibration layer is a bad idea for the following reasons:", "You\u2019re fixing the symptom rather than the cause.", "You\u2019ve built a more brittle system that you must now keep up to date.", "If possible, avoid calibration layers. Projects that use calibration layers tend to become reliant on them \u2014 using calibration layers to fix all their model\u2019s sins. Ultimately, maintaining the calibration layers can become a nightmare.", "In the same article, Google also listed possible root causes of prediction bias:", "I strongly recommend going through that list and trying to fix those issues before using calibrators.", "That being said, despite google\u2019s well-intentioned warnings, calibrators are used quite often. This does not mean that all of them are created by bad engineers. In practice, things are a lot more complicated and nuanced, and sometimes it\u2019s impossible to \u2018fix the cause rather than the symptom\u2019, Here are some typical scenarios in which uses of calibrators are well justified:", "Google uses logistic regression as their example and claims \u2018Logistic regression predictions should be unbiased.\u2019 However, many other types of classifiers, e.g. random forest or SVM, are not. Whether a particular type of classifier is well calibrated depends on its learning algorithm and loss function. For a detailed comparison of how well some common types of classifiers are calibrated and a more in-depth explanation of the underlying reasons, check out scikit-learn\u2019s guide on probability calibration.", "These are techniques used in practice to deal with imbalances in the dataset. For example, in credit card transaction datasets, you can expect to have a large number of false (non-fraudulent) outcomes and a relatively smaller number of true outcomes. It is often challenging to train standard ML models on an imbalanced dataset \u2014 having few instances of the minority class means that the learning algorithm is often unable to generalize the behavior of the minority class well. This often leads to poor prediction accuracy.", "One typical strategy for dealing with this is resampling, either by undersampling \u2014 removing samples of the majority class at random, or oversampling \u2014 replicating the minority class in the dataset. This strategy improves the prediction accuracy at the expense of introducing differences in class distributions between the training set and test set. Even if a classifier is well-calibrated on the training set, it is no longer calibrated on the test set since the distribution has changed.", "This paper examines this problem in detail and introduces a method to obtain a more calibrated output, which essentially adds a calibration layer between the raw output and final output.", "Label shift is one type of distribution shift in machine learning, typical in production ML systems. In this case, P(X|y) remains the same but P(y) changes. This will cause models to produce uncalibrated results. Using the credit card transaction example again \u2014 maybe fraud was a big problem in 2019 and 10% of transactions were fraudulent, but in 2020 most of the fraudsters went away, and only(!) 1% of the transactions were fraudulent. It is often not desirable to throw all the data in 2019 away. A better approach is to correct the calibration of the model using more recent data and the new base fraud rate. This blogpost examines this phenomenon in detail and proposes a nice solution.", "In production ML systems, labels sometimes come from observed events, such as whether users watched a video or repaid their loans, and this means that we only have labels on the dataset with observed events. For example, in credit underwriting, we only observe the payment patterns for the loans that were given out. If we train a model on the training data with observed labels, it will not be well-calibrated because the training data will have way fewer loans than the test dataset, which includes all incoming applications (assuming the current production model does a good job rejecting loan applications with high default probabilities).", "This is a well-known feedback loop problem in ML and one way to recover the right data distribution on the test set is using exploration \u2014 approving some loan applications that are typically rejected and upweighting those loans. However, that is an expensive strategy that is undesirable on a much larger training set. Even if money isn\u2019t an issue, it will suffer from other problems like high variance and dataset shift. Again, this is a case where it\u2019s difficult to train a well-calibrated model out of the box and it\u2019s more efficient to train a calibrator on a well-curated testing dataset.", "In this blog post, I explained why it is important for classifiers to be calibrated, and discussed when it makes sense to use a calibrator to correct the output of classifiers, instead of fixing the algorithm or the training data. In the next few posts, I will cover different methods of training calibrators and ways to evaluate them.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Applied ML Scientist at Affirm, Inc"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9110831c6bde&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9110831c6bde--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@jasonyonglinwu?source=post_page-----9110831c6bde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jasonyonglinwu?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Jason Yonglin Wu"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39b1fbcdf6cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&user=Jason+Yonglin+Wu&userId=39b1fbcdf6cd&source=post_page-39b1fbcdf6cd----9110831c6bde---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/probability-calibration", "anchor_text": "Probability Calibration"}, {"url": "https://unsplash.com/@wwarby?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "William Warby"}, {"url": "https://unsplash.com/s/photos/measurement?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://www.vegasinsider.com/soccer/story.cfm/story/1892706", "anchor_text": "VegasInsider.com"}, {"url": "https://unsplash.com/@kaysha?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Kay"}, {"url": "https://unsplash.com/s/photos/casino?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html", "anchor_text": "sklearn\u2019s calibration_cruve"}, {"url": "https://scikit-learn.org/stable/modules/calibration.html", "anchor_text": "here"}, {"url": "https://developers.google.com/machine-learning/crash-course/classification/prediction-bias", "anchor_text": "Machine Learning Crash Course \u2014 Classification: Prediction Bias"}, {"url": "https://scikit-learn.org/stable/modules/calibration.html", "anchor_text": "scikit-learn\u2019s guide on probability calibration"}, {"url": "https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf", "anchor_text": "This paper"}, {"url": "https://d2l.ai/chapter_multilayer-perceptrons/environment.html#label-shift", "anchor_text": "one type of distribution shift in machine learning"}, {"url": "https://www.chrisstucchio.com/blog/2020/calibrated_classifier_base_rates.html", "anchor_text": "This blogpost"}, {"url": "https://unsplash.com/@chrislawton?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Chris Lawton"}, {"url": "https://unsplash.com/s/photos/change?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://tech.affirm.com/exploration-for-machine-learning-at-affirm-632ea5930f54", "anchor_text": "exploration"}, {"url": "https://medium.com/tag/maching-learning?source=post_page-----9110831c6bde---------------maching_learning-----------------", "anchor_text": "Maching Learning"}, {"url": "https://medium.com/tag/probability?source=post_page-----9110831c6bde---------------probability-----------------", "anchor_text": "Probability"}, {"url": "https://medium.com/tag/calibration?source=post_page-----9110831c6bde---------------calibration-----------------", "anchor_text": "Calibration"}, {"url": "https://medium.com/tag/probability-calibration?source=post_page-----9110831c6bde---------------probability_calibration-----------------", "anchor_text": "Probability Calibration"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&user=Jason+Yonglin+Wu&userId=39b1fbcdf6cd&source=-----9110831c6bde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&user=Jason+Yonglin+Wu&userId=39b1fbcdf6cd&source=-----9110831c6bde---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9110831c6bde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9110831c6bde---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9110831c6bde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9110831c6bde--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9110831c6bde--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9110831c6bde--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9110831c6bde--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jasonyonglinwu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@jasonyonglinwu?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Jason Yonglin Wu"}, {"url": "https://medium.com/@jasonyonglinwu/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "164 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F39b1fbcdf6cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&user=Jason+Yonglin+Wu&userId=39b1fbcdf6cd&source=post_page-39b1fbcdf6cd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2e1aecbd6f43&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-calibrators-part-1-of-the-series-on-probability-calibration-9110831c6bde&newsletterV3=39b1fbcdf6cd&newsletterV3Id=2e1aecbd6f43&user=Jason+Yonglin+Wu&userId=39b1fbcdf6cd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}