{"url": "https://towardsdatascience.com/recurrent-neural-networks-part-5-885fc3357792", "time": 1683011521.690784, "path": "towardsdatascience.com/recurrent-neural-networks-part-5-885fc3357792/", "webpage": {"metadata": {"title": "Sequence generation using RNNs - An Overview | Towards Data Science", "h1": "Recurrent Neural Networks \u2014 Part 5", "description": "In this blog post, we discuss how to generate symbol sequences from RNNs. We show examples that generate Shakespeare-like text or folk music."}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning", "paragraph_index": 0}, {"url": "http://peaks.informatik.uni-erlangen.de/autoblog/", "anchor_text": "Try it yourself!", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/recurrent-neural-networks-part-4-39a568034d3b", "anchor_text": "Previous Lecture", "paragraph_index": 1}, {"url": "https://youtu.be/ZUz_u3w-sCs", "anchor_text": "Watch this Video", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level", "paragraph_index": 1}, {"url": "https://towardsdatascience.com/visualization-attention-part-1-a16667295007", "anchor_text": "Next Lecture", "paragraph_index": 1}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "great blog post by Andrew Kaparthy", "paragraph_index": 7}, {"url": "https://www.youtube.com/watch?v=avxXRNJvUMk", "anchor_text": "like these folks", "paragraph_index": 10}, {"url": "https://folkrnn.org/competition/", "anchor_text": "on this website", "paragraph_index": 10}, {"url": "https://youtu.be/GpAHm7dvP_k", "anchor_text": "unsupervised deep learning", "paragraph_index": 11}, {"url": "https://youtu.be/ZUz_u3w-sCs", "anchor_text": "one of the next videos", "paragraph_index": 12}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "nice blog post by Andrew Kaparthy", "paragraph_index": 14}, {"url": "https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation/", "anchor_text": "CNN\u2019s for a machine translation", "paragraph_index": 14}, {"url": "http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/", "anchor_text": "cool blog post for music generation", "paragraph_index": 14}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here", "paragraph_index": 15}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep", "paragraph_index": 15}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning", "paragraph_index": 15}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture", "paragraph_index": 15}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube", "paragraph_index": 15}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter", "paragraph_index": 15}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook", "paragraph_index": 15}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn", "paragraph_index": 15}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License", "paragraph_index": 15}, {"url": "http://peaks.informatik.uni-erlangen.de/autoblog/", "anchor_text": "AutoBlog", "paragraph_index": 15}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "Character RNNs", "paragraph_index": 16}, {"url": "https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation/", "anchor_text": "CNNs for Machine Translation", "paragraph_index": 16}, {"url": "http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/", "anchor_text": "Composing Music with RNNs", "paragraph_index": 16}], "all_paragraphs": ["These are the lecture notes for FAU\u2019s YouTube Lecture \u201cDeep Learning\u201d. This is a full transcript of the lecture video & matching slides. We hope, you enjoy this as much as the videos. Of course, this transcript was created with deep learning techniques largely automatically and only minor manual modifications were performed. Try it yourself! If you spot mistakes, please let us know!", "Previous Lecture / Watch this Video / Top Level / Next Lecture", "Welcome back to the final part of our video series on recurrent neural networks! Today, we want to talk a bit about the sampling of recurrent neural networks. When I mean sampling, I mean that we want to use recurrent neural networks to actually generate sequences of symbols. So, how can we actually do that?", "Well, if you train your neural networks in the right way. You can actually create them in a way that they predict the probability distribution of the next element. So, if I train them to predict the next symbol in the sequence, you can also use them actually for generating sequences. The idea here is that you start with the empty symbol and then you use the RNN to generate some output. Then, you take this output and put it into the next state\u2019s input. If you go ahead and do so, then you can see that you can actually generate whole sequences from your trained recurrent neural network.", "So, the simple strategy is to perform a greedy search. So here we start with the empty symbol. Then, we just pick the most likely element as the input to the RNN in the next state and generate the next one and the next one and the next one and this generates exactly one sample sequence per experiment. So, this would be a greedy search and you can see that we exactly get one sentence that is constructed here. The sentence that we are constructing here is \u201clet\u2019s go through time\u201d. Well, the drawback is, of course, there is no look-ahead possible. So, let\u2019s say the most likely word after \u201clet\u2019s go\u201d is \u201clet\u2019s\u201d. So you could be generating loops like \u201clet\u2019s go let\u2019s go\u201d and so on. So, you\u2019re not able to detect that \u201clet\u2019s go through time\u201d has a higher total probability. So, it tends to repeat sequences of frequent words \u201cand\u201d, \u201cthe\u201d, \u201csome\u201d and so on in speech.", "Now, we are interested in alleviating this problem. This can be done with a beam search. Now, the beam search concept is to select the k most likely elements. k is essentially the beam width or size. So, here you then roll out k possible sequences. You have the one with these k elements as prefix and take the k most probable ones. So, in the example that we show here on the right-hand side, we start with the empty word. Then, we take the two most likely ones which would be \u201clet\u2019s\u201d and \u201cthrough\u201d. Next, we generate \u201clet\u2019s\u201d as output if we take \u201cthrough\u201d. If we take \u201clet\u2019s\u201d, we generate \u201cgo\u201d and we can continue this process and with our beam of the size of two. We can keep the two most likely sequences in the beam search. So now, we generate two sequences at a time. One is \u201clet\u2019s go through time\u201d and the other one is \u201cthrough let\u2019s go time\u201d. So, you see that we can use this beam idea to generate multiple sequences. In the end, we can determine which one we like best or which one generated the most total probability. So, we can generate multiple sequences in one go which typically then also contains better sequences than in the greedy search. I would say this is one of the most common techniques actually to sample from an RNN.", "Of course, there are also other things like random sampling. Here, the idea is that you select the next one according to the output probability distribution. You remember, we encoded our word as one-hot-encoded vectors. Then, we can essentially interpret the output of the RNN as a probability distribution and sample from it. This then allows us to generate many different sequences. So let\u2019s say if \u201clet\u2019s\u201d has an output probability of 0.8, it is sampled 8 out of 10 times as the next word. This creates very diverse results and it may look too random. So, you see here we get quite diverse results and the sequences that we are generating here. There\u2019s quite some randomness that you can also observe in the generated sequences. To reduce the randomness, you can increase the probability or decrease the probability of probable or less probable words. This can be done for example by temperature sampling. Here you see that we introduced this temperature \ud835\udf0f that we then use in order to steer the probability sampling. This is a common technique that you have already seen in various instances in this class.", "So let\u2019s look into some examples and one thing that I found very interesting is character-based language modeling with RNNs. There\u2019s a great blog post by Andrew Kaparthy which we have here. I also put it as a link to the description below. There he essentially trained an RNN for text generation based on Shakespeare. It\u2019s trained on the character level. So, you only have one character as input and then you generate the sequence. It generates very interesting sequences. So here, you can see typical examples that have been generated. Let me read this to you:", "\u201cPandarus Alas I think he shall be come approached and the dayWhen little srain would be attain\u2019d into being never fed, And who is but a chain and subjects of his death, I should not sleep.\u201d", "and so on. So, you can see that this is very interesting that the type of language that is generated this very close to Shakespeare but if you read through these examples, you can see that they\u2019re essentially complete nonsense. Still, it\u2019s interesting that the tone of the language that is generated is still present and is very typical for Shakespeare. So, that\u2019s really interesting.", "Of course, you can generate many, many other things. One of a very nice example that I want to show to you today is composing folk music. So, music composition is typically tackled with RNNS and you can find different examples in literature, also by J\u00fcrgen Schmidhuber. The idea here is to use bigger deeper networks to generate folk music. So, what they employ is a character level RNN using ABC format including generating the title. So one example that I have here is this small piece of music. Yeah, as you can hear, it is really folk music. So, this is completely automatically generated. Interesting isn\u2019t it? If you listen very closely, then you can also hear that folk music may be particularly suited for this because you could argue it\u2019s kind a bit of repetitive. Still, it\u2019s pretty awesome that the entire song is completely automatically generated. There are actually people meeting playing computer-generated songs like these folks on real instruments. Very interesting observation. So, I also put the link here for your reference if you\u2019re interested in this. You can listen to many more examples on this website.", "So there are also RNNs for non-sequential tasks. RNNs can also be used for stationary inputs like image generation. Then, the idea is to model the process from rough sketch to final image. You can see one example here where we start essentially by drawing numbers from blurry to sharp. In this example, they use an additional attention mechanism telling the network where to look. This then generates something similar to brushstrokes. It actually uses a variational autoencoder which we will talk about when we talk on the topic of unsupervised deep learning.", "So let\u2019s summarize this a little bit. You\u2019ve seen recurrent neural networks are able to directly model sequential algorithms. You train via truncated backpropagation through time. The simple units suffer extremely from the exploding and vanishing gradients. We have seen that the LSTMs and GRUs are improved RNNs that explicitly model this forgetting and remembering operation. What we haven\u2019t talked about is that there are many, many more developments that we can\u2019t cover in this short lecture. So, it would be interesting also to talk about memory networks, neural Turing machines, and what we only touched at the moment is attention and recurrent neural networks. We\u2019ll talk a bit more about attention in one of the next videos as well.", "So, next time in deep learning, we want to talk about visualization. In particular, we want to talk about visualizing architectures the training process, and of course also the inner workings of the network. We want to figure out what is actually happening inside the network and there are quite a few techniques \u2014 and to be honest \u2014 we\u2019ve already seen some of them earlier in this class. In this lecture, we will really want to look into those methods and understand how they actually work in order to figure out what\u2019s happening inside of deep neural networks. One interesting observation is that this is also related to neural network art. Another thing that deserves some little more thought is attention mechanisms and this will also be covered in one of the videos very soon to follow.", "So, I have some comprehensive questions: \u201cWhat\u2019s the strength of RNNs compared to feed-forward networks?\u201d Then, of course: \u201cHow do you train an RNN?\u201d, \u201cWhat are the challenges?\u201d, \u201cWhat\u2019s the main idea behind LSTMs?\u201d So you should be able to describe the unrolling of RNNs during the training. You should be able to describe the Elman cell, the LSTM, and the GRU. So, these are really crucial things that you should know if you have to take some tests in the very close future. So, better be prepared for questions like this one. Ok, we have some further reading below. There\u2019s this very nice blog post by Andrew Kaparthy. There is a very cool blog post about CNN\u2019s for a machine translation that I really recommend reading and a cool blog post for music generation which you can also find below. Of course, we also have plenty of scientific references. So, I hope you enjoyed this video and see you in the next one. Bye-bye!", "If you liked this post, you can find more essays here, more educational material on Machine Learning here, or have a look at our Deep LearningLecture. I would also appreciate a follow on YouTube, Twitter, Facebook, or LinkedIn in case you want to be informed about more essays, videos, and research in the future. This article is released under the Creative Commons 4.0 Attribution License and can be reprinted and modified if referenced. If you are interested in generating transcripts from video lectures try AutoBlog.", "Character RNNsCNNs for Machine TranslationComposing Music with RNNs", "I do research in Machine Learning. My positions include being Prof @FAU_Germany, President @DataDonors, and Board Member for Science & Technology @TimeMachineEU"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F885fc3357792&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/tagged/fau-lecture-notes", "anchor_text": "FAU LECTURE NOTES"}, {"url": "https://akmaier.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Andreas Maier"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee----885fc3357792---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F885fc3357792&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=-----885fc3357792---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F885fc3357792&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=-----885fc3357792---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning"}, {"url": "http://peaks.informatik.uni-erlangen.de/autoblog/", "anchor_text": "Try it yourself!"}, {"url": "https://towardsdatascience.com/recurrent-neural-networks-part-4-39a568034d3b", "anchor_text": "Previous Lecture"}, {"url": "https://youtu.be/ZUz_u3w-sCs", "anchor_text": "Watch this Video"}, {"url": "https://towardsdatascience.com/all-you-want-to-know-about-deep-learning-8d68dcffc258", "anchor_text": "Top Level"}, {"url": "https://towardsdatascience.com/visualization-attention-part-1-a16667295007", "anchor_text": "Next Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "Character-level RNNs"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "great blog post by Andrew Kaparthy"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "Karparthy\u2019s blog"}, {"url": "https://themachinefolksession.org/tunes/", "anchor_text": "Composing folk music"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://www.youtube.com/watch?v=avxXRNJvUMk", "anchor_text": "like these folks"}, {"url": "https://folkrnn.org/competition/", "anchor_text": "on this website"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://youtu.be/GpAHm7dvP_k", "anchor_text": "unsupervised deep learning"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://youtu.be/ZUz_u3w-sCs", "anchor_text": "one of the next videos"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "https://creativecommons.org/licenses/by/4.0/", "anchor_text": "CC BY 4.0"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Deep Learning Lecture"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "nice blog post by Andrew Kaparthy"}, {"url": "https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation/", "anchor_text": "CNN\u2019s for a machine translation"}, {"url": "http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/", "anchor_text": "cool blog post for music generation"}, {"url": "https://medium.com/@akmaier", "anchor_text": "more essays here"}, {"url": "https://lme.tf.fau.de/teaching/free-deep-learning-resources/", "anchor_text": "here"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Deep"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&index=1", "anchor_text": "Learning"}, {"url": "https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj", "anchor_text": "Lecture"}, {"url": "https://www.youtube.com/c/AndreasMaierTV", "anchor_text": "YouTube"}, {"url": "https://twitter.com/maier_ak", "anchor_text": "Twitter"}, {"url": "https://www.facebook.com/andreas.maier.31337", "anchor_text": "Facebook"}, {"url": "https://www.linkedin.com/in/andreas-maier-a6870b1a6/", "anchor_text": "LinkedIn"}, {"url": "https://creativecommons.org/licenses/by/4.0/deed.de", "anchor_text": "Creative Commons 4.0 Attribution License"}, {"url": "http://peaks.informatik.uni-erlangen.de/autoblog/", "anchor_text": "AutoBlog"}, {"url": "https://folkrnn.org/competition/", "anchor_text": "FolkRNN.org"}, {"url": "https://themachinefolksession.org/tunes/", "anchor_text": "MachineFolkSession.com"}, {"url": "https://github.com/IraKorshunova/folk-rnn/blob/master/soundexamples/successes/The%20Glas%20Herry%20Comment%2014128.mp3", "anchor_text": "The Glass Herry Comment 14128"}, {"url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "anchor_text": "Character RNNs"}, {"url": "https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation/", "anchor_text": "CNNs for Machine Translation"}, {"url": "http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/", "anchor_text": "Composing Music with RNNs"}, {"url": "http://www.pnas.org/content/79/8/2554.full.pdf.", "anchor_text": "http://www.pnas.org/content/79/8/2554.full.pdf."}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----885fc3357792---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----885fc3357792---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----885fc3357792---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/fau-lecture-notes?source=post_page-----885fc3357792---------------fau_lecture_notes-----------------", "anchor_text": "Fau Lecture Notes"}, {"url": "https://medium.com/tag/data-science?source=post_page-----885fc3357792---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F885fc3357792&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=-----885fc3357792---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F885fc3357792&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=-----885fc3357792---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F885fc3357792&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee----885fc3357792---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa5f0dee142a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&newsletterV3=b1444918afee&newsletterV3Id=a5f0dee142a2&user=Andreas+Maier&userId=b1444918afee&source=-----885fc3357792---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Written by Andreas Maier"}, {"url": "https://akmaier.medium.com/followers?source=post_page-----885fc3357792--------------------------------", "anchor_text": "2.2K Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1444918afee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&user=Andreas+Maier&userId=b1444918afee&source=post_page-b1444918afee----885fc3357792---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa5f0dee142a2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Frecurrent-neural-networks-part-5-885fc3357792&newsletterV3=b1444918afee&newsletterV3Id=a5f0dee142a2&user=Andreas+Maier&userId=b1444918afee&source=-----885fc3357792---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/codex/10-ideas-to-make-money-from-large-language-models-86f2cb31bb25?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Andreas Maier"}, {"url": "https://medium.com/codex?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/10-ideas-to-make-money-from-large-language-models-86f2cb31bb25?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "10 Ideas to Make Money from Large Language ModelsLarge Language Models work, but what can we do with them?"}, {"url": "https://medium.com/codex/10-ideas-to-make-money-from-large-language-models-86f2cb31bb25?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "\u00b73 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2F86f2cb31bb25&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2F10-ideas-to-make-money-from-large-language-models-86f2cb31bb25&user=Andreas+Maier&userId=b1444918afee&source=-----86f2cb31bb25----0-----------------clap_footer----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://medium.com/codex/10-ideas-to-make-money-from-large-language-models-86f2cb31bb25?source=author_recirc-----885fc3357792----0---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F86f2cb31bb25&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2F10-ideas-to-make-money-from-large-language-models-86f2cb31bb25&source=-----885fc3357792----0-----------------bookmark_preview----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----885fc3357792----1---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----885fc3357792----1-----------------bookmark_preview----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----885fc3357792----2---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----885fc3357792----2-----------------bookmark_preview----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://medium.com/codex/gradient-descent-and-back-tracking-line-search-d8bd120bd625?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Andreas Maier"}, {"url": "https://medium.com/codex?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "CodeX"}, {"url": "https://medium.com/codex/gradient-descent-and-back-tracking-line-search-d8bd120bd625?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "Gradient Descent and Back-tracking Line SearchAn Introduction to Optimization using Gradient Descent"}, {"url": "https://medium.com/codex/gradient-descent-and-back-tracking-line-search-d8bd120bd625?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": "\u00b713 min read\u00b7Apr 10, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcodex%2Fd8bd120bd625&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fgradient-descent-and-back-tracking-line-search-d8bd120bd625&user=Andreas+Maier&userId=b1444918afee&source=-----d8bd120bd625----3-----------------clap_footer----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://medium.com/codex/gradient-descent-and-back-tracking-line-search-d8bd120bd625?source=author_recirc-----885fc3357792----3---------------------3bcebd73_5f34_41a6_b189_2ab35ef688f2-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8bd120bd625&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcodex%2Fgradient-descent-and-back-tracking-line-search-d8bd120bd625&source=-----885fc3357792----3-----------------bookmark_preview----3bcebd73_5f34_41a6_b189_2ab35ef688f2-------", "anchor_text": ""}, {"url": "https://akmaier.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "See all from Andreas Maier"}, {"url": "https://towardsdatascience.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----0-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----885fc3357792----0-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----1-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----885fc3357792----1-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://youssefraafat57.medium.com/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Youssef Hosni"}, {"url": "https://pub.towardsai.net/?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Towards AI"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Building An LSTM Model From Scratch In PythonHow to build a basic LSTM using Basic Python libraries"}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b717 min read\u00b7Jan 2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&user=Youssef+Hosni&userId=859af34925b7&source=-----1dedd89de8fe----0-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://pub.towardsai.net/building-a-lstm-from-scratch-in-python-1dedd89de8fe?source=read_next_recirc-----885fc3357792----0---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dedd89de8fe&operation=register&redirect=https%3A%2F%2Fpub.towardsai.net%2Fbuilding-a-lstm-from-scratch-in-python-1dedd89de8fe&source=-----885fc3357792----0-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----1-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----885fc3357792----1---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----885fc3357792----1-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----2-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----885fc3357792----2---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----885fc3357792----2-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----3-----------------clap_footer----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----885fc3357792----3---------------------3d03a482_4e42_4884_bb83_e951b2488390-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----885fc3357792----3-----------------bookmark_preview----3d03a482_4e42_4884_bb83_e951b2488390-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----885fc3357792--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----885fc3357792--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}