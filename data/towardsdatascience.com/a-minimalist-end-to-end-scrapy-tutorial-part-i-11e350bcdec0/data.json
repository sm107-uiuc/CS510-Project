{"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0", "time": 1683000295.082774, "path": "towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0/", "webpage": {"metadata": {"title": "A Minimalist End-to-End Scrapy Tutorial (Part I) | by Harry Wang | Towards Data Science", "h1": "A Minimalist End-to-End Scrapy Tutorial (Part I)", "description": "Web scraping is an important skill for data scientists. I have developed a number of ad hoc web scraping projects using Python, BeautifulSoup, and Scrapy in the past few years and read a few books\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III", "paragraph_index": 0}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV", "paragraph_index": 0}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V", "paragraph_index": 0}, {"url": "https://github.com/harrywang/scrapy-tutorial-starter", "anchor_text": "starter repo", "paragraph_index": 4}, {"url": "https://docs.python.org/3/tutorial/venv.html", "anchor_text": "Python3 virtual environment documentation", "paragraph_index": 4}, {"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "anchor_text": "Scrapy tutorial", "paragraph_index": 8}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com", "paragraph_index": 8}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com", "paragraph_index": 11}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com", "paragraph_index": 12}, {"url": "https://www.w3schools.com/xml/xpath_syntax.asp", "anchor_text": "Xpath selector", "paragraph_index": 13}, {"url": "https://www.w3schools.com/cssref/css_selectors.asp", "anchor_text": "CSS selector", "paragraph_index": 13}, {"url": "https://developers.google.com/web/tools/chrome-devtools/css/", "anchor_text": "Chrome DevTools", "paragraph_index": 13}, {"url": "http://quotes.toscrape.com/", "anchor_text": "http://quotes.toscrape.com/", "paragraph_index": 23}, {"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html#a-shortcut-for-creating-requests", "anchor_text": "see this section", "paragraph_index": 26}, {"url": "https://twistedmatrix.com/trac/", "anchor_text": "Twisted", "paragraph_index": 30}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II", "paragraph_index": 32}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II", "paragraph_index": 33}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III", "paragraph_index": 33}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV", "paragraph_index": 33}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V", "paragraph_index": 33}], "all_paragraphs": ["Part I, Part II, Part III, Part IV, Part V", "Web scraping is an important skill for data scientists. I have developed a number of ad hoc web scraping projects using Python, BeautifulSoup, and Scrapy in the past few years and read a few books and tons of online tutorials along the way. However, I have not found a simple beginner level tutorial that is end-to-end in the sense that covers all basic steps and concepts in a typical Scrapy web scraping project (therefore Minimalist in the title) \u2014 that\u2019s why I am writing this and hope the code repo can serve as a template to help jumpstart your web scraping projects.", "Many people ask: should I use BeautifulSoup or Scrapy? They are different things: BeautifulSoup is a library for parsing HTML and XML and Scrapy is a web scraping framework. You can use BeautifulSoup instead of Scrapy build-in selectors if you want but comparing BeautifulSoup to Scrapy is like comparing the Mac keyboard to the iMac or a better metaphor as stated in the official documentation \u201clike comparing jinja2 to Django\u201d if you know what they are :) \u2014 In short, you should learn Scrapy if you want to do serious and systematic web scraping.", "In this tutorial series, I am going to cover the following steps:", "First, create a new folder, setup Python 3 virtual environment inside the folder, and install Scrapy. To make this step easy, I created a starter repo, which you can fork and clone (see Python3 virtual environment documentation if needed):", "Your folder should look like the following and I assume we always work in the virtual environment. Note that we only have one package in the requirements.txt so far.", "run scrapy startproject tutorial to create an empty scrapy project and your folder looks like:", "Two identical \u201ctutorial\u201d folders were created. We don\u2019t need the first level \u201ctutorial\u201d folder \u2014 delete it and move the second level \u201ctutorial\u201d folder with its contents one-level up \u2014 I know this is confusing but that\u2019s all you have to do with the folder structure. Now, your folder should look like:", "Don\u2019t worry about the auto-generated files so far, we will come back to those files later. This tutorial is based on the official Scrapy tutorial. Therefore, the website we are going to crawl is http://quotes.toscrape.com, which is quite simple: there are pages of quotes with authors and tags:", "When you click the author, it goes to the author detail page with name, birthday, and bio.", "Now, create a new file named \u201cquotes-spider.py\u201d in the \u201cspider\u201d folder with the following content:", "You just created a spider named \u201cquotes\u201d, which sends a request to http://quotes.toscrape.com and gets the response from the server. However, the spider does not do anything so far when parsing the response and simply outputs a string to the console. Let\u2019s run this spider: scrapy crawl quotes , you should see the output like:", "Next, let\u2019s analyze the response, i.e., the HTML page at http://quotes.toscrape.com using Scrapy Shell by running:", "You can select elements using either Xpath selector or CSS selector and Chrome DevTools is often used to analyze the page (we won\u2019t cover the selector details, please read the documents to learn how to use them):", "For example, you can test the selector and see the results in Scrapy Shell \u2014 assume we want to get the quote block shown above:", "You can either use Xpath response.xpath(\u201c//div[@class=\u2019quote\u2019]\u201d).get() (.get() shows the first selected element, use .getall() to show all) or CSSresponse.css(\u201cdiv .quote\u201d).get() . I bolded the quote text, author, and tags we want to get from this quote block:", "We can proceed in the shell to get the data as follows:", "It seems that the selectors shown above get what we need. Note that I am mixing Xpath and CSS selectors for the demonstration purpose here \u2014 no need to use both in this tutorial.", "Now, let\u2019s revise the spider file and use keyword yield to output the selected data to the console (note that each page has many quotes and we use a loop to go over all of them):", "Run the spider again: scrapy crawl quotes and you can see the extracted data in the log:", "You can save the data in a JSON file by running: scrapy crawl quotes -o quotes.json", "So far, we get all quote information from the first page, and our next task is to crawl all pages. You should notice a \u201cNext\u201d button at the bottom of the front page for page navigation \u2014 the logic is: click the Next button to go to the next page, get the quotes, click Next again till the last page without the Next button.", "Via Chrome DevTools, we can get the URL of the next page:", "Let\u2019s test it out in Scrapy Shell by running scrapy shell http://quotes.toscrape.com/ again:", "Now we can write the following code for the spider to go over all pages to get all quotes:", "next_page = response.urljoin(next_page) gets the full URL and yield scrapy.Request(next_page, callback=self.parse) sends a new request to get the next page and use a callback function to call the same parse function to get the quotes from the new page.", "Shortcuts can be used to further simplify the code above: see this section. Essentially, response.follow supports relative URLs (no need to call urljoin) and automatically uses the href attribute for <a> . So, the code can be shortened further:", "Now, run the spider again scrapy crawl quotes you should see quotes from all 10 pages have been extracted. Hang in there \u2014 we are almost done for this first part. The next task is to crawl the individual author's page.", "As shown above, when we process each quote, we can go to the individual author\u2019s page by following the highlighted link \u2014 let\u2019s use Scrapy Shell to get the link:", "So, during the loop of extracting each quote, we issue another request to go to the corresponding author\u2019s page and create another parse_author function to extract the author\u2019s name, birthday, born location and bio and output to the console. The updated spider looks like the following:", "Run the spider again scrapy crawl quotes and double-check that everything you need to extract is output to the console correctly. Note that Scrapy is based on Twisted, a popular event-driven networking framework for Python and thus is asynchronous. This means that the individual author page may not be processed in sync with the corresponding quote, e.g., the order of the author page results may not match the quote order on the page. We will discuss how to link the quote with its corresponding author page in the later part.", "Congratulations, you have finished Part I of this tutorial.", "Learn more about Item and ItemLoader in Part II.", "Part I, Part II, Part III, Part IV, Part V", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F11e350bcdec0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://harrywang.medium.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Harry Wang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17a1fba2e2cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&user=Harry+Wang&userId=17a1fba2e2cb&source=post_page-17a1fba2e2cb----11e350bcdec0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@pawel_czerwinski?utm_source=medium&utm_medium=referral", "anchor_text": "Pawe\u0142 Czerwi\u0144ski"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V"}, {"url": "https://github.com/harrywang/scrapy-tutorial", "anchor_text": "harrywang/scrapy-tutorialThis repo contains the code for my tutorial: A Minimalist End-to-End Scrapy Tutorial (\u2026github.com"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III"}, {"url": "https://blog.bitsrc.io/what-is-an-orm-and-why-you-should-use-it-b2b6f75f5e2a", "anchor_text": "ORM"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV"}, {"url": "https://github.com/my8100/scrapydweb", "anchor_text": "ScrapydWeb"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V"}, {"url": "https://github.com/harrywang/scrapy-selenium-demo", "anchor_text": "Scrapy + Selenium"}, {"url": "https://link.medium.com/tw6Ylq9wjZ", "anchor_text": "How to Setup Mac for Python Development"}, {"url": "https://git-scm.com/book/en/v2", "anchor_text": "Pro Git book"}, {"url": "https://www.coursera.org/learn/intro-sql", "anchor_text": "Introduction to Structured Query Language (SQL)"}, {"url": "https://github.com/harrywang/scrapy-tutorial-starter", "anchor_text": "starter repo"}, {"url": "https://docs.python.org/3/tutorial/venv.html", "anchor_text": "Python3 virtual environment documentation"}, {"url": "https://github.com/yourusername/scrapy-tutorial-starter.git", "anchor_text": "https://github.com/yourusername/scrapy-tutorial-starter.git"}, {"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "anchor_text": "Scrapy tutorial"}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com"}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com"}, {"url": "http://quotes.toscrape.com", "anchor_text": "http://quotes.toscrape.com"}, {"url": "https://www.w3schools.com/xml/xpath_syntax.asp", "anchor_text": "Xpath selector"}, {"url": "https://www.w3schools.com/cssref/css_selectors.asp", "anchor_text": "CSS selector"}, {"url": "https://developers.google.com/web/tools/chrome-devtools/css/", "anchor_text": "Chrome DevTools"}, {"url": "http://quotes.toscrape.com'", "anchor_text": "http://quotes.toscrape.com'"}, {"url": "http://quotes.toscrape.com/", "anchor_text": "http://quotes.toscrape.com/"}, {"url": "http://quotes.toscrape.com/", "anchor_text": "http://quotes.toscrape.com/"}, {"url": "https://docs.scrapy.org/en/latest/intro/tutorial.html#a-shortcut-for-creating-requests", "anchor_text": "see this section"}, {"url": "http://quotes.toscrape.com/", "anchor_text": "http://quotes.toscrape.com/"}, {"url": "https://twistedmatrix.com/trac/", "anchor_text": "Twisted"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0?source=friends_link&sk=c9f8e32f28a88c61987ec60f93b93e6d", "anchor_text": "Part I"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-ii-b917509b73f7?source=friends_link&sk=ebd3a9cee8b2097b3857194fee3821a6", "anchor_text": "Part II"}, {"url": "https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-iii-bcd94a2e8bf3?source=friends_link&sk=a1fdde9c9dd5383d8de2e08395ee3f98", "anchor_text": "Part III"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-iv-3290d76a2aef?sk=6f0902f9a15092575814ab533a56f8ef", "anchor_text": "Part IV"}, {"url": "https://medium.com/@HarryWang/a-minimalist-end-to-end-scrapy-tutorial-part-v-e7743ee9a8ef?source=friends_link&sk=c1c5110f63c7ccbe4eb8c6209ee2f57c", "anchor_text": "Part V"}, {"url": "https://medium.com/tag/python?source=post_page-----11e350bcdec0---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/web-scraping?source=post_page-----11e350bcdec0---------------web_scraping-----------------", "anchor_text": "Web Scraping"}, {"url": "https://medium.com/tag/scrapy?source=post_page-----11e350bcdec0---------------scrapy-----------------", "anchor_text": "Scrapy"}, {"url": "https://medium.com/tag/data-science?source=post_page-----11e350bcdec0---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/web-crawler?source=post_page-----11e350bcdec0---------------web_crawler-----------------", "anchor_text": "Web Crawler"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&user=Harry+Wang&userId=17a1fba2e2cb&source=-----11e350bcdec0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&user=Harry+Wang&userId=17a1fba2e2cb&source=-----11e350bcdec0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F11e350bcdec0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----11e350bcdec0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----11e350bcdec0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----11e350bcdec0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----11e350bcdec0--------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://harrywang.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Harry Wang"}, {"url": "https://harrywang.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "152 Followers"}, {"url": "http://harrywang.me", "anchor_text": "harrywang.me"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F17a1fba2e2cb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&user=Harry+Wang&userId=17a1fba2e2cb&source=post_page-17a1fba2e2cb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fb98b5ed4151&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0&newsletterV3=17a1fba2e2cb&newsletterV3Id=b98b5ed4151&user=Harry+Wang&userId=17a1fba2e2cb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}