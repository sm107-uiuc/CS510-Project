{"url": "https://towardsdatascience.com/word-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745", "time": 1682995201.155648, "path": "towardsdatascience.com/word-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745/", "webpage": {"metadata": {"title": "Word Embedding (Part I). The original issue of NLP is the\u2026 | by Matyas Amrouche | Towards Data Science", "h1": "Word Embedding (Part I)", "description": "The original issue of NLP is the encoding of a word/sentence into an understandable format for computer processing. Representation of words in a vector space allows NLP models to learn. A first and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/@matyasamrouche19/word-embedding-part-ii-intuition-and-some-maths-to-understand-end-to-end-glove-model-9b08e6bf5c06", "anchor_text": "short presentation", "paragraph_index": 14}, {"url": "http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf", "anchor_text": "The original Skip-gram paper", "paragraph_index": 15}, {"url": "https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/syllabus.html", "anchor_text": "Standford NLP ressources", "paragraph_index": 15}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "Word2Vec tutorial", "paragraph_index": 15}], "all_paragraphs": ["The original issue of NLP is the encoding of a word/sentence into an understandable format for computer processing. Representation of words in a vector space allows NLP models to learn.A first and simple representation of words into vectors is one-hot-encoding as shown in Figure 1.", "This implementation suffers from lack of information like the context of a word, by context we mean to which other words a given word is related. Indeed, \u201cbrown\u201d and \u201cfox\u201d are orthogonal and therefore unrelated given our one-hot-encoding. On the top of that the size of a one-hot-vector is the same as the vocabulary and can reach thousands of words, which makes it impractical.", "A first solution to those limits would be :1) to consider the meaning of a word given its context 2) to reduce the dimension of its representation into a more practical size", "The Skip-gram model is one of the most popular word embeddings which aims to encode words given their context.", "\u201cYou shall know a word by the company it keeps\u201d (Firth, J. R. 1957)", "This quotation from Firth, a linguist of the 20th century, perfectly illustrates our concerns. By \u201cthe company it keeps\u201d or context, we mean the words that appear nearby a center word, within a fixed size window.", "The idea is that words that appear in similar context will have the same word representation. To achieve this goal Skip-gram will work as a predictor of the context words within a window of fixed size m for a given center word. Hence, for a vocabulary of size T the Skip-gram model will want to maximize the following predictive accuracy or likelihood:", "For calculation ease and because in machine learning we prefer to minimize functions rather than maximize them, we will now consider the average negative log likelihood and minimize it:", "In order to calculate the P(w_{i+j} | w_{i}), we are going to use two vectors :- u_{w} when w is a context word- v_{w} when w is a center word", "Then we will use the softmax function to compute the probability of a context word o (outside word) given a center word c:", "Let\u2019s interpret this equation for a better understanding of the intuition behind the Skip-gram model. The higher the similarities between the center word and the context word, the higher dot product at the numerator, hence a higher probability for the context word to be predicted as a nearby word.Here, we force the Skip-gram model to learn those u_{w} and v_{w} vectors in order to make the correct predictions.", "The Skip-gram model can be summarized by the following illustration.", "Once the Skip-gram model has trained on its prediction task, the words representations are available in the word embedding matrix representation of center words.", "Now, we are able to embed words with the Skip-gram model. However, we must notice that Skip-gram captures the meaning of words given their local context and doesn\u2019t consider a more global learning. As an example, imagine we have the sentence: \u201cThe fox\u2026\u201d, \u201cthe\u201d and \u201cfox\u201d might often appear together but Skip-gram doesn\u2019t know if \u201cthe\u201d is a common word or a word closely related to \u201cfox\u201d specifically.", "To cope with this potential issue, the Glove model has been created to look at both local context and global statistics of words. If you feel like diving deeper in word embedding approaches, here is a short presentation to quickly understand this Glove model.", "References and other useful ressources:- The original Skip-gram paper- Standford NLP ressources - Word2Vec tutorial", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML & NLP for Search Relevance @ Leboncoin \ud83d\udce6"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcab57760c745&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://matyasamrouche.medium.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": ""}, {"url": "https://matyasamrouche.medium.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Matyas Amrouche"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad07e8173fb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&user=Matyas+Amrouche&userId=ad07e8173fb2&source=post_page-ad07e8173fb2----cab57760c745---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/2JIvboGLeho?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Susan Yin"}, {"url": "https://unsplash.com/search/photos/library?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://medium.com/@matyasamrouche19/word-embedding-part-ii-intuition-and-some-maths-to-understand-end-to-end-glove-model-9b08e6bf5c06", "anchor_text": "short presentation"}, {"url": "http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf", "anchor_text": "The original Skip-gram paper"}, {"url": "https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/syllabus.html", "anchor_text": "Standford NLP ressources"}, {"url": "http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/", "anchor_text": "Word2Vec tutorial"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cab57760c745---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----cab57760c745---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/word-embedding?source=post_page-----cab57760c745---------------word_embedding-----------------", "anchor_text": "Word Embedding"}, {"url": "https://medium.com/tag/skip-gram?source=post_page-----cab57760c745---------------skip_gram-----------------", "anchor_text": "Skip Gram"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----cab57760c745---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&user=Matyas+Amrouche&userId=ad07e8173fb2&source=-----cab57760c745---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&user=Matyas+Amrouche&userId=ad07e8173fb2&source=-----cab57760c745---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcab57760c745&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cab57760c745---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cab57760c745--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cab57760c745--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cab57760c745--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cab57760c745--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cab57760c745--------------------------------", "anchor_text": ""}, {"url": "https://matyasamrouche.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://matyasamrouche.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Matyas Amrouche"}, {"url": "https://matyasamrouche.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "158 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fad07e8173fb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&user=Matyas+Amrouche&userId=ad07e8173fb2&source=post_page-ad07e8173fb2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5ead0b158385&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword-embeddings-intuition-and-some-maths-to-understand-end-to-end-skip-gram-model-cab57760c745&newsletterV3=ad07e8173fb2&newsletterV3Id=5ead0b158385&user=Matyas+Amrouche&userId=ad07e8173fb2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}