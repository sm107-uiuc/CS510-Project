{"url": "https://towardsdatascience.com/keras-hyperparameter-optimization-on-aws-cbd494a7ea15", "time": 1682996857.4085288, "path": "towardsdatascience.com/keras-hyperparameter-optimization-on-aws-cbd494a7ea15/", "webpage": {"metadata": {"title": "Keras Hyperparameter Optimization in the Cloud | by Mike Moritz | Towards Data Science", "h1": "Keras Hyperparameter Optimization in the Cloud", "description": "When training machine learning models it is often more convenient (and necessary) to offload the computation to a remote server. While free services such as Google Colab and Azure Notebooks are great\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab", "paragraph_index": 0}, {"url": "https://notebooks.azure.com/", "anchor_text": "Azure Notebooks", "paragraph_index": 0}, {"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "Sagemaker", "paragraph_index": 1}, {"url": "https://aws.amazon.com/ec2/spot/", "anchor_text": "spot instances", "paragraph_index": 4}, {"url": "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009/downloads/red-wine-quality-cortez-et-al-2009.zip/2", "anchor_text": "dataset from Kaggle", "paragraph_index": 7}, {"url": "https://github.com/autonomio/talos", "anchor_text": "Talos", "paragraph_index": 8}, {"url": "https://www.tensorflow.org/install/docker", "anchor_text": "Docker image from Tensorflow", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Matthews_correlation_coefficient", "anchor_text": "Matthews correlation coefficient", "paragraph_index": 40}, {"url": "https://github.com/mikepm35/KerasRemoteTraining", "anchor_text": "https://github.com/mikepm35/KerasRemoteTraining", "paragraph_index": 44}], "all_paragraphs": ["When training machine learning models it is often more convenient (and necessary) to offload the computation to a remote server. While free services such as Google Colab and Azure Notebooks are great for initial manual work in a Jupyter notebook, they are not well-suited to long running experiments such as hyperparameter training because of their automated turndown after a few hours.", "Using AWS as an example cloud provider, the most direct translation is to run the notebook on Sagemaker. However, more cost efficiency can be gained by setting up the training within a Docker container and taking on the deployment yourself. Developing a model in this type of environment also has the advantage of portability and reproducibility (more on that later).", "Within AWS, for this type of job, there are three primary Docker deployment options:", "In order to compare cost across the options we will fix the region to US-East-1 and use the CPU/memory pricing for Fargate to provide an instance-equivalent cost ($0.04048/vCPU/hr + $0.004445/GB/hr).", "It\u2019s clear that if we can leverage spot instances there is a significant cost advantage, and the same type of benefits apply to other instance types such as c5.large. The primary limitation of spot instances is that the capacity could be reclaimed at any time, however hyperparameter training jobs are well suited to this.", "Also, since ECS is really intended to manage clusters, we will roll our own EC2 instance to avoid this overhead by taking the following steps:", "It is worth noting that Sagemaker also offers a suite a services for training and hyperparameter optimization not considered here.", "For this example we will use a simple dataset from Kaggle that presents various wine attributes with associated quality scores.", "Keras with a Tensorflow backend will be the machine learning library of choice, and for hyperparameter optimization we will select a new library called Talos which has a very easy to use workflow. For an introduction, visit their article on Towards Data Science:", "The easiest way to migrate a local experiment to a remote server is to always work inside a Docker container since this allows you to port an exact copy of the environment from the OS through the Python packages.", "As a base we can use the Docker image from Tensorflow with Python 3. First navigate to your project directory, and then run the command below to start a shell session.", "Then in the Docker shell install the minimum Python libraries needed:", "Note: As of writing this the version of Talos available on PyPi is v0.4.9. However v0.6 is coming soon with significant changes and so this branch was used instead. In order to do this git needs to be installed apt-get update && apt-get install -y git and then pass the branch to pip instead of talos, e.g. pip install git+https://github.com/autonomio/talos.git@daily-dev. I have also created a snapshot so that this example is reproducible: https://github.com/mikepm35/talos.git@v0.6-prerelease.", "A Jupyter session can then be started via the command below, and accessed on your local machine at http://localhost:8888/.", "By mapping the working directory inside the container to the project directory all of the files will be created and saved on your local machine.", "The pattern for this example is that model development takes place in a Jupyter notebook, which can also be run in a \u201cnotebook as a service\u201d platform such as Google Colab. It is then converted to a regular Python file for executing long-running optimization experiments in the cloud.", "To help with this, the following elements are included to properly configure the notebooks:", "Given that the attributes span multiple orders of magnitude, we will normalize all of the feature columns ( X).", "The label columns (Y) will be encoded as one-hot for two classes (bad quality, good quality) based on a threshold value. This also follows the guidance from the accompanying description with the data from Kaggle.", "One concern is that the classes are highly unbalanced with only 13.6% of observations labeled as \u201cgood quality\u201d. In this section we calculate the class weights for optional incorporation into training, however manual experimentation showed no improvement in performance so it was excluded from the final model.", "Setting up an experiment for Talos follows the pattern of a normal Keras sequential model, except that substitutions are added for parameters intended for optimization (params). To allow for varying numbers of hidden layers, a Talos function is used instead of building them directly in our function.", "The input to the optimization experiment is defined as a dictionary of discreet values [a, b, c] or ranges(min, max, steps). For more information on available parameters see the Talos documentation.", "The actual experiment starts when Scan() is called. Herefraction_limit defines the percentage from the full grid parameter space that will be run, i.e. 25% of all possible parameter combinations will actually be run. Not shown in this example are the multitude of options within Talos to define the optimization strategy.", "After the scan has started Talos will provide the total number of experiments to be run as well as an estimated time to complete. In our case there are 5,760 runs that will take approximately 10 hours. (Note that the time estimation will update as new runs are executed, and the actual total execution for this experiment was 22 hours).", "After the experiment is complete we can create a deployment package that includes the best Keras model as defined by val_acc. This zip file, and the results csv created after each run, is then be uploaded to S3.", "After the model setup is complete, run the following command inside the Docker container to save the Python dependencies:", "If you are using the separate branch of Talos be sure to replace talos==0.6.0 with the git url.", "In order to deploy the experiment, a custom Docker image has to be developed to re-create the local environment. This Dockerfile starts from the same base Tensorflow image, copies the Jupyter notebook file, data, and requirements, and then installs all of the Python packages. A new user, kerasdeploy, is also created, which is the trigger to install the proper matplotlib backend.", "Since this is a headless experiment, we will use nbconvert to convert the notebook into a regular Python file that is then executed as soon as the container starts up.", "\u2026and then run locally for a few iterations to verify everything works.", "Now that a Docker image has been completed, the cloud environment needs to be setup. In this example we will use ECR as the Docker repository, however similar push/pull commands could also be used with a Docker hub (or other) repository.", "Navigate to ECR, create a new repository keras-remote-training, and note the URI. Tag the build using this URI, retrieve basic auth credentials, and then push to ECR.", "Within AWS start the \u201cLaunch Instance\u201d wizard and use the following options:", "When the instance is launched the optimization experiments will automatically begin to execute, and will save the results to S3!", "It can be very helpful to setup a CPU alert as a proxy for when training as stopped (e.g. when average CPU utilization has dropped to <10% for at least five minutes). This alarm can send an email notification, or automatically terminate the instance to reduce charges.", "Talos contains built-in reporting functionality, however, to provide further customization we will load the results file directly into a Pandas dataframe. Since these results are in S3, we will run the local instance without executing Scan().", "The Kaggle documentation refers to an AUC target of 0.88, we will calculate that from the best model as a first reference. The result is 0.89, which is a good start.", "To explore quality of fit we will plot validation accuracy versus loss, and training loss versus validation loss.", "Two primary conclusions can be drawn from the above charts:", "To handle overfitting in the experiment we will add a new parameter to the results which represents the difference between the validation and training losses (positive values indicate overfitting). Positive values indicate overfitting, and a threshold is set for subsequent filtering.", "Using this new parameter we can now view the top results that were not overfit. Although we are sorting by accuracy, we will also include the Matthews correlation coefficient as a proxy for the confusion matrix.", "As expected, increasing dropout is correlated to reducing overfitting as measured by loss_diff. The most impactful factors for accuracy and the Matthews correlation coefficient are learning rate and hidden layers, with a weaker relationship to batch size and epochs.", "Depending on the desired fine-tuning, these results can be used directly to deploy a model, or construct narrower subsequent experiments.", "This example uses a very small dataset, and so a memory optimized instance is not the best choice. Re-running in c5.large, which is half the price of m5.xlarge, we can observe better resource utilization and reasonable total cost for the experiment of $0.81.", "To view the code associated with this article, visit https://github.com/mikepm35/KerasRemoteTraining.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcbd494a7ea15&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mike.p.moritz?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mike.p.moritz?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Mike Moritz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8de386bbbfff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&user=Mike+Moritz&userId=8de386bbbfff&source=post_page-8de386bbbfff----cbd494a7ea15---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@robertina?utm_source=medium&utm_medium=referral", "anchor_text": "Roberta Sorge"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://colab.research.google.com/notebooks/welcome.ipynb", "anchor_text": "Google Colab"}, {"url": "https://notebooks.azure.com/", "anchor_text": "Azure Notebooks"}, {"url": "https://aws.amazon.com/sagemaker/", "anchor_text": "Sagemaker"}, {"url": "https://aws.amazon.com/ec2/spot/", "anchor_text": "spot instances"}, {"url": "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009/downloads/red-wine-quality-cortez-et-al-2009.zip/2", "anchor_text": "dataset from Kaggle"}, {"url": "https://github.com/autonomio/talos", "anchor_text": "Talos"}, {"url": "https://towardsdatascience.com/hyperparameter-optimization-with-keras-b82e6364ca53", "anchor_text": "Hyperparameter Optimization with Kerastowardsdatascience.com"}, {"url": "https://www.tensorflow.org/install/docker", "anchor_text": "Docker image from Tensorflow"}, {"url": "https://unsplash.com/@andreuuuw?utm_source=medium&utm_medium=referral", "anchor_text": "Andrew Wulf"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://en.wikipedia.org/wiki/Matthews_correlation_coefficient", "anchor_text": "Matthews correlation coefficient"}, {"url": "https://github.com/mikepm35/KerasRemoteTraining", "anchor_text": "https://github.com/mikepm35/KerasRemoteTraining"}, {"url": "https://medium.com/tag/docker?source=post_page-----cbd494a7ea15---------------docker-----------------", "anchor_text": "Docker"}, {"url": "https://medium.com/tag/keras?source=post_page-----cbd494a7ea15---------------keras-----------------", "anchor_text": "Keras"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----cbd494a7ea15---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/jupyter-notebook?source=post_page-----cbd494a7ea15---------------jupyter_notebook-----------------", "anchor_text": "Jupyter Notebook"}, {"url": "https://medium.com/tag/data-science?source=post_page-----cbd494a7ea15---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&user=Mike+Moritz&userId=8de386bbbfff&source=-----cbd494a7ea15---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&user=Mike+Moritz&userId=8de386bbbfff&source=-----cbd494a7ea15---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fcbd494a7ea15&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----cbd494a7ea15---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----cbd494a7ea15--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mike.p.moritz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mike.p.moritz?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mike Moritz"}, {"url": "https://medium.com/@mike.p.moritz/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "117 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8de386bbbfff&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&user=Mike+Moritz&userId=8de386bbbfff&source=post_page-8de386bbbfff--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1718c47cbc7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeras-hyperparameter-optimization-on-aws-cbd494a7ea15&newsletterV3=8de386bbbfff&newsletterV3Id=1718c47cbc7b&user=Mike+Moritz&userId=8de386bbbfff&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}