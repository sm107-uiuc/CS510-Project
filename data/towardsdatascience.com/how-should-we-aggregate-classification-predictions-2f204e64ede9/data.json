{"url": "https://towardsdatascience.com/how-should-we-aggregate-classification-predictions-2f204e64ede9", "time": 1683012972.3753119, "path": "towardsdatascience.com/how-should-we-aggregate-classification-predictions-2f204e64ede9/", "webpage": {"metadata": {"title": "How Should We Aggregate Classification Predictions? | by Tomas Dvorak | Towards Data Science", "h1": "How Should We Aggregate Classification Predictions?", "description": "If you are reading this, then you probably tried to predict who will survive the Titanic shipwreck. This Kaggle competition is a canonical example of machine learning, and a right of passage for any\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/titanic", "anchor_text": "This Kaggle competition", "paragraph_index": 0}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167947312003568", "anchor_text": "Hong (2013)", "paragraph_index": 1}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167947312003568)", "anchor_text": "Hong (2013)", "paragraph_index": 7}, {"url": "https://github.com/tsakim/poibin", "anchor_text": "package for Python", "paragraph_index": 7}, {"url": "https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2014WR016617", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://www.tandfonline.com/doi/abs/10.1080/00949655.2018.1440294", "anchor_text": "Zhang, Hong and Balakrishnan (2018)", "paragraph_index": 9}, {"url": "https://cran.r-project.org/src/contrib/Archive/GPB/", "anchor_text": "GPB", "paragraph_index": 9}, {"url": "http://www-stat.wharton.upenn.edu/~maolson/docs/olson.pdf", "anchor_text": "Olson and Wyner (2018)", "paragraph_index": 15}, {"url": "https://dvorakt.github.io/business_analytics/aggregating-classification-predictions-v2.html", "anchor_text": "here", "paragraph_index": 18}], "all_paragraphs": ["If you are reading this, then you probably tried to predict who will survive the Titanic shipwreck. This Kaggle competition is a canonical example of machine learning, and a right of passage for any aspiring data scientist. What if instead of predicting who will survive, you only had to predict how many will survive? Or, what if you had to predict the average age of survivors, or the sum of the fare that the survivors paid?", "There are many applications where classification predictions need to be aggregated. For example, a customer churn model may generate probabilities that a customer will churn, but the business may be interested in how many customers are predicted to churn, or how much revenue will be lost. Similarly, a model may give a probability that a flight will be delayed, but we may want to know how many flights will be delayed, or how many passengers are affected. Hong (2013) lists a number of other examples from actuarial assessment to warranty claims.", "Most binary classification algorithms estimate probabilities that examples belong to the positive class. If we treat these probabilities as known values (rather than estimates), then the number of positive cases is a random variable with a Poisson Binomial probability distribution. (If the probabilities were all the same, the distribution would be Binomial.) Similarly, the sum of two-value random variables where one value is zero and the other value some other number (e.g. age, revenue) is distributed as a Generalized Poisson Binomial. Under these assumptions we can report mean values as well as prediction intervals. In summary, if we had the true classification probabilities, then we could construct the probability distributions of any aggregate outcome (number of survivors, age, revenue, etc.).", "Of course, the classification probabilities we obtain from machine learning models are just estimates. Therefore, treating the probabilities as known values may not be appropriate. (Essentially, we would be ignoring the sampling error in estimating these probabilities.) However, if we are interested only in the aggregate characteristics of survivors, perhaps we should focus on estimating parameters that describe the probability distributions of these aggregate characteristics. In other words, we should recognize that we have a numerical prediction problem rather than a classification problem.", "I compare two approaches to getting aggregate characteristics of Titanic survivors. The first is to classify and then aggregate. I estimate three popular classification models and then aggregate the resulting probabilities. The second approach is a regression model to estimate how aggregate characteristics of a group of passengers affect the share that survives. I evaluate each approach using many random splits of test and train data. The conclusion is that many classification models do poorly when the classification probabilities are aggregated.", "Let\u2019s use the Titanic data to estimate three different classifiers. The logistic model will use only age and passenger class as predictors; Random Forest and XGBoost will also use sex. I train the model on the 891 passengers in Kaggle\u2019s training data. I evaluate the predictions on the 418 in the test data. (I obtained the labels for the test set to be able to evaluate my models.)", "The logistic model with only age and passenger class as predictors has an AUC of 0.67. Random Forest and XGBoost that also use sex reach a very respectable AUC of around 0.8. Our task, however, is to predict how many passengers will survive. We can estimate this by adding up the probabilities that a passenger will survive. Interestingly, of the three classifiers, the logistic model was the closest to the actual number of survivors despite having the lowest AUC. It is also worth noting that a naive estimate based on the share of survivors in the training data did best of all.", "Given the probabilities of survival for each passenger in the test set, the number of passengers that will survive is a random variable distributed Poisson Binomial. The mean of this random variable is the sum of the individual probabilities. The percentiles of this distribution can be obtained using the `poibin` R package developed by Hong (2013). A similar package for Python is under development. The percentiles can also be obtained through brute force by simulating 10,000 different sets of outcomes for the 418 passengers in the test set. The percentiles can be interpreted as prediction intervals telling us that the actual number of survivors will be within this interval with 95% probability.", "The interval based on the Random Forest probabilities widely missed the actual number of survivors. It is worth noting that the width of the interval is not necessarily based on the accuracy of the individual probabilities. Instead, it depends on how far those individual probabilities are from 0.5. Probabilities close to 0.9 or 0.1 rather than 0.5 mean that there is a lot less uncertainty as to how many passengers will survive. A good discussion of forecast reliability versus sharpness is here.", "While the number of survivors is a sum of zero/one random variables (Bernoulli trials), we may also be interested in predicting other aggregate characteristics of the survivors, e.g. total fare paid by the survivors. This measure is a sum of two-value random variables where one value is zero (passenger did not survive) and the other one is the fare that the passenger paid. Zhang, Hong and Balakrishnan (2018) call the probability distribution of this sum Generalized Poisson Binomial. As with Poisson Binomial, Hong, co-wrote an R package, GPB, that makes computing the probability distributions straightforward. Once again, simulating the distribution is an alternative to using the packages to compute percentiles.", "If we only care about the aggregate characteristics of survivors, then we really have a numerical prediction problem. The simplest estimate of the share of survivors in the test set is the share of survivors in the training set \u2014 it is the naive estimate from the previous section. This estimate is probably unbiased and efficient if the characteristics of passengers in the test and train sets are identical. If not, then we would want an estimate of the share of survivors conditional on the characteristics of the passengers.", "The issue is that we don\u2019t have the data to estimate how aggregate characteristics of a group of passengers affect the share that survived. After all, the Titanic hit the iceberg only once. Perhaps in other applications such as customer churn, we may have new data every month.", "In the Titanic case I resort to simulating many different training data sets by re-sampling the original training data set. I calculate the average characteristics of each simulated data set to estimate of how these characteristics affect the share that will survive. I then take the average characteristics of passengers in the test set and predict how many will survive in the test set. There are many different ways one could summarize the aggregate characteristics. I use the share of passengers in first class, the share of passengers under the age of 10 and the share of female passengers. Not surprisingly, the samples of passengers that have more women, children and first class passengers have a higher share of survivors.", "Applying the above equation to aggregate characteristics of the test data, I predict 162 survivors against the actual of 158 with a prediction interval of 151 to 173. Thus, the regression approach worked quite well.", "So far, we evaluated the two approaches using only one test set. In order to compare the two approaches more systematically, I re-sampled from the union of the original train and test data set to create five hundred new train and test data sets. I then applied the two approaches five hundred times and calculated the mean square error of each approach across these five hundred samples. The graphs below show the relative performance of each approach.", "Among the classification models, the logistic model did best (had the lowest MSE). XGBoost is a relatively close second. Random Forest is way off. The accuracy of aggregate predictions depends crucially on the accuracy of the estimated probabilities. The logistic regression directly estimates the probability of survival. Similarly, XGBoost optimizes a logistic loss function. Therefore, both provide a decent estimate of probabilities. In contrast, Random Forest estimates probabilities as shares of trees that classified the example as success. As pointed out by Olson and Wyner (2018), the share of trees that classified the example as a success has nothing to do with the probability that the example will be a success. (For the same reason, calibration plots for Random Forest tend to be poor.) Although Random Forest can deliver a high AUC, the estimated probabilities are inappropriate for aggregation.", "The aggregate regression model had the lowest MSE of all the approaches, beating even the classification logistic model. The naive predictions are handicapped in this evaluation because the share of survivors in the test data is not independent of the share of survivors in the train data. If we happen to have many survivors in the train, we will naturally have fewer survivors in the test. Even with this handicap, naive predictions handily beat XGBoost and Random Forest.", "If we only need aggregate characteristics, estimating and aggregating individual classification probabilities seems like more trouble than is needed. In many cases, the share of survivors in the train set is a pretty good estimate of the share of survivors in the test set. Customer churn rate this month is probably a pretty good estimate of churn rate next month. More complicated models are worth building if we want to understand what drives survival or churn. It is also worth building more complicated models when our training data has very different characteristics than the test data, and when these characteristics affect survival or churn. Still, even in these cases, it is clear that using methods that are optimized for individual classifications could be inferior to methods optimized for a numerical prediction when a numerical prediction is needed.", "You can find the R code behind this note here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I am a Professor of Economics at Union College in Schenectady, NY. I spent my last sabbatical on the data science team at a local health insurer."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2f204e64ede9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://dvorakt.medium.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": ""}, {"url": "https://dvorakt.medium.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Tomas Dvorak"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F47a548d2efb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&user=Tomas+Dvorak&userId=47a548d2efb1&source=post_page-47a548d2efb1----2f204e64ede9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/c/titanic", "anchor_text": "This Kaggle competition"}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167947312003568", "anchor_text": "Hong (2013)"}, {"url": "https://www.sciencedirect.com/science/article/abs/pii/S0167947312003568)", "anchor_text": "Hong (2013)"}, {"url": "https://github.com/tsakim/poibin", "anchor_text": "package for Python"}, {"url": "https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2014WR016617", "anchor_text": "here"}, {"url": "https://www.tandfonline.com/doi/abs/10.1080/00949655.2018.1440294", "anchor_text": "Zhang, Hong and Balakrishnan (2018)"}, {"url": "https://cran.r-project.org/src/contrib/Archive/GPB/", "anchor_text": "GPB"}, {"url": "http://www-stat.wharton.upenn.edu/~maolson/docs/olson.pdf", "anchor_text": "Olson and Wyner (2018)"}, {"url": "https://dvorakt.github.io/business_analytics/aggregating-classification-predictions-v2.html", "anchor_text": "here"}, {"url": "https://medium.com/tag/aggregation?source=post_page-----2f204e64ede9---------------aggregation-----------------", "anchor_text": "Aggregation"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----2f204e64ede9---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/titanic?source=post_page-----2f204e64ede9---------------titanic-----------------", "anchor_text": "Titanic"}, {"url": "https://medium.com/tag/classification?source=post_page-----2f204e64ede9---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/predictions?source=post_page-----2f204e64ede9---------------predictions-----------------", "anchor_text": "Predictions"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&user=Tomas+Dvorak&userId=47a548d2efb1&source=-----2f204e64ede9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&user=Tomas+Dvorak&userId=47a548d2efb1&source=-----2f204e64ede9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F2f204e64ede9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----2f204e64ede9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----2f204e64ede9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----2f204e64ede9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----2f204e64ede9--------------------------------", "anchor_text": ""}, {"url": "https://dvorakt.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://dvorakt.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tomas Dvorak"}, {"url": "https://dvorakt.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "58 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F47a548d2efb1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&user=Tomas+Dvorak&userId=47a548d2efb1&source=post_page-47a548d2efb1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F47a548d2efb1%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-should-we-aggregate-classification-predictions-2f204e64ede9&user=Tomas+Dvorak&userId=47a548d2efb1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}