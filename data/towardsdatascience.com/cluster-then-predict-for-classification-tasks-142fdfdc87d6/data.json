{"url": "https://towardsdatascience.com/cluster-then-predict-for-classification-tasks-142fdfdc87d6", "time": 1683003788.7290199, "path": "towardsdatascience.com/cluster-then-predict-for-classification-tasks-142fdfdc87d6/", "webpage": {"metadata": {"title": "Cluster-then-predict for classification tasks | by Cole | Towards Data Science", "h1": "Cluster-then-predict for classification tasks", "description": "Supervised classification problems require a dataset with (a) a categorical dependent variable (the \u201ctarget variable\u201d) and (b) a set of independent variables (\u201cfeatures\u201d) which may (or may not!) be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8", "anchor_text": "Logistic Regression", "paragraph_index": 0}, {"url": "https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb", "anchor_text": "How to Determine the Optimal K for K-Means?", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Standard_score", "anchor_text": "z-scores", "paragraph_index": 11}, {"url": "https://medium.com/predict/what-overfitting-is-and-how-to-fix-it-887da4bf2cba", "anchor_text": "overfitting", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/clustering-analyses-with-highly-imbalanced-datasets-27e486cd82a4", "anchor_text": "this article", "paragraph_index": 25}, {"url": "https://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf", "anchor_text": "Data structures for statistical computing in python", "paragraph_index": 27}], "all_paragraphs": ["Supervised classification problems require a dataset with (a) a categorical dependent variable (the \u201ctarget variable\u201d) and (b) a set of independent variables (\u201cfeatures\u201d) which may (or may not!) be useful in predicting the class. The modeling task is to learn a function mapping features and their values to a target class. An example of this is Logistic Regression.", "Unsupervised learning takes a dataset with no labels and attempts to find some latent structure within the data. K-means is one such algorithm. In this article, I will show you how to increase your classifier\u2019s performance by using k-means to discover latent \u201cclusters\u201d in your dataset and either use these clusters as new features in your dataset or to partition your dataset by cluster and train a separate classifier on each.", "We begin by generating a nonce dataset using sklearn\u2019s make_classification utility. We will simulate a multi-class classification problem and generate 15 features for prediction.", "We now have a dataset of 1000 rows with 4 classes and 8 features, 5 of which are informative (the other 3 being random noise). We convert these to a pandas dataframe for easier manipulation.", "We can now divide our data into a train and test set (75/25) split.", "Firstly, you will want to determine what the optimal k is given the dataset.", "For the sake of brevity and so as not to distract from the purpose of this article, I refer the reader to this excellent tutorial: How to Determine the Optimal K for K-Means? should you want to read further on this matter.", "In our case, because we used the make_classification utility, the parameter", "is already set and defaults to 2. Therefore, we do not need to determine the optimal k; however, we do need to identify the clusters! We will use the following function to find the 2 clusters in the training set, then predict them for our test set.", "We now have a new feature called \u201cclusters\u201d with a value of 0 or 1.", "Before we fit any models, we need to scale our features: this ensures all features are on the same numerical scale. With a linear model like logistic regression, the magnitude of the coefficients learned during training will depend on the scale of the features. If you had features that were on the scale of 0\u20131 and other features on the scale of say 0\u2013100, the coefficients could not be reliably compared.", "To scale the features, we use the following function which computes z-scores for each of the features and maps the learnings from the train set to the test set.", "We are now ready to run some experiments!", "I chose to use Logistic Regression for this problem because it is extremely fast and inspection of the coefficients allows one to quickly assess feature importance.", "To run our experiments, we will build a logistic regression model on 4 datasets:", "Out study is a 1x4 between-groups design with dataset [base, cluster-feature, clusters-0, clusters-1] as the only factor. The following creates our datasets.", "To efficiently run our experiments, we\u2019ll use the following function which loops through the 4 datasets and runs 5-fold cross-valdiation on each. For each dataset, we obtain 5 estimates for each classifier\u2019s: accuracy, weighted precision, weighted recall, and weighted f1. We will plot these to observe general performance. We then obtain classification reports from each model on its respective test set to evaluate fine-grained performance.", "Let\u2019s plot our results and see how each dataset affected classifier performance.", "In general, it appears that our \u201cbase\u201d dataset, with no clustering information, creates the worst performing classifier. By adding our binary \u201cclusters\u201d as a feature, we see a modest boost to performance; however, when we fit a model on each cluster, we see the largest boost in performance.", "When we look at classification reports for fine-grained performance evaluation, the picture becomes very clear: when the datasets are segmented by cluster, we see a large boost to performance.", "Consider the class \u201c0\u201d, the f1 scores across the four datasets are", "For the \u201c0\u201d class, the model trained on the cluster-0 dataset shows ~23% relative improvement in f1 score over the other models and datasets.", "In this article, I have shown how you can leverage \u201ccluster-then-predict\u201d for your classification problems and have teased some results suggesting that this technique can boost performance. There is still much more that can be done in terms of cluster creation and evaluation of the results.", "In our case, we had a dataset with 2 clusters; however, in your problems you may have many more clusters to find. (Once you determine the optimal k using the elbow method on your dataset!)", "In the case of k>2, you can treat the \u201cclusters\u201d feature as a categorical variable and apply one-hot encoding to use them in your model. As k increases, you may run into issues of overfitting should you decide to fit a model for each cluster.", "If you find that K-Means is not increasing the performance of your classifier, perhaps your data is better suited for another clustering algorithm \u2014 see this article for an introduction to Hierarchical Clustering on imbalanced datasets.", "As with all data science problems, experiment, experiment, experiment! Run tests for different techniques and let the data guide your modeling decisions.", "Data structures for statistical computing in python, McKinney, Proceedings of the 9th Python in Science Conference, Volume 445, 2010.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F142fdfdc87d6&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://1234567891.medium.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": ""}, {"url": "https://1234567891.medium.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Cole"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d51c08849a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&user=Cole&userId=8d51c08849a5&source=post_page-8d51c08849a5----142fdfdc87d6---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb", "anchor_text": "How to Determine the Optimal K for K-Means?"}, {"url": "https://en.wikipedia.org/wiki/Standard_score", "anchor_text": "z-scores"}, {"url": "https://medium.com/predict/what-overfitting-is-and-how-to-fix-it-887da4bf2cba", "anchor_text": "overfitting"}, {"url": "https://towardsdatascience.com/clustering-analyses-with-highly-imbalanced-datasets-27e486cd82a4", "anchor_text": "this article"}, {"url": "https://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf", "anchor_text": "Data structures for statistical computing in python"}, {"url": "https://doi.org/10.1038/s41586-020-2649-2", "anchor_text": "10.1038/s41586\u2013020\u20132649\u20132"}, {"url": "http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html", "anchor_text": "Scikit-learn: Machine Learning in Python"}, {"url": "https://doi.org/10.1109/MCSE.2007.55", "anchor_text": "J. D. Hunter, \u201cMatplotlib: A 2D Graphics Environment\u201d, Computing in Science & Engineering, vol. 9, no. 3, pp. 90\u201395, 2007"}, {"url": "https://doi.org/10.21105/joss.03021", "anchor_text": "https://doi.org/10.21105/joss.03021"}, {"url": "https://medium.com/tag/k-means?source=post_page-----142fdfdc87d6---------------k_means-----------------", "anchor_text": "K Means"}, {"url": "https://medium.com/tag/clustering?source=post_page-----142fdfdc87d6---------------clustering-----------------", "anchor_text": "Clustering"}, {"url": "https://medium.com/tag/classification?source=post_page-----142fdfdc87d6---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----142fdfdc87d6---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/data-science?source=post_page-----142fdfdc87d6---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&user=Cole&userId=8d51c08849a5&source=-----142fdfdc87d6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&user=Cole&userId=8d51c08849a5&source=-----142fdfdc87d6---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F142fdfdc87d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----142fdfdc87d6---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----142fdfdc87d6--------------------------------", "anchor_text": ""}, {"url": "https://1234567891.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://1234567891.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Cole"}, {"url": "https://1234567891.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "172 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8d51c08849a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&user=Cole&userId=8d51c08849a5&source=post_page-8d51c08849a5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffaca0e106c8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcluster-then-predict-for-classification-tasks-142fdfdc87d6&newsletterV3=8d51c08849a5&newsletterV3Id=faca0e106c8a&user=Cole&userId=8d51c08849a5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}