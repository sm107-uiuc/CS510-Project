{"url": "https://towardsdatascience.com/apply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de", "time": 1683014494.6879702, "path": "towardsdatascience.com/apply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de/", "webpage": {"metadata": {"title": "A Simple Reinforcement Learning Problem | by Mike Thompson | Towards Data Science", "h1": "A Simple Reinforcement Learning Problem", "description": "This article assumes the reader is familiar with basic Reinforcement Learning (RL) concepts. This article provides a great high-level overview. The purpose here is to solve a simple problem in order\u2026"}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292", "anchor_text": "article", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Markov_chain", "anchor_text": "Markov Chain", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Bellman_equation", "anchor_text": "Bellman equation", "paragraph_index": 9}], "all_paragraphs": ["This article assumes the reader is familiar with basic Reinforcement Learning (RL) concepts. This article provides a great high-level overview. The purpose here is to solve a simple problem in order to illustrate how RL problems are set up so you will be able to start coding your own projects.", "The BetYou need to make 90 out of 100 free throws to win a bet. You have unlimited attempts over a one-year period and you need to specify the start of each attempt. How should you decide whether to continue with your current attempt or to start over? How many shots do you expect to take before successfully completing the bet? How does your reset strategy impact this number? Reinforcement Learning can answer these questions.", "It follows from the binomial distribution that a 78% shooter has a 0.14% probability of success for one attempt, which equates to a 40% probability of success over 365 attempts. Let\u2019s assume that 78% is your shooting percentage since this gives a reasonable probability of both winning or losing the bet (above 80% is almost guaranteed success and below 70% is almost guaranteed failure).", "Method 1: Reinforcement Learning \u2014 Markov ChainA stochastic process is a Markov Chain if the probability of transitioning from one state to the next is based entirely on the current state (i.e. previous states do not impact the probability). This bet can be modeled as a Markov Chain with the number of baskets made and the number of baskets missed as the states.", "Absorbing states are states that are not left once entered. Then let matrix \ud835\udc47 be a subset of matrix \ud835\udc43 that only includes transition (non-absorbing) states. \ud835\udc47 = \ud835\udc43\u2080:\u2089\u2089\u2080,\u2080:\u2089\u2089\u2080, since the final ten states represent success, resulting in no additional attempts once one of these states is entered (this is the reason we set the final ten states as the success states, so they can be removed easily).", "Define matrix \ud835\udc36 such that every element \ud835\udc4b\ud835\udc56\ud835\udc57 is the number of expected transitions from state \ud835\udc56 to state \ud835\udc57 at any point in time (even if other states are entered in-between) before entering into one of the absorbing states. It can be shown that Matrix \ud835\udc36 is calculated as:", "Then the sum of row 0 is the expected total number of shots required for success. When shooting until either failure or success, the expected number of shots until success is 35,418. When resetting based on the binomial distribution (reset if the current state has a lower likelihood of success than a new attempt), the total number of shots is reduced to 13,262:", "Method 2a: Reinforcement Learning \u2014 Value Iteration: Determine Optimal PolicyWe were able to calculate the reset policy and number of expected shots directly since we know that the number of shots made is a binomially distributed random variable. However, the underlying distributions of many reinforcement learning problems are unknown, such as predicting customer orders for an inventory management problem or predicting your opponent\u2019s actions in a game of poker. Therefore, we will calculate the optimal reset policy using value iteration to illustrate how to handle unknown distributions.", "First we define the states, actions, and rewards available to the agent in the given environment:", "Then set the initial value of each state/action pair to 0 and iterate over each pair repeatedly to solve for updated value estimates using the Bellman equation until the maximum difference between successive iterations becomes arbitrarily small. V(s)=R(s,a)+\u03b3\u2217V(s\u2032), where:", "Each state has two values, one for continuing to shoot, equal to the expected value of the reward after the shot plus the value of the next state, and each state has a value for resetting the bet, which is simply equal to the value of the starting state (since there will never be a reward when resetting). The value of the state is the highest of these two values. For example, the value at 89 makes, 10 misses (the next shot results in either winning the bet or resetting the bet) is equal to:v[89, 10] = max(action[shoot]: 78% * 100 + 22% * 0.98 * v[0,0], action[reset]: v[0,0]); = max(action[shoot]:78.0047, action[reset]: 0.0217);= action[shoot]: 78.0047.", "Unsurprisingly, the optimal policy at this state is to continue with the current attempt. This also demonstrates how the states are interdependent: v[0,0] depends on v[89, 10], but v[89,10] also depends on v[0, 0], hence why it is necessary to continue iterating through the calculations until the changes in values from one iteration to the next become almost 0.", "From the Markov Chain code, this reset strategy has total expected shots of 13,026, a 1.7% improvement compared to the Binomial Method.", "Method 2b: Simulation \u2014 Calculate Expected Number of Shots", "Since the distribution is not always known, we will also use simulation to calculate the expected number of shots using the optimal policy determined from value iteration.", "We simulate a large number of attempts and take the average number of shots until success to estimate the expected value. To do this, we generate a sufficiently large list of uniform random numbers between 0 and 1, with values below the shooting percentage representing made shots and values above representing missed shots. We then determine whether any reset thresholds were met, representing failure. If no reset thresholds were met, then at least 90 free throws were made and the result was successful. Then calculate the number of shots taken to reach success for each attempt, and take the average of these values.", "The average of 10 iterations of the above code resulted in 13,145 expected shots, which was 0.9% higher than the value directly calculated above.", "Running simulations has the additional benefit that we can estimate the distribution of the number of shots until success:", "We were able to find a closed-form solution to our problem since it is a Markov Chain. However, many reinforcement learning problems are more complex and require an iterative approach. We showed how one such approach, value iteration, could also solve this problem. Policy iteration is another useful approach not covered in this article.", "Thank you for reading and good luck with solving your own reinforcement learning problems!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Masters in Data Science Candidate at University of Chicago and Former Actuary (FSA)"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff555b8adc0de&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mthomp12?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mthomp12?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Mike Thompson"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28ba38616343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&user=Mike+Thompson&userId=28ba38616343&source=post_page-28ba38616343----f555b8adc0de---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://medium.com/u/98505f8c082?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Max Chiswick"}, {"url": "https://unsplash.com/@rapiana?utm_source=medium&utm_medium=referral", "anchor_text": "Ramiro Pianarosa"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292", "anchor_text": "article"}, {"url": "https://en.wikipedia.org/wiki/Markov_chain", "anchor_text": "Markov Chain"}, {"url": "https://en.wikipedia.org/wiki/Bellman_equation", "anchor_text": "Bellman equation"}, {"url": "https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf", "anchor_text": "https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf"}, {"url": "https://www.cis.upenn.edu/~cis519/fall2015/lectures/14_ReinforcementLearning.pdf", "anchor_text": "https://www.cis.upenn.edu/~cis519/fall2015/lectures/14_ReinforcementLearning.pdf"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f555b8adc0de---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----f555b8adc0de---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----f555b8adc0de---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/editors-pick?source=post_page-----f555b8adc0de---------------editors_pick-----------------", "anchor_text": "Editors Pick"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----f555b8adc0de---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&user=Mike+Thompson&userId=28ba38616343&source=-----f555b8adc0de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&user=Mike+Thompson&userId=28ba38616343&source=-----f555b8adc0de---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff555b8adc0de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f555b8adc0de---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f555b8adc0de--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f555b8adc0de--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f555b8adc0de--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mthomp12?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mthomp12?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mike Thompson"}, {"url": "https://medium.com/@mthomp12/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "15 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28ba38616343&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&user=Mike+Thompson&userId=28ba38616343&source=post_page-28ba38616343--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F28ba38616343%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fapply-reinforcement-learning-to-win-a-free-throw-bet-f555b8adc0de&user=Mike+Thompson&userId=28ba38616343&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}