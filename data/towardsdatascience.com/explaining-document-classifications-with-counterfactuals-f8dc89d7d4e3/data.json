{"url": "https://towardsdatascience.com/explaining-document-classifications-with-counterfactuals-f8dc89d7d4e3", "time": 1682995801.6542668, "path": "towardsdatascience.com/explaining-document-classifications-with-counterfactuals-f8dc89d7d4e3/", "webpage": {"metadata": {"title": "Explaining Document Classifications with Counterfactuals | by Anusha Lihala | Towards Data Science", "h1": "Explaining Document Classifications with Counterfactuals", "description": "Test set metrics may not provide a holistic view of the strengths and weaknesses of a model. Explanations for model predictions help humans understand why the predictions have been made and, in some\u2026"}, "outgoing_paragraph_urls": [{"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "C. Molnar, Interpretable machine learning. A Guide for Making Black Box Models Explainable, (2019).", "paragraph_index": 41}], "all_paragraphs": ["Note: Explainability and interpretability are used interchangeably in this article.", "Test set metrics may not provide a holistic view of the strengths and weaknesses of a model. Explanations for model predictions help humans understand why the predictions have been made and, in some cases, to consistently predict the model\u2019s result. This is beneficial as;", "Moreover, explanations of how decisions are made are sometimes legal or regulatory requirements.", "Smaller Decision Trees and Logistic Regression models with few features are considered explainable as the relationship between the inputs and the prediction is easy to understand.", "When these models involve hundreds of features, however, it becomes overwhelming to analyse the impact of a particular feature on predictions or the main factors which lead to a particular decision being made.", "Explanations which are concise and highlight the most important factors are more understandable than explanations which provide a complete list of factors.", "The paper proposes a model-agnostic technique for explaining individual predictions.", "Counterfactuals are contrastive. They explain why a decision was made instead of another. A counterfactual explanation of a prediction may be defined as; [2]", "The smallest change to the feature values that changes the prediction to a predefined output.", "The paper explores how removing certain words from a document can change its predicted class. The proposed method differs from most counterfactual techniques in that it produces a set of words instead of a feature vector representing a different instance.", "The paper primarily focuses on explaining why a document has received (rightly or wrongly) a \u201cpositive\u201d classification.", "In the context of the paper, an explanation is defined as;", "A set of words present in the document such that removing these words causes a change in the predicted class.", "The set of words is minimal. That is, removing any subset of words does not yield a change in class.", "This approach starts by checking if removing a particular word from the document changes the predicted class. If the class does not change for one word only, combinations of 2 different words are considered next. If the removal of any 2 words does not result in a class change either, combinations of 3 different words are considered and so on.", "An explanation for the example below is E = {\u2018computer\u2019}.", "The approach takes advantage of the sparseness of document representations, as the candidate word combinations are all combinations of words in the document, rather than in the whole vocabulary. However, it is still not feasible for large documents as its complexity grows exponentially with the number of unique words in the document.", "Greedy SearchModels usually compute the probability of an instance belonging to a particular class rather than a hard classification, and this can be used as a heuristic to guide the selection of word combinations to be removed next via a greedy search.After checking all one-word explanations and calculating the corresponding changes in the probability of the predicted class, the word which reduces the probability the most is used in subsequent word combinations.More generally;At each step in the search, given the current set of word combinations denoting partial explanations, the algorithm next will expand the partial explanation for which the output score changes the most in the direction of class change. Expanding the partial explanation entails creating a set of new, candidate explanations, comprising all combinations with one additional word from the document that is not yet included in the partial explanation. [1]", "Search-Space PruningWhen the goal is to find multiple explanations, the set of words constituting an explanation E need not be considered when searching for other explanations.", "For non-linear models, it is not possible to estimate the effects of feature interactions on the predicted class probability. This leads to the following issues;", "The paper presents an empirical case study on the problem of classifying web pages as containing objectionable content, with the goal of allowing advertisers to choose not to have their ads appear there.", "A second empirical demonstration on news-story topic classification uses the 20 Newsgroups benchmark dataset.", "It was found that global explanations in the form of a decision tree or a list of the most indicative words did not provide satisfactory solutions.", "A surrogate decision tree model with 327 nodes generated using the C4.5 algorithm had a fidelity of only 87%. Pruning the tree reduced its size but also decreased fidelity.", "In the case of examining word feature weights for linear models, explanation of individual decisions simply required too many individual words; more than two thousand top-weight words (3% of the vocabulary) were needed before even half of the documents were explained.", "This combined with the sparsity of the document-term matrix suggests that words in individual explanations vary tremendously and supports the use of instance-level explanation algorithms.", "This is also demonstrated by the figure below, which plots the percentage of test instance classifications that would be explained by considering the top-k words, weighted according to different methods.", "The line with the maximal area underneath is obtained for words ranked according to how often they occur in explanations.", "Almost all the documents have an explanation comprising fewer than three dozen words, and more than half have an explanation with fewer than two dozen words. In other words, each explanation is very concise,", "The plots also show that document explanation sizes vary quite smoothly and that there seem to be many different explanations for documents. The former observation suggests that the strength of the individual evidence varies widely: some cases are classified by aggregating many weak pieces of evidence, others by a few strong pieces of evidence (and some, presumably by a combination of strong and weak). The latter observation suggests substantial redundancy. [1]", "Explanations can be useful for debugging models, particularly when they are unintuitive. Such explanations are called hyper-explanations.", "The explanation may show that there is no evidence for the positive class; more specifically, that there is no model-relevant evidence. In this case, the model vocabulary may need to be extended.", "It may also be the case that evidence for the negative class outweighs evidence for positive class. Here the explanation techniques may be applied to find explanations for why the example was classified as the negative class, as they would highlight the words that the model feels trump the positive-class-indicative words in the document. This would provide an opportunity to update the model\u2019s weights (via active feature labelling) or review the labels of documents containing these words.", "An example of an explanation for a false negative produced by a classifier classifying stories from the 20 Newsgroups dataset as \u2018comp\u2019 or \u2018not comp\u2019;", "The explanation may show that the words used to classify the example as positive are not really associated with the positive class. Such explanations provide useful support for interactive model development, as background knowledge can be incorporated to counter the misclassification.", "In other cases, the explanations may highlight the ambiguous meanings of some words.", "An example of an explanation for a false positive produced by a classifier classifying stories from the 20 Newsgroups dataset as \u2018comp\u2019 or \u2018not comp\u2019;", "The story actually belonged to the \u2018rec.autos\u2019 newsgroup.", "In cases where words provided by the explanation seem reasonably related to the positive class, the example\u2019s label can be verified.", "The techniques presented in the paper can also be useful in other high-dimensional classification problems, as long as the individual dimensions (and small subsets thereof) are interpretable.", "For example, classifying web users based on the web pages they visit. Each user can be represented by a set of webpage URLs from an extremely large set. Users can then be classified by models over this vocabulary.", "[2] C. Molnar, Interpretable machine learning. A Guide for Making Black Box Models Explainable, (2019).", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Interested in ML, NLP and EdTech"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Ff8dc89d7d4e3&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@anusha.lihala?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@anusha.lihala?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Anusha Lihala"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7bcddd3cfcf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&user=Anusha+Lihala&userId=7bcddd3cfcf0&source=post_page-7bcddd3cfcf0----f8dc89d7d4e3---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/BVyNlchWqzs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Amador Loureiro"}, {"url": "https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://christophm.github.io/interpretable-ml-book/", "anchor_text": "C. Molnar, Interpretable machine learning. A Guide for Making Black Box Models Explainable, (2019)."}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----f8dc89d7d4e3---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nlp?source=post_page-----f8dc89d7d4e3---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/counterfactuals?source=post_page-----f8dc89d7d4e3---------------counterfactuals-----------------", "anchor_text": "Counterfactuals"}, {"url": "https://medium.com/tag/explainable-ai?source=post_page-----f8dc89d7d4e3---------------explainable_ai-----------------", "anchor_text": "Explainable Ai"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&user=Anusha+Lihala&userId=7bcddd3cfcf0&source=-----f8dc89d7d4e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&user=Anusha+Lihala&userId=7bcddd3cfcf0&source=-----f8dc89d7d4e3---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Ff8dc89d7d4e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----f8dc89d7d4e3---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----f8dc89d7d4e3--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@anusha.lihala?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@anusha.lihala?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Anusha Lihala"}, {"url": "https://medium.com/@anusha.lihala/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "121 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7bcddd3cfcf0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&user=Anusha+Lihala&userId=7bcddd3cfcf0&source=post_page-7bcddd3cfcf0--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F97021e914421&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fexplaining-document-classifications-with-counterfactuals-f8dc89d7d4e3&newsletterV3=7bcddd3cfcf0&newsletterV3Id=97021e914421&user=Anusha+Lihala&userId=7bcddd3cfcf0&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}