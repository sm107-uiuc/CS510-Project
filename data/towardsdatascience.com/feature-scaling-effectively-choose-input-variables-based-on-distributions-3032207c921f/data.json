{"url": "https://towardsdatascience.com/feature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f", "time": 1683011790.204917, "path": "towardsdatascience.com/feature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f/", "webpage": {"metadata": {"title": "Feature Scaling \u2014 Effectively Choose Input Variables Based on Distributions | by Sushmitha Pulagam | Towards Data Science", "h1": "Feature Scaling \u2014 Effectively Choose Input Variables Based on Distributions", "description": "We often come across a situation dealing with a variety of numerical variables consisting of different ranges, units, and magnitudes while building an ML model. As a common practice, we will apply\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/SushmithaPulagam/FeatureScaling-with-Distributions", "anchor_text": "here", "paragraph_index": 5}, {"url": "https://github.com/SushmithaPulagam/FeatureScaling-with-Distributions", "anchor_text": "profile", "paragraph_index": 30}], "all_paragraphs": ["We often come across a situation dealing with a variety of numerical variables consisting of different ranges, units, and magnitudes while building an ML model. As a common practice, we will apply Standardization or Normalization techniques for all the features before building a model. However, it is crucial to study the distributions of the data before making a decision on which technique to apply for feature scaling.", "In this article, we will go through the difference between Standardization and Normalization along with understanding the distributions of the data. In the end, we will see how to select the strategies based on Gaussian and Non-Gaussian distribution of the features to improve the performance of the Logistic Regression model.", "Both these techniques are sometimes used interchangeably but they refer to different approaches.", "Standardization: This technique transforms the data to have a mean of zero and a standard deviation to 1.", "Normalization: This technique transforms the values in variables between 0 and 1.", "We are using the Pima Indian Diabetes dataset and you can find the same [here]", "From the above, we can see that the numerical variables are varying in different ranges and the Outcome is the target variable. We will perform both the scaling techniques and apply Logistic Regression.", "\ud83d\udc49 Applying Standardization to all features and modeling.", "From the sklearn library, we need to use StandardScaler to implement Standardization.", "Let us do the train and test the split for the standardized features.", "Now we are going to apply Logistic Regression on the standardized dataset.", "From the above, we can see that the accuracy of the model with all the features applying Standardization technique is 72 percent.", "\ud83d\udc49 Applying Normalization to all features and modeling.", "From the sklearn library, we need to use MinMaxScaler to implement Normalization.", "Let us do the train and test the split for the normalized features.", "Applying Logistic Regression on the normalized dataset.", "The accuracy of the model when all the features are normalized is 74 percent.", "\ud83d\udc49 Understanding the distribution of features", "Let us plot the histograms of the variables to study the distribution.", "Gaussian Distribution \u2014 BMI, BloodPressure, Glucose.", "Finally, we came to an experiment waiting to select the variables and apply both the strategies based on the distributions on the same dataset.", "To apply this strategy, we are going to use Column Transformer and Pipeline concepts from sklearn as we need to do the mixed type of techniques by subsetting the columns.", "As mentioned above, we are initiating different pipelines for Gaussian and Non-Gaussian features", "Now, let us build the Logistic Regression model on the data with selective features for Standardization and Normalization.", "Below is the accuracy details for the different models we have built so far.", "Accuracy after standardizing all the features: 0.72", "Accuracy after normalizing all the features: 0.74", "Accuracy after applying Standardization to Gaussian distribution features and Normalization to Non- Gaussian distribution features: 0.79", "We need to perform Feature Scaling when we are dealing with Gradient Descent Based algorithms (Linear and Logistic Regression, Neural Network) and Distance-based algorithms (KNN, K-means, SVM) as these are very sensitive to the range of the data points. This step is not mandatory when dealing with Tree-based algorithms.", "The main focus of this article is to explain how the distribution of the data plays an important role in feature scaling and how to select the strategies based on Gaussian and Non-Gaussian distribution to improve the overall accuracy of the model.", "You can get the complete code from my GitHub [profile]", "Thank you for reading and Happy Learning! \ud83d\ude42", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Business Analytics | Data Science | Machine Learning. Wish to share my learnings towards Analytics community."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3032207c921f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3032207c921f--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@sushmithapulagam?source=post_page-----3032207c921f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sushmithapulagam?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Sushmitha Pulagam"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F311a5d2c608f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&user=Sushmitha+Pulagam&userId=311a5d2c608f&source=post_page-311a5d2c608f----3032207c921f---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/SushmithaPulagam/FeatureScaling-with-Distributions", "anchor_text": "here"}, {"url": "https://github.com/SushmithaPulagam/FeatureScaling-with-Distributions", "anchor_text": "profile"}, {"url": "https://medium.com/tag/data-science?source=post_page-----3032207c921f---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----3032207c921f---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----3032207c921f---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/statistics?source=post_page-----3032207c921f---------------statistics-----------------", "anchor_text": "Statistics"}, {"url": "https://medium.com/tag/normal-distribution?source=post_page-----3032207c921f---------------normal_distribution-----------------", "anchor_text": "Normal Distribution"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&user=Sushmitha+Pulagam&userId=311a5d2c608f&source=-----3032207c921f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&user=Sushmitha+Pulagam&userId=311a5d2c608f&source=-----3032207c921f---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3032207c921f--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3032207c921f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3032207c921f---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3032207c921f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3032207c921f--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3032207c921f--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3032207c921f--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3032207c921f--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sushmithapulagam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@sushmithapulagam?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sushmitha Pulagam"}, {"url": "https://medium.com/@sushmithapulagam/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "228 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F311a5d2c608f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&user=Sushmitha+Pulagam&userId=311a5d2c608f&source=post_page-311a5d2c608f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fab3691ac057f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-scaling-effectively-choose-input-variables-based-on-distributions-3032207c921f&newsletterV3=311a5d2c608f&newsletterV3Id=ab3691ac057f&user=Sushmitha+Pulagam&userId=311a5d2c608f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}