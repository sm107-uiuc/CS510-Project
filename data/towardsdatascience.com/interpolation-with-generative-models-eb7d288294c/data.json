{"url": "https://towardsdatascience.com/interpolation-with-generative-models-eb7d288294c", "time": 1682994704.285037, "path": "towardsdatascience.com/interpolation-with-generative-models-eb7d288294c/", "webpage": {"metadata": {"title": "Interpolation with Deep Generative Models | by Zichen Wang | Towards Data Science", "h1": "Interpolation with Deep Generative Models", "description": "In this post I am going to write about generative models. It\u2019s gonna cover the dichotomy between generative and discriminative models, and how generative models can really learn the essence of\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1312.6114", "anchor_text": "Kingma & Welling, 2014", "paragraph_index": 9}, {"url": "https://arxiv.org/abs/1406.2661", "anchor_text": "Goodfellow et al., 2014", "paragraph_index": 10}, {"url": "https://medium.com/@jonathan_hui/gan-a-comprehensive-review-into-the-gangsters-of-gans-part-1-95ff52455672", "anchor_text": "the list keeps growing", "paragraph_index": 10}, {"url": "https://blog.openai.com/glow/", "anchor_text": "manipulate images of human faces", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Imagination", "anchor_text": "imagination is the process of producing mental images", "paragraph_index": 12}], "all_paragraphs": ["In this post I am going to write about generative models. It\u2019s gonna cover the dichotomy between generative and discriminative models, and how generative models can really learn the essence of objects of interest by being able to perform interpolations.", "To be honest, I merely started to contemplate about the nature of statistical and Machine Learning models after the Generative Adversarial Nets (GANs) took off. In the original version of GAN, let\u2019s term it vanilla GAN, you have a generative network (G) that is generating synthetic data from Gaussian noise and a discriminative network (D) that is trying to distinguish the fake from the real. Obviously, G and D in the vanilla GAN are generative and discriminative model, respectively. In fact, GAN is perhaps the first ML algorithm that harmonizes generative and discriminative models, which learns the parameters of both models through the innovative adversarial training.", "So much for my own experience, what are generative and discriminative models? Intuitively, generative models are trying to abstract the some generalizable patterns of some collection of objects whereas discriminative models attempt to find the differences between collections. Concretely, in the context of a classification problem, for instance, generative models would learn the characteristics of each classes whereas discriminative models would find the decision boundaries that best separate the classes. More formally, let\u2019s represent an instance as a feature vector x labeled by some scalar value y,generative models learn the joint probability distribution p(x, y), whereas discriminative models learn conditional probability distribution p(y|x).", "There are also some interesting generator-discriminator pairs to think about:", "It\u2019s also worth mentioning that most traditional ML classifiers are discriminative models, including Logistic Regression, SVM, Decision Trees, Random Forest, LDA. Discriminative models are parsimonious in terms of the parameters to be learned, and has been demonstrated to have superior performance over their generative counterpart in many classification tasks.", "But I\u2019d like to argue that learning to tell one class from another is not really learning, as it usually can\u2019t work when situated into another context. For example, a discriminative classifier trained to distinguish cats and birds with exceptional accuracy may fail miserably when an unseen class, dog, is added to the test set, as the discriminative classifier may simple learn that something with four legs are cats and otherwise birds.", "To further illustrate what Generative and Discriminative models really learn, let\u2019s consider the simplest classification models from each, Naive Bayes and Logistic Regression. The following figure visualize the learned \u201cknowledge\u201d by Naive Bayes and Logistic Regression classifiers on a binary classification problem.", "Naive Bayes classifier learns the mean and variance vectors for the two classes whereas Logistic Regression learns the slope and intercept of a linear boundary that optimally separate the two classes. With the means and variances learned from the Naive Bayes classifier, we can generate synthetic samples for each class by sampling from the multivariate Gaussian distribution. This is similar to generating synthetic samples using GANs, but obviously Naive Bayes won\u2019t be able to generate any high quality high dimensional images because it is too naive to model the features dependently.", "I briefly touched on Naive Bayes algorithm, arguably the simplest form of generative model. Modern generative models usually involves deep neural network architectures, hence termed deep generative models. There are three types of deep generative models:", "VAE was introduced by Kingma & Welling, 2014, as an probabilistic extension of the autoencoder (AE). It has the following three additional features over vanilla AE:", "GAN was introduced by Goodfellow et al., 2014 and is composed of a pair of Generator and Discriminator networks playing a minimax game against each other. Many variants of GANs have been developed, such as Bidirectional GAN (BiGAN), CycleGAN, InfoGAN, Wasserstein GAN and the list keeps growing.", "BiGAN is particularly attractive in that it explicitly learns an Encoder network, E(x) to map the input back to the latent space:", "With some knowledge of the some of the deep generative models, we\u2019ll examine their capabilities. Generative models are able to learn lower dimensional probability distribution for samples from different classes. Such probability distribution can be used for supervised learning and for generating synthetic samples. While these capabilities are tremendously useful, I am more impressed by generative models\u2019 ability to perform interpolations for real samples along any arbitrary axis to generate non-existent manipulated samples. For example, deep generative models can manipulate images of human faces along axes like age, gender, hair color and etc. In my opinion, this suggests that deep generative models are able to obtain the ability to imagine, as imagination is the process of producing mental images. Next let\u2019s delve into how to perform the interpolation.", "The interpolation works by performing simple linear algebra in the latent space (z) learned by the generative model. First, we want to find an axis in the latent space to interpolate along with, which can be something like biological sex. The interpolation vector for biological sex can then be simply computed as the vector pointing from the centroid of males to the centroid of females in the latent space.", "More generically, we first need to find the centroids of two classes (a, b) in the latent space:", "The interpolation vector in the latent space pointing from class b to class a is:", "Given any unseen sample of any class x_c, we can manipulate the unseen sample with the interpolation vector by: 1) encode the sample into the latent space; 2) perform linear interpolation in the latent space; and 3) decode the interpolated sample back to the original space:", "\u03b1 in the above equation is a scalar determining the magnitude and direction of the interpolation. Next, I will play with around the \u03b1 to slide along different interpolation vectors. The following Python function can make a trained generative model perform such interpolation:", "I trained some generative models, including Naive Bayes, VAE and BiGAN, on the MNIST handwritten digit dataset to experiment with interpolation. Below is a figure visualizing the latent space of a VAE with only two neurons at the bottleneck layer. Although there is some distinctive patterns for the different digits, the reconstruction quality is pretty bad. Perhaps it is challenging to compress 784-dimensional space to 2-d space. I found VAE with 20 neurons at the bottleneck layer can reconstruct the MNIST data with decent quality.", "It is also worth pointing out the generative models are trained unsupervisedly. Therefore, the learned latent space has no knowledge of the class labels. The interpolation vectors are calculated after models have finished learning.", "To play with the interpolation, I first visualized the interpolation vectors between all the 45 possible pairs of the 10 digits:", "In the figure above, each row corresponds to a interpolation vector pointing from one digit to another whereas each column corresponds to an alpha value. It is intriguing to look at the digits generated from the latent space from left to right to see how one number gradually change to another. From this we can also find the ambiguous digits that lie between two centroids of our 10 digits.", "Next, I did another interesting experiment with the interpolation: I asked whether we can turn a digit 7 to a digit 6 or 0 by moving it along the 6->0 vector. Here are the results of the generated images. It shows some relatively 0 looking images to the right while the left ones do not look like 6 at all.", "These images can also be quantified using a Logistic Regression classifier trained on MNIST to predict the probabilities of the labels. And the classifier pretty much agrees with our perception from eyeballing the images.", "The seemingly boring proof-of-concept experiments with MNIST dataset demonstrated deep generative models\u2019 ability to imagine. I can envision many practical applications with the interpolation.", "This post is based on my GitHub repo if you want to get more technical details:", "Notebook version of this post presented at Ma\u2019ayan lab meeting:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Scientist @AWS. Passionate about Machine Learning, Healthcare and Biology."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Feb7d288294c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://wangz10.medium.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Zichen Wang"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcefe6819be80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&user=Zichen+Wang&userId=cefe6819be80&source=post_page-cefe6819be80----eb7d288294c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.slideshare.net/ckmarkohchang/generative-adversarial-networks", "anchor_text": "https://www.slideshare.net/ckmarkohchang/generative-adversarial-networks"}, {"url": "https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html", "anchor_text": "an excellent blog for this type of models"}, {"url": "https://arxiv.org/abs/1312.6114", "anchor_text": "Kingma & Welling, 2014"}, {"url": "https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence", "anchor_text": "Kullback-Leibler divergence"}, {"url": "https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html", "anchor_text": "https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html"}, {"url": "https://arxiv.org/abs/1406.2661", "anchor_text": "Goodfellow et al., 2014"}, {"url": "https://medium.com/@jonathan_hui/gan-a-comprehensive-review-into-the-gangsters-of-gans-part-1-95ff52455672", "anchor_text": "the list keeps growing"}, {"url": "https://arxiv.org/abs/1605.09782", "anchor_text": "Donahue et al, 2016 Adversarial Feature Learning"}, {"url": "https://blog.openai.com/glow/", "anchor_text": "manipulate images of human faces"}, {"url": "https://en.wikipedia.org/wiki/Imagination", "anchor_text": "imagination is the process of producing mental images"}, {"url": "https://github.com/wangz10/Generative-Models", "anchor_text": "wangz10/Generative-ModelsTutorial on deep generative models with experiments on MNIST - wangz10/Generative-Modelsgithub.com"}, {"url": "https://nbviewer.jupyter.org/github/wangz10/Generative-Models/blob/master/Main.ipynb", "anchor_text": "Jupyter Notebook ViewerCheck out this Jupyter notebook!nbviewer.jupyter.org"}, {"url": "https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf", "anchor_text": "Ng AY & Jordan MI: On Discriminative vs. Generative classifiers"}, {"url": "https://arxiv.org/abs/1312.6114", "anchor_text": "Kingma & Welling: Auto-Encoding Variational Bayes"}, {"url": "https://arxiv.org/abs/1406.2661", "anchor_text": "Goodfellow IJ et al: Generative Adversarial Networks"}, {"url": "https://arxiv.org/abs/1605.09782", "anchor_text": "Donahue et al: Adversarial Feature Learning"}, {"url": "https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html", "anchor_text": "Flow-based Deep Generative Models"}, {"url": "https://blog.openai.com/glow/", "anchor_text": "Glow: Better Reversible Generative Models"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----eb7d288294c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ai?source=post_page-----eb7d288294c---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/autoencoder?source=post_page-----eb7d288294c---------------autoencoder-----------------", "anchor_text": "Autoencoder"}, {"url": "https://medium.com/tag/data-science?source=post_page-----eb7d288294c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----eb7d288294c---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&user=Zichen+Wang&userId=cefe6819be80&source=-----eb7d288294c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&user=Zichen+Wang&userId=cefe6819be80&source=-----eb7d288294c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Feb7d288294c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----eb7d288294c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----eb7d288294c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----eb7d288294c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----eb7d288294c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----eb7d288294c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----eb7d288294c--------------------------------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://wangz10.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Zichen Wang"}, {"url": "https://wangz10.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "537 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcefe6819be80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&user=Zichen+Wang&userId=cefe6819be80&source=post_page-cefe6819be80--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F6eb2de67e9a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finterpolation-with-generative-models-eb7d288294c&newsletterV3=cefe6819be80&newsletterV3Id=6eb2de67e9a8&user=Zichen+Wang&userId=cefe6819be80&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}