{"url": "https://towardsdatascience.com/why-deep-learning-uses-gpus-c61b399e93a0", "time": 1683011616.3453498, "path": "towardsdatascience.com/why-deep-learning-uses-gpus-c61b399e93a0/", "webpage": {"metadata": {"title": "Why Deep Learning Uses GPUs?. And why you should too\u2026 | by German Sharabok | Towards Data Science", "h1": "Why Deep Learning Uses GPUs?", "description": "There is a lot of information out there about GPUs for Deep Learning. You have probably heard that this field requires some huge computers and incredible power. Maybe you have seen people train their\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["There is a lot of information out there about GPUs for Deep Learning. You have probably heard that this field requires some huge computers and incredible power. Maybe you have seen people train their models for days or even weeks just figure out there was a bug in their code. Additionally, we hear about GPUs mostly when talking about gaming and sometimes graphical design. This article will help you understand what is actually going on here and why Nvidia is a huge innovator in Deep Learning.", "A GPU is a processor that is great at handling specialized computations. We can contrast this to the Central Processing Unit(CPU), which is great at handling general computations. CPUs power most of the computations performed on the devices we use daily.", "GPU can be faster at completing tasks than CPU. However, it is not true for every case. The performance hugely depends on the type of computation being performed. GPUs are great at tasks that can be run in parallel.", "Parallel computing is a type of computing architecture in which several processors simultaneously execute multiple, smaller calculations broken down from an overall larger, complex problem.", "If we have multiple cores in our processing unit we can split our tasks into multiple smaller tasks and run them at the same time. This will make use of the processing power we have available and complete our tasks much faster.", "CPUs generally have four, eight, or sixteen, while GPUs could have thousands! From here we can conclude that GPU is best suitable for tasks that can be completed simultaneously. Since parallel computing deals with such tasks, we can see why a GPU would be used in that case.", "We have concluded that GPUs are best used when a huge task can be broken down into many smaller ones, which is the reason GPUs are used in parallel computing. If we take a look into neural networks, we can notice that they are embarrassingly parallel. It means that we do not even need to slit the tasks and decide which part goes to which core. The neural networks are specifically made for running in parallel. Since they are the base for deep learning, we can conclude that GPUs are perfect for this task.", "Additionally, neural networks are parallel in such a way that they do not have to depend on each other's results. Everything could run simultaneously without having to wait for other cores. An example of such computation that is hugely independent is convolution.", "Here is an example of how convolution without numbers could look like. We have an input channel on the left and the output on the right. In the animation, the process of computation is happening sequentially, which is not the case in real life. Actually, all of the operations could be happening at the same time and neither one of them depends on the results of any other computation.", "As a result of this, the computations can happen in parallel on a GPU and the result can be produced. From the example, we can see that parallel computing and GPUs can seriously accelerate the convolution operation. In comparison, running the same convolution on a CPU will lead to sequential execution, similar to the one in the animation. This process will take a lot more time.", "This is where we can learn about CUDA. Nvidia is a company that produces GPUs and they have created CUDA, which is a software that nicely connects to the hardware they produce. This software allows developers to easily utilize the power of parallel computing with the Nvidia GPUs.", "To put it simply, GPU is the hardware and CUDA is the software. As you might have guessed an Nvidia GPU is required to use CUDA, and CUDA can be downloaded from Nvidia\u2019s website entirely free.", "CUDA allows us to selectively run computations on either the GPU or the CPU. Why not use GPU for everything if it is so much better?", "The answer is that GPUs are better only for specific types of tasks. For example, if our data is on the CPU, moving it to the GPU can be costly. So in the case when the task is rather simple, it will be more costly to use the GPU. We can conclude that the GPU will perform better only when tasks are sufficiently large and can be broken down into smaller tasks. For small processes, it will only make things slower.", "For that reason, it is often acceptable to use the CPU when just getting started, since the initial tasks will be short and simple.", "When the GPU was first created, it was mostly aimed at dealing with computer graphics, which is where the name comes from. Now, more and more tasks are moved to GPUs and Nvidia is a pioneer in that space. CUDA was created nearly 10 years ago and only now developers are starting to make use of it.", "Deep learning and other types of parallel computing have led to the development of a new field, called GPGPU or general-purpose GPU computing.", "The GTC talk by Nvidia is a must-see for everyone in the field of deep learning. When we hear about the GPU computing stack, we should think of GPU as the hardware on the bottom, CUDA software architecture in the middle, and libraries like cuDNN on top.", "GPUs play a huge role in the current development of deep learning and parallel computing. With all of that development, Nvidia as a company is certainly a pioneer and leader in the field. It provides both the hardware and software for creators.", "It is certainly alright to get started creating neural networks with just a CPU. However, modern GPUs can speed up the task and make the learning process much more enjoyable.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc61b399e93a0&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@gsharabok?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gsharabok?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "German Sharabok"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc37991cc441&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&user=German+Sharabok&userId=cc37991cc441&source=post_page-cc37991cc441----c61b399e93a0---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@lime517?utm_source=medium&utm_medium=referral", "anchor_text": "Joseph Greve"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://youtu.be/f0t-OCG79-U", "anchor_text": "https://youtu.be/f0t-OCG79-U"}, {"url": "https://youtu.be/FPM3nmlaN00", "anchor_text": "https://youtu.be/zeSIXD6y3WQ"}, {"url": "https://www.omnisci.com/technical-glossary/parallel-computing", "anchor_text": "https://www.omnisci.com/technical-glossary/parallel-computing"}, {"url": "https://medium.com/tag/gpu?source=post_page-----c61b399e93a0---------------gpu-----------------", "anchor_text": "Gpu"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c61b399e93a0---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c61b399e93a0---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/nvidia?source=post_page-----c61b399e93a0---------------nvidia-----------------", "anchor_text": "Nvidia"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&user=German+Sharabok&userId=cc37991cc441&source=-----c61b399e93a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&user=German+Sharabok&userId=cc37991cc441&source=-----c61b399e93a0---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fc61b399e93a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----c61b399e93a0---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c61b399e93a0--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c61b399e93a0--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c61b399e93a0--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gsharabok?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gsharabok?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "German Sharabok"}, {"url": "https://medium.com/@gsharabok/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "144 Followers"}, {"url": "https://www.linkedin.com/in/gsharabok/", "anchor_text": "https://www.linkedin.com/in/gsharabok/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc37991cc441&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&user=German+Sharabok&userId=cc37991cc441&source=post_page-cc37991cc441--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F422117da785f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-deep-learning-uses-gpus-c61b399e93a0&newsletterV3=cc37991cc441&newsletterV3Id=422117da785f&user=German+Sharabok&userId=cc37991cc441&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}