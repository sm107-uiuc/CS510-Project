{"url": "https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21", "time": 1682995389.608484, "path": "towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21/", "webpage": {"metadata": {"title": "Checklist for debugging neural networks | by Cecelia Shao | Towards Data Science", "h1": "Checklist for debugging neural networks", "description": "Machine learning code can be notoriously difficult to debug with bugs that are expensive to chase. Even for simple, feedforward neural networks, you often have to make several decisions around\u2026"}, "outgoing_paragraph_urls": [{"url": "https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/feedforward.html", "anchor_text": "feedforward neural networks", "paragraph_index": 0}, {"url": "https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765", "anchor_text": "How to unit test machine learning code", "paragraph_index": 1}, {"url": "https://hackernoon.com/choosing-the-right-machine-learning-algorithm-68126944ce1f", "anchor_text": "\u2018Choosing the Right Machine Learning Algorithm\u2019", "paragraph_index": 4}, {"url": "http://cs231n.github.io/neural-networks-3/#baby", "anchor_text": "Stanford CS231n coursework", "paragraph_index": 10}, {"url": "https://cs231n.github.io/neural-networks-3/#summary", "anchor_text": "should be 1-e3", "paragraph_index": 15}, {"url": "http://cs231n.github.io/neural-networks-3/#gradcheck", "anchor_text": "here", "paragraph_index": 17}, {"url": "http://cs231n.github.io/optimization-1/#gradcompute", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://www.youtube.com/watch?v=P6EtCVrvYPU", "anchor_text": "specific lesson", "paragraph_index": 17}, {"url": "https://www.linkedin.com/in/faizankshaikh/", "anchor_text": "Faizan Shaikh", "paragraph_index": 18}, {"url": "https://conx.readthedocs.io/en/latest/Getting%20Started%20with%20conx.html#What-is-ConX?", "anchor_text": "ConX", "paragraph_index": 19}, {"url": "https://www.tensorflow.org/guide/tensorboard_histograms", "anchor_text": "Tensorboard", "paragraph_index": 19}, {"url": "https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59", "anchor_text": "\u2018Visualizing parts of Convolutional Neural Networks using Keras and Cats\u2019", "paragraph_index": 20}, {"url": "https://towardsdatascience.com/@theshank", "anchor_text": "Dishank Bansal", "paragraph_index": 24}, {"url": "https://towardsdatascience.com/pitfalls-of-batch-norm-in-tensorflow-and-sanity-checks-for-training-networks-e86c207548c8", "anchor_text": "Pitfalls of Batch Norm in TensorFlow and Sanity Checks for Training Networks", "paragraph_index": 24}, {"url": "https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout", "anchor_text": "From Stackoverflow user", "paragraph_index": 27}, {"url": "https://arxiv.org/abs/1801.05134", "anchor_text": "From arXiv", "paragraph_index": 28}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Li%2C+X", "anchor_text": "Xiang Li", "paragraph_index": 28}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+S", "anchor_text": "Shuo Chen", "paragraph_index": 28}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+X", "anchor_text": "Xiaolin Hu", "paragraph_index": 28}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+J", "anchor_text": "Jian Yang", "paragraph_index": 28}, {"url": "http://bit.ly/2J6dxWA", "anchor_text": "Comet.ml", "paragraph_index": 30}], "all_paragraphs": ["Machine learning code can be notoriously difficult to debug with bugs that are expensive to chase. Even for simple, feedforward neural networks, you often have to make several decisions around network architecture , weight initialization, and network optimization \u2014 all of which can lead to insidious bugs in your machine learning code.", "As Chase Roberts wrote in an excellent piece on \u2018How to unit test machine learning code\u2019, his frustrations stemmed from common traps like:", "So what is to be done about it?", "This article will provide a framework to help you debug your neural networks:", "Feel free to skip to a particular section or read through below! Please note: we do not cover data preprocessing or specific model algorithm selection. There are plenty of great resources for those topics online (for example, check out \u2018Choosing the Right Machine Learning Algorithm\u2019).", "A neural network that has a complex architecture with regularization and a learning rate scheduler will be harder to debug than a simple network. We\u2019re kind of cheating with this first point since it\u2019s not really related to debugging a network you\u2019ve already built, but it\u2019s still an important recommendation!", "To start off, build a small network with a single hidden layer and verify that everything is working correctly. Then gradually add model complexity while checking that each aspect of your model\u2019s structure (additional layer, parameter, etc..) works before moving on.", "As a quick sanity check, you can use one or two training data points to confirm whether your model is able to overfit. The neural network should immediately overfit with a training accuracy of 100% and a validation accuracy that\u2019s commensurate to your model randomly guessing. If your model is unable to overfit just those data points, then either it\u2019s too small or there is a bug.", "Even when you\u2019ve verified that your model is working, try train for a single (or a few) epochs before progressing.", "Your model\u2019s loss is the primary way to evaluate your model\u2019s performance and it\u2019s what the model is evaluating to set important parameters, so you want to make sure that:", "It\u2019s also important to pay attention to your initial loss. Check to see if that initial loss is close to your expected loss if your model started by guessing randomly. In the Stanford CS231n coursework, Andrej Karpathy suggests the following:", "Look for correct loss at chance performance. Make sure you\u2019re getting the loss you expect when you initialize with small parameters. It\u2019s best to first check the data loss alone (so set regularization strength to zero). For example, for CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.302, because we expect a diffuse probability of 0.1 for each class (since there are 10 classes), and Softmax loss is the negative log probability of the correct class so: -ln(0.1) = 2.302.", "For a binary example, you would simply do a similar calculation for each of your classes. Let\u2019s say your data is 20% 0's and 80% 1's. Your expected initial loss would work out to \u22120.2ln(0.5)\u22120.8ln(0.5) = 0.693147. If your initial loss is much bigger than 1, it could indicate that your neural network weights are not balanced properly (i.e. your initialization was poor) or your data is not normalized.", "To debug a neural network, it can often be useful to understand the dynamics inside a neural network and the role played by the individual intermediate layers and how the layers are connected. You may be running into errors around:", "If your gradient values are zero, it could mean that the learning rate might be too small in the optimizer or that you\u2019re encountering Error #1 above with incorrect expressions for the gradient updates.", "Aside from looking at the absolute values of the gradient updates, make sure to monitor the magnitudes of activations, weights, and updates of each layer match. For example, the magnitude of the updates to the parameters (weights and biases) should be 1-e3.", "There is a phenomenon called the \u2018Dying ReLU\u2019 or \u2018vanishing gradient problem\u2019 where the ReLU neurons will output a zero after learning a large negative bias term for its weights. Those neurons will never activate on any datapoint again.", "You can use gradient checking to check for these errors by approximating the gradient using a numerical approach. If it is close to the calculated gradients, then backpropagation was implemented correctly. To implement gradient checking, check out these great resources from CS231 here and here and Andrew Ng\u2019s specific lesson on the topic.", "Faizan Shaikh writes about the three primary methods of visualizing your neural network:", "There are many useful tools for visualizing individual layers\u2019 activations and connections such as ConX and Tensorboard.", "Working with image data? Erik Rippel has a great, colorful post on \u2018Visualizing parts of Convolutional Neural Networks using Keras and Cats\u2019", "Neural networks have large numbers of parameters that interact with each other, making optimization hard. Please note, this is an area of active research so the suggestions below are simply starting points.", "[It] has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions \u2014 and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation.", "Machine learning frameworks such as Keras, Tensorflow, PyTorch, MXNet now all have documentation or examples around using learning rate schedulers/decay:", "This article from Dishank Bansal \u2018Pitfalls of Batch Norm in TensorFlow and Sanity Checks for Training Networks\u2019 is a great resource for common errors with batch normalization.", "It is often the case that a loss function is a sum of the data loss and the regularization loss (e.g. L2 penalty on weights). One danger to be aware of is that the regularization loss may overwhelm the data loss, in which case the gradients will be primarily coming from the regularization term (which usually has a much simpler gradient expression). This can mask an incorrect implementation of the data loss gradient.", "To audit this, you should turn off regularization and check your data loss gradient independently.", "From Stackoverflow user MiloMinderBinder : \u201cDropout is meant to block information from certain neurons completely to make sure the neurons do not co-adapt. So, the batch normalization has to be after dropout otherwise you are passing information through normalization statistics.\u201d", "From arXiv: Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift (Xiang Li, Shuo Chen, Xiaolin Hu, Jian Yang) \u2014 \u201cTheoretically, we find that Dropout would shift the variance of a specific neural unit when we transfer the state of that network from train to test. However, BN would maintain its statistical variance, which is accumulated from the entire learning procedure, in the test phase. The inconsistency of that variance (we name this scheme as \u201cvariance shift\u201d) causes the unstable numerical behavior in inference that leads to more erroneous predictions finally, when applying Dropout before BN.\u201d", "It\u2019s easy to overlook the importance of documenting your experiments until you forget which learning rate or class weights you used. With better tracking, you can easily review and reproduce previous experiments to reduce duplicating work (aka running into the same errors).", "However, manually documenting information can be difficult to do and scale for multiple experiments. Tools like Comet.ml can help automatically track datasets, code changes, experimentation history and production models (this includes key pieces of information about your model like hyperparameters, model performance metrics, and environment details).", "Your neural network can be very sensitive to slight changes in both data, parameters, and even package versions \u2014 leading to drops in model performance that can build up. Tracking your work is the first step you can take to begin standardizing your environment and modeling workflow.", "We hope this post serves a solid starting point for debugging your neural network. To summarize the highlights, you should:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fd8b2a9434f21&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ceceliashao?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Cecelia Shao"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F370d0382c596&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&user=Cecelia+Shao&userId=370d0382c596&source=post_page-370d0382c596----d8b2a9434f21---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/photos/RLw-UC03Gwc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Glenn Carstens-Peters"}, {"url": "https://unsplash.com/search/photos/list?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/feedforward.html", "anchor_text": "feedforward neural networks"}, {"url": "https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765", "anchor_text": "How to unit test machine learning code"}, {"url": "https://hackernoon.com/choosing-the-right-machine-learning-algorithm-68126944ce1f", "anchor_text": "\u2018Choosing the Right Machine Learning Algorithm\u2019"}, {"url": "https://blog.algorithmia.com/introduction-to-loss-functions/", "anchor_text": "loss functions"}, {"url": "https://arxiv.org/pdf/1603.08155.pdf", "anchor_text": "feature loss"}, {"url": "http://cs231n.github.io/neural-networks-3/#baby", "anchor_text": "Stanford CS231n coursework"}, {"url": "https://cs231n.github.io/neural-networks-3/#summary", "anchor_text": "should be 1-e3"}, {"url": "http://cs231n.github.io/neural-networks-3/#gradcheck", "anchor_text": "here"}, {"url": "http://cs231n.github.io/optimization-1/#gradcompute", "anchor_text": "here"}, {"url": "https://www.youtube.com/watch?v=P6EtCVrvYPU", "anchor_text": "specific lesson"}, {"url": "https://www.linkedin.com/in/faizankshaikh/", "anchor_text": "Faizan Shaikh"}, {"url": "https://conx.readthedocs.io/en/latest/Getting%20Started%20with%20conx.html#What-is-ConX?", "anchor_text": "ConX"}, {"url": "https://www.tensorflow.org/guide/tensorboard_histograms", "anchor_text": "Tensorboard"}, {"url": "https://conx.readthedocs.io/en/latest/README.html", "anchor_text": "ConX"}, {"url": "https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59", "anchor_text": "\u2018Visualizing parts of Convolutional Neural Networks using Keras and Cats\u2019"}, {"url": "https://arxiv.org/abs/1609.04836", "anchor_text": "\u2018On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima\u2019"}, {"url": "http://cs231n.github.io/neural-networks-3/", "anchor_text": "different techniques to implement annealing learning rates"}, {"url": "https://keras.io/callbacks/#learningratescheduler", "anchor_text": "https://keras.io/callbacks/#learningratescheduler"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay", "anchor_text": "https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay"}, {"url": "https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html", "anchor_text": "https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html"}, {"url": "https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/learning_rate_schedules.html", "anchor_text": "https://mxnet.incubator.apache.org/versions/master/tutorials/gluon/learning_rate_schedules.html"}, {"url": "https://towardsdatascience.com/@theshank", "anchor_text": "Dishank Bansal"}, {"url": "https://towardsdatascience.com/pitfalls-of-batch-norm-in-tensorflow-and-sanity-checks-for-training-networks-e86c207548c8", "anchor_text": "Pitfalls of Batch Norm in TensorFlow and Sanity Checks for Training Networks"}, {"url": "http://ruder.io/optimizing-gradient-descent/", "anchor_text": "\u2018An overview of gradient descent optimization algorithms\u2019"}, {"url": "https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/", "anchor_text": "SGD > Adam"}, {"url": "http://cs231n.github.io/neural-networks-3/#ratio", "anchor_text": "the CS231n course"}, {"url": "https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout", "anchor_text": "From Stackoverflow user"}, {"url": "https://arxiv.org/abs/1801.05134", "anchor_text": "From arXiv"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Li%2C+X", "anchor_text": "Xiang Li"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+S", "anchor_text": "Shuo Chen"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Hu%2C+X", "anchor_text": "Xiaolin Hu"}, {"url": "https://arxiv.org/search/cs?searchtype=author&query=Yang%2C+J", "anchor_text": "Jian Yang"}, {"url": "http://bit.ly/2J6dxWA", "anchor_text": "Comet.ml"}, {"url": "http://bit.ly/2J6dxWA", "anchor_text": "Comet.ml"}, {"url": "https://www.youtube.com/watch?v=xaybRkapeNE&t=5s", "anchor_text": "here"}, {"url": "https://news.ycombinator.com/item?id=19392173", "anchor_text": "Follow the discussion on HackerNews"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----d8b2a9434f21---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----d8b2a9434f21---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/data-science?source=post_page-----d8b2a9434f21---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----d8b2a9434f21---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----d8b2a9434f21---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&user=Cecelia+Shao&userId=370d0382c596&source=-----d8b2a9434f21---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&user=Cecelia+Shao&userId=370d0382c596&source=-----d8b2a9434f21---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fd8b2a9434f21&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----d8b2a9434f21---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----d8b2a9434f21--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ceceliashao?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Cecelia Shao"}, {"url": "https://medium.com/@ceceliashao/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.3K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F370d0382c596&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&user=Cecelia+Shao&userId=370d0382c596&source=post_page-370d0382c596--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F667173e72180&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecklist-for-debugging-neural-networks-d8b2a9434f21&newsletterV3=370d0382c596&newsletterV3Id=667173e72180&user=Cecelia+Shao&userId=370d0382c596&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}