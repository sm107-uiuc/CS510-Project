{"url": "https://towardsdatascience.com/ai-enabled-conversations-with-analytics-tables-66a10c9a3d05", "time": 1683015900.6540868, "path": "towardsdatascience.com/ai-enabled-conversations-with-analytics-tables-66a10c9a3d05/", "webpage": {"metadata": {"title": "Table QA| Table Question answering| | Towards Data Science", "h1": "AI-enabled conversations with Analytics tables", "description": "This article will cover the fundamentals of Tabular Question answering, challenges, datasets, AI progress in transforming natural language database queries to SQL code starting from rule-based systems to the modern state of the art deep learning-based approaches."}, "outgoing_paragraph_urls": [{"url": "https://www.linkedin.com/in/gowtham1/", "anchor_text": "Gowtham R", "paragraph_index": 0}, {"url": "http://sundeepteki.org", "anchor_text": "Sundeep Teki", "paragraph_index": 0}, {"url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html?highlight=sequence%20sequence", "anchor_text": "seq2seq", "paragraph_index": 8}, {"url": "https://github.com/jkkummerfeld/text2sql-data/blob/master/tools/canonicaliser.py", "anchor_text": "canonicalize SQL queries", "paragraph_index": 14}, {"url": "https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html#sec-bert", "anchor_text": "pretraining", "paragraph_index": 25}, {"url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html", "anchor_text": "encoder-decoder [21]", "paragraph_index": 26}, {"url": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "anchor_text": "RNN", "paragraph_index": 26}, {"url": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "anchor_text": "", "paragraph_index": 26}, {"url": "https://d2l.ai/chapter_recurrent-modern/lstm.html", "anchor_text": "LSTM", "paragraph_index": 26}, {"url": "https://d2l.ai/chapter_attention-mechanisms/transformer.html", "anchor_text": "transformer", "paragraph_index": 26}, {"url": "https://www.educative.io/courses/natural-language-processing-ml/N0Wr9zwpEmv", "anchor_text": "output vocabulary", "paragraph_index": 27}, {"url": "https://towardsdatascience.com/understanding-pointer-networks-81fbbc1ddbc8", "anchor_text": "pointer networks", "paragraph_index": 28}, {"url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html?highlight=sequence%20sequence", "anchor_text": "sequence to sequence", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Semantic_role_labeling", "anchor_text": "slot-filling", "paragraph_index": 29}, {"url": "https://d2l.ai/chapter_attention-mechanisms/index.html", "anchor_text": "attention-based", "paragraph_index": 30}, {"url": "https://ruslanspivak.com/lsbasi-part7/", "anchor_text": "AST", "paragraph_index": 30}, {"url": "https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html#sec-bert", "anchor_text": "BERT", "paragraph_index": 30}, {"url": "https://www.conceptnet.io/", "anchor_text": "knowledge base", "paragraph_index": 32}, {"url": "https://d2l.ai/chapter_attention-mechanisms/transformer.html#multi-head-attention", "anchor_text": "self-attention", "paragraph_index": 36}], "all_paragraphs": ["Written by Gowtham R and Sundeep Teki on November 1, 2020", "In recent years, the amount of data powering different industries, and their systems has been increasing exponentially. Majority of business information is stored in the form of relational databases that store, process, and retrieve data. Databases power information systems across multiple industries, for instance, consumer tech (e.g. orders, cancellations, refunds), supply chain (e.g. raw materials, stocks, vendors), healthcare (e.g. medical records), finance (e.g. financial business metrics), customer support, search engines, and much more.", "It is imperative for modern data-driven companies to track the real-time state of its business in order to quickly understand and diagnose any emerging issues, trends, or anomalies in the data and take immediate corrective actions. This work is usually performed manually by business analysts who compose complex queries in declarative query languages like SQL to derive business insights stored in multiple tables. These results are typically processed in the form of charts or graphs to enable leadership teams to quickly visualize the results and facilitate data-driven decision making.", "Although the most common SQL queries that address fundamental business metrics are predefined and incorporated in commercial products like PowerBi that power insights into business metrics, any new or follow-up business queries still need to be manually coded by the analysts. Such static interactions between database queries and consumption of the corresponding results require time-consuming manual intervention and result in slow feedback cycles. It is vastly more efficient to have non-technical business leaders directly interact with the analytics tables via natural language queries that abstract away the underlying SQL code.", "Defining the SQL query requires a strong understanding of database schema, SQL syntax and can quickly get overwhelming for beginners and non-technical stakeholders. Efforts to bridge this communication gap have led to the development of a new type of processing called Natural Language Interface to Database (NLIDB). This natural search capability has become more popular over recent years as companies such as Microsoft [1][2], Salesforce [3][4], and others are developing similar technologies for Natural language (NL) to SQL (NL2SQL). The converted SQL could also enable virtual assistants like Alexa, Google Home, and others to improve their responses when the answer can be found in different databases or tables. This blog will review the challenges, evaluation methods, datasets, different approaches, and some state-of-the-art deep learning approaches for NL2SQL.", "The system must understand both the user\u2019s question and the table schemas (columns, table names, and values) to map the query to SQL correctly. A key challenge here is understanding the structured schema of DB tables (e.g., the name, data type, and stored values of columns) and the alignment between the input query and the schema. For instance, for the question, Which country has the largest GDP?, the model needs to map GDP to the Gross Domestic Product Column. Sometimes the question might also require understanding the semantics of a column rather than just column names.", "For the table and question shown in Figure 3, the Venue column used to answer the example question refers to host cities. Hence, the model needs to align \u201ccity\u201d in the query with the venue column in the table.", "Collecting large training data for different domains is expensive and non-scalable. Hence, it is important to train systems to generalize to different domains and databases. This generalization would involve identifying new entities, mapping unseen phrases and entities correctly in the SQL query, and handling novel database and query structures (larger tables, the composition of SQL components, etc.)[5].", "One of the standard ways to solve the NL2SQL tasks is to use seq2seq (since both NL query and SQL are sequences) models and their variants. One of the issues with this approach is that different SQL queries may be equivalent to each other due to commutative and associative properties.", "In the above example, we see that even if the WHERE conditions are swapped, it would yield the same results, but syntactically both the queries are different. If we have the former as the ground truth, and the seq2seq model predicts the latter, it would be penalized.", "There are several datasets for NL2SQL tasks. These contain annotated NL questions, SQL pairs corresponding to one or more tables. These datasets differ in terms of domains (single vs. cross-domain), size (number of queries \u2014 which is essential for proper model evaluation), and query complexity (single table vs. multi-table).", "The early datasets like ATIS, GeoQuery focus on single domains and are also limited in terms of the number of queries. Some of the latest datasets like WikiSQL, Spider are cross-domain, and context-independent with a larger size. One significant difference between WikiSQL and Spider is query complexity. Queries in WikiSQL are simpler (which only covers SELECT and WHERE clauses). Also, each database in WikiSQL is only a simple table without any foreign key. Spider contains a modest number of queries and includes complex questions that involve joins of tables and nested queries. The SParC[15] and CoSQL[16] are the extensions of the Spider dataset that are created for contextual cross-domain semantic parsing and conversational dialog text-to-SQL system.", "The most common methods to evaluate NL2SQL systems are execution accuracy and logical form accuracy.", "Execution accuracy compares the result after execution of the predicted SQL query with the result of the ground truth query. One downside of this method is that it is possible to have an unrelated SQL query that does not correspond to the question but still gives the right answer (for example, NULL result).", "Logical form accuracy compares the exact string match of predicted SQL query with the ground truth query. This metric has the limitation of incorrectly penalizing predictions that yield correct results upon execution but do not have an exact string match with a ground truth SQL query. One approach to solving the ordering issue is to canonicalize SQL queries before comparison [17]. SQL canonicalization is a method to make evaluations consistent by ordering columns in SELECT, tables in FROM, and WHERE constraints and standardizing table aliases, capitalization, and space between symbols.", "Authors of Spider [19] use component matching, which measures the average exact match between the prediction and ground truth on different SQL components like SELECT, WHERE, GROUP BY, etc. The prediction and ground truth is parsed and decomposed into subcomponents and then their exact match is calculated component-wise.", "For example, to evaluate the SELECT component:", "And then this set is compared with the ground truth sets.", "Even though this takes care of the ordering issue, it still does not account for when the prediction uses a different logic (compared to ground truth SQL) to arrive at the same result. Hence for a thorough evaluation, execution accuracy should also be used.", "The authors in [19] also categorize query by hardness based on the number of SQL components, selections, and conditions. This categorization can be very helpful for getting more insights about model performance with respect to query complexity.", "Most existing approaches focus on a rule-based parser for natural language combined with ambiguity detection. Some rule-based systems use trigger words to identify patterns in the user\u2019s question. For example, \u201cby\u201d is a common word used in aggregation queries like \u201cList the movies directed by <director>\u201d. Here, the trigger word\u2019s left side might have the keywords required for the SELECT clause, and the right side would have the necessary keywords for the GROUP BY clause.", "Despite its simplicity, this approach (if rules are well-formed) has been shown to handle a surprisingly broad type of queries. Modern conversational agents such as Siri and Cortana follow a similar principle, although the rules are not deterministic and based on training (logistic regression classifier of intent).", "In Grammar-based systems, the user\u2019s question is parsed, and the resulting parsed tree is directly mapped to expression in SQL. A grammar is created which can describe the possible syntactic structures of the user\u2019s questions.", "The over-simplistic grammar shown in the figure considers the user\u2019s question(S) to be composed of Noun Phrase and a Verb Phrase; Noun phrases consist of a Determiner followed by Noun, Determiner consists of the word \u201cWhat\u201d or \u201cWhich\u201d etc.", "This grammar can then be used to parse a question like \u201cWhich rock contains magnesium?\u201d into a parse tree and then map the resulting parse tree to SQL. This mapping back to SQL would be carried out by rules and based entirely on the parse tree\u2019s syntactic information.", "Rule-based approaches are limited in terms of coverage, scalability, and naturalness. They are also not robust to natural language diversity and are very difficult to scale across domains. The advent of large scale supervised datasets like WikiSQL, Spider, etc., and advances in Natural language processing, pretraining [20], etc. has enabled Deep learning models to achieve the state of the art results in NL2SQL tasks.", "Almost all the deep learning models generate the SQL query from natural language input with an encoder-decoder [21] model. The encoder could be RNN [22] / LSTM [24] or the recent transformer [25] networks. Most of the models differ in how they encode the schema (table names, column names, cell values, etc.) and how they produce the SQL output.", "Some models make schema as part of their output vocabulary. In other words, they put all the table names, column names, etc., into their output vocabulary, and while decoding the SQL output, they select these words from the vocabulary. NSP[10], DBPAL[18] are some of the methods which use this approach. One major limitation of this approach is we cannot adapt them to cross-domains as they do not encode new schemas in their input.", "In contrast, other methods like SEQ2SQL[3] use the schema as input to the model and while decoding, use the table or column names mentioned in the input using pointer networks [26]. For instance, in SEQ2SQL[3], the authors use column names, question tokens, and SQL tokens like SELECT, WHERE, COUNT, MIN, MAX, etc. as input. Their pointer network produces the SQL query by selecting exclusively from this augmented input sequence. The authors also claim that apart from limiting the output space, this augmented pointer network produces higher quality WHERE clauses.", "Based on the generation of SQL queries from natural language input, there exist three types of models: sequence to sequence, sequence to tree, and slot-filling[23]. The sequence to sequence models generates the SQL as a sequence of words. The sequence to tree models generates a syntax tree of the predicted SQL query. The slot-filling methods treat the SQL query as a set of slots and then decode the whole question using relevant decoders for each slot. An advantage of grammar-based decoders is that they can check for grammatical errors at every step, producing complex queries with joins, nested queries, etc. without any syntax errors.", "Modern Deep Learning approaches use more techniques to learn joint representations over NL questions and structured information present in tables. They use various attention-based architectures for question/schema encoding and AST based structure architecture (sequence to tree) for query decoding. IRNet [1], RAT-SQL (current SOTA approach in spider) [2] use BERT [21] (for NL representation) along with in-house strategies to encode structured information in tables. In contrast, TaBERT[27] uses a general-purpose pretraining approach to learn representations of natural language sentences and tabular data. These techniques include schema linking, better schema encoding, using DB content (Cell values instead of just column and table names), contextualizing questions and schema representations.", "This involves aligning the entity references in the question to the right schema columns or tables. Textual matches are the best evidence for question-schema alignment, and it might be directly beneficial to the encoder. Linking is generally done with string matching in IRNet and RAT-SQL. N-grams (up to lengths of 5 or 6) in the question are used to match (both exact matches and partial matches are considered) column or table names in the schema. After linking, IRNet tags each entity mentioned in the question with the type of the corresponding entity (table name/column name, etc.) while encoding. The column names are also assigned types EXACT MATCH and PARTIAL MATCH based on n-gram overlap with question words. RAT-SQL, on the other hand, constructs a graph with question words and the column/table names as the nodes and edges being QUESTION-COLUMN-M, QUESTION-TABLE-M, etc., where M is either one of EXACTMATCH, PARTIALMATCH, or NOMATCH.", "The natural language question can also have value mentions (like \u20184\u2019 in \u2018For cars with 4 cylinders, which model has the largest horsepower\u2019), which would be present as a cell value in some table. IRNet looks up the value mention from the question in a knowledge base and searches the results returned over the column names for partial or exact matches. The column names are assigned types VALUE EXACT MATCH and VALUE PARTIAL MATCH based on the match. RAT-SQL, on the other hand, adds an edge COLUMN-VALUE between question word and a column name if the question word occurs as a value in the column.", "TaBERT uses the DB content directly instead of linking and using the column name. The authors reason that contents provide more detail about a column\u2019s semantics than just the column\u2019s name, which might be ambiguous. They select a content snapshot consisting of only a few rows that are most relevant based on string matching (n-gram overlap) to the NL question.", "This involves encoding the relational structure in databases. It is much more challenging in databases with multi-table relations (where encoding primary, foreign keys, etc. are essential). IRNet encodes both the columns and tables to get column and row representations. The columns are represented by column name and their type, which is defined from schema linking. The final representations are created by adding the column name embeddings, context embeddings (based on n-grams matched in the question), and type embeddings.", "RAT-SQL represents the schema as a directed graph with columns and tables as nodes. The edges are defined by database relations detailed in the above diagram.", "This helps in learning effective joint representations. RAT-SQL augments their schema graph by adding edges between question words and schema entities defined after schema linking. They introduce a relation-aware self-attention [25] layer to use the relational structure in the input and also learn \u201csoft\u201d relations between the sequence elements. They do this by providing a way to communicate known relations (like primary key, foreign keys, etc. defined in edge labels) by adding their representations to the attention.", "In this blog, we reviewed the state-of-the-art in NL2SQL \u2014 the problem statement, challenges, evaluation of such systems, and the modern machine learning techniques for solving the task. Recent work also focuses on improving the user experience while using such systems. Photon [4] is a flexible system that supports both NL questions and SQL as input. It also has a confusion detection module that detects unanswerable questions and helps users paraphrase a question to get the right answers. Authors in [28] also show that incorporating human feedback can further improve the accuracy and user experience of these systems (see figure 19).", "Although modern NL2SQL techniques achieve good accuracy on benchmark test sets, they are still far from demonstrating robust performance in production settings. In the context of business decision making, it is critical to achieving reliable performance to foster and build users\u2019 trust in such systems. NL2SQL methods have the potential to significantly enhance the efficiency of human analysts so they can focus more time on contextual interpretation and validation of results. The output of modern end-to-end deep learning systems suffer from a lack of interpretability, and while there is significant research on how AI systems work under the hood, incorporating humans-in-the-loop to provide feedback and improve the predictive power will accelerate the adoption and use of NL2SQL systems across the modern data-driven organizations.", "[3] Zhong, Victor, Caiming Xiong, and Richard Socher. \u201cSeq2sql: Generating structured queries from natural language using reinforcement learning.\u201d (2017) arXiv preprint arXiv:1709.00103", "[5] Suhr, Alane, et al. \u201cExploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing.\u201d (2020) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.", "[6] Dahl, Deborah A., et al. \u201cExpanding the scope of the ATIS task: The ATIS-3 corpus.\u201d(1994) HUMAN LANGUAGE TECHNOLOGY: Proceedings of a Workshop held at Plainsboro, New Jersey, March 8\u201311, 1994.", "[7] Tang, Lappoon R., and Raymond J. Mooney. \u201cUsing multiple clause constructors in inductive logic programming for semantic parsing.\u201d(2001) European Conference on Machine Learning. Springer, Berlin, Heidelberg, 2001.", "[8] Tang, Lappoon R., and Raymond Mooney. \u201cAutomated construction of database interfaces: Integrating statistical and relational learning for semantic parsing.\u201d (2000) Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.", "[9] Li, Fei, and H. V. Jagadish. \u201cConstructing an interactive natural language interface for relational databases.\u201d (2014) Proceedings of the VLDB Endowment 8.1: 73\u201384.", "[11] Yaghmazadeh, Navid, et al. \u201cSQLizer: query synthesis from natural language.\u201d (2017) Proceedings of the ACM on Programming Languages 1.OOPSLA: 1\u201326.", "[12] Zhong, Victor, Caiming Xiong, and Richard Socher. \u201cSeq2sql: Generating structured queries from natural language using reinforcement learning.\u201d (2017) arXiv preprint arXiv:1709.00103", "[18] Basik, Fuat, et al. \u201cDbpal: A learned nl-interface for databases.\u201d (2018) Proceedings of the 2018 International Conference on Management of Data", "[21] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \u201cSequence to sequence learning with neural networks.\u201d (2014) Advances in neural information processing systems.", "[22] Williams, Ronald J.; Hinton, Geoffrey E.; Rumelhart, David E. \u201cLearning representations by back-propagating errors\u201d. (October 1986) Nature.", "[25] Vaswani, Ashish, et al. \u201cAttention is all you need.\u201d (2017) Advances in neural information processing systems.", "[26] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \u201cPointer networks.\u201d (2015) Advances in neural information processing systems.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Incoming CS PhD student at University of Wisconsin-Madison | Former Researcher at AI4Bharat, IIT madras | Interested in knowledge-intensive NLP, multilinguality"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F66a10c9a3d05&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@gowtham.ramesh1?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gowtham.ramesh1?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Gowtham Ramesh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85a948100fcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&user=Gowtham+Ramesh&userId=85a948100fcc&source=post_page-85a948100fcc----66a10c9a3d05---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/making-sense-of-big-data", "anchor_text": "Making Sense of Big Data"}, {"url": "https://www.linkedin.com/in/gowtham1/", "anchor_text": "Gowtham R"}, {"url": "http://sundeepteki.org", "anchor_text": "Sundeep Teki"}, {"url": "https://unsplash.com/@casparrubin", "anchor_text": "Caspar Camille Rubin"}, {"url": "https://unsplash.com/photos/fPkvU7RDmCo", "anchor_text": "Unsplash"}, {"url": "https://arxiv.org/pdf/1711.04436.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1906.11790.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/2005.08314.pdf", "anchor_text": "source"}, {"url": "https://www.aclweb.org/anthology/2020.acl-main.742.pdf", "anchor_text": "source"}, {"url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html?highlight=sequence%20sequence", "anchor_text": "seq2seq"}, {"url": "https://arxiv.org/pdf/1711.04436.pdf", "anchor_text": "source"}, {"url": "https://www.researchgate.net/publication/343021594_Recent_Advances_in_SQL_Query_Generation_A_Survey", "anchor_text": "source"}, {"url": "https://github.com/jkkummerfeld/text2sql-data/blob/master/tools/canonicaliser.py", "anchor_text": "canonicalize SQL queries"}, {"url": "https://arxiv.org/pdf/1809.08887.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1906.08990.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/cmp-lg/9503016.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/cmp-lg/9503016.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/cmp-lg/9503016.pdf", "anchor_text": "source"}, {"url": "https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html#sec-bert", "anchor_text": "pretraining"}, {"url": "https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html", "anchor_text": "encoder-decoder [21]"}, {"url": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "anchor_text": "RNN"}, {"url": "https://d2l.ai/chapter_recurrent-neural-networks/index.html", "anchor_text": ""}, {"url": "https://d2l.ai/chapter_recurrent-modern/lstm.html", "anchor_text": "LSTM"}, {"url": "https://d2l.ai/chapter_attention-mechanisms/transformer.html", "anchor_text": "transformer"}, {"url": "https://www.educative.io/courses/natural-language-processing-ml/N0Wr9zwpEmv", "anchor_text": "output vocabulary"}, {"url": "https://arxiv.org/pdf/1709.00103.pdf", "anchor_text": "source"}, {"url": "https://towardsdatascience.com/understanding-pointer-networks-81fbbc1ddbc8", "anchor_text": "pointer networks"}, {"url": "https://www.researchgate.net/publication/318488414_End-to-End_Information_Extraction_without_Token-Level_Supervision", "anchor_text": "source"}, {"url": "https://d2l.ai/chapter_recurrent-modern/seq2seq.html?highlight=sequence%20sequence", "anchor_text": "sequence to sequence"}, {"url": "https://en.wikipedia.org/wiki/Semantic_role_labeling", "anchor_text": "slot-filling"}, {"url": "https://d2l.ai/chapter_attention-mechanisms/index.html", "anchor_text": "attention-based"}, {"url": "https://ruslanspivak.com/lsbasi-part7/", "anchor_text": "AST"}, {"url": "https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html#sec-bert", "anchor_text": "BERT"}, {"url": "https://arxiv.org/pdf/1911.04942.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1905.08205.pdf", "anchor_text": "source"}, {"url": "https://www.conceptnet.io/", "anchor_text": "knowledge base"}, {"url": "https://arxiv.org/pdf/1906.11790.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/1906.11790.pdf", "anchor_text": "source"}, {"url": "https://d2l.ai/chapter_attention-mechanisms/transformer.html#multi-head-attention", "anchor_text": "self-attention"}, {"url": "https://arxiv.org/pdf/1906.11790.pdf", "anchor_text": "source"}, {"url": "https://arxiv.org/pdf/2005.02539.pdf", "anchor_text": "source"}, {"url": "http://dmkd.cs.vt.edu/papers/WWW20.pdf", "anchor_text": "source"}, {"url": "https://medium.com/tag/nlp?source=post_page-----66a10c9a3d05---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----66a10c9a3d05---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----66a10c9a3d05---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/making-sense-of-big-data?source=post_page-----66a10c9a3d05---------------making_sense_of_big_data-----------------", "anchor_text": "Making Sense Of Big Data"}, {"url": "https://medium.com/tag/sql?source=post_page-----66a10c9a3d05---------------sql-----------------", "anchor_text": "Sql"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&user=Gowtham+Ramesh&userId=85a948100fcc&source=-----66a10c9a3d05---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&user=Gowtham+Ramesh&userId=85a948100fcc&source=-----66a10c9a3d05---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F66a10c9a3d05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----66a10c9a3d05---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----66a10c9a3d05--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gowtham.ramesh1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@gowtham.ramesh1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gowtham Ramesh"}, {"url": "https://medium.com/@gowtham.ramesh1/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "22 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85a948100fcc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&user=Gowtham+Ramesh&userId=85a948100fcc&source=post_page-85a948100fcc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2F85a948100fcc%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-enabled-conversations-with-analytics-tables-66a10c9a3d05&user=Gowtham+Ramesh&userId=85a948100fcc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}