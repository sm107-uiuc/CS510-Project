{"url": "https://towardsdatascience.com/self-supervised-learning-methods-for-computer-vision-c25ec10a91bd", "time": 1683017757.840661, "path": "towardsdatascience.com/self-supervised-learning-methods-for-computer-vision-c25ec10a91bd/", "webpage": {"metadata": {"title": "Self-Supervised Learning Methods for Computer Vision | by Nilesh Vijayrania | Towards Data Science", "h1": "Self-Supervised Learning Methods for Computer Vision", "description": "Self-supervised Learning is an unsupervised learning method where the supervised learning task is created out of the unlabelled input data. Some examples are MoCo, SimCLR, BYOL etc."}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1807.03748", "anchor_text": "Representation learning with contrastive predictive coding", "paragraph_index": 8}, {"url": "https://arxiv.org/abs/2002.05709", "anchor_text": "original paper", "paragraph_index": 26}], "all_paragraphs": ["Self-supervised Learning is an unsupervised learning method where the supervised learning task is created out of the unlabelled input data.", "This task could be as simple as given the upper-half of the image, predict the lower-half of the same image, or given the grayscale version of the colored image, predict the RGB channels of the same image, etc.", "Supervised learning requires usually a lot of labelled data. Getting good quality labelled data is an expensive and time-consuming task specially for a complex task such as object detection, instance segmentation where more detailed annotations are desired. On the other hand, the unlabelled data is readily available in abundance. The motivation behind Self-supervised learning is to learn useful representations of the data from unlabelled pool of data using self-supervision first and then fine-tune the representations with few labels for the supervised downstream task. The downstream task could be as simple as image classification or complex task such as semantic segmentation, object detection, etc.", "Lately, in natural language processing, Transformer models have achieved a lot of success. Transformers like Bert[1], T5[2], etc. applied the idea of self-supervision to NLP tasks. They first train the model with large unlabelled data and then fine-tuning the model with few labelled data examples. Similar self-supervised learning methods have been researched for computer vision as well and in this post, I will try to cover a few of those.", "The fundamental idea for self-supervised learning is to create some auxiliary pre-text task for the model from the input data itself such that while solving the auxiliary task, the model learns the underlying structure of the data(for instance the structure of the object in case of image data). Many self-supervised learning methods have been researched but contrastive learning methods seem to be work better than others for computer vision, hence in this post, I would concentrate on contrastive learning-based self-supervised learning methods", "suppose we have a function f(represented by any deep network Resnet50 for example), given an input x, it gives us the features f(x) as output.", "Contrastive Learning states that for any positive pairs x1 and x2, the respective outputs f(x1) and f(x2) should be similar to each other and for a negative input x3, f(x1) and f(x2) both should be dissimilar to f(x3).", "The positive pair could be two crops of same image(lets say top-left and bottom right), two frames of same video file, two augmented views(horizontally flipped version for instance) of same image, etc. and respective negatives could be a crop from different image, frame from different video, augmented view of different image, etc.", "The idea of contrastive learning was first introduced in this paper \u201cRepresentation learning with contrastive predictive coding\u201d[3] by Aaron van den Oord et al. from DeepMind. The formulated contrastive learning task gave a strong basis for learning useful representations of the image data which is described next.", "The central idea of CPC is to first divide the whole image into a coarse grid and given the upper few rows of the image, the task is to predict the lower rows of the same image. The motivation is, to accomplish this task, the model has to learn the structure of the object in the image(for example seeing the face of a dog, the model should predict that it would have 4 legs) and this would give us a useful representations for downstream tasks.", "The whole auxiliary task could be summarized in 3 steps.", "The below image depicts the task pictorially.", "To train this model effectively, a loss function is required to enforce the similarity between positive pairs(correct patch prediction) and negative pairs(incorrect patch). For calculating the loss, the set X of N patches is used where X is the set of N-1 negative samples and 1 positive sample(correct path). The N-1 negatives are sampled randomly from all available patches of the same image(expect the correct patch) and different images in the batch. This loss is termed as InfoNCE loss where NCE stands for Noise Contrastive and it is shown below.", "Here q is the network prediction, k+ is the positive patch(correct patch) and k- represents a set of N-1 negative patches. Note that k+, k- and q, all are in representation space i.e. output of g_enc and not into original image space.", "In simple terms, the formula is equivalent to the log_softmax function. To calculate the similarity, the dot product is used. Take a dot product of all N samples with the prediction q and then calculate the log of softmax of the similarity score of the positive sample with the prediction q.", "In order to validate the richness of the representations learnt by CPC, a linear evaluation protocol is used. A linear classifier is trained on top of the output of the frozen encoder model(g_enc) using the Imagenet dataset and then it is evaluated for the classification accuracy of the learnt classifier model on the Imagenet Val/Test set. Note that during this whole training process of the linear classifier, the backbone model(g_enc) is fixed and is not trained at all. The table below shows that the classification accuracy of CPC representations outperformed all the other methods introduced before CPC with 48.7% top-1 acc.", "Although CPC outperformed other unsupervised learning methods for representation learning, the classification accuracy was still very far from the supervised counterpart(Resnet-50 with 100% labels on the Imagenet has 76.5% top-1 accuracy). This idea of image crop discrimination was extended to instance discrimination and tightened the gap between self-supervised learning and supervised learning methods.", "Instance Discrimination applies the concept of contrastive learning to whole image instance. Instance Discrimination method constraints that two augmented versions of the same image(positive pair) should have similar representations and two augmented versions of the different image(negative pair) should have different representations.", "Two papers MoCo and SimCLR worked on the idea of instance discrimination around the same time. Their main objective is, under a certain kind of image augmentations, the learnt representations should be invariant. These certain image augmentations include horizontal flip, a random crop of a certain size, color channel distortion, gaussian blur, etc. Intuitively, these augmentations although change the input image, but does not change the class of the input image(a cat would be a cat after flipping and cropping as well) and hence their representations should also not change.", "The whole method is as follows.", "The major difference between SimCLR and MoCo is how they handle the negative samples.", "SimCLR considers all the images in the current batch as negative samples. Trained in this way, SimCLR representations achieve a top-1% accuracy of 69.3% on the Imagenet with the linear evaluation protocol described in the CPC section.", "In practice, InfoNCE loss performance is dependent upon the number of negatives and it requires a high number of negatives while calculating the loss term. Hence, simCLR is trained with a high number of batches(as big as 8k) for best results which are very computationally demanding and require multi-GPU training. This is considered as the main drawback of simCLR method.", "Momentum Contrast(MoCo) on the other hand, keeps a separate buffer of negatives(as high as 8k) and uses them for calculating the InfoNCE loss. This allows them to train MoCo with smaller batch sizes without compromising on accuracy.", "MoCo keeps all recent mini-batches in fixed-size buffer for negatives(shown as x_0, x_1,x_2 in below image). To achieve superior results, a momentum encoder(\u0398_k) is used which has exact architecture as the encoder (\u0398_q)but the weights are slowly moving towards the actual encoder(shown below in the image).", "The only role of the momentum encoder is to generate representations(k_0, k_1, k_2\u2026 in the image below) out of the negative samples. Mind that momentum encoder does not update the weights through backpropagation which makes the method more memory efficient and allows to keep a large buffer of negatives in memory. Now in a short summary, given the first input x_query, the encoder generates the representations q, which is matched against another augmented version of the same image x_query(not shown in the image below) and also matched with the N negatives provided by the momentum encoder. Then the loss term is calculated using InfoNCE loss described in CPC section.", "It might be difficult for the readers to understand the relevance of momentum encoder and application of MoCo only through the post, so please for more details, I highly recommend reading the original paper . I have just covered the main highlights of the idea.", "In the second version of MoCo, the representations attained 71.1% accuracy on the Imagenet under linear evaluation protocol which went further close to the supervised Resnet-50 model(76.5%).", "Although MoCo showed good results but the dependency on negative samples has complicated the method. Recently BYOL[7] was introduced based on the instance discrimination method and it has shown that using two networks similar to MoCo, better visual representations could be learnt even without negatives. Their method achieves 74.3% top-1 classification accuracy on ImageNet under linear evaluation protocol using Resnet50 and further reduces the gap with their supervised counterpart using wider and deeper Resnets. The results are shown below.", "The actual BYOL training method is worthy of a separate post and I would leave it for future posts.", "Below is the list of references used for writing this post.", "Intrigued about Deep learning and all things ML."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc25ec10a91bd&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://nilesh0109.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Nilesh Vijayrania"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae2c3b0d24ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=post_page-ae2c3b0d24ec----c25ec10a91bd---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc25ec10a91bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----c25ec10a91bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc25ec10a91bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=-----c25ec10a91bd---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://arxiv.org/abs/1807.03748", "anchor_text": "Representation learning with contrastive predictive coding"}, {"url": "https://arxiv.org/abs/1807.03748", "anchor_text": "Representation learning with contrastive predictive coding"}, {"url": "https://arxiv.org/abs/2002.05709", "anchor_text": "original paper"}, {"url": "https://nilesh0109.medium.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b", "anchor_text": "https://nilesh0109.medium.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b"}, {"url": "https://medium.com/tag/self-supervised-learning?source=post_page-----c25ec10a91bd---------------self_supervised_learning-----------------", "anchor_text": "Self Supervised Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c25ec10a91bd---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----c25ec10a91bd---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/unsupervised-learning?source=post_page-----c25ec10a91bd---------------unsupervised_learning-----------------", "anchor_text": "Unsupervised Learning"}, {"url": "https://medium.com/tag/representation-learning?source=post_page-----c25ec10a91bd---------------representation_learning-----------------", "anchor_text": "Representation Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc25ec10a91bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----c25ec10a91bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc25ec10a91bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----c25ec10a91bd---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc25ec10a91bd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae2c3b0d24ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=post_page-ae2c3b0d24ec----c25ec10a91bd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcead73d39ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&newsletterV3=ae2c3b0d24ec&newsletterV3Id=cead73d39ca8&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----c25ec10a91bd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Written by Nilesh Vijayrania"}, {"url": "https://nilesh0109.medium.com/followers?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "90 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae2c3b0d24ec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=post_page-ae2c3b0d24ec----c25ec10a91bd---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fcead73d39ca8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fself-supervised-learning-methods-for-computer-vision-c25ec10a91bd&newsletterV3=ae2c3b0d24ec&newsletterV3Id=cead73d39ca8&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----c25ec10a91bd---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Nilesh Vijayrania"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Different Normalization Layers in Deep LearningPresently Deep Learning has been revolutionizing many subfields such as natural language processing, computer vision, robotics, etc. Deep\u2026"}, {"url": "https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "7 min read\u00b7Dec 10, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a7214ff71d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-normalization-layers-in-deep-learning-1a7214ff71d6&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----1a7214ff71d6----0-----------------clap_footer----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/different-normalization-layers-in-deep-learning-1a7214ff71d6?source=author_recirc-----c25ec10a91bd----0---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a7214ff71d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-normalization-layers-in-deep-learning-1a7214ff71d6&source=-----c25ec10a91bd----0-----------------bookmark_preview----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----c25ec10a91bd----1---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----c25ec10a91bd----1-----------------bookmark_preview----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://medium.com/@jacob_marks?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Jacob Marks, Ph.D."}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "How I Turned My Company\u2019s Docs into a Searchable Database with OpenAIAnd how you can do the same with your docs"}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "15 min read\u00b7Apr 25"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736----2-----------------clap_footer----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----c25ec10a91bd----2---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "20"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----c25ec10a91bd----2-----------------bookmark_preview----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Nilesh Vijayrania"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "Hands on Review: BYOL(Bootstrap Your Own Latent)Lately, Self-supervised learning methods have become the cornerstone for unsupervised visual representation learning. One such method\u2026"}, {"url": "https://towardsdatascience.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": "6 min read\u00b7Jan 2, 2021"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67e4c5744e1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b&user=Nilesh+Vijayrania&userId=ae2c3b0d24ec&source=-----67e4c5744e1b----3-----------------clap_footer----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/hands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b?source=author_recirc-----c25ec10a91bd----3---------------------1d4841fe_688f_44b4_a956_1631543a5db6-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67e4c5744e1b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-review-byol-bootstrap-your-own-latent-67e4c5744e1b&source=-----c25ec10a91bd----3-----------------bookmark_preview----1d4841fe_688f_44b4_a956_1631543a5db6-------", "anchor_text": ""}, {"url": "https://nilesh0109.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "See all from Nilesh Vijayrania"}, {"url": "https://towardsdatascience.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Jehill Parikh"}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "U-Nets with attentionU-Net are popular NN architecture which are employed for many applications and were initially developed for medical image segmentation."}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b72 min read\u00b7Nov 15, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&user=Jehill+Parikh&userId=c972081b627e&source=-----c8d7e9bf2416----0-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://jehillparikh.medium.com/u-nets-with-attention-c8d7e9bf2416?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8d7e9bf2416&operation=register&redirect=https%3A%2F%2Fjehillparikh.medium.com%2Fu-nets-with-attention-c8d7e9bf2416&source=-----c25ec10a91bd----0-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://wolfecameron.medium.com/?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Cameron R. Wolfe"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Using Transformers for Computer VisionAre Vision Transformers actually useful?"}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b713 min read\u00b7Oct 5, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&user=Cameron+R.+Wolfe&userId=28aa6026c553&source=-----6f764c5a078b----1-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/using-transformers-for-computer-vision-6f764c5a078b?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f764c5a078b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-transformers-for-computer-vision-6f764c5a078b&source=-----c25ec10a91bd----1-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Steins"}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Diffusion Model Clearly Explained!How does AI artwork work? Understanding the tech behind the rise of AI-generated art."}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b77 min read\u00b7Dec 26, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&user=Steins&userId=a36be384d77d&source=-----cd331bd41166----0-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166?source=read_next_recirc-----c25ec10a91bd----0---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcd331bd41166&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40steinsfu%2Fdiffusion-model-clearly-explained-cd331bd41166&source=-----c25ec10a91bd----0-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@martin-thissen?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Martin Thissen"}, {"url": "https://medium.com/mlearning-ai?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "MLearning.ai"}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Understanding and Coding the Attention Mechanism \u2014 The Magic Behind TransformersIn this article, I\u2019ll give you an introduction to the attention mechanism and show you how to code the attention mechanism yourself."}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b712 min read\u00b7Dec 6, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fmlearning-ai%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&user=Martin+Thissen&userId=f99c73950195&source=-----fe707a85cc3f----1-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/mlearning-ai/understanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f?source=read_next_recirc-----c25ec10a91bd----1---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe707a85cc3f&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fmlearning-ai%2Funderstanding-and-coding-the-attention-mechanism-the-magic-behind-transformers-fe707a85cc3f&source=-----c25ec10a91bd----1-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://naokishibuya.medium.com/vit-vision-transformer-2020-7bf74a3d4b5d?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://naokishibuya.medium.com/?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://naokishibuya.medium.com/?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Naoki"}, {"url": "https://naokishibuya.medium.com/vit-vision-transformer-2020-7bf74a3d4b5d?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "ViT: Vision Transformer (2020)An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"}, {"url": "https://naokishibuya.medium.com/vit-vision-transformer-2020-7bf74a3d4b5d?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b75 min read\u00b7Nov 2, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7bf74a3d4b5d&operation=register&redirect=https%3A%2F%2Fnaokishibuya.medium.com%2Fvit-vision-transformer-2020-7bf74a3d4b5d&user=Naoki&userId=1038cf2d79d&source=-----7bf74a3d4b5d----2-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://naokishibuya.medium.com/vit-vision-transformer-2020-7bf74a3d4b5d?source=read_next_recirc-----c25ec10a91bd----2---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7bf74a3d4b5d&operation=register&redirect=https%3A%2F%2Fnaokishibuya.medium.com%2Fvit-vision-transformer-2020-7bf74a3d4b5d&source=-----c25ec10a91bd----2-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/three-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@poulinakis.kon?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/@poulinakis.kon?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Konstantinos Poulinakis"}, {"url": "https://medium.com/geekculture?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Geek Culture"}, {"url": "https://medium.com/geekculture/three-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "Three reasons Self-Supervised Learning will dominate AISupervised learning was all I studied until I came across Self-Supervised learning. That\u2019s when I decided to upgrade my level."}, {"url": "https://medium.com/geekculture/three-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": "\u00b75 min read\u00b7Nov 22, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgeekculture%2F69904684c935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fthree-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935&user=Konstantinos+Poulinakis&userId=18fd5e3887bd&source=-----69904684c935----3-----------------clap_footer----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/geekculture/three-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935?source=read_next_recirc-----c25ec10a91bd----3---------------------c78bab7b_a798_49b0_a94d_b0efad13bb65-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F69904684c935&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fgeekculture%2Fthree-reasons-self-supervised-learning-will-dominate-artificial-intelligence-ai-69904684c935&source=-----c25ec10a91bd----3-----------------bookmark_preview----c78bab7b_a798_49b0_a94d_b0efad13bb65-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----c25ec10a91bd--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}