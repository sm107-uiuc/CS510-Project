{"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b", "time": 1683009786.408128, "path": "towardsdatascience.com/lovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b/", "webpage": {"metadata": {"title": "Lovecraft with NLP: Latent Semantic Analysis | Towards Data Science", "h1": "Lovecraft with Natural Language Processing \u2014 Part 4: Latent Semantic Analysis", "description": "Applying dimension-reduction techniques to convert TF-IDF vectors into more meaningful representations of H. P. Lovecraft's stories."}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/H._P._Lovecraft", "anchor_text": "H. P. Lovecraft", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-1-rule-based-sentiment-analysis-5727e774e524", "anchor_text": "Part 1 \u2014 Rule-based Sentiment Analysis", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-2-tokenisation-and-word-counts-f970f6ff5690", "anchor_text": "Part 2\u2014Tokenisation", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-3-tf-idf-vectors-8c2d4df98621", "anchor_text": "Part 3 \u2014 TF-IDF Vectors", "paragraph_index": 0}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "documentation", "paragraph_index": 14}, {"url": "https://github.com/MatePocs/lovecraft/blob/master/results/word_counts/lsa_clustering.csv", "anchor_text": "GitHub repo", "paragraph_index": 20}], "all_paragraphs": ["This is the fourth post in my ongoing series in which I apply different Natural Language Processing technologies on the writings of H. P. Lovecraft. For the previous posts in the series, see Part 1 \u2014 Rule-based Sentiment Analysis, Part 2\u2014Tokenisation, Part 3 \u2014 TF-IDF Vectors.", "This post builds heavily on the concept of the TF-IDF vectors, a vector representation of a document, based on the relative importance of individual words in the documents and the whole corpus. As a next step, we are going to transform those vectors into lower-dimension representation using Latent Semantic Analysis (LSA). LSA makes it possible to search documents based on meaning, rather than exact word usage, which quite often results in better matches than TF-IDF.", "We will start by discussing the drawbacks of using TF-IDF, and why it would make sense to adjust those vectors. Then, we will clear up some mathematic terminology that I personally found confusing. Finally, we repeat the steps we did in the previous post, create a vector representation of the Lovecraft stories, and see if we can come up with meaningful groups using cluster analysis.", "As we saw in the previous post, TF-IDF vectors are multidimensional vector representations of individual documents in a corpus. If we have 10,000 unique words across all the documents, and 500 documents, we can create a 500 x 10,000 matrix, where each row is a vector representing a document, the unique words form the dimensions, and each element represents the relative importance of a particular word in a particular document. There is some information we lose in the process, most importantly, the order of the words, but TF-IDF is still a surprisingly powerful way to convert a group of documents into numbers and search among them.", "However, there are a couple of issues with TF-IDF:", "In order to solve these issues, we are going to stop focusing on individual words, and come up with \u201ctopics\u201d instead. Let\u2019s take Lovecraft\u2019s works. Instead of counting how many times he used \u201chorrendous\u201d or \u201chideous\u201d, we would have topics like \u201cdreamland description\u201d, \u201cGreat Old Ones\u201d, and \u201canti-immigrant sentiment\u201d (yes, well, nobody is perfect). Words that correspond strongly with one topic or another will increase the overall score of those topics in their respective story. And then instead of measuring how close the word frequencies are to each other, we will only consider the aggregated topics. That is basically the thought process behind Latent Semantic Analysis, it will find words that belong together because they will correlate highly with the same topics.", "We will apply this approach in order to strengthen the cluster analysis we are doing on the stories. One can hope that if we consider aggregated topics instead of individual words, stories that feel like they should belong together will be assigned to the same group with a higher chance.", "However, a much more important and widespread application of this dimension-reduction technique is when it comes to classification problems. NLP data tends to have a large vocabulary and a relatively small amount of observations. If you analyse 5,000 tweets, you might have 10,000 words, which means you would have twice as many features as observations, which is definitely not ideal. If you manage to decrease those dimensions while keeping a high portion of the information, that will make your model much stronger.", "So the only question is, how are we coming up with those topics? That is where Singular Value Decomposition comes into the picture. However, I would like to mention one thing before we look into the math just to manage expectations: those topics that I mentioned, the clean and nicely labelled ones \u2014 we can forget about getting anything similar to that, unless you are working with a very few very well constructed example sentences. With a corpus the size and homogeneity of Lovecraft\u2019s stories I think it would be impossible to come up with a nice reasoning behind how the topics are created. But that\u2019s not the goal of this analysis to begin with, we just want to examine if we can come up with a structure that automatically groups the stories.", "All right, let\u2019s have a look at the math concepts behind creating the topic vectors! As I mentioned in the introduction, I found the way these concepts are often used interchangeably in the literature confusing. Hopefully, these high-level definitions will clear up some confusion.", "And now, finally, on with the LSA for our stories! As mentioned above, LSA can be applied to a variety of NLP representations, but we are using it on the TF-IDF vectors now.", "We have a sparse matrix called result from the previous project, which contains the TF-IDF representation of the 63 stories in our corpus. In general, before doing a PCA, one needs to normalise the vectors in order to scale the different dimensions to the same magnitude. With the TF-IDF vectors, this is already mostly done by scikit-learn, but we can still centralise the vectors around 0. To do this, we will sadly have to let the sparse matrix format go:", "Now we have a pandas DataFrame, which can be used without further adjustments in the model.", "As many things in scikit-learn, creating a model is very simple:", "The most important parameter is the n_components, it defines how many different components (\u201ctopics\u201d in the case of an NLP problem) we want the model to aggregate to. (See the documentation for details of other parameters.) So where does 50 as the number of topics come from? It requires some fine-tuning with the method called explained_variance_ratio_:", "This will determine the percentage of the variance between the stories that we preserved by compressing the original matrix of over 17 thousand to 50. In our case, this preserved ratio was about 87%, which was certainly suspicious at first sight, but one has to remember that with 63 components, we would have been able to preserve 100% of the original information.", "To me, 87% seemed good enough. You can certainly go with a more scientific route and calculate the explained variance ratio for a number of different number of components, and then find the \u201celbow\u201d point. Once we are happy with the configurations, we can call fit_transform:", "The new result_df is going to be a matrix with 63 rows (the original stories) and 50 columns (the artificially created \u201ctopics\u201d).", "Now we can basically repeat the same process as in the previous post, just with a much, much lower number of features.", "And organising the results in a pandas DataFrame:", "The cluster_df_2 object from above is available in CSV form in my GitHub repo.", "Let\u2019s see how well the LSA clusters performed!", "Once again, we run into a similar problem as in the previous post with the TF-IDFs: I don\u2019t think there is a really elegant solution to this grouping question to begin with, and a human expert would also find this task very difficult, if not impossible.", "That being said, I managed to find some nice patterns. For example, if we have a look at the 4-means groups, there are three very distinct groups of stories:", "This seems to be a common theme with the different clusters. The algorithm usually separates a couple of really weird and unique stories, and leaves the rest of them in one large group. The really popular and famous stories of Lovecraft are almost always assigned to the same group, regardless of the number of clusters.", "I personally think this is still quite an impressive result. We managed to compress the meaning of Lovecraft stories in 50 artificially created topics, and even if the groups that are created are not outright brilliant, you can certainly discover patterns. Did it perform better than TF-IDF? I think so. I managed to find nice patterns in the LSA results that were not there before.", "We could have experimented with a lower number of dimensions to compress the meanings even further, that could improve the clustering. However, I think the main issue is that we have a very small corpus, only 63 documents. And sadly, we will not get any more original Lovecraft stories.", "Hobson, L. & Cole, H. & Hannes, H. (2019). Natural Language Processing in Action: Understanding, Analyzing, and Generating Text with Python. Manning Publications, 2019.", "The Complete Works of H. P. Lovecraft:", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F70aa2fa2161b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://matepocs.medium.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": ""}, {"url": "https://matepocs.medium.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Mate Pocs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F686b78ddcf4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&user=Mate+Pocs&userId=686b78ddcf4b&source=post_page-686b78ddcf4b----70aa2fa2161b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/users/DarkWorkX-1664300/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3394066", "anchor_text": "DarkWorkX"}, {"url": "https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3394066", "anchor_text": "Pixabay"}, {"url": "https://en.wikipedia.org/wiki/H._P._Lovecraft", "anchor_text": "H. P. Lovecraft"}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-1-rule-based-sentiment-analysis-5727e774e524", "anchor_text": "Part 1 \u2014 Rule-based Sentiment Analysis"}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-2-tokenisation-and-word-counts-f970f6ff5690", "anchor_text": "Part 2\u2014Tokenisation"}, {"url": "https://towardsdatascience.com/lovecraft-with-natural-language-processing-part-3-tf-idf-vectors-8c2d4df98621", "anchor_text": "Part 3 \u2014 TF-IDF Vectors"}, {"url": "https://en.wikipedia.org/wiki/Singular_value_decomposition", "anchor_text": "Singular Value Decomposition (SVD)"}, {"url": "https://en.wikipedia.org/wiki/Principal_component_analysis", "anchor_text": "Principal Component Analysis (PCA)"}, {"url": "https://en.wikipedia.org/wiki/Latent_semantic_analysis", "anchor_text": "Latent Semantic Analysis (LSA)"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "documentation"}, {"url": "https://github.com/MatePocs/lovecraft/blob/master/results/word_counts/lsa_clustering.csv", "anchor_text": "GitHub repo"}, {"url": "https://en.wikipedia.org/wiki/Ibid_(short_story)", "anchor_text": "Ibid (1928)"}, {"url": "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html", "anchor_text": "sklearn.decomposition.PCA - scikit-learn 0.23.1 documentationPrincipal component analysis (PCA). Linear dimensionality reduction using Singular Value Decomposition of the data to\u2026scikit-learn.org"}, {"url": "https://arkhamarchivist.com/free-complete-lovecraft-ebook-nook-kindle/", "anchor_text": "https://arkhamarchivist.com/free-complete-lovecraft-ebook-nook-kindle/"}, {"url": "https://medium.com/tag/python?source=post_page-----70aa2fa2161b---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/nlp?source=post_page-----70aa2fa2161b---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/dimensionality-reduction?source=post_page-----70aa2fa2161b---------------dimensionality_reduction-----------------", "anchor_text": "Dimensionality Reduction"}, {"url": "https://medium.com/tag/lovecraft?source=post_page-----70aa2fa2161b---------------lovecraft-----------------", "anchor_text": "Lovecraft"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----70aa2fa2161b---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&user=Mate+Pocs&userId=686b78ddcf4b&source=-----70aa2fa2161b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&user=Mate+Pocs&userId=686b78ddcf4b&source=-----70aa2fa2161b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F70aa2fa2161b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----70aa2fa2161b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----70aa2fa2161b--------------------------------", "anchor_text": ""}, {"url": "https://matepocs.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://matepocs.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mate Pocs"}, {"url": "https://matepocs.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "460 Followers"}, {"url": "http://linkedin.com/in/matepocs", "anchor_text": "linkedin.com/in/matepocs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F686b78ddcf4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&user=Mate+Pocs&userId=686b78ddcf4b&source=post_page-686b78ddcf4b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea5ecc8b4148&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flovecraft-with-natural-language-processing-part-4-latent-semantic-analysis-70aa2fa2161b&newsletterV3=686b78ddcf4b&newsletterV3Id=ea5ecc8b4148&user=Mate+Pocs&userId=686b78ddcf4b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}