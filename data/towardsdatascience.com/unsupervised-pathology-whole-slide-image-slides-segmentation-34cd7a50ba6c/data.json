{"url": "https://towardsdatascience.com/unsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c", "time": 1683017730.0486898, "path": "towardsdatascience.com/unsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c/", "webpage": {"metadata": {"title": "Generalized Categorisation of Digital Pathology Whole Image Slides using Unsupervised Learning | by Mostafa Ibrahim | Towards Data Science", "h1": "Generalized Categorisation of Digital Pathology Whole Image Slides using Unsupervised Learning", "description": "An article about using machine learning in Digital Pathology, specifically unsupervised learning and autoencoders"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["In this article, I am going to talk about one of my dearest and best projects that I have worked on, my undergraduate thesis at University College London. My thesis was about using unsupervised machine learning to automate the process of breaking down huge Whole Slide Images and labeling them without supervision. This proved to be a much more difficult task than I originally thought. I honestly can't believe that if you search for \u201cunsupervised digital pathology\u201d on google, the first result is my paper!", "Cancer is the second leading cause of death worldwide, responsible for around 15% of deaths[1]. Therefore automating diagnostic processes using machine learning (ML) has become one of the most significant medical tasks. Cancer occurs when the cells start dividing and growing uncontrollably, moreover, it is worthy to note that solid tumors are not simply clones of cancer cells [2], they are extraordinary organs that are made up of several cell types, their texture is not consistent, which makes identifying them a hard problem for both pathologists and ML algorithms.", "Due to the recent advancement of microscopes, a subfield of pathology has emerged, Digital Pathology. This subfield introduces a realm of possibilities for automation of diagnosis and medical analysis as it digitizes any microscopic slide.", "When a digital microscope takes a snapshot of a cancer biopsy, it records the biopsy as a \u201cWhole Slide Image\u201d, this is essentially a huge image that can be magnified up to 500x for accuracy and precision. The main challenge here lies in analyzing, processing, and labeling these images since they have a huge size and resolution (up to 3GB per image). Typically neural networks take in images that are 224 x 224 or 512 x 512 but usually not more.", "To further demonstrate what this means, the initial Whole Slide image would like something like this:", "And the goal of our algorithm would be to transform it into something like this:", "There are tons of supervised digital pathology projects where Neural Networks are trained to diagnose a certain disease. However, the issue with each one is that you would have to spend tons of money and time to get a labeled dataset, which obviously wouldn\u2019t be available for each distinct disease.", "The main goal of this project is to solve this problem. The software package breaks down the huge WSI into tiles and gives the user a nice list of sub-directories where each directory contains a group of similar tiles.", "While I still haven\u2019t officially published it in a journal, you can have a look at the paper here:", "The final code deliverable gives a command-line interface that takes in a Whole Image Slide, breaks it down, and then clusters the tiles into subdirectories according to the options given. How it does that, is the interesting bit we are going to talk about for the rest of this article.", "The project consisted mainly of 4 different experiments, those 4 experiments all use the same clustering algorithms but use different dimensionality reduction techniques.", "If you are not familiar with unsupervised learning, you can think of clustering algorithms as algorithms that group similar data points together and dimensionality reduction as a compression and extraction technique that \u201cfilters\u201d the data. The more filtered the data, the more accurate clusters you will get.", "If these algorithms interest you, keep reading this article as they were heavily used:", "Before we start diving into the details of the approaches and algorithms used, we have to define a metric to compare them. And since this is unsupervised learning (so no labels involved), this can be a bit tricky. We chose the Completeness score.", "This score is not the same as accuracy, since the unsupervised algorithms have no knowledge of the ground truth labels; they are simply just placing every group of data points in a cluster, but they don\u2019t know what this cluster is.", "A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same clusters, this metric is independent of the absolute value of labels.", "Where H is the entropy function, Ypred is the predicted label, and Ytrue is the true label, this score stems from mathematical combinatorics. This metric ranges from 0 to 1, where 1 means that all members of a given class are assigned to the same cluster.", "Furthermore, our 2 main clustering algorithms that were used are K-Means and Gaussian Mixture Models.", "K-Means uses the Euclidean distance as the similarity measure for data points. It starts with randomly initializing k centroids, where k is a hyperparameter, after that it attempts to make the inter-cluster data points as similar as possible (minimize the distances) while also keeping theclusters as different as possible. To do this, it uses the following loss function", "Where \u03bc[j] is cluster number j, \u03c1i[j] is a boolean indicator variable used to indicate whether the data point i belongs to cluster j. The target of K-Means is simply to minimize the sum of squares of the distances of each instance to its closest centroid, to optimize this loss function. The Expectation Maximisation algorithm is used (which will also be used in Gaussian Mixture Models).This algorithm is guaranteed to converge but not necessarily to a global optimum.", "As with regards to GMMs, Gaussian mixtures are essentially a mixture of k features (hyper- parameter) where each k is assumed to have a Gaussian (normal) distribution. The main target of this algorithm is to estimate the parameters that best fit the k features combined. Those parameters are the mean u that defines the center, the covariance matrix (matrix of pairwise variances) defining the width, and the mixing probability that defines how big or small the Gaussian is.", "Although the image tiles (broken down WSIs) may be tiny, 150 x 150 RGB images, in the machine learning world this is equivalent to 67,500 (150 x 150 x 3) dimensions/features! which is insanely huge. Most algorithms underperform in such huge dimensional spaces (the famous curse of dimensionality) so we had to figure out how to bring that number down. One solution is to try out Principal Component Analysis. I am not going to get into the fine details of each algorithm because that will make this article extremely long. But, you can always read more about how they work and why they were used in the paper. Here is how PCA works briefly : (from the paper)", "PCA works through Projected Variance Maximisation where the target is to project the original m dimensions into d dimensions such that the sample variance is maximally preserved. This d dimensional subspace encapsulates the directions along which the data varies the most. The loss function is called the reconstruction error and can be described as", "Where \\bar{x} is the mean of the project data, u is a set of basis vectors that span the data subspace d, and the main objective is minimizing the 2 norms squared for points 1 to n (the whole dataset).", "The interesting bit is that with PCA we can reduce the dimensions down to around 2,025 dimensions (97% reduction) with only 1% loss in variance !! Although that\u2019s great, 2,025 are still a lot, the clustering algorithms weren\u2019t performing too well in that situation. Also, although automatic feature selection (which is being used here) sounds amazing, sometimes you need to manually select the features that you think are going to work the best and keep experimenting.", "So, we decided to select 5 features, giving us only 5 dimensions to work with. 3 of those 5 are the mean RGB values for each tile, and the other 2 are the mean Hematoxylin & Eosin (H&E) values. H&E are histopathologic stains that have been used frequently to help pathologists in diagnosing cancerous cells.", "We can also now drive those 5 dimensions down to 2 dimensions just for visualization purposes, and the results look something like this:", "The intuition here is that if we want to separate every colored group of points (a class), there has to be more space between them, it\u2019s as simple as that. But, this is very hard to do in practice, because we want to find the perfect set of features that are just going to do that, without those features we are mostly placing data points in the wrong classes.", "To further understand this, we have to note that clustering algorithms typically group points that are closer in the Euclidean space into a cluster. That\u2019s not how all clustering algorithms work, but I personally think that this is a significant element of how most of them work assuming you are using the Euclidean distance.", "To find this perfect set of features, we tried using Autoencoders. Autoencoders are neural networks that take in images and attempt to output those same images. Which at first sounds trivial, however, the main idea here is that they have a bottleneck in the middle that the Autoencoder attempts the reconstruction from. The underlying theory here is that this bottleneck will contain the most valuable features of the image. So essentially the Autoencoder tries to compress the image greatly and then reconstruct the image from that encoding. And to do that it has to use some sort of reconstruction loss.", "Autoencoder example, not the architecture used:", "We experimented with Mean squared error and Structural Similarity Index.", "Where x is the original image and y is the reconstructed image, N is the number of training tiles", "Where \u03bc is average, \u03c3 is variance (\\sigma_{xy} is covariance), c is added to stabilize the division.", "We experimented with several different architectures, for the sake of brevity, those 2 were the best ones:", "The Autoencoders seemed to be doing great, the reconstruction errors were minimalistic, improved completeness scores, and great cluster plots. However, the separation was still not great. To visualize that separation we had to find a better way than using PCA since driving down 1,152\u20131,296 dimensions to 2 dimensions would result in a huge data loss. This time we are going to use t-SNE.", "Unlike PCA, t-SNE is a non-linear algorithm that falls under the class of manifold learning / nonlinear dimensionality reduction. The main idea of T-SNE is constructing 2 probability distributions of the dataset, one for the original high dimensional dataset and one for the lower-dimensional space (2D), and then as typical machine learning algorithms, it minimizes the loss between those 2 distributions through Kullback-Leibler divergence which measures the divergence (difference) between 2 probability distributions and is defined as", "And the results look something like this:", "Our final approach is the most interesting one and definitely my favorite. This is the point where things started getting quite difficult because conventional methods didn\u2019t seem to be reaching the required level of performance so we had to go out of our way to innovate. The main idea of this approach is to introduce another head to the bottleneck that would use image labels (hence the transition here to semi-supervised learning) to improve the quality of the features in the bottleneck. The architecture for such a network would look like this:", "By classification loss, we mean categorical loss entropy, which is the standard for multi-class classification. This is summed up by the following equation:", "where y is the predicted value, N is the number of training samples.", "Moreover, things start to get a bit complicated here. We start to add other metrics to improve our evaluation of the performance such as the Autoencoders reconstruction error and the F1-score (supervised evaluation metric that relies on precision and recall). Furthermore, we also experiment with the number of classes with 2 different datasets, one that has 2 classes (malignant/benign) and another one that has 8 different classes (different tissue types including malignant/benign). This table summarizes those experiments:", "The table shows a fairly interesting result, which is that the f1-score for 2 classes is much higher than the f1-score for 8 classes, this proves the difficulty of the multi-class texture problem. It is also worth noting that the multi-class problem will be harder than the 2-class because it is easier to choose the correct class when only 2 classes are involved (50% random chance) compared to when 8 classes are involved (12.5% random chance of getting it correct).", "Finally, we check out the t-SNE plot to see if the separation actually improved. This was one of my favorite moments\u2026", "It goes without saying that I haven\u2019t included a lot of details here. The main purpose of this article is to give you a quick overview of the paper. It\u2019s quite difficult to condense 30 papers worth of information into a 5\u201310 minute read. If you would just like to see a comparison of the performance for the different approaches used, checkout chart:", "To also compare the performance of the final autoencoder more visually, we generated the following \u201cCluster plot\u201d:", "To sum up, our main goal was to produce a piece of software that can help the digital pathology community to more easily work on various machine learning projects without having to go through the tedious process of searching for labeled images or working with pathologists to manually label every single image which is very time-consuming. The final system works like this:", "Of course, we understand that the performance isn\u2019t going to be perfect, there will certainly be outliers. However, the design was built around allowing the user to quickly investigate and find those outliers. This is why we used symbolic links because you can quickly preview the images and remove outliers (and hopefully you wouldn\u2019t have to find a lot of those).", "As for future work, we wanted to experiment with Variational Autoencoders. Those have very interesting bottlenecks that are mostly an improvement of the semi-supervised bottleneck we introduced here. You can also try to use a Neural Network interpretability framework such as Deepdream to visualize the convolutions in the intermediate layers. This will help us greatly understand why the networks work and why they seem to be underperforming in some areas.", "If you ask me what is the most valuable lesson you have learned from this project, I guess it would be to calibrate the balance between trying new approaches and analyzing the approaches that you have implemented properly. This means that for every approach you implement, you have to understand why it gave the result that it did, to properly select the next approach.", "If you want to receive regular paper reviews about the latest papers in AI & Machine learning, add your email here & Subscribe!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Eng. University College London Computer Science Graduate. Passionate about Machine Learning in Healthcare. Top writer in AI"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F34cd7a50ba6c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://mostafaibrahim18.medium.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": ""}, {"url": "https://mostafaibrahim18.medium.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Mostafa Ibrahim"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1f214c06d3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&user=Mostafa+Ibrahim&userId=b1f214c06d3e&source=post_page-b1f214c06d3e----34cd7a50ba6c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://blogs.nvidia.com/blog/2019/11/07/harvard-pathology-lab-data-fusion-ai-cancer/", "anchor_text": "Nvidia"}, {"url": "https://arxiv.org/abs/2012.13955", "anchor_text": "https://arxiv.org/abs/2012.13955"}, {"url": "https://github.com/mostafaibrahim17/Whole-Image-Slides-Unsupervised-Categorization", "anchor_text": "https://github.com/mostafaibrahim17/Whole-Image-Slides-Unsupervised-Categorization"}, {"url": "https://artisanal-motivator-8249.ck.page/5524b8f934", "anchor_text": "https://artisanal-motivator-8249.ck.page/5524b8f934"}, {"url": "http://www.who.int/news-room/fact-sheets/detail/cancer", "anchor_text": "http://www.who.int/news-room/fact-sheets/detail/cancer"}, {"url": "https://www.ncbi.nlm.nih.gov/pubmed/20627072", "anchor_text": "https://www.ncbi.nlm.nih.gov/pubmed/20627072"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----34cd7a50ba6c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----34cd7a50ba6c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----34cd7a50ba6c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----34cd7a50ba6c---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----34cd7a50ba6c---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&user=Mostafa+Ibrahim&userId=b1f214c06d3e&source=-----34cd7a50ba6c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&user=Mostafa+Ibrahim&userId=b1f214c06d3e&source=-----34cd7a50ba6c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F34cd7a50ba6c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----34cd7a50ba6c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----34cd7a50ba6c--------------------------------", "anchor_text": ""}, {"url": "https://mostafaibrahim18.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://mostafaibrahim18.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mostafa Ibrahim"}, {"url": "https://mostafaibrahim18.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.2K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb1f214c06d3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&user=Mostafa+Ibrahim&userId=b1f214c06d3e&source=post_page-b1f214c06d3e--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd376c1b5023a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funsupervised-pathology-whole-slide-image-slides-segmentation-34cd7a50ba6c&newsletterV3=b1f214c06d3e&newsletterV3Id=d376c1b5023a&user=Mostafa+Ibrahim&userId=b1f214c06d3e&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}