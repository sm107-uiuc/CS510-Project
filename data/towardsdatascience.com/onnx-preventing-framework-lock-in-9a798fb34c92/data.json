{"url": "https://towardsdatascience.com/onnx-preventing-framework-lock-in-9a798fb34c92", "time": 1683015813.914706, "path": "towardsdatascience.com/onnx-preventing-framework-lock-in-9a798fb34c92/", "webpage": {"metadata": {"title": "ONNX: Preventing Framework Lock in | by Fernando L\u00f3pez | Towards Data Science", "h1": "ONNX: Preventing Framework Lock in", "description": "In this blog, we are going to see what the ONNX standard is, its components and how to carry out interoperability between different Deep Learning frameworks. This blog will address the following\u2026"}, "outgoing_paragraph_urls": [{"url": "https://onnx.ai/", "anchor_text": "Open Neural Network Exchange (ONNX)", "paragraph_index": 5}, {"url": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "anchor_text": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "paragraph_index": 16}, {"url": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "anchor_text": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "paragraph_index": 29}], "all_paragraphs": ["In this blog, we are going to see what the ONNX standard is, its components and how to carry out interoperability between different Deep Learning frameworks. This blog will address the following sections:", "PyTorch, Tensorflow, Caffe2, MXNet, etc, are just some of the most popular frameworks today for the development of Deep Learning models. Although the common denominator between these frameworks is the training and tuning of deep learning models, the \u201chow they do it\u201d and the sector they are aimed at are the main differentiator. Some frameworks are more research-oriented (such as PyTorch) and some others are mostly used for device deployment (such as Tensorflow), likewise, some frameworks base their design architecture on static graphs (such is the case Tensorflow and Caffe2) and others in dynamic graphs (such is the case of PyTorch).", "Obviously, each of these frameworks offers different advantages over the others, however, how could we link these advantages? How could we interoperate different frameworks? How could we optimize a model with framework \u201cx\u201d and deploy it in an architecture optimized for framework \u201cy\u201d? Well, this type of interoperability is achieved thanks to the ONNX standard and the ONNX Runtime (which we will see later). In Figure 1, it is described the problematic addressed by ONNX and ONNX Runtime.", "ONNX has come to break the dependency between frameworks and hardware architectures. ONNX seeks to become the default standard for portability and interoperability between the different Deep Learning frameworks. So, let\u2019s see in a little more detail what is ONNX and what is ONNX Runtime.", "ONNX is the acronym that stands for Open Neural Network Exchange. Which refers to a standard model that facilitates interoperability between Deep Learning frameworks. The ONNX standard began in 2017 at the initiative of the giants Microsoft, Facebook and Amazon. The basic idea was to propose a standard that would allow portability and interoperability between the already well-known Deep Learning frameworks.", "Open Neural Network Exchange (ONNX) is an open ecosystem that empowers AI developers to choose the right tools as their project evolves [1].", "ONNX has come to streamline the lifecycle of Machine Learning models, from research to production, since it is common for some frameworks to be more suitable for prototyping and optimizing models while others provide tools that speed up deployment to different devices. Therefore, it is important to mention that currently ONNX has the capacity to support inference, that is, we can train a model in framework \u201ca\u201d and perform inference in framework \u201cb\u201d. Figure 2 provides a visual description of framework interoperability.", "The ONNX specification addresses the following three components to enable interoperability:1. A definition of an extensible computation graph model.2. Definitions of standard data types.3. Definitions of built-in operators.", "To date, several frameworks already integrate an extension to be able to export models under the ONNX specification, likewise the frameworks that have not yet integrated the export module make use of wrappers that work perfectly.", "Well, so far we already know why a standard is required for interoperability between frameworks, in the same way we already know what the participation of ONNX is in this ecosystem, now we have to know what \u201cONNX Runtime\u201d is and the great impact that it generates in the industry, so let\u2019s go for it!", "ONNX Runtime is a multiplatform accelerator focused on training and model inferences compatible with the most common Machine Learning & Deep Learning frameworks [2]. In other words, ONNX Runtime is the implementation of the ONNX standard.", "ONNX Runtime arises due to the need for an interface that accelerates inference in different hardware architectures. Before ONNX Runtime, it was very expensive to deploy models that were optimized mainly for CUDA-based architectures towards NUPHAR, nGraph, OpenVINO-based architectures, etc. In other words, there was a dependency between the framework and the hardware architecture for which the model was optimized. It is with the ONNX standard and the ONNX Runtime accelerator that the doors are opened to a wide spectrum of interoperability between frameworks and hardware architectures.", "Some key benefits of ONNX Runtime are:", "Great, now we know the impact of ONNX and ONNX Runtime in terms of interoperability and portability, let\u2019s see an example!", "In the following example we are going to demonstrate how to use the ONNX standard to be able to interoperate between different Deep Learning frameworks.", "The architecture of the example is given as follows, we are going to train a classifier in PyTorch, then we are going to use this trained model to perform inference in Tensorflow, Caffe2 and ONNX Runtime. The architecture of the example is given as follows:", "If you want to take a look at the complete code, this is the implementation: https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2 . Feel free to clone or fork!", "First we are going to create generic data, the idea is to create a dummy model, so let\u2019s define the following generator that will return the training and test data:", "Now let\u2019s define the structure of our dummy model as well as the forward function. We basically define two linear layers, that\u2019s enough.", "Perfect! So far we already have the generic data as well as our dummy model, it is time to train the model!", "As we can see, the training phase is very simple and does not require much explanation. So let\u2019s move on to the following, it\u2019s time to export our model to the ONNX standard, for this PyTorch already provide us with an extension to export models in ONNX format, let\u2019s see how we do it!", "Let\u2019s first look at the if-else statement of line 4. We are defining a \u201cdummy input\u201d because ONNX needs to traverse the entire graph defined by PyTorch, in this way ONNX will be in charge of tracking each of the layers and parameters defined in each graph instance. In this case, we are defining a generic input with the \u201cvariable\u201d or in its case, we are defining the dummy input as the real input that is used in the training.", "Later, in lines 9 and 10, we define the names that we will assign to each layer in the graph that ONNX will generate, if not, ONNX will use generic names.", "Finally, in line 13 we make use of the ONNX extension of PyTorch, we pass as arguments the trained model, the dummy input and the names that we assign to each element of the graph. It is important to look at the argument passed in line 22, since inference tensors can have some variations in dimension size (commonly it is the dimension that refers to the batch size), we define such dimension as \u201cdynamic\u201d, therefore at the time of inferring, we can pass any batch size, not specifically the one used when training the original model.", "Well, so far we have already trained a model in PyTorch and saved under the ONNX standard, now we see how to load this model with different frameworks to make the inference.", "To perform inference with ONNX Runtime, we need to import the onnxruntime library, then we just need to load the onnx model with the onnx module and generate the predictions.", "To make predictions with the caffe2 framework, we need to import the caffe2 extension for onnx which works as a backend (similar to the session in tensorflow), then we would be able to make predictions.", "To make predictions with Tensorflow it is required to make use of the onnx_tf module which provides a wrapper (which simulates the session), in order to make predictions.", "Congratulations! we reached the end of the blog.", "If you want to take a look at the complete code, this is the implementation: https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2 . Feel free to clone or fork!", "In this blog, we explained the need for which the ONNX standard arises. We also addressed the idea of how ONNX helps prevent framework lock in. On the other hand, we explained how the ONNX standard in conjunction with ONNX Runtime allows us to reduce the time in the Deep Learning lifecycle, since it accelerates the connection between the training phase and deployment phase.Finally, we saw an example where, using ONNX, we can train a model in a given framework and perform inference in other frameworks.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Machine Learning Engineer | Data Scientist | Software Engineer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F9a798fb34c92&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://ferneutron.medium.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Fernando L\u00f3pez"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd606f5d846f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=post_page-d606f5d846f2----9a798fb34c92---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@egnaro?utm_source=medium&utm_medium=referral", "anchor_text": "Rick Mason"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.flaticon.com/home", "anchor_text": "flaticon"}, {"url": "https://onnx.ai/", "anchor_text": "Open Neural Network Exchange (ONNX)"}, {"url": "https://www.flaticon.com/", "anchor_text": "flaticon"}, {"url": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "anchor_text": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2"}, {"url": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2", "anchor_text": "https://github.com/FernandoLpz/ONNX-PyTorch-TF-Caffe2"}, {"url": "https://github.com/onnx/onnx", "anchor_text": "https://github.com/onnx/onnx"}, {"url": "https://microsoft.github.io/onnxruntime/docs/", "anchor_text": "https://microsoft.github.io/onnxruntime/docs/"}, {"url": "https://medium.com/tag/onnx?source=post_page-----9a798fb34c92---------------onnx-----------------", "anchor_text": "Onnx"}, {"url": "https://medium.com/tag/onnx-runtime?source=post_page-----9a798fb34c92---------------onnx_runtime-----------------", "anchor_text": "Onnx Runtime"}, {"url": "https://medium.com/tag/pytorch?source=post_page-----9a798fb34c92---------------pytorch-----------------", "anchor_text": "Pytorch"}, {"url": "https://medium.com/tag/tensorflow?source=post_page-----9a798fb34c92---------------tensorflow-----------------", "anchor_text": "TensorFlow"}, {"url": "https://medium.com/tag/interoperability?source=post_page-----9a798fb34c92---------------interoperability-----------------", "anchor_text": "Interoperability"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----9a798fb34c92---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=-----9a798fb34c92---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F9a798fb34c92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----9a798fb34c92---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----9a798fb34c92--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----9a798fb34c92--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----9a798fb34c92--------------------------------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://ferneutron.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Fernando L\u00f3pez"}, {"url": "https://ferneutron.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "537 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd606f5d846f2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=post_page-d606f5d846f2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F14c367392dfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fonnx-preventing-framework-lock-in-9a798fb34c92&newsletterV3=d606f5d846f2&newsletterV3Id=14c367392dfa&user=Fernando+L%C3%B3pez&userId=d606f5d846f2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}