{"url": "https://towardsdatascience.com/deep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc", "time": 1683001500.3395882, "path": "towardsdatascience.com/deep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc/", "webpage": {"metadata": {"title": "Deep Multi-Input Models Transfer Learning for Image and Word Tag Recognition | by Yuefeng Zhang, PhD | Towards Data Science", "h1": "Deep Multi-Input Models Transfer Learning for Image and Word Tag Recognition", "description": "With the advancement of deep learning such as convolutional neural network (i.e., ConvNet) [1], computer vision becomes a hot scientific research topic again. One of the main goals of computer vision\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Deep_learning", "anchor_text": "deep learning", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "anchor_text": "convolutional neural network", "paragraph_index": 0}, {"url": "https://neurohive.io/en/popular-networks/vgg16/", "anchor_text": "ConvNet", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Computer_vision", "anchor_text": "computer vision", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Word_embedding", "anchor_text": "word embedding", "paragraph_index": 6}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "NLP", "paragraph_index": 6}, {"url": "https://code.google.com/archive/p/word2vec/", "anchor_text": "word2vec", "paragraph_index": 7}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe", "paragraph_index": 7}, {"url": "https://pypi.org/project/word2vec-keras/", "anchor_text": "word2vec-keras", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural network", "paragraph_index": 7}, {"url": "https://keras.io/examples/lstm_stateful/", "anchor_text": "LSTM", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "NLP", "paragraph_index": 7}, {"url": "https://nanonets.com/blog/ai-in-insurance/", "anchor_text": "insurance claim process automation", "paragraph_index": 8}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning", "paragraph_index": 9}, {"url": "https://neurohive.io/en/popular-networks/vgg16/", "anchor_text": "VGG16", "paragraph_index": 16}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning", "paragraph_index": 47}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning", "paragraph_index": 52}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe: Global Vectors for Word Representation", "paragraph_index": 53}, {"url": "https://towardsdatascience.com/deep-learning-for-natural-language-processing-using-word2vec-keras-d9a240c7bb9d", "anchor_text": "Deep Learning for Natural Language Processing Using word2vec-keras", "paragraph_index": 54}, {"url": "https://github.com/yzzhang/machine-learning/tree/master/deep_learning/multi_input_transfer_learning", "anchor_text": "Github", "paragraph_index": 55}], "all_paragraphs": ["With the advancement of deep learning such as convolutional neural network (i.e., ConvNet) [1], computer vision becomes a hot scientific research topic again. One of the main goals of computer vision nowadays is to use machine learning (especially deep learning) to train computers to gain human-level understanding from digital images, texts, or videos.", "With its widespread use, ConvNet becomes the de facto model for image recognition. As described in [1], generally speaking, there are two approaches for using ConvNet for computer vision:", "As shown in the following diagram, a ConvNet model consists of two parts: a convolutional base and a fully connected classifier.", "Figure 1: Typical scenario of ConvNet transfer learning.", "The ConvNet transfer learning can be further subdivided into three methods:", "Method 2 is used in this article for multi-input models transfer learning.", "The main idea behind transfer learning can be used for not only supervised ConvNet but also other deep learning algorithms such as the unsupervised word embedding models for natural language processing (NLP)[4].", "There are two popular pre-trained word embedding models: word2vec and GloVe [3]. Like the word2vec-keras model used in [4], these pre-trained word embedding models are usually combined with other supervised deep learning algorithms such as the recurrent neural network (RNN) LSTM for NLP such as text classification [4].", "A ConvNet model or a NLP model (e.g., combination of word embedding with LSTM) can be used separately to solve many interesting problems in computer vision and NLP. As to be shown in this article, these different types of models can also be combined in various ways [1] to form more powerful models to address more challenging problems such as insurance claim process automation that require not only the capability of image recognition but also natural language (e.g., texts) understanding.", "This article uses an interesting, but challenging dataset in Kaggle, Challenges in Representation Learning: Multi-modal Learning [2], to present a new multi-input transfer learning model that combines two input models with a fully connected classification layer for both image recognition and word tag recognition at the same time (see Figure 2).", "The main idea behind the new multi-input model is to translate the problem of image and word tag recognition into a machine learning classification problem, that is, determining whether or not a given image matches a given set of word tags (0-No, 1-Yes).", "After the Kaggle dataset of image files and word tag files [2] has been downloaded onto a local machine, the code below can be used to build and shuffle the lists of image file names and related word tag file names. There are 100,000 image files and 100,000 corresponding word tag files in the dataset for training purpose.", "In order to train the new multi-input model on a laptop within a reasonable amount of time (a few hours), I randomly selected 2,000 images and corresponding 2,000 word tag files for model training for this article:", "The code below is to load the 2,000 image tag file names and the corresponding 2,000 word tags into Pandas DataFrame:", "Similarly to [4], a textual data preprocessing procedure is included in the Jupyter notebook [5] to perform minimum data preprocessing such as removing stop words and numeric numbers in case it makes a significant difference:", "As described in [4], the impact of textual data preprocessing is insignificant and thus the raw word tags without preprocessing are used for model training in this article.", "As shown in the diagram below, the new multi-input transfer learning model uses the pre-trained ConvNet model VGG16 for receiving and handling images and a new NLP model (a combination of the pre-trained word embedding model GloVe and Keras LSTM) for receiving and handling word tags. These two input models are merged together first and then combined with a fully connected output classification model that uses both of the image recognition model output and the NLP model output to determine whether or not an input pair of an image and a set of word tags is a match (0-No, 1-Yes).", "Figure 2: The architecture of the new deep learning model for multi-input models transfer learning.", "As shown in Figure 2, the new multi-input transfer learning model uses the pre-trained ConvNet model VGG16 for image recognition. The VGG16 model has already been included in the Keras library. The following code from [1] is used to combine the VGG16 convolutional base with a new fully connected classifier to form a new image recognition input model:", "As shown in Figure 2, the new multi-input transfer learning model uses the pre-trained word embedding model GloVe [3] for converting word tags into compact vectors. Once the GloVe dataset [3] has been downloaded to local machine, the following code from [1] can be used to load the word embedding model into memory:", "As it can be seen in Figure 2, the GloVe word embedding is combined with Keras LSTM to form a new NLP input model for predicting/recognizing word tags:", "Once the new image recognition input model and the new NLP input model have been created, the following code can combine them with a new output classifier into one multi-input transfer learning model:", "As described in [1], both the pre-trained VGG16 convolutional base and the GloVe word embedding layer must be frozen so that the pre-trained weights of those models will not be modified during the new multi-input model training:", "However, regarding the VGG16 convolutional base, it\u2019s interesting to note that I tried both ways (frozen or not frozen), but didn\u2019t see significant difference in terms of model training time or model prediction results.", "The original Kaggle training dataset includes only the correct pairs of images and corresponding word tags. Each of such correct pairs is labeled as 1 (match) in this article (also see the code below). In order to create a balanced dataset, the following code creates 2,000 incorrect pairs of images and word tags in addition to the existing 2,000 correct pairs of images and word tags. For simplicity, this is achieved by pairing each (say Image i) of the selected 2,000 images with the word tags of next image file (i.e., word tags of Image i+1).", "Each of the image word tags needs to be encoded as an integer, and each list/sequence of word tags needs to be converted into a sequence of integer values before the word tags can be consumed by the word embedding model. This is achieved as follows by using and modifying the code in [1]:", "The resulting image and word tag training datasets are converted into Numpy arrays and shuffled for model training:", "The new multi-input model is compiled and trained as follows with only 30 epochs and 4,000 balanced pairs of images and word tags:", "As shown below, the private testing dataset in [2] includes 500 images and each image is associated with two sets of word tags:", "Given an image in the testing dataset, the new multi-input transfer learning model needs to be able to predict which of the given two sets of word tags matches the image.", "The following code is to load the testing images into memory:", "The testing word tags are converted into sequence of encoded integer values as follows:", "The resulting Python arrays of images and word tags are then converted into Numpy arrays and fit into the trained model for prediction:", "The following table shows the first 20 prediction results:", "The following image is Image 201.png in the testing dataset:", "The two associated sets of word tags are as follows:", "The answer with the higher probability of 0.999 is:", "As another positive example, the following is Image 76.png in the testing dataset:", "The following are the associated two sets of word tags:", "The answer with the higher probability of 0.997 is:", "As a false positive example, the following is Image 189.png in the testing dataset:", "The following are the associated two sets of word tags:", "The false positive answer with the higher probability of 0.999 is:", "The testing results above show that even though the new multi-input transfer learning model is trained with only 4,000 pairs of images and word tags and 30 epochs, the model was able to obtain quite reasonable results in terms of accuracy.", "However the model also generated quite some false positives due to model overfit.", "This article presented a new multi-input deep transfer learning model that combines two pre-trained input models (VGG16 and GloVe & LSTM) with a new fully connected classification layer for recognizing images and word tags simultaneously.", "The key point of the new multi-input deep learning method is to translate the problem of image and word tag recognition into a classification problem, that is, determining whether or not a given image matches a given set of word tags (0-No, 1-Yes).", "The challenging public dataset in Kaggle, Challenges in Representation Learning: Multi-modal Learning [2], was used to train and evaluate the new model.", "The model prediction results demonstrated that the new model performed reasonably well with limited model training (only 30 epochs and 4,000 pairs of images and word tags) for demonstration purpose. However, with no surprise, the model also generated quite some false positives due to model overfit. This issue can be addressed by training the model with more epochs and/or more pairs of images and word tags.", "Apparently a random chosen 2,000 training images were not good enough representative of a total of 100,000 available training images. The model performance should be improved significantly by increasing the number of training images from 2,000 to a larger size like 10,000.", "A Jupyter notebook with all of the source code is available in Github [5].", "[1] F. Chollet, Deep Learning with Python, Manning Publications Co., 2018", "[2] Challenges in Representation Learning: Multi-modal Learning", "[3] J. Pennington, R. Socher, C.D. Manning, GloVe: Global Vectors for Word Representation", "[4] Y. Zhang, Deep Learning for Natural Language Processing Using word2vec-keras", "[5] Y. Zhang, Jupyter notebook in Github", "DISCLOSURE STATEMENT: \u00a9 2019 Capital One. Opinions are those of the individual author. Unless noted otherwise in this post, Capital One is not affiliated with, nor endorsed by, any of the companies mentioned. All trademarks and other intellectual property used or displayed are property of their respective owners.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior Data Scientist at Wavicle Data Solutions, He was a Senior Data Scientist at SMS Assist, a Senior Data Engineer at Capital One, and a DMTS at Motorola"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7ae0462253dc&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@zhangyuefeng1?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zhangyuefeng1?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Yuefeng Zhang, PhD"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80e8f2faf4bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&user=Yuefeng+Zhang%2C+PhD&userId=80e8f2faf4bc&source=post_page-80e8f2faf4bc----7ae0462253dc---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://en.wikipedia.org/wiki/Deep_learning", "anchor_text": "deep learning"}, {"url": "https://en.wikipedia.org/wiki/Convolutional_neural_network", "anchor_text": "convolutional neural network"}, {"url": "https://neurohive.io/en/popular-networks/vgg16/", "anchor_text": "ConvNet"}, {"url": "https://en.wikipedia.org/wiki/Computer_vision", "anchor_text": "computer vision"}, {"url": "https://en.wikipedia.org/wiki/Transfer_learning", "anchor_text": "transfer learning"}, {"url": "https://en.wikipedia.org/wiki/Word_embedding", "anchor_text": "word embedding"}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "NLP"}, {"url": "https://code.google.com/archive/p/word2vec/", "anchor_text": "word2vec"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://pypi.org/project/word2vec-keras/", "anchor_text": "word2vec-keras"}, {"url": "https://en.wikipedia.org/wiki/Recurrent_neural_network", "anchor_text": "recurrent neural network"}, {"url": "https://keras.io/examples/lstm_stateful/", "anchor_text": "LSTM"}, {"url": "https://en.wikipedia.org/wiki/Natural_language_processing", "anchor_text": "NLP"}, {"url": "https://nanonets.com/blog/ai-in-insurance/", "anchor_text": "insurance claim process automation"}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning"}, {"url": "https://neurohive.io/en/popular-networks/vgg16/", "anchor_text": "VGG16"}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning"}, {"url": "https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data", "anchor_text": "Challenges in Representation Learning: Multi-modal Learning"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe: Global Vectors for Word Representation"}, {"url": "https://towardsdatascience.com/deep-learning-for-natural-language-processing-using-word2vec-keras-d9a240c7bb9d", "anchor_text": "Deep Learning for Natural Language Processing Using word2vec-keras"}, {"url": "https://github.com/yzzhang/machine-learning/tree/master/deep_learning/multi_input_transfer_learning", "anchor_text": "Github"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----7ae0462253dc---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/convnets?source=post_page-----7ae0462253dc---------------convnets-----------------", "anchor_text": "Convnets"}, {"url": "https://medium.com/tag/word-embeddings?source=post_page-----7ae0462253dc---------------word_embeddings-----------------", "anchor_text": "Word Embeddings"}, {"url": "https://medium.com/tag/lstm?source=post_page-----7ae0462253dc---------------lstm-----------------", "anchor_text": "Lstm"}, {"url": "https://medium.com/tag/transfer-learning?source=post_page-----7ae0462253dc---------------transfer_learning-----------------", "anchor_text": "Transfer Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&user=Yuefeng+Zhang%2C+PhD&userId=80e8f2faf4bc&source=-----7ae0462253dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&user=Yuefeng+Zhang%2C+PhD&userId=80e8f2faf4bc&source=-----7ae0462253dc---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F7ae0462253dc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----7ae0462253dc---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7ae0462253dc--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----7ae0462253dc--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----7ae0462253dc--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zhangyuefeng1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@zhangyuefeng1?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yuefeng Zhang, PhD"}, {"url": "https://medium.com/@zhangyuefeng1/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "293 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F80e8f2faf4bc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&user=Yuefeng+Zhang%2C+PhD&userId=80e8f2faf4bc&source=post_page-80e8f2faf4bc--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F84632d34eae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeep-multi-input-models-transfer-learning-for-image-and-word-tag-recognition-7ae0462253dc&newsletterV3=80e8f2faf4bc&newsletterV3Id=84632d34eae6&user=Yuefeng+Zhang%2C+PhD&userId=80e8f2faf4bc&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}