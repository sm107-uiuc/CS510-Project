{"url": "https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c", "time": 1683001860.0764842, "path": "towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c/", "webpage": {"metadata": {"title": "The art of joining in Spark. Practical tips to speedup joins in\u2026 | by Andrea Ialenti | Towards Data Science", "h1": "The art of joining in Spark", "description": "Performance optimization, in Apache Spark, can be challenging. In this article I focus on some practical tips to improve Joins performance."}, "outgoing_paragraph_urls": [{"url": "https://amzn.to/39TIOYN", "anchor_text": "Spark: The Definitive Guide", "paragraph_index": 0}, {"url": "https://amzn.to/39TIOYN", "anchor_text": "US", "paragraph_index": 0}, {"url": "https://amzn.to/2K82rBO", "anchor_text": "UK", "paragraph_index": 0}, {"url": "https://databricks.com/speaker/bill-chambers", "anchor_text": "Bill Chambers", "paragraph_index": 0}, {"url": "https://databricks.com/speaker/matei-zaharia", "anchor_text": "Matei Zaharia", "paragraph_index": 0}, {"url": "https://0x0fff.com/spark-memory-management/", "anchor_text": "brief article about Spark memory", "paragraph_index": 16}], "all_paragraphs": ["I\u2019ve met Apache Spark a few months ago and it has been love at first sight. My first thought was: \u201cit\u2019s incredible how something this powerful can be so easy to use, I just need to write a bunch of SQL queries!\u201d. Indeed starting with Spark is very simple: it has very nice APIs in multiple languages (e.g. Scala, Python, Java), it\u2019s virtually possible to just use SQL to unleash all of its power and it has a widespread community and tons of documentation. My starting point has been a book, Spark: The Definitive Guide (<- affiliate link US, UK), I believe it\u2019s a good introduction to the tool: it is authored by Bill Chambers (Product Manager at Databricks) and Matei Zaharia (Chief Technologist at Databricks and creator of Spark).", "Very soon I realized that things are not that easy as I used to believe. And that same discovery is probably the reason why you landed on this article. For example, I would bet that you will find the following image quite familiar:", "As you may already know the above is a typical manifestation of data skewness during a join operation: one task will take forever to complete just because all the effort of the join is put on a single executor process.", "Looking at what tables we usually join with Spark, we can identify two situations: we may be joining a big table with a small table or, instead, a big table with another big table. Of course, during Spark development we face all the shades of grey that are between these two extremes!", "Sticking to use cases mentioned above, Spark will perform (or be forced by us to perform) joins in two different ways: either using Sort Merge Joins if we are joining two big tables, or Broadcast Joins if at least one of the datasets involved is small enough to be stored in the memory of the single all executors. Note that there are other types of joins (e.g. Shuffle Hash Joins), but those mentioned earlier are the most common, in particular from Spark 2.3.", "When Spark translates an operation in the execution plan as a Sort Merge Join it enables an all-to-all communication strategy among the nodes: the Driver Node will orchestrate the Executors, each of which will hold a particular set of joining keys. Before running the actual operation, the partitions are first sorted (this operation is obviously heavy itself). As you can imagine this kind of strategy can be expensive: nodes need to use the network to share data; note that Sort Merge Joins tend to minimize data movements in the cluster, especially compared to Shuffle Hash Joins.", "Broadcast joins happen when Spark decides to send a copy of a table to all the executor nodes. The intuition here is that, if we broadcast one of the datasets, Spark no longer needs an all-to-all communication strategy and each Executor will be self-sufficient in joining the big dataset records in each node, with the small (broadcasted) table. We\u2019ll see that this simple idea improves performance\u2026 usually.", "Some of the biggest villains that we may face during join operations are:", "An important note before delving into some ideas to optimize joins: sometimes I will use the execution times to compare different join strategies. Actually, a lower absolute execution time does not imply that one method is absolutely better than the other. Performance also depends on the Spark session configuration, the load on the cluster and the synergies among configuration and actual code. So, read what follows with the intent of gathering some ideas that you\u2019ll probably need to tailor on your specific case!", "First of all, let\u2019s see what happens if we decide to broadcast a table during a join. Note that the Spark execution plan could be automatically translated into a broadcast (without us forcing it), although this can vary depending on the Spark version and on how it is configured.", "We will be joining two tables: fact_table and dimension_table. First of all, let\u2019s see how big they are:", "In this case, the data are not skewed and the partitioning is all right \u2014 you\u2019ll have to trust my word. Note that the dimension_table is not exactly \u201csmall\u201d (although size is not information that we can infer by only observing the number of rows, we\u2019d rather prefer to look at the file size on HDFS).", "By the way, let\u2019s try to join the tables without broadcasting to see how long it takes:", "Now, what happens if we broadcast the dimension table? By a simple addition to the join operation, i.e. replace the variable dimension_table with broadcast(dimension_table), we can force Spark to handle our tables using a broadcast:", "The broadcast made the code run 71% faster! Again, read this outcome having in mind what I wrote earlier about absolute execution time.", "Is broadcasting always good for performance? Not at all! If you try to execute the snippets above giving more resources to the cluster (in particular more executors), the non-broadcast version will run faster than the broadcast one! One reason why this happens is because the broadcasting operation is itself quite expensive (it means that all the nodes need to receive a copy of the table), so it\u2019s not surprising that if we increase the amount of executors that need to receive the table, we increase the broadcasting cost, which suddenly may become higher than the join cost itself.", "It\u2019s important to remember that when we broadcast, we are hitting on the memory available on each Executor node (here\u2019s a brief article about Spark memory). This can easily lead to Out Of Memory exceptions or make your code unstable: imagine to broadcast a medium-sized table. You run the code, everything is fine and super fast. A couple of months later you suddenly find out that your code breaks, OOM. After some hours of debugging, you may discover that the medium-sized table you broadcast to make your code fast is not that \u201cmedium\u201d anymore. Takeaway, if you broadcast a medium-sized table, you need to be sure it will remain medium-sized in the future!", "Skewness is a common issue when you want to join two tables. We say a join is skewed when the join key is not uniformly distributed in the dataset. During a skewed join, Spark cannot perform operations in parallel, since the join\u2019s load will be distributed unevenly across the Executors.", "Let\u2019s take our old fact_table and a new dimension:", "Great our dimension_table2 is very small and we can decide to broadcast it straightforward! Let\u2019s join and see what happens:", "Now, observe on the SparkUI what happened to the tasks during the execution:", "As you can see in the image above, one of the tasks took much more time to complete compared to the others. This is clearly an indication of skewness in the data \u2014 and this conjecture would be easily verifiable by looking at the distribution of the join key in the fact_table.", "To make things work, we need to find a way to redistribute the workload to improve our join\u2019s performance. I want to propose two ideas:", "We can select a column that is uniformly distributed and repartition our table accordingly; if we combine this with broadcasting, we should have achieved the goal of redistributing the workload:", "Note that we want to choose a column also looking at the cardinality (e.g. I wouldn\u2019t choose a key with \u201ctoo high\u201d or \u201ctoo low\u201d cardinality, I let you quantify those terms).", "Important note: if you cannot broadcast the dimension table and you still want to use this strategy, the left side and the right side of the join need to be repartitioned using the same partitioner! Let\u2019s see what happens if we don\u2019t.", "Consider the following snippet and let\u2019s look at the DAG on the Spark UI", "As you can see, it this case my repartitioning is basically ignored: after it is performed, spark still decides to re-exchange the data using the default configuration. Let\u2019s look at how the DAG changes if we use the same partitioner:", "Another strategy is to forge a new join key!", "We still want to force spark to do a uniform repartitioning of the big table; in this case, we can also combine Key salting with broadcasting, since the dimension table is very small.", "The join key of the left table is stored into the field dimension_2_key, which is not evenly distributed. The first step is to make this field more \u201cuniform\u201d. An easy way to do that is to randomly append a number between 0 and N to the join key, e.g.:", "As you can see we modified the dimension_2_key which is now \u201cuniformly\u201d distributed, we are on the right path to a better workload on the cluster. We have modified the join key, so we need to do the same operation on the dimension table. To do so, we create for each \u201cnew\u201d key value in the fact table, a corresponding value in the dimension: for each value of the id in the dimension table we generate N values in which we append to the old ids the numbers in the [0,N] interval. Let\u2019s make this clearer with the following image:", "At this point, we can join the two datasets using the \u201cnew\u201d salted key.", "This simple trick will improve the degree of parallelism of the DAG execution. Of course, we have increased the number of rows of the dimension table (in the example N=4). A higher N (e.g. 100 or 1000) will result in a more uniform distribution of the key in the fact, but in a higher number of rows for the dimension table!", "First, we need to append the salt to the keys in the fact table. This is a surprisingly challenging task, or, better, it\u2019s a decision point:", "Just for fun, let\u2019s go with this third option (it also appear to be a bit faster)", "Now we need to \u201cexplode\u201d the dimension table with the new key. The fastest way that I have found to do so is to create a dummy dataset containing the numbers between 0 and N (in the example between 0 and 1000) and cross-join the dimension table with this \u201cdummy\u201d dataset:", "Finally, we can join the tables using the salted key and see what happens!", "Again, execution time is not really a good indicator to understand our improvement, so let\u2019s look at the event timeline:", "As you can see we greatly increased the parallelism.", "In this case, a simple repartitioning plus broadcast, worked better than crafting a new key. Note that this difference is not due to the join, but to the random number generation during the fact table lift.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "I\u2019m a Data Scientist, I usually ride a giant unicorn with a rainbow mane. I love learning by explaining. \u201cLike a bicycle I need to move to keep my balance\u201d."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdcbd33d693c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Andrea Ialenti"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc4f0dc70838c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&user=Andrea+Ialenti&userId=c4f0dc70838c&source=post_page-c4f0dc70838c----dcbd33d693c---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://amzn.to/39TIOYN", "anchor_text": "Spark: The Definitive Guide"}, {"url": "https://amzn.to/39TIOYN", "anchor_text": "US"}, {"url": "https://amzn.to/2K82rBO", "anchor_text": "UK"}, {"url": "https://databricks.com/speaker/bill-chambers", "anchor_text": "Bill Chambers"}, {"url": "https://databricks.com/speaker/matei-zaharia", "anchor_text": "Matei Zaharia"}, {"url": "https://0x0fff.com/spark-memory-management/", "anchor_text": "brief article about Spark memory"}, {"url": "https://towardsdatascience.com/six-spark-exercises-to-rule-them-all-242445b24565", "anchor_text": "Six Spark Exercises to Rule Them AllSome challenging Spark SQL questions, easy to lift-and-shift on many real-world problems (with solutions)towardsdatascience.com"}, {"url": "https://towardsdatascience.com/clustering-pollock-1ec24c9cf447", "anchor_text": "Clustering PollockA cluster analysis on Jackson Pollock's paintings: how to use k-means to group colorstowardsdatascience.com"}, {"url": "https://medium.com/tag/big-data?source=post_page-----dcbd33d693c---------------big_data-----------------", "anchor_text": "Big Data"}, {"url": "https://medium.com/tag/apache-spark?source=post_page-----dcbd33d693c---------------apache_spark-----------------", "anchor_text": "Apache Spark"}, {"url": "https://medium.com/tag/scala?source=post_page-----dcbd33d693c---------------scala-----------------", "anchor_text": "Scala"}, {"url": "https://medium.com/tag/sql?source=post_page-----dcbd33d693c---------------sql-----------------", "anchor_text": "Sql"}, {"url": "https://medium.com/tag/data-science?source=post_page-----dcbd33d693c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----dcbd33d693c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&user=Andrea+Ialenti&userId=c4f0dc70838c&source=-----dcbd33d693c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdcbd33d693c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----dcbd33d693c---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----dcbd33d693c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----dcbd33d693c--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----dcbd33d693c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@andrea.ialenti?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Andrea Ialenti"}, {"url": "https://medium.com/@andrea.ialenti/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "543 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc4f0dc70838c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&user=Andrea+Ialenti&userId=c4f0dc70838c&source=post_page-c4f0dc70838c--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F38edc5d7a9a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-art-of-joining-in-spark-dcbd33d693c&newsletterV3=c4f0dc70838c&newsletterV3Id=38edc5d7a9a0&user=Andrea+Ialenti&userId=c4f0dc70838c&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}