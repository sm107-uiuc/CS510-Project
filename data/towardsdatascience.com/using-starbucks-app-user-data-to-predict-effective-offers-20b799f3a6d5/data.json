{"url": "https://towardsdatascience.com/using-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5", "time": 1682994175.29297, "path": "towardsdatascience.com/using-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5/", "webpage": {"metadata": {"title": "Using Starbucks app user data to predict effective offers | by Syuen Loh | Towards Data Science", "h1": "Using Starbucks app user data to predict effective offers", "description": "The business motivation behind these 2 questions are two fold: firstly, from the business perspective, Starbucks can better target their offers towards customers with higher propensity to take up the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/syuenloh/UdacityDataScientistCapstone", "anchor_text": "Github repo", "paragraph_index": 18}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/", "anchor_text": "here", "paragraph_index": 129}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)", "anchor_text": ")", "paragraph_index": 129}, {"url": "https://github.com/syuenloh/UdacityDataScientistCapstone", "anchor_text": "here", "paragraph_index": 193}], "all_paragraphs": ["In my capstone project, I aim to answer 2 main business questions:", "The business motivation behind these 2 questions are two fold: firstly, from the business perspective, Starbucks can better target their offers towards customers with higher propensity to take up the offers. In doing this, they have the potential to maximize on revenues obtained from offer take up to the right customers, and saving on marketing and promotional costs by sending more relevant offers.", "Secondly, from the customer point of view, the customer gets a better experience with Starbucks and on the app, as they will be receiving personalized, relevant offers to their tastes.", "This capstone project is using data provided by Udacity as part of the Data Scientist Nanodegree course. It contains simulated data that mimics customer behavior on the Starbucks rewards mobile app.", "The provided background information on the mobile app is that once every few days, Starbucks sends out an offer to users of the mobile app. Some users might not receive any offer during certain weeks, and not all users receive the same offer.", "As stated above, the problem statement I am aiming to answer are to (1) discover the main drivers of offer effectiveness, and (2) explore if we can predict whether a user would take up an offer.", "The data provided consists of 3 datasets:", "Using the data provided, I answer the above two questions using 3 classification supervised machine learning models, feeding in the data from three different offer types.", "I use the model to uncover the feature importances to identify the drivers of offer effectiveness, while exploring if the model itself could be used to predict if a user would take up an offer.", "Lastly, I also explore the characteristics of users who do or do not take up an offer.", "My project aims to answer the two questions above, but I also ended up adding 2 additional models as points of exploration which will be expounded in Part 4 \u2014 the first, assessing whether an all-in-one model could be used in place of 3 different models, with the offer types functioning as a categorical variable. Secondly, I also build a regression model to see if we could predict the amount a user would spend, given that the offer is effectively influencing them.", "If I am able to successfully implement the models above, my expected solution would be to find the drivers of the effective offers, which could be demographic attributes of the users, for example the membership tenure of the user.", "Ideally, a successful model would also be able to predict the propensity of a user to take up an offer with at least 75% accuracy. That would be my benchmark accuracy for the 3 models I plan to implement.", "To assess the performance of my models, the metrics I will be using is accuracy, with F1 score to compare against, as these are classification models.", "F1 score provides a better sense of model performance compared to purely accuracy as takes both false positives and false negatives in the calculation. With an uneven class distribution, F1 may usually be more useful than accuracy.", "It is worth noting in this case that the F1 score is based on the harmonic mean of precision and recall, and focuses on positive cases. For the Starbucks app here, it would be fine as we would prioritise more on whether offers are effective, and less focus on why offers are ineffective.", "Meanwhile, accuracy provides a good overall metric to assess my model performance, and would be sufficient for the purposes of predicting the propensity of a user taking up the offer as we will not be too worried about the negatively classified cases. In fact, for business purposes, we may allow some misclassified negative cases, as we may rather grab the possible sale of product via the incentive of the offer, rather than allow a missed opportunity.", "With that, I will explain my project in the following sections:", "Although I will delve into my code output if required for understanding on how I implemented this project, I will not delve into the nitty gritty every step of the way. For more details on that, you can check my Github repo which contains the Jupyter Notebook of the project.", "According to the information provided by Udacity, the schema is as follows:", "Moreover, some further information given about the offers is that there are 3 different offer types:", "Thus, the schema is pretty straightforward, as it contains the attributes of 3 different offer types. While the duration was not explained I assumed from context that it is in terms of number of days.", "After taking a snapshot view of the data, I noted some key elements to do data cleaning during the preprocessing stage. Among them:", "Demographic data for customers is provided in the profile dataset. The schema and variables are as follows:", "It is also relatively straightforward, as it contains the demographic profile on the customer.", "I did some data visualization of the income column and found some further data preprocessing steps required.", "The schema for the transactional data is as follows:", "This data looks a bit more tricky, as it is ordered by time and has an event and value. In particular, the value column will have to be preprocessed depending on the event.", "I also found that the number of people (i.e. number of unique IDs) in transcript are the same as the number of people in the Demographics Data, so that is good news. But a lot of preprocessing will need to be done in order to extract meaningful insights out of this dataset.", "Now I do a bit of data cleaning for the transcript dataset. In order to extract insights from the value column, I expanded the values into individual columns depending on the event. With that, I end up with a clean transcript dataset to be analysed further.", "Before I proceeded to preprocess the data for the model, I first revisited my objective. Having done a preliminary exploration of the data, I had to reassess how I would clean and prepare the data for the models I intended to build.", "In order to identify the main drivers of an effective offer, I have to first define what an \u2018effective\u2019 offer is within the Starbucks app. Thus, I did some further exploration on the datasets and how all three would interact.", "First, I explored the kinds of events within each offer type.", "We know that there are 4 types of events: offer completed, offer received, offer viewed and transaction. But our data shows that we do not have any offer_id associated with transactions, because they are not recorded in the transcript event data. Thus, the first objective in data preprocessing is to define a methodology to assign offer_ids to specific transactions.", "Moreover, we also know that BOGO and discount offers have an offer completed event when offers are completed. However, informational offers do not have this event associated with it. Thus, we also specify the approach to define an effective offer as follows:", "For a BOGO and discount offer, an effective offer would be defined if the following events were recorded in the right sequence in time:", "offer received -> offer viewed -> transaction -> offer completed", "Meanwhile, for an informational offer, since there offer completed event associated with it, I will have to define transactions as a conversion to effective offer:", "offer received -> offer viewed -> transaction", "After defining the approach above, we now have to explore methods to assign offer_ids to specific transactions. Among the considerations is to define the following main groups of customers:", "2. People who received and viewed an offer but did not successfully convert \u2014 ineffective offers:", "3. People who purchase/complete offers regardless of awareness of any offers:", "4. People who received offers but no action taken:", "For people in group 2, I would need to check if there are events where there is an offer received and offer viewed event, but no conversion event, i.e. offer completed or transaction - these are cases of ineffective offers.", "I would have to separate out the people in group 2 from people in group 4, as people in group 2 may have viewed an offer but did not take any action, whereas people in group 4 did not even have an offer viewed event.", "Separating the conversions for effective offers (group 1) and people who purchase/complete offers regardless of awareness of any offers (group 3) is particularly tricky. For people in group 3, a conversion is invalid (i.e., not a successful conversion from an offer) if an offer completed or transactionoccurs before an offer viewed. There also may be scenarios where an offer completed occurs after the offer is viewed, but a transaction was done prior to the offer being viewed. In this instance, the offer may have been completed, but it is also not a valid conversion.", "Defining the target variable effective offer:", "After defining these conditions, we have to decide what the target variable will be.", "We know that group 1 customers will be our target variable effective_offer=1, but there are many ineffective offer definitions for groups 2-4.", "So what would we define as an ineffective offer? As already stated above, group 2 would be within our definition of an ineffective offer; where a user is aware of an offer, but the offer is ineffective as it does not convert the user into a customer. So group 2 can be defined as our target variable effective_offer=0.", "What about group 3 and group 4? Group 3 consists of users who may have received offers but would have purchased regardless. From the business point of view, we would not want to be sending them any offers.", "Meanwhile, group 4 users would be considered low priority customers, as they do not do any action, regardless of whether they receive offers or not.", "So, we can deprioritise group 3 and group 4 users from our model. It would still be worth doing some exploratory analysis onto group 3 and 4, just to explore on their demographics.", "The conditions above are the basis of which I can assign the offer id that \u2018influences\u2019 a transaction by ensuring that the transaction occurs after an offer viewed event.", "Any unique person-offer_id belonging to group 1 can thus be considered in our target variable effective_offer=1 group.", "Meanwhile, group 2 is in our target variable effective_offer=0 group. For customers in groups 3 and 4, I deprioritise them for model implementation, but will be doing some exploratory analysis on them later in Part 4.", "As such, I created a dataset for each offer type consisting of both effective and ineffective offers by appending group 1 and group 2 customer datasets together, and successfully prepared the target variables for our BOGO and discount datasets.", "Meanwhile, for informational offers in particular, before we can tag the effective offers column, there is an additional consideration \u2014 the validity of the offer. This is because the conversion event is not an offer completed event, but a transaction.", "For informational offers, the duration of the offer can be considered to be the duration of the influence. Hence, we can make the assumption that an offer should only be considered effective if it is within the duration of the offer.", "Meanwhile, for BOGO and discount offers, we can assume that if there is a conversion/ offer completed event, it should be within duration as it would not make sense for an offer to be completed if an offer is past its validity period.", "Now we have to look back had to look into the features and see how to be creative in creating new features.", "d.i. became_member_on column to be engineered", "Recalling my preliminary data exploration steps, the became_member_on column were in date format. Hence in order to extract meaningful insights from that feature, we can convert it as a feature indicating tenure of membership. There could be some influence in how long someone has been a member, with whether he takes up an offer.", "Thus, I extracted the membership tenure of each person in days from the became_member_on column, using 2018 as the current year.", "As part of some further data exploration, I discovered that there could be multiple offers received per person.", "We can see above that the offer received per person in the transactional data could range from 1 to 6 offers received. I had the hypothesis that the frequency of offers received per person might result in more effective offers, so decided to engineer a feature offer_received_cnt to account for this frequency.", "d.ii. Separating user behaviours by transactions", "I also wondered how many transactions were considered \u2018invalid\u2019 by my definition. Ordinarily, these would be the sum of transactions done by people not in group 1. The objective of offers are to drive purchases, so it would already be the case that users with high spend in their transactions would be flagged as effective_offers.", "We\u2019ve already defined that there are people in groups 3 and 4, where they are separate pools of users who are loyal spenders, and already tend to purchase more, isolated from the the effect of offers.", "But for users in group 1 have a high amount of \u2018invalid spend\u2019 outside of the effect of offers, there might be some predictive power onto the effectiveness of offers; since a loyal user might have a higher tendency of taking up an offer.", "The logic is to wonder if there is some baseline level of spending for users who are highly influenced by certain offers (in group 1), and group 2, and if there is some predictive power in this baseline level of \u2018invalid transactions\u2019 that can predict the propensity of a user to take up an offer.", "Thus, I calculated the \u2018invalid\u2019 transactions for each person as an additional feature.", "However, in doing so I found out that the missing values were quite extensive in this engineered feature column.", "Because of the sparsity, it is debatable whether this column amount_invalid would be useful to include in the model. Since it is so 'sparse', it might not have much information after all. I plan to assess this feature again later during the model implementation phase. For now, I decided to fill the missing amount_invalid column with 0 as it could represent that only 4% of the overall users tend to purchase without offers; the other 96% would only purchase with awareness of an ongoing offer.", "Meanwhile, we had already conducted the analysis above on the income and gender columns, which I had already chosen to drop as they are not useful when they are null, and they only make up 7% of the dataset.", "d. iii. Time elapsed between offers received", "I also wanted to include time as a potential feature into my dataset, but since the transactional data starts from time=0, I suspected it would not have been of much predictive power without some feature engineering. I had the hypothesis that if there were multiple offers received per person within a certain time period, there might be some predictive power in the time elapsed between offers received.", "Now that the datasets are ready, we can proceed to implement the model. Revisiting our objective, we wanted to analyse the drivers of an effective offer, with the target variable being effective_offer.", "Since we have 3 offer types, there are thus 3 different models to be built. Since we are predicting whether an offer would be effective or not, this is effectively a binary classification supervised learning model.", "I decided to compare the performance of a simple decision tree classifier model as a baseline model, with an ensemble random forest classifier model. Reason why I selected a decision tree as the baseline model is because I wanted to prioritise the interpretability of the model. Going back to the objective, since we intend to analyse the feature importance to determine the drivers of an effective offer, a decision tree would provide good interpretability for us to analyse.", "Meanwhile, I also selected random forest as an alternate model to compare the baseline model is as an improvement over simple ensemble bagging of decision trees, in order to drive towards a high accuracy in training the model.", "Before we can proceed, we have to make sure that the classes we are predicting for are balanced in each dataset.", "We can see that the classes are quite uneven for all three offer types, but not too imbalanced such that it would pose a problem. Hence, we can proceed to implement the models.", "A note on model evaluation and validation; since the classes for the all 3 models are imbalanced, I decided to implement both accuracy and f1 score as the model evaluation metric, as already mentioned earlier.", "Revisiting our objective, we are creating 3 models to predict the effectiveness of an offer within each type, depending on offer attributes and user demographics.", "I performed the usual required steps for modeling:", "I defined model pipeline functions to implement my model as I plan to implement 3 different models; hence it would be easier to implement repeatedly.", "I used a DecisionTree Classifier as my baseline model and a Random Forest classifier with randomly assigned parameters to compare the performance.", "The accuracy for Random Forest Classifier (RF) model actually ends up outperforming the Decision Tree Classifier (DT) model slightly, but overall the performance for both models is about the same (82.14% vs 81.77% respectively in terms of accuracy). Accuracy for a first attempt is quite good, more than 80%. I will try to tune the model further to get a better accuracy.", "However, in terms of the F1 score, both models are below 80%, with the Random Forest model performing worse compared to the Decision Tree Classifier, with 75.91% vs. 79.63%. To analyse this, we have to refer to the formula for Precision, Recall and F1 score:", "Recall or Sensitivity or TPR (True Positive Rate):", "According to sklearn documentation, the recall is intuitively the ability of the classifier to find all the positive samples.", "Number of items correctly identified as positive out of total true positives: True Positives /(True Positives +False Negatives)", "According to the sklearn documentation, it is intuitively the ability of the classifier not to label as positive a sample that is negative.", "Number of items correctly identified as positive out of total items identified as positive: True Positives /(True Positives + False Positives)", "Since my F-beta score is F1 with beta=1, I am weighting recall and precision as equally important.", "The formula is given by the harmonic mean of precision and recall: F1 = 2*Precision*Recall/(Precision + Recall)", "We can see that the F1 scores for DT outperformed RF slightly, but both are lower than the accuracy. This would indicate that DT model is doing slightly better compared to RF at not misclassifying negative events as positive (meaning, misclassifying people on which offers are ineffective, as people on which offers would be effective).", "The difference in F1 score vs accuracy indicate that there could are instances where both models are falsely classifying negatives as positives, likely due to the imbalance of classes. But the overall higher recall/accuracy compared to F1 score indicates that the model is predicting the positive case (i.e. where an offer is effective) more accurately compared to predicting the negative cases (i.e. where an offer is ineffective), which is expected given the uneven classes..", "However, revisiting our use case, we are perhaps not as concerned with these misclassification since we don\u2019t mind sending people more offers than they would have liked; we would rather not miss anyone on which an offer would have been effective.", "Given this case, I will still go with the RF model.", "Since I aim to analyse the drivers of an effective offer, I will check the feature importances for the models after I have selected the best model from refinement.", "I repeat the same steps above but with my offer_discounts dataset.", "This time, the Random Forest Classifier model also has a better performance compared to the Decision Tree Classifier in terms of accuracy (87.23% vs 86.72%), and the F1 score is also lower (81.43% vs 82.87%).", "The F1 score for these models are lower overall compared to the Accuracy score. This could be an indication that there are some instances where both models are classifying the negative cases (effective_offer = 0) falsely. Again, I am not too bothered by this as I am more concerned with the model predicting positive cases accurately, so would rather go with a higher accuracy model where F1 score for cases effective_offer=1 is higher, for which our RF classifier has better performance (0.9317 vs 0.9280).", "Repeating the steps above for offers_info dataset:", "The performance for these models are worse compared to the other 2 datasets, with accuracy below 80% for both models, but RF model still performing better. The F1 score is also worse, at 67.54% RF Classifier, worse than the DT model at 68.66%.", "One potential reason for the worse performance is perhaps due to the fact that I had the key assumption to assign the conversion events to be transactions that only occur after an offer is viewed and within the specified duration; I might have missed out on some valuable information by removing those transactions that occur regardless. We can see this from how the overall sample dataset is smaller (about half) the datasets for the other 2 offers, with only about 5K samples compared to about 10K for both BOGO and discount respectively.", "In refining the model, I will first try parameter tuning for the 3 RF models, before experimenting with removing or adding features to improve model performance.", "b. i. Grid Search to discover optimal parameters", "I decided to do GridSearch to determine what would be the optimal parameters for the model.", "For all three offers, the Random Forest model had relatively good performance, so I used Grid Search on this to determine the best parameters.", "When I reran the model for BOGO dataset with the optimal parameters, I obtained the following results:", "The accuracy for the RF model increased slightly \u2014 from 82.14% to 82.51%, and the F1 score increased from 75.91% to 77.64%. This is a good performance increase but minimal, which indicates that perhaps there\u2019s not much that can be done to improve the performance of the model with parameter tuning.", "So I will have to explore other avenues with the features to improve the performance of the model further.", "Meanwhile, for the discount dataset, running GridSearchCV obtained the following parameters:", "Implementing the model with these parameters obtained the following results:", "The accuracy of the model increaased slightly, from 87.23% to 87.47%, and the F1 score improved from 81.43% to 82.06%. The good thing is that now both the accuracy and the F1 score for the RF model is better than the DT model.", "But because the increase was minimal, again we can conclude that tuning the parameters won\u2019t really improve the performance of the model significantly.", "Finally, for the informational offers dataset, running GridSearch obtained the following params:", "Again we see some improvement in accuracy for RF model, from 75.09% to 75.30%, and slight increase in F1 score from 67.54% to 67.78%. This improvement is minimal,so we look into improving the feature selection of the model.", "b.ii Removing sparse features e.g. amount_invalid", "In terms of feature selection, I wanted to try and see if removing the amount_invalid variable, which we had noted as being sparse, hence may not be useful in predicting the effectiveness of offers, would help.", "I removed the feature from my data prep and retrained the model using the same optimal parameters found via GridSearch, with the DT model as a baseline.", "Model accuracy and F1 score did improve, so I will leave the amount_invalid feature out of my model.", "Accuracy of the model actually increased while F1 model remained the same. In this case, I will also remove the amount_invalid feature for the discount model.", "Accuracy of the model actually decreased here for info model, so I will also keep the feature in. This is expected since the model had already a worse performance compared to the other 2 models, so the model is slightly underfitting compared to the others. Hence the model needs more features to learn to predict better.", "b. iii. Dropping one level of dummy variables/one-hot encoding", "There is a debate when using tree models and using regression models when it comes to one hot encoding. For regression classification models (e.g. logistic regression, we should typically remove one level of the variable in order to prevent multicollinearity between variables. Typically, we should not run into this issue with tree-based models like the ones I am using here.", "However, there is some debate as to whether one should do it or not. According to some articles (like here), it is generally not advisable to encode categorical variables as they would generate sparse matrices, resulting in:", "In scikitlearn implementations of RF and DT, one has to encode the variables. So I decided to test my model performance if I were to drop one level of my categorical variables (in my data \u2014 the channel variables and the gender variables), just to reduce the sparsity and noise in the data for my model.", "However, I found that overall, there is not much improvement in model performance just by reducing one level of categorical features.", "Although all three models had met my benchmark rate of 75%, especially the BOGO and discount models, I wanted to explore if I can improve the performance of the info model.", "I will leave the BOGO and discount models aside for now, as I was satisfied with the performance of the model.", "Since a low accuracy score for the info model is likely due to the model underfitting, I decided to attempt if transforming the features further might improve model performance. I applied a polynomial feature transform to my variables in the info model to check the model performance.", "We can see that performance actually decreased slightly for the RF model. Hence it would perhaps be a better idea to just keep the model as is. A maximum accuracy of 75.30% is acceptable for the info offers, even though it is not as high as the BOGO or discount offers. After all, we already included some assumptions for the \u2018influence\u2019 of the offer based on the duration.", "Plotting the training and test accuracy for the RF info models so far yields the following chart:", "We can see above that the model is performing better in the training accuracy as we add more variables for each model via polynomial features and removing the amount_invalid feature. It is just that the testing accuracy was reducing, and we can see this is due to overfitting.", "I can improve the accuracy and performance of the info model further by using RF info model 5, but adding more data, as we already noted the dataset for the offers_info dataset is half the size of the BOGO and discount datasets. Hence, ultimately with more data and with performance tuning, removing unnecessary variables and feature transformation, with more data I could have ultimately got the performance of the model perhaps above 80%.", "b.iv. Discussion on best models and feature importances", "Now that I am done with refining the 3 models, we can check the results for our best models for all 3 and check the feature importances to see the top drivers of effectiveness of offers. Using my best_model function, I get the below dataframe of the results:", "Overall, we can see that the top performing models are the 3rd model (with GridSearch to find optimal model parameters and removing amount_invalid column) for predicting effectiveness of BOGO and discount offers, whereas the best performing model for informational offers was just after performing GridSearch to find the optimal parameters.", "In order to find the most influential drivers of an effective offer, we can check the feature importances of our best models above.", "Checking on the feature importance to analyse the main drivers of an effective offer, we can see that the most important driver of effective offers across all three are the tenure of membership. However, the 2nd most important feature is different for each of the three models.", "For a BOGO offer, the membership tenure is the most important feature, and the other variables are a lot smaller in proportions. Income, age and offer_received_cnt are the 2nd, 3rd and 4th most important features, but their proportions are very small.", "For a discount offer, after the membership tenure, age and income are the next most important variables. But it is still very small in proportions.", "The feature importances for the informational offer models are more distributed compared to the BOGO and discount models, with income being the 2nd most important feature. Age is the third and mobile channel interestingly being the 4th.", "We had earlier delineated those in groups 3 and 4 as people who would purchase regardless of viewing any offers. Now we can do some exploratory analyses to see what kind of demographic this group of users consist of.", "It would be interesting to see how people in groups 3 and 4 contrast with people in groups 1 and 2, so I decided to compare between all 3.", "I appended the data from all groups from the three offer types together, then compare the characteristics of each group via visualizations.", "I also cleaned the dataset of null values, similar to the preparation of the datasets above for modeling.", "Comparing the sizes of the 3 groups, we can see that group 1 is the largest, while group 2 is the smallest, which is unsurprising as we had seen that the classes in our datasets were imbalanced in favour of positive classes (i.e. effective_offers=1). Meanwhile for people in groups 3 and 4 there are quite a significant number of people as well, larger than the number of people in group 2.", "Meanwhile, in order to effectively compare between the groups, I visualized the groups together.", "First, we can explore the income distribution between the 3 groups.", "Across the 3 segments, most people fall within the middle range of income (50K \u2014 100K). The income distribution between the 3 segments are relatively similar.", "Age distribution looks relatively similar between the 3 groups as well, with most people between the age 40\u201380 years old.", "Group 2 are people who did not spend at all as the offers were ineffective on them, hence they are not in the graph. But for groups 1 and 3+4, we can see that the amount spent is relatively similar, except that people in group 1 spent slightly more. This is to be expected as we might expect that the offers managed to incentivise them to purchase more, hence their overall spend increased.", "The distribution of membership tenure also looks similar between the 3 segments, with most people between 0\u2013700 days of tenure. It appears as though there are not much demographic characteristic differences between the 3 groups, at least in the current data provided.", "Out of curiosity, I wondered if we could predict the effectiveness of an offer if the offer type was included as a categorical feature. Would the type of offer affect the user\u2019s responsiveness?", "After initializing and running the model, I checked the performance for all three models I had built previously against the all-in-one model.", "Comparing the performance of the 3 best models for each offer type with the all_in_one model, we can se that having the all-in-one model is not as good as the RF bogo and discount models, and is about slightly better than the info model. This is probably due to the info model pulling down the performance, resulting in lower accuracy for the all in one model. I suspect that if we were to break down the all-in-one model performance to just looking at its ability to predict the effectiveness of informational offer types, it would also be worse than its performance predicting the other 2 types.", "If we take a step back and look at the big picture, it is more useful to have a higher accuracy for 3 separate models, as opposed to one all-in-one model. This is because the BOGO and discount offers are actually aimed at driving sales with some promotional cost, whereas the informational offer is essentially \u2018free\u2019 with no cost, and if they can drive sales that would be a bonus.", "Hence, I would actually suggest that the 3 separate models are more useful.", "In addition to the all-in-one model, since we already kept the datasets of effective transactions, I was curious to know if I could build a regression model to predict how much someone would spend, given an effective offer. I could have built a model separately for each offer type to predict their spend, but I was curious to know if the type of offer would also determine a user\u2019s level of spend.", "However, the regression models significantly underperformed in terms of predicting the amount spent. It appears with the current data within our group 1 of customers, there is not enough information to predict the amount that can be driven by the offer type. We can see the Decision Tree Regressor model really overfit the data, with a very high training score but sub par testing score. Meanwhile, the linear regression model (with ridge/l2 regularization) also shows a minimal correlation between the features and the target variable. The model really underfits the data.", "I may get better performance if I break the models up into 3 different models based on offer type again; or even try to include non-influenced/invalid transactions, but this could be an exploration for another time.", "Overall, I found this project challenging, mainly due to the structure of the data in the transcript dataset. I had started out with 2 business questions:", "For Question 1, the feature importance given by all 3 models were that the tenure of a member is the biggest predictor of the effectiveness of an offer. Further study would be able to indicate what average tenure days would result in an effective BOGO offer.", "For all three models, the top 3 variables were the same \u2014 membership tenure, income and age. However, income and age switched orders depending on offer type.", "For BOGO and discount offers, the distribution of feature importances were relatively equal. However, for informational offers, the distribution is slightly more balanced, with income the second most important variable.", "My decision to use 3 separate models to predict the effectiveness of each offer type ended up with good accuracy for the BOGO and discount models (82.83% for BOGO and 87.35% for discount), while slightly less accurate performance for informational offers (75.3%). However, I would regard 75% as acceptable in a business setting, as for informational offers, there is no cost involved to inform users of a product.", "Meanwhile, for BOGO and discount models, I am quite happy with the 80% and above accuracy, as in a business setting that would be acceptable to show offers to people, even if the model misclassifies a few, the overall revenue increase might justify the few mistakes.", "When analysing and building the machine learning models to answer the above questions, reflections on my main challenges and findings are as follows:", "b.i. Attribution framework for assigning offer_ids for transactions", "In order to answer Question 1, I had to first define what an \u2018effective offer\u2019 means using the transactional records. This proved to be the trickiest portion of the project. I had to define a funnel for what what an effective conversion would look like, as we had data on both effective and noneffective conversions. Thus, I was desigining an attribution model for the conversion events (offer completed and transaction events) based on the events that occurred prior for each person.", "I ended up having to separate the users into 4 different pools, based on their actions in the transcript data:", "Even after separating the groups, it was challenging to assign the people in group 3 based on the transactional data. I had to define the event space where the right sequence of events would occur before I could assign an offer id to transactions (which did not have an offer_id), essentally designing a event/sequence-based attribution window.", "After attributing the conversions to specific offers, the rest of the data preparation and cleaning was relatively straightforward. I was grateful that there were not many missing values, and the preparation of categorical variables was also relatively straightforward.", "I decided to do some basic feature engineering as I found the model had slightly underfit on my first attempt in this project, so I had added the feature engineering section later. It improved the performance of the model slightly, and the membership_tenure feature I had engineered out of the became_member_on column ended up being the most important predictor variable.", "However, overall I found that I could not think of additional features using the time data, even though I had the hunch that the time of receiving the offer might be quite influential in determining whether it is effective or not.", "I had made the decision to build 3 separate models depending on offer types based on my definition of the problem statement \u2014 as I wanted to discover what would drive an effective offer, I thought it made more sense to remove noise from the data by separating the data into the offer types. My decision ended up to be quite a good one as the single BOGO and discount models got good performance in testing scores, compared to the all-in-one model overall score.", "For the info model, the accuracy was slightly worse as we had less records overall (half of the BOGO and discount models). As elaborated above, I believe that if we had more data, I could have gotten the accuracy higher, as there was a clear diverging pattern occurring between the training and testing score as I made decisions to improve the model fit like adding polynomial features and removing \u2018noisy\u2019 features like the amount_invalid feature. Due to the limited data, my decisions ended up with the model overfitting, hence I believe the model accuracy would have benefitted from more data.", "An additional note on model selection \u2014 I selected tree-based models as I wanted to assess feature importance, but I could have extended this study further by testing a parametric/ regression model (e.g. logistic regression for classification tasks). The weights of the coefficients from a regression model might have been interesting to contrast with the feature importance of a tree-based model, given that both models have different ways of analysing the data. The feature membership_tenure_days might not have been the highest weighted feature, in contrast to how it was in this study.", "b.iv. Exploring demographics of different customer groups", "I was curious to know what the characteristics were of groups 3 and 4, which are customers who are not influenced by an offer at all. However, after comparing their characteristics with groups 1 and 2, I could not see any significant differences in their demographics.", "I would have liked to have more data to perhaps understand why this group of customers tend to not be influenced by offer, in order to make useful suggestions on how to give a good customer experience to these customers, even if we do not serve them any offers.", "b.v. Model accuracy in predicting amount spent given an effective offer", "The regression model I built out of curiosity to see if we could predict the amount a user would spend, given that they are effectively influenced by an offer. The motivation was that if we can predict how much someone would spend given an offer, perhaps we can assess which offers bring in the most revenue.", "However, my model found virtually no correlation between the features provided (namely, offer characteristics and demographics of app users) with the amount spent per user. These features aren\u2019t strong enough to predict the amount spent per user. Perhaps if we also have a value of the offer, for example, for a discount offer, the value of the discount in dollar terms, perhaps we might be able to predict better.", "Perhaps I could have broken them up into 3 different models for the 3 offer types, the way I did with the binary classification models, in order to get a better result. However, given that this was just a curiosity and I wanted to explore if the offer type would be a statistically significant predictor feature, I built an all-in-one model for this instance. This would be worth exploring further, given more time and data.", "The sequential, event-based nature of the transcript dataset had posed the biggest challenge, but it is quite common in app data, or many digital analytics data that would include transactional data including web. Hence, I found this challenge to be a rewarding experience.", "This project could definitely have been extended further given more varieties of data on the types of products offered, along with the prices of products. It could be extended to a longer, customer segmentation exercise to determine attributes of customers that prefer certain offer types or products, as well as even predicting the relevant price band for offers.", "However, the data preparation and cleaning would have been even more challenging, so with that context I am quite grateful that the data provided was more limited and controlled. I am satisfied with the performance of my models within this scope.", "As mentioned above, this write-up, while containing code output required for understanding, lacks the exhaustive details that went into the project. If you would like to see my code and analysis in further detail, the link to my Github is available here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F20b799f3a6d5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@syuenloh.ds?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@syuenloh.ds?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Syuen Loh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F35ff10ddf05a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&user=Syuen+Loh&userId=35ff10ddf05a&source=post_page-35ff10ddf05a----20b799f3a6d5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/@kaiquestr", "anchor_text": "Kaique Rocha"}, {"url": "https://github.com/syuenloh/UdacityDataScientistCapstone", "anchor_text": "Github repo"}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/", "anchor_text": "here"}, {"url": "https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)", "anchor_text": ")"}, {"url": "https://github.com/syuenloh/UdacityDataScientistCapstone", "anchor_text": "here"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----20b799f3a6d5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----20b799f3a6d5---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/udacity?source=post_page-----20b799f3a6d5---------------udacity-----------------", "anchor_text": "Udacity"}, {"url": "https://medium.com/tag/digital-analytics?source=post_page-----20b799f3a6d5---------------digital_analytics-----------------", "anchor_text": "Digital Analytics"}, {"url": "https://medium.com/tag/app-analytics?source=post_page-----20b799f3a6d5---------------app_analytics-----------------", "anchor_text": "App Analytics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&user=Syuen+Loh&userId=35ff10ddf05a&source=-----20b799f3a6d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&user=Syuen+Loh&userId=35ff10ddf05a&source=-----20b799f3a6d5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F20b799f3a6d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----20b799f3a6d5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----20b799f3a6d5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@syuenloh.ds?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@syuenloh.ds?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Syuen Loh"}, {"url": "https://medium.com/@syuenloh.ds/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F35ff10ddf05a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&user=Syuen+Loh&userId=35ff10ddf05a&source=post_page-35ff10ddf05a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa25c37778359&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fusing-starbucks-app-user-data-to-predict-effective-offers-20b799f3a6d5&newsletterV3=35ff10ddf05a&newsletterV3Id=a25c37778359&user=Syuen+Loh&userId=35ff10ddf05a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}