{"url": "https://towardsdatascience.com/feature-selection-techniques-1bfab5fe0784", "time": 1683000703.997621, "path": "towardsdatascience.com/feature-selection-techniques-1bfab5fe0784/", "webpage": {"metadata": {"title": "Feature Selection Techniques. An end to end guide on how to reduce\u2026 | by Pier Paolo Ippolito | Towards Data Science", "h1": "Feature Selection Techniques", "description": "According to Forbes, about 2.5 quintillion bytes of data is generated every day [1]. This data can then be analysed using Data Science and Machine Learning techniques in order to provide insights and\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/uciml/mushroom-classification", "anchor_text": "Kaggle Mushroom Classification Dataset", "paragraph_index": 1}, {"url": "https://www.kaggle.com/pierpaolo28/mushrooms-selection?scriptVersionId=20931617", "anchor_text": "Kaggle", "paragraph_index": 1}, {"url": "https://github.com/pierpaolo28/Kaggle-Challenges/blob/master/mushrooms-selection.ipynb", "anchor_text": "GitHub Account", "paragraph_index": 1}, {"url": "https://en.wikipedia.org/wiki/Chi-squared_test", "anchor_text": "Chi-squared (Chi2)", "paragraph_index": 29}, {"url": "https://medium.com/@pierpaoloippolito28?source=post_page---------------------------", "anchor_text": "follow me on Medium", "paragraph_index": 33}, {"url": "http://eepurl.com/gwO-Dr?source=post_page---------------------------", "anchor_text": "mailing list", "paragraph_index": 33}, {"url": "https://www.edureka.co/blog/what-is-big-data/", "anchor_text": "https://www.edureka.co/blog/what-is-big-data/", "paragraph_index": 34}, {"url": "https://linktr.ee/pierpaolo28", "anchor_text": "https://linktr.ee/pierpaolo28", "paragraph_index": 36}], "all_paragraphs": ["According to Forbes, about 2.5 quintillion bytes of data is generated every day [1]. This data can then be analysed using Data Science and Machine Learning techniques in order to provide insights and make predictions. Although, in most of the cases, the originally gathered data needs to be first preprocessed before starting any statistical analysis with it. There are many different reasons why it might be necessary to carry out a preprocessing analysis, some examples are:", "In this article, I will walk you through how to reduce the number of features in a dataset in Python using the Kaggle Mushroom Classification Dataset. All the code used in this post (and more!) is available on Kaggle and on my GitHub Account.", "Reducing the number of features to use during a statistical analysis can possibly lead to several benefits such as:", "In fact, it is statistically proven that when performing a Machine Learning task there exist an optimal number of features which should be used for every specific task (Figure 1). If more features are added than the ones which are strictly necessary, then our model performance will just decrease (because of the added noise). The real challenge is to find out what is the optimal number of features to use (this is, in fact, dependent on the amount of data we have available and by the complexity of the task we are trying to achieve). That\u2019s where Feature Selections techniques come to our rescue!", "There are many different methods which can be applied for Feature Selection. Some of the most important ones are:", "In this article, I will make use of the Mushroom Classification dataset to try to predict if a Mushroom is poisonous or not by looking at the given features. While doing so, we will try different feature elimination techniques to see how this can affect training times and overall model accuracy.", "First of all, we need to import all the necessary libraries.", "The dataset we will be using in this example is shown in the figure below.", "Before feeding this data into our Machine Learning models I decided to One Hot Encode all the Categorical Variables, divide our data into features (X) and labels (Y), and finally in training and test sets.", "Decision Trees models which are based on ensembles (eg. Extra Trees and Random Forest) can be used to rank the importance of the different features. Knowing which features our model is giving most importance can be of vital importance to understand how our model is making it\u2019s predictions (therefore making it more explainable). At the same time, we can get rid of the features which do not bring any benefit to our model (or confuse it to make a wrong decision!).", "As shown below, training a Random Forest classifier using all the features, led to 100% Accuracy in about 2.2s of training time. In each of the following examples, the training time of each model will be printed out on the first line of each snippet for your reference.", "Once our Random Forest Classifier has been trained, we can then create a Feature Importance plot to see which features have been considered as most important for our model to make its predictions (Figure 4). In this example, just the top 7 features are shown below.", "Now that we know which features are considered to be most important by our Random Forest, we can try to train our model just using the top 3.", "As we can see below, using just 3 features lead to a decrease of just 0.03% in accuracy and halved the training time.", "We can also understand how to perform Feature Selection by visualizing a trained Decision Tree structure.", "The features which will be at the top of the tree structure are the ones our model retained most important in order to perform its classification. Therefore by picking just the first few features at the top and discarding the others could possibly lead to creating a model which an appreciable accuracy score.", "Recursive Feature Elimination (RFE) takes as input the instance of a Machine Learning model and the final desired number of features to use. It then recursively reduces the number of features to use by ranking them using the Machine Learning model accuracy as metrics.", "Creating a for loop in which the number of input features is our variable, it could then be possible to find out the optimal number of features our model needs by keeping track of the accuracy registered in each loop iteration. Using RFE support method, we can then find out the names of the features which have been evaluated as most important (rfe.support return a boolean list in which TRUE represent that a feature is considered as important and FALSE represent that a feature is not considered important).", "SelectFromModel is another Scikit-learn method which can be used for Feature Selection. This method can be used with all the different types of Scikit-learn models (after fitting) which have a coef_ or feature_importances_ attribute. Compared to RFE, SelectFromModel is a less robust solution. In fact, SelectFromModel just removes less important features based on a calculated threshold (no optimization iteration process involved).", "In order to test SelectFromModel efficacy, I decided to use an ExtraTreesClassifier in this example.", "ExtraTreesClassifier (Extremely Randomized Trees) is tree-based ensemble classifier which can yield less variance compared to Random Forest methods (reducing, therefore, the risk of overfitting). The main difference between Random Forest and Extremely Randomized Trees is that in Extremely Randomized Trees nodes are sampled without replacement.", "Another possible method which can be used in order to reduce the number of features in our dataset is to inspect the correlation of our features with our labels.", "Using Pearson correlation our returned coefficient values will vary between -1 and 1:", "In this case, we will consider just the features which are at least 0.5 correlated with the output variable.", "We can now try to take a closer look at the relationship between the different correlated features by creating a Correlation Matrix.", "Another possible aspect to control in this analysis would be to check if the selected variables are highly correlated with each other. If they are, we would then need to keep just one of the correlated ones and drop the others.", "Finally, we can now select just the features which are most correlated with Y and train/test an SVM model to evaluate the results of this approach.", "Univariate Feature Selection is a statistical method used to select the features which have the strongest relationship with our correspondent labels. Using the SelectKBest method we can decide which metrics to use to evaluate our features and the number of K best features we want to keep. Different types of scoring functions are available depending on our needs:", "In this example, we will be using chi2 (Figure 7).", "Chi-squared (Chi2) can take as input just non-negative values, therefore, first of all, we scale our input data in a range between 0 and 1.", "When applying regularization to a Machine Learning model, we add a penalty to the model parameters to avoid that our model tries to resemble too closely our input data. In this way, we can make our model less complex and we can avoid overfitting (making learn to our model, not just the key data characteristics but also it\u2019s intrinsic noise).", "One of the possible Regularization Methods is Lasso (L1) Regression. When using Lasso Regression, the coefficients of the inputs features gets shrunken if they are not positively contributing to our Machine Learning model training. In this way, some of the features might get automatically discarded assigning them coefficients equal to zero.", "Once trained our model, we can again create a Feature Importance plot to understand which features have been considered most important by our model (Figure 8). This can be really useful especially when trying to understand how our model decided to make its predictions, therefore making our model more explainable.", "If you want to keep updated with my latest articles and projects follow me on Medium and subscribe to my mailing list. These are some of my contacts details:", "[1] What is Big Data? \u2014 A Beginner\u2019s Guide to the World of Big Data. Anushree Subramaniam, edureka! . Accessed at: https://www.edureka.co/blog/what-is-big-data/", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data Analytics @ Swiss Re, TDS Associate Editor and Freelancer. https://linktr.ee/pierpaolo28"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F1bfab5fe0784&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://pierpaoloippolito28.medium.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb8391a6a5f1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=post_page-b8391a6a5f1a----1bfab5fe0784---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@clemono2?utm_source=medium&utm_medium=referral", "anchor_text": "Clem Onojeghuo"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/uciml/mushroom-classification", "anchor_text": "Kaggle Mushroom Classification Dataset"}, {"url": "https://www.kaggle.com/pierpaolo28/mushrooms-selection?scriptVersionId=20931617", "anchor_text": "Kaggle"}, {"url": "https://github.com/pierpaolo28/Kaggle-Challenges/blob/master/mushrooms-selection.ipynb", "anchor_text": "GitHub Account"}, {"url": "https://en.wikipedia.org/wiki/Chi-squared_test", "anchor_text": "Chi-squared (Chi2)"}, {"url": "https://medium.com/@pierpaoloippolito28?source=post_page---------------------------", "anchor_text": "follow me on Medium"}, {"url": "http://eepurl.com/gwO-Dr?source=post_page---------------------------", "anchor_text": "mailing list"}, {"url": "https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------", "anchor_text": "Linkedin"}, {"url": "https://pierpaolo28.github.io/blog/?source=post_page---------------------------", "anchor_text": "Personal Blog"}, {"url": "https://pierpaolo28.github.io/?source=post_page---------------------------", "anchor_text": "Personal Website"}, {"url": "https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------", "anchor_text": "Medium Profile"}, {"url": "https://github.com/pierpaolo28?source=post_page---------------------------", "anchor_text": "GitHub"}, {"url": "https://www.kaggle.com/pierpaolo28?source=post_page---------------------------", "anchor_text": "Kaggle"}, {"url": "https://www.edureka.co/blog/what-is-big-data/", "anchor_text": "https://www.edureka.co/blog/what-is-big-data/"}, {"url": "https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/", "anchor_text": "https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/"}, {"url": "https://www.researchgate.net/publication/324800823_Integrated_Chemometrics_and_Statistics_to_Drive_Successful_Proteomics_Biomarker_Discovery", "anchor_text": "https://www.researchgate.net/publication/324800823_Integrated_Chemometrics_and_Statistics_to_Drive_Successful_Proteomics_Biomarker_Discovery"}, {"url": "https://www.lifeinfreshwater.org.uk/Stats%20for%20twits/Chi-Squared.html", "anchor_text": "https://www.lifeinfreshwater.org.uk/Stats%20for%20twits/Chi-Squared.html"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1bfab5fe0784---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----1bfab5fe0784---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----1bfab5fe0784---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/programming?source=post_page-----1bfab5fe0784---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----1bfab5fe0784---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----1bfab5fe0784---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=-----1bfab5fe0784---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F1bfab5fe0784&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----1bfab5fe0784---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1bfab5fe0784--------------------------------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://pierpaoloippolito28.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Pier Paolo Ippolito"}, {"url": "https://pierpaoloippolito28.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5.1K Followers"}, {"url": "https://linktr.ee/pierpaolo28", "anchor_text": "https://linktr.ee/pierpaolo28"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb8391a6a5f1a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=post_page-b8391a6a5f1a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4e32d8fa9b0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffeature-selection-techniques-1bfab5fe0784&newsletterV3=b8391a6a5f1a&newsletterV3Id=4e32d8fa9b0e&user=Pier+Paolo+Ippolito&userId=b8391a6a5f1a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}