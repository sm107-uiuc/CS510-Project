{"url": "https://towardsdatascience.com/scrape-tabular-data-with-python-b1dd1aeadfad", "time": 1683005456.9770188, "path": "towardsdatascience.com/scrape-tabular-data-with-python-b1dd1aeadfad/", "webpage": {"metadata": {"title": "Scrape Tabular Data with Python. How to scrape NBA players\u2019 data using\u2026 | by Yufeng | Towards Data Science", "h1": "Scrape Tabular Data with Python", "description": "The ways of data assembling vary a lot with the type of data, of which scraping the tabular datasets from the web is one of the most typical sources. I\u2019ve used it for a long time to get as much data\u2026"}, "outgoing_paragraph_urls": [{"url": "https://sites.google.com/a/chromium.org/chromedriver/home", "anchor_text": "https://sites.google.com/a/chromium.org/chromedriver/home", "paragraph_index": 11}, {"url": "https://www.basketball-reference.com/", "anchor_text": "basketball-reference", "paragraph_index": 16}, {"url": "https://jianan-lin.medium.com/membership", "anchor_text": "https://jianan-lin.medium.com/membership", "paragraph_index": 45}], "all_paragraphs": ["One of the bottlenecks in executing a machine learning project is the dataset assembling.", "The ways of data assembling vary a lot with the type of data, of which scraping the tabular datasets from the web is one of the most typical sources. I\u2019ve used it for a long time to get as much data as I need efficiently.", "I have been writing about machine learning techniques for a while using the NBA players\u2019 stats as the raw data. One of the most frequently asked questions to me is whether I could share the data because people would like to play with it.", "There\u2019s an old saying in Asia,", "Give a man a fish, and you feed him for a day; teach a man to fish, and you feed him for a lifetime.", "So, in this post, I would like to share with you how to scrape tabular data from the web with Python.", "Besides the standard steps, I will also introduce the practical issues I met and the solutions to solve them.", "The codes above show the installation of four required python packages to do the job, and most of the time they are sufficient.", "After successfully installing these packages, simply import them into the python environment.", "If you are using Google Chrome as your default browser, please make sure that the chromedriver is executable in your PATH. If not, you may run into the same problem as I did, with the error message below.", "Message: \u2018chromedriver\u2019 executable needs to be in PATH", "To solve the problem, simply download the chromedriver from https://sites.google.com/a/chromium.org/chromedriver/home and put it in an executable path or adding its current location to the system PATH variable.", "To add its location to PATH, open the ~/.bash_profile by typing", "Then add the following line to the end of the file,", "To check whether chromedriver is executable, just type chromedriver in the terminal and you can see the message from the package,", "Till now, we have all the tools required.", "First, we need to find a target page. I will use the NBA player\u2019s stats page from basketball-reference as the example of this tutorial. Here is the URL of my target page:", "To scrape data from a specific webpage, we need to know its structure via a developer\u2019s view. Right-click the page and left-click the \u2018Inspect\u2019 button as below.", "Then you will see the script of the webpage on the right side as shown below.", "The information shown above is hardly human-readable but after carefully checking, you may find some patterns.", "For example, the tables on the page always start with <table \u2026> and end with </table> (highlighted by blue in the plot above). And these tables are exactly what I want from the page.", "Now, we are going to scrape those tables from the page using Beautifulsoup. The standard way of getting all the tables from the page is,", "where requests.get(URL) is basically getting the information from the page and BeautifulSoup(page.content, \u2018html.parser\u2019) is to parse the information.", "We then can apply the find_all function to the parsed information in soup. soup.find_all(\u201ctable\u201d) is collecting all the blocks of information that start with <table> and end with </table>.", "For each of the table in the variable tables, usually, the table headers start with <th> and all the table cells of the rows start with <td>. So, the table can be extracted and converted to pandas data frame in the following code.", "The generated data frame is as below,", "To move the first row to the headers, simply type", "To get all the tables of the page in the same way as the first table (tables[0]), I created a dictionary and use the attribute \u2018id\u2019 of each table as the key within the for-loop.", "I was able to extract the table id by table[\u2018id\u2019] because \u2018id\u2019 is an attribute of the table, which is \u2018per_game\u2019 as shown below,", "In this way, I should have all the tables in pandas data frame format deposited in the large dictionary tabs_dic.", "When I first tried to investigate the table numbers on the player\u2019s page, I found this issue where I only scraped ONE table from it!!!", "I did use find_all(\u201ctable\u201d) as shown in the previous code, how can I miss all the other tables except the first one?!", "I checked the types of the tables on the page and I found that the tables that escaped from my scraping were those within javascript.", "Then, selenium was used to solve the problem.", "The codes above solved the problem and successfully acquired 75 tables then.", "I was confused again because 75 seemed too many to me. I checked the webpage over and over again and found even though some of the blocks start with <table>, they only deposit one or two values and are not the tables I want.", "So, I further revised the code to select several classes of tables on the page based on the class attribute of the tables.", "where the class information was passed to the function in a dictionary format.", "I finally got 22 tables in total.", "To require the players\u2019 stats is one of my most frequent operations, so I wrote a large function for my future use.", "Webpage scraping is a powerful skill, especially for those who are interested to apply machine learning techniques to some interesting fields.", "For example, the scraping skill is fundamental to all the following posts I wrote about machine learning and basketball.", "Usually, after getting the data as we want, the next step is for data visualization before the modeling part. However, data visualization is beyond the scope of this post. Those who are interested can refer to one of my posts about it:", "That\u2019s it! Cheers! Now you should know how to scrape tabular data with Python.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ph.D., Data Scientist and Bioinformatician. Support my writing by becoming one of my referred members: https://jianan-lin.medium.com/membership"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb1dd1aeadfad&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jianan-lin.medium.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": ""}, {"url": "https://jianan-lin.medium.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Yufeng"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9cda0369fb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&user=Yufeng&userId=9cda0369fb2&source=post_page-9cda0369fb2----b1dd1aeadfad---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral", "anchor_text": "Markus Spiske"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://sites.google.com/a/chromium.org/chromedriver/home", "anchor_text": "https://sites.google.com/a/chromium.org/chromedriver/home"}, {"url": "https://medium.com/@jianan.jay.lin", "anchor_text": "Yufeng"}, {"url": "https://www.basketball-reference.com/", "anchor_text": "basketball-reference"}, {"url": "https://www.basketball-reference.com/players/i/irvinky01.html", "anchor_text": "https://www.basketball-reference.com/players/i/irvinky01.html"}, {"url": "https://medium.com/@jianan.jay.lin", "anchor_text": "Yufeng"}, {"url": "https://medium.com/@jianan.jay.lin", "anchor_text": "Yufeng"}, {"url": "https://medium.com/@jianan.jay.lin", "anchor_text": "Yufeng"}, {"url": "https://medium.com/@jianan.jay.lin", "anchor_text": "Yufeng"}, {"url": "https://www.basketball-reference.com/players/i/irvinky01.html'", "anchor_text": "https://www.basketball-reference.com/players/i/irvinky01.html'"}, {"url": "https://towardsdatascience.com/whos-the-mvp-of-nba-this-season-3e347c66a40a", "anchor_text": "Who\u2019s The MVP of NBA This Season?A case study to show what a machine learning project looks like from the beginning to the end.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/present-the-feature-importance-of-the-random-forest-classifier-99bb042be4cc", "anchor_text": "Present The Feature Importance of The Random Forest ClassifierHow to build a random forest classifier, extract the feature importance, and present them beautifully.towardsdatascience.com"}, {"url": "https://towardsdatascience.com/end-to-end-project-of-game-prediction-based-on-lebrons-stats-using-three-machine-learning-models-38c20f49af5f", "anchor_text": "End-to-End Project of Game Prediction Based on LeBron\u2019s Stats Using Three Machine Learning ModelsComprehensive guidance of a binary classification problem using three different classifiers, including Logistic\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/hands-on-guidance-of-data-visualization-in-r-package-ggplot2-of-nba-players-stats-d812ed272d66", "anchor_text": "Hands-on Guidance of Data Visualization in R Package \u201cggplot2\u201d of NBA Players\u2019 StatsA 6-minute tour of R data visualization tool, \u201cggplot2\u201d, applied to NBA data.towardsdatascience.com"}, {"url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#", "anchor_text": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#"}, {"url": "https://www.basketball-reference.com/", "anchor_text": "https://www.basketball-reference.com/"}, {"url": "https://stackoverflow.com/questions/46305314/using-beautifulsoup-to-scrape-tables-within-comment-tags", "anchor_text": "https://stackoverflow.com/questions/46305314/using-beautifulsoup-to-scrape-tables-within-comment-tags"}, {"url": "https://sites.google.com/a/chromium.org/chromedriver/downloads", "anchor_text": "https://sites.google.com/a/chromium.org/chromedriver/downloads"}, {"url": "https://unsplash.com/@cyscapes?utm_source=medium&utm_medium=referral", "anchor_text": "Cyrus Crossan"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----b1dd1aeadfad---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----b1dd1aeadfad---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/scraping?source=post_page-----b1dd1aeadfad---------------scraping-----------------", "anchor_text": "Scraping"}, {"url": "https://medium.com/tag/nba?source=post_page-----b1dd1aeadfad---------------nba-----------------", "anchor_text": "NBA"}, {"url": "https://medium.com/tag/programming?source=post_page-----b1dd1aeadfad---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&user=Yufeng&userId=9cda0369fb2&source=-----b1dd1aeadfad---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&user=Yufeng&userId=9cda0369fb2&source=-----b1dd1aeadfad---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fb1dd1aeadfad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----b1dd1aeadfad---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----b1dd1aeadfad--------------------------------", "anchor_text": ""}, {"url": "https://jianan-lin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jianan-lin.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yufeng"}, {"url": "https://jianan-lin.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "728 Followers"}, {"url": "https://jianan-lin.medium.com/membership", "anchor_text": "https://jianan-lin.medium.com/membership"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9cda0369fb2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&user=Yufeng&userId=9cda0369fb2&source=post_page-9cda0369fb2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ff12c76e2ba88&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscrape-tabular-data-with-python-b1dd1aeadfad&newsletterV3=9cda0369fb2&newsletterV3Id=f12c76e2ba88&user=Yufeng&userId=9cda0369fb2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}