{"url": "https://towardsdatascience.com/checking-data-consistency-during-platform-migrations-83eed17479c5", "time": 1683015276.7535942, "path": "towardsdatascience.com/checking-data-consistency-during-platform-migrations-83eed17479c5/", "webpage": {"metadata": {"title": "Checking data consistency during platform migrations | by Yulia R\u00f6nsch | Towards Data Science", "h1": "Checking data consistency during platform migrations", "description": "Ensuring a smooth data migration: my own experience with Salesforce, SAP, and many others with practical examples, charts, and code chunks."}, "outgoing_paragraph_urls": [{"url": "http://technical-content-writer.com", "anchor_text": "technical-content-writer.com", "paragraph_index": 48}], "all_paragraphs": ["With a platform, I mean every software that somehow stores the data permanently. Not a necessarily data analytics platform, but a CRM, an ERP (enterprise resource planning), a campaign management platform, etc.", "Platform migrations used to be something unique and rare a decade ago. Nowadays, a lot of companies migrate their working processes every couple of years. Sometimes, they do it because better technology has arrived. More often, an old and even good-working one gets scheduled for retirement.", "The data that the platform has gathered is often used for business analytics reports. Typically, a business platform has an analytics extension. A good example is the Salesforce platform and its Einstein Analytics extension. In some cases, the data must regularly be extracted, processed, and visualized in a third-party tool.", "Each platform and its analytics extension has routines for calculating and visualizing key performance indicators. These routines vary across platforms. Some offer an ETL tool; some do not, so you do some data cleaning directly in the visualization interface.", "But as a business owner or manager, you need a common denominator, a standard representation of all critical KPIs that you use for decision-making daily. You also want to ensure that the underlying calculation might lead to the same or almost the same result, although it might be different.", "After the migration is over, you open a freshly built but unfamiliar KPI dashboard. The numbers must still make sense to you.", "Another potential pitfall is that implementing new calculating routines means new data pipelines. New data storage. New ways of ejecting the data from where it originates. A lot of steps before a shiny business report can be created at all. A lot of possibilities that an error would slip in.", "So far, that may have sounded too theoretical \u2014 a couple of examples from my past.", "A few years ago, I participated in a platform migration caused by a need for more significant data storage and faster cloud-based data pipelines. The company decided to replace the legacy platform with an Amazon S3 cloud.", "Customers delivered the data in the form of .CSV files that they saved on an SFTP server. The Amazon S3 data pipeline would digest them, process, and create an SQL database. The database was connected to multiple Tableau dashboards. The new data came in daily.", "Before showing the customers the new system, we ran both of them simultaneously for a while. We soon noticed that the new pipeline often fails to deliver the same results as the old one. One of the reasons was that the .CSV files did not match the pattern created in the Amazon S3. Roughly speaking, the files often had different column names or data came in the wrong format.", "Another time, my company wanted to migrate from a niche campaign management tool to Google DoubleClick. Since our primary customer wanted his old reports one-to-one, the data should be extracted from DoubleClick, written to an SQL database, and then digested into Microsoft PowerBI.", "The pitfalls revealed themselves pretty soon. As in the previous case, the .CSV files had wrong column names. They were sometimes changed in Google Analytics without warning. Since the download of the .CSV files ran automatically, the inconsistent data was inserted into the database and spoiled the KPI dashboard afterward. Besides, naming conventions for the categorical dimensions were not followed.", "The new data arrived on a daily basis as well. The gaps were automatically piped into the PowerBI visualization, and their wrongness made a lot of people feel very frustrated.", "My next migration had a colossal scope: the company wanted to move an ERP, a CRM, and an analytics tool from SAP that announced the retirement of some of its modules to its competitor Salesforce. Salesforce does not specialize in the ERP market. It offers single packages that can help you to assemble a working flow for booking and invoicing. It requires a lot of customization, though.", "As a result, the data that came from the new ERP was very different from that coming from the SAP environment. Besides, the Salesforce analytical extension has quite a few specifics. During this migration, the SAP data was inserted directly into the Salesforce Einstein Analytics. As a bridge between the two systems, an SQL database stored the data in-between.", "The .CSV files ejected from SAP failed to be added into the database. On top of that, the Einstein Analytics data pipeline delivered results that deviated from those we saw in the SAP analytics tool. The KPIs, like highly aggregated revenue sums, just were not the same!", "Each discrepancy made me dig into the data. I developed a couple of reliable methods.", "You start with the KPIs that are typically high aggregations of smaller units values. For instance, you see that the total revenue is different across platforms. You may further compare the revenue per customer or for a given time period.", "It can be that the sums only deviate for particular customers. You go deeper and select the next level, for instance, a contract. Then a bill. Sooner or later, you\u2019ll find the discrepancy and can now look for the reason. You should locate a data entry that is wrong. Then you go and find out when the data entry was added to your system. Look into the bunch of data, like a .CSV file. Maybe, it was corrupted, not matching with the data structure, or had data formatting problems.", "Depending on the type of report, sometimes you can directly allocate the time period when the wrong data entries arrived. Or the time period that covers the duration of the contracts that show incorrect total revenues. You can then jump to the lowest level of aggregation or to the level without an aggregation at all. For instance, you take each contract or bill, export them from each system, and compare them by matching their IDs.", "I did not like to compare KPIs. This implied understanding their business logic. And this logic could often change without me being updated on it. Comparing the meta-data seemed a more secure way, but was not always enough.", "As we all know, meta-data is data about data. That what I previously meant by the pattern. You check if the incoming data has the same structure. This includes but is not limited to:", "If you have data about three marketing campaigns, and, all of a sudden, a .CSV has a fourth campaign for which you have no handling rule, then your data pipeline may get confused.", "If the smallest data units \u2014 contracts, bills, bookings \u2014 have different values across platforms, it means that you load incorrect data into one or both data pipelines.", "Starting from this level, the deviations will only grow, and the aggregated results grow apart.", "In many cases, these smallest units are matched with some additional data inside the pipeline, like customer, industry, etc. that allows to group and aggregate data later in the process. Those matches fail quite often: a customer changes the company name, the CRM had an incorrect name, name and ID does not match, and so on.", "Exceptions in the matching rules are also a headache. If you forget to copy all the old system\u2019s exceptions into the new one, you\u2019ll have deviations. They become visible only if you start comparing aggregated data.", "Basically, all methods work for ongoing monitoring, too. You just have to automate them.", "You can either monitor one platform, probably the new one, or both. It depends on your trust in the legacy platform or on the method you use.", "From the technical point of view, this worked the following way. I extracted the data from both platforms and matched them against each other. I took a limited period of time, mostly the recent one. Some calculations needed data from the previous periods, too. In a few particular cases, the users could adjust data entries for the past periods, like adding a discount to a contract that reached a discount-enabling value in the present time. That\u2019s why I regularly ran the consistency checks for last year\u2019s data.", "You can run the checks in one of the analytics extensions. Alternatively, you can export data from both systems and compare the meta-data in a third tool. I tried both ways but ended up with Python-based pipelines.", "The extraction of both reports can be automated, too. Depends on the tool, though.", "I downloaded two CSV. files from the legacy platform and from the new one. They had a different structure, but there ought to be a key, like a transaction ID. I had an R or Python script that processed data from both systems, took the key, and compared other data treating them as attributes of the key.", "Below are the screenshots of both (of course, fictitious) exports:", "The script standardized the data from both systems, renaming columns or dimensions or using additional data to bring different namings together.", "For instance, transaction 313200 has a $40,00 value in the legacy and $40 in the new system. It is a match. The Python script finds a common denominator for both formats and compares the actual values.", "I compared every single attribute of a transaction, not only sums but also string columns:", "As the last example, I attached the aggregated revenue comparison.", "As you may have noticed before, the same transaction has a different customer ID across platforms. I transform the columns holding their names and use them as a key. Then I sum up the transaction values to get revenue per customer and calculate deltas.", "You can timestamp the data with the date-time indicating when it was ejected or digested. Then you check the last period of time, like, yesterday, for the amount of new data added to the database to exclude anomalies and errors on this stage.", "You calculate the number of rows timestamped on a particular day, like yesterday.", "The same for checking categorical variables. You can just create a data visualization showing your dimensions\u2019 values or even checking if any new values were added.", "Another good practice is to create an alert that would warn you if something went wrong. For instance, if the number of new rows is smaller than zero.", "For this article, I re-created my former working routines in a bit simplified form. I cannot publish exactly the same data and methods since I neither have access to them nor the right to use them for my own benefit. I created an abstraction of my real methods to make them anonymous and generalizable. All company-specific information was carefully removed. It was also my own initiative to run the data consistency checks on a regular basis in addition to my routine tasks and to work out the methods.", "I used a Salesforce Einstein Analytics Trailhead Playground to build the data visualizations above. No data pipeline was involved. The data processing happened directly in the data visualization interface.", "Below are the SAQL queries that I used to build the tables:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "A storyteller. Ph.D. in comm science. Statistician, given up to my writing passion. Dog and travel lover. Late started climber. technical-content-writer.com"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F83eed17479c5&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----83eed17479c5--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@y.lukashina?source=post_page-----83eed17479c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@y.lukashina?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Yulia R\u00f6nsch"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd19e677b3ae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&user=Yulia+R%C3%B6nsch&userId=d19e677b3ae6&source=post_page-d19e677b3ae6----83eed17479c5---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/hands-on-tutorials", "anchor_text": "Hands-on Tutorials"}, {"url": "https://medium.com/tag/data-consistency?source=post_page-----83eed17479c5---------------data_consistency-----------------", "anchor_text": "Data Consistency"}, {"url": "https://medium.com/tag/salesforce?source=post_page-----83eed17479c5---------------salesforce-----------------", "anchor_text": "Salesforce"}, {"url": "https://medium.com/tag/data-migration?source=post_page-----83eed17479c5---------------data_migration-----------------", "anchor_text": "Data Migration"}, {"url": "https://medium.com/tag/business-analytics?source=post_page-----83eed17479c5---------------business_analytics-----------------", "anchor_text": "Business Analytics"}, {"url": "https://medium.com/tag/hands-on-tutorials?source=post_page-----83eed17479c5---------------hands_on_tutorials-----------------", "anchor_text": "Hands On Tutorials"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&user=Yulia+R%C3%B6nsch&userId=d19e677b3ae6&source=-----83eed17479c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&user=Yulia+R%C3%B6nsch&userId=d19e677b3ae6&source=-----83eed17479c5---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F83eed17479c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----83eed17479c5---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----83eed17479c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----83eed17479c5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----83eed17479c5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----83eed17479c5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----83eed17479c5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@y.lukashina?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@y.lukashina?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Yulia R\u00f6nsch"}, {"url": "https://medium.com/@y.lukashina/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "242 Followers"}, {"url": "http://technical-content-writer.com", "anchor_text": "technical-content-writer.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd19e677b3ae6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&user=Yulia+R%C3%B6nsch&userId=d19e677b3ae6&source=post_page-d19e677b3ae6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F836fa6dad609&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchecking-data-consistency-during-platform-migrations-83eed17479c5&newsletterV3=d19e677b3ae6&newsletterV3Id=836fa6dad609&user=Yulia+R%C3%B6nsch&userId=d19e677b3ae6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}