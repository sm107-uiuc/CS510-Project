{"url": "https://towardsdatascience.com/what-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533", "time": 1683009387.456852, "path": "towardsdatascience.com/what-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533/", "webpage": {"metadata": {"title": "What distinguishes a neural network that generalizes well from those that don\u2019t? | by Ratul Ghosh | Towards Data Science", "h1": "What distinguishes a neural network that generalizes well from those that don\u2019t?", "description": "I recently came across this widely talked about paper, \u201cUnderstanding Deep Learning Requires Rethinking Generalization(Zhang et al. 2016)\u201d. The paper has already won the best paper award at ICLR\u2026"}, "outgoing_paragraph_urls": [{"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "Understanding Deep Learning Requires Rethinking Generalization(Zhang et al. 2016)", "paragraph_index": 0}, {"url": "https://en.wikipedia.org/wiki/Shattered_set", "anchor_text": "shatter", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Cardinality", "anchor_text": "cardinality", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Universal_approximation_theorem", "anchor_text": "Universal Approximation Theorem", "paragraph_index": 23}, {"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "paper", "paragraph_index": 23}, {"url": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true", "anchor_text": "A Closer Look at Memorization in Deep Networks", "paragraph_index": 25}, {"url": "https://www.linkedin.com/in/ratulghosh1/", "anchor_text": "LinkedIn", "paragraph_index": 29}], "all_paragraphs": ["I recently came across this widely talked about paper, \u201cUnderstanding Deep Learning Requires Rethinking Generalization(Zhang et al. 2016)\u201d. The paper has already won the best paper award at ICLR 2017. It raises a very important question \u201cWhy a deep neural network generalizes, despite having enough capacity just to memorize the inputs?\u201d", "In this article, I will share my understanding and discuss the different experiments performed and the results along with the implications.", "Before jumping straight into the paper I will explain a few concepts that would be useful.", "Generalization Error is defined as the difference between the training error and testing error.", "The training error is marked by the green curve and the testing error is marked by the red curve. Here we can see the model is overfitting and the generalization error is increasing gradually.", "Model capacity is defined as how flexibly a model can fit different types of input.", "A feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly.", "A classification model f with some parameter vector \u03b8 is said to shatter a set of data points (x1,x2,\u2026\u2026.,xn) if, for all assignments of labels to those points, there exists a \u03b8 such that the model f makes no errors when evaluating that set of data points.", "The VC dimension of a model f is the maximum number of points that can be arranged so that f shatters them. More formally, it is the maximum cardinal D such that some data point set of cardinality D can be shattered by f.", "The maximum number of data points we can perfectly label is called the VC dimension of the model.", "In the above example, we have a simple linear classifier and we want to separate the two groups(blue pluses and red minuses). For four input data points, there exist some possible combinations of data points that are impossible to separate into two groups using a linear classifier. Therefore, the VC dimension of the linear classifier would be three.", "The VC dimension predicts a probabilistic upper bound on the test error of a classification model.", "Here, D is the number of parameters in the model and N is the size of the training set.", "The above condition is only valid when D << N. This probabilistic upper bound is not useful for a deep neural network where usually the number of parameters is more than the number of data points(N << D).", "The paper introduces two new definitions, explicit and implicit regularization. Drop out, data augmentation, weight sharing, conventional regularization(L1 and L2) are all explicit regularization. Implicit regularization is early stopping, batch normalization, and SGD. Although how the distinction is made is not defined in the paper, I feel implicit regularization are those where we are achieving regularization as a side-effect of some other process. For example, we use L1 exclusively for regularization hence explicit. Whereas we use batch normalization for normalizing the activations of the different inputs and as a side-effect it also happens to perform some sort of regularization, so it is implicit regularization.", "Note: The above part is my understanding, please correct me if I\u2019m wrong.", "In the paper the authors have performed the following randomized tests:", "The results look quite interesting as the model can perfectly fit the noisy Gaussian samples. It also perfectly fits the training data with completely random labels although it takes a bit more time. This shows that a deep neural network with enough parameters could completely memorize some random inputs. This result is quite counter-intuitive as it is a widely accepted theory that Deep Learning usually discovers lower level features, middle-level features, and higher-level features and if a model can memorize any random inputs then what\u2019s the guarantee that the model will try to learn some constructive features instead of simply memorizing the input data.", "The first diagram shows the effect of different explicit regularization on the training and testing accuracy. Here, the key takeaway is that there is not a very significant difference in the generalization performance between using regularization and not using regularization.", "The second diagram shows the effect of batch normalization(implicit regularization) on the training and testing accuracy. We can see that the training with batch normalization is quite smooth but it doesn\u2019t improve the test accuracy.", "From the experiments, the authors concluded that both explicit and implicit regularizers could help to improve generalization performance. However, it is unlikely that regularizers are the fundamental reason for generalization.", "The authors also proved the following theorem:", "There exists a two-layer neural network with ReLU activations and 2n+d weights that can represent any function on a sample of size n in d dimensions.", "which is basically an extension of the Universal Approximation Theorem. The prove is quite heavy if interested refer to Section C in the appendix of the paper.", "In the final section, the authors show that SGD-based learning imparts a regularization effect as the SGD converges to the solution with minimum L2 norm. Their experiments also show that a minimum norm doesn\u2019t ensure a better generalization performance.", "A subsequent paper \u201cA Closer Look at Memorization in Deep Networks\u201d has challenged some of the views pointed out in this paper. They have convincingly demonstrating qualitative differences in learning random noise vs. learning actual data.", "The above experiment shows a deep neural net attempting to memorize random noise takes significantly longer to learn relative to the actual dataset. It also shows fitting some random noise results in a more complex function(more number of hidden units per layer).", "This experiment shows that regularizers do control the speed at which DNNs memorize.", "Thus to conclude, a deep neural network first tries to discover patterns, not brute force memorization, to fit real data. However, if it doesn\u2019t find any patterns(like in case of random noise), the network is capable of simply optimizing in a way that just memorizes the training data. As both, the paper suggests we need to find some better tools to control the degree of generalization and memorization, and tools like regularization, batch normalization, and dropout are not perfect.", "If you have any thoughts, comments, or questions, please leave a comment below or contact me on LinkedIn. Happy reading \ud83d\ude42", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Applied Scientist. Working on search, recommendation, advertisement and MLOps. I don\u2019t represent my employer."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8954f741d533&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8954f741d533--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@ratulghoshr?source=post_page-----8954f741d533--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ratulghoshr?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Ratul Ghosh"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda2147ddc6a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&user=Ratul+Ghosh&userId=da2147ddc6a5&source=post_page-da2147ddc6a5----8954f741d533---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@xinimini?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Tina Xinia"}, {"url": "https://medium.com/s/photos/cat-in-a-bowl?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText", "anchor_text": "Unsplash"}, {"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "Understanding Deep Learning Requires Rethinking Generalization(Zhang et al. 2016)"}, {"url": "https://en.wikipedia.org/wiki/Universal_approximation_theorem", "anchor_text": "Universal Approximation Theorem"}, {"url": "http://www.deeplearningbook.org/contents/mlp.html", "anchor_text": "DLB"}, {"url": "https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension", "anchor_text": "Vapnik\u2013Chervonenkis VC dimension"}, {"url": "https://en.wikipedia.org/wiki/Shattered_set", "anchor_text": "shatter"}, {"url": "https://en.wikipedia.org/wiki/Cardinality", "anchor_text": "cardinality"}, {"url": "https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension", "anchor_text": "https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension"}, {"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf"}, {"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf"}, {"url": "https://en.wikipedia.org/wiki/Universal_approximation_theorem", "anchor_text": "Universal Approximation Theorem"}, {"url": "https://bengio.abracadoudou.com/cv/publications/pdf/zhang_2017_iclr.pdf", "anchor_text": "paper"}, {"url": "https://en.wikipedia.org/wiki/Shattered_set", "anchor_text": "shatter"}, {"url": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true", "anchor_text": "A Closer Look at Memorization in Deep Networks"}, {"url": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true", "anchor_text": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true"}, {"url": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true", "anchor_text": "https://dl.acm.org/doi/pdf/10.5555/3305381.3305406?download=true"}, {"url": "https://www.linkedin.com/in/ratulghosh1/", "anchor_text": "LinkedIn"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----8954f741d533---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8954f741d533---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----8954f741d533---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8954f741d533---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----8954f741d533---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&user=Ratul+Ghosh&userId=da2147ddc6a5&source=-----8954f741d533---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&user=Ratul+Ghosh&userId=da2147ddc6a5&source=-----8954f741d533---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8954f741d533--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8954f741d533&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8954f741d533---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8954f741d533--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8954f741d533--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8954f741d533--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8954f741d533--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8954f741d533--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ratulghoshr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@ratulghoshr?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Ratul Ghosh"}, {"url": "https://medium.com/@ratulghoshr/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "56 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda2147ddc6a5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&user=Ratul+Ghosh&userId=da2147ddc6a5&source=post_page-da2147ddc6a5--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fda2147ddc6a5%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-distinguishes-a-neural-network-that-generalizes-well-from-those-that-dont-8954f741d533&user=Ratul+Ghosh&userId=da2147ddc6a5&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}