{"url": "https://towardsdatascience.com/the-basics-evaluating-regressions-91ffa7bde2b9", "time": 1683003397.61663, "path": "towardsdatascience.com/the-basics-evaluating-regressions-91ffa7bde2b9/", "webpage": {"metadata": {"title": "The Basics: Evaluating Regressions | by Max Miller | Towards Data Science", "h1": "The Basics: Evaluating Regressions", "description": "After all the data collection and data cleaning, it\u2019s time to fit a model and make some predictions. Why not try a couple of different models, actually \u2014 a plain linear regression or one with a\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["After all the data collection and data cleaning, it\u2019s time to fit a model and make some predictions. Why not try a couple of different models, actually \u2014 a plain linear regression or one with a regularization method like Ridge or Lasso, maybe KNN or a decision tree for regression. But now, how do you decide which of these models has actually performed the best? Is it possible to quantify how well any given model works? This is actually something of a tricky question and requires that you balance multiple goals that are frequently in opposition to each other. On the one hand, you want to minimize the error in any given prediction your model will make. On the other, you want your model to generalize, to work well on unseen data, which means avoiding overfit. There are numerous different metrics you can use to evaluate your models along these lines. Some quantify how much error is present in your model\u2019s predictions, some try to quantify how well the model accounts for the variance in the underlying data and some even make adjustments to try to quantify overfit.", "The first step when evaluating any model is to consider the prediction error, the amount by which your prediction is different from the true value for a given point, across all the available test data. Consider a simple regression problem, with one input feature:", "We can fit a linear regression to these points, and consider the error, which in this case is simply represented by the vertical distance between the points and the line we\u2019ve fit:", "A prediction can be above or below the true value, of course, so typically the error term is either squared or the absolute value of the error term is considered to avoid negative values canceling out positive ones. The simplest way to consider the overall error is to simply add it all up, either the sum of absolute errors (SAE):", "Or the sum of squared errors (SSE):", "A note that the error term is also called the \u2018residual\u2019, so you\u2019ll also see this as the sum of squared residuals (SSR). Of course, the goal is to minimize these sums.", "Why would you choose to consider the squared error term rather than the absolute error? Well, squaring the error term increases the influence of larger errors. As a hypothetical, consider a simple case that is predicting two points. Our first model has an error of 7 for the first point and -3 for the other, thus the sum of absolute errors is 10. Our second model has errors of -5 and 5, so it also has an SAE of 10. Our last model has no error for one of the points, but 10 for the second; it too has an SAE of 10. Considering the squared errors allows us to rank these models. The first model with errors of 7 and -3 has an SSE of 49 + 9 = 58. The second with the errors of -5 and 5 has an SSE of 25 + 25 = 50. The last model has an SSE of 0 + 100 = 100. The squared errors implicitly give more weight to the larger error terms, even if the total absolute error is the same.", "When it comes to ranking one model vs another on the same data, in a way these sums are all you need. The numbers are a little hard to interpret on their own, however. For one thing, an overall sum tends to increase with the size of the sample; it doesn\u2019t mean much that the summed error across 100 points is more than the summed error across 10. For that reason, when describing a model\u2019s performance, it\u2019s common to take the average of these measures of error, the mean absolute error (MAE) and mean squared error (MSE). These give you a measure of the amount of error per prediction made.", "The mean absolute error even has a simple interpretation \u2014 the average error on any given prediction \u2014 and it has the correct units. If your model is trying to predict, say, some dollar value, the error term for any point will also be an amount in dollars, so your mean absolute error is, very practically, the average number of dollars by which your prediction misses the mark. The mean squared error is a little different, and it no longer has the same units as what you\u2019re predicting. Your model predicted a dollar amount, but the squared error for any given point is in dollars squared. For that reason, it is also common to take the square root of the mean square error, giving you the Root Mean Square Error (RMSE). The RMSE has the same units as the thing you are predicting, but it has been weighted towards the larger error terms. It isn\u2019t quite as simple to interpret directly as the MAE, but it gives you a sense of the error that is more sensitive to outlier values while having roughly the same scale as the target variable.", "The MAE, MSE, and RMSE are a good place to start, but there\u2019s one more commonly used but oft misunderstood statistic that\u2019s worth considering: R-Squared or the coefficient of determination. The R-Squared value tries to quantify how much of the overall variance in the data is explained by your model and is used for assessing linear models (there are some different \u2018pseudo \u2014 R-squared\u2019 metrics that try to capture something similar for other model types) . There are a couple of different ways to calculate R-squared, but maybe the simplest is with this formula:", "On top of the fraction is the Sum of Square Residuals, which you may recall is the same thing as the sum of square errors we\u2019ve been discussing. On the bottom is the total sum of squares, which is a similar thing, but it captures the overall variance in the target variable by summing up the square of the distance from any given point to the average value of all points:", "The R-squared value tells us how much of the overall variance in our target variable y is explained by our model. An R-squared of .6 tells us that our model accounts for 60% of the variance of the target variable, leaving 40% unexplained by the model.", "When summing up error, it may seem natural that lower error is better, and of course, to an extent that is true, but measures of error on their own are typically insufficient because considering only the summed error tends to lead to overfit. Consider the following models fit to the dummy data we used up top. Here\u2019s a KNN regression with K set to 3:", "Not horrible, but we want to minimize those error terms. In our zeal we drop K down to 1:", "Now we\u2019ve eliminated all that unwanted error! Of course, the cost is that our model won\u2019t generalize. It swings wildly up and down to catch each point in our data, it\u2019s not likely to generalize. Are there any metrics or methods we can use to avoid this sort of situation?", "The first, and probably most important answer is that good data and modeling practice should avoid the worst cases of this. In particular, splitting your data into a training set and a test or validation set is a must. When we train on one set of points and test on an another, we can often weed out overfit models just using the simple measures of error. Consider our obviously overfit case of a KNN with K set to 1, but here we segment the data into a training set and a test set, and only graph the error terms for the test set:", "We frequently run into dramatically large error terms. Our measure of SSE is 2,893. Compare to this with K set to 3:", "Of course, there is still error in the model, but since the model\u2019s predictions don\u2019t swing around quite as dramatically, we avoid the largest of the errors. Our SSE here is only 1,163.", "This method isn\u2019t quite error proof on its own, particularly for smaller datasets, because you\u2019re a little bit at the mercy of the random test/train split. If we were to repeat the process with the KNN model with K set to 1 we might get the graph I had above with the particularly large error, or we might get this graph with a slightly more reasonable SSE of 1,351:", "Or we might get this graph with the downright misleading SSE of 949:", "The good luck (or perhaps, bad luck) of getting a few testing points that happened to be near some of the training points has given you an undeservedly low measure of error.", "The case of dropping the value of K down to 1 might seem a little contrived, but something similar happens as you add more and more explanatory variables to a multivariate regression. As you add more variables to your model, your measure of error inevitably goes down and your value for R-squared inevitably goes up. Adding a variable with little explanatory value may not cause your R-squared value to go up by much, but it will never cause your R-squared to go down and even adding a useless variable can cause your R-squared to go up due to statistical noise.", "To avoid this sort of situation we might turn to the last category of metrics discussed here, those that favor simpler models in addition to models with less error. The simplest of these is the Adjusted R-Squared, which is essentially just the R-squared you know and love, but multiplied by a term that decreases its value as the number of variables goes up:", "The adjusted R-squared value imposes a penalty when you increase the number of feature variables, so you can\u2019t simply load your model up with useless features or interaction terms to artificially boost your R-squared.", "Two other, conceptually similar, metrics are the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). As with the adjusted R-squared, both of these metrics deal with the possibility of adding too many feature variables by adding a penalty to increasing the number of features (this penalty in the BIC actually increases as the number of points in our sample increases), though unlike R-squared they measure the fit of the model with something called the Likelihood function, which expands the number of models they can be applied towards.", "I am avoiding the technical definitions of these two metrics because they can seem a little forbidding, but I want to stress that they are operating in much the same way as the adjusted R-squared, measuring fit while imposing a penalty for model complexity. In order for the addition of a new variable to be judged useful by the adjusted R-squared, AIC or BIC metric, the added benefit to the fit of the model needs to be greater than the penalty imposed for the addition of a new variable. All things being equal, these metrics all prefer simpler models and demand that increases in model complexity be accompanied by sufficiently large increases in performance.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Data scientist with a particular passion for limericks, policy and renewable energy."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F91ffa7bde2b9&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332----91ffa7bde2b9---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/tag/data-science?source=post_page-----91ffa7bde2b9---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/data-science-ground-up?source=post_page-----91ffa7bde2b9---------------data_science_ground_up-----------------", "anchor_text": "Data Science Ground Up"}, {"url": "https://medium.com/tag/regression?source=post_page-----91ffa7bde2b9---------------regression-----------------", "anchor_text": "Regression"}, {"url": "https://medium.com/tag/model-evaluation?source=post_page-----91ffa7bde2b9---------------model_evaluation-----------------", "anchor_text": "Model Evaluation"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&user=Max+Miller&userId=dfd5ba1a8332&source=-----91ffa7bde2b9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&user=Max+Miller&userId=dfd5ba1a8332&source=-----91ffa7bde2b9---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F91ffa7bde2b9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----91ffa7bde2b9---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----91ffa7bde2b9--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@max.samuel.miller?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Max Miller"}, {"url": "https://medium.com/@max.samuel.miller/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "409 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdfd5ba1a8332&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&user=Max+Miller&userId=dfd5ba1a8332&source=post_page-dfd5ba1a8332--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F930bd413e257&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-basics-evaluating-regressions-91ffa7bde2b9&newsletterV3=dfd5ba1a8332&newsletterV3Id=930bd413e257&user=Max+Miller&userId=dfd5ba1a8332&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}