{"url": "https://towardsdatascience.com/neural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e", "time": 1683006736.2433112, "path": "towardsdatascience.com/neural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e/", "webpage": {"metadata": {"title": "Neural Networks for Absolute Beginners with Numpy from scratch \u2014 Part 3: Logistic Regression | by Suraj Donthi | Towards Data Science", "h1": "Neural Networks for Absolute Beginners with Numpy from scratch \u2014 Part 3: Logistic Regression", "description": "In both Machine Learning and Deep Learning, you could encounter two kinds of problems which are regression and classification. In regression problems, you predict a continuous real-valued number\u2026"}, "outgoing_paragraph_urls": [{"url": "https://colab.research.google.com/", "anchor_text": "Google Colab", "paragraph_index": 5}], "all_paragraphs": ["In both Machine Learning and Deep Learning, you could encounter two kinds of problems which are regression and classification.", "In regression problems, you predict a continuous real-valued number while in classification problems, you predict different classes of objects.", "In the previous tutorials, we went in-depth into what a perceptron is and later learned how it learns to predict with the use of linear regression. In case, you\u2019re an absolute beginner to this domain I recommend you to go through short and easy previous tutorials of mine.", "In this tutorial, you will learn about logistic regression that is used for classification problems.", "As before a bit of math will be involved, but I\u2019ll ensure to cover from the basics so that you can understand easily.", "If you are unsure of which environment to use for implementing the code in this tutorial, I recommend Google Colab. The environment comes with many important packages already installed. Installing new packages and also importing and exporting the data is quite simple. Most of all, it also comes with GPU support. So, go ahead and get coding!", "Lastly, I recommend that you go through the first two tutorials before you start this. However, if you already know well about linear regression and a bit about Neural Networks or just want to learn about Logistic Regression, you could start right away!", "One of the earliest and most popular activation functions utilized is the Sigmoid function.", "The equation of the sigmoid function is as follows:", "and the graph for the function is as below:", "Hence, a perceptron with a sigmoid activation function does binary classification on a given set of data. This process of binary classification is popularly called Logistic Regression. In the next section, we\u2019ll dive deeper into logistic regression and also understand how the model is trained.", "Logistic regression is a technique used for binary classification. It creates a decision boundary between data points to categorize them in any one of the two classes. Such an illustration can be seen in the figure below. We shall go deeper into understanding and training a logistic regression model through a hands-on implementation. Understanding logistic regression will provide the base for understanding a Neural Network model.", "The computation graph for logistic regression to be implemented is shown in the below figure.", "We have two inputs x\u2081 and x\u2082 which are multiplied by the weights w\u2081 and w\u2082 respectively. An additional bias b is added to their sum to obtain z. The parameters (w\u2081, w\u2082, b) are learned during gradient descent.", "The first step would be to import the required packages.", "You\u2019ll use the sklearn package to perform two tasks:", "You\u2019ll use matplotlib for visualizing the results.", "Before you start defining code, in any machine learning project your first task will be to define the hyperparameters. The hyperparameters can be the dataset size, the learning rate, number of epochs, etc. You must be wondering why these variables are called hyperparameters! You\u2019ll find out later that parameters are what is learned in the model and we use hyperparameter to fine-tune the model for achieving better accuracy.", "Here we also define the number of input features and the number of clusters as we need to create the dataset.", "Next, we import the dataset from scikit-learn with the make_blobs function which creates blobs of classes. We will visualize the same too.", "Now lets, plot a graph to visualize the data generated.", "The two sets of data points belong to the two classes. Our goal is to find an optimal decision boundary that separates these two classes.", "The next step will be to split the data into train set and test set. We do this so that we can verify the accuracy of the learned algorithm.", "You\u2019ll now randomly initialize the parameters W and b, which are learned during training.", "After we have randomly initialized the parameters, the next step is to perform forward propagation and see how the network predicts.", "You will now utilize the generate_mesh_grid function to plot the dataset along with the contour.", "It\u2019s now time to define the loss function!!", "Unlike the MSE for Linear Regression, here we use a logistic loss function. This is because when we pass the sum z through a sigmoid activation function, the output is non-linear (as the sigmoid function is non-linear). This results in an error that is non-convex.", "But what do you mean by non-convex?", "In unsophisticated terms, the non-convex function appears to be like the graph on the right.", "In such situations, while our goal is to find the minimal point, it becomes extremely difficult to find one because of the troughs and crests. Instead, we could make our problem simpler if we could just have a simple function (like the one on the left) where we can easily find the minimum point. This is the convex function on the left.", "Hence, we use a log function that actually converts the non-linear function back to a linear one, which in turn results in a convex function!", "The graph of \uffdalog(x) is shown in the above figure. You can infer that given y = 1 if y \u2192 0, then loss \u2192 0 and when y\u2019 \u2192 0, then loss \u2192 \u221e. Similarly, if y\u2019 \u2192 0, then loss \u2192 0 and when y\u2019 \u2192 1, then loss \u2192 \u221e given y = 0. It implies that when the prediction is wrong, the parameters are heavily penalized and when the prediction is right, the parameters are not penalized.", "Here, the function reduces to \uffdalog(y\u2019) when y = 1 and log(1 \uffda y\u2019) when y = 0 just as we had defined earlier.", "While the above is only the error for only one example (datapoint), we need to account for all the examples. Therefore, we find the mean of the errors by summing all of them and dividing by the number of examples as shown below.", "The code for this would be as below:", "Let\u2019s plot the loss. You\u2019ll keep track of the losses for all the iterations (epochs) after which you will be able to visualize the decrease in error.", "This will usually be the toughest part to understand, but I have put in very easy terms.", "Gradient descent in layman words is like walking down a hill. This hill refers to the error in our case. Higher the error, higher the hill!! So as you roll down the hill, the error (Loss) goes down.", "Therefore, our goal is to roll down to the point of least error.", "Hey, but wait a sec! How can I change the loss? \ud83e\udd14", "Now you must observe that if you tweak the parameters W and b the Loss also changes!!", "Hence, we find the derivative (i.e., the rate of change) with respect to the parameters W & b and update them accordingly.", "Well, that\u2019s simple! Just find its derivative or the slope. Mathematically, the slope is zero at the minimal point(minima) [You can refer to this wonderful Khan Academy video if you do not know about derivatives and the slope.] and if you observe keenly, the slope is negative on the left of minima and positive on the right of minima. And when p is to the left of minima, we need to add some value so that it moves towards optimal p and when p is to the right subtract some value.", "We find the derivative of the Loss with respect to W and b in our case.", "I\u2019ve skipped a few steps which are unnecessary, but if interested, you can refer to this video below.", "As to the last part of updating the parameters, with the slopes, we multiply the slope by a dampening factor \u03b1 so that the parameters don\u2019t overshoot when having a very high error.", "You\u2019ll now implement the same gradient_descent algorithm as below.", "Now there\u2019s one last thing to do i.e., update combine both the plot functions into one.", "We have obtained a beautiful plot of the decision boundary as well as the Loss.", "Now as your final task, let\u2019s put together everything you had done until now and see the results for yourselves.", "So, you will first define the hyperparameters. You can play around with these values especially the learning rate l_r and epoch to observe how the model learns to predict.", "Now, you can write the code from creating a dataset to training your logistic regression model in a single go as below.", "We had earlier created a test dataset, you\u2019ll now test your regression model against it and determine the accuracy.", "We have obtained an accuracy of 95% which is pretty good!", "In the next tutorial, you\u2019ll learn to implement Neural Networks from scratch using only Numpy!", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F18b474096a4e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----18b474096a4e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@surajdonthi95?source=post_page-----18b474096a4e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajdonthi95?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Suraj Donthi"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc25979339f86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&user=Suraj+Donthi&userId=c25979339f86&source=post_page-c25979339f86----18b474096a4e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/neural-networks-with-numpy-for-absolute-beginners-introduction-c1394639edb2", "anchor_text": "Neural Networks with Numpy for Absolute Beginners: IntroductionIn this tutorial, you will get a brief understanding of what Neural Networks are and how they have been developed. In\u2026towardsdatascience.com"}, {"url": "https://towardsdatascience.com/neural-networks-with-numpy-for-absolute-beginners-part-2-linear-regression-e53c0c7dea3a", "anchor_text": "Neural Networks with Numpy for Absolute Beginners \u2014 Part 2: Linear RegressionIn this tutorial, you will learn to implement Linear Regression for prediction using Numpy in detail and also visualize\u2026towardsdatascience.com"}, {"url": "https://colab.research.google.com/", "anchor_text": "Google Colab"}, {"url": "https://bit.ly/3d9ESRL", "anchor_text": "https://bit.ly/3d9ESRL"}, {"url": "https://gph.is/1SuKcy4", "anchor_text": "Giphy"}, {"url": "https://gph.is/1NiQzpi", "anchor_text": "Giphy"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----18b474096a4e---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----18b474096a4e---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----18b474096a4e---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&user=Suraj+Donthi&userId=c25979339f86&source=-----18b474096a4e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&user=Suraj+Donthi&userId=c25979339f86&source=-----18b474096a4e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F18b474096a4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----18b474096a4e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----18b474096a4e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----18b474096a4e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----18b474096a4e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----18b474096a4e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----18b474096a4e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajdonthi95?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@surajdonthi95?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Suraj Donthi"}, {"url": "https://medium.com/@surajdonthi95/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "75 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc25979339f86&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&user=Suraj+Donthi&userId=c25979339f86&source=post_page-c25979339f86--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fadf447e480a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-networks-with-numpy-for-absolute-beginners-part-3-logistic-regression-18b474096a4e&newsletterV3=c25979339f86&newsletterV3Id=adf447e480a4&user=Suraj+Donthi&userId=c25979339f86&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}