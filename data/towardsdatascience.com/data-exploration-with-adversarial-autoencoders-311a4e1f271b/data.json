{"url": "https://towardsdatascience.com/data-exploration-with-adversarial-autoencoders-311a4e1f271b", "time": 1682997317.841383, "path": "towardsdatascience.com/data-exploration-with-adversarial-autoencoders-311a4e1f271b/", "webpage": {"metadata": {"title": "Data Exploration with Adversarial Autoencoders | by Donny Hanz | Towards Data Science", "h1": "Data Exploration with Adversarial Autoencoders", "description": "Like many, I started my journey into deep learning with Autoencoders as they are a nice entry point for developing an intuition for artificial neural networks and to get your head around the deep\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "Adversarial Autoencoders", "paragraph_index": 0}, {"url": "https://arxiv.org/abs/1312.6114", "anchor_text": "Variational Autoencoders", "paragraph_index": 3}, {"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "original paper", "paragraph_index": 6}], "all_paragraphs": ["Like many, I started my journey into deep learning with Autoencoders as they are a nice entry point for developing an intuition for artificial neural networks and to get your head around the deep learning framework of your choice. What started as an exercise with not many relevant use-cases already found many applications today, and turned out to be a deep learning swiss army knife. Autoencoders are often used for the detection of anomalies, to learn low dimensional representations that you can feed into other neural networks, to generate data and more. In this article, I want to introduce you to a special architecture called Adversarial Autoencoders, and with it, a new application for autoencoders, the unsupervised clustering of data, which I will mainly focus on in this article. I want to discuss the workings of such an encoder and show you how to easily build and train them with Keras and how to use them to cluster and explore time-series on an example involving foreign exchange market data.", "Autoencoders fascinated me when I first started getting into deep learning, I liked how easy the setup is and how experimenting with them quickly makes you develop a feeling for artificial neural networks. The idea is very simple, train a neural network model to reproduce its input under the constraint that in the middle of the network lies an informational bottleneck that is too small for the data to fit through. This restriction requires the autoencoder to find a representation for the input data that fits through that bottleneck, in order to then attempt to reproduce it as accurately as possible from that representation. It has to find a succinct code -hence the name autoencoder- which is also often referred to as the latent vector. Though it sounds very simple, this type of neural network allows you find an almost arbitrarily low dimensional representation for any kind of data, and you are simultaneously gaining a measure of how uncommon or anomalous a sample of data is depending on its reconstruction error.", "One thing you cannot really do with vanilla auto-encoders though is generating new data. In theory, you could feed some random vector into the decoder part and get fresh new cat pictures or whatever you\u2019ve been encoding. The reason why this doesn\u2019t work is that the latent representation that the encoder produces is not distributed in any way, which can be expressed by a simple parametric distribution, like a normal distribution, that you can sample from. Instead, the latent space often appears fractured into different domains in the code space, and If you would just feed the decoder with a random vector sampled from a random variable like a normal distribution you most likely end up generating just garbage. In other words, you don\u2019t know how to pick random values for the decoder to produce quality cat pictures.", "To address this issue Variational Autoencoders were invented to train the encoder to learn the parameters of a latent distribution instead, which can then be sampled from and fed into the decoder. The problem is only that they tend to be difficult to train, and even though variational autoencoders are better at catching properties of data of a stochastic nature and have better properties for sampling and generating data, still, the samples they produce often include poor examples, mostly on the boundaries between classes of the input data, if such exist. The latent space still does not get distributed ideally, especially if the data cannot be approximated well by Gaussian distributions used in the variational inference process. Also, there is one thing you cannot do with variational encoders and that is to have the latent representation take the properties of any arbitrary distribution, as they only learn the properties of multiple Gaussian distributions. But what if you want to sample from a beta- or a uniform distribution for example?", "Since the advent of Generative Adversarial Networks and adversarial training methods, neural networks have been able to learn not only to classify but also produce photorealistic images and nowadays even videos. As it turns out, the same techniques employed in GANs that are used to train the generators can also be used to regularize the properties of your neural networks. The idea behind adversarial autoencoders is that you train the encoder to produce a latent space that looks like a prior distribution of your choice. If your prior is a normal Gaussian distribution then the latent vectors produced by the encoder will also assume that distribution, values will have a mean of 0 and a standard deviation of 1 and you can easily sample from it. You can basically impose any arbitrary distribution onto the latent space, even ones that cannot be expressed in a parametric way, as long as you have a method of sampling from them.", "As it is the tradition in adversarial training, this is achieved with a Discriminator, a different neural network model that learns to tell the output of a network from a real-world example of the target; but instead of learning to tell noise from real cat pictures, the discriminator learns to tell the latent space from the prior distribution and gives feedback to the encoder about how wrong the distribution of the latent space is. From this feedback in the form of a gradient, the encoder learns to distribute the code as desired.", "In the original paper on adversarial autoencoders, in chapters 5 and 6, the authors outline a method of how their architecture can be used for unsupervised clustering. The idea is that in addition to the latent vector, the encoder will also generate a categorical vector or so-called one-hot encoded vector, so a vector with one of its values being 1 and all other values being 0. This vector will also be fed into the decoder for reconstruction so that it will be likely to also carry relevant information about the input data, basically some sort of additional hint for the reconstruction. The idea is that this hint will be the same for similar input data, and these similarities are what we want the encoder to find and encode into categories. In contrast to classical clustering algorithms, where predefined parameters determine how the data is segregated, the encoder and decoder solely agree on where to draw the line between different categories, which can lead to interesting results.", "In order for the encoder to produce a categorical vector and not just another latent vector of arbitrary values, the authors also use adversarial training with a discriminator that is taught to tell if a vector is categorical or not. In the same fashion as with the latent vector the discriminator is trained on the vectors produces by the encoder as well as the \u201cprior distribution\u201d, which in this case is a bunch of random one-hot vectors. This discriminator will also give feedback to the encoder about how much the vector follows the rules, and by making it part of the encoders objective to satisfy the discriminator it will learn to create categorical vectors.", "Because the MNIST handwritten digits dataset was already done by the authors in the paper and is probably explored beyond reason at this point I want to try something a bit more intriguing instead. No, not cat pictures, unfortunately. The experiment I want to discuss here is something I recently investigated as part of a personal quest to build an algorithmic trading system, like many others before me, as it poses an interesting challenge. For this example, I will be using Foreign Exchange data, specifically the EUR-USD exchange rate for the year 2018, in 5-minute intervals. You can get this kind of data from many places on the Internet. I got mine from an online broker called Oanda, mostly because I like their REST API and that you can use it with a free paper trading account, to access all historical market data for the available instruments. In the end, it almost doesn\u2019t matter if you use FX data or apply the same strategy outlined here to stock- or crypto- or on non-financial time series data, like IoT sensor or medical data. You can find the code for downloading and preprocessing the data in the notebook attached at the end of the article.", "The features we\u2019ll create from the raw exchange data to ultimately feed to the autoencoder will be the logarithmic returns of the high, low and close price, the trade volume, as well as some statistics like the rolling mean, variance, and skewness of the close price and a few technical indicators, the Relative Strength Index, the Average True Range, and the Moving Average Convergence Divergence Signal line. There is no particular reason for the choices made except to include features that contain indications about trend strength and direction, volatility and deviation from the mean, and to have some features that the encoder has to find potential correlations, patterns and a succinct representation for, and clustering only on the noisy returns data does not yield the most meaningful results. There are definitely many other features you could include, or signals and data-sources to add.", "In order for the encoder to create a lower-dimensional representation and to recreate it into a sequence again, we need to work with signals of a fixed length, since the time component is lost in the compression and the sequence length needs to be explicitly defined when building the encoder, hence I decided to cut the data into windows of 32 time-steps. Since the features of our data have very different value ranges in parts, like the price, the volume, and the indicators, we perform z-score standardization for each channel on a per-window basis to bring all features into the same value range, and to preserve local patterns but not mix in extreme values from the past or future. That will be the data the encoder will try to cluster, local movements in a sequence of 32 readings of 5-minute time-intervals, as plotted in the image below.", "Note: I have haggled a lot about how to preprocess the data, by normalizing or standardizing over the entire data or just per-window. And what I\u2019ve found is that it heavily depends. If you\u2019d be building an algorithmic trading system and you would want to feed the result of the encoder into a classifier etc. then you would probably standardize on a per-window basis too. This has the implication that the encoder will cluster the data by these localized patterns. If you would have a dataset that never changes and you don\u2019t care about future values and want to cluster your data by global attributes then maybe normalizing or standardizing over the entire data would make more sense. After some experimentation with this, I can tell is that both approaches lead to quite different types of clusters for this type of data.", "Because we are dealing with time-series data we will build the encoder and decoder mostly from recurrent layers. A simple LSTM does not work for the specific task of encoding time series data I have found to some surprise after some trials, bi-directional LSTMs, on the other hand, work better than anything else I\u2019ve tried out so far, including Convolutional Networks. Some also recommend a combination of Convolutional and Recurrent Networks, in any case, it might need some experimentation to find an architecture that works well for your type of data.", "The encoder and decoder both mostly consist of two stacked, bi-directional LSTMs where the second LSTM of the encoder does not return a sequence but only its last state as a base for the latent representation and the categorical vector. The decoder consists of a similar, reversed setup and is fed with a combination of the latent vector and the categorical vector and tries to decode it back into a sequence that matches the input as closely as possible.", "The discriminators are designed as simple Multi-Layer Perceptrons, made from a few densely connected layers, as they only have to tell the distribution of rather low dimensional vectors apart, so you can\u2019t make them too good otherwise the encoder will not be able to fool the discriminators and will not properly converge on any task. This also counts for weighting the losses for each Task, the reconstruction of the input will have to produce the majority of the gradient or the encoder will not learn anything useful. On the other hand, you also can\u2019t make them too weak, or they will not learn to tell the samples apart, and no regularization will happen.", "Below is the code that creates the networks for the encoder/decoder and the discriminators. You can see that we are using batch normalization only in the encoder part, as the authors of the paper did suggest. I tried out using it in the decoder part as well and for the unsupervised clustering application, I can confirm that it only worsens the performance. You can see that the categorical vector has softmax as the activation function which helps in forming a categorical distribution and that the latent vector is activated with a linear function since it needs to be able to output values in an unbound range, to be able to satisfy the dictated distribution. The latent vector and the categorical vector are then simply concatenated and the result is repeated for the length of the input sequence so that the decoder part can reconstruct it into a sequence of the same length again. I also added a linear transformation after the input since I found that it speeds up the training somewhat when using rectifiers and input with negative values.", "When training the autoencoder the outputs of both the discriminators become part of the autoencoder's loss. The target for them is simply always 1, for real, as we want the encoder to learn a representation that makes the discriminator output 1, basically saying \u201cah yes, this is a sample from the prior distribution\u201d. Binary-Crossentropy works well as a loss-function for that, and if the encoder produces a latent vector or categorical vector that doesn\u2019t satisfy the discriminators the loss will create a gradient that will make the encoder learn a latent- and categorical representation that follows the rules, in theory.", "Below is the code that is used to glue the encoder and the discriminators together into the model that we can then train later as per the schematic above. Notice how we set the discriminators weights to trainable = false, this is necessary at this point because we wire them into the autoencoder, and when training the encoder we do not want the discriminator's weights to change. Later when training the discriminators we will change this setting but you have to do it while wiring them up or Keras or rather TensorFlow will complain that the set of trainable weights has changed.", "For training this setup we first start with training the discriminators. For that, let the encoder create a batch of latent- and categorical vectors and also create a second batch of vectors that you sample from the prior distributions. Next, you train the discriminator on these batches with the respective labels, fake (o) for the output of the encoder and real (1) for the samples from your priors. Then, you freeze the weights of the discriminators for this training iteration, because you don\u2019t want the discriminators to be updated when training the encoder since the error will flow through them. Next, you train the encoder on a batch of your data, with the goal to reproduce the input as accurately as possible, while also having the two other objectives to satisfy both the discriminators, aka. making them output 1, for real samples. After repeating this for about a few thousand randomized mini-batch training iterations the autoencoder starts to converge on all three tasks.", "During training you will probably notice that the accuracy of the discriminators will only fall slowly as long as the encoder is still learning the encoding and decoding, only when the gradient from this objective becomes shallower or plateaus the encoder will learn to redistribute the latent space and the categorical vector, which will, in turn, worsen the encoding/decoding performance again, which will steepen the gradient towards a lower reconstruction error. That means that the learning process often follows some sort of feedback loop, also due to the discriminators becoming better over time, that will become less intense as training goes on.", "When we now let the training loop as shown in the above code run for a total of 10 thousand iterations, you will probably get similar looking plots for the losses like in the following images below, which is from an example run that I have trained for this article with the included code, and that I want to discuss further in the following.", "In the images, you can see that the reconstruction loss is decreasing properly for the test- and validation set, so it doesn\u2019t look like we ran into overfitting. The accuracy for the discriminator for the categorical vector hovers between 50- and 70 percent, where 50 is pretty much optimal since at that point the discriminator is performing not better than random guessing at telling the vectors apart, which means that the encoder is successfully able to fool it. The accuracy for the discriminator for the latent vector is not looking so hot, after going down to about 60 we can see that it rises again, so it seems that the discriminator is outperforming the encoder a bit, but we can also see that it is slowly decreasing again, so with more training it might converge. Not ideal, but good enough for our purposes.", "Even though we can see that the accuracy and the reconstruction loss decrease, it is still a good idea to confirm the results visually after training is finished, and look at a few examples to see if the autoencoder actually learned to reproduce the input in a reasonable fashion and if we achieved our goal of producing actual categorical vectors.", "Below are a few examples of the in- and outputs that the encoder produces, as well as the latent- and categorical vectors. In the examples, you can see that the reconstruction is a strongly denoised version of the input, almost as if the encoder would capture the main frequency components of the input, which appears to be the best approach to approximate for the reproduction of such noisy data under the constraint of the code space. Furthermore, we can also confirm that we were successful in our attempt to regularize the encoder to produce the categorical vectors for our clustering; they appear to have one value close to 1 and the rest of the values hovering around 0, and what is even better is that the categorical vector seems to differ for most examples, which means the encoder did indeed assign different categories to different inputs. The error plot is mostly the noise from the input signal that didn\u2019t make it through, though we can see that sometimes the error is especially high for a channel or combination of channels when a sudden spike appeared that does not get encoded properly since it is probably an uncommon or anomalous pattern.", "Now that the autoencoder is trained, we can use it to generate class labels for all our data, and we can finally take a look at these clusters I\u2019ve been promising you. First, let\u2019s check how the classes are distributed. The size that you assign to the categorical vector does not necessarily correspond to the number of clusters that the autoencoder will identify. Often I\u2019ve gotten 6 to 7 classes, sometimes all 8, under some circumstances only 4. After running several experiments I can report that the number of clusters and the properties of the clusters is highly dependent on the autoencoders hyperparameters and architecture, the mini-batch size and the optimizer that is used, and also noticeably from the strength of the discriminators in comparison to the encoder. It almost seems to depend more on the network's hyperparameters than on the data itself.", "It seems that the encoder used all 8 categories to classify the input data in this example, and the classes that were identified appear to be more or less evenly distributed, though we can already see that class 0 is a bit over- and class 1 a bit underrepresented in our dataset. Now, let\u2019s see if the classes discovered by the encoder actually form some sort of clusters when we perform a t-SNE of the input data onto a 2D plane. The plot below shows that the class labels the encoder assigns actually form mostly coherent clusters, but some clusters appear to be more scattered and have samples far from their clusters center, which in part might be a side effect of the used embedding algorithm.", "Here is an alternative found with the same network setup with a slightly larger batch-size and Adam instead of Nadam as the optimizer. It converges in a very similar way during training, but the result is quite different. Instead of using all 8 classes the encoder puts the data in only 6 categories. Below is the histogram again and we can see that all classes are distributed quite evenly.", "I have found that the stronger you make the discriminator for the categorical vector, the fewer categories the encoder clusters the data in, whereas a lax discriminator causes for a wider range of classes with clusters that are more fractured. Both results are valid and interesting on their own.", "I will continue to mainly focus on the example that resulted in 8 classes as I liked the results but I wanted to show how can different the results can be with small changes to hyperparameters.", "So, now we have some categories that form colorful blobs, but what do those categories mean? Good question! As with many unsupervised clustering algorithms, the results are more meant as an inspiration supposed to make you think and puzzle about your data and what the algorithm could have found here so that you can investigate them further. I just want to take a quick look into some properties of these classes. If we map the categories back to the original input windows before we processed and standardized them and look at some of the statistical properties we might find intriguing differences between the classes.", "First I want to look at a histogram of the values for each class over all frames of that class, to see if we might be able to spot some intriguing differences in the distributions. When we create a histogram for the most significant channels of the input data, like the indicators we calculated, we can see some differences between the properties of the distributions, different means, standard deviations and skews.", "Depending on the outcome of the clustering sometimes there are strong differences in the distribution of some signals, and sometimes more in others.In this example, very often the ATR Signal has interestingly shaped distributions of which many look somewhat like Gaussian mixtures, and appear to have different means for each class. The MACD signal line seems to be a strong driver for the different classes as we can see that the majority of values lie within a narrow band in quite different means for each class, and similar can also be said about the distributions of the close price returns. The distributions for the RSI signal look very much like proper Gaussians, with the mode and skew differing slightly between classes as well.", "Earlier in the article, when talking about preprocessing the input data, I mentioned something about local patterns that we want the encoder to find and compress. Taking the above histograms into account it would be interesting to see if there are indeed common patterns that emerged for each class. So basically I want to see how the values of the individual channels develop over time for each class.", "For that, we just calculate the average value for each channel at each timestep over all the signals in a class. I actually expected to get mostly squiggly lines with no noticeable direction, and for the raw high, low and close returns signals this is mostly the case, even though for some classes these signals seem to average on some kind of \u201cwavy\u201d motion. More interesting are the signals for the rolling statistics and the technical indicators that we added to the raw data, where we can see clear tendencies for each class. For some classes, some of the channels move in opposite directions, while in other classes they move together. Also, we can see that for all classes found in the data, the MACD signal line and the running mean of the close price seem to be highly correlated and move together in some fashion, and the same seems to be the case for the ATR and the variance of the close price returns, which makes sense since these statistics and indicators in both cases make slightly different statements about the same things, volatility and trend.", "One thing you always get for free, no matter what you\u2019re intending to do with your autoencoder, is anomaly detection. Once an encoder is trained successfully most errors in the reconstruction should be the result of noise in the input data. If you look at the distribution of reconstruction error values per channel you can see that the distributions center at zero and have a rather low standard deviation for most channels, yet we can see that there are also some extreme values in parts. Since the encoder, under the constraint of the latent space and the additional constraint of an imposed distribution, which limits the value range, learns to reconstruct the patterns best which occur in the majority of samples. Patterns that only occur in a few samples are likely to have no proper encoding since there was simply no space for them, which results in a poor reconstruction. This reconstruction error can be a good measure to detect these uncommon events and classify them as outliers or anomalies in your dataset.", "Below you can see a plot of histograms of the error values for each channel. We can see that the error centers around 0 for all channels but has different standard deviations. If you wanted to detect anomalies in your data or identify uncommon events, you could choose a threshold for each channel at which a spike of the reconstruction error above this threshold would be indicative of such an event.", "Since we also took all this effort to cluster our data, you can do this on an even more fine-grained scale and choose a different threshold for each channel within each class. When we look at the histograms of errors for each channel split up by classes we can see that the distributions of errors have slight differences between the classes.", "Clustering data with an adversarial autoencoder is certainly one of the more exotic approaches that you can take, and even though there is probably a more traditional algorithm for many problems including time series and tabular data, there are certainly also just as many others where this might not be the case yet, like when dealing with image data for example.", "Often for traditional algorithms, you have to experiment with certain parameters like how many points you need for a neighborhood and what distance they should have or how many clusters you expect and then check if the results are satisfactory. With this approach, you have to experiment with architectures and hyper-parameters and finding the right fit is much more time-consuming than with simpler and optimized algorithms.", "Considering that you\u2019re doing some Deep Learning here the whole routine takes much longer and consumes generally more computational power than your regular off the mill clustering algorithms, but the approach is certainly highly interesting. It is probably more likely that you\u2019re building an autoencoder for a different reason and not just for clustering, but now you should have an idea of how you can not only regularize latent representations but also have your autoencoder cluster your data on the side as well.", "In the beginning, I talked a lot about the code space the encoders produce and how we need to regularize them and all that, but over all the fuss with the categorical vectors, I never showed you what actually happened to the code space after all that training. Looking at a histogram of the values from the latent space we can clearly see a well-formed gaussian distribution. Looks like the regularization worked just fine. It seems that even though the discriminator was not quite satisfied, it appears it just got too picky. The t-SNE of the latent space looks somewhat like a 2D Gaussian distribution as well, if you add the labels to the code space too you can see the clusters are less coherent here though.", "Thank you very much for reading, and below is the jupyter notebook as promised.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Software Engineer, Cat Worshipper & Coffee Disposal Unit. Interested in Coding, Machine Learning, and Science"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F311a4e1f271b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hanz.donny?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hanz.donny?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Donny Hanz"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F763811044bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&user=Donny+Hanz&userId=763811044bf3&source=post_page-763811044bf3----311a4e1f271b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://pixabay.com/photos/egypt-cairo-lamps-shining-bazaar-4269151/", "anchor_text": "Source: Pixabay"}, {"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "Adversarial Autoencoders"}, {"url": "https://arxiv.org/abs/1312.6114", "anchor_text": "Variational Autoencoders"}, {"url": "https://arxiv.org/abs/1511.05644", "anchor_text": "original paper"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----311a4e1f271b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----311a4e1f271b---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----311a4e1f271b---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/algorithmic-trading?source=post_page-----311a4e1f271b---------------algorithmic_trading-----------------", "anchor_text": "Algorithmic Trading"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----311a4e1f271b---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&user=Donny+Hanz&userId=763811044bf3&source=-----311a4e1f271b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&user=Donny+Hanz&userId=763811044bf3&source=-----311a4e1f271b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F311a4e1f271b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----311a4e1f271b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----311a4e1f271b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----311a4e1f271b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----311a4e1f271b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hanz.donny?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hanz.donny?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Donny Hanz"}, {"url": "https://medium.com/@hanz.donny/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "173 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F763811044bf3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&user=Donny+Hanz&userId=763811044bf3&source=post_page-763811044bf3--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9754f8528bad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-exploration-with-adversarial-autoencoders-311a4e1f271b&newsletterV3=763811044bf3&newsletterV3Id=9754f8528bad&user=Donny+Hanz&userId=763811044bf3&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}