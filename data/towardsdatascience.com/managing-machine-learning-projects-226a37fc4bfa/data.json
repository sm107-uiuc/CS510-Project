{"url": "https://towardsdatascience.com/managing-machine-learning-projects-226a37fc4bfa", "time": 1683014492.5950952, "path": "towardsdatascience.com/managing-machine-learning-projects-226a37fc4bfa/", "webpage": {"metadata": {"title": "Managing Machine Learning projects | Towards Data Science", "h1": "Managing Machine Learning projects", "description": "It involves a tight interaction with customers: To understand the data, challenge, and desired value that should be achieved through Machine Learning."}, "outgoing_paragraph_urls": [], "all_paragraphs": ["When I started working as a Machine Learning researcher at slashwhy (formerly SALT AND PEPPER Software) full time, I came from a background of developing in Unity with C# \u2014 and also in Python. Over the course of a few months, our team grew to a total of 5 people and we soon had to face a few very essential questions about the way we work and organize ourselves. As a quick background, we almost always work on deep learning projects with a wide range of different customers from the industrial sector, spanning work on large machine data to optical recognition and quality assurance. As such, our work always involves a tight interaction with our customers: To understand the data, the challenge, and the desired value that should be achieved through the use of Machine Learning.", "The questions that we had to ask ourselves were the following:", "While some of these questions might seem trivial at first, their answers are not straight forward. Back when we started out, we had limited computational resources as well as a limited budget \u2014 a situation that might sound familiar to anyone who has worked in a small, young team before. As such, while trying to find answers to our questions, we tried to avoid expensive out-of-the-box solutions and instead focused on freely available open-source solutions. Let\u2019s have a look at the aforementioned questions in turn and our solutions and experiences.", "To Jupyter or not to Jupyter?", "Three out of five people in our team had a background in more traditional software development. As such, using git as version control and having clear coding guidelines and style guides for projects was a concept we wanted to apply to our ML work as well.", "Gitlab was already used by almost all people in our company, so version control was not an issue. Code and project structure on the other hand was.Discussing how we might properly structure our workflow quickly brought up the question of Jupyter notebooks \u2014 and how to handle them in our daily routine. Looking at how popular notebooks and Google Collab have become, now you may ask \u201cWhy wouldn\u2019t I just use Jupyter notebooks for everything?\u201d. In our experience, Jupyter notebooks are great for exploratory work such as initial data exploration and even for mocking quick prototypes. They are easy to use and good in keeping track of what you are doing with your data. But once your project grows and things like Docker deployment, code re-usability and testing enter the stage, they quickly become an ugly mess. They also do not play well with version control since the logic of your algorithms is entangled with the representation syntax \u2014 making reviews a mess (especially if someone forgets to clear the output before committing).", "Thus, we decided to create a structural basis for all our upcoming projects and in the form of a template. In its first version, it was basically a bash script that created a file and folder structure which looked something like this:", "It was essential for us to keep our different projects as similar as possible. After all, we do customer work \u2014 there are new projects at a steady pace and it is initially not clear if they survive the proof of concept phase. We wanted to be able to look into a project that one of our team members had been working on and immediately understand what is going on without having to read through all of their code first. Also, having clearly structured projects makes communication with our customers much easier.", "Furthermore, we decided to use a single script called run.py as our central interface for all projects: It has to be identical in all repositories and manage things such as GPU usage and running either training or model inference on the specified data.", "While we decided against using Jupyter notebooks for our general coding routine, we still kept an exploratory notebook for the initial data exploration as part of our template.", "Having our projects set up this way already helped a lot, but still didn\u2019t solve a few essential issues:", "At this point, we had a clear code structure within our projects and even a style guide where we agreed on what coding guidelines to use. What we were still lacking was any way of methodically organizing our actual core work \u2014 ML experiments.", "Back then, we relied on Tensorboard for result tracking and visualization. This was mostly fine but had no central place to store and compare our results. Also, with us using different machines to run training on, it quickly led to a bunch of Tensorboard record files lying around here and there. In short, we were looking for a better solution.", "For us and most of our customers, data security and privacy are very important topics. For many clients it is absolutely no option to use cloud-based services in combination with their data. It is not uncommon to send data via physical hard drives as people tend to be very careful, especially with actual customer data. Whatever our solution to this problem looked like, it had to be on-premise and not a 3rd party cloud service.", "Luckily, around that time a new open source project came to live that would change our workflow quite substantially \u2014 Sacred. Sacred is a framework dedicated to managing ML experiments by logging and saving them to a database.", "We quickly decided to give it a try and turned one of our ML workstations into a MongoDB server. Having a decentralized project structure with many different scripts turned out to be a benefit here, as sacred integrates into this structure very well. Within a short time, we got our first projects running with sacred support. Now we had a central server with a very structured and organized tracking system \u2014 we decided to use Omniboard as a database viewer.", "The only issue back then was that Sacred still lacked a few features that seemed critical for us:", "When using sacred, it is common to have a dictionary of hyperparameters as part of your main training script which is used to override parameters in function calls. While we really liked this idea, it didn\u2019t quite fit our structure of separate scripts for each part of our code, so we added a config.py script to our New Project Template. This config script contains a default config that can be accessed via a function call, as well as a config override function which can create a list of permuted configs from multiple values for the same hyperparameter. If one for example wants to investigate the impact of different learning rate values on training performance, simply entering a list of multiple different values in the config creates and returns a list of multiple config dictionaries that can in turn be used for grid training.", "When we started using sacred, it was very much focused on running single experiments. It was already possible to merely queue up a run instead of starting it immediately, but this meant typing in different configurations for each such run. With our config.py script at hand, we thus extended run.py to use a list of different configs and automatically create a queue in our database from that. A multithreaded training loop with dedicated GPU access per training run made it possible for us to create a large grid training and have it run automatically without any further need for human supervision.", "Last but not least, we decided to write a few custom callbacks to expand Sacred\u2019s logging capabilities. At this point, this is what our project structure looked like:", "As you can see, a docker deployment folder has sneaked its way in there as well. Having all code neatly separated in individual scripts makes it easy to reuse it for tasks such as Docker deployment \u2014 or any deployment, in fact.", "With Sacred in place, we now had a clear project structure, code style guidelines, and an experiment management system. What we were still lacking though was something very fundamental \u2014 continuous testing.", "Whenever I read articles about ML, usually written by people with a Python background, I notice that despite large amounts of information on data processing or neural network fine-tuning, code quality is rarely an issue. This is alright if you work in a purely scientific environment and mostly just code for yourself. For us, writing code and hoping for the best by manually testing it was simply not enough.", "Thus, we added yet another section to our new project template \u2014 tests. We decided to use unittest, the classic Python package for testing your code. And then, we started writing tests.", "To make our lives a lot easier, we use the GitLab Continous Integration (CI) to automatically run our tests after each commit.", "Testing ML projects is often somewhat more complex than it is in other types of software development, but it can still help quite a lot! What we found to be most important to test in our project pipeline was the data loading and (pre)processing section. Here, with just a few bits of data added to the repository, one can automatically assure that whatever changes are made to the data pipeline, your intermediate results still keep their desired range, shape, and types.", "Continuous testing becomes a challenge if one looks at the training of a model though. Most of the time this is a time expensive process and something one would not want to run for every commit. It is also a highly stochastic process in a very sensitive floating-point regime and we had to write a lot of asserts with an error margin on floating-point accuracy. In the end, we divided our testing efforts according to a common computer science paradigm into integration and unit tests. We run the more complex and time-intensive tests that require the building of a complex model only for the merge requests and run the faster unit tests that check our data manipulation on every commit.", "Since we also need a bit of computational power we decoupled the GitLab runner from the company-wide pipelines and let it run on our dedicated machine learning servers.", "For sharing intermediate results with our customers we up to then had basically two strategies: 1 \u2014 quickly build up a few images and slides that explain our current state or 2 \u2014 directly use the Jupyter notebook. This is not optimal since we want to focus our meetings on results and have a slicker way of interacting with the data (instead of altering code and rerunning cells). It is also quite cumbersome to transfer working algorithms from the notebook structure to pure Python scripts that make up our remaining code structure. So we looked for different tooling.", "Thankfully we found Streamlit and were immediately convinced of its functionality. Streamlit allows for generating a small web application with a minimum of additional code. This was beneficial for us for the following reasons:", "In the development cycle it can become a bit slow due to the way Streamlit manages hot code replacements (basically it doesn\u2019t) but so far we couldn\u2019t find a better tool for this aspect of our projects.", "Our final and current NPT structure now looks like this:", "We work in a field that is moving at an incredible speed. It is already hard enough to keep track of all the moving parts in a regular software project, but we found that a Machine Learning project is way less standardized as of now. Our approach to ML the projects we work on puts us somewhere in between two popular approaches: The more data scientific side of validating first experiments with computationally less expensive algorithms and the fully cloud-enabled data pipeline with a rich ecosystem of hardware and software resources.", "The frameworks we settled for are currently the best fit for our needs and although this will (most likely) change in the upcoming months and years we are happy with the choices so far. They keep our work independent and allow for a very individual approach to each project while also ensuring flexible data handling and easy reuse of proven algorithms and routines. We started small but we always strive to improve on our daily doing and make it more efficient as well as improving our communication with our customers. Maybe this post helped you to answer some questions around setting up an end to end Machine Learning project and we hope that it was an interesting insight into our technology stack.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F226a37fc4bfa&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@tpetri?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tpetri?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Tobias Petri"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc23b814fdd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&user=Tobias+Petri&userId=c23b814fdd2&source=post_page-c23b814fdd2----226a37fc4bfa---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@mukukostudio?utm_source=medium&utm_medium=referral", "anchor_text": "Mukuko Studio"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://raw.githubusercontent.com/vivekratnavel/omniboard/master/docs/assets/screenshots/metric-graphs.png", "anchor_text": "vivekratnavel/omniboard"}, {"url": "https://unsplash.com/@headwayio?utm_source=medium&utm_medium=referral", "anchor_text": "Headway"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://github.com/streamlit/streamlit", "anchor_text": "ithub.com/streamlit/streamlit"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----226a37fc4bfa---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----226a37fc4bfa---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/devops?source=post_page-----226a37fc4bfa---------------devops-----------------", "anchor_text": "DevOps"}, {"url": "https://medium.com/tag/sacred?source=post_page-----226a37fc4bfa---------------sacred-----------------", "anchor_text": "Sacred"}, {"url": "https://medium.com/tag/project-management?source=post_page-----226a37fc4bfa---------------project_management-----------------", "anchor_text": "Project Management"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&user=Tobias+Petri&userId=c23b814fdd2&source=-----226a37fc4bfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&user=Tobias+Petri&userId=c23b814fdd2&source=-----226a37fc4bfa---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F226a37fc4bfa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----226a37fc4bfa---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----226a37fc4bfa--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tpetri?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@tpetri?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Tobias Petri"}, {"url": "https://medium.com/@tpetri/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "4 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc23b814fdd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&user=Tobias+Petri&userId=c23b814fdd2&source=post_page-c23b814fdd2--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fc23b814fdd2%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmanaging-machine-learning-projects-226a37fc4bfa&user=Tobias+Petri&userId=c23b814fdd2&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}