{"url": "https://towardsdatascience.com/binary-classification-with-logistic-regression-31b5a25693c4", "time": 1683001556.26545, "path": "towardsdatascience.com/binary-classification-with-logistic-regression-31b5a25693c4/", "webpage": {"metadata": {"title": "Binary Classification with Logistic Regression | by Dirk Hornung | Towards Data Science", "h1": "Binary Classification with Logistic Regression", "description": "In performance marketing, an important Key Performance Indicator (KPI) is given by the Click Through Rate (CTR). The CTR is the ratio of users who click on a specific link to the number of total\u2026"}, "outgoing_paragraph_urls": [{"url": "https://gist.github.com/Knowledge91/8b839bec47c8113c8f279e0cc574a40a", "anchor_text": "Gist", "paragraph_index": 20}, {"url": "https://web.stanford.edu/~hastie/ElemStatLearn/", "anchor_text": "https://web.stanford.edu/~hastie/ElemStatLearn/", "paragraph_index": 28}], "all_paragraphs": ["In performance marketing, an important Key Performance Indicator (KPI) is given by the Click Through Rate (CTR). The CTR is the ratio of users who click on a specific link to the number of total users who view a page, email, or advertisement (ad).", "Estimating the CTR is a binary classification problem. When a user views an ad he either clicks (y=1)or does not click (y=0). Having solely two possible results let us use logistic regression as our model. Logistic regression is applied to estimate any number of discrete classes in contrary to linear regression, which is used to infer continuous variables. I have given a simple visualization, which gives the right model to three of the major Data Science problems:", "In this story, I want to guide you first through the technical details of logistic regression before applying everything learned to a \u201cClick-Through Rate Prediction\u201d challenge of Kaggle\u00b9.", "Logistic regression is characterized by a logistic function to model the conditional probability of the label Y variables X", "In our case Y takes the state clicked or not clicked and X will be an observable of features we want to select (e.g. device type).", "We will work with m observations, each containing n features. For each of them, we will have m row vectors x\u1d62 of dimension n+1. Our labels Y can only be zero or one. The parameters will be given in a column vector \u0398 of dimension n+1.", "The conditional probability of a user who clicks given an observation X can then be modeled as the sigmoid function.", "The core of logistic regression is the sigmoid function. The sigmoid function maps a continuous variable to a closed set [0, 1], which then can be interpreted as a probability. Every data point on the right-hand side gets interpreted as y=1 and every data point on the left-hand side gets inferred as y=0.", "The sigmoid function appears naturally when deriving the conditional probability. We can express P(Y|X) with Bayes\u2019 theorem", "From a Bayesian interpretation we have", "We will fit the posterior and the prior to our data and have to get rid of the unknown probability P(X). This can be done by using the complement conditional probability.", "When dividing the posterior by the complement conditional probability and taking the logarithm we get the log-odds (logit)", "Here we assumed that the logit is a linear function in X! Now we just have to undo the logarithm and solve for the posterior to derive the sigmoid function", "So far we have modeled the posterior with a set of parameters \u0398. How do we determine the best choice of \u0398? The conditional probability of a user who clicked is equal to the sigmoid function. The sum over the probability of all cases has to add up to one. As we do have solely two cases we can find an elegant way to express both probabilities within a single expression:", "The right-hand side is referred to as the probability mass function (PMF) of the Bernoulli distribution. The Bernoulli distribution describes a random variable that can take one of two outcomes like our labels clicked or not clicked. Now to determine our parameters \u0398 we need to maximize the probability of reproducing the distribution of our population, while only be given a sample. This method is called maximum likelihood estimation (MLE). We principally join all the probabilities of every single event in our sample. This joint probability is called the likelihood, which has much in common with a probability but is focused on the parameters", "We could maximize the above function, but for convenience (to obtain prettier derivatives) we apply the logarithm to the likelihood. We can do so as the logarithm is a monotonically increasing and thus conserving the position of the maximum. By applying the logarithm the product turns into a sum", "To maximize the log-likelihood we can use calculus. The derivative of an extreme point has to be equal to zero", "In the last result, we have used the derivative with respect to \u0398 of the sigmoid function. The derivation is as follows", "To perform MLE we have to find the root of the first derivative of the log-likelihood. We can use the Newton-Raphson\u00b3 root-finding algorithm for this task. Newton-Raphson is the standard method to maximize the log-likelihood. It needs the second derivative to be calculated. In our case, we can analytically determine it. In other cases, where the second derivative is computationally expensive, we could use gradient descent (ascent) for the optimization. The second derivative is given by", "and the Newton-Raphson method then tells us how to update the parameters for each iteration.", "In the second part of this story, we want to code our own logistic regression implementation. The Jupyter notebook I build has been published as Gist. We will work with data from the \u201cClick-Through Rate Prediction\u201d Kaggle competition\u00b9. After downloading the data we unpack it and prepare a sample of 10000 rows before training on the complete set.", "We then load the CSV into a panda data frame and split it into a training and a test set", "Now you should focus on feature exploration, but to keep things simple I selected the columns device_type, C1, C15 and C16 as feature columns. I then can prepare my feature matrix X and use the click column as label", "For our algorithm to work we need the previously derived first and second derivative of the log-likelihood, which can be coded as follows", "The iterative Netwon-Raphons steps and our logistic regression algorithm are then", "By calling logisticRegression(X, y) we will iteratively calculate the parameters \u0398, which then can be used to make a prediction of the click probability of a user", "For a test run, we get the following probabilities", "To evaluate the model I compared predictions from the test set to their actual value, which showed that the model is rather poor. To improve we could spend more time on the feature selection and train on more data, while constantly measure the model performance with evaluation metrics like the logarithmic loss or the ROC curve.", "[2]: The Elements of Statistical Learning, T. Hastie, R. Tibshirani, J. Friedman https://web.stanford.edu/~hastie/ElemStatLearn/", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Former theoretical physicist and Full Stack Developer who tries to grasp some Data Science."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F31b5a25693c4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://drdirk.medium.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": ""}, {"url": "https://drdirk.medium.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Dirk Hornung"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13cd3eeb2a46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&user=Dirk+Hornung&userId=13cd3eeb2a46&source=post_page-13cd3eeb2a46----31b5a25693c4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://gist.github.com/Knowledge91/8b839bec47c8113c8f279e0cc574a40a", "anchor_text": "Gist"}, {"url": "https://www.kaggle.com/c/avazu-ctr-prediction", "anchor_text": "https://www.kaggle.com/c/avazu-ctr-prediction"}, {"url": "https://web.stanford.edu/~hastie/ElemStatLearn/", "anchor_text": "https://web.stanford.edu/~hastie/ElemStatLearn/"}, {"url": "https://en.wikipedia.org/wiki/Newton%27s_method", "anchor_text": "https://en.wikipedia.org/wiki/Newton%27s_method"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----31b5a25693c4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/logistic-regression?source=post_page-----31b5a25693c4---------------logistic_regression-----------------", "anchor_text": "Logistic Regression"}, {"url": "https://medium.com/tag/ai?source=post_page-----31b5a25693c4---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/data-science?source=post_page-----31b5a25693c4---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/classification?source=post_page-----31b5a25693c4---------------classification-----------------", "anchor_text": "Classification"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&user=Dirk+Hornung&userId=13cd3eeb2a46&source=-----31b5a25693c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&user=Dirk+Hornung&userId=13cd3eeb2a46&source=-----31b5a25693c4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F31b5a25693c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----31b5a25693c4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----31b5a25693c4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----31b5a25693c4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----31b5a25693c4--------------------------------", "anchor_text": ""}, {"url": "https://drdirk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://drdirk.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Dirk Hornung"}, {"url": "https://drdirk.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "67 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13cd3eeb2a46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&user=Dirk+Hornung&userId=13cd3eeb2a46&source=post_page-13cd3eeb2a46--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fdef563479df&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbinary-classification-with-logistic-regression-31b5a25693c4&newsletterV3=13cd3eeb2a46&newsletterV3Id=def563479df&user=Dirk+Hornung&userId=13cd3eeb2a46&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}