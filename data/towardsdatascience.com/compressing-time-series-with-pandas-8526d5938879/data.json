{"url": "https://towardsdatascience.com/compressing-time-series-with-pandas-8526d5938879", "time": 1683017291.977401, "path": "towardsdatascience.com/compressing-time-series-with-pandas-8526d5938879/", "webpage": {"metadata": {"title": "Compressing Time Series with Pandas | by Gautier Dagan | Towards Data Science", "h1": "Compressing Time Series with Pandas", "description": "So you\u2019ve done it, you\u2019ve got a nice time series with helpful features in a pandasDataFrame. Maybe you\u2019ve used pd.ffill()or pd.bfill() to fill in empty time steps using the previous or next value and\u2026"}, "outgoing_paragraph_urls": [{"url": "http://getmansa.com", "anchor_text": "Mansa", "paragraph_index": 1}], "all_paragraphs": ["So you\u2019ve done it, you\u2019ve got a nice time series with helpful features in a pandasDataFrame. Maybe you\u2019ve used pd.ffill()or pd.bfill() to fill in empty time steps using the previous or next value and perform analysis or feature extraction on your full series.", "We faced this problem today at Mansa, where we were saving hundreds (if not thousands) of unnecessary rows after our pre-processing pipeline was completed.", "Since we deal with financial data, we want to be able to tell the balance for an account at any point in time and to calculate statistics over number of days and through time. As a result, our pre-processing includes a step to resample our working DataFrame in order to fill all dates with missing information. The issue here was that we were saving this filled-in DataFrame with the resampled dates and filled-in values instead of compressing it back.", "TL;DR: Skip to the end gist for the most efficient way!", "To proxy our real data, I\u2019ve made this simple example generator that will spit out a filled up time-series. The date column here is the column of daily timestamps that will be generated and filled to be complete (through resampling).", "As a simple example, assume we have a user with an account that dates back to early 2018. This user uses it as a secondary account, and so only has a transaction every two days or so. Over three years, they only have 500 days where the balance actually changes.", "Say that in order to plot or analyse their balance over time we want to know it at the end of day mark, and so have to expand back the series of 500 observations to the full three years (resampling). Since balance remains in the account until it is observed to change, then we can fill the values of the days after an observation with the balance of that observation, until the next observation(ffill).", "So if I had a 5\u20ac balance on Thursday night and 500\u20ac on Sunday night, then I know that I also had 5\u20ac on Friday night and Saturday night, since observations only happen when there is a change in the balance.", "With about 500 random observations in three years, if we resample the dates to get the full daily DataFrame, we will get from 500 rows to around ~1k (365*3).", "Because if a day has the same balance as another day occurring much later, a naive drop_duplicates will ignore the temporal dimensionality of your data.", "Depending on how small are your time steps and how sparse are your observations, you can have a lot of repeated or empty rows in your DataFrame.", "My first approach was to simply iterate over the sorted DataFrame to detect whenever a row is different to a previous one (ignoring the time step column).", "In this case, I simply iterate over the rows in the DataFrame and find all indexes where a change happens between the time step i and i-1.", "This works, but iterrows is not fast.", "Timing the block of code with %%timeit and my small generated DataFrame I get:", "2. Taking a stab at using reduce :", "Ok so iterrows is slow, what can we do to make it faster. My second thought was to work directly with the numpy values array and use reduce from the standard library in order to efficiently go over two rows at a time.", "I first find the column indexes to compare (again ignoring the time step column \u201cdate\u201d) and then have a reduce function that appends a row if it is different from a previous one.", "We can then create a DataFrame back with the new values.", "This was already much faster (100x improvement)!", "But can we make it better?", "The next big realization I had was that since I only cared about the previous time step, I could simply shift the entire table to compare all values simultaneously!", "This simplifies the code greatly. I still only want to compare all columns excluding \u201cdate\u201d, so I shift the selection of columns by one and compare to the original. With ~(...).all(axis=1) I can compare the two row wise in order to select the rows in the original df that are not the same as the previous row.", "This is even faster (not a surprise since we are not iterating through anymore)! This is 4x faster than using the reduce approach and 400x faster than the naive iterrows !", "It also has the benefit of fitting on 2 lines of code!", "4. To go even faster we can implement this in numpy:", "This does the same as the pandas shift essentially.", "We construct the shift by using the np.roll function and setting the first element as nan. Again, we compare all values against the shifted array row wise.", "Nearly 5 times faster than the previous approach and 2000x faster than the naive approach!", "Note: For all of the solutions the DataFrame was assumed to be sorted by the time step (in this case \u201cdate\u201d) column. These solutions would not work otherwise.", "Avoid iterrows , use shift .", "In the end I\u2019ve opted for solution #3 and not the most performant since it is less lines of code and probably clearer to understand. Sometimes the simplicity of a solution is more important than its performance gains.", "I am sure we could push the performance even more and I challenge you, the reader, to try it!", "I hope that you learned something or that this has helped you tackle a similar problem. This is my first blog entry so apologies if a bit unstructured, I\u2019d really appreciate any feedback and if you think you have a different way of doing this don\u2019t hesitate let me know!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "MSc. in AI @ UVA | Previously, LD15 @ EF and 1st Employee + ML Engineer @ Mansa"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8526d5938879&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://gautier-dagan.medium.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": ""}, {"url": "https://gautier-dagan.medium.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Gautier Dagan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff14e37e12baf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&user=Gautier+Dagan&userId=f14e37e12baf&source=post_page-f14e37e12baf----8526d5938879---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@jjying?utm_source=medium&utm_medium=referral", "anchor_text": "JJ Ying"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "http://getmansa.com", "anchor_text": "Mansa"}, {"url": "https://medium.com/tag/pandas?source=post_page-----8526d5938879---------------pandas-----------------", "anchor_text": "Pandas"}, {"url": "https://medium.com/tag/python?source=post_page-----8526d5938879---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/time-series-analysis?source=post_page-----8526d5938879---------------time_series_analysis-----------------", "anchor_text": "Time Series Analysis"}, {"url": "https://medium.com/tag/data-science?source=post_page-----8526d5938879---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----8526d5938879---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&user=Gautier+Dagan&userId=f14e37e12baf&source=-----8526d5938879---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&user=Gautier+Dagan&userId=f14e37e12baf&source=-----8526d5938879---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F8526d5938879&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----8526d5938879---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----8526d5938879--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----8526d5938879--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----8526d5938879--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----8526d5938879--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----8526d5938879--------------------------------", "anchor_text": ""}, {"url": "https://gautier-dagan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://gautier-dagan.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Gautier Dagan"}, {"url": "https://gautier-dagan.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "5 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff14e37e12baf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&user=Gautier+Dagan&userId=f14e37e12baf&source=post_page-f14e37e12baf--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Ff14e37e12baf%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcompressing-time-series-with-pandas-8526d5938879&user=Gautier+Dagan&userId=f14e37e12baf&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}