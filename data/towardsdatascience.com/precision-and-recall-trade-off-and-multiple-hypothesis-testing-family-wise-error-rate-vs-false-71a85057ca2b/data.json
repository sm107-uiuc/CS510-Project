{"url": "https://towardsdatascience.com/precision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b", "time": 1682996269.286422, "path": "towardsdatascience.com/precision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b/", "webpage": {"metadata": {"title": "Precision and Recall Trade-off and Multiple Hypothesis Testing | by Giacomo Vianello | Towards Data Science", "h1": "Precision and Recall Trade-off and Multiple Hypothesis Testing", "description": "A deep dive into multiple hypothesis testing, and different techniques to balance precision and recall in such setting."}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/Gamma-ray_burst", "anchor_text": "explosions of large stars", "paragraph_index": 0}, {"url": "https://github.com/giacomov/giacomov.github.io/tree/master/notebooks", "anchor_text": "GitHub repository", "paragraph_index": 3}, {"url": "https://en.wikipedia.org/wiki/Statistical_hypothesis_testing", "anchor_text": "statistical tests, null vs alternative hypothesis, p-value, type I error and type II errors", "paragraph_index": 4}, {"url": "http://195.134.76.37/applets/AppletTtest/Appl_Ttest2.html", "anchor_text": "Student\u2019s T-test", "paragraph_index": 8}, {"url": "https://en.wikipedia.org/wiki/Binomial_distribution", "anchor_text": "Binomial distribution", "paragraph_index": 16}, {"url": "https://en.wikipedia.org/wiki/Precision_and_recall", "anchor_text": "Precision and Recall", "paragraph_index": 37}, {"url": "https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method", "anchor_text": "here", "paragraph_index": 39}, {"url": "https://www.jstor.org/stable/2346101?seq=1#page_scan_tab_contents", "anchor_text": "Benjamini and Holdberg (1995)", "paragraph_index": 43}, {"url": "http://www.linkedin.com/in/giacomovianello", "anchor_text": "www.linkedin.com/in/giacomovianello", "paragraph_index": 52}], "all_paragraphs": ["In my previous job as an Astrophysicist, I was working on detecting explosions of large stars (GRBs) releasing an incredible amount of energy. Our automatic analysis pipelines were searching for GRBs everywhere and anywhere because it is impossible to predict when and where such an explosion will occur. This posed an important challenge, related to the statistical nature of our detection process: multiple hypothesis testing.", "The same challenge can be found in my current job as a Data Scientist, for example when searching for anomalies in multiple datasets or performing many A/B tests.", "Let\u2019s start from the basics and illustrate what it means to have multiple tests.", "NOTE: this post is available as a runnable Jupyter notebook in my GitHub repository. The functions and classes I use throughout the post are available in a code cell at the end.", "In this post, I assume familiarity with some concepts, in particular, statistical tests, null vs alternative hypothesis, p-value, type I error and type II errors.", "Roughly speaking, a statistical test is something capable of either rejecting or not rejecting the null hypothesis with a given type I error probability \u03b1 (probability of a false positive) and a type II error probability \u03b2 (probability of a false negative).", "Let\u2019s consider the problem of determining whether two populations have the same average or not. The null hypothesis is that the average is the same, the alternative is that it is not.", "Note that you can substitute this problem with any other problem answerable with a statistical test and all the discussion here will still hold (but of course you need to rework the code).", "The test most appropriate for the problem at hand is the Student\u2019s T-test. Let\u2019s write the function that computes the p-value and a function that decides whether the null is rejected or not based on the p-value:", "We now generate a synthetic dataset with the null hypothesis set to true and we apply the test. We will use a type I error probability \u03b1=0.05:", "The test worked as expected, and didn\u2019t reject the null hypothesis (which we know is true). Let\u2019s verify that the performance of the test is nominal, i.e., that by repeating a large number of independent realizations of the same experiment we reject by chance the null hypothesis with the nominal type I error probability \u03b1:", "Ok, it works as expected. Of course, if you run this you might get a slightly different value due to the random nature of the generative process, but it should stay close to 0.05.", "Let\u2019s now imagine that we have m pairs of populations, and we want to find out whether one or more pairs have a significant difference between the populations of the pair.", "The null hypothesis here is \u201cwithin all pairs, the two populations have the same average,\u201d the alternative one is \u201cthere is at least one pair where the average is different between the two populations.\u201d", "Can we just apply the test separately to each pair and see if it rejects for at least one? (Spoiler: the answer is no! Also, let\u2019s neglect the fact that there are other tests designed for this situation). Let\u2019s see:", "At first, this result might come as a surprise. After all, we know that the null hypothesis is true!", "However, if you recall the definition of Type I error probability, by fixing \u03b1=0.05 we are setting up the test so that it will wrongly reject the null with 5% probability. Therefore, by repeating the test 50 times (one for each pair) we had each time a 5% chance of a type I error. The probability of having at least one rejection is hence given by the Binomial distribution:", "There is over 90% chance to get at least one false positive in our setup. Testing a hypothesis multiple times as part of the same question is called \u201cmultiple testing\u201d and requires some more thought.", "Bonferroni (1936) introduced a simple correction for situations like this. The prescription is to substitute \u03b1 for each one of the m independent tests within the composite test with a corrected type I error probability given by the Sidak formula \u03b1\u2032=1\u2212(1\u2212\u03b1)^(1/m) (which for large m is often approximated with \u03b1\u2032=\u03b1/m.", "Sometimes, in literature, the correction \u03b1\u2032=\u03b1/m is called \u201cBonferroni correction\u201d while the correction \u03b1\u2032=1\u2212(1\u2212\u03b1)^(1/m) is called \u201cSidak correction.\u201d Here we will use the latter formulation, but use the name interchangeably as the difference is very small for all practical purposes", "The justification for the Sidak formula can be derived very easily and it is a direct consequence of the observation we just found in the Binomial distribution. The probability \u03b1 of obtaining 1 or more successes in m trials with probability \u03b1\u2032 is given by 1\u2212B(m,p=\u03b1\u2032, k=0), where B(m,p=\u03b1\u2032, k=0) is the probability of obtaining 0 successes given by the Binomial distribution.", "Here we have just substituted k=0. Solving for \u03b1\u2032 we obtain the type I error probability that we need to use in each of the m tests to obtain a global type I error probability of \u03b1, which is the Bonferroni/Sidak correction.", "NOTE: we assume independent tests. If there is correlation between the different tests, the methods presented here might or might not apply, you need to look closer at the relevant papers.", "Let\u2019s see if this solves our problem. We just need to change the criterium used to decide whether to reject the null or not. There\u2019s no need to change the computation of the p-values:", "That looks better. In order to make sure, let\u2019s generate a lot of synthetic datasets and see if our Bonferroni-corrected test provides the nominal type I error probability \u03b1=0.05.", "It worked. The type I error probability is indeed very close to the nominal 5%.", "Until now we were dealing with the \u201cglobal\u201d null hypothesis for the problem \u201cis there any pair where the average is different between the two populations?\u201d The null hypothesis is that all pairs have the same average between the populations, the alternative being that at least one does not.", "However, often we are interested in another problem: \u201cfind all the pairs where the average is different\u201d. Or, \u201cfind all the stellar explosions\u201d, as in my Astrophysics problem. In this second case, each pair gets its own null and alternative hypothesis, and we are interested in how many null hypotheses are rejected.", "It is clear that the Bonferroni correction will still guarantee a global \u03b1 type I error probability of rejecting one or more nulls by chance, but it penalizes all tests in order to do so, because \u03b1 for each test is given by the Sidak formula and 1\u2212(1\u2212\u03b1)^(1/m) < \u03b1 for m>1.", "Moreover, as m grows, the global null hypothesis is still tested with the same type I error probability, but each of the m null hypotheses gets tested more and more restrictively, and as m\u2192\u221e we have \u03b1\u2032\u21920 so it would be extremely difficult to find any deviation from the null hypothesis. In other words, \u201cthe more you look, the less you find.\u201d", "Let\u2019s illustrate this by considering the Type II error of one single test, i.e. the probability of not rejecting the null when we should have. First, let\u2019s generate and test a pair where the null is false:", "We have rightfully rejected the null hypothesis. Now let\u2019s see how many times we fail to reject the null even if it is false over many repetitions of the same experiment (type II error probability):", "So, for one test we have a probability of around 6% (\u03b2=0.06) of not rejecting the null even if it is false (of course, \u03b2 depends on \u03b1, as well as on the size of the effect \u2014 in this case, the difference between the two averages).", "Now, let\u2019s see what happens if we use the Bonferroni-corrected test on 50 pairs, where only one has the null hypothesis false:", "Now we have a 41% probability of not rejecting the null when we should have. We clearly have lost a lot of sensitivity now that the difference in one pair is buried in a sample of 50 pairs.", "To some extent, this is inevitable and is the price we pay for not knowing exactly where to look.", "However, when trying to test all the local null hypotheses instead of the global one, things get out of hand very quickly. In order to get an idea, let\u2019s make several larger and larger datasets with 50 false null hypotheses each, and see how the type II error changes as a function of the number of pairs/tests m:", "NOTE: from now on, we will repeatedly use the concepts of Precision and Recall. The former describes the fraction of correct \u201cdetections\u201d (i.e., null hypothesis rejected) among all detections, i.e. describes the purity of the output sample of our procedure. The latter describes the fraction of null hyp. that we have rejected among the one that we should have rejected (i.e. the completeness of our output sample).", "We can see that the purity of the output sample is constant to 1.0, but the completeness is small and it also falls very quickly as the number of tests increases. In other words, we are detecting fewer and fewer anomalies as m increases, but the ones we detect are always correct. The type I error probability of detecting any false positive is always below the declared \u03b1 level, although very conservatively so for small m. Can we do better?", "There are several corrections that have been proposed to the vanilla Bonferroni/Sidak method. You can find them described here. Without going into the details of each one of them (see the Wikipedia page for that), let\u2019s just test them:", "The new methods conserve the absolute purity of the vanilla Bonferroni and a type I error below or at the nominal value, but improve the completeness a little bit. However, we can do a lot better than this! Let\u2019s see how.", "Up until now, our solutions to the problem of multiple hypothesis testing have been trying to keep the Family-Wise Error Rate (FWER) under control, i.e. the rate of type I errors committed in the entire set of m tests (what we called the global \u03b1 in the plots above).", "However, in the case where we expect several \u201cdetections\u201d (i.e. several false null hypotheses), we can sacrifice our desire for complete purity a little and decide that we can accept a controlled amount of false positives if this helps to improve the completeness. This is a very familiar idea for a Data Science practitioner: we can trade some precision for increased recall. In other words, we can accept to have a certain number of \u201cimpostors\u201d in our output sample of detections. This is the idea behind the FDR.", "Benjamini and Holdberg (1995) presented a procedure that does just that. There, \u03b1 does not represent the type I error probability anymore but rather controls the purity of the output sample (i.e. directly affects the Precision instead of the global \u03b1, as in our previous methods). The (expected) Precision is guaranteed to be >1\u2212\u03b1.", "As before, we refer to the paper for details. Here I want to illustrate the difference with respect to our earlier methods. Let\u2019s use the same procedure as before. For simplicity, let\u2019s consider only the best method for our problem among the Bonferroni-like ones, according to the previous plot (\u201cholm-sidak\u201d):", "We can immediately see that the BH method provides a much larger Recall (\u201ccompleteness\u201d, second panel) by sacrificing a controlled amount of Precision (\u201cpurity\u201d). Indeed, as promised, the Precision is >1\u2212\u03b1. Going from \u03b1=0.01 to \u03b1=0.05 in the BH method increases the purity as expected but decreases the completeness. Also, the global \u03b1 (bottom panel) for the BH method is large and close to 1, which means that in any experiment there is a high probability of getting one or more false positives. This is the price to pay for increasing the completeness, where we almost gain a factor of 2 especially for a large or even very large number of tests m with respect to Bonferroni-like methods.", "Now, we understand the key difference between FWER-controlling and FDR-controlling methods: the former put an upper limit \u03b1 on the FWER (\u201cglobal\u201d \u03b1, bottom panel), while the latter put a lower limit 1\u2212\u03b1 on the Precision (\u201cpurity,\u201d upper panel).", "Up to now, we have studied the case where the number of false null hypotheses are constant and the number of tests increases. What happens when the number of false hypotheses increases with the number of tests? This happens, for example, when we are expanding a search to a previously-unexplored part of the parameter space when we expect the false null hypotheses/anomalies (or stellar explosions, as in our Astronomical example) to have the same density as before.", "Results are similar as before, but now the completeness (Recall) for the BH method is essentially constant (middle panel), independently of m.", "We have illustrated the problem with multiple hypothesis testing, and two very different methods of dealing with it.", "NOTE: in this illustrative example we used one single effect size for all false null hypotheses. This is almost never the case, so the distribution of the effect size (the magnitude of the difference between the average of the two populations in our t-test example, or the brightness of the stellar explosion for our Astrophysical example) is going to obviously affect the number of anomalies/detections. However, the general idea presented here still holds. Using the FDR instead of the FWER allows detecting more and smaller effect sizes (increase the sensitivity/recall) at the expenses of some false positives.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Principal Data Scientist at Cape Analytics. Formerly a Research Scientist @ Stanford working in high-energy Astrophysics. www.linkedin.com/in/giacomovianello"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F71a85057ca2b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@giacomo.vianello?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giacomo.vianello?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Giacomo Vianello"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feb22dd1e98f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&user=Giacomo+Vianello&userId=eb22dd1e98f6&source=post_page-eb22dd1e98f6----71a85057ca2b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/towards-data-science/data-science-in-the-real-world/home", "anchor_text": "Data Science in the Real World"}, {"url": "https://en.wikipedia.org/wiki/Gamma-ray_burst", "anchor_text": "explosions of large stars"}, {"url": "https://en.wikipedia.org/wiki/Gamma_ray", "anchor_text": "Gamma-Rays"}, {"url": "https://fermi.gsfc.nasa.gov/", "anchor_text": "Fermi Space Telescope"}, {"url": "https://en.wikipedia.org/wiki/Galactic_coordinate_system", "anchor_text": "Galactic coordinates"}, {"url": "https://en.wikipedia.org/wiki/Galactic_plane", "anchor_text": "Galactic plane"}, {"url": "https://www.nasa.gov/multimedia/guidelines/index.html", "anchor_text": "NASA Media Usage guidelines"}, {"url": "https://nasa.tumblr.com/post/176492220069/gamma-ray-bursts-black-hole-birth-announcements", "anchor_text": "https://nasa.tumblr.com/post/176492220069/gamma-ray-bursts-black-hole-birth-announcements"}, {"url": "https://github.com/giacomov/giacomov.github.io/tree/master/notebooks", "anchor_text": "GitHub repository"}, {"url": "https://en.wikipedia.org/wiki/Statistical_hypothesis_testing", "anchor_text": "statistical tests, null vs alternative hypothesis, p-value, type I error and type II errors"}, {"url": "http://195.134.76.37/applets/AppletTtest/Appl_Ttest2.html", "anchor_text": "Student\u2019s T-test"}, {"url": "https://en.wikipedia.org/wiki/Binomial_distribution", "anchor_text": "Binomial distribution"}, {"url": "https://en.wikipedia.org/wiki/Precision_and_recall", "anchor_text": "Precision and Recall"}, {"url": "https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method", "anchor_text": "here"}, {"url": "https://www.jstor.org/stable/2346101?seq=1#page_scan_tab_contents", "anchor_text": "Benjamini and Holdberg (1995)"}, {"url": "https://en.wikipedia.org/wiki/Malmquist_bias", "anchor_text": "Malmquist bias"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----71a85057ca2b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/ds-in-the-real-world?source=post_page-----71a85057ca2b---------------ds_in_the_real_world-----------------", "anchor_text": "Ds In The Real World"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----71a85057ca2b---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&user=Giacomo+Vianello&userId=eb22dd1e98f6&source=-----71a85057ca2b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&user=Giacomo+Vianello&userId=eb22dd1e98f6&source=-----71a85057ca2b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F71a85057ca2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----71a85057ca2b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----71a85057ca2b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----71a85057ca2b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----71a85057ca2b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giacomo.vianello?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@giacomo.vianello?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Giacomo Vianello"}, {"url": "https://medium.com/@giacomo.vianello/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "100 Followers"}, {"url": "http://www.linkedin.com/in/giacomovianello", "anchor_text": "www.linkedin.com/in/giacomovianello"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feb22dd1e98f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&user=Giacomo+Vianello&userId=eb22dd1e98f6&source=post_page-eb22dd1e98f6--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd1fa0cbdc2ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprecision-and-recall-trade-off-and-multiple-hypothesis-testing-family-wise-error-rate-vs-false-71a85057ca2b&newsletterV3=eb22dd1e98f6&newsletterV3Id=d1fa0cbdc2ae&user=Giacomo+Vianello&userId=eb22dd1e98f6&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}