{"url": "https://towardsdatascience.com/the-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23", "time": 1682996946.99748, "path": "towardsdatascience.com/the-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23/", "webpage": {"metadata": {"title": "The Complete Guide to Resampling Methods and Regularization in Python | by Marco Peixeiro | Towards Data Science", "h1": "The Complete Guide to Resampling Methods and Regularization in Python", "description": "Resampling and regularization are two important steps that can significantly improve both your model\u2019s performance and your confidence in your model. In this article, cross-validation will be\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel", "paragraph_index": 3}, {"url": "https://towardsdatascience.com/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8", "anchor_text": "linear regression", "paragraph_index": 26}, {"url": "https://towardsdatascience.com/the-complete-guide-to-classification-in-python-b0e34c92e455", "anchor_text": "logistic regression", "paragraph_index": 26}, {"url": "https://github.com/marcopeix/ISL-Ridge-Lasso", "anchor_text": "dataset", "paragraph_index": 41}, {"url": "https://github.com/marcopeix/ISL-Ridge-Lasso", "anchor_text": "solution notebook", "paragraph_index": 41}], "all_paragraphs": ["Resampling and regularization are two important steps that can significantly improve both your model\u2019s performance and your confidence in your model.", "In this article, cross-validation will be extensively addressed as it is the most popular resampling method. Then, ridge regression and lasso will be introduced as regularization methods for linear models. Afterwards, resampling and regularization will be applied in a project setting.", "I hope this article will serve as a reference for one of your future projects, and that it finds its way into your bookmarks.", "For hands-on video tutorials on machine learning, deep learning, and artificial intelligence, checkout my YouTube channel.", "Resampling methods are an indispensable tool in modern statistics. They involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model. This allows us to gain more information that could not be available from fitting the model only once.", "Usually, the objective of a data science project is to create a model using training data, and have it make predictions on new data. Hence, the resampling methods allow us to see how the model would perform on data it has not been trained on, without collecting new data.", "Cross-validation (CV) is used to estimate the test error associated with a model to evaluate its performance or to select the appropriate level of flexibility. Evaluating a model\u2019s performance is usually defined as model assessment, and model selection is used for selecting the level of flexibility. This terminology is widely used in the field of data science.", "Now, there are different ways to perform cross-validation. Let\u2019s explore each one of them.", "This is the most basic approach. It simply involves randomly dividing the dataset into two parts: a training set and a validation set or hold-out set. The model is fit on the training set and the fitted model is used to make predictions on the validation set.", "Above is a schematic of the validation set approach. You have n observations in a dataset, it was randomly split into two parts. The blue side represents the training set, and the orange side is the validation set. The numbers simply represent the rows.", "Of course, with such a simple approach, there are some drawbacks.", "First, the validation test error rate is highly variable depending on which observations are in the training and validation set.", "Second, only a small subset of the observations are used to fit the model. However, we know that statistical methods tend to perform worse when trained on less data.", "Above, on the left, you see the MSE when the validation set approach was applied only once. On the right, the process was repeated 10 times. As you can see, the MSE greatly varies.", "This shows the significant variability of the MSE when the validation set approach is used.", "Of course, there are methods that address these drawbacks.", "The leave-one-out cross-validation (LOOCV) is a better option than the validation set approach. Instead of splitting the dataset into two subsets, only one observation is used for validation and the rest is used to fit the model.", "Above is a schematic of LOOCV. As you can see, only one observation is used for validation and the rest is used for training. The process is then repeated multiple times.", "After multiple runs, the error is estimated as:", "Which is simply the mean of the errors of each run.", "This method is much better, because it has far less bias, since more observations are used to fit the model. There is no randomness in the training/validation set splits. Therefore, we reduce the variability of the MSE, as shown below.", "This approach involves randomly dividing the set of observations into k groups or folds of approximately equal size. The first fold is treated as a validation set and the model is fit on the remaining folds. The procedure is then repeated k times, where a different group is treated as the validation set.", "Hence, you realize that LOOCV is a special case of k-fold cross validation where k is equal to total number of observations n. However, it is common to set k equal to 5 or 10.", "Whereas LOOCV is computationally intensive for large datasets, k-fold is more general and it can be used with any model. In addition, it often gives more accurate estimates of test error than does LOOCV. Therefore, to assess and validate your model, the k-fold cross-validation approach is the best option.", "Now that we know how cross-validation works and how it can improve our confidence in the model\u2019s performance, let\u2019s see how we can improve the model itself with regularization.", "Regularization methods effectively prevent overfitting. Overfitting occurs when a model performs well on the training set, but then performs poorly on the validation set.", "We have seen that linear models, such as linear regression and, by extension, logistic regression, use the least squares method to estimate the parameters.", "Now, we explore how we can improve linear models by replacing least squares fitting with other fitting procedures. These methods will yield better prediction accuracy and model interpretability.", "But why? Why use other fitting methods?", "Least squares fitting works most of the time, but there are situations where it will fail.", "For example, if your number of observations n is greater than the number of predictors p, then the least squares estimates will have a low variance and it performs well. On the other hand, with p is greater than n (more predictors than observations), then variance is infinite and the method cannot be used!", "Also, multiple liner regression tends to add variables that are not actually associated with the response. This adds unnecessary complexity to the model. It would be good if there was a way to automatically perform feature selection, such as to include only the most relevant variables.", "To achieve that, we introduce ridge regression and lasso. These are two common regularization methods, also called shrinkage methods.", "Shrinking the estimated coefficients towards 0 can significantly improve the fit and reduce the variance of the coefficients. Here, we explore ridge regression and lasso.", "Traditional linear fitting involves minimizing the RSS (residual sum of squares). In ridge regression, a new parameter is added, and now the parameters will minimize:", "Where lambda is a tuning parameter. This parameter is found using cross-validation as it must minimize the test error. Therefore, a range of lambdas is used to fit the model and the lambda that minimizes the test error is the optimal value.", "Here, ridge regression will include all p predictors in the model. Hence, it is a good method to improve the fit of the model, but it will not perform variable selection.", "Similarly to ridge regression, lasso will minimizes:", "Notice that we use the absolute value of the parameter beta instead of its squared value. Also, the same tuning parameter is present.", "However, if lambda is large enough, some coefficients will effectively be 0! Therefore, lasso can also perform variable selection, making the model much easier to interpret.", "Great! We know how regularization and resampling works. Now, let\u2019s apply these techniques in a project setting.", "Fire up a Jupyter notebook and grab the dataset. If you ever get stuck, the solution notebook is also available.", "Like with any project, we import our usual libraries that will help us perform basic data manipulation and plotting.", "Now, we can start our exploratory data analysis.", "We start off by importing our dataset and looking at the first five rows:", "Notice that the Unnamed: 0 column is useless. Let\u2019s take it out.", "And now, our dataset looks like this:", "As you can see, we only have three advertising mediums, and sales is our target variable.", "Let\u2019s see how each variable impacts the sales by making a scatter plot. First, we build a helper function to make a scatter plot:", "Now, we can generate three different plots for each feature.", "As you can see, TV and radio ads seem to be good predictors for sales, while there seems to be no correlations between sales and newspaper ads.", "Luckily, our dataset does not require further processing, so we are ready to move on to modelling right away!", "Let\u2019s take a look at what the code looks like, before going through it.", "First, we import the LinearRegression and cross_val_score objects. The first one will allow us to fit a linear model, while the second object will perform k-fold cross-validation.", "Then, we define our features and target variable.", "The cross_val_score will return an array of MSE for each cross-validation steps. In our case, we have five of them. Therefore, we take the mean of MSE and print it. You should get a negative MSE of -3.0729.", "Now, let\u2019s see if ridge regression or lasso will be better.", "For ridge regression, we introduce GridSearchCV. This will allow us to automatically perform 5-fold cross-validation with a range of different regularization parameters in order to find the optimal value of alpha.", "Then, we can find the best parameter and the best MSE with the following:", "You should see that the optimal value of alpha is 20, with a negative MSE of -3.07267. This is a slight improvement upon the basic multiple linear regression.", "For lasso, we follow a very similar process to ridge regression:", "In this case, the optimal value for alpha is 1, and the negative MSE is -3.0414, which is the best score of all three models!", "That\u2019s it! You now understand how resampling and regularization can greatly improve your model, and you know how to implement each in a project setting.", "I hope you found this article useful and that you refer back to it.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Senior data scientist | Author | Instructor. I write hands-on articles with a focus on practical skills."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5037f4f8ae23&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----5037f4f8ae23---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.youtube.com/channel/UC-0lpiwlftqwC7znCcF83qg?view_as=subscriber", "anchor_text": "YouTube channel"}, {"url": "https://towardsdatascience.com/the-complete-guide-to-linear-regression-in-python-3d3f8f06bf8", "anchor_text": "linear regression"}, {"url": "https://towardsdatascience.com/the-complete-guide-to-classification-in-python-b0e34c92e455", "anchor_text": "logistic regression"}, {"url": "https://github.com/marcopeix/ISL-Ridge-Lasso", "anchor_text": "dataset"}, {"url": "https://github.com/marcopeix/ISL-Ridge-Lasso", "anchor_text": "solution notebook"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5037f4f8ae23---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----5037f4f8ae23---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/python?source=post_page-----5037f4f8ae23---------------python-----------------", "anchor_text": "Python"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5037f4f8ae23---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----5037f4f8ae23---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----5037f4f8ae23---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----5037f4f8ae23---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5037f4f8ae23&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5037f4f8ae23---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5037f4f8ae23--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@marcopeixeiro?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Marco Peixeiro"}, {"url": "https://medium.com/@marcopeixeiro/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "3.6K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9835bccb3d51&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-resampling-methods-and-regularization-in-python-5037f4f8ae23&newsletterV3=741c1c8fcfbd&newsletterV3Id=9835bccb3d51&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://www.manning.com/books/time-series-forecasting-in-python-book", "anchor_text": "Time Series Forecasting in Python2022"}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}