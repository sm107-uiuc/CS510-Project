{"url": "https://towardsdatascience.com/a-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8", "time": 1683012858.9447649, "path": "towardsdatascience.com/a-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8/", "webpage": {"metadata": {"title": "A Step by Step Guide to Web Scraping in Python | by Sara A. Metwalli | Towards Data Science", "h1": "A Step by Step Guide to Web Scraping in Python", "description": "As data scientists, we are always on the look for new data and information to analyze and manipulate. One of the main approaches to find data right now is scraping the web for a particular inquiry\u2026"}, "outgoing_paragraph_urls": [{"url": "https://en.wikipedia.org/wiki/List_of_countries_by_coffee_production", "anchor_text": "coffee production", "paragraph_index": 44}, {"url": "https://en.wikipedia.org/wiki/Time%27s_List_of_the_100_Best_Novels", "anchor_text": "best 100 books of all time", "paragraph_index": 55}, {"url": "http://bit.ly/2CvFAw6", "anchor_text": "bit.ly/2CvFAw6", "paragraph_index": 78}], "all_paragraphs": ["As data scientists, we are always on the look for new data and information to analyze and manipulate. One of the main approaches to find data right now is scraping the web for a particular inquiry.", "When we browse the internet, we come across a massive number of websites, these websites display various data on the browser. If we, for some reason want to use this data for a project or an ML algorithm, we can \u2014 but shouldn\u2019t \u2014 gather this data manually. So, we will copy the sections we want and paste them in a doc or CSV file.", "Needless to say, that will be quite a tedious task. That\u2019s why most data scientists and developers go with web scraping using code. It\u2019s easy to write code to extract data from a 100 webpage than do them by hand.", "Web Scraping is the technique used by programmers to automate the process of finding and extracting data from the internet within a relatively short time.", "The most important question when it comes to web scraping, is it legal?", "The more detailed answer, scraping publically available data for non-commercial purposes was announced to be completely legal in late January 2020.", "You might wonder, what does publically available mean?", "Publically available information is the information that anyone can see/ find on the internet without the need for special access. So, information on Wikipedia, social media or Google\u2019s search results are examples of publically available data.", "Now, social media is somewhat complicated, because there are parts of it that are not publically available, such as when a user sets their information to be private. In this case, this information is illegal to be scraped.", "One last thing, there\u2019s a difference between publically available and copyrighted. For example, you can scrap YouTube for video titles, but you can\u2019t use the videos for commercial use because they are copyrighted.", "There are different programming languages that you can use to scrape the web, and within every programming language, there are different libraries to achieve the same goal.", "In this article, I will use Python, Requests, and BeautifulSoup to scrap some pages from Wikipedia.", "To scrap and extract any information from the internet, you\u2019ll probably need to go through three stages: Fetching HTML, Obtaining HTML Tree, then Extracting information from the tree.", "We will use the Requests library to fetch the HTML code from a specific URL. Then, we will use BeautifulSoup to Parse and Extract the HTML tree, and finally, we will use pure Python to organize the data.", "Before we get scraping, let\u2019s revise HTML basics quickly. Everything in HTML is defined within tags. The most important tag is <HTML> which means that the text to follow is HTML code.", "In HTML, each opened tag must be closed. So, at the end of the HTML file, we need a closure tag </HTML>.", "Different tags in HTML means different things. Using a combination of tags, a webpage is represented. Any text enclosed between an open and close tag is called inner HTML text.", "If we have multiple elements with the same tag, we might \u2014 actually, always \u2014 want to differentiate between them somehow. There are two ways to do that, either through using classes or ids. Ids are unique, which means we can\u2019t have two elements with the same id. Classes, on the other hand, are not. More than one element can have the same class.", "Here are 10 HTML tags you will see a lot when scraping the web.", "Awesome, now that we know the basics, let\u2019s start up small and then build up!", "Our first step is to install BeautifulSoup by typing the following in the command line.", "To get familiar with scraping basics, we will consider an example HTML code and learn how to use BeautifulSoup to explore it.", "BeautifulSoup doesn\u2019t fetch HTML from the web, it is, however, extremely good at extracting information from an HTML string.", "In order to use the above HTML in Python, we will set it up as a string and then use different BeautifulSoup to explore it.", "Note: if you\u2019re using Jupyter Notebook to follow this article, you can type the following command to view HTML within the Notebook.", "For example, the above HTML will look something like this:", "Next, we need to feed this HTML to BeautifulSoup in order to generate the HTML tree. HTML tree is a representation of the different levels of the HTML code, it shows the hierarchy of the code.", "The HTML tree of the above code is:", "To generate the tree, we write", "The variable soup now has the information extracted from the HTML string. We can use this variable to obtain information from the HTML tree.", "BeautifulSoup has many functions that can be used to extract specific aspects of the HTML string. However, two functions are used to most: find and find_all.", "The function find returns only the first occurrence of the search query, while find_all returns a list of all matches.", "Say, we are searching for all <h1> headers in the code.", "As you can see, the find function gave me the <h1> tag. With the tags and all. Often, we only want to extract the inner HTML text. To do that we use .text .", "That was simply because we only have one <h1> tag. But what if we want to look for list items \u2014 we have an unordered list with three items in our example \u2014 we can\u2019t use find. If we do, we will only get the first item.", "To find all the list items, we need to use find_all.", "Okay, now that we have a list of items, let\u2019s answer two questions:", "1- How to get the inner HTML of the list items?", "To obtain the inner text only, we can\u2019t use .text straight away, because now we have a list of elements and not just one. Hence, we need to iterate over the list and obtain the inner HTML of each list item.", "2- What if we have multiple lists in the code?", "If we have more than one list in the code \u2014 which is usually the case \u2014 we can be precise when searching for elements. In our example, the list has id=\u2019list\u2019 and class=\u2019coolList\u2019. We can use this \u2014 both or just one \u2014 with the find_all or find functions to be precise and get the information we want.", "One thing to note here is the return of the find or find_all functions are BeautifulSoup objects and those can be traversed further. So, we can treat them just like the object obtained directly from the HTML string.", "We can traverse the HTML tree using other BeautifulSoup functions, like children, parent, next, etc.", "Let\u2019s consider a more realistic example, where we fetch the HTML from a URL and then use BeautifulSoup to extract patterns and data.", "We will start by fetching one webpage. I love coffee, so let\u2019s try fetching the Wikipedia page listing countries by coffee production and then plot the countries using Pygal.", "To fetch the HTML we will use the Requests library and then pass the fetched HTML to BeautifulSoup.", "If we opened this wiki page, we will find a big table with the countries, and different measures of coffee production. We just want to extract the country name and the coffee production in tons.", "To extract this information, we need to study the HTML of the page to know what to query. We can just highlight a country name, right-click, and choose inspect.", "Through inspecting the page, we can see that the country names and the quantity are enclosed within a \u2018table\u2019 tag. Since it is the first table on the page, we can just use the find function to extract it.", "However, extracting the table directly will give us all the table\u2019s content, with the table header \u2014 the first row of the table \u2014 and the quantity in different measures.", "So, we need to fine-tune our search. Let\u2019s try it out with the top 10 countries.", "Notice that to clean up the results, I used string manipulation to extract the information I want.", "I can use this list to finally plot the top 10 countries using Pygal.", "Wow, that was a lot! \ud83d\ude03", "But, we yet to write code that scraps different webpages.", "For this section, we will scrap the wiki page with the best 100 books of all time, and then we will categorize these books based on their genre. Trying to see if we can find a relation between the genre and the list \u2014 which genre performed best.", "The wiki page contains links to each of the 100 books as well as their authors. We want our code to navigate the list, go to the book wiki page, extract info like genre, name, author, and publishing year and then store this info in a Python dictionary \u2014 you can store the data in a Pandas frame as well.", "So, to do this we need a couple of steps:", "Step #1: Fetch main URL HTML code", "Step #2: Feed that HTML to BeautifulSoup", "Step #3: Extract each book from the list and get the wiki link of each book", "Step #4: Obtain data for each book", "This is the most lengthy and important step. We will first consider only one book, assume it\u2019s the first one in the list. If we open the wiki page of the book we will see the different information of the book enclosed in a table on the right side of the screen.", "Going through the HTML we can see where everything is stored.", "To make things easier and more efficient, I wrote custom functions to extract different information from the book\u2019s wiki.", "Now, that we have these cool functions, let\u2019s write a function to use these functions, this will help us with the automation.", "In this function, I used the try..except formate to avoid crashing if some of the book's info is missing.", "Step #5: Get all books data, clean, and plot final results", "We have all we need to automate the code and run it.", "One last thing to note: It is legal to scrap Wikipedia, however, they don\u2019t like it when you scrap more than one page each second. So we will need to add pauses between each fetch to avoid breaking the server.", "Data collected! this will take 100 seconds to finish, so feel free to do something else while you wait \ud83d\ude09", "Finally, let\u2019s clean the data, get the genre count, and plot the results.", "I have to say, collecting data is not always a 100% accurate, as you can see in the plot, the longest bar belongs to the \u2018None\u2019 value. Which means one of two things", "That\u2019s why after automating the data collection, we often go through the weird and unusual results and recheck them manually.", "Web scraping is one of the essential skills a data scientist needs. And it can\u2019t be any easier than with using Python, Requests, and BeautifulSoup.", "We can never trust full automation, sometimes we will need to go through the final result a recheck for abnormal information manually.", "The full code for the books section:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Ph.D. candidate working on Quantum Computing. Traveler, writing lover, science enthusiast, and CS instructor. Get in touch with me bit.ly/2CvFAw6"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5c4d9cef76e8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://saraametwalli.medium.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": ""}, {"url": "https://saraametwalli.medium.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Sara A. Metwalli"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7938431b336a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&user=Sara+A.+Metwalli&userId=7938431b336a&source=post_page-7938431b336a----5c4d9cef76e8---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.pexels.com/@caio?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Caio"}, {"url": "https://www.pexels.com/photo/light-smartphone-macbook-mockup-67112/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels", "anchor_text": "Pexels"}, {"url": "https://towardsdatascience.com/choose-the-best-python-web-scraping-library-for-your-application-91a68bc81c4f", "anchor_text": "Choose the Best Python Web Scraping Library for Your ApplicationOverview of the top 5 libraries and when to use each of them.towardsdatascience.com"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://www.canva.com/", "anchor_text": "Canva"}, {"url": "https://en.wikipedia.org/wiki/List_of_countries_by_coffee_production", "anchor_text": "coffee production"}, {"url": "https://towardsdatascience.com/interactive-data-visualization-in-python-with-pygal-4696fccc8c96", "anchor_text": "Interactive Data Visualization In Python with PygalA Step by Step Tutorial To Create Stunning Visualizationstowardsdatascience.com"}, {"url": "https://towardsdatascience.com/a-guide-to-everything-string-formatting-in-python-e724f101eac5", "anchor_text": "A Guide to Everything String Formatting in PythonAll you need to know about the five methods to format strings in Pythontowardsdatascience.com"}, {"url": "https://en.wikipedia.org/wiki/Time%27s_List_of_the_100_Best_Novels", "anchor_text": "best 100 books of all time"}, {"url": "https://en.wikipedia.org/wiki/Time%27s_List_of_the_100_Best_Novels'", "anchor_text": "https://en.wikipedia.org/wiki/Time%27s_List_of_the_100_Best_Novels'"}, {"url": "https://en.wikipedia.org'", "anchor_text": "https://en.wikipedia.org'"}, {"url": "https://medium.com/tag/data-science?source=post_page-----5c4d9cef76e8---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/programming?source=post_page-----5c4d9cef76e8---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/software-development?source=post_page-----5c4d9cef76e8---------------software_development-----------------", "anchor_text": "Software Development"}, {"url": "https://medium.com/tag/web?source=post_page-----5c4d9cef76e8---------------web-----------------", "anchor_text": "Web"}, {"url": "https://medium.com/tag/computer-science?source=post_page-----5c4d9cef76e8---------------computer_science-----------------", "anchor_text": "Computer Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&user=Sara+A.+Metwalli&userId=7938431b336a&source=-----5c4d9cef76e8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&user=Sara+A.+Metwalli&userId=7938431b336a&source=-----5c4d9cef76e8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5c4d9cef76e8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5c4d9cef76e8---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5c4d9cef76e8--------------------------------", "anchor_text": ""}, {"url": "https://saraametwalli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://saraametwalli.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Sara A. Metwalli"}, {"url": "https://saraametwalli.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "7.7K Followers"}, {"url": "http://bit.ly/2CvFAw6", "anchor_text": "bit.ly/2CvFAw6"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7938431b336a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&user=Sara+A.+Metwalli&userId=7938431b336a&source=post_page-7938431b336a--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffe98bb54630a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-step-by-step-guide-to-web-scraping-in-python-5c4d9cef76e8&newsletterV3=7938431b336a&newsletterV3Id=fe98bb54630a&user=Sara+A.+Metwalli&userId=7938431b336a&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}