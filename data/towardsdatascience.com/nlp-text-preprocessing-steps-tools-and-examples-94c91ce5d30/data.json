{"url": "https://towardsdatascience.com/nlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30", "time": 1683015496.967148, "path": "towardsdatascience.com/nlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30/", "webpage": {"metadata": {"title": "NLP Text Preprocessing: Steps, tools, and examples | by Viet Hoang Tran Duong | Towards Data Science", "h1": "NLP Text Preprocessing: Steps, tools, and examples", "description": "Text data is everywhere, from your daily Facebook or Twitter newsfeed to textbooks and customer feedback. Data is the new oil, and text is an oil well that we need to drill deeper. Before we can\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/gpreda/covid19-tweets", "anchor_text": "Covid-19 Twitter", "paragraph_index": 1}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.1.%20clean%20%26%20filter%20english%20tweets.ipynb", "anchor_text": "part 1", "paragraph_index": 2}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.2.%20clean%20text%2C%20tags%20%26%20date.ipynb", "anchor_text": "part 2", "paragraph_index": 2}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.3.%20clean%20%26%20get_embeddings.ipynb", "anchor_text": "part 3", "paragraph_index": 2}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "codes", "paragraph_index": 2}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here", "paragraph_index": 2}, {"url": "https://pypi.org/project/langdetect/", "anchor_text": "Langdetect", "paragraph_index": 6}, {"url": "https://code.google.com/archive/p/language-detection/", "anchor_text": "language detection", "paragraph_index": 6}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.1.%20clean%20%26%20filter%20english%20tweets.ipynb", "anchor_text": "here", "paragraph_index": 8}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "resource", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "resources", "paragraph_index": 9}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "anchor_text": "here", "paragraph_index": 10}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "anchor_text": "resource", "paragraph_index": 10}, {"url": "https://pypi.org/project/geopy/", "anchor_text": "geopy", "paragraph_index": 11}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.2.%20clean%20text%2C%20tags%20%26%20date.ipynb", "anchor_text": "here", "paragraph_index": 13}, {"url": "https://spacy.io/usage/vectors-similarity", "anchor_text": "spacy", "paragraph_index": 14}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe", "paragraph_index": 14}, {"url": "https://github.com/google-research/bert", "anchor_text": "bert", "paragraph_index": 14}, {"url": "http://nlp.stanford.edu/data/glove.6B.zip", "anchor_text": "here", "paragraph_index": 15}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.3.%20clean%20%26%20get_embeddings.ipynb", "anchor_text": "part 3", "paragraph_index": 19}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "code", "paragraph_index": 21}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here", "paragraph_index": 22}], "all_paragraphs": ["Text data is everywhere, from your daily Facebook or Twitter newsfeed to textbooks and customer feedback. Data is the new oil, and text is an oil well that we need to drill deeper. Before we can actually use the oil, we must preprocess it so it fits our machines. Same for data, we must clean and preprocess the data to fit our purposes. This post will include a few simple approaches to cleaning and preprocessing text data for text analytics tasks.", "We will model the approach on the Covid-19 Twitter dataset. There are 3 major components to this approach: First, we clean and filter all non-English tweets/texts as we want consistency in the data.Second, we create a simplified version for our complex text data.Finally, we vectorize the text and save their embedding for future analysis.", "If you want to check out the code: feel free to check out the code for part 1, part 2, and part 3 embedded here. You can also check the whole project blogpost and codes here.", "First, to simplify the text, we want to standardize our text into only English characters. This function will remove all non-English characters.", "We can even do better by removing the stopwords. Stopwords are common words that appear in English sentences without contributing much to the meaning. We will use the nltk package to filter the stopwords. As our main task is visualizing the common theme of tweets using word cloud, this step is necessary to avoid common words like \u201cthe,\u201d \u201ca,\u201d etc. However, if your tasks require full sentence structure, like next word prediction or grammar check, you can skip this step.", "For tweets, there is a special feature we need to consider before cleaning: mentions. Your data might have special features like this (or not), and this is case-by-case and not a universal requirement. Hence, know your data well before blindly clean and preprocess!", "Before, we clean the non-English characters. Now, we remove the non-English texts (semantically). Langdetect is a python package that allows for checking the language of the text. It is a direct port of Google\u2019s language detection library from Java to Python.", "We then filter out all columns then is not \u201cen\u201d language.", "All of the codes for part 1 can be found here.", "For numerical data, good processing methods are scaling, standardizing, and normalizing. This resource is beneficial in understanding and applies these methods to your data. Within this post's scope, I will not discuss further as other resources have done a great job doing so.", "For categorical data, there are numerous approaches. The two nominal approaches are Label Encoder (assigning a distinct number for each label) and One hot encoding (represent with a vector of 0s and 1). More details on the approach to these categorical values can be found here. This resource is very substantial with more types of encoding than these two I mentioned.", "This post will introduce some ways to reduce the complexity of data, especially location data. In my dataset, there is a column for location, with the address of the author. However, I cannot perform much analysis with these raw data as they are too messy and complex (having city, county, state, country). Hence, we can standardize the text and reduce it to the \u201ccountry\u201d level (or state if you are interested). A package to deal with location data is geopy. It can identify the correct address and reformat these locations to standard form. Then, you can choose to keep whichever information you need. For me, the state, country is decent enough.", "Python is awesome with so many packages. I believe you can always find something for your specific need, as I do with my messy location data. Good luck with simplifying these messy data.", "The code for part 2 can be found here.", "Text vectorization is converting text into vectors of values to represent their meanings. Earlier days, we have one hot encoding method with a vector with a size of our vocabulary, and value 1 wherever the text appear and 0s elsewhere. Nowadays, we have more advanced methods like spacy, GloVe, or even bert embedding. For the scope of this project, I will introduce you to GloVe in python and Jupiter notebooks.", "First, we download the embeddings. You can download it manually here or do it directly in your notebooks.", "Then, we create a function to vectorize each data point. The sentence is the mean representation of each word. For empty sentences, we default it to a zeros vector.", "Finally, we vectorize the whole dataset and save the vectorized numpy array as a file, so we don\u2019t have to go through this process again every time running the code. The vectorized version will be saved as a numpy array in the form of .npy files. Numpy package is convenient in storing and dealing with massive array data.", "As my personal standard practice, I try to save all data as separate files after each part to evaluate the data and alter my code more flexibly.", "The code for part 3 is here.", "Data preprocessing, specifically with text, can be a very troublesome process. A big part of your machine learning engineer workflow will be for these cleaning and formatting data (lucky you if your data is already perfectly clean & kudos to all data engineers for making that happen).", "All the code in this post is very abstract and can be applied to many data projects (you only need to change to the name of columns, and all should work properly). In the notebook, I also added exception functions to handle failure cases, ensuring that your code will not crash midway. I hope it helps you with your projects, as much as it helps me in mine.", "You can check out the project blog post here.", "Good luck with your projects, and let me know if anything needs to change and improve! Thank you, and see you in the next posts!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "ML Engineer | CS Senior @ Minerva | Founder @ Vizly | AI/ML developer and just a person who loves cooking and traveling"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F94c91ce5d30&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@viethoangtranduong?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@viethoangtranduong?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Viet Hoang Tran Duong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc5d004a4e555&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&user=Viet+Hoang+Tran+Duong&userId=c5d004a4e555&source=post_page-c5d004a4e555----94c91ce5d30---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.kaggle.com/gpreda/covid19-tweets", "anchor_text": "Covid-19 Twitter"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.1.%20clean%20%26%20filter%20english%20tweets.ipynb", "anchor_text": "part 1"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.2.%20clean%20text%2C%20tags%20%26%20date.ipynb", "anchor_text": "part 2"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.3.%20clean%20%26%20get_embeddings.ipynb", "anchor_text": "part 3"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "codes"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here"}, {"url": "https://pixabay.com/illustrations/personal-data-data-click-3914806/", "anchor_text": "Source"}, {"url": "https://pypi.org/project/langdetect/", "anchor_text": "Langdetect"}, {"url": "https://code.google.com/archive/p/language-detection/", "anchor_text": "language detection"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.1.%20clean%20%26%20filter%20english%20tweets.ipynb", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "resource"}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "resources"}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "anchor_text": "resource"}, {"url": "https://pypi.org/project/geopy/", "anchor_text": "geopy"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.2.%20clean%20text%2C%20tags%20%26%20date.ipynb", "anchor_text": "here"}, {"url": "https://spacy.io/usage/vectors-similarity", "anchor_text": "spacy"}, {"url": "https://nlp.stanford.edu/projects/glove/", "anchor_text": "GloVe"}, {"url": "https://github.com/google-research/bert", "anchor_text": "bert"}, {"url": "http://nlp.stanford.edu/data/glove.6B.zip", "anchor_text": "here"}, {"url": "http://nlp.stanford.edu/data/glove.6B.zip", "anchor_text": "http://nlp.stanford.edu/data/glove.6B.zip"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets/blob/master/1.3.%20clean%20%26%20get_embeddings.ipynb", "anchor_text": "part 3"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "code"}, {"url": "https://github.com/viethoangtranduong/covid19-tweets", "anchor_text": "here"}, {"url": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02", "anchor_text": "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02"}, {"url": "https://www.kaggle.com/kazanova/sentiment140", "anchor_text": "https://www.kaggle.com/kazanova/sentiment140"}, {"url": "https://www.kaggle.com/gpreda/covid19-tweets", "anchor_text": "https://www.kaggle.com/gpreda/covid19-tweets"}, {"url": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02", "anchor_text": "https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02"}, {"url": "https://medium.com/tag/nlp?source=post_page-----94c91ce5d30---------------nlp-----------------", "anchor_text": "NLP"}, {"url": "https://medium.com/tag/twitter?source=post_page-----94c91ce5d30---------------twitter-----------------", "anchor_text": "Twitter"}, {"url": "https://medium.com/tag/data-science?source=post_page-----94c91ce5d30---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/ai?source=post_page-----94c91ce5d30---------------ai-----------------", "anchor_text": "AI"}, {"url": "https://medium.com/tag/data?source=post_page-----94c91ce5d30---------------data-----------------", "anchor_text": "Data"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&user=Viet+Hoang+Tran+Duong&userId=c5d004a4e555&source=-----94c91ce5d30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&user=Viet+Hoang+Tran+Duong&userId=c5d004a4e555&source=-----94c91ce5d30---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F94c91ce5d30&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----94c91ce5d30---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----94c91ce5d30--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----94c91ce5d30--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----94c91ce5d30--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@viethoangtranduong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@viethoangtranduong?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Viet Hoang Tran Duong"}, {"url": "https://medium.com/@viethoangtranduong/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "39 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc5d004a4e555&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&user=Viet+Hoang+Tran+Duong&userId=c5d004a4e555&source=post_page-c5d004a4e555--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1012bc530fa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnlp-text-preprocessing-steps-tools-and-examples-94c91ce5d30&newsletterV3=c5d004a4e555&newsletterV3Id=1012bc530fa4&user=Viet+Hoang+Tran+Duong&userId=c5d004a4e555&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}