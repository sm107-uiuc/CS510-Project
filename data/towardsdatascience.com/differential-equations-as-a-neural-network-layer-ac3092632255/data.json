{"url": "https://towardsdatascience.com/differential-equations-as-a-neural-network-layer-ac3092632255", "time": 1683006262.0620391, "path": "towardsdatascience.com/differential-equations-as-a-neural-network-layer-ac3092632255/", "webpage": {"metadata": {"title": "Differential Equations as a Neural Network Layers | by Kevin Hannay | Towards Data Science", "h1": "Differential Equations as a Neural Network Layers", "description": "The main idea of artificial neural networks (ANN) is to build up representations for complicated functions using compositions of relatively simple functions called layers. Although layers are\u2026"}, "outgoing_paragraph_urls": [{"url": "https://github.com/FluxML/Flux.jl", "anchor_text": "Flux", "paragraph_index": 9}, {"url": "https://github.com/SciML/DiffEqFlux.jl", "anchor_text": "DiffEqFlux", "paragraph_index": 9}, {"url": "https://docs.sciml.ai/v5.0.0/", "anchor_text": "DifferentialEquations", "paragraph_index": 9}, {"url": "https://github.com/khannay/FittingParamsDiffEqFlux/", "anchor_text": "posted in this Github repo", "paragraph_index": 9}, {"url": "https://en.wikipedia.org/wiki/Stuart%E2%80%93Landau_equation", "anchor_text": "Stuart-Landau equation", "paragraph_index": 23}, {"url": "http://www.lsd.df.uba.ar/materias/dnl/dnl_2011_files/guias_files/Ott_Chaos.pdf", "anchor_text": "populations of coupled oscillators", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Arrow_of_time", "anchor_text": "arrow of time", "paragraph_index": 25}, {"url": "https://en.wikipedia.org/wiki/Lorenz_system", "anchor_text": "lorenz system.", "paragraph_index": 34}, {"url": "https://github.com/SciML", "anchor_text": "scientific machine learning sciml)", "paragraph_index": 45}, {"url": "https://julialang.org/blog/2019/01/fluxdiffeq/", "anchor_text": "initial conditions to be on the GPU", "paragraph_index": 47}, {"url": "https://github.com/khannay/FittingParamsDiffEqFlux/", "anchor_text": "can be found here", "paragraph_index": 48}], "all_paragraphs": ["The main idea of artificial neural networks (ANN) is to build up representations for complicated functions using compositions of relatively simple functions called layers.", "A deep neural network is one that has many layers, or many functions composed together.", "Although layers are typically simple functions( e.g. relu(Wx+b)) in general they could be any differentiable functions.", "The layer is specified by some finite vector of parameters \u03b8 \u2208 \u211d\u1d56. To be practically useful we need to be able to fit this layer (or layers) to data. This involves defining a cost or loss function which measures the closeness of the model prediction to the data.", "If our layers are differentiable then we can find the gradient of this cost function \u2207C(\u03b8) and use this to find a local minimum of the cost in an efficient manner.", "Here I am considering differential equations models. These systems describe the time evolution of the state of a system (x) in time, using an expression which involves the derivative of the current state. In general, they take the form:", "A differential equation fits into our neural network framework, as it takes in some parameters and produces the solution as output and it is differentiable.", "Thus, we can use a differential equation as a layer in a neural network. This is really neat for a few reasons:", "For simplicity, in this article, I am going to focus on neural networks with a single differential equations based layer in this article. However, these layers could easily be embedded as one layer in a deep learning project. The combination of deep learning with domain knowledge in the form of a differential equation is a game-changer in many fields.", "To demonstrate how you can build your own differential equations layers into neural networks I am going to make use of the Julia Flux, DiffEqFlux and DifferentialEquations libraries. In the article, I will keep the code to small snippets to allow for developing intuition, but the full code for these examples has been posted in this Github repo.", "To begin we will consider fitting the parameters of a classic model in mathematical biology. The Lotka-Volterra predator prey model describes the oscillations in a population that can be observed in simple ecological communities.", "A famous example of this can be observed in the Hudson bay trading company fur trade data from the 1800s.", "The equations for the model are given by", "The predator species oscillations will tend to lag behind the peak in the prey species population.", "Now let\u2019s use this model as a layer in a neural network, with a set of six parameters. Two for the initial populations of the prey x\u2080 and predators y\u2080 and the four rate parameters \u03b1, \u03b2, \u03b4, \u03b3.", "In Julia, we can define this system and a set of default parameters.", "Now we define the differential equation layer as a function of the input parameters. The parameter array has the first two entries as the initial conditions.", "The next thing to do is generate some fake data to fit from (add some noise) and then define a loss function. I used a simple mean square error loss function for our data, although we certainly could add some regularization of the parameters to the loss function easily.", "Finally, we define a function to actually perform the model fitting. Here is where the Julia ecosystem really pays off as this system can easily use gradient methods for fitting the parameters.", "As you can see I use 3000 Adams iterations followed by a call to BFGS to fit minimize the cost. This is a good combination, you could just jump straight to BFGS but the convergence will take much longer. It is better to let the Adams iterations get you in the neighborhood and then finish with BFGS.", "The recovered parameters are given by:", "Here is a plot of our data against the simulated time-series data. As you can see the minimization finds and excellent fit to the data.", "Of course, the real test for a neural network is how it generalizes to validation data. In this case, we can easily test the system for an unobserved initial condition to see if our neural network has captured the dynamics.", "Now let\u2019s consider the problem of recovering the parameters from a dynamical system that often comes up in my research field. The Stuart-Landau equation describes the dynamics of a nonlinear system which is near a Hopf bifurcation (common way oscillations emerge in nonlinear systems). I\u2019m going to consider a variation of this which comes up in the study of synchrony in populations of coupled oscillators.", "Part of the motivation for using this model is due to my familiarity with this model. However, I have another deeper motivation. The Lotka-Volterra predator-prey model is a great model to start with, but it is kind of a weird model for mathematical biology. It is a conservative system, much like is observed in physical system (without friction). This means instead of having an isolated attracting oscillation (called a limit cycle) the Lotka-Volterra system has a whole class of concentric cycles.", "This has the potential to skew our understanding of fitting differential equation models, because conservative systems retain a memory of initial conditions. For limit cycle oscillations we lose information about the initial conditions over time (transient dynamics decay, arrow of time). Since many initial conditions end up at the same final state this could make the question of parameter recovery more difficult.", "The equations for the system are given by:", "these are written in polar coordinates. Thus R describes the amplitude and \u03c8 the angle in radians. The dynamics take the qualitative form of", "In Julia it is a simple matter to update our predator prey model to allow for this type of system.", "Now we define a ode layer generate some data and create a loss function.", "Finally, the following function creates runs an optimization to recover parameters.", "The recovered parameters are given by:", "The fit for the training data is shown below:", "We can test our model further by looking at how well it generalizes for new initial values.", "Now time for a fun application. Let\u2019s consider a parameter recovery using time-series data from a chaotic system. For this, we will use the famous lorenz system.", "It is simple enough to define this system in Julia:", "As a matter of demonstration let\u2019s take a look at some time series data for the X variable generated from slightly different initial condition values.", "This plot demonstrates a sensitive dependence on initial conditions which is a hallmark of chaos.", "As usual, we define a differential equation layer which depends on initial conditions and parameters.", "Generate some data and add some noise to the time-series and define our usual error function.", "Now define the training function using the DiffEqFlux library.", "Running the optimization gives a good fit to the training data, which generalizes well when we integrate for times beyond the training sample.", "We can also look at the training model fit in a time-series plot.", "Since the model was only trained on t \u2208 [0,10], we can see that the model generalizes pretty well for t \u2208 [10,20] but quickly diverges from the true value after that time.", "So we have found a pretty close fit.", "It is relatively straightforward to include differential equation models into neural networks using the Julia ecosystem (scientific machine learning sciml). This allows us to include whole branches of knowledge through classical dynamical systems models into our neural network models for time-series data. The next step is to combine these differential equations layers into our deep learning models.", "On the subject of the interface of dynamical systems and artificial neural networks. Three possible generalizations of what we have begun here are:", "Also, I should mention that all of the models we discussed in this article can easily be moved to the GPU for training. One simply has to declare the initial conditions to be on the GPU.", "Reminder all of the code for this article can be found here.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Applied Math PhD, Machine Learning Engineer"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fac3092632255&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac3092632255--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@moleculeboy24?source=post_page-----ac3092632255--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moleculeboy24?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Kevin Hannay"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2aee0cbca1e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&user=Kevin+Hannay&userId=2aee0cbca1e1&source=post_page-2aee0cbca1e1----ac3092632255---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://github.com/FluxML/Flux.jl", "anchor_text": "Flux"}, {"url": "https://github.com/SciML/DiffEqFlux.jl", "anchor_text": "DiffEqFlux"}, {"url": "https://docs.sciml.ai/v5.0.0/", "anchor_text": "DifferentialEquations"}, {"url": "https://github.com/khannay/FittingParamsDiffEqFlux/", "anchor_text": "posted in this Github repo"}, {"url": "https://en.wikipedia.org/wiki/Stuart%E2%80%93Landau_equation", "anchor_text": "Stuart-Landau equation"}, {"url": "http://www.lsd.df.uba.ar/materias/dnl/dnl_2011_files/guias_files/Ott_Chaos.pdf", "anchor_text": "populations of coupled oscillators"}, {"url": "https://en.wikipedia.org/wiki/Arrow_of_time", "anchor_text": "arrow of time"}, {"url": "https://en.wikipedia.org/wiki/Lorenz_system", "anchor_text": "lorenz system."}, {"url": "https://github.com/SciML", "anchor_text": "scientific machine learning sciml)"}, {"url": "https://arxiv.org/abs/1806.07366", "anchor_text": "Neural differential equations"}, {"url": "https://towardsdatascience.com/work-smarter-not-harder-when-building-neural-networks-6f4aa7c5ee61", "anchor_text": "show poor convergence in modeling time-series"}, {"url": "https://arxiv.org/abs/2001.04385", "anchor_text": "Universal differential equations"}, {"url": "https://github.com/SciML/DiffEqFlux.jl#universal-differential-equations-for-neural-optimal-control", "anchor_text": "control function"}, {"url": "https://arxiv.org/abs/1803.04779", "anchor_text": "Hybrid dynamical systems"}, {"url": "https://julialang.org/blog/2019/01/fluxdiffeq/", "anchor_text": "initial conditions to be on the GPU"}, {"url": "https://github.com/khannay/FittingParamsDiffEqFlux/", "anchor_text": "can be found here"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ac3092632255---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ac3092632255---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/differential-equations?source=post_page-----ac3092632255---------------differential_equations-----------------", "anchor_text": "Differential Equations"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----ac3092632255---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&user=Kevin+Hannay&userId=2aee0cbca1e1&source=-----ac3092632255---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&user=Kevin+Hannay&userId=2aee0cbca1e1&source=-----ac3092632255---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ac3092632255--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fac3092632255&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----ac3092632255---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----ac3092632255--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ac3092632255--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ac3092632255--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ac3092632255--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ac3092632255--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moleculeboy24?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@moleculeboy24?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Kevin Hannay"}, {"url": "https://medium.com/@moleculeboy24/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "301 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2aee0cbca1e1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&user=Kevin+Hannay&userId=2aee0cbca1e1&source=post_page-2aee0cbca1e1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Ffe6194563141&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdifferential-equations-as-a-neural-network-layer-ac3092632255&newsletterV3=2aee0cbca1e1&newsletterV3Id=fe6194563141&user=Kevin+Hannay&userId=2aee0cbca1e1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}