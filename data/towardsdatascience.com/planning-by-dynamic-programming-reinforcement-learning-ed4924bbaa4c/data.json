{"url": "https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c", "time": 1682993986.9297202, "path": "towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c/", "webpage": {"metadata": {"title": "Planning by Dynamic Programming: Reinforcement Learning | by Ryan Wong | Towards Data Science", "h1": "Planning by Dynamic Programming: Reinforcement Learning", "description": "In this blog post, I will be explaining how to evaluate and find optimal policies using Dynamic Programming. This series of blog posts contain a summary of concepts explained in Introduction to\u2026"}, "outgoing_paragraph_urls": [{"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "Introduction to Reinforcement Learning", "paragraph_index": 0}], "all_paragraphs": ["In this blog post, I will be explaining how to evaluate and find optimal policies using Dynamic Programming. This series of blog posts contain a summary of concepts explained in Introduction to Reinforcement Learning by David Silver.", "We will now use the concepts such as MDPs and the Bellman Equations discussed in the previous parts to determine how good a given policy is and how to find an optimal policy in a Markov Decision Process.", "Dynamic programming is a method for solving complex problems by breaking them down into sub-problems. The solutions to the sub-problems are combined to solve overall problem.", "The two required properties of dynamic programming are:", "Markov Decision Processes satisfy both of these properties:", "Dynamic programming can be used to solve reinforcement learning problems when someone tells us the structure of the MDP (i.e when we know the transition structure, reward structure etc.). Therefore dynamic programming is used for the planning in a MDP either to solve:", "Given a MDP <S, A, P, R, \u03b3> and a policy \u03c0. Find the value function v_\u03c0 (which tells you how much reward you are going to get in each state). i.e the goal is to find out how good a policy \u03c0 is.", "Given a MDP <S, A, P, R, \u03b3>. Find the optimal value function v_\u03c0 and the optimal policy \u03c0*. i.e the goal is to find the policy which gives you the most reward you can receive with the best action to choose.", "Problem: Evaluate a given policy \u03c0 and MDP. (Find out how good a policy \u03c0 is)Solution: Iterative application of Bellman Expectation backup.", "Approach:Start with initial value function v\u2081 (a value of all states in the MDP). E.g. start with a value of 0. Therefore there is no reward. Then use the Bellman Expectation Equation to compute v\u2082 and repeat many times, which will eventually converge to v_\u03c0.", "One method to achieve this convergence is to use synchronous backups where we consider all states at every step.", "v\u2096(s\u2019) is updated using the Bellman Expectation Equation discussed in Part 2.", "Example:Suppose we have a grid world with 14 states, where each block represents a state. We also have 2 terminal states, one in the bottom right and the other in the top left of the grid world. We can take the actions of moving up, down, left and right with each transition we take gives us a immediate reward of -1 until a terminal state is reached. With a discount factor of \u03b3=1 and our given policy \u03c0 for our agent follows a uniform random policy:", "We need to compute the value of being in each state to determine how good our defined policy \u03c0 is.", "1. By following our approach described above we can start with an initial value function v\u2080 with all values being 0.", "2. Next we compute the new value function v\u2081 using the Bellman Expectation Equation by applying a one step look ahead.", "3. Repeating the processing using v\u2081 to compute v\u2082", "4. Repeating this process with k=\u221e will eventually converge our value function to v_\u03c0.", "We have therefore computed the value associated to being in each state in our MDP for our policy \u03c0.", "How to Improve a Policy?In the above approach we have evaluated a given policy but not found the best policy (actions to take) in our environment. In order to improve a given policy we can evaluate a given policy \u03c0 and improve the policy by acting greedily with respect to v_\u03c0. This can be done using Policy Iteration.", "Problem: Find the best policy \u03c0* for a given MDP. Solution: Bellman Expectation Equation Policy Iteration and Acting Greedy.", "Approach:Start with a given policy \u03c0", "In order to act greedily we use a one step look ahead to determine the action which gives us the maximum action value function (described in Part 2):", "Recall the action value function has the following equations:", "An alternative approach to control problems is with value iteration using the Bellman Optimality Equation. First we need to define how we can divide an optimal policy into its components using the Principle of Optimality.", "Principle of OptimalityAny optimal policy can be subdivided into two components which make the overall behaviour optimal:- An optimal first action A\u2217- Followed by an optimal policy from successor state S", "Theorem (Principle of Optimality)A policy \u03c0(a|s) achieves the optimal value from state s, v_\u03c0(s)=v\u2217(s), if and only if:- For any state s\u2019 reachable from s- \u03c0 achieves the optimal value from state s\u2019, v_\u03c0(s\u2019 )=v\u2217(s\u2019 )", "Problem: Find the optimal policy \u03c0* for a given MDP. Solution: Iterative application of Bellman Optimality backup", "Approach:Using synchronous backups update the value function until the optimal value function is computed without computing the action value function.", "v\u2096(s\u2019) is updated using the Bellman Optimality Equation discussed in the Part 2:", "By repeating the above process, it will eventually converge to v*. Note this process differs to policy iteration in that intermediate value functions may not correspond to any policy.", "All the algorithms described in this post are solutions to planning problems in reinforcement learning (where we are given the MDP). These planning problems (prediction and control) can be solved using synchronous dynamic programming algorithms.", "Prediction problems can be solved using the Bellman Expectation Equation Iterative (Policy Evaluation).", "Control problems can be solved using Bellman Expectation Equation Policy Iteration & Greedy (Policy Improvement) or the Bellman Optimality Equation (Value Iteration).", "If you enjoyed this post and want to see more don\u2019t forget follow and/or leave a clap."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fed4924bbaa4c&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@taggatle?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Ryan Wong"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ed4924bbaa4c---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=-----ed4924bbaa4c---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "Introduction to Reinforcement Learning"}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d", "anchor_text": "1"}, {"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb", "anchor_text": "2"}, {"url": "https://towardsdatascience.com/model-free-prediction-reinforcement-learning-507297e8e2ad", "anchor_text": "4"}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/DP.pdf", "anchor_text": "UCL Course on RL \u2014 Lecture 3"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ed4924bbaa4c---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----ed4924bbaa4c---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/reinforcement-learning?source=post_page-----ed4924bbaa4c---------------reinforcement_learning-----------------", "anchor_text": "Reinforcement Learning"}, {"url": "https://medium.com/tag/data-science?source=post_page-----ed4924bbaa4c---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed4924bbaa4c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ed4924bbaa4c---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F87d33b7279c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&newsletterV3=8c034a2353ca&newsletterV3Id=87d33b7279c4&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Written by Ryan Wong"}, {"url": "https://medium.com/@taggatle/followers?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "347 Followers"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8c034a2353ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&user=Ryan+Wong&userId=8c034a2353ca&source=post_page-8c034a2353ca----ed4924bbaa4c---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F87d33b7279c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fplanning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c&newsletterV3=8c034a2353ca&newsletterV3Id=87d33b7279c4&user=Ryan+Wong&userId=8c034a2353ca&source=-----ed4924bbaa4c---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Getting Started with Markov Decision Processes: Reinforcement LearningPart 2: Explaining the concepts of the Markov Decision Process, Bellman Equation and Policies"}, {"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "7 min read\u00b7Oct 2, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&user=Ryan+Wong&userId=8c034a2353ca&source=-----ada7b4572ffb----0-----------------clap_footer----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/getting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb?source=author_recirc-----ed4924bbaa4c----0---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fada7b4572ffb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-markov-decision-processes-reinforcement-learning-ada7b4572ffb&source=-----ed4924bbaa4c----0-----------------bookmark_preview----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://barrmoses.medium.com/?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Barr Moses"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Zero-ETL, ChatGPT, And The Future of Data EngineeringThe post-modern data stack is coming. Are we ready?"}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "9 min read\u00b7Apr 3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&user=Barr+Moses&userId=2818bac48708&source=-----71849642ad9c----1-----------------clap_footer----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/zero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c?source=author_recirc-----ed4924bbaa4c----1---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "21"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F71849642ad9c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fzero-etl-chatgpt-and-the-future-of-data-engineering-71849642ad9c&source=-----ed4924bbaa4c----1-----------------bookmark_preview----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=author_recirc-----ed4924bbaa4c----2---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ed4924bbaa4c----2-----------------bookmark_preview----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "Reinforcement Learning: An Introduction to the Concepts, Applications and CodePart 1: An introduction to reinforcement learning, explaining common terms, concepts and applications."}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": "5 min read\u00b7Sep 23, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fced6fbfd882d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d&user=Ryan+Wong&userId=8c034a2353ca&source=-----ced6fbfd882d----3-----------------clap_footer----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d?source=author_recirc-----ed4924bbaa4c----3---------------------f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fced6fbfd882d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d&source=-----ed4924bbaa4c----3-----------------bookmark_preview----f560e7ba_2074_45fc_b3f3_fadc391a6bcf-------", "anchor_text": ""}, {"url": "https://medium.com/@taggatle?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "See all from Ryan Wong"}, {"url": "https://towardsdatascience.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "See all from Towards Data Science"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Steve Roberts"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "State Values and Policy Evaluation in 5 minutesAn Introduction to Reinforcement Learning"}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b75 min read\u00b7Jan 11"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&user=Steve+Roberts&userId=6b6735266652&source=-----f3e00f3c1a50----0-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@tinkertytonk/state-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff3e00f3c1a50&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40tinkertytonk%2Fstate-values-and-policy-evaluation-in-5-minutes-f3e00f3c1a50&source=-----ed4924bbaa4c----0-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "AI Anyone Can Understand Part 1: Reinforcement LearningReinforcement learning is a way for machines to learn by trying different things and seeing what works best. For example, a robot could\u2026"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&user=Andrew+Austin&userId=42d388912d13&source=-----6c3b3d623a2d----1-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c3b3d623a2d&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-reinforcement-learning-6c3b3d623a2d&source=-----ed4924bbaa4c----1-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----0-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----ed4924bbaa4c----0---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----ed4924bbaa4c----0-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://kayjanwong.medium.com/?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://kayjanwong.medium.com/?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Kay Jan Wong"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "6 Reinforcement Learning Algorithms ExplainedIntroduction to reinforcement learning terminologies, basics, and concepts (model-free, model-based, online, offline RL)"}, {"url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b714 min read\u00b7Nov 25, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F237a79dbd8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F6-reinforcement-learning-algorithms-explained-237a79dbd8e&user=Kay+Jan+Wong&userId=fee8693930fb&source=-----237a79dbd8e----1-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e?source=read_next_recirc-----ed4924bbaa4c----1---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F237a79dbd8e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F6-reinforcement-learning-algorithms-explained-237a79dbd8e&source=-----ed4924bbaa4c----1-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----2-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----ed4924bbaa4c----2---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----ed4924bbaa4c----2-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@zitaa?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/@zitaa?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Zita"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "7 Best Data Science YouTubers to Watch for Free LearningCheck out these creators for expert insights and practical examples for Data Science Learning"}, {"url": "https://towardsdatascience.com/7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": "\u00b76 min read\u00b7Dec 20, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F610ecc5ee847&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847&user=Zita&userId=938acdb89e4c&source=-----610ecc5ee847----3-----------------clap_footer----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847?source=read_next_recirc-----ed4924bbaa4c----3---------------------b5732635_b93e_4bb4_93b5_df0844742cc1-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F610ecc5ee847&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-best-data-science-youtubers-to-watch-for-free-learning-610ecc5ee847&source=-----ed4924bbaa4c----3-----------------bookmark_preview----b5732635_b93e_4bb4_93b5_df0844742cc1-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----ed4924bbaa4c--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}