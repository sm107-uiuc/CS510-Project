{"url": "https://towardsdatascience.com/beyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d", "time": 1683004923.135274, "path": "towardsdatascience.com/beyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d/", "webpage": {"metadata": {"title": "Guide to Advanced CNNs in tensorflow | Towards Data Science", "h1": "Complete Guide to Advanced CNNs in Tensorflow 2", "description": "Create advanced CNNs and counter overfitting. Learn to make sparsely connected and skip architectures. Find out about Depth Seperable and Dilated Conv2D."}, "outgoing_paragraph_urls": [{"url": "https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728", "anchor_text": "article", "paragraph_index": 1}, {"url": "https://keras.rstudio.com/reference/layer_spatial_dropout_2d.html", "anchor_text": "Keras documentation for spatial documentation", "paragraph_index": 3}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout", "anchor_text": "documentation", "paragraph_index": 5}, {"url": "https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-5-dropout-and-noise-29d980ece933", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-ker", "anchor_text": "here", "paragraph_index": 9}, {"url": "https://arxiv.org/abs/1409.4842", "anchor_text": "Inception", "paragraph_index": 11}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "ResNet50", "paragraph_index": 15}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Deep Residual Learning for Image Recognition", "paragraph_index": 15}], "all_paragraphs": ["The first ConvNet model I built was to identify dogs or cats and had a basic structure of a sequential model having Conv2d layers along with a mix of batch normalization and max-pooling layers here and there and not to forget a dropout layer to counter overfitting\ud83d\ude0f. All this was followed by a flattening layer which ultimately led to a Dense layer. They were added to the model using add. It worked well and gave a good enough accuracy. Then I tried the famous MNIST dataset and used the same architecture. All I had to do was to change the loss in my dense layer from binary cross-entropy to categorical cross-entropy and tada I felt I had mastered CNNs. But, boy, was I wrong! There is a lot more to it like making sparsely connected architectures with different types of Conv2d layers, applying different techniques for overfitting and lots more.", "They are more efficient, require less memory and less computation and can even provide better results in some cases. Due to these characteristics, they are generally used when our model has to be deployed on Edge/IoT devices because they have limited CPU and RAM. It divides the process of a normal convolution layer into two processes i.e. depthwise convolution and pointwise convolution. In depthwise convolution, the kernel iterates over one channel at a time. The pointwise convolution uses a 1x1 kernel to increase the number of channels. This way the total number of multiplications required is reduced and that makes our network faster. This is a great article to learn more about it.", "Dilated convolutions can be implemented in normal convolution layers as well as depthwise separable convolution layers. It is a normal convolution operation with gaps. Along with providing a larger receptive field, efficient computation and lesser memory consumption it also preserves the resolution and order of data. Hence it generally improves the performance of the model.", "In normal dropout, some randomly selected neurons are ignored during training. Those neurons do not contribute in the forward pass and their weights are not updated during backward pass. This leads the network to learn multiple independent internal representations and it makes it less probable to overfit on the training data. In spatial dropout instead of dropping neurons, we drop out entire feature maps. As stated in the Keras documentation for spatial documentation:", "If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, spatial dropout will help promote independence between feature maps and should be used instead.", "It is a combination of dropout and Gaussian noise. That means that this layer along with dropping some neurons also applies multiplicative 1-centered Gaussian noise. Like the normal dropout, it also takes the argument rate. From its documentation:", "Float, drop probability (as with dropout). The multiplicative noise will have standard deviation sqrt(rate / (1 \u2014 rate)).", "For more in-depth reading about it, you can refer to this article here.", "Regularization makes slight changes to networks so that they generalize better. It encourages a neural network to learn sparse features or internal representations of raw observations which makes the model perform better on unseen data. There are three types of regularization techniques supported:", "The value of weight matrices decreases due to the addition of the regularization term and it leads to simpler models which reduces overfitting. For more information about regularization techniques refer here.", "There are two types of architectures, densely connected and sparsely connected.", "It was popularised by the Inception network. So what was the need for these types of architectures? Can\u2019t we just keep on adding layers and the deeper the network the better the result? Well, not at all. The bigger the model, the more prone is it to overfitting especially with smaller datasets and it also increases the amount of computation power required to train it. Sometimes even the training error even becomes worse. Sparsely connected architectures help us in increasing the depth and width of our models while not overshooting the computation power needed. They can have different sizes of kernels for convolutions which also helps the model when the test objects are of different sizes.", "Generally, we use tf.keras.layers.add to make densely connected architectures. We can visualize our models using tf.keras.utils.plot_model.", "We can also create models like these by assigning them to variables and placing them the variable name to the layer it is connected to at the end. Input shape is specified in tf.keras.layers.Input and tf.keras.models.Model is used to underline the inputs and outputs i.e. the first and last layer of our model.", "Now, to make sparsely connected architectures we just need to assign some layer to multiple layers and then use tf.keras.layers.concatenate to join them.", "This was popularised by the network ResNet50. The main idea behind skip connections was to solve this problem given below by Microsoft Research as given in their paper Deep Residual Learning for Image Recognition.", "When deeper networks are able to start converging, a degradation problem has been exposed: with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly. Unexpectedly, such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error\u2026", "Its advantage is that it makes estimating good values for the weights easier and the model generalizes better.", "If you understood how to make sparsely connected architectures, you can easily guess how this will work but in this case to join them we will use tf.keras.layers.Add.", "Using these techniques might improve our model, but that\u2019s not always the case. They might even perform worse than a simple densely connected architecture with normal Conv2D layers. You will need to try and see which strategy gives the best results.", "For revision purposes, I have created a model using the concepts provided above. This is just for revision purpose and I do not garuntee that this model will give better results.", "Your home for data science. A Medium publication sharing concepts, ideas and codes."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa7562d25ca2d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@vardanagarwal16?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Vardan Agarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b122513e3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&user=Vardan+Agarwal&userId=e0b122513e3b&source=post_page-e0b122513e3b----a7562d25ca2d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral", "anchor_text": "Markus Spiske"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728", "anchor_text": "article"}, {"url": "http://www.erogol.com/dilated-convolution/", "anchor_text": "here"}, {"url": "https://keras.rstudio.com/reference/layer_spatial_dropout_2d.html", "anchor_text": "Keras documentation for spatial documentation"}, {"url": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout", "anchor_text": "documentation"}, {"url": "https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-5-dropout-and-noise-29d980ece933", "anchor_text": "here"}, {"url": "https://www.google.com/url?sa=i&url=http%3A%2F%2Flaid.delanover.com%2Fdifference-between-l1-and-l2-regularization-implementation-and-visualization-in-tensorflow%2F&psig=AOvVaw2-BdRWRvBXmAsVNFdu14WF&ust=1584432566455000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCOC__rjFnugCFQAAAAAdAAAAABAD", "anchor_text": "here"}, {"url": "https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-ker", "anchor_text": "here"}, {"url": "https://arxiv.org/abs/1409.4842", "anchor_text": "Inception"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "ResNet50"}, {"url": "https://arxiv.org/abs/1512.03385", "anchor_text": "Deep Residual Learning for Image Recognition"}, {"url": "https://www.google.com/imgres?imgurl=https%3A%2F%2Fkharshit.github.io%2Fimg%2Fresnet_block.png&imgrefurl=https%3A%2F%2Fkharshit.github.io%2Fblog%2F2018%2F09%2F07%2Fskip-connections-and-residual-blocks&tbnid=YqX4hhjHTgLN5M&vet=12ahUKEwii846BlqLoAhWCHysKHfEuDmkQMygAegUIARDdAQ..i&docid=vDE83FK50zkAbM&w=574&h=312&q=skip%20connections&ved=2ahUKEwii846BlqLoAhWCHysKHfEuDmkQMygAegUIARDdAQ", "anchor_text": "here"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----a7562d25ca2d---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----a7562d25ca2d---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/overfitting?source=post_page-----a7562d25ca2d---------------overfitting-----------------", "anchor_text": "Overfitting"}, {"url": "https://medium.com/tag/cnn?source=post_page-----a7562d25ca2d---------------cnn-----------------", "anchor_text": "Cnn"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&user=Vardan+Agarwal&userId=e0b122513e3b&source=-----a7562d25ca2d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&user=Vardan+Agarwal&userId=e0b122513e3b&source=-----a7562d25ca2d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fa7562d25ca2d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----a7562d25ca2d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----a7562d25ca2d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@vardanagarwal16?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Vardan Agarwal"}, {"url": "https://medium.com/@vardanagarwal16/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "399 Followers"}, {"url": "https://www.linkedin.com/in/vardan-agarwal-6bb123168/", "anchor_text": "https://www.linkedin.com/in/vardan-agarwal-6bb123168/"}, {"url": "https://www.buymeacoffee.com/vardan", "anchor_text": "https://www.buymeacoffee.com/vardan"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0b122513e3b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&user=Vardan+Agarwal&userId=e0b122513e3b&source=post_page-e0b122513e3b--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F4ce0157411b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbeyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d&newsletterV3=e0b122513e3b&newsletterV3Id=4ce0157411b4&user=Vardan+Agarwal&userId=e0b122513e3b&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}