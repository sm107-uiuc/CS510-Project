{"url": "https://towardsdatascience.com/error-backpropagation-5394d33ff49b", "time": 1683015579.758303, "path": "towardsdatascience.com/error-backpropagation-5394d33ff49b/", "webpage": {"metadata": {"title": "Understanding Error Backpropagation | by hollan haule | Towards Data Science", "h1": "Understanding Error Backpropagation", "description": "Neural Networks (NN) , the technology from which Deep learning is founded upon, is quite popular in Machine Learning. I remember back in 2015 after reading the article, A Neural network in 11 lines\u2026"}, "outgoing_paragraph_urls": [{"url": "https://iamtrask.github.io/2015/07/12/basic-python-network/", "anchor_text": "A Neural network in 11 lines of python code", "paragraph_index": 0}, {"url": "https://twitter.com/iamtrask", "anchor_text": "Andrew Trask", "paragraph_index": 0}, {"url": "https://towardsdatascience.com/linear-regression-from-math-to-code-9659132383ec", "anchor_text": "post", "paragraph_index": 0}, {"url": "https://github.com/hollan86/neural_network/blob/main/NN.ipynb", "anchor_text": "Github", "paragraph_index": 24}], "all_paragraphs": ["Neural Networks (NN) , the technology from which Deep learning is founded upon, is quite popular in Machine Learning. I remember back in 2015 after reading the article, A Neural network in 11 lines of python code, by Andrew Trask, I was immediately hooked on to the field of Artificial Intelligence. But try building a NN from scratch, I believe most people would agree with me that Error Backpropagation or simply Backprop (BP) would be one of the early obstacles in accomplishing this task, at least depending on the depth you are willing to dive into. For those who are not familiar, BP is the algorithm used along with an optimization algorithm such as Gradient Descent (GD) to learn the parameters of a NN model. BP produces gradients which are then used in optimization. In this article, I will attempt to explain how this algorithm works, and then build a simple neural network from scratch to test this network on a regression problem I used in my previous post. For those who are struggling with this algorithm, I hope this article acts as an intuitive guide.", "Please note that, good grasp of Matrix algebra and multivariate calculus is very essential in order to fully understand this algorithm", "To get a full understanding of BP, I will start by giving the big picture of the NN we are going to build. From this you will hopefully get an intuitive understanding of the design decisions for the NN as well as matrix operations used in the BP. Note that this is just my design, which I find intuitive and other authors might have other designs. I\u2019m going to use a simple feed forward NN, which is simply a composition of functions/layers stacked on top of each other as can be seen in the diagram below.", "Each training iteration of NN has two main stages", "The BP stage has the following steps", "The idea here is, the network estimates a target value during the forward pass. Then, we compute how far our estimates are from the actual targets at the last layer (error signal \u03b4_k ). Finally we compute the error signal for each of the previous layers recursively.", "Given an error function such as the root mean square, error gradients of the last layer can be found using partial differentiation.", "Note that h\u2019(a_k) = 1 for a linear activation and because of this (\u2202E_n/\u2202y_k) = (\u2202E_n/\u2202a_k). The index n has been ignored to keep the equation uncluttered. The quantity (y_nk - t_nk) is called the error signal, \u03b4_k, for the last layer. Therefore, gradient for the parameter linking a particular error signal and input signal is a product of the input signal and the error signal. Using chain rule, the error signal for the previous layer can be computed using the error signal of the current layer. From the diagram above,", "Note how the error signal for a node in the previous layer is obtained by taking a weighed sum of all the error signals from the current layer nodes to which the previous layer node sends its signals i.e sum over over index k. This is why its called Error backpropagation. Also to see where this sum over k comes from mathematically note that \u2202E_n/\u2202a_k is a Jacobian vector and \u2202a_k/\u2202a_j is a Jacobian matrix.", "As before and in general, the gradient for a parameter linking a particular error signal and input signal in a layer is a product of the input signal and the error signal of the layer. In the previous case,", "Note that this is recursive, error signals from the current layer are used to evaluate error signals in a previous layer. This is a very important piece in the puzzle, therefore let\u2019s see how we are going to vectorize and later implement this in code. We are going to assume batch training but the same design can be used for online training by just setting batch size to 1.", "For a layer of output K and input P, layer weights will be initialized as (PxK). Therefore, for N inputs with dimension P, we get N outputs with dimension K. This is the layer forward propagation step as can be seen in the diagram. Bias, initialized as (K,), is not shown here because it is broadcasted over N and will not affect output dimension.", "The error signal, \u03b4_k, therefore has the shape (NxK). For a reason we\u2019ll see shortly, I transpose this error signal and feed into the backprop function as (KxN). Now, multiplying the layer parameters with the layer error signal, performs the weighed sum over over k for all the N patterns, hence the reason why the error signal is first transposed. Let\u2019s call the matrix obtained from this step DM.", "Now here is the tricky part, to complete computation of the previous layer back-propagated error signal, each node weighed sum, has to be multiplied by h\u2019(a_j), whose dimension is (NxP). I\u2019ll call this derivative matrix D. In matrix algebra, this is done by putting the particular input pattern as a diagonal matrix then multiplying this matrix with the corresponding column of DM. I will call this diagonal matrix, S_n. I\u2019m going to zero initialize a matrix A of size (PxN) to accumulate the previous layer signal iteratively", "How you build matrix S_n and DM_n is up to you. You will see one way of doing this in the code section. Perhaps there are more efficient ways that doesn\u2019t involve looping, let me know if you know this :).", "Now these error signals are passed on to the previous layer , L_k-1, to update its parameters. The current layer , L_k, parameters are updated by the error signals that have been passed on to this layer using its \u201cBackprop\u201d function.", "One subtle thing to note is that the layer L_k-1 error signals are computed before layer L_k parameters are updated.", "As explained before, to compute layer param gradients, we multiply error signal by the input signal for that layer. I will call G_w weight gradients and G_b bias gradients. For layer K , matrix A is (KxN), and input signal I is (NxP)", "Note that the operations above sums over N, the effect of this is accumulating the gradients over a batch of size N.", "First, import everything that will be required", "Next i\u2019m going to create a layer class. When this layer is called it performs forward propagation using __call__. Multiple layers can be stacked together by passing a previous layer instance into the instantiation of the current layer. Forward propagation proceeds from the earliest layer to the latest layer. And two layers can only be attached if the output size/dimension of the previous layer matches with the input dimension of the current layer.", "Next, the model class. This class handles the training process and prediction of the NN.", "And finally, a generator class for supplying data to the network while training", "Next, let\u2019s create our network and start training. In this example I will create a 4 layer network.", "In this article I have tried to cover the nuts and bolts of Backpropagation and in the process showed how one might create a NN from scratch. The test result shows that this NN is much more powerful and flexible than the linear regression model in my previous article. The notebook for this article can be found on my Github. For the interested readers, I encourage you to try modifying the network to test it on a classification task.", "Thank you for reading my article, see you in another one! Meanwhile take care during these tough times!", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "PhD student | Coding | Math"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F5394d33ff49b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@hhollan?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hhollan?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "hollan haule"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2de4078be2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&user=hollan+haule&userId=b2de4078be2f&source=post_page-b2de4078be2f----5394d33ff49b---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://iamtrask.github.io/2015/07/12/basic-python-network/", "anchor_text": "A Neural network in 11 lines of python code"}, {"url": "https://twitter.com/iamtrask", "anchor_text": "Andrew Trask"}, {"url": "https://towardsdatascience.com/linear-regression-from-math-to-code-9659132383ec", "anchor_text": "post"}, {"url": "https://github.com/hollan86/neural_network/blob/main/NN.ipynb", "anchor_text": "Github"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----5394d33ff49b---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----5394d33ff49b---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/mathematics?source=post_page-----5394d33ff49b---------------mathematics-----------------", "anchor_text": "Mathematics"}, {"url": "https://medium.com/tag/backpropagation?source=post_page-----5394d33ff49b---------------backpropagation-----------------", "anchor_text": "Backpropagation"}, {"url": "https://medium.com/tag/software-engineering?source=post_page-----5394d33ff49b---------------software_engineering-----------------", "anchor_text": "Software Engineering"}, {"url": "http://creativecommons.org/licenses/by/4.0/", "anchor_text": "Some rights reserved"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&user=hollan+haule&userId=b2de4078be2f&source=-----5394d33ff49b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&user=hollan+haule&userId=b2de4078be2f&source=-----5394d33ff49b---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F5394d33ff49b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----5394d33ff49b---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----5394d33ff49b--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----5394d33ff49b--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----5394d33ff49b--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hhollan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@hhollan?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "hollan haule"}, {"url": "https://medium.com/@hhollan/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "18 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb2de4078be2f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&user=hollan+haule&userId=b2de4078be2f&source=post_page-b2de4078be2f--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fa514e2903369&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ferror-backpropagation-5394d33ff49b&newsletterV3=b2de4078be2f&newsletterV3Id=a514e2903369&user=hollan+haule&userId=b2de4078be2f&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}