{"url": "https://towardsdatascience.com/an-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4", "time": 1682994202.585341, "path": "towardsdatascience.com/an-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4/", "webpage": {"metadata": {"title": "An introduction to high-dimensional hyper-parameter tuning | by Thalles Silva | Towards Data Science", "h1": "An introduction to high-dimensional hyper-parameter tuning", "description": "Hyper-parameter tuning refers to the problem of finding an optimal set of parameter values for a learning algorithm. Even for simple algorithms like Linear Regression, finding the best set for the\u2026"}, "outgoing_paragraph_urls": [{"url": "https://guide.freecodecamp.org/computer-science/notation/big-o-notation/", "anchor_text": "O(v\u1d56) time", "paragraph_index": 12}, {"url": "https://sthalles.github.io/", "anchor_text": "https://sthalles.github.io/", "paragraph_index": 47}], "all_paragraphs": ["If you ever struggled with tuning Machine Learning (ML) models, you are reading the right piece.", "Hyper-parameter tuning refers to the problem of finding an optimal set of parameter values for a learning algorithm.", "Usually, the process of choosing these values is a time-consuming task.", "Even for simple algorithms like Linear Regression, finding the best set for the hyper-parameters can be tough. With Deep Learning, things get even worse.", "Some of the parameters to tune when optimizing neural nets (NNs) include:", "In this short piece, we talk about the best practices for optimizing ML models. These practices come in hand mainly when the number of parameters to tune exceeds two or three.", "Grid Search is usually a good choice when we have a small number of parameters to optimize. For two or even three different parameters, it might be the way to go.", "For each hyper-parameter, we define a set of candidate values to explore.", "Then, the idea is to exhaustively try every possible combination of the values of the individual parameters.", "For each combination, we train and evaluate a different model.", "In the end, we keep the one with the smallest generalization error.", "The main problem with Grid Search is that it is an exponential time algorithm. Its cost grows exponentially with the number of parameters.", "In other words, if we need to optimize p parameters and each one takes at most v values, it runs in O(v\u1d56) time.", "Also, Grid Search is not as effective in exploring the hyper-parameter space as we may think.", "Take a look at the code above again. Using this setup, we are going to train a total of 256 different models. Note that if we decide to add one more parameter, the number of experiments would increase to 1024.", "However, this setup only explores four different values for each hyper-parameter. That is it, we train 256 models to only explore four values of the learning rate, regularization, and so on.", "Besides, Grid Search usually requires repetitive trials. Take the learning_rate_search values from the code above as an example.", "Suppose that after our first run (256 model trials), we get the best model with a learning rate value of 0.01.", "In this situation, we should try to refine our search values by \u201czooming in\u201d on the grid around 0.01 in the hope to find an even better value.", "To do this, we could setup a new Grid Search and redefine the learning rate search range such as:", "But what if we get the best model with a learning rate value was 0.0001?", "Since this value is at the very edge of our initial search range, we should shift the values and try again with a different set like:", "And possibly try to refine the range after finding a good candidate.", "All these details only emphasize how time-consuming hyper-parameter search can be.", "How about choosing our hyper-parameter candidate values at random? As not intuitive as it might seem, this idea is almost always better than Grid Search.", "Note that some of the hyper-parameters are more important than others.", "The learning rate and the momentum factor, for example, are more worth tuning than all others.", "However, with the above exception, it is hard to know which ones play major roles in the optimization process. In fact, I would argue that the importance of each parameter might change for different model architectures and datasets.", "Suppose we are optimizing over two hyper-parameters \u2014 the learning rate and the regularization strength. Also, take into consideration that only the learning rate matters for the problem.", "In the case of Grid Search, we are going to run nine different experiments, but only try three candidates for the learning rate.", "Now, take a look at what happens if we sample the candidates uniformly at random. In this scenario, we are actually exploring nine different values for each parameter.", "If you are not yet convinced, suppose we are optimizing over three hyper-parameters. For example, the learning rate, the regularization strength, and momentum.", "For Grid Search, we would be running 125 training runs, but only exploring five different values of each parameter.", "On the other hand, with Random Search, we would be exploring 125 different values of each.", "If we want to try values for the learning rate, say within the range of 0.1 to 0.0001, we do:", "Note that we are sampling values from a uniform distribution on a log scale.", "You can think of the values -1 and -4 (for the learning rate) as the exponents in the interval [10e-1, 10e-4].", "If we do not use a log-scale, the sampling will not be uniform within the given range. In other words, you should not attempt to sample values like:", "In this situation, most of the values would not be sampled from a \u2018valid\u2019 region. Actually, considering the learning rate samples in this example, 72% of the values would fall in the interval [0.02, 0.1].", "In the graphic below, we are sampling 25 random values from the range [0.1,0.0004]. The plot in the top left shows the original values.", "The bottom plot shows the distribution of values. Only 12% of the values are in the interval [0.0004, 0.01]. To solve this problem, sample the values from a uniform distribution in a log-scale.", "A similar behavior would happen with the regularization parameter.", "Also, note that like with Grid Search, you need to consider the two cases we mentioned above.", "If the best candidate falls very near the edge, your range might be off and should be shifted and re-sampled. Also, after choosing the first good candidates, try re-sampling to a finer range of values.", "In conclusion, these are the key takeaways.", "Thanks for reading! For more cool stuff on Deep Learning, check out some of my previous articles:", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Computer Vision & Deep Learning. Personal blog: https://sthalles.github.io/"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fdf5c0106e5a4&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@thalles.silva?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Thalles Silva"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8db098eb9ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&user=Thalles+Silva&userId=f8db098eb9ca&source=post_page-f8db098eb9ca----df5c0106e5a4---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://guide.freecodecamp.org/computer-science/notation/big-o-notation/", "anchor_text": "O(v\u1d56) time"}, {"url": "http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf", "anchor_text": "Random Search for Hyper-Parameter Optimization"}, {"url": "https://medium.freecodecamp.org/how-to-train-your-own-faceid-cnn-using-tensorflow-eager-execution-6905afe4fd5a", "anchor_text": "How to train your own FaceID ConvNet using TensorFlow Eager executionFaces are everywhere \u2014 from photos and videos on social media websites, to consumer security applications like the\u2026medium.freecodecamp.org"}, {"url": "https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645", "anchor_text": "Machine Learning 101: An Intuitive Introduction to Gradient DescentGradient descent is, with no doubt, the heart and soul of most Machine Learning (ML) algorithms. I definitely believe\u2026towardsdatascience.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----df5c0106e5a4---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----df5c0106e5a4---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----df5c0106e5a4---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/optimization?source=post_page-----df5c0106e5a4---------------optimization-----------------", "anchor_text": "Optimization"}, {"url": "https://medium.com/tag/towards-data-science?source=post_page-----df5c0106e5a4---------------towards_data_science-----------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&user=Thalles+Silva&userId=f8db098eb9ca&source=-----df5c0106e5a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&user=Thalles+Silva&userId=f8db098eb9ca&source=-----df5c0106e5a4---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Fdf5c0106e5a4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----df5c0106e5a4---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----df5c0106e5a4--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@thalles.silva?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Thalles Silva"}, {"url": "https://medium.com/@thalles.silva/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.4K Followers"}, {"url": "https://sthalles.github.io/", "anchor_text": "https://sthalles.github.io/"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8db098eb9ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&user=Thalles+Silva&userId=f8db098eb9ca&source=post_page-f8db098eb9ca--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea9a35433442&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fan-introduction-to-high-dimensional-hyper-parameter-tuning-df5c0106e5a4&newsletterV3=f8db098eb9ca&newsletterV3Id=ea9a35433442&user=Thalles+Silva&userId=f8db098eb9ca&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}