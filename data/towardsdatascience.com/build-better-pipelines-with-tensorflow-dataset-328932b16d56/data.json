{"url": "https://towardsdatascience.com/build-better-pipelines-with-tensorflow-dataset-328932b16d56", "time": 1683016116.6108181, "path": "towardsdatascience.com/build-better-pipelines-with-tensorflow-dataset-328932b16d56/", "webpage": {"metadata": {"title": "TensorFlow Dataset Pipelines With Python | Towards Data Science", "h1": "Build Better Pipelines With TensorFlow Dataset", "description": "The vast majority of ML is simply data wrangling - input pipelines are key to successful data projects. We take a look at TensorFlow's pipeline solution."}, "outgoing_paragraph_urls": [{"url": "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data", "anchor_text": "Kaggle here", "paragraph_index": 15}, {"url": "https://twitter.com/jamescalam", "anchor_text": "Twitter", "paragraph_index": 39}, {"url": "https://www.youtube.com/c/jamesbriggs", "anchor_text": "https://www.youtube.com/c/jamesbriggs", "paragraph_index": 41}], "all_paragraphs": ["Data pipelines are the less glamorous but still fundamental building blocks in any scalable, production-quality ML solution. Indeed, the vast majority of ML is actually data wrangling \u2014 so it makes sense that a strong pipeline is a big factor in building strong solutions.", "Focusing on TensorFlow 2, we have a wonderful thing called a Dataset object built-in with the library. Using dataset objects, we can design efficient data pipelines with significantly less effort \u2014 the result is a cleaner, logical, and highly optimized pipeline.", "We will be doing a deep-dive on the dataset object. Covering what they are, why we should use them, and how we use them.", "If you prefer video, I\u2019ve covered everything in this article here too:", "Datasets are an object contained within the tf.data API, which represents a sequence of elements. Each element is given a particular structure dependent on the format required by our models.", "The tf.data API is TensorFlow\u2019s built-in approach for building input data pipelines \u2014 providing methods for developing more efficient pipelines with less code.", "The dataset abstraction makes data extraction, transformation, and loading incredibly easy.", "For example, we can build a pipeline to iteratively load from file (rather than keeping everything in memory), perform some given transformations (like tokenization of text data), batch, shuffle, and load the data into our model for training.", "All of this typically needs no more than a few lines of code. To batch and shuffle our dataset takes nothing more than dataset.shuffle(10000).batch(64).", "As mentioned, we have two options regarding how we read data into our dataset, (1) from in-memory or (2) from disk.", "The simplest approach is simply reading the data directly into Python using a dataframe, array, lists, or other data structure. This approach is absolutely okay to use but can quickly become unmanageable with larger datasets.", "So, if working with smaller datasets \u2014 you have these options:", "These methods produce the dataset structures shown above. Clearly, reading from in-memory objects is incredibly straightforward \u2014 but it\u2019s not ideal for larger datasets.", "The second approach is to read in the data from an out-of-memory source, such as a local hard-drive.", "When taking this approach, we benefit from only loading the data we need in memory \u2014 meaning that for a 20M sample dataset, we can avoid loading the full dataset at once and iteratively load only what we need.", "We will use the IMDB movie reviews dataset in this example. You can download it from Kaggle here.", "Our training data is contained inside train.tsv, which we will use to train a sentiment classifier. For this, we would need to take the text contained in Content as our input feature and Sentiment as our target labels. We do not need any other columns.", "With this approach, we can easily keep the data stored in-memory low and still shuffle and batch data with ease \u2014 it\u2019s an incredibly convenient option.", "Now we\u2019ve covered the basics of reading and writing dataset objects; we can begin transforming our loaded dataset.", "When reading from file, these operations are not needed as they are built-in to read functions like tf.data.experimental.make_csv_dataset \u2014 but this does not happen when we build the dataset from in-memory.", "Fortunately, it\u2019s still incredibly easy. We give a large number (10000 is pretty common) as the argument to shuffle and our training batch size to batch:", "It takes nothing more than this single line to shuffle and batch our dataset!", "We can use the map function to perform operations on each sample within xour dataset. For example, for predicting the next time-step in a sequence, we may want to train on input data, which consists of timesteps n to n+8, and output data consisting of timesteps n+1 to n+9.", "Initially, our dataset may consist of many samples containing sequences of 10 time-steps. To train our model, we need to split these 10-long sequences into two sets of 9-long sequences \u2014 the input data, the other our target data.", "To perform this operation, we use the map method, like so:", "When feeding our datasets into a model for training the default format of (input, output) is expected. Meaning every record/batch contained in the dataset should contain an input tensor and label/output tensor.", "With that format, we can pass our dataset object to our training method like so:", "The single input/output format is not always the one we will need to use. For any restructuring, we can again rely on the map method.", "We can map multiple inputs and outputs by mapping our dataset into a dictionary format where we have our input name (the key) pointing to the set of values we will be using (the value).", "If we match up the input/output layer names to the input/output dataset dictionary keys, we can pass dataset to our model as per usual!", "A common use-case for this is creating two input layers for transformer models. Many of these models require an input ID tensor and corresponding attention mask tensor \u2014 where we can use the same logic:", "Another important point here is the split of training and validation sets (test-sets too). The easiest way to implement a split in a dataset is to use the take and split methods.", "To take a given number of records, we use take \u2014 like so:", "We can then skip a given number of records using skip, returning all that follow \u2014 like so:", "With a combination of both methods, we can create a split in our data. For example, for a 70\u201330% training-validation split, we do:", "And create another split to add a test-set.", "When we come to feeding the training and validations sets into our model for training, we do so like this:", "We\u2019ve covered how-to build cleaner, more efficient data input pipelines in TF2 using dataset objects! Including:", "Which is all we need to know for a big portion of ML input pipelines. Everything we\u2019ve done is incredibly easy to perform, and lightning-fast thanks to the clear and efficient tf.data API.", "I hope you\u2019ve enjoyed this article! Let me know if you have any questions or ideas via Twitter or in the comments below.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Freelance ML engineer learning and writing about everything. I post a lot on YT https://www.youtube.com/c/jamesbriggs"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F328932b16d56&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://jamescalam.medium.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": "James Briggs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1----328932b16d56---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://towardsdatascience.com/tagged/getting-started", "anchor_text": "Getting Started"}, {"url": "https://unsplash.com/@romanenko29061983?utm_source=medium&utm_medium=referral", "anchor_text": "roman pentin"}, {"url": "https://unsplash.com?utm_source=medium&utm_medium=referral", "anchor_text": "Unsplash"}, {"url": "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data", "anchor_text": "Kaggle here"}, {"url": "https://twitter.com/jamescalam", "anchor_text": "Twitter"}, {"url": "https://bit.ly/nlp-transformers", "anchor_text": "\ud83e\udd16 70% Discount on the NLP With Transformers Course"}, {"url": "https://medium.com/tag/technology?source=post_page-----328932b16d56---------------technology-----------------", "anchor_text": "Technology"}, {"url": "https://medium.com/tag/data-science?source=post_page-----328932b16d56---------------data_science-----------------", "anchor_text": "Data Science"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----328932b16d56---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/programming?source=post_page-----328932b16d56---------------programming-----------------", "anchor_text": "Programming"}, {"url": "https://medium.com/tag/getting-started?source=post_page-----328932b16d56---------------getting_started-----------------", "anchor_text": "Getting Started"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&user=James+Briggs&userId=b9d77a4ca1d1&source=-----328932b16d56---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&user=James+Briggs&userId=b9d77a4ca1d1&source=-----328932b16d56---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F328932b16d56&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----328932b16d56---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----328932b16d56--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----328932b16d56--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----328932b16d56--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----328932b16d56--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----328932b16d56--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----328932b16d56--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----328932b16d56--------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://jamescalam.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "James Briggs"}, {"url": "https://jamescalam.medium.com/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.6K Followers"}, {"url": "https://www.youtube.com/c/jamesbriggs", "anchor_text": "https://www.youtube.com/c/jamesbriggs"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F75e31c56d187&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-better-pipelines-with-tensorflow-dataset-328932b16d56&newsletterV3=b9d77a4ca1d1&newsletterV3Id=75e31c56d187&user=James+Briggs&userId=b9d77a4ca1d1&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}