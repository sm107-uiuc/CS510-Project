{"url": "https://towardsdatascience.com/slow-and-arbitrary-style-transfer-3860870c8f0e", "time": 1683012803.551235, "path": "towardsdatascience.com/slow-and-arbitrary-style-transfer-3860870c8f0e/", "webpage": {"metadata": {"title": "Slow and Arbitrary Style Transfer | by Mayank Agarwal | Towards Data Science", "h1": "Slow and Arbitrary Style Transfer", "description": "Style transfer is the technique of combining two images, a content image and a style image, such that the generated image displays the properties of both its constituents. The goal is to generate an\u2026"}, "outgoing_paragraph_urls": [], "all_paragraphs": ["Style transfer is the technique of combining two images, a content image and a style image, such that the generated image displays the properties of both its constituents. The goal is to generate an image that is similar in style (e.g., color combinations, brush strokes) to the style image and exhibits structural resemblance (e.g., edges, shapes) to the content image.", "In this post, we describe an optimization-based approach proposed by Gatys et al. in their seminal work, \u201cImage Style Transfer Using Convolutional Neural Networks\u201d. But, let us first look at some of the building blocks that lead to the ultimate solution.", "At the outset, you can imagine low-level features as features visible in a zoomed-in image. In contrast, high-level features can be best viewed when the image is zoomed-out. Now, how does a computer know how to distinguish between these details of an image? CNNs, to the rescue.", "Learned filters of pre-trained convolutional neural networks are excellent general-purpose image feature extractors. Different layers of a CNN extract the features at different scales. The hidden unit in shallow layers, which sees only a relatively small part of the input image, extracts low-level features like edges, colors, and simple textures. Deeper layers, however, with a wider receptive field tend to extract high-level features such as shapes, patterns, intricate textures, and even objects.", "So, how can we leverage these feature extractors for style transfer?", "In a convolutional neural network, a layer with N distinct filters (or, C channels) has N (or, C) feature maps each of size HxW, where H and W are the height and width of the feature activation map respectively. The feature activation for this layer is a volume of shape NxHxW (or, CxHxW). Let\u2019s see how to use these activations to separate content and style information from individual images.", "Traditionally, the similarity between two images is measured using L1/L2 loss functions in the pixel-space. While these losses are good to measure the low-level similarity, they do not capture the perceptual difference between the images. For instance, two identical images offset from each other by a single pixel, though perceptually similar, will have a high per-pixel loss.", "Intuitively, if the convolutional feature activations of two images are similar, they should be perceptually similar. Therefore, we refer to the feature responses of the network as the content representation, and the difference between feature responses for two images is called the perceptual loss. To find the content reconstruction of an original content image, we can perform gradient descent on a white noise image that triggers similar feature responses.", "The scales of features captured by different layers of the network can be visualized by generating content reconstructions by matching only feature responses from a particular layer (refer Fig 2). Reconstructions from lower layers are almost perfect (a,b,c). In higher layers of the network, detailed pixel information is lost while high-level content is preserved (d,e).", "To obtain a representation of the style of an input image, a feature space is built on top of the filter responses in each layer of the network. It consists of the correlation between different filter responses over the spatial extent of the feature maps. Mathematically, the correlation between different filter responses can be calculated as a dot product of the two activation maps. Formally, the style representation of an image can be captured by a Gram Matrix (refer Fig 3) which captures the correlation of all feature activation pairs. For N filters in a layer, the Gram Matrix is an NxN dimensional matrix.", "By capturing the prevalence of different types of features (i, i), as well as how much different features occur together (i, j), the Gram Matrix measures the style of an image. Essentially, by discarding the spatial information stored at each location in the feature activation maps, we can successfully extract style information.", "Similar to content reconstructions, style reconstructions can be generated by minimizing the difference between Gram Matrices of a random white image and a reference style image (Refer Fig 2). This creates images that match the style of a given image on an increasing scale while discarding information of the global arrangement of the scene.", "Now that we have all the key ingredients for defining our loss functions, let\u2019s jump straight into it.", "Let C, S, and G be the original content image, original style image and the generated image, and a\u1d9c, a\u02e2 and a\u1d33 their respective feature activations from layer l of a pre-trained CNN.", "The content loss, as described in Fig 4, can be defined as the squared-error loss between the feature representations of the content and the generated image. Along the processing hierarchy of a CNN, the input image is transformed into representations that are increasingly sensitive to the actual content of the image but becomes relatively invariant to its precise appearance. In practice, we can best capture the content of an image by choosing a layer l somewhere in the middle of the network.", "The style loss, as described in Fig 5, can be defined as the squared-error loss between Gram Matrices of the style and the generated image. We generally take a weighted contribution of style loss across multiple layers of the pre-trained network.", "Combining the separate content and style losses, the final loss formulation is defined in Fig 6. We start with a random image G, and iteratively optimize this image to match the content of the image C and style of the image S, while keeping the weights of the pre-trained feature extractor network fixed.", "In conclusion, it is important to note that, though the optimization process is slow, this method allows style transfer between any arbitrary pair of content and style images.", "Your home for data science. A Medium publication sharing concepts, ideas and codes.", "Deep Learning and Computer Vision Enthusiast"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F3860870c8f0e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://towardsdatascience.com/?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Towards Data Science"}, {"url": "https://medium.com/@mayankgrwl97?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mayankgrwl97?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Mayank Agarwal"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7209a567aeed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&user=Mayank+Agarwal&userId=7209a567aeed&source=post_page-7209a567aeed----3860870c8f0e---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf", "anchor_text": "Image Style Transfer Using Convolutional Neural Networks"}, {"url": "https://arxiv.org/abs/1603.08155", "anchor_text": "Perceptual Losses for Real-Time Style Transfer and Super-Resolution"}, {"url": "https://www.coursera.org/learn/convolutional-neural-networks/", "anchor_text": "https://www.coursera.org/learn/convolutional-neural-networks/"}, {"url": "https://medium.com/tag/neural-style-transfer?source=post_page-----3860870c8f0e---------------neural_style_transfer-----------------", "anchor_text": "Neural Style Transfer"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----3860870c8f0e---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/convolutional-network?source=post_page-----3860870c8f0e---------------convolutional_network-----------------", "anchor_text": "Convolutional Network"}, {"url": "https://medium.com/tag/style-transfer?source=post_page-----3860870c8f0e---------------style_transfer-----------------", "anchor_text": "Style Transfer"}, {"url": "https://medium.com/tag/digital-art?source=post_page-----3860870c8f0e---------------digital_art-----------------", "anchor_text": "Digital Art"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&user=Mayank+Agarwal&userId=7209a567aeed&source=-----3860870c8f0e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&user=Mayank+Agarwal&userId=7209a567aeed&source=-----3860870c8f0e---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "More from Towards Data Science"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F3860870c8f0e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&collection=Towards+Data+Science&collectionId=7f60cf5620c9&source=post_page-----3860870c8f0e---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://towardsdatascience.com/?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Read more from Towards Data Science"}, {"url": "https://medium.com/?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----3860870c8f0e--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----3860870c8f0e--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----3860870c8f0e--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mayankgrwl97?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mayankgrwl97?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Mayank Agarwal"}, {"url": "https://medium.com/@mayankgrwl97/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "265 Followers"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7209a567aeed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&user=Mayank+Agarwal&userId=7209a567aeed&source=post_page-7209a567aeed--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9055fb73009b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fslow-and-arbitrary-style-transfer-3860870c8f0e&newsletterV3=7209a567aeed&newsletterV3Id=9055fb73009b&user=Mayank+Agarwal&userId=7209a567aeed&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}