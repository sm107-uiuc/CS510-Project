{"url": "https://ayearofai.com/rohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d", "time": 1682988332.312256, "path": "ayearofai.com/rohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d/", "webpage": {"metadata": {"title": "Rohan & Lenny #1: Neural Networks & The Backpropagation Algorithm, Explained | by Rohan Kapur | A Year of Artificial Intelligence", "h1": "Rohan & Lenny #1: Neural Networks & The Backpropagation Algorithm, Explained", "description": "In Rohan\u2019s last post, he talked about evaluating and plugging holes in his knowledge of machine learning thus far. The backpropagation algorithm \u2014 the process of training a neural network \u2014 was a\u2026"}, "outgoing_paragraph_urls": [{"url": "https://medium.com/u/de8e2540b759?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Lenny", "paragraph_index": 0}, {"url": "https://medium.com/u/cb55958ea3bb?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Rohan", "paragraph_index": 0}, {"url": "https://medium.com/a-year-of-artificial-intelligence", "anchor_text": "journey", "paragraph_index": 0}, {"url": "https://medium.com/a-year-of-artificial-intelligence/0-2016-is-the-year-i-venture-into-artificial-intelligence-d702d65eb919#.bfjoaqxu5", "anchor_text": "introduction", "paragraph_index": 0}, {"url": "http://www.magicbroom.info/Papers/DuchiHaSi10.pdf", "anchor_text": "Adagrad", "paragraph_index": 23}, {"url": "http://arxiv.org/abs/1412.6980", "anchor_text": "Adam", "paragraph_index": 23}, {"url": "https://en.wikipedia.org/wiki/Chain_rule", "anchor_text": "chain rule", "paragraph_index": 29}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood", "anchor_text": "log-likelihood", "paragraph_index": 36}, {"url": "https://en.wikipedia.org/wiki/Step_function", "anchor_text": "step function", "paragraph_index": 40}, {"url": "https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning", "anchor_text": "here", "paragraph_index": 44}, {"url": "http://www.numpy.org/", "anchor_text": "numpy", "paragraph_index": 89}, {"url": "http://cs231n.github.io/python-numpy-tutorial/", "anchor_text": "here ya\u2019 go", "paragraph_index": 89}, {"url": "http://arxiv-web3.library.cornell.edu/abs/1502.01852", "anchor_text": "here", "paragraph_index": 91}, {"url": "http://caffe.berkeleyvision.org/", "anchor_text": "Caffe", "paragraph_index": 107}, {"url": "http://torch.ch/", "anchor_text": "Torch", "paragraph_index": 107}, {"url": "http://tensorflow.org", "anchor_text": "TensorFlow", "paragraph_index": 107}, {"url": "http://cs231n.stanford.edu", "anchor_text": "Stanford\u2019s CS231n", "paragraph_index": 109}, {"url": "http://cs231n.stanford.edu/syllabus.html", "anchor_text": "here", "paragraph_index": 109}, {"url": "http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/", "anchor_text": "MIT 6.034", "paragraph_index": 110}, {"url": "https://www.youtube.com/watch?v=q0pm3BrIUFo", "anchor_text": "lecture", "paragraph_index": 110}], "all_paragraphs": ["This is the first group (Lenny and Rohan) entry in our journey to extend our knowledge of Artificial Intelligence in the year of 2016. Learn more about our motives in this introduction post.", "In Rohan\u2019s last post, he talked about evaluating and plugging holes in his knowledge of machine learning thus far. The backpropagation algorithm \u2014 the process of training a neural network \u2014 was a glaring one for both of us in particular. Together, we embarked on mastering backprop through some great online lectures from professors at MIT & Stanford. After attempting a few programming implementations and hand solutions, we felt equipped to write an article for AYOAI \u2014 together.", "Today, we\u2019ll do our best to explain backpropagation and neural networks from the beginning. If you have an elementary understanding of differential calculus and perhaps an intuition of what machine learning is, we hope you come out of this blog post with an (acute, but existent nonetheless) understanding of neural networks and how to train them. Let us know if we succeeded!", "Let\u2019s start off with a quick introduction to the concept of neural networks. Fundamentally, neural networks are nothing more than really good function approximators \u2014 you give a trained network an input vector, it performs a series of operations, and it produces an output vector. To train our network to estimate an unknown function, we give it a collection of data points \u2014 which we denote the \u201ctraining set\u201d \u2014 that the network will learn from and generalize on to make future inferences.", "Neural networks are structured as a series of layers, each composed of one or more neurons (as depicted above). Each neuron produces an output, or activation, based on the outputs of the previous layer and a set of weights.", "When using a neural network to approximate a function, the data is forwarded through the network layer-by-layer until it reaches the final layer. The final layer\u2019s activations are the predictions that the network actually makes.", "All this probably seems kind of magical, but it actually works. The key is finding the right set of weights for all of the connections to make the right decisions (this happens in a process known as training) \u2014 and that\u2019s what most of this post is going to be about.", "When we\u2019re training the network, it\u2019s often convenient to have some metric of how good or bad we\u2019re doing; we call this metric the cost function. Generally speaking, the cost function looks at the function the network has inferred and uses it to estimate values for the data points in our training set. The discrepancies between the outputs in the estimations and the training set data points are the principle values for our cost function. When training our network, the goal will be to get the value of this cost function as low as possible (we\u2019ll see how to do that in just a bit, but for now, just focus on the intuition of what a cost function is and what it\u2019s good for). Generally speaking, the cost function should be more or less convex, like so:", "In reality, it\u2019s impossible for any network or cost function to be truly convex. However, as we\u2019ll soon see, local minima may not be a big deal, as long as there is still a general trend for us to follow to get to the bottom. Also, notice that the cost function is parameterized by our network\u2019s weights \u2014 we control our loss function by changing the weights.", "One last thing to keep in mind about the loss function is that it doesn\u2019t just have to capture how correctly your network estimates \u2014 it can specify any objective that needs to be optimized. For example, you generally want to penalize larger weights, as they could lead to overfitting. If this is the case, simply adding a regularization term to your cost function that expresses how big your weights will mean that, in the process of training your network, it will look for a solution that has the best estimates possible while preventing overfitting.", "Now, let\u2019s take a look at how we can actually minimize the cost function during the training process to find a set of weights that work the best for our objective.", "Now that we\u2019ve developed a metric for \u201cscoring\u201d our network (which we\u2019ll denote as J(W)), we need to find the weights that will make that score as low as possible. If you think back to your pre-calculus days, your first instinct might be to set the derivative of the cost function to zero and solve, which would give us the locations of every minimum/maximum in the function. Unfortunately, there are a few problems with this approach:", "Especially as the size of networks begins to scale up, solving for the weights directly becomes increasingly infeasible. Instead, we look at a different class of algorithms, called iterative optimization algorithms, that progressively work their way towards the optimal solution.", "The most basic of these algorithms is gradient descent. Recall that our cost function will be essentially convex, and we want to get as close as possible to the global minimum. Instead of solving for it analytically, gradient descent follows the derivatives to essentially \u201croll\u201d down the slope until it finds its way to the center.", "Let\u2019s take the example of a single-weight neural network, whose cost function is depicted below.", "We start off by initializing our weight randomly, which puts us at the red dot on the diagram above. Taking the derivative, we see the slope at this point is a pretty big positive number. We want to move closer to the center \u2014 so naturally, we should take a pretty big step in the opposite direction of the slope.", "If we repeat the process enough, we soon find ourselves nearly at the bottom of our curve and much closer to the optimal weight configuration for our network.", "More formally, gradient descent looks something like this:", "Let\u2019s dissect. Every time we want to update our weights, we subtract the derivative of the cost function w.r.t. the weight itself, scaled by a learning rate , and \u2014 that\u2019s it! You\u2019ll see that as it gets closer and closer to the center, the derivative term gets smaller and smaller, converging to zero as it approaches the solution. The same process applies with networks that have tens, hundreds, thousands, or more parameters \u2014 compute the gradient of the cost function w.r.t. each of the weights, and update each of your weights accordingly.", "I do want to say a few more words on the learning rate, because it\u2019s one of the more important hyperparameters (\u201csettings\u201d for your neural network) that you have control over. If the learning rate is too high, it could jump too far in the other direction, and you never get to the minimum you\u2019re searching for. Set it too low, and your network will take ages to find the right weights, or it will get stuck in a local minimum. There\u2019s no \u201cmagic number\u201d to use when it comes to a learning rate, and it\u2019s usually best to try several and pick the one that works the best for your individual network and dataset. In practice, many choose to anneal the learning rate over time \u2014 it starts out high, because it\u2019s furthest from the solution, and decays as it gets closer.", "But as it turns out, gradient descent is kind of slow. Really slow, actually. Earlier I used the analogy of the weights \u201crolling\u201d down the gradient to get to the bottom, but that doesn\u2019t actually make any sense \u2014 it should pick up speed as it gets to the bottom, not slow down! Another iterative optimization algorithm, known as momentum, does just that. As the weights begin to \u201croll\u201d down the slope, they pick up speed. When they get closer to the solution, the momentum that they picked up carries them closer to the optima while gradient descent would simply stop. As a result, training with momentum updates is both faster and can provide better results.", "Here\u2019s what the update rule looks like for momentum:", "As we train, we accumulate a \u201cvelocity\u201d value V. At each training step, we update V with the gradient at the current position (once again scaled by the learning rate). Also notice that, with each time step, we decay velocity V by a factor mu (usually somewhere around .9), so that over time we lose momentum instead of bouncing around by the minimum forever. We then update our weight in the direction of the velocity, and repeat the process again. Over the first few training iterations, V will grow as our weights \u201cpick up speed\u201d and take successively bigger leaps. As we approach the minimum, our velocity stops accumulating as quickly, and eventually begins to decay, until we\u2019ve essentially reached the minimum. An important thing to note is that we accumulate a velocity independently for each weight \u2014 just because one weight is changing particularly clearly doesn\u2019t mean any of the other weights need to be.", "There are lots of other iterative optimization algorithms that are commonly used with neural networks, but I won\u2019t go into all of them here (if you\u2019re curious, some of the more popular ones include Adagrad and Adam). The basic principle remains the same throughout \u2014 gradually update the weights to get them closer to the minimum. But regardless of which optimization algorithm you use, we still need to be able to compute the gradient of the cost function w.r.t. each weight. But our cost function isn\u2019t a simple parabola anymore \u2014 it\u2019s a complicated, many-dimensional function with countless local optima that we need to watch out for. That\u2019s where backpropagation comes in.", "The backpropagation algorithm was a major milestone in machine learning because, before it was discovered, optimization methods were extremely unsatisfactory. One popular method was to perturb (adjust) the weights in a random, uninformed direction (ie. increase or decrease) and see if the performance of the ANN increased. If it did not, one would attempt to either a) go in the other direction b) reduce the perturbation size or c) a combination of both. Another attempt was to use Genetic Algorithms (which became popular in AI at the same time) to evolve a high-performance neural network. In both cases, without (analytically) being informed on the correct direction, results and efficiency were suboptimal. This is where the backpropagation algorithm comes into play.", "Recall that, for any given supervised machine learning problem, we (aim to) select weights that provide the optimal estimation of a function that models our training data. In other words, we want to find a set of weights W that minimizes on the output of J(W). We discussed the gradient descent algorithm \u2014 one where we update each weight by some negative, scalar reduction of the error derivative with respect to that weight. If we do choose to use gradient descent (or almost any other convex optimization algorithm), we need to find said derivatives in numerical form.", "For other machine learning algorithms like logistic regression or linear regression, computing the derivatives is an elementary application of differentiation. This is because the outputs of these models are just the inputs multiplied by some chosen weights, and at most fed through a single activation function (the sigmoid function in logistic regression). The same, however, cannot be said for neural networks. To demonstrate this, here is a diagram of a double-layered neural network:", "As you can see, each neuron is a function of the previous one connected to it. In other words, if one were to change the value of w1, both \u201chidden 1\u201d and \u201chidden 2\u201d (and ultimately the output) neurons would change. Because of this notion of functional dependencies, we can mathematically formulate the output as an extensive composite function:", "Here, the output is a composite function of the weights, inputs, and activation function(s). It is important to realize that the hidden units/nodes are simply intermediary computations that, in actuality, can be reduced down to computations of the input layer.", "If we were to then take the derivative of said function with respect to some arbitrary weight (for example w1), we would iteratively apply the chain rule (which I\u2019m sure you all remember from your calculus classes). The result would look similar to the following:", "Now, let\u2019s attach a black box to the tail of our neural network. This black box will compute and return the error \u2014 using the cost function \u2014 from our output:", "All we\u2019ve done is add another functional dependency; our error is now a function of the output and hence a function of the input, weights, and activation function. If we were to compute the derivative of the error with any arbitrary weight (again, we\u2019ll choose w1), the result would be:", "Each of these derivatives can be simplified once we choose an activation and error function, such that the entire result would represent a numerical value. At that point, any abstraction has been removed, and the error derivative can be used in gradient descent (as discussed earlier) to iteratively improve upon the weight. We compute the error derivatives w.r.t. every other weight in the network and apply gradient descent in the same way. This is backpropagation \u2014 simply the computation of derivatives that are fed to a convex optimization algorithm. We call it \u201cbackpropagation\u201d because it almost seems as if we are traversing from the output error to the weights, taking iterative steps using chain the rule until we \u201creach\u201d our weight.", "When I first truly understood the backprop algorithm (just a couple of weeks ago), I was taken aback by how simple it was. Sure, the actual arithmetic/computations can be difficult, but this process is handled by our computers. In reality, backpropagation is just a rather tedious (but again, for a generalized implementation, computers will handle this) application of the chain rule. Since neural networks are convoluted multilayer machine learning model structures (at least relative to other ones), each weight \u201ccontributes\u201d to the overall error in a more complex manner, and hence the actual derivatives require a lot of effort to produce. However, once we get past the calculus, backpropagation of neural nets is equivalent to typical gradient descent for logistic/linear regression.", "Thus far, I\u2019ve walked through a very abstract form of backprop for a simple neural network. However, it is unlikely that you will ever use a single-layered ANN in applications. So, now, let\u2019s make our black boxes \u2014 the activation and error functions \u2014 more concrete such that we can perform backprop on a multilayer neural net.", "Recall that our error function J(W) will compute the \u201cerror\u201d of our neural network based on the output predictions it produces vs. the correct a priori outputs we know in our training set. More formally, if we denote our predicted output estimations as vector p, and our actual output as vector a, then we can use:", "This is just one example of a possible cost function (the log-likelihood is also a popular one), and we use it because of its mathematical convenience (this is a notion one will frequently encounter in machine learning): the squared expression exaggerates poor solutions and ensures each discrepancy is positive. It will soon become clear why we multiply the expression by half.", "The derivative of the error w.r.t. the output was the first term in the error w.r.t. weight derivative expression we formulated earlier. Let\u2019s now compute it!", "Our result is simply our predictions take away our actual outputs.", "Now, let\u2019s move on to the activation function. The activation function used depends on the context of the neural network. If we aren\u2019t in a classification context, ReLU (Rectified Linear Unit, which is zero if input is negative, and the identity function when the input is positive) is commonly used today.", "If we\u2019re in a classification context (that is, predicting on a discrete state with a probability ie. if an email is spam), we can use the sigmoid or tanh (hyperbolic tangent) function such that we can \u201csqueeze\u201d any value into the range 0 to 1. These are used instead of a typical step function because their \u201csmoothness\u201d properties allows for the derivatives to be non-zero. The derivative of the step function before and after the origin is zero. This will pose issues when we try to update our weights (nothing much will happen!).", "Now, let\u2019s say we\u2019re in a classification context and we choose to use the sigmoid function, which is of the following equation:", "As per usual, we\u2019ll compute the derivative using differentiation rules as:", "EDIT: On the 2nd line, the denominator should be raised to +2, not -2. Thanks to a reader for pointing this out.", "Sidenote: ReLU activation functions are also commonly used in classification contexts. There are downsides to using the sigmoid function \u2014 particularly the \u201cvanishing gradient\u201d problem \u2014 which you can read more about here.", "The sigmoid function is mathematically convenient (there it is again!) because we can represent its derivative in terms of the output of the function. Isn\u2019t that cool\u203d", "We are now in a good place to perform backpropagation on a multilayer neural network. Let me introduce you to the net we are going to work with:", "This net is still not as complex as one you may use in your programming, but its architecture allows us to nevertheless get a good grasp on backprop. In this net, we have 3 input neurons and one output neuron. There are four layers in total: one input, one output, and two hidden layers. There are 3 neurons in each hidden layer, too (which, by the way, need not be the case). The network is fully connected; there are no missing connections. Each neuron/node (save the inputs, which are usually pre-processed anyways) is an activity; it is the weighted sum of the previous neurons\u2019 activities applied to the sigmoid activation function.", "To perform backprop by hand, we need to introduce the different variables/states at each point (layer-wise) in the neural network:", "It is important to note that every variable you see here is a generalization on the entire layer at that point. For example, when I say x_i, I am referring to the input to any input neuron (arbitrary value of i). I chose to place it in the middle of the layer for visibility purposes, but that does not mean that x_i refers to the middle neuron. I\u2019ll demonstrate and discuss the implications of this later on.", "x refers to the input layer, y refers to hidden layer 1, z refers to hidden layer 2, and p refers to the prediction/output layer (which fits in nicely with the notation used in our cost function). If a variable has the subscript i, it means that the variable is the input to the relevant neuron at that layer. If a variable has the subscript j, it means that the variable is the output of the relevant neuron at that layer. For example, x_i refers to any input value we enter into the network. x_j is actually equal to x_i, but this is only because we choose not to use an activation function \u2014 or rather, we use the identity activation function \u2014 in the input layer\u2019s activities. We only include these two separate variables to retain consistency. y_i is the input to any neuron in the first hidden layer; it is the weighted sum of all previous neurons (each neuron in the input layer multiplied by the corresponding connecting weights). y_j is the output of any neuron at the hidden layer, so it is equal to activation_function(y_i) = sigmoid(y_i) = sigmoid(weighted_sum_of_x_j). We can apply the same logic for z and p. Ultimately, p_j is the sigmoid output of p_i and hence is the output of the entire neural network that we pass to the error/cost function.", "The weights are organized into three separate variables: W1, W2, and W3. Each W is a matrix (if you are not comfortable with Linear Algebra, think of a 2D array) of all the weights at the given layer. For example, W1 are the weights that connect the input layer to the hidden layer 1. Wlayer_ij refers to any arbitrary, single weight at a given layer. To get an intuition of ij (which is really i, j), Wlayer_i are all the weights that connect arbitrary neuron i at a given layer to the next layer. Wlayer_ij (adding the j component) is the weight that connects arbitrary neuron i at a given layer to an arbitrary neuron j at the next layer. Essentially, Wlayer is a vector of Wlayer_is, which is a vector of real-valued Wlayer_ijs.", "NOTE: Please note that the i\u2019s and j\u2019s in the weights and other variables are completely different. These indices do not correspond in any way. In fact, for x/y/z/p, i and j do not represent tensor indices at all, they simply represent the input and output of a neuron. Wlayer_ij represents an arbitrary weight at an index in a weight matrix, and x_j/y_j/z_j/p_j represent an arbitrary input/output point of a neuron unit.", "That last part about weights was tedious! It\u2019s crucial to understand how we\u2019re separating the neural network here, especially the notion of generalizing on an entire layer, before moving forward.", "To acquire a comprehensive intuition of backpropagation, we\u2019re going to backprop this neural net as discussed before. More specifically, we\u2019re going to find the derivative of the error w.r.t. an arbitrary weight in the input layer (W1_ij). We could find the derivative of the error w.r.t. an arbitrary weight in the first or second hidden layer, but let\u2019s go as far back as we can; the more backprop, the better!", "So, mathematically, we are trying to obtain (to perform our iterative optimization algorithm with):", "We can express this graphically/visually, using the same principles as earlier (chain rule), like so:", "In two layers, we have three red lines pointing in three different directions, instead of just one. This is a reinforcement of (and why it is important to understand) the fact that variable j is just a generalization/represents any point in the layer. So, when we differentiate p_i with respect to the layer before that, there are three different weights, as I hope you can see, in W3_ij that contribute to the value p_i. There also happen to be three weights in W3 in total, but this isn\u2019t the case for the layers before; it is only the case because layer p has one neuron \u2014 the output \u2014 in it. We stop backprop at the input layer and so we just point to the single weight we are looking for.", "Wonderful! Now let\u2019s work out all this great stuff mathematically. Immediately, we know:", "We have already established the left hand side, so now we just need to use the chain rule to simplify it further. The derivative of the error w.r.t. the weight can be written as the derivative of the error w.r.t. the output prediction multiplied by the derivative of the output prediction w.r.t. the weight. At this point, we\u2019ve traversed one red line back. We know this because", "is reducible to a numerical value. Specifically, the derivative of the error w.r.t. the output prediction is:", "Going one more layer backwards, we can determine that:", "In other words, the derivative of the output prediction w.r.t. the weight is the derivative of the output w.r.t. the input to the output layer (p_i) multiplied by the derivative of that value w.r.t. the weight. This represents our second red line. We can solve the first term like so:", "This corresponds with the derivative of the sigmoid function we solved earlier, which was equal to the output multiplied by one minus the output. In this case, p_j is the output of the sigmoid function. Now, we have:", "Let\u2019s move on to the third red line(s). This one is interesting because we begin to \u201cspread\u201d out. Since there are multiple different weights that contribute to the value of p_i, we need to take into account their individual \u201cpull\u201d factors into our derivative:", "If you\u2019re a mathematician, this notation may irk you slightly; sorry if that\u2019s the case! In computer science, we tend to stray from the notion of completely legal mathematical expressions. This is yet again again another reason why it\u2019s key to understand the role of layer generalization; z_j here is not just referring to the middle neuron, it\u2019s referring to an arbitrary neuron. The actual value of j in the summation is not changing (it\u2019s not even an index or a value in the first place), and we don\u2019t really consider it. It\u2019s less of a mathematical expression and more of a statement that we will iterate through each generalized neuron z_j and use it. In other words, we iterate over the derivative terms and sum them up using z_1, z_2, and z_3. Before, we could write p_j as any single value because the output layer just contains one node; there is just one p_j. But we see here that this is no longer the case. We have multiple z_j values, and p_i is functionally dependent on each of these z_j values. So, when we traverse from p_j to the preceding layer, we need to consider each contribution from layer z to p_j separately and add them up to create one total contribution. There\u2019s no upper bound to the summation; we just assume that we start at zero and end at our maximum value for the number of neurons in the layer. Please again note that the same changes are not reflected in W1_ij, where j refers to an entirely different thing. Instead, we\u2019re just stating that we will use the different z_j neurons in layer z.", "Since p_i is a summation of each weight multiplied by each z_j (weighted sum), if we were to take the derivative of p_i with any arbitrary z_j, the result would be the connecting weight since said weight would be the coefficient of the term (derivative of m*x w.r.t. x is just m):", "W3_ij is loosely defined here. ij still refers to any arbitrary weight \u2014 where ij are still separate from the j used in p_i/z_j \u2014 but again, as computer scientists and not mathematicians, we need not be pedantic about the legality and intricacy of expressions; we just need an intuition of what the expressions imply/mean. It\u2019s almost a succinct form of psuedo-code! So, even though this defines an arbitrary weight, we know it means the connecting weight. We can also see this from the diagram: when we walk from p_j to an arbitrary z_j, we walk along the connecting weight. So now, we have:", "At this point, I like to continue playing the \u201creduction test\u201d. The reduction test states that, if we can further simplify a derivative term, we still have more backprop to do. Since we can\u2019t yet quite put the derivative of z_j w.r.t. W1_ij into a numerical term, let\u2019s keep going (and fast-forward a bit). Using chain rule, we follow the fourth line back to determine that:", "Since z_j is the sigmoid of z_i, we use the same logic as the previous layer and apply the sigmoid derivative. The derivative of z_i w.r.t. W1_ij, demonstrated by the fifth line(s) back, requires the same idea of \u201cspreading out\u201d and summation of contributions:", "Briefly, since z_i is the weighted sum of each y_j in y, we sum over the derivatives which, similar to before, simplifies to the relevant connecting weights in the preceding layer (W2 in this case).", "We\u2019re almost there, let\u2019s go further; there\u2019s still more reduction to do:", "We have, of course, another sigmoid activation function to deal with. This is the sixth red line. Notice, now, that we have just one line remaining. In fact, our last derivative term here passes (or rather, fails) the reduction test! The last line traverses from the input at y_i to x_j, walking along W1_ij. Wait a second \u2014 is this not what we are attempting to backprop to? Yes, it is! Since we are, for the first time, directly deriving y_i w.r.t. the weight W1_ij, we can think of the coefficient of W1_ij as being x_j in our weighted sum (instead of the vice versa as used previously). Hence, the simplification follows:", "Of course, since each x_j in layer x contributes to the weighted sum y_i, we sum over the effects. And that\u2019s it! We can\u2019t reduce any further from here. Now, let\u2019s tie all these individual expressions together:", "EDIT: The denominator on the left hand side should say dW\u00b9ij instead of \u201clayer\u201d.", "With no more partial derivative terms left, our work is complete! This gives us the derivative of the error w.r.t. any arbitrary weight in the input layer/W1. That was a lot of work \u2014 maybe now we can sympathize with the poor computers!", "Something you should notice is that values such as p_j, a, z_j, y_j, x_j etc. are the values of the network at the different points. But where do they come from? Actually, we would need to perform a feed-forward of the neural network first and then capture these variables.", "Our task is to now perform Gradient Descent to train the neural net:", "We perform gradient descent on each weight in each layer. Notice that the resulting gradient should change each time because the weight itself changes, (and as a result, the performance and output of the entire net should change) even if it\u2019s a small perturbation. This means that, at each update, we need to do a feed-forward of the neural net. Not just once before, but once each iteration.", "These are then the steps to train an entire neural network:", "It\u2019s important to note that one must not initialize the weights to zero, similar to what may be done in other machine learning algorithms. If weights are initialized to zero, after each update, the outgoing weights of each neuron will be identical, because the gradients will be identical (which can be proved). Because of this, the proceeding hidden units will remain the same value and will continue to follow each other. Ultimately, this means that our training will become extremely constrained (due to the \u201csymmetry\u201d), and we won\u2019t be able to build interesting functions. Also, neural networks may get stuck at local optima (places where the gradient is zero but are not the global minima), so random weight initialization allows one to hopefully have a chance of circumventing that by starting at many different random values.", "3. Perform one feed-forward using the training data", "4. Perform backpropagation to get the error derivatives w.r.t. each and every weight in the neural network", "5. Perform gradient descent to update each weight by the negative scalar reduction (w.r.t. some learning rate alpha) of the respective error derivative. Increment the number of iterations.", "6. If we have converged (in reality, though, we just stop when we have reached the number of maximum iterations) training is complete. Else, repeat starting at step 3.", "If we initialize our weights randomly (and not to zero) and then perform gradient descent with derivatives computed from backpropagation, we should expect to train a neural network in no time! I hope this example brought clarity to how backprop works and the intuition behind it. If you didn\u2019t understand the intricacies of the example but understand and appreciate the concept of backprop as a whole, you\u2019re still in a great place! Next we\u2019ll go ahead and explain backprop code that works on any generalized architecture of a neural network using the ReLU activation function.", "Now that we\u2019ve developed the math and intuition behind backpropagation, let\u2019s try to implement it. We\u2019ll divide our implementation into three distinct steps:", "Let\u2019s start off by defining what the API we\u2019re implementing looks like. We\u2019ll define our network as a series of Layer instances that our data passes through \u2014 this means that instead of modeling each individual neuron, we group neurons from a single layer together. This makes it a bit easier to reason about larger networks, but also makes the actual computations faster (as we\u2019ll see shortly). Also \u2014 we\u2019re going to write the code in Python.", "Each layer will have the following API:", "(This isn\u2019t great API design \u2014 ideally, we would decouple the backprop and weight update from the rest of the object, so the specific algorithm we use for updating weights isn\u2019t tied to the layer itself. But that\u2019s not the point, so we\u2019ll stick with this design for the purposes of explaining how backpropagation works in a real-life scenario. Also: we\u2019ll be using numpy throughout the implementation. It\u2019s an awesome tool for mathematical operations in Python (especially tensor based ones), but we don\u2019t have the time to get into how it works \u2014 if you want a good introduction, here ya\u2019 go.)", "We can start by implementing the weight initialization. As it turns out, how you initialize your weights is actually kind of a big deal for both network performance and convergence rates. Here\u2019s how we\u2019ll initialize our weights:", "This initializes a weight matrix of the appropriate dimensions with random values sampled from a normal distribution. We then scale it rad(2/self.size_in), giving us a variance of 2/self.size_in (derivation here).", "And that\u2019s all we need for layer initialization! Let\u2019s move on to implementing our first objective \u2014 feed-forward. This is actually pretty simple \u2014 a dot product of our input activations with the weight matrix, followed by our activation function, will give us the activations we need. The dot product part should make intuitive sense; if it doesn\u2019t, you should sit down and try to work through it on a piece of paper. This is where the performance gains of grouping neurons into layers comes from: instead of keeping an individual weight vector for each neuron, and performing a series of vector dot products, we can just do a single matrix operation (which, thanks to the wonders of modern processors, is significantly faster). In fact, we can compute all of the activations from a layer in just two lines:", "Simple enough. Let\u2019s move on to backpropagation.", "This one\u2019s a bit more involved. First, we compute the derivative of the output w.r.t. the weights, then the derivative of the cost w.r.t. the output, followed by chain rule to get the derivative of the cost w.r.t. the weights.", "Let\u2019s start with the first part \u2014 the derivative of the output w.r.t. the weights. That should be simple enough; because you\u2019re multiplying the weight by the corresponding input activation, the derivative will just be the corresponding input activation.", "Except, because we\u2019re using the ReLU activation function, the weights have no effect if the corresponding output is < 0 (because it gets capped anyway). This should take care of that hiccup:", "(More formally, you\u2019re multiplying by the derivative of the activation function, which is 0 when the activation is < 0 and 1 elsewhere.)", "Let\u2019s take a brief detour to talk about the out_grad parameter that our backward method gets. Let\u2019s say we have a network with two layers: the first has m neurons, and the second has n. Each of the m neurons produces an activation, and each of the n neurons looks at each of the m activations. The out_grad parameter is an m x n matrix of how each m affects each of the n neurons it feeds into.", "Now, we need the derivative of the cost w.r.t. each of the outputs \u2014 which is essentially the out_grad parameter we\u2019re given! We just need to sum up each row of the matrix we\u2019re given, as per the backpropagation formula.", "Finally, we end up with something like this:", "Now, we need to compute the derivative of our inputs to pass along to the next layer. We can perform a similar chain rule \u2014 derivative of the output w.r.t. the inputs times the derivative of the cost w.r.t. the outputs.", "And that\u2019s it for the backpropagation step.", "The final step is the weight update. Assuming we\u2019re sticking with gradient descent for this example, this can be a simple one-liner:", "To actually train our network, we take one of our training samples and call forward on each layer consecutively, passing the output of the previous layer as the input of the following layer. We compute dJ, passing that as the out_grad parameter to the last layer\u2019s backward method. We call backward on each of the layers in reverse order, this time passing the output of the further layer as out_grad to the previous layer. Finally, we call update on each of our layers and repeat.", "There\u2019s one last detail that we should include, which is the concept of a bias (akin to that of a constant term in any given equation). Notice that, with our current implementation, the activation of a neuron is determined solely based on the activations of the previous layer. There\u2019s no bias term that can shift the activation up or down independent of the inputs. A bias term isn\u2019t strictly necessary \u2014 in fact, if you train your network as-is, it would probably still work fine. But if you do need a bias term, the code stays almost the same \u2014 the only difference is that you need to add a column of 1s to the incoming activations, and update your weight matrix accordingly, so one of your weights gets treated as a bias term. The only other difference is that, when returning cost_wrt_inputs, you can cut out the first row \u2014 nobody cares about the gradients associated with the bias term because the previous layer has no say in the activation of the bias neuron.", "Implementing backpropagation can be kind of tricky, so it\u2019s often a good idea to check your implementation. You can do so by computing the gradient numerically (by literally perturbing the weight and calculating the difference in your cost function) and comparing it to your backpropagation-computed gradient. This gradient check doesn\u2019t need to be run once you\u2019ve verified your implementation, but it could save a lot of time tracking down potential problems with your network.", "Nowadays, you often don\u2019t even need to implement a neural network on your own, as libraries such as Caffe, Torch, or TensorFlow will have implementations ready to go. That being said, it\u2019s often a good idea to try implementing it on your own to get a better grasp of how everything works under the hood.", "Intrigued? Looking to learn more about neural networks? Here are some great online classes to get you started:", "Stanford\u2019s CS231n. Although it\u2019s technically about convolutional neural networks, the class provides an excellent introduction to and survey of neural networks in general. Class videos, notes, and assignments are all posted here, and if you have the patience for it I would strongly recommend walking through the assignments so you can really get to know what you\u2019re learning.", "MIT 6.034. This class, taught by Prof. Patrick Henry Winston, explores many different algorithms and disciplines in Artificial Intelligence. There\u2019s a great lecture on backprop that I actually used as a stepping stone to getting setup writing this article. I also learned genetic algorithms from Prof. Winston \u2014 he\u2019s a great teacher!", "We hope that, if you visited this article without knowing how the backpropagation algorithm works, you are reading this with an (at least rudimentary) mathematical or conceptual intuition of it. Writing and conveying such a complex algorithm to a supposed beginner has proven to be an extremely difficult task for us, but it\u2019s helped us truly understand what we\u2019ve been learning about. With greater knowledge in a fundamental area of machine learning, we are now excited to take a look at new, interesting algorithms and disciplines in the field. We are looking forward to continue documenting these endeavors together.", "Our ongoing effort to make the mathematics, science, linguistics, and philosophy of artificial intelligence fun and simple."], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fabf4609d4f9d&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://ayearofai.com/?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": ""}, {"url": "https://ayearofai.com/?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "A Year of Artificial Intelligence"}, {"url": "https://medium.com/@mckapur?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mckapur?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Rohan Kapur"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb55958ea3bb&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&user=Rohan+Kapur&userId=cb55958ea3bb&source=post_page-cb55958ea3bb----abf4609d4f9d---------------------follow_byline-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=--------------------------bookmark_header-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=--------------------------bookmark_header-----------", "anchor_text": "Save"}, {"url": "https://medium.com/u/de8e2540b759?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Lenny"}, {"url": "https://medium.com/u/cb55958ea3bb?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Rohan"}, {"url": "https://medium.com/a-year-of-artificial-intelligence", "anchor_text": "journey"}, {"url": "https://medium.com/a-year-of-artificial-intelligence/0-2016-is-the-year-i-venture-into-artificial-intelligence-d702d65eb919#.bfjoaqxu5", "anchor_text": "introduction"}, {"url": "http://www.magicbroom.info/Papers/DuchiHaSi10.pdf", "anchor_text": "Adagrad"}, {"url": "http://arxiv.org/abs/1412.6980", "anchor_text": "Adam"}, {"url": "https://en.wikipedia.org/wiki/Chain_rule", "anchor_text": "chain rule"}, {"url": "https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood", "anchor_text": "log-likelihood"}, {"url": "http://i.stack.imgur.com/8CGlM.png", "anchor_text": "http://i.stack.imgur.com/8CGlM.png"}, {"url": "https://en.wikipedia.org/wiki/Step_function", "anchor_text": "step function"}, {"url": "https://en.wikibooks.org/wiki/File:HardLimitFunction.png", "anchor_text": "https://en.wikibooks.org/wiki/File:HardLimitFunction.png"}, {"url": "https://en.wikibooks.org/wiki/File:SigmoidFunction.png", "anchor_text": "https://en.wikibooks.org/wiki/File:SigmoidFunction.png"}, {"url": "https://www.quora.com/What-is-special-about-rectifier-neural-units-used-in-NN-learning", "anchor_text": "here"}, {"url": "http://www.numpy.org/", "anchor_text": "numpy"}, {"url": "http://cs231n.github.io/python-numpy-tutorial/", "anchor_text": "here ya\u2019 go"}, {"url": "http://arxiv-web3.library.cornell.edu/abs/1502.01852", "anchor_text": "here"}, {"url": "http://caffe.berkeleyvision.org/", "anchor_text": "Caffe"}, {"url": "http://torch.ch/", "anchor_text": "Torch"}, {"url": "http://tensorflow.org", "anchor_text": "TensorFlow"}, {"url": "http://cs231n.stanford.edu", "anchor_text": "Stanford\u2019s CS231n"}, {"url": "http://cs231n.stanford.edu/syllabus.html", "anchor_text": "here"}, {"url": "http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/", "anchor_text": "MIT 6.034"}, {"url": "https://www.youtube.com/watch?v=q0pm3BrIUFo", "anchor_text": "lecture"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----abf4609d4f9d---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----abf4609d4f9d---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/algorithms?source=post_page-----abf4609d4f9d---------------algorithms-----------------", "anchor_text": "Algorithms"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fa-year-of-artificial-intelligence%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&user=Rohan+Kapur&userId=cb55958ea3bb&source=-----abf4609d4f9d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fa-year-of-artificial-intelligence%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&user=Rohan+Kapur&userId=cb55958ea3bb&source=-----abf4609d4f9d---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://ayearofai.com/?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "More from A Year of Artificial Intelligence"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Fa-year-of-artificial-intelligence%2Fabf4609d4f9d&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&collection=A+Year+of+Artificial+Intelligence&collectionId=bb87da25612c&source=post_page-----abf4609d4f9d---------------------follow_footer-----------", "anchor_text": "Follow"}, {"url": "https://ayearofai.com/?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Read more from A Year of Artificial Intelligence"}, {"url": "https://medium.com/?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----abf4609d4f9d--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mckapur?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@mckapur?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Rohan Kapur"}, {"url": "https://medium.com/@mckapur/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "1.7K Followers"}, {"url": "http://mckapur.com", "anchor_text": "mckapur.com"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcb55958ea3bb&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&user=Rohan+Kapur&userId=cb55958ea3bb&source=post_page-cb55958ea3bb--two_column_layout_sidebar-----------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fusers%2Fcb55958ea3bb%2Flazily-enable-writer-subscription&operation=register&redirect=https%3A%2F%2Fayearofai.com%2Frohan-lenny-1-neural-networks-the-backpropagation-algorithm-explained-abf4609d4f9d&user=Rohan+Kapur&userId=cb55958ea3bb&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}