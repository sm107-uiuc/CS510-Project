{"url": "https://blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8", "time": 1683019445.4158442, "path": "blog.insightdatascience.com/reinforcement-learning-from-scratch-819b65f074d8/", "webpage": {"metadata": {"title": "Reinforcement Learning from scratch | by Emmanuel Ameisen | Insight", "h1": "Reinforcement Learning from scratch", "description": "Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program. Are you a\u2026"}, "outgoing_paragraph_urls": [{"url": "http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "Insight Artificial Intelligence Fellows Program", "paragraph_index": 0}, {"url": "http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "get in touch", "paragraph_index": 1}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e", "anchor_text": "lessons", "paragraph_index": 2}, {"url": "https://medium.com/u/18dfe63fa7f0?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Arthur Juliani", "paragraph_index": 2}, {"url": "https://twitter.com/EmmanuelAmeisen", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://blog.openai.com/dota-2/", "anchor_text": "beating", "paragraph_index": 5}, {"url": "https://deepmind.com/research/alphago/", "anchor_text": "defeating", "paragraph_index": 5}, {"url": "https://unity3d.com/unity", "anchor_text": "Unity", "paragraph_index": 6}, {"url": "https://www.linkedin.com/in/arthur-juliani-50a38a21/", "anchor_text": "Arthur Juliani", "paragraph_index": 7}, {"url": "https://www.linkedin.com/in/zhongyuechen/", "anchor_text": "Leon Chen", "paragraph_index": 7}, {"url": "https://medium.com/u/18dfe63fa7f0?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Arthur Juliani", "paragraph_index": 7}, {"url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0", "anchor_text": "here", "paragraph_index": 7}, {"url": "https://en.wikipedia.org/wiki/Multi-armed_bandit", "anchor_text": "Multi-armed bandits", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Q-learning", "anchor_text": "Q function", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Softmax_function", "anchor_text": "softmax", "paragraph_index": 11}, {"url": "https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies", "anchor_text": "epsilon greedy", "paragraph_index": 12}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "back propagate", "paragraph_index": 20}, {"url": "https://www.alexirpan.com/2018/02/14/rl-hard.html", "anchor_text": "problem", "paragraph_index": 29}, {"url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0", "anchor_text": "read", "paragraph_index": 33}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "course", "paragraph_index": 33}, {"url": "https://twitter.com/EmmanuelAmeisen", "anchor_text": "here", "paragraph_index": 33}, {"url": "http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "Insight Artificial Intelligence Fellows Program", "paragraph_index": 34}, {"url": "http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "get in touch", "paragraph_index": 35}], "all_paragraphs": ["Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program.", "Are you a company working in AI and would like to get involved in the Insight AI Fellows Program? Feel free to get in touch.", "Recently, I gave a talk at the O\u2019Reilly AI conference in Beijing about some of the interesting lessons we\u2019ve learned in the world of NLP. While there, I was lucky enough to attend a tutorial on Deep Reinforcement Learning (Deep RL) from scratch by Unity Technologies. I thought that the session, led by Arthur Juliani, was extremely informative and wanted to share some big takeaways below.", "In our conversations with companies, we\u2019ve seen a rise of interesting Deep RL applications, tools and results. In parallel, the inner workings and applications of Deep RL, such as AlphaGo pictured above, can often seem esoteric and hard to understand. In this post, I will give an overview of core aspects of the field that can be understood by anyone.", "Many of the visuals are from the slides of the talk, and some are new. The explanations and opinions are mine. If anything is unclear, reach out to me here!", "Deep RL is a field that has seen vast amounts of research interest, including learning to play Atari games, beating pro players at Dota 2, and defeating Go champions. Contrary to many classical Deep Learning problems that often focus on perception (does this image contain a stop sign?), Deep RL adds the dimension of actions that influence the environment (what is the goal, and how do I get there?). In dialog systems for example, classical Deep Learning aims to learn the right response for a given query. On the other hand, Deep Reinforcement Learning focuses on the right sequences of sentences that will lead to a positive outcome, for example a happy customer.", "This makes Deep RL particularly attractive for tasks that require planning and adaptation, such as manufacturing or self-driving. However, industry applications have trailed behind the rapidly advancing results coming out of the research community. A major reason is that Deep RL often requires an agent to experiment millions of times before learning anything useful. The best way to do this rapidly is by using a simulation environment. This tutorial will be using Unity to create environments to train agents in.", "For this workshop led by Arthur Juliani and Leon Chen, their goal was to get every participants to successfully train multiple Deep RL algorithms in 4 hours. A tall order! Below, is a comprehensive overview of many of the main algorithms that power Deep RL today. For a more complete set of tutorials, Arthur Juliani wrote an 8-part series starting here.", "Deep RL can be used to best the top human players at Go, but to understand how that\u2019s done, you first need to understand a few simple concepts, starting with much easier problems.", "1/It all starts with slot machines", "Let\u2019s imagine you are faced with 4 chests that you can pick from at each turn. Each of them have a different average payout, and your goal is to maximize the total payout you receive after a fixed number of turns. This is a classic problem called Multi-armed bandits and is where we will start. The crux of the problem is to balance exploration, which helps us learn about which states are good, and exploitation, where we now use what we know to pick the best slot machine.", "Here, we will utilize a value function that maps our actions to an estimated reward, called the Q function. First, we\u2019ll initialize all Q values at equal values. Then, we\u2019ll update the Q value of each action (picking each chest) based on how good the payout was after choosing this action. This allows us to learn a good value function. We will approximate our Q function using a neural network (starting with a very shallow one) that learns a probability distribution (by using a softmax) over the 4 potential chests.", "While the value function tells us how good we estimate each action to be, the policy is the function that determines which actions we end up taking. Intuitively, we might want to use a policy that picks the action with the highest Q value. This performs poorly in practice, as our Q estimates will be very wrong at the start before we gather enough experience through trial and error. This is why we need to add a mechanism to our policy to encourage exploration. One way to do that is to use epsilon greedy, which consists of taking a random action with probability epsilon. We start with epsilon being close to 1, always choosing random actions, and lower epsilon as we go along and learn more about which chests are good. Eventually, we learn which chests are best.", "In practice, we might want to take a more subtle approach than either taking the action we think is the best, or a random action. A popular method is Boltzmann Exploration, which adjust probabilities based on our current estimate of how good each chest is, adding in a randomness factor.", "The previous example was a world in which we were always in the same state, waiting to pick from the same 4 chests in front of us. Most real-word problems consist of many different states. That is what we will add to our environment next. Now, the background behind chests alternates between 3 colors at each turn, changing the average values of the chests. This means we need to learn a Q function that depends not only on the action (the chest we pick), but the state (what the color of the background is). This version of the problem is called Contextual Multi-armed Bandits.", "Surprisingly, we can use the same approach as before. The only thing we need to add is an extra dense layer to our neural network, that will take in as input a vector representing the current state of the world.", "3/Learning about the consequences of our actions", "There is another key factor that makes our current problem simpler than mosts. In most environments, such as in the maze depicted above, the actions that we take have an impact on the state of the world. If we move up on this grid, we might receive a reward or we might receive nothing, but the next turn we will be in a different state. This is where we finally introduce a need for planning.", "First, we will define our Q function as the immediate reward in our current state, plus the discounted reward we are expecting by taking all of our future actions. This solution works if our Q estimate of states is accurate, so how can we learn a good estimate?", "We will use a method called Temporal Difference (TD) learning to learn a good Q function. The idea is to only look at a limited number of steps in the future. TD(1) for example, only uses the next 2 states to evaluate the reward.", "Surprisingly, we can use TD(0), which looks at the current state, and our estimate of the reward the next turn, and get great results. The structure of the network is the same, but we need to go through one forward step before receiving the error. We then use this error to back propagate gradients, like in traditional Deep Learning, and update our value estimates.", "Another method to estimate the eventual success of our actions is Monte Carlo Estimates. This consists of playing out the entire episode with our current policy until we reach an end (success by reaching a green block or failure by reaching a red block in the image above) and use that result to update our value estimates for each traversed state. This allows us to propagate values efficiently in one batch at the end of an episode, instead of every time we make a move. The cost is that we are introducing noise to our estimates, since we attribute very distant rewards to them.", "The previous methods were using neural networks to approximate our value estimates by mapping from a discrete number of states and actions to a value. In the maze for example, there were 49 states (squares) and 4 actions (move in each adjacent direction). In this environment, we are trying to learn how to balance a ball on a 2 dimensional paddle, by deciding at each time step whether we want to tilt the paddle left or right. Here, the state space becomes continuous (the angle of the paddle, and the position of the ball). The good news is, we can still use Neural Networks to approximate this function!", "A note about off-policy vs on-policy learning: The methods we used previously, are off-policy methods, meaning we can generate data with any strategy(using epsilon greedy for example) and learn from it. On-policy methods can only learn from actions that were taken following our policy (remember, a policy is the method we use to determine which actions to take). This constrains our learning process, as we have to have an exploration strategy that is built in to the policy itself, but allows us to tie results directly to our reasoning, and enables us to learn more efficiently.", "The approach we will use here is called Policy Gradients, and is an on-policy method. Previously, we were first learning a value function Q for each action in each state and then building a policy on top. In Vanilla Policy Gradient, we still use Monte Carlo Estimates, but we learn our policy directly through a loss function that increases the probability of choosing rewarding actions. Since we are learning on policy, we cannot use methods such as epsilon greedy (which includes random choices), to get our agent to explore the environment. The way that we encourage exploration is by using a method called entropy regularization, which pushes our probability estimates to be wider, and thus will encourage us to make riskier choices to explore the space.", "In practice, many state of the art RL methods require learning both a policy and value estimates. The way we do this with deep learning is by having both be two separate outputs of the same backbone neural network, which will make it easier for our neural network to learn good representations.", "One method to do this is Advantage Actor Critic (A2C). We learn our policy directly with policy gradients (defined above), and learn a value function using something called Advantage. Instead of updating our value function based on rewards, we update it based on our advantage, which measures how much better or worse an action was than our previous value function estimated it to be. This helps make learning more stable compared to simple Q Learning and Vanilla Policy Gradients.", "There is an additional advantage to using Deep Learning for these methods, which is that Deep Neural Networks excel at perceptive tasks. When a human plays a game, the information received is not a list of states, but an image (usually of a screen, or a board, or the surrounding environment).", "Image-based Learning combines a Convolutional Neural Network (CNN) with RL. In this environment, we pass in a raw image instead of features, and add a 2 layer CNN to our architecture without changing anything else! We can even inspect activations to see what the network picks up on to determine value, and policy. In the example below, we can see that the network uses the current score and distant obstacles to estimate the value of the current state, while focusing on nearby obstacles for determining actions. Neat!", "As a side note, while toying around with the provided implementation, I\u2019ve found that visual learning is very sensitive to hyperparameters. Changing the discount rate slightly for example, completely prevented the neural network from learning even on a toy application. This is a widely known problem, but it is interesting to see it first hand.", "So far, we\u2019ve played with environments with continuous and discrete state spaces. However, every environment we studied had a discrete action space: we could move in one of four directions, or tilt the paddle to the left or right. Ideally, for applications such as self-driving cars, we would like to learn continuous actions, such as turning the steering wheel between 0 and 360 degrees. In this environment called 3D ball world, we can choose to tilt the paddle to any value on each of its axes. This gives us more control as to how we perform actions, but makes the action space much larger.", "We can approach this by approximating our potential choices with Gaussian distributions. We learn a probability distribution over potential actions by learning the mean and variance of a Gaussian distribution, and our policy we sample from that distribution. Simple, in theory :).", "There are a few concepts that separate the algorithms described above from state of the art approaches. It\u2019s interesting to see that conceptually, the best robotics and game-playing algorithms are not that far away from the ones we just explored:", "That\u2019s it for this overview, I hope this has been informative and fun! If you are looking to dive deeper into the theory of RL, give Arthur\u2019s posts a read, or diving deeper by following David Silver\u2019s UCL course. If you are looking to learn more about the projects we do at Insight, or how we work with companies, please check us out below, or reach out to me here.", "Want to learn about applied Artificial Intelligence from leading practitioners in Silicon Valley, New York, or Toronto? Learn more about the Insight Artificial Intelligence Fellows Program.", "Are you a company working in AI and would like to get involved in the Insight AI Fellows Program? Feel free to get in touch.", "Head of AI at Insight Data Science @EmmanuelAmeisen"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F819b65f074d8&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/@emmanuelameisen?source=post_page-----819b65f074d8--------------------------------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Emmanuel Ameisen"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F45cca2d4999f&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=post_page-45cca2d4999f----819b65f074d8---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://blog.insightdatascience.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Insight"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F819b65f074d8&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----819b65f074d8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F819b65f074d8&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=-----819b65f074d8---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "Insight Artificial Intelligence Fellows Program"}, {"url": "http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "get in touch"}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e", "anchor_text": "lessons"}, {"url": "https://medium.com/u/18dfe63fa7f0?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Arthur Juliani"}, {"url": "https://twitter.com/EmmanuelAmeisen", "anchor_text": "here"}, {"url": "https://blog.openai.com/dota-2/", "anchor_text": "beating"}, {"url": "https://deepmind.com/research/alphago/", "anchor_text": "defeating"}, {"url": "https://unity3d.com/unity", "anchor_text": "Unity"}, {"url": "https://www.linkedin.com/in/arthur-juliani-50a38a21/", "anchor_text": "Arthur Juliani"}, {"url": "https://www.linkedin.com/in/zhongyuechen/", "anchor_text": "Leon Chen"}, {"url": "https://medium.com/u/18dfe63fa7f0?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Arthur Juliani"}, {"url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Multi-armed_bandit", "anchor_text": "Multi-armed bandits"}, {"url": "https://en.wikipedia.org/wiki/Q-learning", "anchor_text": "Q function"}, {"url": "https://en.wikipedia.org/wiki/Softmax_function", "anchor_text": "softmax"}, {"url": "https://en.wikipedia.org/wiki/Multi-armed_bandit#Semi-uniform_strategies", "anchor_text": "epsilon greedy"}, {"url": "https://en.wikipedia.org/wiki/Backpropagation", "anchor_text": "back propagate"}, {"url": "https://www.alexirpan.com/2018/02/14/rl-hard.html", "anchor_text": "problem"}, {"url": "https://eng.uber.com/deep-neuroevolution/", "anchor_text": "encouraging"}, {"url": "http://worldmodels.github.io", "anchor_text": "This"}, {"url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0", "anchor_text": "read"}, {"url": "http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html", "anchor_text": "course"}, {"url": "https://twitter.com/EmmanuelAmeisen", "anchor_text": "here"}, {"url": "http://insightdata.ai?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "Insight Artificial Intelligence Fellows Program"}, {"url": "http://insightdatascience.com/partnerships?utm_source=deep_rl&utm_medium=blog&utm_content=top", "anchor_text": "get in touch"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----819b65f074d8---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/insight-ai?source=post_page-----819b65f074d8---------------insight_ai-----------------", "anchor_text": "Insight Ai"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----819b65f074d8---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/artificial-intelligence?source=post_page-----819b65f074d8---------------artificial_intelligence-----------------", "anchor_text": "Artificial Intelligence"}, {"url": "https://medium.com/tag/research?source=post_page-----819b65f074d8---------------research-----------------", "anchor_text": "Research"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F819b65f074d8&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----819b65f074d8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F819b65f074d8&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----819b65f074d8---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F819b65f074d8&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=post_page-----819b65f074d8--------------------------------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F45cca2d4999f&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=post_page-45cca2d4999f----819b65f074d8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2a56026f6a21&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&newsletterV3=45cca2d4999f&newsletterV3Id=2a56026f6a21&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----819b65f074d8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Written by Emmanuel Ameisen"}, {"url": "https://medium.com/@emmanuelameisen/followers?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "5.1K Followers"}, {"url": "https://blog.insightdatascience.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Insight"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F45cca2d4999f&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=post_page-45cca2d4999f----819b65f074d8---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F2a56026f6a21&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Freinforcement-learning-from-scratch-819b65f074d8&newsletterV3=45cca2d4999f&newsletterV3Id=2a56026f6a21&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----819b65f074d8---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Emmanuel Ameisen"}, {"url": "https://blog.insightdatascience.com/?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Insight"}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "How to solve 90% of NLP problems: a step-by-step guideUsing Machine Learning to understand and leverage text."}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "13 min read\u00b7Jan 24, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2Ffda605278e4e&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fhow-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----fda605278e4e----0-----------------clap_footer----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?source=author_recirc-----819b65f074d8----0---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "47"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffda605278e4e&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fhow-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e&source=-----819b65f074d8----0-----------------bookmark_preview----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/how-to-access-s3-data-from-spark-74e40e0b2231?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@hoa_9453?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@hoa_9453?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Hoa Nguyen"}, {"url": "https://blog.insightdatascience.com/?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Insight"}, {"url": "https://blog.insightdatascience.com/how-to-access-s3-data-from-spark-74e40e0b2231?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "How to access S3 data from SparkGetting data from an AWS S3 bucket is as easy as configuring your Spark cluster"}, {"url": "https://blog.insightdatascience.com/how-to-access-s3-data-from-spark-74e40e0b2231?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "5 min read\u00b7Jun 1, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F74e40e0b2231&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fhow-to-access-s3-data-from-spark-74e40e0b2231&user=Hoa+Nguyen&userId=b48e50852cf5&source=-----74e40e0b2231----1-----------------clap_footer----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/how-to-access-s3-data-from-spark-74e40e0b2231?source=author_recirc-----819b65f074d8----1---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74e40e0b2231&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fhow-to-access-s3-data-from-spark-74e40e0b2231&source=-----819b65f074d8----1-----------------bookmark_preview----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/airflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@sriram_82638?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@sriram_82638?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Sriram Baskaran"}, {"url": "https://blog.insightdatascience.com/?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Insight"}, {"url": "https://blog.insightdatascience.com/airflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Airflow 101: Start automating your batch workflows with easeIn this blog, I cover the main concepts behind pipeline automation with Airflow and go through the code (and a few gotchas) to create your\u2026"}, {"url": "https://blog.insightdatascience.com/airflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "7 min read\u00b7Oct 17, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F8e7d35387f94&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fairflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94&user=Sriram+Baskaran&userId=43d4e6f51837&source=-----8e7d35387f94----2-----------------clap_footer----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/airflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94?source=author_recirc-----819b65f074d8----2---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8e7d35387f94&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Fairflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94&source=-----819b65f074d8----2-----------------bookmark_preview----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Emmanuel Ameisen"}, {"url": "https://blog.insightdatascience.com/?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Insight"}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "Always start with a stupid model, no exceptions.How to efficiently build Machine Learning powered products."}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": "9 min read\u00b7Mar 6, 2018"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Finsight-data%2F3a22314b9aaa&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Falways-start-with-a-stupid-model-no-exceptions-3a22314b9aaa&user=Emmanuel+Ameisen&userId=45cca2d4999f&source=-----3a22314b9aaa----3-----------------clap_footer----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa?source=author_recirc-----819b65f074d8----3---------------------65ab676b_54dd_4ef1_9829_3f7128521796-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "4"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3a22314b9aaa&operation=register&redirect=https%3A%2F%2Fblog.insightdatascience.com%2Falways-start-with-a-stupid-model-no-exceptions-3a22314b9aaa&source=-----819b65f074d8----3-----------------bookmark_preview----65ab676b_54dd_4ef1_9829_3f7128521796-------", "anchor_text": ""}, {"url": "https://medium.com/@emmanuelameisen?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "See all from Emmanuel Ameisen"}, {"url": "https://blog.insightdatascience.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "See all from Insight"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://wvheeswijk.medium.com/?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Wouter van Heeswijk, PhD"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Proximal Policy Optimization (PPO) ExplainedThe journey from REINFORCE to the go-to algorithm in continuous control"}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b713 min read\u00b7Nov 29, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----abed1952457b----0-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/proximal-policy-optimization-ppo-explained-abed1952457b?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fabed1952457b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fproximal-policy-optimization-ppo-explained-abed1952457b&source=-----819b65f074d8----0-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://thepycoach.com/?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "The PyCoach"}, {"url": "https://artificialcorner.com/?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Artificial Corner"}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "You\u2019re Using ChatGPT Wrong! Here\u2019s How to Be Ahead of 99% of ChatGPT UsersMaster ChatGPT by learning prompt engineering."}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b77 min read\u00b7Mar 17"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fartificial-corner%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&user=The+PyCoach&userId=fb44e21903f3&source=-----886a50dabc54----1-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://artificialcorner.com/youre-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "276"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F886a50dabc54&operation=register&redirect=https%3A%2F%2Fartificialcorner.com%2Fyoure-using-chatgpt-wrong-here-s-how-to-be-ahead-of-99-of-chatgpt-users-886a50dabc54&source=-----819b65f074d8----1-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@mattchapmanmsc?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Matt Chapman"}, {"url": "https://towardsdatascience.com/?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Towards Data Science"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "The Portfolio that Got Me a Data Scientist JobSpoiler alert: It was surprisingly easy (and free) to make"}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b710 min read\u00b7Mar 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&user=Matt+Chapman&userId=bf7d13fc53db&source=-----513cc821bfe4----0-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://towardsdatascience.com/the-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4?source=read_next_recirc-----819b65f074d8----0---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "42"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F513cc821bfe4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-portfolio-that-got-me-a-data-scientist-job-513cc821bfe4&source=-----819b65f074d8----0-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@timothymugayi?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Timothy Mugayi"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "How To Build Your Own Custom ChatGPT With Custom Knowledge BaseFeed your ChatGPT bot with custom data sources"}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b711 min read\u00b7Apr 7"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&user=Timothy+Mugayi&userId=34774d6cac27&source=-----4e61ad82427e----1-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/how-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e?source=read_next_recirc-----819b65f074d8----1---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "83"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e61ad82427e&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fhow-to-build-your-own-custom-chatgpt-with-custom-knowledge-base-4e61ad82427e&source=-----819b65f074d8----1-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Andrew Austin"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "AI Anyone Can Understand: Part 2 \u2014 The Bellman EquationMake sure you check out the rest of the AI Anyone Can Understand Series I have written and plan to continue to write on"}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b74 min read\u00b7Dec 11, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&user=Andrew+Austin&userId=42d388912d13&source=-----614846383eb7----2-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/@MoneyAndData/ai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7?source=read_next_recirc-----819b65f074d8----2---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F614846383eb7&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40MoneyAndData%2Fai-anyone-can-understand-part-1-the-bellman-equation-614846383eb7&source=-----819b65f074d8----2-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://dwiuzila.medium.com/?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Albers Uzila"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "Wanna Break into Data Science in 2023? Think Twice!It won\u2019t be smooth sailing for you"}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": "\u00b711 min read\u00b7Dec 23, 2022"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&user=Albers+Uzila&userId=159e5ce51250&source=-----26842e9a87fe----3-----------------clap_footer----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/wanna-break-into-data-science-in-2023-think-twice-26842e9a87fe?source=read_next_recirc-----819b65f074d8----3---------------------3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "12"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26842e9a87fe&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwanna-break-into-data-science-in-2023-think-twice-26842e9a87fe&source=-----819b65f074d8----3-----------------bookmark_preview----3a921693_8ecc_4f6d_aaaf_fb9c0740400d-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----819b65f074d8--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----819b65f074d8--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}