{"url": "https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06", "time": 1682993096.846022, "path": "netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06/", "webpage": {"metadata": {"title": "How Netflix uses Druid for Real-time Insights to Ensure a High-Quality Experience | by Netflix Technology Blog | Netflix TechBlog", "h1": "How Netflix uses Druid for Real-time Insights to Ensure a High-Quality Experience", "description": "Ensuring a consistently great Netflix experience while continuously pushing innovative technology updates is no easy feat. How can we be confident that updates are not harming our users? And that\u2026"}, "outgoing_paragraph_urls": [{"url": "https://www.youtube.com/watch?v=AGEXxB-nWMw&feature=youtu.be&t=2540", "anchor_text": "software updates", "paragraph_index": 4}, {"url": "https://druid.apache.org/", "anchor_text": "Apache Druid", "paragraph_index": 6}, {"url": "https://druid.apache.org/docs/latest/design/segments.html", "anchor_text": "segments", "paragraph_index": 12}, {"url": "https://druid.apache.org/docs/latest/development/extensions-core/kafka-ingestion.html", "anchor_text": "Kafka Indexing Tasks", "paragraph_index": 14}, {"url": "https://druid.apache.org/docs/latest/design/processes.html", "anchor_text": "Middle Managers", "paragraph_index": 14}, {"url": "https://druid.apache.org/docs/latest/ingestion/index.html#ingestion-specs", "anchor_text": "Ingestion Spec", "paragraph_index": 15}, {"url": "https://druid.apache.org/docs/latest/ingestion/index.html#granularityspec", "anchor_text": "Query Granularity", "paragraph_index": 16}, {"url": "https://druid.apache.org/docs/latest/design/segments.html#replacing-segments", "anchor_text": "replacing and superseding", "paragraph_index": 21}, {"url": "https://github.com/Netflix/atlas", "anchor_text": "Atlas", "paragraph_index": 26}], "all_paragraphs": ["Ensuring a consistently great Netflix experience while continuously pushing innovative technology updates is no easy feat. How can we be confident that updates are not harming our users? And that we\u2019re actually making measurable improvements when we intend to?", "Using real-time logs from playback devices as a source of events, we derive measurements in order to understand and quantify how seamlessly users\u2019 devices are handling browsing and playback.", "Once we have these measures, we feed them into a database. Every measure is tagged with anonymized details about the kind of device being used, for example, whether the device is a Smart TV, an iPad or an Android Phone. This enables us to classify devices and view the data according to various aspects. This in turn allows us to isolate issues that may only affect a certain group, such as a version of the app, certain types of devices, or particular countries.", "This aggregated data is available immediately for querying, either via dashboards or ad-hoc queries. The metrics are also continuously checked for alarm signals, such as if a new version is affecting playback or browsing for some users or devices. These checks are used to alert the responsible team which can address the issue as quickly as possible.", "During software updates, we enable the new version for a subset of users and use these real-time metrics to compare how the new version is performing vs the previous version. Any regression in the metrics gives us a signal to abort the update and revert those users getting the new version back to the previous version.", "With this data arriving at over 2 million events per second, getting it into a database that can be queried quickly is formidable. We need sufficient dimensionality for the data to be useful in isolating issues and as such we generate over 115 billion rows per day. At Netflix we leverage Apache Druid to help tackle this challenge at our scale.", "\u201cApache Druid is a high performance real-time analytics database. It\u2019s designed for workflows where fast queries and ingest really matter. Druid excels at instant data visibility, ad-hoc queries, operational analytics, and handling high concurrency.\u201d \u2014 druid.io", "As such, Druid fits really well with our use-case. High ingestion rate of event data, with high cardinality and fast query requirements.", "Druid is not a relational database, but some concepts are transferable. Rather than tables, we have datasources. As with relational databases, these are logical groupings of data that are represented as columns. Unlike relational databases, there is no concept of joins. As such we need to ensure that whichever columns we want to filter or group-by are included in each datasource.", "There are primarily three classes of columns in a datasource \u2014 time, dimensions and metrics.", "Everything in Druid is keyed by time. Each datasource has a timestamp column that is the primary partition mechanism. Dimensions are values that can be used to filter, query or group-by. Metrics are values that can be aggregated, and are nearly always numeric.", "By removing the ability to perform joins, and assuming data is keyed by timestamp, Druid can make some optimizations in how it stores, distributes and queries data such that we\u2019re able to scale the datasource to trillions of rows and still achieve query response times in the 10s of milliseconds.", "To achieve this level of scalability, Druid divides the stored data into time chunks. The duration of time chunks is configurable. An appropriate duration can be chosen depending on your data and use-case. For our data and use-case, we use 1 hour time chunks. Data within a time chunk is stored in one or more segments. Each segment holds rows of data all falling within the time chunk as determined by its timestamp key column. The size of the segments can be configured such that there is an upper bound on the number of rows, or the total size of the segment file.", "When querying data, Druid sends the query to all nodes in the cluster that are holding segments for the time chunks within the range of the query. Each node processes the query in parallel across the data it is holding, before sending the intermediate results back to the query broker node. The broker will perform the final merge and aggregation before sending the result set back to the client.", "Inserts to this database occur in real-time. Rather than individual records being inserted into a datasource, the events (metrics in our case) are read from Kafka streams. We use 1 topic per datasource. Within Druid we use Kafka Indexing Tasks which create multiple indexing workers that are distributed among the Realtime Nodes (Middle Managers).", "Each of these indexers subscribes to the topic and reads its share of events from the stream. The indexers extract values from the event messages according to an Ingestion Spec and accumulate the created rows in memory. As soon as a row is created, it\u2019s available to be queried. Queries arriving for a time chunk where a segment is still being filled by the indexers, will be served by the indexers themselves. As indexing tasks are essentially performing 2 jobs, ingestion and fielding queries, it\u2019s important to get the data out to the Historical Nodes in a timely manner to offload the query work to them, in a more optimized way.", "Druid can roll up data as it is ingested to minimize the amount of raw data that needs to be stored. Rollup is a form of summarization or pre-aggregation. In some circumstances, rolling up data can dramatically reduce the size of data that needs to be stored, potentially reducing row counts by orders of magnitude. However, this storage reduction does come at a cost: we lose the ability to query individual events and can only query at the predefined Query Granularity. For our use-case we chose a 1-minute query granularity.", "During ingestion, if any rows have identical dimensions and their timestamp is within the same minute (our Query Granularity), the rows are rolled up. This means the rows are combined by adding together all the metric values and incrementing a counter so we know how many events contributed to this row\u2019s values. This form of rollup can significantly reduce the row count in the database and thereby speed up queries as we then have fewer rows to operate on and aggregate.", "Once the number of accumulated rows hits a certain threshold, or the segment has been open for too long, the rows are written into a segment file and offloaded to deep storage. The indexer then informs the coordinator that the segment is ready so that the coordinator can tell one or more historical nodes to load it. Once the segment has been successfully loaded into Historical nodes, it is then unloaded from the indexer and any queries targeting that data will now be served by the historical nodes.", "As you may imagine, as the cardinality of dimensions increases, the likelihood of having identical events within the same minute decreases. Managing cardinality, and therefore roll-up, is a powerful lever to achieving good query performance.", "To achieve the rate of ingestion that we need, we run many instances of the indexers. Even with the rollup combining identical rows in the indexing tasks, the chances of getting those identical rows all in the same instance of an indexing task are very low. To combat this and achieve the best possible rollup, we schedule a task to run after all the segments for a given time-chunk have been handed-off to the historical nodes.", "This scheduled compaction task fetches all the segments for the time-chunk from deep storage, and runs through a map/reduce job to recreate segments and achieve a perfect rollup. The new segments are then loaded and published by the Historical nodes replacing and superseding the original, less-rolled-up segments. In our case we see about a 2x improvement in row count by using this additional compaction task.", "Knowing when all the events for a given time-chunk have been received is not trivial. There can be late-arriving data on the Kafka topics, or the indexers could be taking time to hand-off the segments to the Historical nodes. To work around this we enforce some limitations and perform checks before running compaction.", "Firstly, we discard any very late arriving data. We consider this too old to be useful in our real-time system. This sets a bound on how late data can be. Secondly, the compaction task is scheduled with a delay, this gives the segments plenty of time to have been offloaded to the Historical nodes in the normal flow. And lastly, when the scheduled compaction task for the given time chunk kicks off, it queries the segment metadata to check if there are any relevant segments still being written to, or handed-off. If there are, it will wait and try again in a few minutes. This ensures that all data is processed by the compaction job.", "Without these measures, we found that sometimes we\u2019d lose data. Segments that were still being written to when compaction started would be overwritten with the newly compacted segments that have a higher version and so take precedence. This effectively deleted the data that was contained in those segments that had not yet finished being handed-off.", "Druid supports two query languages: Druid SQL and native queries. Under the hood, Druid SQL queries are converted into native queries. Native queries are submitted as JSON to a REST endpoint and is the primary mechanism we use.", "Most queries to our cluster are generated by custom internal tools such as dashboards and alerting systems. These systems were originally designed to work with our internally developed, and open-sourced, time-series database, Atlas. As such, these tools speak the Atlas Stack query language.", "To accelerate adoption of querying Druid, and enable re-use of existing tools, we added a translation layer that takes Atlas queries, rewrites them as Druid queries, issues the query and reformats the results as Atlas results. This abstraction layer enables existing tools to be used as-is and creates no additional learning curve for users to access the data in our Druid datastore.", "While adjusting the configuration of the cluster nodes, we ran a series of repeatable and predictable queries at high rate in order to get a benchmark of the response time and query throughput for each given configuration. The queries were designed to isolate parts of the cluster to check for improvements or regressions in query performance.", "For example we ran targeted queries for the most recent data so that only Middle Managers were queried. Likewise for longer durations but only older data to ensure we query only the Historical nodes to test the caching configuration. And again with queries that group by very high cardinality dimensions to check how result merging was affected. We continued to tweak and run these benchmarks until we were happy with the query performance.", "During these tests we found that tuning the size of buffers, number of threads, query queue lengths and memory allocated to query caches had an effective impact on the query performance. However, the introduction of the compaction job, which takes our poorly-rolled-up segments and re-compacts them with perfect roll-up, has a more significant impact on query performance.", "We also found that enabling caches on the Historical nodes was very beneficial, whereas enabling caches on the broker nodes was much less so. So much that we don\u2019t use caches on the brokers. It may be due to our use case, but nearly every query we make misses the cache on the brokers, likely because the queries usually include the most current data, which won\u2019t be in any caches as it\u2019s always arriving.", "After multiple iterations of tuning and tailoring for our use case and data rate, Druid has proven to be as capable as we initially hoped.", "We\u2019ve been able to get to a capable and usable system, but there\u2019s still more work to do. Our volume and rate of ingestion is constantly increasing, as are the number and complexity of the queries. As the value of this detailed data is realized by more teams, we frequently add more metrics and dimensions which pushes the system to work harder. We have to continue to monitor and tune to keep the query performance in check.", "We\u2019re currently ingesting at over 2 million events per second, and querying over 1.5 trillion rows to get detailed insights into how our users are experiencing the service. All this helps us maintain a high-quality Netflix experience, while enabling constant innovation.", "Learn more about how Netflix designs, builds, and operates our systems and engineering organizations"], "all_outgoing_urls": [{"url": "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F19e1e8568d06&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&source=---two_column_layout_nav----------------------------------", "anchor_text": "Open in app"}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---two_column_layout_nav-----------------------new_post_sidenav-----------", "anchor_text": "Write"}, {"url": "https://medium.com/search?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign up"}, {"url": "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=post_page---two_column_layout_nav-----------------------global_nav-----------", "anchor_text": "Sign In"}, {"url": "https://netflixtechblog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Netflix Technology Blog"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc3aeaf49d8a4&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=post_page-c3aeaf49d8a4----19e1e8568d06---------------------post_header-----------", "anchor_text": "Follow"}, {"url": "https://netflixtechblog.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Netflix TechBlog"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2F19e1e8568d06&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----19e1e8568d06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F19e1e8568d06&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=-----19e1e8568d06---------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://www.linkedin.com/in/sykesb/", "anchor_text": "Ben Sykes"}, {"url": "https://www.youtube.com/watch?v=AGEXxB-nWMw&feature=youtu.be&t=2540", "anchor_text": "software updates"}, {"url": "https://druid.apache.org/", "anchor_text": "Apache Druid"}, {"url": "https://druid.apache.org/docs/latest/design/segments.html", "anchor_text": "segments"}, {"url": "https://druid.apache.org/docs/latest/development/extensions-core/kafka-ingestion.html", "anchor_text": "Kafka Indexing Tasks"}, {"url": "https://druid.apache.org/docs/latest/design/processes.html", "anchor_text": "Middle Managers"}, {"url": "https://druid.apache.org/docs/latest/ingestion/index.html#ingestion-specs", "anchor_text": "Ingestion Spec"}, {"url": "https://druid.apache.org/docs/latest/ingestion/index.html#granularityspec", "anchor_text": "Query Granularity"}, {"url": "https://druid.apache.org/docs/latest/design/segments.html#replacing-segments", "anchor_text": "replacing and superseding"}, {"url": "https://github.com/Netflix/atlas", "anchor_text": "Atlas"}, {"url": "https://medium.com/tag/druid?source=post_page-----19e1e8568d06---------------druid-----------------", "anchor_text": "Druid"}, {"url": "https://medium.com/tag/realtime?source=post_page-----19e1e8568d06---------------realtime-----------------", "anchor_text": "Realtime"}, {"url": "https://medium.com/tag/metrics-and-analytics?source=post_page-----19e1e8568d06---------------metrics_and_analytics-----------------", "anchor_text": "Metrics And Analytics"}, {"url": "https://medium.com/tag/apache?source=post_page-----19e1e8568d06---------------apache-----------------", "anchor_text": "Apache"}, {"url": "https://medium.com/tag/kafka?source=post_page-----19e1e8568d06---------------kafka-----------------", "anchor_text": "Kafka"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2F19e1e8568d06&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----19e1e8568d06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2F19e1e8568d06&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----19e1e8568d06---------------------clap_footer-----------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F19e1e8568d06&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&source=--------------------------bookmark_footer-----------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc3aeaf49d8a4&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=post_page-c3aeaf49d8a4----19e1e8568d06---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8ddcdec29142&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&newsletterV3=c3aeaf49d8a4&newsletterV3Id=8ddcdec29142&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----19e1e8568d06---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Written by Netflix Technology Blog"}, {"url": "https://netflixtechblog.medium.com/followers?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "367K Followers"}, {"url": "https://netflixtechblog.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Netflix TechBlog"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc3aeaf49d8a4&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=post_page-c3aeaf49d8a4----19e1e8568d06---------------------follow_profile-----------", "anchor_text": "Follow"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F8ddcdec29142&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06&newsletterV3=c3aeaf49d8a4&newsletterV3Id=8ddcdec29142&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----19e1e8568d06---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/building-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix Technology Blog"}, {"url": "https://netflixtechblog.com/?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix TechBlog"}, {"url": "https://netflixtechblog.com/building-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Building a Media Understanding Platform for ML InnovationsThe media understanding platform serves as an abstraction layer between Machine Learning (ML) algos and various applications."}, {"url": "https://netflixtechblog.com/building-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "12 min read\u00b7Mar 14"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2F9bef9962dcb7&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fbuilding-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----9bef9962dcb7----0-----------------clap_footer----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/building-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7?source=author_recirc-----19e1e8568d06----0---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "8"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9bef9962dcb7&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fbuilding-a-media-understanding-platform-for-ml-innovations-9bef9962dcb7&source=-----19e1e8568d06----0-----------------bookmark_preview----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/improved-alerting-with-atlas-streaming-eval-e691c60dc61e?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix Technology Blog"}, {"url": "https://netflixtechblog.com/?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix TechBlog"}, {"url": "https://netflixtechblog.com/improved-alerting-with-atlas-streaming-eval-e691c60dc61e?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Improved Alerting with Atlas Streaming EvalRuchir Jha, Brian Harrington, Yingwu Zhao"}, {"url": "https://netflixtechblog.com/improved-alerting-with-atlas-streaming-eval-e691c60dc61e?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "7 min read\u00b74 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2Fe691c60dc61e&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fimproved-alerting-with-atlas-streaming-eval-e691c60dc61e&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----e691c60dc61e----1-----------------clap_footer----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/improved-alerting-with-atlas-streaming-eval-e691c60dc61e?source=author_recirc-----19e1e8568d06----1---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "1"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe691c60dc61e&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fimproved-alerting-with-atlas-streaming-eval-e691c60dc61e&source=-----19e1e8568d06----1-----------------bookmark_preview----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix Technology Blog"}, {"url": "https://netflixtechblog.com/?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix TechBlog"}, {"url": "https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Ready for changes with Hexagonal ArchitectureA story on how we leveraged Hexagonal Architecture principles to be prepared for changes in the Netflix Studio ecosystem."}, {"url": "https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "9 min read\u00b7Mar 10, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2Fb315ec967749&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fready-for-changes-with-hexagonal-architecture-b315ec967749&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----b315ec967749----2-----------------clap_footer----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749?source=author_recirc-----19e1e8568d06----2---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "29"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb315ec967749&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fready-for-changes-with-hexagonal-architecture-b315ec967749&source=-----19e1e8568d06----2-----------------bookmark_preview----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/how-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix Technology Blog"}, {"url": "https://netflixtechblog.com/?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "Netflix TechBlog"}, {"url": "https://netflixtechblog.com/how-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "How Netflix Scales its API with GraphQL Federation (Part 1)Learn how Netflix uses GraphQL federation for its API architecture, offering a unified, curated API powered by decoupled back-end services."}, {"url": "https://netflixtechblog.com/how-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": "9 min read\u00b7Nov 9, 2020"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fnetflix-techblog%2Fae3557c187e2&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2&user=Netflix+Technology+Blog&userId=c3aeaf49d8a4&source=-----ae3557c187e2----3-----------------clap_footer----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.com/how-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2?source=author_recirc-----19e1e8568d06----3---------------------55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae3557c187e2&operation=register&redirect=https%3A%2F%2Fnetflixtechblog.com%2Fhow-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2&source=-----19e1e8568d06----3-----------------bookmark_preview----55c8a84f_1ea3_4ba6_94ed_2a0d41649a48-------", "anchor_text": ""}, {"url": "https://netflixtechblog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "See all from Netflix Technology Blog"}, {"url": "https://netflixtechblog.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "See all from Netflix TechBlog"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://alexcancode.medium.com/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Alexander Nguyen"}, {"url": "https://levelup.gitconnected.com/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Level Up Coding"}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Why I Keep Failing Candidates During Google Interviews\u2026They don\u2019t meet the bar."}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "\u00b74 min read\u00b7Apr 13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&user=Alexander+Nguyen&userId=a148fd75c2e9&source=-----dc8f865b2c19----0-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://levelup.gitconnected.com/why-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "89"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdc8f865b2c19&operation=register&redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fwhy-i-keep-failing-candidates-during-google-interviews-dc8f865b2c19&source=-----19e1e8568d06----0-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@SeattleDataGuy?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@SeattleDataGuy?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Ben Rogojan"}, {"url": "https://medium.com/coriers?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "SeattleDataGuy By SeattleDataGuy"}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Data Engineering Vs Machine Learning PipelinesWhat\u2019s the difference?"}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "\u00b78 min read\u00b7Apr 24"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fcoriers%2F82d0e1be410c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoriers%2Fdata-engineering-vs-machine-learning-pipelines-82d0e1be410c&user=Ben+Rogojan&userId=41cd8f154e82&source=-----82d0e1be410c----1-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/coriers/data-engineering-vs-machine-learning-pipelines-82d0e1be410c?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "3"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F82d0e1be410c&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fcoriers%2Fdata-engineering-vs-machine-learning-pipelines-82d0e1be410c&source=-----19e1e8568d06----1-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://cookjack248.medium.com/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://cookjack248.medium.com/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Jack C"}, {"url": "https://betterprogramming.pub/?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Better Programming"}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "dbt v1.5 \u2014 the 3 Big New ThingsData contracts, model versions, and model access"}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "6 min read\u00b73 days ago"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fbetter-programming%2F660e59fd29cb&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fdbt-v1-5-the-3-big-new-things-660e59fd29cb&user=Jack+C&userId=1eb3d543fd09&source=-----660e59fd29cb----0-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://betterprogramming.pub/dbt-v1-5-the-3-big-new-things-660e59fd29cb?source=read_next_recirc-----19e1e8568d06----0---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "5"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F660e59fd29cb&operation=register&redirect=https%3A%2F%2Fbetterprogramming.pub%2Fdbt-v1-5-the-3-big-new-things-660e59fd29cb&source=-----19e1e8568d06----0-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@jankammerath/boomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@jankammerath?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@jankammerath?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Jan Kammerath"}, {"url": "https://medium.com/@jankammerath/boomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Boomer Developers: 10 Lessons I Learned From ThemBoomers taught me valuable lessons about software engineering which I want to share with you. Especially if you\u2019re a younger generation."}, {"url": "https://medium.com/@jankammerath/boomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "\u00b717 min read\u00b7Apr 23"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6c8e73ef64c6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jankammerath%2Fboomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6&user=Jan+Kammerath&userId=80520e660179&source=-----6c8e73ef64c6----1-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@jankammerath/boomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6?source=read_next_recirc-----19e1e8568d06----1---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "13"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6c8e73ef64c6&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40jankammerath%2Fboomer-developers-10-lessons-i-learned-from-them-6c8e73ef64c6&source=-----19e1e8568d06----1-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://kai-waehner.medium.com/fraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://kai-waehner.medium.com/?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://kai-waehner.medium.com/?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Kai Waehner"}, {"url": "https://kai-waehner.medium.com/fraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Fraud Detection with Apache Kafka, KSQL and Apache FlinkFraud Detection case studies and architectures with Apache Kafka, KSQL, and Apache Flink at Paypal, Capital One, ING Bank, Grab, Kakao\u2026"}, {"url": "https://kai-waehner.medium.com/fraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "\u00b76 min read\u00b7Jan 26"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fd0f68223cb98&operation=register&redirect=https%3A%2F%2Fkai-waehner.medium.com%2Ffraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98&user=Kai+Waehner&userId=dcf5fd266935&source=-----d0f68223cb98----2-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://kai-waehner.medium.com/fraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98?source=read_next_recirc-----19e1e8568d06----2---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": ""}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd0f68223cb98&operation=register&redirect=https%3A%2F%2Fkai-waehner.medium.com%2Ffraud-detection-with-apache-kafka-ksql-and-apache-flink-d0f68223cb98&source=-----19e1e8568d06----2-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/fintechexplained/the-guide-to-choose-the-right-database-for-your-project-74b1af4150ab?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@farhadmalik?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/@farhadmalik?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "Farhad Malik"}, {"url": "https://medium.com/fintechexplained?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "FinTechExplained"}, {"url": "https://medium.com/fintechexplained/the-guide-to-choose-the-right-database-for-your-project-74b1af4150ab?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "The Guide To Choosing The Right Database For Your ProjectClearly Explained Rules On Selecting The Right Database For Your Application With AWS Database Examples"}, {"url": "https://medium.com/fintechexplained/the-guide-to-choose-the-right-database-for-your-project-74b1af4150ab?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": "\u00b74 min read\u00b7Mar 28"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ffintechexplained%2F74b1af4150ab&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ffintechexplained%2Fthe-guide-to-choose-the-right-database-for-your-project-74b1af4150ab&user=Farhad+Malik&userId=d9b237bc89f0&source=-----74b1af4150ab----3-----------------clap_footer----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/fintechexplained/the-guide-to-choose-the-right-database-for-your-project-74b1af4150ab?source=read_next_recirc-----19e1e8568d06----3---------------------68d5ff2f_5f6d_41a7_8149_193c5d38d843-------&responsesOpen=true&sortBy=REVERSE_CHRON", "anchor_text": "2"}, {"url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74b1af4150ab&operation=register&redirect=https%3A%2F%2Fmedium.com%2Ffintechexplained%2Fthe-guide-to-choose-the-right-database-for-your-project-74b1af4150ab&source=-----19e1e8568d06----3-----------------bookmark_preview----68d5ff2f_5f6d_41a7_8149_193c5d38d843-------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "See more recommendations"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=post_page-----19e1e8568d06--------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}