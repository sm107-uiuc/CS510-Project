{"url": "https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/\n", "time": 1683020739.689763, "path": "analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/\n/", "webpage": {"metadata": {"title": "Spark Transformations and Actions On RDD", "h1": "Using PySpark to perform Transformations and Actions on RDD", "description": "In this article we will learn about spark transformations and actions on RDD. These include map, filter, groupby, sample, set, max, min, sum etc on RDDs."}, "outgoing_paragraph_urls": [{"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article", "paragraph_index": 0}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "hackathons", "paragraph_index": 0}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "previous", "paragraph_index": 3}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article to setup PySpark", "paragraph_index": 4}, {"url": "https://drive.google.com/open?id=0B3GihyBQdu_PZ05MM2x3VTdvQ2M", "anchor_text": "link", "paragraph_index": 11}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD", "anchor_text": "doc", "paragraph_index": 66}], "all_paragraphs": ["In my previous article, I introduced you to the basics of Apache Spark, different data representations (RDD / DataFrame / Dataset) and basics of operations (Transformation and Action). We even solved a machine learning problem from one of our past hackathons. In this article, I will continue from the place I left in my previous article. I will focus on manipulating RDD in PySpark by applying operations (Transformation and Actions).", "As you would remember, a RDD (Resilient Distributed Database) is a collection of elements, that can be divided across multiple nodes in a cluster to run parallel processing. It is also a fault tolerant collection of elements, which means it can automatically recover from failures. RDD is immutable, i.e. once created, we can not change a RDD. So, then how do I apply operations on a RDD? Well, we apply an operation and store results in another RDD", "For this article, one must have \u00a0some understanding about Apache Spark and hands on experience in python programming.", "Let\u2019s recall concepts about RDD from our previous\u00a0article:", "Before applying transformations and actions on RDD, we need to first open the PySpark shell (please refer to my previous article to setup PySpark ).", "Spark has certain operations which can be performed on RDD. An operation is a method, which can be applied on a RDD to accomplish\u00a0certain task. RDD supports two types of operations, which are Action and Transformation. An operation can\u00a0be something as simple as\u00a0sorting, filtering and summarizing data.", "Let\u2019s take few examples to understand the concept of transformation and action better. Let\u2019s assume,\u00a0we want to develop a machine learning model on a data set. Before applying a machine learning model, we will need\u00a0to perform certain tasks:", "All the above mentioned tasks are examples of an operation. In Spark, operations are divided into 2 parts \u2013 one is transformation and second is action. Find below a brief\u00a0descriptions of these operations.", "Transformation: Transformation refers to the operation applied on a RDD to create new RDD. Filter, groupBy and map are the examples of transformations.", "Actions: Actions refer to an operation which also applies on RDD, that instructs Spark to perform computation and send the result back to driver. This is an example of action.", "The Transformations and Actions in Apache Spark are divided into 4 major categories:", "To understand the operations, I am going to use the text file from my previous article. Let\u2019s begin, I have already copied and pasted all text from my blog in a textfile called blogtexts. To download this file you can refer to this\u00a0link. Before applying operations on blogtexts, we need to first load this file with the help of SparkContext.", "In above code, \u2018PATH\u2019 is the location of blogtexts. Let\u2019s\u00a0see\u00a0first 5 elements of RDD.", "Now lets see one by one how transformations and actions work on RDDs.", "For each transformation, \u00a0I have first laid out the need of the transformation in the form of a question and then answered it in the subsequent section.", "Q1: Convert all words in a rdd to lowercase and split the lines of a document using space.", "To lower\u00a0the case of each word of a document, we can use the map transformation. A map transformation is useful when we need to transform a RDD by applying a function to each element. So how can we use map transformation on \u2018rdd\u2019 in our case?", "Solution: Let\u2019s see through the example, Apply a function called \u201cFunc\u201d on each words of a document ( blogtexts ). \u201cFunc\u201d will do two things:", "To do this first we need to write\u00a0\u201cFunc\u201d\u00a0and then apply this function using map.", "After applying the function (Func) on \u201crdd\u201d, we have transformed this \u201crdd\u201d into \u201crdd1\u201d, we can see the first 5 elements of \u201crdd1\u201d by applying take operation (which is an action).", "Output is too long so, I have just attached a snippet of it. We can also see that our output is not flat (it\u2019s a nested list). So for getting the flat output, we need to apply a transformation which will flatten the output, The transformation\u00a0\u201cflatMap\u201d\u00a0will help here:", "The \u201cflatMap\u201d transformation\u00a0will return a new RDD by first applying a function to all elements of this RDD, and then flattening the results. This is the main difference between the \u201cflatMap\u201d and map transformations. Let\u2019s apply a \u201cflatMap\u201d transformation on \u201crdd\u201d , then take the result of this transformation in \u201crdd2\u201d and print\u00a0the result after applying this transformation.", "You can now observe that the new output is flattened out.", "Q2: Next, I want to remove the words, which are not necessary to\u00a0analyze this text. We call these words as \u201cstop words\u201d; Stop words do not add much value in a text. For example, \u201cis\u201d, \u201cam\u201d, \u201care\u201d and \u201cthe\u201d are few examples of stop words.", "Solution: To remove the stop words, we can use a \u201cfilter\u201d transformation which will return a new RDD containing only the elements that satisfy given condition(s). Lets apply \u201cfilter\u201d transformation on \u201crdd2\u201d and get\u00a0words which are not stop words and get\u00a0the result in \u201crdd3\u201d. To do that:", "We can check first 10 elements of \u201crdd3\u201d by applying take action.", "After seeing the result of a filter transformation, we can check now we don\u2019t have specified stop words in rdd3 (there are no for and a).", "Q3: After getting the results into rdd3, we want to group the words in rdd3 based on which letters they start with. For example, suppose I want to group each word of rdd3 based on first 3 characters.", "Solution: The \u201cgroupBy\u201d \u00a0transformation will group the data in the original RDD. It creates a set of key value pairs, where the key is output of a user function, and the value is all items for which the function yields this key.", "After applying \u201cgroupBy\u201d function, we store\u00a0the transformed result in \u201crdd4\u201d (RDDs are immutable \u2013 remember!). To view \u201crdd4\u201d, we can print first (key, value) elements in \u201crdd4\u201d.", "Q4: What if we want to calculate how many times each word is coming in corpus ?", "Solution: We can apply the \u201cgroupByKey\u201d / \u201creduceByKey\u201d transformations on (key,val) pair RDD. The \u201cgroupByKey\u201d will group the values for each key in the original RDD. It will create a new pair, where the original key corresponds to this collected group of values.", "To use \u201cgroupbyKey\u201d / \u201creduceByKey\u201d transformation to find\u00a0the frequencies of each words, you can follow the steps below:", "Let\u2019s see, how to convert \u201crdd3\u201d to new mapped (key,val) RDD. And then we can apply\u00a0\u201cgroupbyKey\u201d / \u201creduceByKey\u201d\u00a0transformation on this RDD.", "In the above code I am first converting \u201crdd3\u201d into \u201crdd3_mapped\u201d. \u00a0The \u201crdd3_mapped\u201d is nothing but a mapped (key,val) pair RDD. Then I am applying \u201cgroupByKey\u201d transformation on \u201crdd3_mapped\u201d to group the all elements based on the keys (words). Next, I am\u00a0saving the result into \u201crdd3_grouped\u201d. Let\u2019s\u00a0see the first 5 elements in \u201crdd3_grouped\u201d.", "After seeing the result of the above code, I rechecked the corpus to know, how many times the word \u2018manager\u2019 is there, so I found that \u2018manager\u2019 is written more then once. I figure out that there are more words like \u2018manager.\u2019 , \u2018manager,\u2019 and \u201dmanager:\u2019.\u00a0Let\u2019s filter \u2018manager,\u2019 in \u201crdd3\u201d.", "We can see that in above output, we have multiple words with \u2018manager\u2019 in our corpus. To overcome this situation we can do several things. We could apply a regular expression to remove unnecessary punctuation from the words. For the purpose of this article,\u00a0I am skipping that part.", "Until now we have not calculated the frequencies / counts of each words. Let\u2019s\u00a0proceed further :", "In the above code, I first applied \u201cmapValues\u201d transformation on \u201crdd3_grouped\u201d. The \u201cmapValues\u201d (only applicable on pair RDD) transformation is like a map (can be applied on any RDD) transform but it has one difference that when we apply map transform on pair RDD we can access the key and value both of this RDD but in case of \u201cmapValues\u201d transformation, it will transform the values by applying some function and key will not be affected. So for example, in above code I applied sum, which will calculate the sum (counts) for the each word.", "After applying \u201cmapValues\u201d \u00a0transformation I want to sort the words based on their frequencies so for doing that I am first converting a ( word, frequency ) pair to ( frequency,word ) so that our key and values will be interchanged then, I will apply a sorting based on key and then get a result in \u201crdd3_freq_of_words\u201d. We can see that 10 most frequent words I used in my previous blog by applying \u201ctake\u201d action.", "Above output shows that I used words spark 69 times and Apache 52 times in my previous blog.", "We can also use \u201creduceByKey\u201d transformation for counting the frequencies of each word in (key,value) pair RDD. Lets see how will we do this.", "If we compare the result of both ( \u201cgroupByKey\u201d and \u201creduceByKey\u201d) transformations, we have got the same results. I am sure you must be wondering what is the difference in both transformations. The \u201creduceByKey\u201d transformations first combined the values for each key in all partition, so each partition will have only one value for a key then after shuffling, in reduce phase executors will apply operation for example, in my case sum(lambda x: x+y).", "But in case of \u201cgroupByKey\u201d transformation, it will not combine the values in each key in all partition it directly shuffle the data then merge the values for each key. Here in\u00a0\u201cgroupByKey\u201d transformation lot of shuffling in the data is required to get the answer, so it is better to use \u201creduceByKey\u201d in case of large shuffling of data.", "Q5: How do I perform a task (say count the words \u2018spark\u2019 and \u2018apache\u2019 in rdd3) separatly on each partition and get the output of the task performed in these partition ?\nSoltion: We can do this by applying \u201cmapPartitions\u201d transformation. The \u201cmapPartitions\u201d is like a map transformation but runs separately on different partitions of a RDD. So, for counting the frequencies of words \u2018spark\u2019 and \u2018apache\u2019 in each partition of RDD, you can follow the steps:", "Lets apply above function called \u2018func\u2019 on each partition of rdd3.", "I have used the \u201cglom\u201d function which is very useful when we want to see the data insights for each partition of a RDD. So above result shows that 49,39 are the counts of \u2018spark\u2019, \u2018apache\u2019 in partition1 and 20,13 are the counts of \u2018spark\u2019, \u2018apache\u2019 in partition2. If we won\u2019t use the\u00a0\u201cglom\u201d function we won\u2019t we able to see the results of each partition.", "Q6: What if I want to work with samples instead of full data ?\nSoltion:\u00a0\u201csample\u201d transformation helps us in taking samples instead of working on full data. The sample method will return a new RDD, containing a statistical sample of the original RDD.\nWe can pass the arguments insights as the sample operation:", "Q 7: What if I want to create a RDD which contains all the elements (a.k.a. union) of two RDDs ?\n Solution: To do so, we can use \u201cunion\u201d transformation on two RDDs. In Spark \u201cunion\u201d transformation will return a new RDD by taking the union of two RDDs. Please note that duplicate items will not be removed in the new RDD. To illustrate this:", "From the above output, we can see that the \u201csample1\u201d, \u201csample2\u201d both have 914 elements each. And in the \u201cunion_of_sample1_sample2\u201d, we have 1828 elements which shows that union operation didn\u2019t remove the duplicate elements.", "Q 8: If we want to join the two pair RDDs based on their key.\n Solution:\u00a0The \u201cjoin\u201d transformation can help us join two pairs of RDDs based on their key. To show\u00a0that:", "Q 9: How to calculate distinct elements in a RDD ?\n Solution:\u00a0We can apply \u201cdistinct\u201d transformation on RDD to get the distinct elements. Let\u2019s see how many distinct words do we have in the \u201crdd3\u201d.", "\u201crdd3_distinct\u201d will contain all the unique words / elements present in \u201crdd3\u201d. We\u00a0can also check that we have 1485 unique words in the \u201crdd3\u201d.", "Q 10: What if I want to reduce the number of partition of a RDD and get the result in a new RDD?\n Solution:\u00a0We will use \u201ccoalesce\u201d transformation here. To demonstrate that:", "2. And now apply coalesce transformation on \u201crdd3\u201d ,\u00a0get the results in \u201crdd3_coalesce\u201d and see the number of partitions.", "In some previous examples of transformation I already used some of the actions on different RDDs for printing\u00a0the result. For example,\u201dtake\u201d to print the first n elements of a RDD ,\u00a0\u201cgetNumPartitions\u201d to know how many partition a RDD has and \u201ccollect\u201d to print all elements of RDD.", "Now, I will take few more actions to demonstrate how we can get the results.", "Q 11: How do I find out number of parition in RDD ?", "Solution: With\u00a0\u201cgetNumPartitions\u201d, we can find out that how many partitions exist in our RDD. Let\u2019s see how many partition our initial RDD (\"rdd3\") has.", "Q 12: If I want to find out the sum the all numbers in a RDD.", "Solution: To demonstrate this, I will:", "A reduce action is use for aggregating all the elements of RDD by applying pairwise user function.", "In the code above, I first created a RDD(\u201cnum_rdd\u201d) from the list and then I applied a reduce action on it to sum all \u00a0the numbers in \u201cnum_rdd\u201d.", "Q 13: Count the number of elements in RDD.", "Solution:\u00a0The count action will count the number of elements in RDD. To see that, let\u2019s apply count action on \u201crdd3\u201d to count the number of words in \"rdd3\".", "To take the maximum, minimum, sum, variance and standard deviation of a RDD, we can apply \u201cmax\u201d, \u201cmin\u201d, \u201csum\u201d, \u201cvariance\u201d and \u201cstdev\u201d actions. Let\u2019s take the maximum, minimum, sum, variance and standard deviation of \u201cnum_rdd\u201d.", "Taking a step back, we got introduced to the fascinating world of Apache Spark in the last article.\u00a0In this article, I have introduced you to some of the most common transformations and actions on RDD. There are many more transformations and actions defined on RDDs, but it is cumbersome (and unwanted) to cover all of them in one article. To learn more about transformations and actions, you can refer RDD API\u00a0doc\u00a0in Python.", "I suggest you to apply these operations at your end in\u00a0RDD, and get hands on experience on what are the challenges you are face\u00a0while applying these. Let me know your doubts & any challenges you face in the comments section and I would be happy to answer them.", "Also,\u00a0if you have any questions or suggestions\u00a0about other features of RDD that you would like to know about, please drop in your comments below. In the next article, I\u2019ll discuss about Dataframe operations in PySpark.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fusing-pyspark-to-perform-transformations-and-actions-on-rdd%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=Using PySpark to perform Transformations and Actions on RDD&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fusing-pyspark-to-perform-transformations-and-actions-on-rdd%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fusing-pyspark-to-perform-transformations-and-actions-on-rdd%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/facebook_user_4/", "anchor_text": "1201904"}, {"url": "https://www.analyticsvidhya.com/blog/category/big-data/", "anchor_text": "Big data"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-engineering/", "anchor_text": "Data Engineering"}, {"url": "https://www.analyticsvidhya.com/blog/category/intermediate/", "anchor_text": "Intermediate"}, {"url": "https://www.analyticsvidhya.com/blog/category/libraries/", "anchor_text": "Libraries"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/programming/", "anchor_text": "Programming"}, {"url": "https://www.analyticsvidhya.com/blog/category/python-2/", "anchor_text": "Python"}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article"}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "hackathons"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/article.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "previous"}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article to setup PySpark"}, {"url": "https://drive.google.com/open?id=0B3GihyBQdu_PZ05MM2x3VTdvQ2M", "anchor_text": "link"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/outputimage.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/reduceByKey-3.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/groupbykey.png", "anchor_text": ""}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD", "anchor_text": "doc"}, {"url": "http://datahack.analyticsvidhya.com/contest/all", "anchor_text": "Live Competitions"}, {"url": "https://www.analyticsvidhya.com/blog/tag/advanced-python/", "anchor_text": "Advanced Python"}, {"url": "https://www.analyticsvidhya.com/blog/tag/apache-spark/", "anchor_text": "Apache Spark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/big-data-in-python/", "anchor_text": "big data in python"}, {"url": "https://www.analyticsvidhya.com/blog/tag/pyspark/", "anchor_text": "PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/rdd-in-pyspark/", "anchor_text": "RDD in Pyspark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/rdds/", "anchor_text": "RDDs"}, {"url": "https://www.analyticsvidhya.com/blog/tag/resilient-distributed-database/", "anchor_text": "resilient distributed database"}, {"url": "https://www.analyticsvidhya.com/blog/tag/spark/", "anchor_text": "Spark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/transformations-and-actions/", "anchor_text": "transformations and actions"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-apache-spark-rdd-and-pyspark/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "A Comprehensive Guide to Apache Spark RDD and PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/2022/08/create-rdd-in-apache-spark-using-pyspark/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "Create RDD in Apache Spark using Pyspark"}, {"url": "https://www.analyticsvidhya.com/blog/2022/06/an-end-to-end-starter-guide-on-apache-spark-and-rdd/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "An End-to-End Starter Guide on Apache Spark and RDD"}, {"url": "https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-pyspark-rdd-operations/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "A Comprehensive Guide to PySpark RDD Operations"}, {"url": "https://www.analyticsvidhya.com/blog/2022/08/introduction-to-on-apache-spark-and-its-datasets/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "Introduction to Apache Spark and its Datasets"}, {"url": "https://www.analyticsvidhya.com/blog/2022/04/beginners-guide-on-apache-spark-rdds/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/", "anchor_text": "Beginners Guide on Apache Spark & RDDs"}, {"url": "https://www.analyticsvidhya.com/blog/author/facebook_user_4/", "anchor_text": "1201904"}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/rahul105/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/sion/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/chirag676/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/barney6/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/arnab1408/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/prateekmaj21/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/shanthababu/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/", "anchor_text": "Deep Learning Guide: Introduction to Implementing Neural Networks using TensorFlow in Python"}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/winners-solution-from-the-super-competitive-the-ultimate-student-hunt/", "anchor_text": "Winner\u2019s Solution from the super competitive \u201cThe Ultimate Student Hunt\u201d"}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}