{"url": "https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n", "time": 1683020702.9271529, "path": "analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/\n/", "webpage": {"metadata": {"title": "PySpark DataFrames | Dataframe Operations In Pyspark", "h1": "Complete Guide on DataFrame Operations in PySpark", "description": "Learn how to create dataframes in Pyspark. This tutorial explains dataframe operations in PySpark, dataframe manipulations and its uses."}, "outgoing_paragraph_urls": [{"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem", "paragraph_index": 0}, {"url": "http://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem", "paragraph_index": 0}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/?utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem", "paragraph_index": 1}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article", "paragraph_index": 7}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "Black Friday Practice Problem", "paragraph_index": 15}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "here", "paragraph_index": 15}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD", "anchor_text": "doc", "paragraph_index": 65}], "all_paragraphs": ["In my first real world machine learning problem, I introduced you to basic concepts of Apache Spark like how does it work, different cluster modes in Spark and What are the different data representation in Apache Spark. To provide you with a hands-on-experience, I also used a real world machine learning problem and then I solved it using PySpark.", "In my second real world machine learning problem, I introduced you on how to create RDD from different sources ( External, Existing ) and briefed you on basic operations ( Transformation and Action) on RDD.", "In this article, I will be talking about DataFrame and its features in detail. Then, we will see how to create DataFrame from different sources and how to perform various operations in DataFrame.", "P.S. \u2013 If you have not read the previous 2 articles, I strongly recommend that you go through them before going further.", "In Apache Spark, a DataFrame is a distributed collection of rows under named columns. In simple terms, it is same as a table in relational database or an Excel sheet with Column headers. It also shares some common characteristics with RDD:", "My first exposure to DataFrames was when I learnt about Pandas. Today, it is difficult for me to run my data science workflow with out Pandas DataFrames. So, when I saw similar functionality in Apache Spark, I was excited about the possibilities it opens up!", "I am sure this question must be lingering in your mind. To make things simpler for you, I\u2019m listing down few advantages of DataFrames:", "In order to understand the operations of DataFrame, you need to first setup the Apache Spark in your machine. Follow the step by step approach mentioned in my previous article,\u00a0which will guide you to setup Apache Spark in Ubuntu.", "DataFrame supports wide range of operations which are very useful while working with data. In this section, I will take you through some of the common operations on DataFrame.", "First step, in any Apache programming is to create a SparkContext. SparkContext is required when we want to execute operations in a cluster. SparkContext tells Spark how and where to access a cluster. And the first step is to connect with Apache Cluster. If you are using Spark Shell, you will notice\u00a0that it\u00a0is already created. Otherwise, we can create the SparkContext by importing, initializing and providing the configuration settings. For example,", "Again we need to do same with the SQLContext, if it is not loaded.", "A DataFrame in Apache Spark can be created in\u00a0multiple ways:", "I am following these steps for creating a DataFrame from list of tuples:", "Lets check the type of schemaPeople.", "For reading a csv file in Apache Spark, we need to specify a new library in our python shell. To perform this action, first we need to download Spark-csv package (Latest version) and extract this package into the home directory of Spark. Then, we need to open a PySpark shell and include the package (I am using \u201cspark-csv_2.10:1.3.0\u201d).", "Let\u2019s read the data from csv file and create the DataFrame. To demonstrate this I\u2019m to using the train and test datasets from the Black Friday Practice Problem, which you can download\u00a0here.", "PATH is the location of folder, where your train and test csv files are located. Header is True, which\u00a0means that the csv files contains the header. We are using inferSchema = True option for telling sqlContext to automatically detect the data type of each column in data frame. If we do not set inferSchema to be true, all columns will be read as string.", "Now comes the fun part. You have loaded the dataset by now. Let us start playing with it now.", "To see the types of columns in DataFrame, we can use the printSchema, dtypes. Let\u2019s apply printSchema() on train which will Print the schema in a tree format.", "From above output, we can see that, we have perfectly captured the schema / data types of each columns while reading from csv.", "We can use head\u00a0operation\u00a0to see first n observation (say, 5 observation). Head operation in PySpark is similar to head operation\u00a0in Pandas.", "Above results are comprised of row like format. To see the result in more interactive manner\u00a0(rows under the columns), we can use the\u00a0show operation. Let\u2019s apply show operation on train and take first 2 rows of it. We can pass the argument truncate = True to truncate the result.", "We can use count\u00a0operation to count the number of rows in DataFrame. Let\u2019s apply count operation on train & test files to count the number of rows.", "For getting the columns name we can use columns\u00a0on DataFrame,\u00a0similar to what we do for getting the columns in pandas DataFrame. Let\u2019s first print the number of columns and columns name in train file then in test file.", "Lets do the same for the test.", "From the above output we can check that we have 13 columns in test file and 12 in train file. \u201cPurchase\u201d not present in test file where as \u201cComb\u201d is only in test\u00a0file.\u00a0We can also see that, we have one column (\u201d) in test file which doesn\u2019t have a name.", "describe\u00a0operation is used to calculate the summary statistics of numerical column(s) in DataFrame. If we don\u2019t specify the name of columns, it will calculate summary statistics for all numerical columns present in DataFrame.", "Let\u2019s check what happens when we specify the name of a categorical / String columns in\u00a0describe\u00a0operation.", "As we can see that, describe operation is working for String type column but the output for mean, stddev are null and min & max values are calculated based on ASCII value of categories.", "To subset the columns, we need to use select operation on DataFrame and we need\u00a0to pass the columns names separated by commas inside\u00a0select\u00a0Operation. Let\u2019s select first 5 rows of \u2018User_ID\u2019 and \u2018Age\u2019 from the train.", "The distinct\u00a0operation can be used here, to calculate the number of distinct rows in a DataFrame. Let\u2019s apply distinct operation to calculate the number of distinct product in train and test file each.", "We have 3631 & 3491 distinct product in train & test file respectively. After counting the number of distinct values for train and test files, we can see the train file has more categories than test file. Let us check what are the categories for Product_ID, which are in test file but not in train file by applying subtract operation.We can do the same for all categorical features.", "Above, you can see that 46 different categories are in test file but not in train. In this case, either we collect more data about them or skip the rows in test file for those categories (invalid category) which are not in train file.", "We can use crosstab\u00a0operation on DataFrame to calculate the pair wise frequency of columns. Let\u2019s apply crosstab operation on \u2018Age\u2019 and \u2018Gender\u2019 columns of train DataFrame.", "In the above output, the first column of each row will be the distinct values of Age and the column names will be the distinct values of Gender. The name of the first column will be Age_Gender. Pair with no occurrences will have zero count in contingency table.", "We can use dropDuplicates operation to drop the duplicate rows of a DataFrame and get the DataFrame which won\u2019t have duplicate rows. To demonstrate that I am performing this on two columns Age and Gender of train and get the all unique rows for these columns.", "The dropna operation can be use here. To drop row from the DataFrame it consider three options.", "Let\u2019t drop null rows in train with default parameters and count the rows in output DataFrame. Default options are any, None, None for how, thresh, subset respectively.", "Use fillna operation here. The fillna will take two parameters to fill the null values.", "Let\u2019s fill \u2018-1\u2019 inplace of null values in train DataFrame.", "We can apply the filter\u00a0operation\u00a0on Purchase column in train DataFrame to filter out the rows with values more than 15000. We need to pass a condition. Let\u2019s apply filter on Purchase column in train DataFrame and print the number of rows which has more purchase than 15000.", "The groupby\u00a0operation can be used here to find the mean of Purchase for each age group in train. Let\u2019s see how can we get the mean purchase for the \u2018Age\u2019 column train.", "We can also apply sum, min, max, count with groupby when we want to get different summary insight each group. Let\u2019s take one more example of groupby to count the number of rows in each Age group.", "We can use sample operation to take sample of a DataFrame. The sample method on DataFrame will return a DataFrame containing the sample of base DataFrame. The sample method will take 3 parameters.", "Let\u2019s create the two DataFrame t1 and t2 from train, both will have 20% sample of train and count the number of rows in each.", "We can apply a function on each row of DataFrame using map operation. After applying this function, we get the result in the form of RDD. Let\u2019s apply a map operation on User_ID column of train and print the first 5 elements of mapped RDD(x,1) after applying the function (I am applying lambda function).", "In above code we have passed lambda function in the map operation which will take each row / element of \u00a0\u2018User_ID\u2019 one by one and return pair for them (\u2018User_ID\u2019,1).", "We can use orderBy\u00a0operation on DataFrame to get sorted output based on some column. The orderBy operation take two arguments.", "Let\u2019s sort the train DataFrame based on \u2018Purchase\u2019.", "We can use withColumn\u00a0operation\u00a0to add new column (we can also replace) in base DataFrame and return a new DataFrame. The withColumn operation will take 2 parameters.", "Let\u2019s see how withColumn works. I am calculating new column name \u2018Purchase_new\u2019 in train which is calculated by dviding Purchase column by 2.", "To drop a column from the DataFrame we can use drop operation. Let\u2019s drop the column called \u2018Comb\u2019 from the test and get the remaining columns in test.", "Here, we can use a user defined function ( udf ) to remove the categories of a column which are in test but not in train. Let\u2019s again calculate the categories in Product_ID column which are in test but not in train.", "We have got 46 different categories in test. For removing these categories from the test \u2018Product_ID\u2019 column. I am applying these steps.", "Let\u2019s see how it works. First create \u2018not_found_cat\u2019", "Now resister the udf, we need to import StringType from the pyspark.sql and udf from the pyspark.sql.functions. The udf function takes 2 parameters as arguments:", "In the above code function name is \u2018F1\u2019 and we are putting \u2018-1\u2019 \u00a0for not found catagories in test \u2018Product_ID\u2019. Finally apply above \u2018F1\u2019 function on test \u2018Product_ID\u2019 and take result in k1 for new column calles \u201cNEW_Product_ID\u201d.", "Now, let\u2019s see the results by again calculating the different categories in k and train subtract operation.", "The output 1 means we have now only 1 different category k and train.", "We have already discussed in the above section that DataFrame has additional information about datatypes and names of columns associated with it. Unlike RDD, this additional information allows Spark to run SQL queries on DataFrame. To apply SQL queries on DataFrame first we need to register DataFrame as table. Let\u2019s first register train DataFrame as table.", "In the above code, we have registered \u2018train\u2019 as table(\u2018train_table\u2019) with the help of registerAsTable operation. Let\u2019s apply SQL queries on \u2018train_table\u2019 to select Product_ID the result of SQL query will be a DataFrame. We need to apply a action to get the result.", "In the above code, I am using sqlContext.sql for specifying SQL query.", "Let\u2019s get maximum purchase of each Age group in train_table.", "Pandas and Spark DataFrame are designed for structural and semistructral data processing. Both share some similar properties (which I have discussed above). The few differences between Pandas and PySpark DataFrame are:", "In addition to above points, Pandas and Pyspark DataFrame have some basic differences like columns selection, filtering, adding the columns, etc. which I am not covering here.", "In this article, I have introduced you to some of the most common operations\u00a0on DataFrame in Apache Spark. There are many more operations\u00a0defined on DataFrame, but it is cumbersome (and unwanted) to cover all of them in one article. To learn more about operations on DataFrame, you can refer Pyspark.sql module\u00a0doc\u00a0in Python.", "A. In Apache Spark, a DataFrame is a distributed collection of rows under named columns. In simple terms, it is the same as a table in a relational database or an Excel sheet with column headers.", "A. DataFrames in Apache Spark are used to process large collections of structured or semi-structured data, by organizing them into rows and columns.", "A. A DataFrame in Apache Spark can be created in\u00a0multiple ways:1. It can be created using different data formats such as JSON, CSV, etc.2. A DataFrame can be created by loading data from existing RDD.3. It can also be programmed by specifying the schema.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fspark-dataframe-and-operations%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=Complete Guide on DataFrame Operations in PySpark&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fspark-dataframe-and-operations%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F10%2Fspark-dataframe-and-operations%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/facebook_user_4/", "anchor_text": "1201904"}, {"url": "https://www.analyticsvidhya.com/blog/category/big-data/", "anchor_text": "Big data"}, {"url": "https://www.analyticsvidhya.com/blog/category/database/", "anchor_text": "Database"}, {"url": "https://www.analyticsvidhya.com/blog/category/intermediate/", "anchor_text": "Intermediate"}, {"url": "https://www.analyticsvidhya.com/blog/category/libraries/", "anchor_text": "Libraries"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/programming/", "anchor_text": "Programming"}, {"url": "https://www.analyticsvidhya.com/blog/category/python-2/", "anchor_text": "Python"}, {"url": "https://www.analyticsvidhya.com/blog/category/sql/", "anchor_text": "SQL"}, {"url": "https://www.analyticsvidhya.com/blog/category/structured-data/", "anchor_text": "Structured Data"}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem"}, {"url": "http://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem"}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/using-pyspark-to-perform-transformations-and-actions-on-rdd/?utm_source=blog&utm_medium=DataFramePySparkarticle", "anchor_text": "real world machine learning problem"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/DataFrame-Operations-in-PySpark.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/09/comprehensive-introduction-to-apache-spark-rdds-dataframes-using-pyspark/", "anchor_text": "article"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/DataFrame-in-Spark.png", "anchor_text": ""}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "Black Friday Practice Problem"}, {"url": "https://datahack.analyticsvidhya.com/contest/black-friday/", "anchor_text": "here"}, {"url": "http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD", "anchor_text": "doc"}, {"url": "https://www.analyticsvidhya.com/blog/tag/apache-spark/", "anchor_text": "Apache Spark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dataframe/", "anchor_text": "Dataframe"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dataframe-rdd/", "anchor_text": "dataframe & RDD"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dataframe-in-pyspark/", "anchor_text": "dataframe in pyspark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dataframe-groupby/", "anchor_text": "dataframe.groupby"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dataframes/", "anchor_text": "dataframes"}, {"url": "https://www.analyticsvidhya.com/blog/tag/pyspark/", "anchor_text": "PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/tag/python/", "anchor_text": "python"}, {"url": "https://www.analyticsvidhya.com/blog/tag/spark/", "anchor_text": "Spark"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-to-apache-spark-rdd-and-pyspark/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "A Comprehensive Guide to Apache Spark RDD and PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/2022/04/getting-started-with-pyspark-using-python/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "Getting Started with PySpark Using Python"}, {"url": "https://www.analyticsvidhya.com/blog/2022/12/crafting-serverless-etl-pipeline-using-aws-glue-and-pyspark/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "Crafting Serverless ETL Pipeline Using AWS Glue and PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/2022/09/working-with-dataframes-using-pyspark/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "Working with DataFrames Using PySpark"}, {"url": "https://www.analyticsvidhya.com/blog/2022/04/learn-about-apache-spark-using-python/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "Learn About Apache Spark Using Python"}, {"url": "https://www.analyticsvidhya.com/blog/2021/05/9-most-useful-functions-for-pyspark-dataframe/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/", "anchor_text": "9 most useful functions for PySpark DataFrame"}, {"url": "https://www.analyticsvidhya.com/blog/author/facebook_user_4/", "anchor_text": "1201904"}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/rahul105/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/sion/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/chirag676/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/barney6/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/arnab1408/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/prateekmaj21/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/shanthababu/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/winning-strategies-for-ml-competitions-from-past-winners/", "anchor_text": "Winning Strategies for ML Competitions from Past Winners"}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/winners-approach-codes-from-knocktober-xgboost-dominates/", "anchor_text": "Winners Approach & Codes from Knocktober : It\u2019s all about Feature Engineering!"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}