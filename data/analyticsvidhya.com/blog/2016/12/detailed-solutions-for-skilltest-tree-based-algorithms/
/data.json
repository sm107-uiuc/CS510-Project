{"url": "https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/\n", "time": 1683020634.8055239, "path": "analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/\n/", "webpage": {"metadata": {"title": "Questions On Tree Based Algorithms To Test Data Scientist", "h1": "45 questions to test Data Scientists on Tree Based Algorithms (Decision tree, Random Forests, XGBoost)", "description": "This article contains questions on tree based algorithms. In this article algorithms mentioned are Random Forest, Gradient Boosting & Decision Tree."}, "outgoing_paragraph_urls": [{"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/lb", "anchor_text": "leaderboard", "paragraph_index": 2}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/lb", "anchor_text": "here", "paragraph_index": 4}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-regression/", "anchor_text": "Skill test \u2013 Regression", "paragraph_index": 6}, {"url": "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/", "anchor_text": "A Complete Tutorial on Tree Based Modeling from Scratch (in R & Python)", "paragraph_index": 8}, {"url": "https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/", "anchor_text": "Introduction to Random forest \u2013 Simplified", "paragraph_index": 9}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/", "anchor_text": "Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python", "paragraph_index": 10}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_learning", "anchor_text": "here", "paragraph_index": 49}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q18_Image.jpg", "anchor_text": "", "paragraph_index": 69}, {"url": "https://ai.vub.ac.be/sites/default/files/ch3.pdf", "anchor_text": "this presentation.", "paragraph_index": 93}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/", "anchor_text": "this article.", "paragraph_index": 98}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/", "anchor_text": "article.", "paragraph_index": 127}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-regression/", "anchor_text": "Skilltest Regression", "paragraph_index": 138}], "all_paragraphs": ["Tree Based algorithms like Random Forest, Decision Tree, and Gradient Boosting are commonly used machine learning algorithms. Tree based algorithms are often used to solve data science problems. Every data science aspirant must be skilled in tree based algorithms.\u00a0We conducted this skill test to help you analyze your knowledge in these algorithms.", "A total of 1016 participants registered for this skill test. The test was designed to test the conceptual knowledge of tree based algorithms. If you are one of those who missed out on this skill test, here are the questions and solutions. You missed on the real time test, but can read this article to find out how you could have answered correctly.", "Here are the leaderboard ranking for all the participants.", "Below are the distribution scores, they will help you evaluate your performance.", "You can access the final scores here. More than 400 people participated in the skill test and the highest score obtained was 36 . Here are a few statistics about the distribution.", "You can see that got a bi-modal distribution of scores. We were not expecting that as the first 8 questions were relatively easy and could be solved grounds up without too much knowledge about decision trees.", "If you did well, here is another test coming up \u2013 Skill test \u2013 Regression , which would test you on knowledge of solving regression problems.", "Here are a few resources you can refer to to improve your knowledge on tree based algorithms.", "A Complete Tutorial on Tree Based Modeling from Scratch (in R & Python)", "Introduction to Random forest \u2013 Simplified", "Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python", "Q 1) The data scientists at \u201cBigMart Inc\u201d have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product based on these attributes and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store during a defined period.", "Which learning problem does this belong to?", "Supervised learning is the machine learning task of inferring a function from labeled training data. Here historical sales data is our training data and it contains the labels / outcomes.", "Q2) Before building our model, we first look at our data and make predictions manually. Suppose we have only one feature as an independent variable (Outlet_Location_Type) along with a continuous dependent variable (Item_Outlet_Sales).", "\nWe see that we can possibly\u00a0differentiate in Sales based on location (tier 1 or tier 3). We can write simple if-else statements to make predictions.", "Which of the following models could be used to generate predictions (may not be most accurate)?", "All the options would be correct. All the above models give a prediction as output and here we are not talking about most or least accurate.", "Q3) The below created if-else statement is called a decision stump:", "Now let us evaluate the model we created above on following data:", "We will calculate RMSE\u00a0to evaluate this model.", "The root-mean-square error (RMSE) is a measure of the differences between values predicted by a model or an estimator and the values actually observed.", "What would be the RMSE\u00a0value for this model?", "So by calculating RMSE value using the formula above, we get ~824 as our answer.", "Q4) For the same data, let us evaluate our models. The root-mean-square error (RMSE) is a measure of the differences between values predicted by a model or an estimator and the values actually observed.", "Which of the following will be the best model with respect to RMSE scoring?", "Calculate the RMSE value for each if-else model:", "We see that the model in option A has the lowest value and lower the RMSE, better the model.", "Q5) Now let\u2019s take multiple features into account.", "If have multiple if-else ladders, which model is best with respect to RMSE?", "We see that option D has the lowest value", "Q6) Till now, we have just created predictions using some\u00a0intuition based rules. Hence our predictions may not be optimal.What could be done to optimize the approach of finding better predictions from the given data?", "We will take that value which is more representative of the data. Given all three options, central tendency, mean value would be a better fit for the data.", "Q7) We could improve our model by\u00a0selecting the feature which gives a better prediction\u00a0when we use it for splitting (It is a process of dividing a node into two or more sub-nodes).", "In this example, we want to find which feature would be better for splitting root node (entire population or sample and this further gets divided into two or more homogeneous sets).", "Assume splitting method is \u201cReduction in Variance\u201d i.e. we\u00a0split using a variable, which results in overall lower variance.", "What is the resulting variance if we split using Outlet_Location_Type?", "Option A is correct. The steps to solve this problem are:", "P.S. You will need to take weigthed mean.", "Q8) Next, we want to find which feature would be better for splitting root node (where root node represents entire population). For this, we will set \u201cReduction in Variance\u201d as our splitting method.", "The split with lower variance is selected as the criteria to split the population.", "Among Between Outlet_Location_Type and Item_Fat_Content, which was a better feature to split?", "Option A is correct because Outlet_Location_Type has more reduction in variance. You can perform calculation similar to last question.", "Q9) Look at the below image: The red dots represent original data input, while the green line is the resultant model.", "How do you propose to make this model better while working with decision tree?", "A. As we can see in the image, our model is not general enough, it takes outliers/ noise into account when calculating predictions which makes it overfit the data.", "B. If we can set the number of nodes, we could easily get an optimal tree. But to select this value optimally beforehand is very hard, as it requires extensive cross-validation to be generalizable.", "C. Tuning Tree parameters is the best method to ensure generalizability", "Q10) Which methodology does Decision Tree (ID3) take to decide on first split?", "The process of top-down induction of decision trees (TDIDT) is an example of a greedy algorithm, and it is by far the most common strategy for learning decision trees from data. Read\u00a0here.", "Q11) There are 24 predictors in a dataset. You build 2 models on the dataset:", "1. Bagged decision trees and\n2. Random forest", "Let the number of predictors used at a single split in bagged decision tree is A and Random Forest is B.", "Which of the following statement is correct?", "Random Forest uses a subset of predictors for model building, whereas bagged trees use all the features at once.", "Q12) Why do\u00a0we prefer information gain over accuracy when splitting?", "All the above options are correct", "Q13) Random forests (While solving a regression problem) have the\u00a0higher variance of predicted result in comparison to Boosted Trees (Assumption: both Random Forest and Boosted Tree are\u00a0fully optimized). ", "It completely depends on the data, the assumption cannot be made without data.", "Q14) Assume everything else remains same, which of the following is the right statement about the predictions from decision tree in comparison with predictions from Random Forest?", "The predicted values in Decision Trees have low Bias but high Variance when compared to Random Forests. This is because random forest attempts to reduce variance by bootstrap aggregation. Refer topic 15.4 of Elements of Statistical Learning", "Q15) Which of the following tree based algorithm uses some parallel (full or partial) implementation?", "Only Random Forest and XGBoost have parallel implementations.", "Random Forest is very easy to parallelize, where as XGBoost can have partially parallel implementation. In Random Forest, all trees grows parallel and finally ensemble the output of each tree .", "Xgboost doesn\u2019t run multiple trees in parallel like Random Forest, you need predictions after each tree to update gradients. Rather it does the parallelization WITHIN a single tree to create branches independently.", "Q16) Which of the following could not be\u00a0result\u00a0of two-dimensional feature space from natural recursive binary split?", "1 is not possible. Therefore, Option A is correct. For more details, refer to Page 308 from ELSI (Elements of Statistical Learning).", "Q17) Which of the following is not possible in a boosting algorithm?", "Boosted algorithms minimize error in previously predicted values by last estimator. So it always decreases training error.", "Q18) Which of the following is a decision boundary of Decision Tree?\n", "Decision Boundaries of decision trees are always perpendicular to X and Y axis.", "Q19) Let\u2019s say we have m numbers of estimators (trees) in a boosted tree.\u00a0Now, how many intermediate trees will work on modified version (OR weighted) of data set?", "The first tree in boosted trees works on the original data, whereas all the rest work on modified version of the data.", "Q20) Boosted decision trees perform better than Logistic Regression on anomaly detection problems (Imbalanced Class problems).\u00a0", "Q21) Provided n < N and m < M. A Bagged Decision Tree\u00a0with a dataset of N rows and M columns uses____rows and ____ columns for training an individual intermediate tree.", "Bagged trees uses all the columns for only a sample of the rows. So randomization is done on the number of observations not on number of columns.", "Q22) Given 1000 observations, Minimum observation required to split a node equals to 200 and minimum leaf size equals to 300 then what could be the maximum depth of a decision tree?", "The leaf nodes will be as follows for minimum observation to split is 200 and minimum leaf size is 300:", "So only after 2 split, the tree is created. Therefore depth is 2.", "Q23) Consider a classification tree for whether a person watches \u2018Game of Thrones\u2019 based on features like age, gender, qualification and salary. Is it possible to have following leaf node?", "A node can be split on a feature, as long as it gives information after split. So even though the above split does not reduce the classification error, it improves the Gini index and the cross-entropy. Refer Pg. 314 of ISLR.", "Q24) Generally, in terms of prediction performance which of the following arrangements are correct:", "Generally speaking, Boosting algorithms will\u00a0perform better than bagging algorithms. In terms of bagging vs random forest, random forest works better in practice because random forest has less correlated trees compared to bagging. And it\u2019s always true that ensembles of algorithms are better than single models", "Q25) In which of the following application(s), a tree based algorithm can be applied successfully?", "Option E is correct as we can apply tree based algorithm in all the 3 scenarios.", "Q26) When using Random Forest for feature selection, suppose you permute values of two features \u2013 A and B. Permutation is such that you change the indices of individual values so that they do not remain associated with the same target as before.", "You notice that permuting values does not affect the score of model built on A, whereas the score decreases on the\u00a0model trained on B.Which of the following features would you select from the following solely based on the above finding?", "This is called mean decrease in accuracy when using random forest for feature selection. Intuitively, if shuffling the values is not impacting the predictions, the feature is unlikely to add value.", "Q27) Boosting is said to be a good classifier because:", "A. Trees are sequential in boosting. They are not parallel", "B. Boosting attempts to minimize residual error which reduces margin distribution", "C. As we saw in B, margins are minimized and not maximized.", "Q28)\u00a0Which splitting algorithm is better with categorical variable having high cardinality?", "When high cardinality problems, gain ratio is preferred over any other splitting technique. Refer slide number 72 of this presentation.", "Q29) There are \u201cA\u201d features in a dataset and a Random Forest model is built over it. It is given that there exists only one significant feature\u00a0of the outcome \u2013 \u201cFeature1\u201d. What would be the %\u00a0of total splits that will not consider the \u201cFeature1\u201d as one of the features involved in that split (It is given that m is the number of maximum features for random forest)?", "Note: Considering random forest select features space for every node split.", "Option A is correct. This can be considered as permutation of not selecting a predictor from all the possible predictors", "Q30) Suppose we have missing values in our data.\u00a0Which of the following method(s) can help us\u00a0to deal with missing values while building a decision tree?", "All the options are correct. Refer this article.", "Q31) To reduce under fitting of a Random Forest model, which of the following method can be used?", "Only option B is correct, because", "A: increasing the number of samples for a leaf will reduce the depth of a tree, indirectly increasing underfitting", "B: Increasing depth will definitely decrease help reduce underfitting", "C: increasing the number of samples considered to split will have no effect, as the same information will be given to the model.", "Q32)\u00a0While creating a Decision Tree, can we reuse a feature to split a node?", "Yes, decision tree recursively uses all the features at each node.", "Q33) Which of the following is a mandatory data pre-processing step(s) for XGBOOST?", "XGBoost is doesn\u2019t require most of the pre-processing steps, so only converting data to numeric is required among of the above listed steps", "Q34) Decision Trees are not affected by multicollinearity in features:", "The statement is true. For example, if there are two 90% correlated features, decision tree would consider only one of them for splitting.", "Q35) For parameter tuning in a boosting algorithm, which of the following search strategies may give best tuned model:", "For a a given search space,", "Both random search or grid search may give best tuned model. It depends on how much time and resources can be allocated for search.", "Q36) Imagine a two variable predictor space having 10 data points. A\u00a0decision tree is built over it with 5 leaf nodes.\u00a0The number of distinct regions that will be formed in predictors space?", "The predictor space will be divided into 5 regions. Therefore, option D is correct.", "Q37) In Random Forest, which of the following is randomly selected?", "Option A is False because, number of trees has to decided when building a tree. It is not random.", "Options B and C are true", "Q38) Which of the following are the\u00a0disadvantage of Decision Tree algorithm?", "Option A is False, as decision tree are very easy to interpret", "Option B is True, as decision tree are high unstable models", "Option C is True, as decision tree also tries to memorize noise.", "Q39) While tuning the parameters \u201cNumber of estimators\u201d and \u201cShrinkage Parameter\u201d/\u201dLearning Rate\u201d for boosting algorithm.Which of the following relationship should be kept in mind?", "It is generally seen that smaller learning rates require more trees to be added to the model and vice versa. So when tuning parameters of boosting algorithm, there is a trade-off between learning rate and number of estimators", "Q40) Let\u2019s say we have m number of estimators (trees) in a XGBOOST model.\u00a0Now, how many trees will work on bootstrapped data set?", "All the trees in XGBoost will work on bootstrapped data. Therefore, option C is true", "Q41) Which of the following statement is correct about XGBOOST parameters:", "1 and 4 are wrong statements, whereas 2 and 3 are correct. Therefore D is true. Refer this article.", "Q42) What can be the maximum depth of decision tree (where k is the number of features and N is the number of samples)? Our constraint is that we are considering a binary decision tree with no duplicate rows in sample (Splitting criterion is not fixed).", "The answer is N-1. An example of max depth would be when splitting only happens on the left node.", "Q43) Boosting is a general approach that can be applied to many statistical learning methods for regression or classification.\u00a0", "Boosting is an ensemble technique and can be applied to various base algorithms", "Q44) Predictions of individual trees of bagged decision trees have lower correlation in comparison to individual trees of random forest.", "This is False because random Forest has more randomly generated uncorrelated trees than bagged decision trees. Random Forest considers only a subset of total features. So individual trees that are generated by random forest may have different feature subsets. This is not true for bagged trees.", "Q45) Below is a list of parameters of Decision Tree. In which of the following cases higher is better?", "For all three options A, B and C, it is not necessary that if you increase the value of parameter the performance may increase. For example, if we have a very high value of depth of tree, the resulting tree may overfit the data, and would not generalize well. On the other hand, if we have a very low value, the tree may underfit the data. So, we can\u2019t say for sure that \u201chigher is better\u201d.", "I hope you enjoyed taking the test and you found the solutions helpful. The test focused on\u00a0conceptual knowledge of tree based algorithms.", "We tried to clear all your doubts through this article but if we have missed out on something then let me know in comments below. If you have any suggestions or improvements you think we should make in the next skilltest, let us know in the comments below.", "Don\u2019t forget to register for Skilltest Regression coming up on 17 Dec\u201916. You will be tested on regression and its various forms. All the Best!", "Faizan is a Data Science enthusiast and a Deep learning rookie. A recent Comp. Sc. undergrad, he aims to utilize his skills to push the boundaries of AI research.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F12%2Fdetailed-solutions-for-skilltest-tree-based-algorithms%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=45 questions to test Data Scientists on Tree Based Algorithms (Decision tree, Random Forests, XGBoost)&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F12%2Fdetailed-solutions-for-skilltest-tree-based-algorithms%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F12%2Fdetailed-solutions-for-skilltest-tree-based-algorithms%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/jalfaizy/", "anchor_text": "JalFaizy Shaikh"}, {"url": "https://www.analyticsvidhya.com/blog/category/advanced/", "anchor_text": "Advanced"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questions/", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/skilltest/", "anchor_text": "Skilltest"}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/lb", "anchor_text": "leaderboard"}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/", "anchor_text": ""}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/lb", "anchor_text": ""}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-tree-based-algorithms/lb", "anchor_text": "here"}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-regression/", "anchor_text": "Skill test \u2013 Regression"}, {"url": "https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/", "anchor_text": "A Complete Tutorial on Tree Based Modeling from Scratch (in R & Python)"}, {"url": "https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/", "anchor_text": "Introduction to Random forest \u2013 Simplified"}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/", "anchor_text": "Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/12/Capture89.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q7_Image.jpg", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q8_Image.jpg", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q9_Image.jpg", "anchor_text": ""}, {"url": "https://en.wikipedia.org/wiki/Decision_tree_learning", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q16_Image.jpg", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q18_Image.jpg", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/12/Capture78.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/11/Q25_Image.jpg", "anchor_text": ""}, {"url": "https://ai.vub.ac.be/sites/default/files/ch3.pdf", "anchor_text": "this presentation."}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/", "anchor_text": "this article."}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/", "anchor_text": "article."}, {"url": "https://datahack.analyticsvidhya.com/contest/skilltest-regression/", "anchor_text": "Skilltest Regression"}, {"url": "http://datahack.analyticsvidhya.com/contest/all", "anchor_text": "Live Competitions"}, {"url": "https://www.analyticsvidhya.com/blog/tag/decision-tree/", "anchor_text": "decision tree"}, {"url": "https://www.analyticsvidhya.com/blog/tag/gradient-boosting/", "anchor_text": "Gradient Boosting"}, {"url": "https://www.analyticsvidhya.com/blog/tag/machine-learning/", "anchor_text": "machine learning"}, {"url": "https://www.analyticsvidhya.com/blog/tag/random-forest/", "anchor_text": "random forest"}, {"url": "https://www.analyticsvidhya.com/blog/tag/skilltest-solution/", "anchor_text": "skilltest solution"}, {"url": "https://www.analyticsvidhya.com/blog/tag/skilltest-tree-based-algorithms/", "anchor_text": "skilltest tree based algorithms"}, {"url": "https://www.analyticsvidhya.com/blog/tag/solution-of-skilltest/", "anchor_text": "solution of skilltest"}, {"url": "https://www.analyticsvidhya.com/blog/tag/tree-algorithms/", "anchor_text": "tree algorithms"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-tree-based-models/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "30 Questions to Test a Data Scientist on Tree Based Models"}, {"url": "https://www.analyticsvidhya.com/blog/2021/04/distinguish-between-tree-based-machine-learning-algorithms/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "Distinguish between Tree-Based Machine Learning Algorithms"}, {"url": "https://www.analyticsvidhya.com/blog/2021/04/best-boosting-algorithm-in-machine-learning-in-2021/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "Best Boosting Algorithm In Machine Learning In 2021"}, {"url": "https://www.analyticsvidhya.com/blog/2023/02/top-10-must-read-interview-questions-on-decision-trees/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "Top 10 Must Read Interview Questions on Decision Trees"}, {"url": "https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "Commonly used Machine Learning Algorithms (with Python and R Codes)"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/automated-machine-learning-for-supervised-learning-part-1/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/", "anchor_text": "Automated Machine Learning for Supervised Learning (Part 1)"}, {"url": "https://www.analyticsvidhya.com/blog/author/jalfaizy/", "anchor_text": "JalFaizy Shaikh"}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/rahul105/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/sion/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/chirag676/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/barney6/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/arnab1408/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/prateekmaj21/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/shanthababu/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/12/deep-learning-session-with-microsoft-at-sp-jain-global-school-of-management-mumbai-5-dec-2016/", "anchor_text": "Deep Learning Session with Microsoft at SP Jain School of High Technology, Mumbai, 5 Dec 2016"}, {"url": "https://www.analyticsvidhya.com/blog/2016/12/webinar-why-or-why-not-become-a-data-scientist-speaker-kunal-jain-7-dec-2016/", "anchor_text": "Webinar \u2013 Why (or why not) become a Data Scientist, Speaker Kunal Jain, 7 Dec 2016"}, {"url": "https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}