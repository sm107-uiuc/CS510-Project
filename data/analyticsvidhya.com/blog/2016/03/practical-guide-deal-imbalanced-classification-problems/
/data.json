{"url": "https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/\n", "time": 1683020902.4854348, "path": "analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/\n/", "webpage": {"metadata": {"title": "Imbalanced Classification Problems in R", "h1": "Practical Guide to deal with Imbalanced Classification Problems in R", "description": "A practical guide to deal with imbalanced classification problems in R. It includes sampling techniques, synthetic techniques etc."}, "outgoing_paragraph_urls": [{"url": "https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/", "anchor_text": "machine learning algorithms", "paragraph_index": 0}], "all_paragraphs": ["We have several machine learning algorithms at our disposal for model building. Doing data based prediction is now easier like never before. Whether it is a regression or classification problem, one can effortlessly achieve a reasonably high accuracy using\u00a0a suitable algorithm. But, this is not the case everytime.\u00a0Classification problems can sometimes get a bit tricky.", "ML algorithms tend to tremble when faced with imbalanced classification data sets. Moreover, they result in biased predictions and misleading accuracies. But, why does it happen ? What factors deteriorate their performance ?", "The answer is simple. With\u00a0imbalanced data sets, an algorithm doesn\u2019t get the necessary information about the minority class to make an accurate\u00a0prediction. Hence, it is desirable to use ML algorithms with balanced data sets. Then, how should we deal with imbalanced data sets ? The methods are simple but tricky as described in this article.", "In this article, I\u2019ve shared the important things\u00a0you need to know to tackle imbalanced classification problems. In particular, I\u2019ve kept my focus on imbalance in binary classification problems. As usual, I\u2019ve kept the explanation simple and informative. Towards the end, I\u2019ve provided a practical view of dealing with such data sets in R with\u00a0ROSE package.", "Imbalanced classification is a supervised learning problem where one class outnumbers other class by a large proportion.\u00a0This problem is faced more\u00a0frequently in binary classification problems than multi-level classification problems.", "The term imbalanced refer to the disparity encountered in the dependent (response) variable. Therefore, an imbalanced classification problem is one in which the dependent variable has imbalanced proportion of classes. In other words, a data set that exhibits an unequal distribution between its classes is considered to be imbalanced.", "For example: Consider a data set with 100,000 observations. This data set consist of candidates who applied for Internship in Harvard. Apparently, harvard is well-known for its extremely low acceptance rate. The dependent variable represents if a candidate has been shortlisted (1) or not shortlisted (0). After analyzing the data, it was found ~ 98% did not get\u00a0shortlisted and only ~ 2% got lucky. This is a perfect case of imbalanced classification.", "In real life, does such situations arise more ? Yes! For better understanding, here are some real life examples. Please note that the degree of imbalance varies per situations:", "There are many more real life situations which result in imbalanced data set. Now you see, the chances of obtaining an imbalanced data is quite high. Hence, it\u2019s important to learn to deal with such problems for every analyst.", "This is an interesting experiment to do. Try it! This way you will\u00a0understand the importance of learning the ways to restructure imbalanced data. I\u2019ve shown this in the practical section below.", "Below are the reasons which leads to reduction in accuracy of ML algorithms on imbalanced data sets:", "The methods are widely known as \u2018Sampling Methods\u2019. Generally, these methods aim to modify an imbalanced data into balanced distribution using some mechanism. The modification occurs by altering the size of original data set and provide the same proportion of balance.", "These methods have acquired higher importance after many researches have proved that balanced data results in improved overall classification\u00a0performance\u00a0compared to an imbalanced data set. Hence, it\u2019s important to learn them.", "Below are\u00a0the methods used to treat imbalanced datasets:", "Let\u2019s understand them one by one.", "This method works with majority class. It reduces the number of observations from majority class to make the data set balanced. This method is best to use when the data set is huge and reducing the number of training samples helps to improve run time and storage troubles.", "Undersampling methods are of 2 types: Random and Informative.", "Random undersampling method randomly chooses observations from majority class\u00a0which are\u00a0eliminated until the data set gets balanced. Informative undersampling follows a pre-specified selection criterion to remove the observations from majority class.", "Within informative undersampling, EasyEnsemble and BalanceCascade algorithms are known to produce good results. These algorithms are easy to understand and straightforward too.", "EasyEnsemble: At first, it extracts several subsets of independent sample (with replacement)\u00a0from majority class. Then, it develops multiple classifiers based on combination of each subset with minority class. As you see, it works just like a unsupervised learning algorithm.", "BalanceCascade: It takes a supervised learning approach where it develops an ensemble of classifier and systematically selects which majority class to ensemble.", "Do you see any problem with undersampling methods?\u00a0Apparently, removing observations may cause the training data to lose important information pertaining to majority class.", "This method works with minority class. It replicates the observations from minority class to balance the data. It is also known as upsampling. Similar to undersampling, this method also can be divided into two types: Random Oversampling and Informative Oversampling.", "Random oversampling balances the data by randomly oversampling the minority class. Informative oversampling uses a pre-specified criterion and synthetically generates minority class observations.", "An advantage of using this method is that it leads to no information loss. The disadvantage of using this method is that, since oversampling simply adds replicated observations in original data set, it ends up adding multiple observations of several types, thus leading to overfitting. Although, the training accuracy of such data set will be high, but the accuracy on unseen data will be worse.", "In simple words, instead of replicating and adding the observations from the minority class, it overcome imbalances by generates artificial\u00a0data.\u00a0It is also a type of oversampling technique.", "In regards to synthetic data generation, synthetic minority oversampling technique (SMOTE) is a powerful and widely used method. SMOTE algorithm creates artificial data based on feature space (rather than data space) similarities from minority samples. We can also say, it generates a random set of minority class observations to shift the classifier learning bias towards minority class.", "To generate artificial data, it uses bootstrapping and k-nearest neighbors.\u00a0Precisely, it works this way:", "R has a very well defined package which incorporates this techniques. We\u2019ll look at it in practical section below.", "It is another commonly used method to handle classification problems with imbalanced data. It\u2019s an interesting method. In simple words, this method evaluates the cost associated with misclassifying observations.", "It does not create balanced data distribution. Instead, it highlights the imbalanced learning problem by using cost matrices which describes the cost for misclassification in a particular scenario. Recent researches have shown that cost sensitive learning have many a times outperformed sampling methods. Therefore, this method provides likely alternative to sampling methods.", "Let\u2019s understand it using an interesting example: A data set of passengers in given. We are interested to know\u00a0if a person has bomb. The data set contains all the necessary information. A person carrying bomb is labeled\u00a0as positive class. And, a person not carrying a bomb in labeled\u00a0as negative class. The problem is to identify which class a person belongs to. Now, understand the cost matrix.", "There in no cost associated with identifying a person with bomb as positive and a person without negative. Right ? But, the cost associated with identifying a person with bomb as negative (False Negative) is much more dangerous than identifying a person without bomb as positive (False Positive).", "Cost Matrix is similar\u00a0of confusion matrix. It\u2019s just, we are here more concerned about false positives and false negatives (shown below). There is no cost penalty associated with True Positive and True Negatives as they are\u00a0correctly identified.", "The goal of this method is to choose a classifier with lowest total cost.", "There are other advanced methods as well for balancing imbalanced data sets. These are Cluster based sampling, adaptive synthetic sampling, border line SMOTE, SMOTEboost, DataBoost \u2013 IM, kernel based methods and many more. The basic working on these algorithm is almost similar as explained above. There are more intuitive methods which you can try for improved predictions:", "Choosing a performance metric is a critical aspect of working with imbalanced data. Most classification algorithms calculate accuracy based on the percentage of observations correctly classified. With imbalanced data, the results are high deceiving since minority classes hold minimum\u00a0effect on overall accuracy.", "The difference between confusion matrix and cost matrix is that, cost matrix provides information only about the misclassification cost, whereas confusion matrix describes the entire set of possibilities using TP, TN, FP, FN. In a cost matrix, the diagonal elements are zero. The most frequently used metrics are Accuracy & Error Rate.", "As mentioned above, these metrics may provide deceiving results and are highly sensitive to changes in data. Further, various metrics can be derived from confusion matrix. The\u00a0resulting\u00a0metrics provide\u00a0a better\u00a0measure to calculate accuracy while working on a imbalanced data set:", "Precision: It is a measure of correctness achieved in positive prediction i.e. of observations labeled as positive, how many are actually labeled positive.", "Recall: It is a measure of actual observations which are labeled (predicted) correctly\u00a0i.e. how many observations of positive class are labeled correctly. It is also known as \u2018Sensitivity\u2019.", "F measure: It combines precision and recall as a measure of effectiveness of classification in terms of ratio of weighted importance on either recall or precision as determined by\u00a0\u03b2 coefficient.", "\u03b2 is usually taken as 1.", "Though, these methods are better than accuracy and error metric, but still ineffective in answering the important questions on classification. For example: precision does not tell us about negative prediction accuracy. Recall is more interesting in knowing actual positives. This suggest, we can still have a better metric to cater to our accuracy needs.", "Fortunately, we have a ROC (Receiver Operating Characteristics) curve to measure the accuracy of a classification prediction. It\u2019s the most widely used evaluation metric. ROC Curve is formed by plotting TP rate (Sensitivity) and\u00a0FP rate (Specificity).", "Any point on ROC graph, corresponds to the performance of a single classifier on a given distribution. It is useful because if provides a visual representation of benefits (TP) and costs (FP) of a classification data. The larger the area under ROC curve, higher will be the accuracy.", "There may be situations when ROC fails to deliver trustworthy performance. It has few shortcomings such as.", "As alternative methods, we can use other visual representation metrics include PR\u00a0curve, cost curves as well. Specifically, cost curves are known to possess the ability to describe\u00a0a classifier\u2019s performance over varying misclassification costs and class distributions in a visual format. In more than 90% instances, ROC curve is known to perform quite well.", "Till here, we\u2019ve learnt about some essential theoretical aspects of\u00a0imbalanced classification. It\u2019s time to learn to implement these techniques practically. \u00a0In R, packages such as ROSE and DMwR helps us to perform sampling strategies quickly. We\u2019ll work on a problem of binary classification.", "ROSE (Random Over Sampling Examples) package helps us to\u00a0generate\u00a0artificial data based on sampling methods and smoothed bootstrap approach. This package has well defined accuracy functions to do the tasks quickly.", "The package ROSE comes with an inbuilt imbalanced data set named as hacide. It comprises of two files: hacide.train and hacide.test. Let\u2019s load it in R environment:", "As you can see, the data set contains 3 variable of 1000 observations. cls is the response variable. x1 and x2 are dependent variables. Let\u2019s check the severity of imbalance in this data set:", "As we see, this data set contains only 2% of positive cases and 98% of negative cases. This is a severely imbalanced data set. So, how badly can this affect our prediction accuracy ? Let\u2019s build a model on this data. I\u2019ll be using decision tree algorithm for modeling purpose.", "Let\u2019s check the accuracy of this prediction. To check accuracy, ROSE package has a function names accuracy.meas, it computes important metrics such as precision, recall & F measure.", "> accuracy.meas(hacide.test$cls, pred.treeimb[,2])\n\u00a0 \u00a0Call: \n\u00a0 \u00a0accuracy.meas(response = hacide.test$cls, predicted = pred.treeimb[, 2])\n\u00a0 \u00a0Examples are labelled as positive when predicted is greater than 0.5\u00a0", "These metrics provide an interesting interpretation. With threshold value as 0.5,\u00a0Precision = 1 says there are no false positives. Recall = 0.20 is very much low and indicates that we have higher number of false negatives. Threshold values can be altered also. F = 0.167 is also low and suggests weak accuracy of this model.", "We\u2019ll check the final accuracy of this model using ROC curve. This will give us a clear picture, if this model is worth. Using the function roc.curve available in this package:", "AUC = 0.60 is a terribly low score. Therefore, it is necessary to balanced data before applying a machine learning algorithm. In this case, the algorithm gets biased toward the majority class and fails to map minority class.", "We\u2019ll use the sampling techniques and try to improve this prediction accuracy.\u00a0This package provides a function named\u00a0ovun.sample which enables oversampling, undersampling in one go.", "Let\u2019s start with oversampling and balance the data.", "In the code above, method over instructs the algorithm to perform over sampling. N refers to number of observations in the resulting balanced set. In this case, originally we had 980 negative observations. So, I instructed this line of code to over sample minority class until it reaches 980 and the total data set comprises of 1960 samples.", "Similarly, we can perform undersampling as well. Remember, undersampling is done without replacement.", "Now the data set is balanced. But, you see that we\u2019ve lost significant information from the sample. Let\u2019s do both undersampling and oversampling on this imbalanced data. This can be achieved using method = \u201cboth\u201c. In this case, the minority class is oversampled with replacement and majority class is undersampled without replacement.", "p refers to the probability of positive class in newly generated sample.", "The data generated from oversampling have expected amount of repeated observations. Data generated from undersampling is deprived of important information from the original data. This leads to inaccuracies in the resulting performance. To encounter these issues, ROSE helps us to generate data synthetically as well. The data generated using ROSE is considered to provide better estimate of original data.", "This generated data has size equal to the original data set (1000 observations). Now, we\u2019ve balanced\u00a0data sets using 4 techniques. Let\u2019s compute the model using each data and evaluate its accuracy.", "#make predictions on unseen data\n> pred.tree.rose <- predict(tree.rose, newdata = hacide.test)\n> pred.tree.over <- predict(tree.over, newdata = hacide.test)\n> pred.tree.under <- predict(tree.under, newdata = hacide.test)\n> pred.tree.both <- predict(tree.both, newdata = hacide.test)", "It\u2019s time to evaluate the accuracy of respective predictions. Using inbuilt function roc.curve allows us to capture roc metric.", "Here is the resultant ROC curve where:", "Hence, we get the highest accuracy from data obtained using ROSE algorithm. We see that the data generated using synthetic methods result in high accuracy as compared to sampling methods. This technique combined with a more robust algorithm (random forest, boosting) can lead to exceptionally high accuracy.", "This package also provide us methods to check the model accuracy using holdout and bagging method.\u00a0This helps us to ensure that our resultant predictions doesn\u2019t suffer from high variance.", "We see that our accuracy retains at ~ 0.98 and shows that our predictions aren\u2019t suffering from high variance. Similarly, you can use bootstrapping by setting method.assess to \u201cBOOT\u201d. The parameter extr.pred is a function which extracts the column of probabilities belonging to positive class.", "When faced with imbalanced data set, one might need to experiment with these methods to get the best suited sampling technique. In our case, we found that synthetic sampling technique outperformed the traditional oversampling and undersampling method. For better results, you can use advanced sampling methods which includes synthetic sampling with boosting methods.", "In this article, I\u2019ve discussed the important things one should know to deal with imbalanced data sets. For R users, dealing with such situations isn\u2019t difficult since we are blessed with some powerful and awesome packages.", "Did you find this article helpful ? Have you used these methods before? Do share your experience / suggestions in the comments section below.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F03%2Fpractical-guide-deal-imbalanced-classification-problems%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=Practical Guide to deal with Imbalanced Classification Problems in R&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F03%2Fpractical-guide-deal-imbalanced-classification-problems%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F03%2Fpractical-guide-deal-imbalanced-classification-problems%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/avcontentteam/", "anchor_text": "avcontentteam"}, {"url": "https://www.analyticsvidhya.com/blog/category/classification/", "anchor_text": "Classification"}, {"url": "https://www.analyticsvidhya.com/blog/category/intermediate/", "anchor_text": "Intermediate"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/project/", "anchor_text": "Project"}, {"url": "https://www.analyticsvidhya.com/blog/category/r/", "anchor_text": "R"}, {"url": "https://www.analyticsvidhya.com/blog/category/structured-data/", "anchor_text": "Structured Data"}, {"url": "https://www.analyticsvidhya.com/blog/category/supervised/", "anchor_text": "Supervised"}, {"url": "https://www.analyticsvidhya.com/blog/category/technique/", "anchor_text": "Technique"}, {"url": "https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/", "anchor_text": "machine learning algorithms"}, {"url": "http://datahack.analyticsvidhya.com/contest/all", "anchor_text": "Live Competitions"}, {"url": "https://www.analyticsvidhya.com/blog/tag/auc/", "anchor_text": "AUC"}, {"url": "https://www.analyticsvidhya.com/blog/tag/balancecascade/", "anchor_text": "balancecascade"}, {"url": "https://www.analyticsvidhya.com/blog/tag/confusion-matrix/", "anchor_text": "confusion matrix"}, {"url": "https://www.analyticsvidhya.com/blog/tag/cost-curves/", "anchor_text": "cost curves"}, {"url": "https://www.analyticsvidhya.com/blog/tag/cost-matrix/", "anchor_text": "cost matrix"}, {"url": "https://www.analyticsvidhya.com/blog/tag/cost-sensitive-learning/", "anchor_text": "cost sensitive learning"}, {"url": "https://www.analyticsvidhya.com/blog/tag/decision-tree/", "anchor_text": "decision tree"}, {"url": "https://www.analyticsvidhya.com/blog/tag/easyensemble/", "anchor_text": "easyensemble"}, {"url": "https://www.analyticsvidhya.com/blog/tag/informative-oversampling/", "anchor_text": "informative oversampling"}, {"url": "https://www.analyticsvidhya.com/blog/tag/oversampling/", "anchor_text": "oversampling"}, {"url": "https://www.analyticsvidhya.com/blog/tag/pr-curves/", "anchor_text": "PR curves"}, {"url": "https://www.analyticsvidhya.com/blog/tag/precision/", "anchor_text": "precision"}, {"url": "https://www.analyticsvidhya.com/blog/tag/random-oversampling/", "anchor_text": "random oversampling"}, {"url": "https://www.analyticsvidhya.com/blog/tag/recall/", "anchor_text": "recall"}, {"url": "https://www.analyticsvidhya.com/blog/tag/smote/", "anchor_text": "SMOTE"}, {"url": "https://www.analyticsvidhya.com/blog/tag/synthetic-samping/", "anchor_text": "synthetic samping"}, {"url": "https://www.analyticsvidhya.com/blog/tag/undersampling/", "anchor_text": "undersampling"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "Overcoming Class Imbalance using SMOTE Techniques"}, {"url": "https://www.analyticsvidhya.com/blog/2022/06/is-adult-income-dataset-imbalanced/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "Is Adult Income Dataset Imbalanced?"}, {"url": "https://www.analyticsvidhya.com/blog/2022/05/handling-imbalanced-data-with-imbalance-learn-in-python/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "Handling Imbalanced Data with Imbalance-Learn in Python"}, {"url": "https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "10 Techniques to Solve Imbalanced Classes in Machine Learning (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/2023/01/practicing-machine-learning-with-imbalanced-dataset/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "Practicing Machine Learning with Imbalanced Dataset"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/5-techniques-to-handle-imbalanced-data-for-a-classification-problem/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/", "anchor_text": "5 Techniques to Handle Imbalanced Data For a Classification Problem"}, {"url": "https://www.analyticsvidhya.com/blog/author/avcontentteam/", "anchor_text": "avcontentteam"}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/rahul105/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/sion/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/chirag676/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/barney6/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/arnab1408/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/prateekmaj21/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/shanthababu/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/exploring-building-banks-recommendation-system/", "anchor_text": "Exploring Recommendation System (with an implementation model in R)"}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/13-machine-learning-data-science-startups-combinator-winter-2016/", "anchor_text": "13 Machine Learning & Data Science Startups from Y Combinator Winter 2016"}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}