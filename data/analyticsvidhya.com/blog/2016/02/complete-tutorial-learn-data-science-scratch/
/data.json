{"url": "https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/\n", "time": 1683020933.1401222, "path": "analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/\n/", "webpage": {"metadata": {"title": "R Programming For Data Science | Learn R for Data Science", "h1": "A Complete Tutorial to learn Data Science in R from Scratch", "description": "Introduction to R programming for data science. A Complete tutorial to learn r for data science that covers machine learning algorithms in data science."}, "outgoing_paragraph_urls": [{"url": "http://discuss.analyticsvidhya.com/t/how-to-run-r-on-jupyter-ipython-notebooks/5512", "anchor_text": "Jupyter Notebooks", "paragraph_index": 0}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii", "anchor_text": "Big Mart Sales Prediction", "paragraph_index": 6}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/", "anchor_text": "Complete Python Tutorial from Scratch", "paragraph_index": 8}, {"url": "http://ftp.heanet.ie/mirrors/cran.r-project.org/", "anchor_text": "old version", "paragraph_index": 9}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/", "anchor_text": "here", "paragraph_index": 42}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/8-ways-deal-continuous-variables-predictive-modeling/", "anchor_text": "here", "paragraph_index": 42}, {"url": "https://www.analyticsvidhya.com/blog/2015/02/7-steps-data-exploration-preparation-building-model-part-2/", "anchor_text": "here", "paragraph_index": 43}, {"url": "https://cran.r-project.org/", "anchor_text": "CRAN", "paragraph_index": 58}, {"url": "https://www.analyticsvidhya.com/blog/2015/12/faster-data-manipulation-7-packages/", "anchor_text": "complete tutorial", "paragraph_index": 61}, {"url": "https://www.analyticsvidhya.com/blog/2015/08/list-r-packages-data-analysis/", "anchor_text": "infographic", "paragraph_index": 63}, {"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/", "anchor_text": "Big Mart Sales Prediction", "paragraph_index": 68}, {"url": "https://www.analyticsvidhya.com/blog/2015/07/guide-data-visualization-r/", "anchor_text": "tutorial", "paragraph_index": 92}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/", "anchor_text": "tutorial", "paragraph_index": 94}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/", "anchor_text": "RMSE", "paragraph_index": 97}, {"url": "https://rpubs.com/bradleyboehmke/data_wrangling", "anchor_text": "tutorial", "paragraph_index": 106}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-bigmart-sales-prediction", "anchor_text": "here", "paragraph_index": 108}, {"url": "https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/", "anchor_text": "here", "paragraph_index": 124}, {"url": "https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/", "anchor_text": "Part 1", "paragraph_index": 144}, {"url": "https://www.analyticsvidhya.com/blog/2015/01/decision-tree-algorithms-simplified/", "anchor_text": "Part 2", "paragraph_index": 144}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/", "anchor_text": "Cross Validation", "paragraph_index": 145}, {"url": "https://www.analyticsvidhya.com/blog/2015/09/random-forest-algorithm-multiple-challenges/", "anchor_text": "tutorial", "paragraph_index": 151}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/lb", "anchor_text": "Leaderboard", "paragraph_index": 161}, {"url": "http://discuss.analyticsvidhya.com/t/download-free-tutorial-to-learn-data-science-in-r-from-scratch/7797/2", "anchor_text": "Download Here", "paragraph_index": 166}], "all_paragraphs": ["R is a powerful language used widely for data analysis and statistical computing. It was developed in early 90s. Since then, endless efforts have been made to improve R\u2019s user interface. The journey of R language from a rudimentary text editor to interactive\u00a0R Studio and more recently\u00a0Jupyter Notebooks has engaged many data science communities across the world.", "This was possible only because of generous contributions by R users globally. Inclusion of powerful packages in R has made it more and more powerful with time. Packages such as dplyr, tidyr, readr, data.table, SparkR, ggplot2 have made data manipulation, visualization and computation much faster.", "My first impression of R was that it\u2019s just a software for statistical computing. Good thing, I was wrong! R has enough provisions to implement machine learning algorithms in a fast and simple\u00a0manner.", "This\u00a0is a complete tutorial to learn data science and machine learning using R.\u00a0By the end of this tutorial, you will have a good exposure to building predictive models using machine learning on your own.", "Note: No prior knowledge of data science / analytics is required. However, prior knowledge of algebra and statistics will be helpful.", "A Complete Tutorial to learn Data Science in R from Scratch", "Note: The data set used in this article is from Big Mart Sales Prediction.", "I don\u2019t know if I have a solid reason to convince you, but let me share what got me started. I have no prior coding experience. Actually, I never had computer science in\u00a0my subjects. I came to\u00a0know that to learn data science, one\u00a0must learn either R or Python as a starter. I chose the former. Here are some benefits I found after using R:", "There are many more benefits. But, these are the ones which have kept me going. If you think they are exciting, stick around and move to next section. And, if you aren\u2019t convinced, you may like Complete Python Tutorial from Scratch.", "You could download and install the old version of R. But, I\u2019d insist you to start with RStudio. It provides much better coding experience. For Windows users, R Studio is available for Windows Vista and above versions. Follow the steps below for installing R Studio:", "Let\u2019s quickly understand the interface of R Studio:", "The sheer power of R lies in its incredible packages. In R, most data handling tasks can be performed in 2 ways: Using R packages and R base functions. In this tutorial, I\u2019ll also introduce you with the\u00a0most handy\u00a0and powerful R packages. To install a package, simply type:", "As a first time user, a pop might\u00a0appear to select your CRAN mirror (country server), choose accordingly and press OK.", "Note: You can type this either in console directly and press \u2018Enter\u2019 or in R script and click \u2018Run\u2019.", "Let\u2019s begin with basics. To get familiar with R coding environment, start with some basic calculations. R console can be used as an interactive calculator too. Type the following in your console:", "Similarly, you can experiment various combinations of calculations and get the results. In case, you want to obtain the previous calculation, this can be done in two ways. First, click in R console, and press \u2018Up / Down Arrow\u2019 \u00a0key on your keyboard. This will activate the previously executed commands. Press Enter.", "But, what if you have done too many calculations ? It would be too painful to scroll through every command and find it out. In such situations, creating variable is a helpful way.", "In R, you can create a variable using <- or = sign. Let\u2019s say I want to create a variable x to compute the sum of 7 and 8. I\u2019ll write it as:", "Once we create a variable, you no longer get the output directly (like calculator), unless you call the variable in the next line. Remember, variables can be alphabets, alphanumeric but not numeric. You can\u2019t create numeric variables.", "Understand and practice this section thoroughly. This is the building block of your R programming knowledge. If you get this right, you would face less trouble in debugging.", "R has five basic or \u2018atomic\u2019 classes of objects. Wait, what is an object ?", "Everything you see or create in R is an object. A vector, matrix, data frame, even a variable is an object. R treats it that way. So, R has 5 basic classes\u00a0of objects. This includes:", "Since these classes are self-explanatory by names, I wouldn\u2019t elaborate on that. These classes have attributes. Think of attributes as their \u2018identifier\u2019, a name or number which aptly identifies them. An object can have following attributes:", "Attributes of an object can be accessed using attributes() function. More on this coming in following section.", "Let\u2019s understand the concept of object and attributes practically. The most basic object in R is known as vector. You can create an empty vector using vector(). Remember, a vector contains object of same class.", "For example: Let\u2019s create vectors of different classes. We can create vector using c()\u00a0or concatenate command also.", "Similarly, you can create vector of various classes.", "R has various type of \u2018data types\u2019 which\u00a0includes vector (numeric, integer etc), matrices, data frames and list. Let\u2019s understand them one by one.", "Vector: As mentioned above, a vector contains object of same class. But, you can mix objects of different classes too.\u00a0When objects of different classes are mixed in a list, coercion occurs. This effect causes the objects of different types to \u2018convert\u2019 into one class. For example:", "To check the class of any object, use class(\u201cvector name\u201d) function.", "To convert the class of a vector, you can use as. command.", "Similarly, you can change the class of any vector. But, you should pay attention here. If you try to convert a \u201ccharacter\u201d vector to \u201cnumeric\u201d , NAs will be introduced. Hence, you should be careful to use this command.", "List: A list is a special type of vector which contain elements of different data types. For example:", "As you can see, the output of a list is different from a vector. This is because, all the objects are of different types. The double bracket [[1]] shows the index of first element and so on. Hence, you can easily extract the element of lists depending on their index. Like this:", "You can use [] single bracket too. But, that would return the list element with its index number, instead of the result above. Like this:", "Matrices: When a vector is introduced with row and column\u00a0i.e. a dimension attribute, it becomes a matrix. A matrix is represented by set of rows and columns. It is a 2 dimensional data structure. It consist of elements of same class. Let\u2019s create a matrix of 3 rows and 2 columns:", "As you can see, the dimensions of a matrix can be obtained using either dim()\u00a0or attributes() command. \u00a0To extract a particular element from a matrix, simply use the index shown above. For example(try this at your end):", "As an interesting fact, you can also create a matrix from a vector. All you need to do is, assign dimension dim() later. Like this:", "You can also join two vectors using cbind() and rbind() functions. But, make sure that both vectors have same number of elements. If not, it will return NA values.", "Data Frame: This is the most commonly used\u00a0member of data types family. It is used to store tabular data. It is different from matrix. In a matrix, every element must have same class. But, in a data frame, you can put list of vectors containing different classes. This means, every column of a data frame acts like a list. Every time you will read\u00a0data in R, it will be stored in the form of a data frame. Hence, it is important to understand the majorly used commands on data frame:", "Let\u2019s understand the code above. df is the name of data frame. dim() returns the dimension of data frame as 4 rows and 2 columns. str() returns the structure of a data frame i.e. the list of variables stored in the data frame. nrow() and ncol() return the number of rows and number of columns in a data set respectively.", "Here you see \u201cname\u201d is a factor variable and \u201cscore\u201d is numeric.\u00a0In data science, a variable can be categorized into two types: Continuous and Categorical.", "Continuous variables are those which can take any form such as 1, 2, 3.5, 4.66 etc. Categorical variables are those which takes only discrete values such as 2, 5, 11, 15 etc. In R, categorical values are represented by factors. In df, name is a factor variable having 4 unique levels. Factor or categorical variable are specially treated in a data set. For more explanation,\u00a0click\u00a0here. Similarly, you can find techniques to deal with\u00a0continuous variables here.", "Let\u2019s now understand the concept of missing values in R. This is one of the most painful yet crucial part of predictive modeling. You must be aware of all techniques to deal with them. The\u00a0complete explanation on\u00a0such techniques is provided here.", "Missing values in R are represented by NA and NaN. Now we\u2019ll check if a data set has missing values (using the same data frame df).", "> df[1:2,2] <- NA #injecting NA at 1st, 2nd row and 2nd column of df\u00a0\n> df\nname score\n1 ash NA\n2 jane NA\n3 paul 87\n4 mark 91\n\n> is.na(df) #checks the entire data set for NAs and return logical output\nname score\n[1,] FALSE TRUE\n[2,] FALSE TRUE\n[3,] FALSE FALSE\n[4,] FALSE FALSE\n> table(is.na(df)) #returns a table of logical output\nFALSE TRUE \n6 \u00a0 \u00a0 \u00a02", "> df[!complete.cases(df),] #returns the list of rows having missing values\nname \u00a0score\n1 ash \u00a0NA\n2 jane NA", "Missing values hinder normal calculations in a data set. For example, let\u2019s say, we want to compute the mean of score. Since there are two missing values, it can\u2019t be done directly. Let\u2019s see:", "The use of na.rm = TRUE\u00a0parameter tells R to ignore the NAs and compute the mean of remaining values in the selected column (score). To remove rows with NA values in a data frame, you can use na.omit:", "As the name suggest, a control structure \u2018controls\u2019 the flow of code / commands written inside a function. A function is a set of multiple commands written to automate a repetitive coding task.", "For example: You have 10 data sets. You want to find the mean of \u2018Age\u2019 column present in every data set. This can be done in 2 ways: either you write the code to compute mean 10 times or you simply create a function and pass the data set to it.", "Let\u2019s understand\u00a0the control structures in R with simple\u00a0examples:", "if, else \u2013 This structure is used to test a condition. Below is the syntax:", "for \u2013 This structure is used when a loop is to be executed fixed number of times. It is commonly used for iterating over the elements of an object (list, vector). Below is the syntax:", "while \u2013 It begins by testing a condition, and executes only if the condition\u00a0is found to be true. Once the loop is executed, the condition is tested again. Hence, it\u2019s necessary to alter the condition such that the loop doesn\u2019t go infinity. Below is the syntax:", "#initialize a condition\nAge <- 12", "There are other control structures as well but are less frequently used than explained above. Those structures are:", "Note: If you find the section \u2018control structures\u2019 difficult to understand, not to worry. R is supported by various packages to compliment the work done by control structures.", "Out of ~7800 packages listed on CRAN, I\u2019ve listed some of the most powerful and commonly used packages in predictive modeling in this article. Since, I\u2019ve already explained the method of installing packages, you can go ahead and install them now. Sooner or later you\u2019ll need them.", "Importing Data:\u00a0R offers wide range of packages for importing data available in any format such as .txt, .csv, .json, .sql etc. To import large files of data quickly, it is advisable to install and use data.table, readr, RMySQL, sqldf, jsonlite.", "Data Visualization: R has in built plotting commands as well. They are good to create simple graphs. But, becomes complex when it comes to creating advanced graphics. Hence, you should install ggplot2.", "Data Manipulation: R has a\u00a0fantastic collection of packages for data manipulation. These packages allows you to do basic & advanced computations quickly. These packages are dplyr, plyr, tidyr, lubridate, stringr. Check out this complete tutorial on data manipulation packages in R.", "Modeling / Machine Learning:\u00a0For modeling, caret package in R is powerful enough to cater to every need for creating machine learning model. However, you can install packages algorithms wise such as randomForest, rpart, gbm etc", "Note: I\u2019ve only mentioned the commonly used packages. You might like to check this interesting infographic on complete list of useful R packages.", "Till here, you became\u00a0familiar with the basic work style in R and its associated components. From next section, we\u2019ll begin with predictive modeling. But before you proceed. I want you to practice, what you\u2019ve learnt till here.", "Practice Assignment:\u00a0 As a part of this assignment, install \u2018swirl\u2019 package in package. Then type, library(swirl) to initiate the package.\u00a0\u00a0And, complete this interactive R tutorial. If you have followed this article thoroughly, this assignment should be an easy task for you!", "From this section onwards, we\u2019ll dive deep into various stages of predictive modeling. Hence,\u00a0make sure you understand every aspect of this section. In case you find anything difficult to understand, ask me in the comments section below.", "Data Exploration is a crucial stage of predictive model. You can\u2019t build great and practical models unless you learn to explore the data from begin to end. This stage forms a concrete foundation for data manipulation (the very next stage). Let\u2019s understand it in R.", "In this tutorial, I\u2019ve taken the data set from Big Mart Sales Prediction. Before we start, you must\u00a0get familiar with these terms:", "Response Variable (a.k.a Dependent\u00a0Variable): In a data set, the response variable (y) is one on which we make predictions. In this case, we\u2019ll predict \u2018Item_Outlet_Sales\u2019. (Refer to image shown below)", "Predictor Variable (a.k.a Independent Variable): In a data set, predictor variables (Xi)\u00a0are those using which the prediction is made on response variable. (Image below).", "Train Data: The predictive model is always built on train data set. An intuitive way to identify the train data is, that it always has the \u2018response variable\u2019 included.", "Test Data: Once the model is built, it\u2019s accuracy is \u2018tested\u2019 on test data. This data always contains less number of observations than train data set. Also, it does not include \u2018response variable\u2019.", "Right now, you should download the data set. Take a good look at train and test data. Cross check the information shared above and then proceed.", "Let\u2019s now begin with importing and exploring data.", "#working directory\npath <- \".../Data/BigMartSales\"\n\n#set working directory\nsetwd(path)", "As a beginner, I\u2019ll advise you to keep the train and test files in your working directly to avoid unnecessary directory troubles. Once the directory is set, we can easily\u00a0import the .csv files using commands below.", "In fact, even prior to loading data in R, it\u2019s a good practice to look at the data in Excel. This helps in strategizing \u00a0the complete prediction modeling process. To check if the data set has been loaded successfully, look at R environment. The data can be seen there. Let\u2019s explore the data quickly.", "We have 8523 rows and 12 columns in train data set and 5681 rows and 11 columns in data set. This makes sense. Test data should always have one column less (mentioned above right?). Let\u2019s get deeper in train data set now.", "Let\u2019s do some quick data exploration.", "To begin with, I\u2019ll first check if this data has missing values. This can be done by using:", "In train data set, we have 1463 missing values. Let\u2019s check the variables in which these values are missing. It\u2019s important to find and locate these missing values. Many data scientists have repeatedly advised beginners to pay close attention to missing value in data exploration stages.", "> colSums(is.na(train))\nItem_Identifier Item_Weight \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01463 \nItem_Fat_Content Item_Visibility \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \nItem_Type \u00a0 \u00a0 \u00a0 \u00a0 Item_MRP \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \nOutlet_Identifier Outlet_Establishment_Year \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \nOutlet_Size \u00a0 \u00a0 \u00a0 Outlet_Location_Type \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0 \nOutlet_Type \u00a0 \u00a0 \u00a0 Item_Outlet_Sales \n0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 0", "Hence, we see that column Item_Weight has 1463 missing values. Let\u2019s get\u00a0more inferences from this data.", "Here are some quick inferences drawn from variables in train data set:", "These inference will help us in treating these variable more accurately.", "I\u2019m sure you would understand these variables better when explained visually. Using graphs, we can analyze the data in 2 ways: Univariate Analysis and Bivariate Analysis.", "Univariate analysis is done with one variable. Bivariate analysis is done with two variables. Univariate analysis is a lot easy to do. Hence, I\u2019ll skip that part here. I\u2019d recommend you to try it at your end. Let\u2019s now experiment doing bivariate analysis and carve out hidden insights.", "For visualization, I\u2019ll use ggplot2 package. These graphs would help us understand the distribution and frequency of variables in the data set.", "We can see that majority of sales has been obtained from products having visibility less than 0.2. This suggests that item_visibility < 2 must be an important factor in determining sales. Let\u2019s plot few more interesting graphs and explore such hidden stories.", "Here, we infer that OUT027 has contributed to majority of sales followed by OUT35. OUT10 and OUT19 have probably the least footfall, thereby contributing to the least outlet sales.", "From this graph, we can infer that Fruits and Vegetables contribute to the highest amount of outlet sales followed by snack foods and household products. This information can also be represented using a box plot chart. The benefit of using a box plot is, you get to see the outlier and mean deviation of corresponding levels of a variable (shown below).", "The black point you see, is an outlier. The mid line you see in the box, is the mean value of each item type. To know more about boxplots, check this tutorial.", "Now, we have an idea of the variables and their importance on response variable. Let\u2019s now move back to where we started. Missing values. Now we\u2019ll impute the missing values.", "We saw variable Item_Weight has missing values. Item_Weight is an continuous variable. Hence, in this case we can impute missing values with mean / median of item_weight. These are\u00a0the most commonly used methods of imputing missing value. To explore other methods of this techniques, check out this tutorial.", "Let\u2019s first combine the data sets. This will save our time as we don\u2019t need to write separate codes for train and test data sets. To combine the two data frames, we must make sure that they have equal columns, which is not the case.", "Test data set has one less column (response variable). Let\u2019s first add the column. We can give this column any value. An intuitive approach would be to extract the mean value of sales from train data set and use it as placeholder for test variable Item _Outlet_ Sales. Anyways, let\u2019s make it simple for now. I\u2019ve taken a value 1. Now, we\u2019ll combine the data sets.", "Impute missing value by median. I\u2019m using median because it is known to be highly robust to outliers. Moreover, for this problem, our evaluation metric is RMSE\u00a0which is also highly affected by outliers. Hence, median is better in this case.", "It\u2019s important to learn to deal with continuous and categorical variables separately in a data set. In other words, they need special attention. In this data set, we have only 3 continuous variables and rest are categorical in nature. If you are still confused, I\u2019ll suggest you to once again look at the data set using str() and proceed.", "Let\u2019s take up Item_Visibility. In the graph above, we saw item visibility has\u00a0zero value also, which is practically not feasible. Hence, we\u2019ll consider it as a missing value and once again make the imputation using median.", "Let\u2019s proceed to categorical variables now. During exploration, we saw there are mis-matched levels in variables which needs to be corrected.", "Using the commands above, I\u2019ve assigned the name \u2018Other\u2019 to unnamed level in Outlet_Size variable. Rest, I\u2019ve simply renamed the various levels of Item_Fat_Content.", "Let\u2019s call it as, the advanced level of data exploration. In this section we\u2019ll practically learn about feature engineering and other useful aspects.", "Feature Engineering: This component separates an intelligent data scientist from a technically enabled data scientist. You might have access to large machines to run heavy computations and algorithms, but the power delivered by new features, just can\u2019t be matched. We create new variables to extract and provide as much \u2018new\u2019 information to the model, to help it make accurate predictions.", "If you have been thinking all this time, great. But now is the time to think deeper. Look at the data set and ask yourself, what else (factor) could influence Item_Outlet_Sales ? Anyhow, the answer is below. But, I want you to try it out first, before scrolling down.", "1. Count of Outlet Identifiers \u2013 There are 10 unique outlets in this data. This variable will give us information on count of outlets in the data set. More the number of counts of an outlet, chances are more will be the sales contributed by it.", "As you can see, dplyr package makes data manipulation quite effortless. You no longer need to write long function. In the code above, I\u2019ve simply stored the new data frame in a variable a. Later, the new column Outlet_Count\u00a0is added in our original \u2018combi\u2019 data set. To know more about dplyr, follow this tutorial.", "2. Count of Item Identifiers\u00a0\u2013 Similarly, we can compute count of item identifiers too. It\u2019s a good practice to fetch more information from\u00a0unique\u00a0ID variables using their count.\u00a0This will help us to understand, which outlet has maximum frequency.", "3. Outlet Years \u2013 This variable represent the information of existence of a particular outlet since year 2013. Why just 2013? You\u2019ll find the answer in problem statement here. My hypothesis is, older the outlet, more footfall, large base of loyal customers and larger the outlet sales.", "This suggests that outlets established in 1999 were 14 years old in 2013 and so on.", "4. Item Type New \u2013 Now, pay attention to Item_Identifiers.\u00a0We are about to discover a new trend.\u00a0Look carefully, there is a pattern in the identifiers starting with \u201cFD\u201d,\u201dDR\u201d,\u201dNC\u201d. Now, check the corresponding Item_Types to these identifiers in the data set. You\u2019ll discover, items corresponding to \u201cDR\u201d, \u00a0are mostly eatables. Items corresponding to \u201cFD\u201d, are drinks. And, item corresponding to \u201cNC\u201d, are products which can\u2019t be consumed, let\u2019s call them non-consumable. Let\u2019s extract these variables into a new variable representing their counts.", "Here I\u2019ll use substr(), gsub() function to extract and rename the variables respectively.", "Let\u2019s now add this information in our data set with a variable name \u2018Item_Type_New.", "I\u2019ll leave the rest of feature engineering intuition to you. You can think of more variables which could add more information to the model. But make sure, the variable aren\u2019t correlated. Since, they are emanating from a same set of variable, there is a high chance for them to be correlated. You can check the same in R using cor() function.", "Just, one last aspect of feature engineering left. Label Encoding and One Hot Encoding.", "Label Encoding, in simple words, is the practice of numerically encoding (replacing) different levels of a categorical variables. For example: In our data set, the variable Item_Fat_Content\u00a0has 2 levels: Low Fat and Regular. So, we\u2019ll encode Low Fat as 0 and Regular as 1. This will help us convert a factor variable in numeric variable. This can be simply done using if else statement in R.", "One Hot Encoding, in simple words, is the splitting\u00a0a categorical variable into its unique levels, and\u00a0eventually removing the original variable from data set. Confused ? Here\u2019s an example: Let\u2019s take any categorical variable, say, Outlet_ Location_Type. It has 3 levels. One hot encoding of this variable, will create 3 different variables consisting of 1s and 0s. 1s will represent the existence of variable and 0s will represent non-existence of variable. Let look at a sample:", "model.matrix creates a matrix of encoded variables. \u00a0 ~. -1 tells R, to encode all variables in the data frame, but suppress the intercept. So, what will happen if you don\u2019t write -1 ? model.matrix will skip the first level of the factor, thereby resulting in just 2 out of 3 factor levels (loss of information).", "This was the demonstration of one hot encoding. Hope you have understood the concept now. Let\u2019s now apply this technique to all categorical variables in our data set (excluding ID variable).", "With this, I have shared 2 different methods of performing one hot encoding in R. \u00a0Let\u2019s check if encoding has been done.", "As you can see, after one hot encoding, the original variables are removed automatically from the data set.", "Finally, we\u2019ll drop the columns which have either been converted using other variables or are identifier variables. This can be accomplished using select from dplyr package.", "In this section, I\u2019ll cover Regression, Decision Trees and Random Forest. A detailed explanation of these algorithms is outside the scope of this article. These algorithms have been satisfactorily explained in our previous articles.\u00a0I\u2019ve provided the links for useful resources.", "As you can see, we have encoded all our categorical variables. Now, this data set is good to take\u00a0forward to modeling. Since, we started from Train and Test, let\u2019s now divide the data sets.", "Multiple Regression is used when response variable is continuous in nature and predictors are many. Had it been categorical, we would have used Logistic Regression.\u00a0Before you proceed, sharpen your\u00a0basics of Regression here.", "Let\u2019s now build out first regression model on this data set. R uses lm() function for regression.", "Adjusted R\u00b2 measures the goodness of fit of a regression model. Higher the R\u00b2, better is the model. Our R\u00b2 = 0.2085. It means we really did something drastically wrong.\u00a0\u00a0Let\u2019s figure it out.", "In our case, I could find our new variables aren\u2019t helping much i.e. Item count, Outlet Count and Item_Type_New. Neither of these variables are significant. Significant variables are denoted by \u2018*\u2019 sign.", "As we know, correlated predictor variables brings down the model accuracy. Let\u2019s\u00a0find out the amount of correlation present in our predictor variables. This can be simply calculated using:", "Alternatively, you can also use corrplot package for some fancy correlation plots. Scrolling through the long list of correlation coefficients, I could find a deadly correlation coefficient:", "Outlet_Count is highly correlated (negatively) with Outlet Type Grocery Store. Here are some problems I could find in this model:", "Let\u2019s try to create a more robust regression model. This time, I\u2019ll be using a building a simple model without encoding and new features. Below is the entire code:", "#create a new variable in test file \n> test$Item_Outlet_Sales <- 1", "#combine train and test data\n> combi <- rbind(train, test)", "#drop variables not required in modeling\n> library(dplyr)\n> combi <- select(combi, -c(Item_Identifier, Outlet_Identifier, Outlet_Establishment_Year))", "Now we have got R\u00b2 = 0.5623. This teaches us that, sometimes all you need is simple thought process to get high accuracy. Quite a good improvement from previous model. Next, time when you work on any model, always remember to start with a simple model.", "Let\u2019s check out regression plot to find out more ways to improve this model.", "You can zoom these graphs in R Studio at your end. All these plots have a different story to tell. But the most important story is being portrayed by Residuals vs Fitted graph.", "Residual values are the difference between actual and predicted outcome values. Fitted values are the predicted values. If you see carefully, you\u2019ll discover it as a funnel shape graph (from right to left ). The shape of this graph suggests that our model is suffering from heteroskedasticity (unequal variance in error terms). Had there been constant variance, there would be no pattern visible in this graph.", "A common practice to tackle heteroskedasticity is by taking the log of response variable. Let\u2019s do it and check if we can get further improvement.", "And, here\u2019s a snapshot of my model output. Congrats! We have got an improved model with R\u00b2 = 0.72. Now, we are on the right path. Once again you can check the residual plots (you might zoom it). You\u2019ll find there is no longer a trend in residual vs fitted value plot.", "This model can be further improved by detecting outliers and high leverage points. For now, I leave that part to you! \u00a0I shall write a separate post on mysteries of regression soon. For now, let\u2019s check our RMSE so that we can compare it with other algorithms demonstrated below.", "To calculate RMSE, we can load a package named Metrics.", "Let\u2019s proceed to decision tree algorithm and try to improve our RMSE score.", "Before you start, I\u2019d recommend you to glance through the basics of decision tree algorithms. To understand what makes it superior than linear regression, check this tutorial\u00a0Part 1\u00a0and Part 2.", "In R, decision tree algorithm can be implemented using rpart package.\u00a0In addition, we\u2019ll use caret package for doing cross validation. Cross validation is a technique to build robust models\u00a0which are not prone to\u00a0overfitting. Read more about Cross Validation.", "In R, decision tree uses a complexity parameter (cp). It measures the tradeoff between model complexity and accuracy on training set. A smaller cp will lead to a bigger tree, which might overfit the model. Conversely, a large cp value might underfit the model. Underfitting occurs when\u00a0the model does not capture underlying trends properly. Let\u2019s find out the optimum cp value for our model with 5 fold cross validation.", "#decision tree\n> tree_model <- train(Item_Outlet_Sales ~ ., data = new_train, method = \"rpart\", trControl = fitControl, tuneGrid = cartGrid)\n> print(tree_model)", "The final value for cp = 0.01. You can also check the table populated in console for more information. The model with cp = 0.01 has the least RMSE. Let\u2019s now build a decision tree with 0.01 as complexity parameter.", "Here is the tree structure of our model. If you have gone through the basics, you would now understand that this algorithm has marked Item_MRP as the most important variable (being the root node). Let\u2019s check the RMSE of this model and see if this is any better than regression.", "As you can see, our RMSE has further improved\u00a0from 1140 to 1102.77 with decision tree. \u00a0To improve this score further, you can further tune the parameters for greater accuracy.", "Random Forest is a powerful algorithm which holistically takes care of missing values, outliers and other non-linearities in the data set. It\u2019s simply a collection of classification trees, hence the name \u2018forest\u2019. I\u2019d suggest you to quickly refresh your basics of random forest with this tutorial.", "In R, random forest algorithm can be implement using randomForest package. Again, we\u2019ll use train package for cross validation and finding optimum value of model parameters.", "For this problem, I\u2019ll focus on two parameters of random forest. mtry and ntree.\u00a0\u00a0ntree is the number of trees to be grown in the forest. mtry\u00a0is the number of variables taken at each node to build a tree. And, we\u2019ll do a 5 fold cross validation.", "#set tuning parameters\n> control <- trainControl(method = \"cv\", number = 5)", "#random forest model\n> rf_model <- train(Item_Outlet_Sales ~ ., data = new_train, method = \"parRF\",\u00a0trControl = \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 control,\u00a0prox = TRUE,\u00a0allowParallel = TRUE)", "If you notice, you\u2019ll see I\u2019ve used method = \u201cparRF\u201d. This is parallel random forest. This is parallel implementation of random forest.\u00a0This package causes\u00a0your local machine to take less time in random forest computation. Alternatively, you can also use method = \u201crf\u201d as a standard random forest function.", "Now we\u2019ve got the optimal value of mtry = 15. Let\u2019s use 1000 trees for computation.", "This model throws RMSE = 1132.04 which is not an improvement over decision tree model. Random forest has a feature of presenting the important variables. We see that the most important variable is Item_MRP (also shown by decision tree algorithm).", "This model can be further improved by tuning parameters. Also,\u00a0Let\u2019s make out first submission with our best RMSE score by decision tree.", "When predicted on out of sample data, our RMSE has come out to be 1174.33.\u00a0Here are some things you can do to improve this model further:", "Do implement the ideas suggested above and share your improvement in the comments section below. Currently, Rank 1 on Leaderboard has obtained RMSE score of 1137.71. Beat it!", "This brings us to the end of this tutorial. Regret for not so happy ending. But, I\u2019ve given you enough hints to work on. The decision to not use encoded variables in the model, turned out to be beneficial until decision trees.", "The motive of this tutorial was to get your started with predictive modeling in R. We learnt few uncanny things such as \u2018build simple models\u2019. Don\u2019t jump towards building a complex model. Simple models give you benchmark score and a threshold to work with.", "In this tutorial, I have demonstrated the steps used in predictive modeling in R. I\u2019ve covered data exploration, data visualization, data manipulation and building models using Regression, Decision Trees and Random Forest algorithms.", "Did you find this tutorial useful ? Are you facing any trouble at any stage of this tutorial ? Feel free to mention your doubts in the comments section below. Do share if you get a better score.", "Edit: On visitor\u2019s request, the PDF version of the tutorial is available for download. You need to create a log in account to download the PDF. Also, you can bookmark this page for future reference. Download Here.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F02%2Fcomplete-tutorial-learn-data-science-scratch%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=A Complete Tutorial to learn Data Science in R from Scratch&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F02%2Fcomplete-tutorial-learn-data-science-scratch%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2016%2F02%2Fcomplete-tutorial-learn-data-science-scratch%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/avcontentteam/", "anchor_text": "avcontentteam"}, {"url": "https://www.analyticsvidhya.com/blog/category/beginner/", "anchor_text": "Beginner"}, {"url": "https://www.analyticsvidhya.com/blog/category/business-analytics/", "anchor_text": "Business Analytics"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-exploration/", "anchor_text": "Data Exploration"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-science/", "anchor_text": "Data Science"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/programming/", "anchor_text": "Programming"}, {"url": "https://www.analyticsvidhya.com/blog/category/r/", "anchor_text": "R"}, {"url": "https://www.analyticsvidhya.com/blog/category/structured-data/", "anchor_text": "Structured Data"}, {"url": "http://discuss.analyticsvidhya.com/t/how-to-run-r-on-jupyter-ipython-notebooks/5512", "anchor_text": "Jupyter Notebooks"}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii", "anchor_text": "Big Mart Sales Prediction"}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/", "anchor_text": "Complete Python Tutorial from Scratch"}, {"url": "http://ftp.heanet.ie/mirrors/cran.r-project.org/", "anchor_text": "old version"}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/8-ways-deal-continuous-variables-predictive-modeling/", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/2015/02/7-steps-data-exploration-preparation-building-model-part-2/", "anchor_text": "here"}, {"url": "https://cran.r-project.org/", "anchor_text": "CRAN"}, {"url": "https://www.analyticsvidhya.com/blog/2015/12/faster-data-manipulation-7-packages/", "anchor_text": "complete tutorial"}, {"url": "https://www.analyticsvidhya.com/blog/2015/08/list-r-packages-data-analysis/", "anchor_text": "infographic"}, {"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/", "anchor_text": "Big Mart Sales Prediction"}, {"url": "https://www.analyticsvidhya.com/wp-content/uploads/2016/02/PRV.png", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2015/07/guide-data-visualization-r/", "anchor_text": "tutorial"}, {"url": "https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/", "anchor_text": "tutorial"}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/7-important-model-evaluation-error-metrics/", "anchor_text": "RMSE"}, {"url": "https://rpubs.com/bradleyboehmke/data_wrangling", "anchor_text": "tutorial"}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-bigmart-sales-prediction", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/", "anchor_text": "here"}, {"url": "https://en.wikipedia.org/wiki/Multicollinearity", "anchor_text": "multicollinearity"}, {"url": "https://en.wikipedia.org/wiki/Autocorrelation#Regression_analysis", "anchor_text": "autocorrelation"}, {"url": "https://en.wikipedia.org/wiki/Heteroscedasticity", "anchor_text": "heteroskedasticity"}, {"url": "https://www.analyticsvidhya.com/blog/2015/01/decision-tree-simplified/", "anchor_text": "Part 1"}, {"url": "https://www.analyticsvidhya.com/blog/2015/01/decision-tree-algorithms-simplified/", "anchor_text": "Part 2"}, {"url": "https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/", "anchor_text": "Cross Validation"}, {"url": "https://www.analyticsvidhya.com/blog/2015/09/random-forest-algorithm-multiple-challenges/", "anchor_text": "tutorial"}, {"url": "https://www.analyticsvidhya.com/blog/2015/09/complete-guide-boosting-methods/", "anchor_text": "Gradient Boosting"}, {"url": "https://www.analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/", "anchor_text": "Ensemble Modeling"}, {"url": "http://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/lb", "anchor_text": "Leaderboard"}, {"url": "http://discuss.analyticsvidhya.com/t/download-free-tutorial-to-learn-data-science-in-r-from-scratch/7797/2", "anchor_text": "Download Here"}, {"url": "http://datahack.analyticsvidhya.com/contest/all", "anchor_text": "participate in our Hackathons"}, {"url": "https://www.analyticsvidhya.com/blog/tag/autocorrelation/", "anchor_text": "Autocorrelation"}, {"url": "https://www.analyticsvidhya.com/blog/tag/caret-package/", "anchor_text": "caret package"}, {"url": "https://www.analyticsvidhya.com/blog/tag/cross-validation/", "anchor_text": "cross-validation"}, {"url": "https://www.analyticsvidhya.com/blog/tag/data-exploration-in-r/", "anchor_text": "data exploration in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/data-manipulation-in-r/", "anchor_text": "data manipulation in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/data-mining-in-r/", "anchor_text": "data mining in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/decision-trees-in-r/", "anchor_text": "decision trees in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/dplyr/", "anchor_text": "dplyr"}, {"url": "https://www.analyticsvidhya.com/blog/tag/feature-engineering-in-r/", "anchor_text": "feature engineering in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/ggplot/", "anchor_text": "ggplot"}, {"url": "https://www.analyticsvidhya.com/blog/tag/heteroskedasticity/", "anchor_text": "heteroskedasticity"}, {"url": "https://www.analyticsvidhya.com/blog/tag/homoskedasticity/", "anchor_text": "Homoskedasticity"}, {"url": "https://www.analyticsvidhya.com/blog/tag/label-encoding/", "anchor_text": "label encoding"}, {"url": "https://www.analyticsvidhya.com/blog/tag/linear-regression-in-r/", "anchor_text": "linear regression in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/missing-values-in-r/", "anchor_text": "missing values in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/multicollinearity/", "anchor_text": "multicollinearity"}, {"url": "https://www.analyticsvidhya.com/blog/tag/multiple-regression-in-r/", "anchor_text": "multiple regression in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/one-hot-encoding/", "anchor_text": "One Hot Encoding"}, {"url": "https://www.analyticsvidhya.com/blog/tag/overfitting/", "anchor_text": "overfitting"}, {"url": "https://www.analyticsvidhya.com/blog/tag/plyr-package/", "anchor_text": "plyr package"}, {"url": "https://www.analyticsvidhya.com/blog/tag/predictive-modeling/", "anchor_text": "Predictive modeling"}, {"url": "https://www.analyticsvidhya.com/blog/tag/random-forest-in-r/", "anchor_text": "random forest in R"}, {"url": "https://www.analyticsvidhya.com/blog/tag/underfitting/", "anchor_text": "underfitting"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2023/01/11-popular-r-packages-for-beginners-in-2023/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "11 Popular R Packages for Beginners in 2023"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/what-is-data-analytics/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "What is Data Analytics? How to Use it in Your Career?"}, {"url": "https://www.analyticsvidhya.com/blog/2021/04/top-10-r-packages-for-data-science-you-must-know-in-2021/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "Top 10 R Packages for Data Science You Must Know in 2021"}, {"url": "https://www.analyticsvidhya.com/blog/2023/02/data-mining-the-knowledge-discovery-of-data/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "Data Mining: The Knowledge Discovery of Data"}, {"url": "https://www.analyticsvidhya.com/blog/2023/03/machine-learning-libraries-in-2023/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "A Comprehensive Guide to Top Machine Learning Libraries in 2023"}, {"url": "https://www.analyticsvidhya.com/blog/2023/03/top-3-ways-to-import-data-into-r-using-copy-and-paste/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/", "anchor_text": "Top 3 Ways to Import Data into R using Copy and Paste"}, {"url": "https://www.analyticsvidhya.com/blog/author/avcontentteam/", "anchor_text": "avcontentteam"}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/guide-build-predictive-models-segmentation/", "anchor_text": "Guide to Build Better Predictive Models using Segmentation"}, {"url": "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/", "anchor_text": "Mastering XGBoost Parameter Tuning: A Complete Guide with Python Codes"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/", "anchor_text": "link"}, {"url": "https://discuss.analyticsvidhya.com/t/download-free-tutorial-to-learn-data-science-in-r-from-scratch/7797", "anchor_text": "this"}, {"url": "https://www.analyticsvidhya.com/blog/2018/01/ultimate-learning-path-becoming-data-scientist-2018/", "anchor_text": "here"}, {"url": "https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/", "anchor_text": "Here"}, {"url": "https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}