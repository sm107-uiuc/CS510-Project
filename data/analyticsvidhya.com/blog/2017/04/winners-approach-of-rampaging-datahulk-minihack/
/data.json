{"url": "https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/\n", "time": 1683020474.7514958, "path": "analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/\n/", "webpage": {"metadata": {"title": "Winner's Approach - Rampaging DataHulk MiniHack, AV DataFest 2017", "h1": "Winner\u2019s Approach \u2013 Rampaging DataHulk MiniHack, AV DataFest 2017", "description": "This article features the approach of Top 3 winners of Rampaging DataHulk minihack. The participants had to predict chances of a stock moving up or down."}, "outgoing_paragraph_urls": [{"url": "https://analyticsvidhya.com/datafest-2017/", "anchor_text": "DataFest 2017", "paragraph_index": 1}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-rampaging-datahulk/", "anchor_text": "Rampaging DataHulk", "paragraph_index": 1}, {"url": "https://datahack.analyticsvidhya.com/contest/machine-learning-hackathon/", "anchor_text": "Machine Learning Hackathon", "paragraph_index": 4}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-the-quicksolver/", "anchor_text": "The QuickSolver MiniHack", "paragraph_index": 4}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-rampaging-datahulk/lb", "anchor_text": "leaderboard", "paragraph_index": 9}, {"url": "https://www.linkedin.com/in/santanu-pattanayak-99843812/", "anchor_text": "Santanu Pattanayak", "paragraph_index": 11}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%203%20-%20Santanu%20Pattanayak.py", "anchor_text": "Code File", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/princeatul/", "anchor_text": "Prince Atul", "paragraph_index": 29}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%202%20-%20Prince%20Atul.py", "anchor_text": "Code File", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/akashgupta222/", "anchor_text": "Akash Gupta", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#cross-validation", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#feature-engineering", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#parameter-tuning", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#max-depth", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#min_child_weight", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#learning-rate-num_rounds-and-early-stopping", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/akashgupta222/av_datahulk#running-the-code", "anchor_text": "", "paragraph_index": 29}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%201%20-%20Akash%20Gupta.py", "anchor_text": "Code File", "paragraph_index": 29}, {"url": "https://datahack.analyticsvidhya.com/contest/machine-learning-hackathon/", "anchor_text": "Machine Learning Hackathon", "paragraph_index": 29}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-the-quicksolver/", "anchor_text": "The QuickSolver MiniHack", "paragraph_index": 29}, {"url": "https://datahack.analyticsvidhya.com/contest/all/", "anchor_text": "here", "paragraph_index": 29}, {"url": "https://www.linkedin.com/in/princeatul/", "anchor_text": "Prince Atul", "paragraph_index": 31}, {"url": "https://www.linkedin.com/in/akashgupta222/", "anchor_text": "Akash Gupta", "paragraph_index": 38}, {"url": "https://github.com/akashgupta222/av_datahulk#cross-validation", "anchor_text": "", "paragraph_index": 41}, {"url": "https://github.com/akashgupta222/av_datahulk#learning-rate-num_rounds-and-early-stopping", "anchor_text": "", "paragraph_index": 46}], "all_paragraphs": ["While participating in a hackathon, a lot of people think that they are competing against the top data scientists. While, in reality, most of us really compete with ourselves. The ones who improve themselves, the ones who\u00a0competing with their own\u00a0previous self and push their\u00a0limits to become better are always the eventual winners.", "We see this happen very frequently on Analytics Vidhya. We saw this again in our first ML contest of DataFest 2017 \u2013\u00a0Rampaging DataHulk. In this minihack, we saw experienced professionals, students & previous winners compete with each other for the top 3 ranks. A total of 1458 people participated in the minihack.\u00a0The competition began at 6 PM on 2 April marking the first competition in DataFest.", "After a fist to fist battle in true \u201cHulk-athon\u201d style, we saw something remarkable. Something which hasn\u2019t happened for a while on Analytics Vidhya. The top 3 ranks were bagged by first-time winners. To top it up, the winner is still in his college days! That is just a testimony to the competitiveness and openness of the platform.", "Like always, the winners of the competition have generously shared their detailed approach and the codes they used in the competition.", "If you missed out the fun this weekend, make sure you participate in the upcoming Machine Learning Hackathon & The QuickSolver MiniHack.", "The problem statement revolved around a hedge fund company \u201cQuickMoney\u201d.\u00a0They rely on automated systems to carry out trades in the stock market at inter-day frequencies. They wish to create a machine learning-based strategy for predicting the movement in stock prices for maximizing their profit. So they were seeking out a help from top data scientists.", "Stock markets are known to have a high degree of unpredictability but it is possible to beat the odds and create a system which will outperform others.", "The participants were required to create a trading strategy for maximizing their profit in the stock market. The task was to predict the probability whether the price for a particular stock for next day market close will be higher(1) or lower(0) compared to the price for market close today.", "The winners used different approaches and rose up on the leaderboard. Below are the top 3 winners on the leaderboard:", "Here are the final rankings of all the participants at the\u00a0leaderboard.", "All the Top 3 winners have shared their detailed approach & code from the competition. I am sure you are eager to know their secrets, go ahead.", "Santanu Pattanayak is Lead Data Scientist at GE Digital. He often participates in machine learning competitions on Analytics Vidhya. He likes to challenge himself.", "Following\u00a0is the approach he took for the Analytics Vidhya Rampaging Datahulk Competition. He secured 3rd place in the competition with a private Leaderboard Score of 0.678784:", "1. First, I did some exploratory data analysis. I checked the number of records in train and test datasets and checked whether there is any class imbalance that we need to deal with. The training dataset was quite balanced with 45% of the data belonging to the positive class. Since the dataset sizes were satisfactory i.e. 702739 train records and 101946 test records hence class imbalance adjustments were not necessary. Then I checked the number of different stocks in both train and test and checked whether all the stocks in test are there in train dataset or not. The train dataset has 1955 stocks while the test dataset has 2118 stocks. Since the test has more stocks clearly stock id cannot be used as a feature since the model would learn nothing about those stock ids that are there in test but not in train.", "2. The main task as in most of the machine learning tasks is to do proper feature engineering. So, spend quite a bit of time thinking what would be good features with respect to the output that we are going to predict \u2013 that is whether the sales of tomorrow\u2019s market close is going to be higher than today\u2019s market close.", "There were missing values in the below fields:", "I replaced the missing values with 99999 and created indicator variables indicating whether these fields have missing values.", "Then I created few variables capturing the difference in the moving averages. For example \u2013 (Three_Day_Moving_Average \u2013 Ten_Day_Moving_Average). I created such variables for each pair of the moving average variables.", "I created couple of features by taking the sum and difference of the variables Positive_Directional_Movement and Negative_Directional_Movement. Similarly, I created two features by taking the sum and difference of the variables True_Range and Average_True_Range.", "Also, I created few features to hold the moving average of the days prior to a specific period as below:", "Here the first variable is computing the average of the 7 days prior to the last 3 days.", "3. Once I build these features then I split the training data into two parts \u2013 80% of the data for training the models and 20% for validation purpose. Below are the models that I tried \u2013", "Gradient boosting from graphlab \u2013 It\u2019s always easy to work with graphlab since you can input a dataframe along with the features and target unlike most of the other packages wherein you would have to create a numpy matrix or a sparse matrix before the algorithms can be invoked. Experimented with 300,500 and 700 trees, with the class weights set to \u201cauto\u201d, tree depth of 6, min child weight and minimum loss reduction set to \u201c4\u201d each. Also, the column subsample and the row subsample was set to 80 percent.", "It gave good performance with validation logloss of around 0.6820 and public leaderboard of around 0.6855", "I tried my hand at a small neural network through Keras with two hidden layers of 300 units each and dropout of each hidden layer set to 0.5. For the hidden layers I chose activation as \u2018RELU\u2019 and the output layer as \u2018sigmoid\u2019 and got a logloss of around 0.688 in both validation and in leaderboard.", "Since the neural network and Gradient boosting are very different models I tried to take the mean of their predicted probabilities and the public leaderboard logloss improved to 0.6831.", "Still I was not able to enter the 0.67 range.", "Next, I tried my luck at xgboost with kind of similar configuration as that of the graphlab gradient boosting model.", "I experimented a bit with the number of trees and finally got the best results with the below parameters.", "\n\n\n\nNo of trees\n700\n\n\nColumn subsample\n0.8\n\n\nRow subsample\n0.8\n\n\nL2 regularization\n2(lambda)\n\n\nL1 regularization\n0.02(alpha)\n\n\nMinimum child weight\n4\n\n\nObjective\n\u00a0Binary:logistic\n\n\nBooster\nGbtree\n\n\nEta\n0.02\n\n\nEarly stopping round\n20\n\n\n\n\nThe above model gave me 0.6780 logloss on Public leaderboard (9th rank) and 0.6787 logloss on the private leaderboard (3rd place).\nSolution: Code File\u00a0\n\u00a0\nRank 2, Prince Atul\nPrince Atul\nPrince Atul is a Senior Scientist at Cognizant. Prince has been participating in various competitions at Analytics Vidhya. Prince is also a volunteer for Analytics Vidhya and helps us with our community efforts. This is his approach:\nI decided to approach this hackathon with more focus on feature engineering than on model selection and data processing.\u00a0 After reading the problem, I decided to use gradient boosting with binary logistics.\nI always submit a preliminary model, generally with all the variables, to set a benchmark score.\nThere were 4 moving averages in the data set and I expected them to be correlated. So, I plotted correlation matrix and as expected 10 days and 20 days moving average were highly correlated with other moving averages. I removed these two variables and trained my model on rest of the data. This model was giving a 0.68 (approx.) score on public leaderboard.\nI checked for null values and there were 4000+ rows which had missing values. I left it as it because it was very small percentage of the train data set. (Wanted to come back to it, didn\u2019t get time)\nAfter this I started creating features. Features which improved my score were (1,0,-1 values) :- comparison of 3 days moving average with other moving averages, comparison of 5 days moving average with other moving averages and sum of these comparison value.\u00a0 I created this to use price movement direction based on moving averages. After creating this, my model was giving a score of 0.677(approx.) on public leaderboard.\nI think that hardest part in any mini-hackathon is to create features. It takes some thinking and not every feature you create will add values. But, it is important to keep on doing it even if first few features are not able to improve your model.\nSolution: Code File\u00a0\n\u00a0\nRank 1, Akash Gupta\nAkash Gupta\nAkash Gupta is a final year student at IIT Roorkee. Akash is one of the most competitive students we have come across on Analytics Vidhya. He fetched his last win in The Ultimate Student Hunt competition by securing 5th rank.\nFind out what\u2019s his secret for winning this minihack.\nInitialization:\u00a0I started out by trying a basic xgboost model using the given features and filling the missing values with -1. I generally start with xgboost because of its speed and good scores. I had removed the ID and timestamp features.\nCross Validation: To set up a quick cross validation, I randomly sampled out 10% of the dataset and set that up as the eval data. I had planned to write for timestamp-based partitioning later. But the initial eval scores for this setup were similar to the ones I got on the public leaderboard, so I persisted with this setup.\n\u00a0\nFeature Engineering\nOn plotting the feature importances using the default set of features, I realized that the MA features were not contributing much. Also, to me using the absolute values of these features was not intuitive. Removing these gave me an improvement in the eval score as well as the public leaderboard score. Then I removed the volume traded feature because it was also having a low contribution and removing it gave me an improvement in both eval and public lb. Later, I created 3 new features:\n\ndifference between three day moving average and five day moving average\ndifference between five day moving average and ten day moving average\ndifference between positive directional movement and negative directional movement I added these features one by one and saw an improvement in both the eval and public lb scores.\n\nI tried creating a feature for differnce between three day moving average of nth day minus the three day moving average of (n-1)th day. This gave me improvement in eval dataset, but not on the public lb. Possibily this had overfit the data, so I removed this feature.\n\u00a0\nParameter Tuning\nmax depth\nI usually start with shallow trees (max depth 3). I prefer to use shallow trees because they dont tend to overfit. I tried increasing the max depth to 4 and 5, but that made the scores worse for public lb. So I stuck to using max depth 3.\nmin_child_weight\nInitially, I set the min_child_weight to 1000 because of the high number of data points. Later I moved it to 1500 and 500 and saw that 500 gave me a better score. Decreasing further to 300 didnt help so I stuck with 500.\nLearning Rate, num_rounds and early stopping\nI set up the early stopping parameter to 50, i.e. if the eval score doesnt improve in 50 rounds, stop training further. The learning rate was initially set to 0.05 and num rounds were initially set to 1500. But this was very slow and the score was improving even after 1500 rounds. So I changed the learning rate to 0.2 and reduced the num rounds to 800. This gave me stopping near the 600th round and quicker training as a result.\nWell, thats it, I did not have the time to try ensemble models which I believe could have improved the score further.\n\u00a0\nRunning the code\n\nKeep all the files(python script, train.csv and test.csv) in the same directory and set the working directory to that directory.\nRun the script by command: python try1.py.\nThe submission is saved as submission_xgb.csv.\n\nSolution:\u00a0Code File\u00a0\n\u00a0\nEnd Notes\nIt was great interacting with these winners and\u00a0know their approach during the\u00a0competition. Hopefully, you will be able to evaluate where you missed out.\n\nTake a cue from these approaches and participate in upcoming Machine Learning Hackathon & The QuickSolver MiniHack. If you have any questions feel free to post them below.\n\nCheck out all the upcoming competitions here.\n\nRelated\n ", "The above model gave me 0.6780 logloss on Public leaderboard (9th rank) and 0.6787 logloss on the private leaderboard (3rd place).", "Prince Atul is a Senior Scientist at Cognizant. Prince has been participating in various competitions at Analytics Vidhya. Prince is also a volunteer for Analytics Vidhya and helps us with our community efforts. This is his approach:", "I decided to approach this hackathon with more focus on feature engineering than on model selection and data processing.\u00a0 After reading the problem, I decided to use gradient boosting with binary logistics.", "I always submit a preliminary model, generally with all the variables, to set a benchmark score.", "There were 4 moving averages in the data set and I expected them to be correlated. So, I plotted correlation matrix and as expected 10 days and 20 days moving average were highly correlated with other moving averages. I removed these two variables and trained my model on rest of the data. This model was giving a 0.68 (approx.) score on public leaderboard.", "I checked for null values and there were 4000+ rows which had missing values. I left it as it because it was very small percentage of the train data set. (Wanted to come back to it, didn\u2019t get time)", "After this I started creating features. Features which improved my score were (1,0,-1 values) :- comparison of 3 days moving average with other moving averages, comparison of 5 days moving average with other moving averages and sum of these comparison value.\u00a0 I created this to use price movement direction based on moving averages. After creating this, my model was giving a score of 0.677(approx.) on public leaderboard.", "I think that hardest part in any mini-hackathon is to create features. It takes some thinking and not every feature you create will add values. But, it is important to keep on doing it even if first few features are not able to improve your model.", "Akash Gupta is a final year student at IIT Roorkee. Akash is one of the most competitive students we have come across on Analytics Vidhya. He fetched his last win in The Ultimate Student Hunt competition by securing 5th rank.", "Find out what\u2019s his secret for winning this minihack.", "Initialization:\u00a0I started out by trying a basic xgboost model using the given features and filling the missing values with -1. I generally start with xgboost because of its speed and good scores. I had removed the ID and timestamp features.", "Cross Validation: To set up a quick cross validation, I randomly sampled out 10% of the dataset and set that up as the eval data. I had planned to write for timestamp-based partitioning later. But the initial eval scores for this setup were similar to the ones I got on the public leaderboard, so I persisted with this setup.", "On plotting the feature importances using the default set of features, I realized that the MA features were not contributing much. Also, to me using the absolute values of these features was not intuitive. Removing these gave me an improvement in the eval score as well as the public leaderboard score. Then I removed the volume traded feature because it was also having a low contribution and removing it gave me an improvement in both eval and public lb. Later, I created 3 new features:", "I tried creating a feature for differnce between three day moving average of nth day minus the three day moving average of (n-1)th day. This gave me improvement in eval dataset, but not on the public lb. Possibily this had overfit the data, so I removed this feature.", "I usually start with shallow trees (max depth 3). I prefer to use shallow trees because they dont tend to overfit. I tried increasing the max depth to 4 and 5, but that made the scores worse for public lb. So I stuck to using max depth 3.", "Initially, I set the min_child_weight to 1000 because of the high number of data points. Later I moved it to 1500 and 500 and saw that 500 gave me a better score. Decreasing further to 300 didnt help so I stuck with 500.", "Learning Rate, num_rounds and early stopping", "I set up the early stopping parameter to 50, i.e. if the eval score doesnt improve in 50 rounds, stop training further. The learning rate was initially set to 0.05 and num rounds were initially set to 1500. But this was very slow and the score was improving even after 1500 rounds. So I changed the learning rate to 0.2 and reduced the num rounds to 800. This gave me stopping near the 600th round and quicker training as a result.", "Well, thats it, I did not have the time to try ensemble models which I believe could have improved the score further.", "I am a Business Analytics and Intelligence professional with deep experience in the Indian Insurance industry. I have worked for various multi-national Insurance companies in last 7 years.", " Notify me of follow-up comments by email.", " Notify me of new posts by email.", "Make Money While Sleeping: Side Hustles to Generate Passive Income..", "Google Bard Learnt Bengali on Its Own: Sundar Pichai", "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your..", "Understand Random Forest Algorithms With Examples (Updated 2023)", " A verification link has been sent to your email id ", " If you have not recieved the link please goto\nSign Up  page again\n", "This email id is not registered with us. Please enter your registered email id."], "all_outgoing_urls": [{"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Home"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": ""}, {"url": "https://courses.analyticsvidhya.com/courses/Machine-Learning-Certification-Course-for-Beginners?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Machine Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/getting-started-with-neural-networks?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "Deep Learning"}, {"url": "https://courses.analyticsvidhya.com/courses/Intro-to-NLP?utm_source=blog_navbar&utm_medium=start_here_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/guide/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Guides"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/?utm_source=blog_navbar&utm_medium=machine_learning_button", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/deep-learning/?utm_source=blog_navbar&utm_medium=deep_learning_button", "anchor_text": "Deep Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/nlp/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "NLP"}, {"url": "https://www.analyticsvidhya.com/blog/category/computer-vision/?utm_source=blog_navbar&utm_medium=article_button", "anchor_text": "Computer Vision"}, {"url": "https://www.analyticsvidhya.com/blog/category/data-visualization/?utm_source=blog_navbar&utm_medium=_button", "anchor_text": "Data Visualization"}, {"url": "https://www.analyticsvidhya.com/blog/category/interview-questsions/?utm_source=blog_navbar&utm_medium=career_button", "anchor_text": "Interview Questions"}, {"url": "https://www.analyticsvidhya.com/blog/category/infographics/?utm-source=blog-navbar", "anchor_text": "Infographics"}, {"url": "https://jobsnew.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "Jobs"}, {"url": "https://www.analyticsvidhya.com/blog/category/podcast/?utm-source=blog-navbar", "anchor_text": "Podcasts"}, {"url": "https://courses.analyticsvidhya.com/courses/ebook-machine-learning-simplified?utm_source=bolg-navbar&utm_medium=homepage&utm_campaign=ebook", "anchor_text": "E-Books"}, {"url": "https://www.analyticsvidhya.com/corporate/?utm-source=blog-navbar", "anchor_text": "For Companies"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2019/?utm-source=blog-navbar", "anchor_text": "Datahack Summit"}, {"url": "https://dsat.analyticsvidhya.com/?utm-source=blog-navbar", "anchor_text": "DSAT"}, {"url": "https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/?utm-source=blog-navbar", "anchor_text": "Glossary"}, {"url": "https://www.analyticsvidhya.com/blog-archive/?utm-source=blog-navbar", "anchor_text": "Archive"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_navbar&utm_medium=blackbelt_button", "anchor_text": "Certified AI & ML BlackBelt Plus"}, {"url": "https://bootcamp.analyticsvidhya.com/?utm_source=blog_navbar&utm_medium=bootcamp_button", "anchor_text": "Data Science Immersive Bootcamp"}, {"url": "https://courses.analyticsvidhya.com/collections?utm_source=blog_navbar&utm_medium=all_courses_button", "anchor_text": "All Courses"}, {"url": "https://datahack.analyticsvidhya.com/blogathon/?utm_source=blog&utm_medium=nav_bar", "anchor_text": "Blogathon"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=Blogs&utm_medium=Nav_Bar", "anchor_text": "Conference"}, {"url": "https://lekhak.analyticsvidhya.com/write/", "anchor_text": "Write an Article"}, {"url": "https://www.analyticsvidhya.com/creators-club/?utm-medium=blog-navbar&utm_source=creator_club_button", "anchor_text": "Creators Club"}, {"url": "https://id.analyticsvidhya.com/accounts/profile/", "anchor_text": "Manage your AV Account"}, {"url": "https://datahack.analyticsvidhya.com/user/?utm-source=blog-navbar", "anchor_text": "My Hackathons"}, {"url": "https://profile.analyticsvidhya.com/accounts/bookmarks/", "anchor_text": "My Bookmarks"}, {"url": "https://courses.analyticsvidhya.com/enrollments/?utm-source=blog-navbar", "anchor_text": "My Courses"}, {"url": "https://jobsnew.analyticsvidhya.com/jobs/myactive/?utm-source=blog-navbar", "anchor_text": "My Applied Jobs"}, {"url": "http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2017%2F04%2Fwinners-approach-of-rampaging-datahulk-minihack%2F", "anchor_text": "Facebook"}, {"url": "http://twitter.com/share?text=Winner\u2019s Approach \u2013 Rampaging DataHulk MiniHack, AV DataFest 2017&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2017%2F04%2Fwinners-approach-of-rampaging-datahulk-minihack%2F", "anchor_text": "Twitter"}, {"url": "http://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2017%2F04%2Fwinners-approach-of-rampaging-datahulk-minihack%2F", "anchor_text": "Linkedin"}, {"url": "https://www.analyticsvidhya.com/blog/author/sunil-ray/", "anchor_text": "Sunil Ray"}, {"url": "https://www.analyticsvidhya.com/blog/category/intermediate/", "anchor_text": "Intermediate"}, {"url": "https://www.analyticsvidhya.com/blog/category/listicle/", "anchor_text": "Listicle"}, {"url": "https://www.analyticsvidhya.com/blog/category/machine-learning/", "anchor_text": "Machine Learning"}, {"url": "https://www.analyticsvidhya.com/blog/category/winners-approach/", "anchor_text": "Winners Approach"}, {"url": "https://analyticsvidhya.com/datafest-2017/", "anchor_text": "DataFest 2017"}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-rampaging-datahulk/", "anchor_text": "Rampaging DataHulk"}, {"url": "https://datahack.analyticsvidhya.com/contest/machine-learning-hackathon/", "anchor_text": "Machine Learning Hackathon"}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-the-quicksolver/", "anchor_text": "The QuickSolver MiniHack"}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-the-quicksolver/", "anchor_text": ""}, {"url": "https://datahack.analyticsvidhya.com/user/profile/akashgupta222", "anchor_text": "Akash Gupta"}, {"url": "https://datahack.analyticsvidhya.com/user/profile/prince.p13029", "anchor_text": "Prince Atul"}, {"url": "https://datahack.analyticsvidhya.com/user/profile/santanu.pattanayak011183@gmail.com", "anchor_text": "Santanu Pattanayak"}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-rampaging-datahulk/lb", "anchor_text": "leaderboard"}, {"url": "https://www.linkedin.com/in/santanu-pattanayak-99843812/", "anchor_text": "Santanu Pattanayak"}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%203%20-%20Santanu%20Pattanayak.py", "anchor_text": "Code File"}, {"url": "https://www.linkedin.com/in/princeatul/", "anchor_text": "Prince Atul"}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%202%20-%20Prince%20Atul.py", "anchor_text": "Code File"}, {"url": "https://www.linkedin.com/in/akashgupta222/", "anchor_text": "Akash Gupta"}, {"url": "https://github.com/akashgupta222/av_datahulk#cross-validation", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#feature-engineering", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#parameter-tuning", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#max-depth", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#min_child_weight", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#learning-rate-num_rounds-and-early-stopping", "anchor_text": ""}, {"url": "https://github.com/akashgupta222/av_datahulk#running-the-code", "anchor_text": ""}, {"url": "https://github.com/analyticsvidhya/rampagingdatahulk-2017/blob/master/Rank%201%20-%20Akash%20Gupta.py", "anchor_text": "Code File"}, {"url": "https://datahack.analyticsvidhya.com/contest/machine-learning-hackathon/", "anchor_text": "Machine Learning Hackathon"}, {"url": "https://datahack.analyticsvidhya.com/contest/avdatafest-the-quicksolver/", "anchor_text": "The QuickSolver MiniHack"}, {"url": "https://datahack.analyticsvidhya.com/contest/all/", "anchor_text": "here"}, {"url": "https://www.analyticsvidhya.com/blog/tag/cross-validation/", "anchor_text": "cross-validation"}, {"url": "https://www.analyticsvidhya.com/blog/tag/feature-engineering/", "anchor_text": "feature engineering"}, {"url": "https://www.analyticsvidhya.com/blog/tag/machine-learning/", "anchor_text": "machine learning"}, {"url": "https://www.analyticsvidhya.com/blog/tag/machine-learning-competition/", "anchor_text": "machine learning competition"}, {"url": "https://www.analyticsvidhya.com/blog/tag/machine-learning-hackathon/", "anchor_text": "machine learning hackathon"}, {"url": "https://www.analyticsvidhya.com/blog/tag/minihack/", "anchor_text": "minihack"}, {"url": "https://www.analyticsvidhya.com/blog/tag/minihack-winners/", "anchor_text": "minihack winners"}, {"url": "https://www.analyticsvidhya.com/blog/tag/rampaging-datahulk-winners/", "anchor_text": "Rampaging Datahulk winners"}, {"url": "https://www.analyticsvidhya.com/datahack-summit-2023/?utm_source=blog_india&utm_medium=side_banner&utm_campaign=27-Apr-2023||&utm_content=generativeAI", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=blog_outside_india&utm_medium=side_banner&utm_campaign=24-Mar-2023||&utm_content=project#ReinforceProject", "anchor_text": ""}, {"url": "https://blackbelt.analyticsvidhya.com/plus?utm_source=RelatedArticles&utm_medium=blog", "anchor_text": "Become a full stack data scientist"}, {"url": "https://www.analyticsvidhya.com/blog/2020/09/how-i-became-a-data-science-competition-master/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "How I Became a Data Science Competition Master from Scratch"}, {"url": "https://www.analyticsvidhya.com/blog/2020/09/hacklive-community-guided-hackathon-data-science/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "Presenting HackLive \u2013 A Guided Community Hackathon by Analytics Vidhya\u2019s Data Science Experts!"}, {"url": "https://www.analyticsvidhya.com/blog/2020/10/12-powerful-tips-ace-data-science-hackathons/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "12 Powerful Tips to Ace Data Science and Machine Learning Hackathons"}, {"url": "https://www.analyticsvidhya.com/blog/2020/12/kaggle-grandmaster-series-exclusive-interview-with-competitions-grandmaster-and-rank-21-agnis-liukis/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "Kaggle Grandmaster Series \u2013 Exclusive Interview with Competitions Grandmaster and Rank #21 Agnis Liukis"}, {"url": "https://www.analyticsvidhya.com/blog/2020/09/5-talks-data-science-hackathons/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "5 Must-Watch Talks Before your Next Data Science Hackathon (featuring SRK, Dipanjan Sarkar, and more!)"}, {"url": "https://www.analyticsvidhya.com/blog/2020/10/hacklive-data-science-hackathons/?utm_source=related_WP&utm_medium=https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/", "anchor_text": "HackLive \u2013 Everything You Need to Get Started with Data Science Hackathons!"}, {"url": "https://www.analyticsvidhya.com/blog/author/sunil-ray/", "anchor_text": "Sunil Ray"}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/rahul105/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/sion/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/chirag676/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/barney6/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/arnab1408/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/prateekmaj21/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/creators-club/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/author/shanthababu/", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/creators/?utm-medium=blog-footer&utm_source=top-authors", "anchor_text": "view more"}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/blog/2017/04/mgr-analytics-msbi-big-data-or-data-visualization-hyderabad-7-12-years-of-experience/", "anchor_text": "MGR Analytics Msbi Big Data OR Data Visualization- Hyderabad (7-12 Years Of Experience)"}, {"url": "https://www.analyticsvidhya.com/blog/2017/04/dl-internship-chennai-3-months/", "anchor_text": "DL Internship- Chennai (3 Months)"}, {"url": "https://www.analyticsvidhya.com/cdn-cgi/l/email-protection", "anchor_text": "[email protected]"}, {"url": "https://www.analyticsvidhya.com/blog/2017/04/winners-approach-of-rampaging-datahulk-minihack/#respond", "anchor_text": "Cancel reply"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/how-to-make-money-with-chatgpt/", "anchor_text": "Make Money While Sleeping: Side Hustles to Generate Passive Income.."}, {"url": "https://www.analyticsvidhya.com/blog/author/aayush1/", "anchor_text": "Aayush Tyagi -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/google-bard-learnt-bengali-on-its-own-sundar-pichai/", "anchor_text": "Google Bard Learnt Bengali on Its Own: Sundar Pichai"}, {"url": "https://www.analyticsvidhya.com/blog/author/yana_khare/", "anchor_text": "Yana Khare -"}, {"url": "https://www.analyticsvidhya.com/blog/2023/04/freedomgpt-personal-bold-and-uncensored-chatbot-running-locally-on-your-pc/", "anchor_text": "FreedomGPT: Personal, Bold and Uncensored Chatbot Running Locally on Your.."}, {"url": "https://www.analyticsvidhya.com/blog/author/sabreena/", "anchor_text": "K.sabreena -"}, {"url": "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/", "anchor_text": "Understand Random Forest Algorithms With Examples (Updated 2023)"}, {"url": "https://www.analyticsvidhya.com/blog/author/sruthi94/", "anchor_text": "Sruthi E R -"}, {"url": "https://www.analyticsvidhya.com/", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.analyticsvidhya.android", "anchor_text": ""}, {"url": "https://apps.apple.com/us/app/analytics-vidhya/id1470025572", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/about/", "anchor_text": "About Us"}, {"url": "https://www.analyticsvidhya.com/team/", "anchor_text": "Our Team"}, {"url": "https://www.analyticsvidhya.com/careers/", "anchor_text": "Careers"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Contact us"}, {"url": "https://www.analyticsvidhya.com/blog/", "anchor_text": "Blog"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hackathon"}, {"url": "https://discuss.analyticsvidhya.com/", "anchor_text": "Discussions"}, {"url": "https://jobsnew.analyticsvidhya.com/", "anchor_text": "Apply Jobs"}, {"url": "https://www.analyticsvidhya.com/corporate/", "anchor_text": "Post Jobs"}, {"url": "https://courses.analyticsvidhya.com/", "anchor_text": "Trainings"}, {"url": "https://datahack.analyticsvidhya.com/", "anchor_text": "Hiring Hackathons"}, {"url": "https://www.analyticsvidhya.com/contact/", "anchor_text": "Advertising"}, {"url": "https://www.facebook.com/AnalyticsVidhya/", "anchor_text": ""}, {"url": "https://www.linkedin.com/company/analytics-vidhya/", "anchor_text": ""}, {"url": "https://www.youtube.com/channel/UCH6gDteHtH4hg3o2343iObA", "anchor_text": ""}, {"url": "https://twitter.com/analyticsvidhya", "anchor_text": ""}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}, {"url": "https://www.analyticsvidhya.com/refund-policy/", "anchor_text": "Refund Policy"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/terms", "anchor_text": "I accept the Terms and Conditions"}, {"url": "https://www.analyticsvidhya.com/privacy-policy/", "anchor_text": "Privacy Policy"}, {"url": "https://www.analyticsvidhya.com/terms/", "anchor_text": "Terms of Use"}]}, "scrape_status": {"code": "1"}}