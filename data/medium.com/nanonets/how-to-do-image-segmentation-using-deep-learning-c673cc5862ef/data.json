{"url": "https://medium.com/nanonets/how-to-do-image-segmentation-using-deep-learning-c673cc5862ef", "time": 1683019558.800473, "path": "medium.com/nanonets/how-to-do-image-segmentation-using-deep-learning-c673cc5862ef/", "webpage": {"metadata": {"title": "How to do Semantic Segmentation using Deep learning | by James Le | NanoNets | Medium", "h1": "How to do Semantic Segmentation using Deep learning", "description": "This article is a comprehensive overview including a step-by-step guide to implement a deep learning image segmentation model. Nowadays, semantic segmentation is one of the key problems in the field\u2026"}, "outgoing_paragraph_urls": [{"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "R-CNN", "paragraph_index": 7}, {"url": "https://arxiv.org/pdf/1407.1808.pdf", "anchor_text": "SDS", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1411.5752.pdf", "anchor_text": "Hypercolumns", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "Mask R-CNN", "paragraph_index": 9}, {"url": "https://arxiv.org/pdf/1411.4038.pdf", "anchor_text": "Fully Convolutional Network (FCN)", "paragraph_index": 10}, {"url": "https://arxiv.org/pdf/1511.00561.pdf", "anchor_text": "SegNet", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1412.7062.pdf", "anchor_text": "DeepLab-CRF", "paragraph_index": 11}, {"url": "https://arxiv.org/pdf/1511.07122.pdf", "anchor_text": "Dilated Convolutions", "paragraph_index": 11}, {"url": "https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Dai_BoxSup_Exploiting_Bounding_ICCV_2015_paper.pdf", "anchor_text": "Boxsup", "paragraph_index": 13}, {"url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Khoreva_Simple_Does_It_CVPR_2017_paper.pdf", "anchor_text": "Simple Does It", "paragraph_index": 13}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Pinheiro_From_Image-Level_to_2015_CVPR_paper.pdf", "anchor_text": "Pixel-level Labeling", "paragraph_index": 13}, {"url": "http://www.cvlibs.net/datasets/kitti/eval_road.php", "anchor_text": "Kitti Road Dataset", "paragraph_index": 15}, {"url": "https://github.com/udacity/CarND-Semantic-Segmentation/", "anchor_text": "this GitHub repo", "paragraph_index": 15}, {"url": "http://www.cs.toronto.edu/~frossard/post/vgg16/", "anchor_text": "here", "paragraph_index": 17}, {"url": "https://neptune.ai/blog/data-exploration-for-image-segmentation-and-object-detection", "anchor_text": "this guide from Neptune", "paragraph_index": 23}], "all_paragraphs": ["This article is a comprehensive overview including a step-by-step guide to implement a deep learning image segmentation model.", "Nowadays, semantic segmentation is one of the key problems in the field of computer vision. Looking at the big picture, semantic segmentation is one of the high-level task that paves the way towards complete scene understanding. The importance of scene understanding as a core computer vision problem is highlighted by the fact that an increasing number of applications nourish from inferring knowledge from imagery. Some of those applications include self-driving vehicles, human-computer interaction, virtual reality etc. With the popularity of deep learning in recent years, many semantic segmentation problems are being tackled using deep architectures, most often Convolutional Neural Nets, which surpass other approaches by a large margin in terms of accuracy and efficiency.", "Semantic segmentation is a natural step in the progression from coarse to fine inference:", "It is also worthy to review some standard deep networks that have made significant contributions to the field of computer vision, as they are often used as the basis of semantic segmentation systems:", "A general semantic segmentation architecture can be broadly thought of as an encoder network followed by a decoder network:", "Unlike classification where the end result of the very deep network is the only important thing, semantic segmentation not only requires discrimination at pixel level but also a mechanism to project the discriminative features learnt at different stages of the encoder onto the pixel space. Different approaches employ different mechanisms as a part of the decoding mechanism. Let\u2019s explore the 3 main approaches:", "The region-based methods generally follow the \u201csegmentation using recognition\u201d pipeline, which first extracts free-form regions from an image and describes them, followed by region-based classification. At test time, the region-based predictions are transformed to pixel predictions, usually by labeling a pixel according to the highest scoring region that contains it.", "R-CNN (Regions with CNN feature) is one representative work for the region-based methods. It performs the semantic segmentation based on the object detection results. To be specific, R-CNN first utilizes selective search to extract a large quantity of object proposals and then computes CNN features for each of them. Finally, it classifies each region using the class-specific linear SVMs. Compared with traditional CNN structures which are mainly intended for image classification, R-CNN can address more complicated tasks, such as object detection and image segmentation, and it even becomes one important basis for both fields. Moreover, R-CNN can be built on top of any CNN benchmark structures, such as AlexNet, VGG, GoogLeNet, and ResNet.", "For the image segmentation task, R-CNN extracted 2 types of features for each region: full region feature and foreground feature, and found that it could lead to better performance when concatenating them together as the region feature. R-CNN achieved significant performance improvements due to using the highly discriminative CNN features. However, it also suffers from a couple of drawbacks for the segmentation task:", "Due to these bottlenecks, recent research has been proposed to address the problems, including SDS, Hypercolumns, Mask R-CNN.", "The original Fully Convolutional Network (FCN) learns a mapping from pixels to pixels, without extracting the region proposals. The FCN network pipeline is an extension of the classical CNN. The main idea is to make the classical CNN take as input arbitrary-sized images. The restriction of CNNs to accept and produce labels only for specific sized inputs comes from the fully-connected layers which are fixed. Contrary to them, FCNs only have convolutional and pooling layers which give them the ability to make predictions on arbitrary-sized inputs.", "One issue in this specific FCN is that by propagating through several alternated convolutional and pooling layers, the resolution of the output feature maps is down sampled. Therefore, the direct predictions of FCN are typically in low resolution, resulting in relatively fuzzy object boundaries. A variety of more advanced FCN-based approaches have been proposed to address this issue, including SegNet, DeepLab-CRF, and Dilated Convolutions.", "Most of the relevant methods in semantic segmentation rely on a large number of images with pixel-wise segmentation masks. However, manually annotating these masks is quite time-consuming, frustrating and commercially expensive. Therefore, some weakly supervised methods have recently been proposed, which are dedicated to fulfilling the semantic segmentation by utilizing annotated bounding boxes.", "For example, Boxsup employed the bounding box annotations as a supervision to train the network and iteratively improve the estimated masks for semantic segmentation. Simple Does It treated the weak supervision limitation as an issue of input label noise and explored recursive training as a de-noising strategy. Pixel-level Labeling interpreted the segmentation task within the multiple-instance learning framework and added an extra layer to constrain the model to assign more weight to important pixels for image-level classification.", "In this section, let\u2019s walk through a step-by-step implementation of the most popular architecture for semantic segmentation \u2014 the Fully-Convolutional Net (FCN). We\u2019ll implement it using the TensorFlow library in Python 3, along with other dependencies such as Numpy and Scipy.", "In this exercise we will label the pixels of a road in images using FCN. We\u2019ll work with the Kitti Road Dataset for road/lane detection. This is a simple exercise from the Udacity\u2019s Self-Driving Car Nano-degree program, which you can learn more about the setup in this GitHub repo.", "Here are the key features of the FCN architecture:", "We first load the pre-trained VGG-16 model into TensorFlow. Taking in the TensorFlow session and the path to the VGG Folder (which is downloadable here), we return the tuple of tensors from VGG model, including the image input, keep_prob (to control dropout rate), layer 3, layer 4, and layer 7.", "Now we focus on creating the layers for a FCN, using the tensors from the VGG model. Given the tensors for VGG layer output and the number of classes to classify, we return the tensor for the last layer of that output. In particular, we apply a 1x1 convolution to the encoder layers, and then add decoder layers to the network with skip connections and upsampling.", "The next step is to optimize our neural network, aka building TensorFlow loss functions and optimizer operations. Here we use cross entropy as our loss function and Adam as our optimization algorithm.", "Here we define the train_nn function, which takes in important parameters including number of epochs, batch size, loss function, optimizer operation, and placeholders for input images, label images, learning rate. For the training process, we also set keep_probability to 0.5 and learning_rate to 0.001. To keep track of the progress, we also print out the loss during training.", "Finally, it\u2019s time to train our net! In this run function, we first build our net using the load_vgg, layers, and optimize function. Then we train the net using the train_nn function and save the inference data for records.", "About our parameters, we choose epochs = 40, batch_size = 16, num_classes = 2, and image_shape = (160, 576). After doing 2 trial passes with dropout = 0.5 and dropout = 0.75, we found that the 2nd trial yields better results with better average losses.", "If you enjoyed this piece, I\u2019d love it if you hit the clap button \ud83d\udc4f so others might stumble upon it. I also recommend checking out this guide from Neptune on how to explore data for image segmentation and object detection. It looks extra comprehensive!"], "all_outgoing_urls": [{"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/nanonets?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/nanonets?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "NanoNets"}, {"url": "https://medium.com/@le-james94?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@le-james94?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "James Le"}, {"url": "https://nanonets.com/object-detection-api/?utm_source=medium.com_Semantic_Segmentation&utm_medium=blog&utm_campaign=semantic_segmentation", "anchor_text": "Nanonets Object Detection APIs"}, {"url": "https://sthalles.github.io/deep_segmentation_network/", "anchor_text": "https://sthalles.github.io/deep_segmentation_network/"}, {"url": "https://blog.goodaudience.com/using-convolutional-neural-networks-for-image-segmentation-a-quick-intro-75bd68779225", "anchor_text": "https://blog.goodaudience.com/using-convolutional-neural-networks-for-image-segmentation-a-quick-intro-75bd68779225"}, {"url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf", "anchor_text": "AlexNet"}, {"url": "https://arxiv.org/pdf/1409.1556.pdf", "anchor_text": "VGG-16"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf", "anchor_text": "GoogLeNet"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf", "anchor_text": "ResNet"}, {"url": "https://www.semanticscholar.org/paper/An-Analysis-of-Deep-Neural-Network-Models-for-Canziani-Paszke/28ee688947cf9d31fc48f07a0497cd75200a9485", "anchor_text": "https://www.semanticscholar.org/paper/An-Analysis-of-Deep-Neural-Network-Models-for-Canziani-Paszke/28ee688947cf9d31fc48f07a0497cd75200a9485"}, {"url": "https://arxiv.org/pdf/1311.2524.pdf", "anchor_text": "R-CNN"}, {"url": "https://arxiv.org/pdf/1407.1808.pdf", "anchor_text": "SDS"}, {"url": "https://arxiv.org/pdf/1411.5752.pdf", "anchor_text": "Hypercolumns"}, {"url": "https://arxiv.org/pdf/1703.06870.pdf", "anchor_text": "Mask R-CNN"}, {"url": "https://arxiv.org/pdf/1411.4038.pdf", "anchor_text": "Fully Convolutional Network (FCN)"}, {"url": "https://arxiv.org/pdf/1511.00561.pdf", "anchor_text": "SegNet"}, {"url": "https://arxiv.org/pdf/1412.7062.pdf", "anchor_text": "DeepLab-CRF"}, {"url": "https://arxiv.org/pdf/1511.07122.pdf", "anchor_text": "Dilated Convolutions"}, {"url": "https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Dai_BoxSup_Exploiting_Bounding_ICCV_2015_paper.pdf", "anchor_text": "Boxsup"}, {"url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Khoreva_Simple_Does_It_CVPR_2017_paper.pdf", "anchor_text": "Simple Does It"}, {"url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Pinheiro_From_Image-Level_to_2015_CVPR_paper.pdf", "anchor_text": "Pixel-level Labeling"}, {"url": "http://www.cvlibs.net/datasets/kitti/eval_road.php", "anchor_text": "Kitti Road Dataset"}, {"url": "https://github.com/udacity/CarND-Semantic-Segmentation/", "anchor_text": "this GitHub repo"}, {"url": "http://www.cvlibs.net/datasets/kitti/eval_road_detail.php?result=3748e213cf8e0100b7a26198114b3cdc7caa3aff", "anchor_text": "http://www.cvlibs.net/datasets/kitti/eval_road_detail.php?result=3748e213cf8e0100b7a26198114b3cdc7caa3aff"}, {"url": "https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn8_vgg.py", "anchor_text": "FCN-8"}, {"url": "https://www.researchgate.net/figure/Illustration-of-the-FCN-8s-network-architecture-as-proposed-in-20-In-our-method-the_fig1_305770331", "anchor_text": "https://www.researchgate.net/figure/Illustration-of-the-FCN-8s-network-architecture-as-proposed-in-20-In-our-method-the_fig1_305770331"}, {"url": "http://www.cs.toronto.edu/~frossard/post/vgg16/", "anchor_text": "here"}, {"url": "https://gist.github.com/khanhnamle1994/e2ff59ddca93c0205ac4e566d40b5e88", "anchor_text": "https://gist.github.com/khanhnamle1994/e2ff59ddca93c0205ac4e566d40b5e88"}, {"url": "https://neptune.ai/blog/data-exploration-for-image-segmentation-and-object-detection", "anchor_text": "this guide from Neptune"}, {"url": "https://nanonets.com/?utm_source=Medium.com&utm_campaign=How%20to%20do%20Semantic%20Segmentation%20using%20Deep%C2%A0learning", "anchor_text": "Nanonets.com"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----c673cc5862ef---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/computer-vision?source=post_page-----c673cc5862ef---------------computer_vision-----------------", "anchor_text": "Computer Vision"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----c673cc5862ef---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/segmentation?source=post_page-----c673cc5862ef---------------segmentation-----------------", "anchor_text": "Segmentation"}, {"url": "https://medium.com/tag/neural-networks?source=post_page-----c673cc5862ef---------------neural_networks-----------------", "anchor_text": "Neural Networks"}, {"url": "https://medium.com/nanonets?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "More from NanoNets"}, {"url": "https://medium.com/nanonets?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "Read more from NanoNets"}, {"url": "https://medium.com/?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c673cc5862ef--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----c673cc5862ef--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----c673cc5862ef--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/plans?source=upgrade_membership---two_column_layout_sidebar----------------------------------", "anchor_text": "Get unlimited access"}, {"url": "https://medium.com/@le-james94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@le-james94?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "James Le"}, {"url": "https://medium.com/@le-james94/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "17.6K Followers"}, {"url": "https://jameskle.com/", "anchor_text": "https://jameskle.com/"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F171511b90ce0&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnanonets%2Fhow-to-do-image-segmentation-using-deep-learning-c673cc5862ef&newsletterV3=52aa38cb8e25&newsletterV3Id=171511b90ce0&user=James+Le&userId=52aa38cb8e25&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}