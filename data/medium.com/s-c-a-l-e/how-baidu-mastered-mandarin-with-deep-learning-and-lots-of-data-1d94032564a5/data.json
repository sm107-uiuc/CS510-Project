{"url": "https://medium.com/s-c-a-l-e/how-baidu-mastered-mandarin-with-deep-learning-and-lots-of-data-1d94032564a5", "time": 1682988277.818221, "path": "medium.com/s-c-a-l-e/how-baidu-mastered-mandarin-with-deep-learning-and-lots-of-data-1d94032564a5/", "webpage": {"metadata": {"title": "Baidu explains how it\u2019s mastering Mandarin with deep learning | by Derrick Harris | > S C A L E | Medium", "h1": "Baidu explains how it\u2019s mastering Mandarin with deep learning", "description": "On Aug. 8 at the International Neural Network Society conference on big data in San Francisco, Baidu senior research engineer Awni Hannun presented on a new model that the Chinese search giant has\u2026"}, "outgoing_paragraph_urls": [{"url": "http://innsbigdata.org/", "anchor_text": "International Neural Network Society conference on big data", "paragraph_index": 1}, {"url": "https://gigaom.com/2014/12/18/baidu-claims-deep-learning-breakthrough-with-deep-speech/", "anchor_text": "first unveiled in December 2014", "paragraph_index": 1}, {"url": "https://gigaom.com/2014/09/04/baidu-says-its-massive-deep-learning-system-is-nearly-complete/", "anchor_text": "handling a fairly high volume of voice searches", "paragraph_index": 11}, {"url": "http://blogs.skype.com/2014/12/15/skype-translator-how-it-works/", "anchor_text": "Microsoft\u2019s Skype Translate", "paragraph_index": 13}, {"url": "https://gigaom.com/2015/01/14/baidu-has-built-a-supercomputer-for-deep-learning/", "anchor_text": "puts so much emphasis on systems architecture", "paragraph_index": 34}], "all_paragraphs": ["> S C A L E", "On Aug. 8 at the International Neural Network Society conference on big data in San Francisco, Baidu senior research engineer Awni Hannun presented on a new model that the Chinese search giant has developed for handling voice queries in Mandarin. The model, which is accurate 94 percent of the time in tests, is based on a powerful deep learning system called Deep Speech that Baidu first unveiled in December 2014.", "In this lightly edited interview, Hannun explains why his new research is important, why Mandarin is such a tough language to learn and where we can expect to see future advances in deep learning methods.", "SCALE: How accurate is Deep Speech at translating Mandarin?", "AWNI HANNUN: It has a 6 percent character error rate, which essentially means that it gets wrong 6 out of 100 characters. To put that in context, this is in my opinion \u2014 and to the best of our lab\u2019s knowledge \u2014 the best system at transcribing Mandarin voice queries in the world.", "In fact, we ran an experiment where we had a few people at the lab who speak Chinese transcribe some of the examples that we were testing the system on. It turned out that our system was better at transcribing examples than they were \u2014 if we restricted it to transcribing without the help of the internet and such things.", "\u201cWe give it enough data that it\u2019s able to learn what\u2019s relevant from the input to correctly transcribe the output, with as little human intervention as possible.\u201d", "What is it about Mandarin that makes it such a challenge compared with other languages?", "There are a couple of differences with Mandarin that made us think it would be very difficult to have our English speech system work well with it. One is that it\u2019s a tonal language, so when you say a word in a different pitch, it changes the meaning of the word, which is definitely not the case in English. In traditional speech recognition, it\u2019s actually a desirable property that there is some pitch invariance, which essentially means that it tries to ignore pitch when it does the transcription. So you have to change a bunch of things to get a system to work with Mandarin, or any Chinese for that matter.", "However, for us, it was not the case that we had to change a whole bunch of things, because our pipeline is much simpler than the traditional speech pipeline. We don\u2019t do a whole lot of pre-processing on the audio in order to make it pitch-invariant, but rather just let the model learn what\u2019s relevant from the data to most effectively transcribe it properly. It was actually able to do that fine in Mandarin without having to change the input.", "The other thing that is very different about Chinese \u2014 Mandarin, in this case \u2014 is the character set. The English alphabet is 26 letters, whereas in Chinese it\u2019s something like 80,000 different characters. Our system directly outputs a character at a time as it\u2019s building its transcription, so we speculated it would be very challenging to have to do that on 80,000 characters at each step versus 26. That\u2019s a challenge we were able to overcome just by using characters that people commonly say, which is a smaller subset.", "Baidu has been handling a fairly high volume of voice searches for a while now. How is the Deep Speech system better than the previous system for handling queries in Mandarin?", "Baidu has a very active system for voice search in Mandarin, and it works pretty well. I think in terms of total query activity, it\u2019s still a relatively small percentage. We want to make that share larger, or at least enable people to use it more by making the accuracy of the system better.", "Can you describe the difference between a search-based system like Deep Speech and something like Microsoft\u2019s Skype Translate, which is also based on deep learning?", "Typically, the way it\u2019s done is there are three modules in the pipeline. The first is a speech-transcription module, the second is the machine-translation module and the third would be the speech-synthesis module. What we\u2019re talking about, specifically, is just the speech-transcription module, and I\u2019m sure Microsoft has one as part of Skype Translate.", "Our system is different than that system in that it\u2019s more what we call end-to-end. Rather than having a lot of human-engineered components that have been developed over decades of speech research \u2014 by looking at the system and saying what what features are important or which phonemes the model should predict \u2014 we just have some input data, which is an audio .WAV file on which we do very little pre-processing. And then we have a big, deep neural network that outputs directly to characters. We give it enough data that it\u2019s able to learn what\u2019s relevant from the input to correctly transcribe the output, with as little human intervention as possible.", "One thing that\u2019s pleasantly surprising to us is that we had to do very little changing to it \u2014 other than scaling it and giving it the right data \u2014 to make this system we showed in December that worked really well on English work remarkably well in Chinese, as well.", "\u201cWe want to build a speech system that can be used as the interface to any smart device, not just voice search.\u201d", "What\u2019s the usual timeline to get this type of system from R&D into production?", "It\u2019s not an easy process, but I think it\u2019s easier than the process of getting a model to be very accurate \u2014 in the sense that it\u2019s more of an engineering problem than a research problem. We\u2019re actively working on that now, and I\u2019m hopeful our research system will be in production in the near term.", "Baidu has plans \u2014 and products \u2014 in other areas, including wearables and other embedded forms of speech recognition. Does the work you\u2019re doing on search relate to these other initiatives?", "We want to build a speech system that can be used as the interface to any smart device, not just voice search. It turns out that voice search is a very important part of Baidu\u2019s ecosystem, so that\u2019s one place we can have a lot of impact right now.", "Is the pace of progress and significant advances in deep learning as fast it seems?", "I think right now, it does feel like the pace is increasing because people are recognizing that if you take tasks where you have some input and are trying to produce some output, you can apply deep learning to that task. If it was some old machine learning task such as machine translation or speech recognition, which has been heavily engineered for the past several decades, you can make significant advances if you try to simplify that pipeline with deep learning and increase the amount of data. We\u2019re just on the crest of that.", "In particular, processing sequential data with deep learning is something that we\u2019re just figuring out how to do really well. We\u2019ve come up with models that seem to work well, and we\u2019re at the point where we\u2019re going to start squeezing a lot of performance out of these models. And then you\u2019ll see that right and left, benchmarks will be dropping when it comes to sequential data.", "\u201cWhere there\u2019s a lot of data and where it makes sense to use a deep learning model, success is with high probability going to happen.\u201d", "Beyond that, I don\u2019t know. It\u2019s possible we\u2019ll start to plateau or we\u2019ll start inventing new architectures to do new tasks. I think the moral of this story is: Where there\u2019s a lot of data and where it makes sense to use a deep learning model, success is with high probability going to happen. That\u2019s why it feels like progress is happening so rapidly right now.", "It really becomes a story of \u201cHow can we get right data?\u201d when deep learning is involved. That becomes the big challenge.", "Architecturally, Deep Speech runs on a powerful GPU-based system. Where are the opportunities to move deep learning algorithms onto smaller systems, such as smartphones, in order to offload processing from Baidu\u2019s (or anyone else\u2019s) servers?", "That\u2019s something I think about a lot, actually, and I think the future is bright in that regard. It\u2019s certainly the case that deep learning models are getting bigger and bigger but, typically, it also has also been the case that the size and expressivity of the model is more necessary during training than it is during testing.", "There has been a lot of work that shows that if you take a model that has been trained at, say, 32-bit floating point precision and then compress it to 8-bit fixed point precision, it works just as well at test time. Or it works almost as well. You can reduce it by a factor of four and still have it work just as well.", "There\u2019s also a lot of work in compressing existing models, like how can we take a giant model that we\u2019ve trained to soak up a lot of data and then, say, train another, much smaller model to duplicate what that large model does. But that small model we can actually put into an embedded device somewhere.", "Often, the hard part is in training the system. In those cases, it needs to be really big and the servers have to be really beefy. But I do think there\u2019s a lot of promising work with which we can make the models a lot smaller and there\u2019s a future in terms of embedding them in different places.", "Of course, something like search has to go back to cloud servers unless you\u2019ve somehow indexed the whole web on your smartphone, right?", "For some additional context on just how powerful a system Deep Speech is \u2014 and why Baidu puts so much emphasis on systems architecture for its deep learning efforts \u2014 consider this explanation offered by Baidu systems research scientist Bryan Catanzaro:", "\u201cAs with other deep neural networks, our system gets more and moreaccurate as it is trained on larger and larger datasets. [Baidu]researchers have been working hard to find large datasets from which ourmodel can learn all the nuances and complexities of spoken Chinese, whichis a very diverse language with many dialects and local accents. As weamass these datasets, we encounter interesting systems problems as we tryto scale the training of our system.", "\u201cTo give some context, training Deep Speech on our full Chinese dataset takes tens of exaflops \u2014 that\u2019s more than 10 quintillion (billion billion) multiplications and additions. In order to evaluate whether a new neural network or additional data will improve Deep Speech, we have to wait for this training process to converge, which can take quite some time. Accordingly, the more rapidly we can train Deep Speech, the more ideas we can evaluate, and the more rapidly we make progress.", "\u201cThis is why we pay special attention to systems issues when training our models. We have noticed that as we improve the efficiency of our training system, accuracy improvements follow rather directly. We parallelize the training of our system across multiple GPUs in order to reduce this training time. Our current system sustains more than 26 teraflops while training a single model on 8 GPUs, which allows us to train Deep Speech on a large dataset in a matter of days. We continue pushing the boundaries of scalability, because we\u2019ve observed that our accuracy continues to improve as we scale our training set.\u201d", "What\u2019s next in computing, told by the people behind the software", "Hi :) Find me on Twitter to see what I\u2019m up to now."], "all_outgoing_urls": [{"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/s-c-a-l-e?source=post_page-----1d94032564a5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/s-c-a-l-e?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "> S C A L E"}, {"url": "https://medium.com/@derrickharris?source=post_page-----1d94032564a5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@derrickharris?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "Derrick Harris"}, {"url": "http://innsbigdata.org/", "anchor_text": "International Neural Network Society conference on big data"}, {"url": "https://gigaom.com/2014/12/18/baidu-claims-deep-learning-breakthrough-with-deep-speech/", "anchor_text": "first unveiled in December 2014"}, {"url": "https://gigaom.com/2014/09/04/baidu-says-its-massive-deep-learning-system-is-nearly-complete/", "anchor_text": "handling a fairly high volume of voice searches"}, {"url": "http://blogs.skype.com/2014/12/15/skype-translator-how-it-works/", "anchor_text": "Microsoft\u2019s Skype Translate"}, {"url": "https://gigaom.com/2015/01/14/baidu-has-built-a-supercomputer-for-deep-learning/", "anchor_text": "puts so much emphasis on systems architecture"}, {"url": "https://medium.com/tag/deep-learning?source=post_page-----1d94032564a5---------------deep_learning-----------------", "anchor_text": "Deep Learning"}, {"url": "https://medium.com/tag/tech?source=post_page-----1d94032564a5---------------tech-----------------", "anchor_text": "Tech"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----1d94032564a5---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/s-c-a-l-e?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "More from > S C A L E"}, {"url": "https://medium.com/s-c-a-l-e?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "Read more from > S C A L E"}, {"url": "https://medium.com/?source=post_page-----1d94032564a5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----1d94032564a5--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----1d94032564a5--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----1d94032564a5--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----1d94032564a5--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/plans?source=upgrade_membership---two_column_layout_sidebar----------------------------------", "anchor_text": "Get unlimited access"}, {"url": "https://medium.com/@derrickharris?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@derrickharris?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Derrick Harris"}, {"url": "https://medium.com/@derrickharris/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "9.8K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F5a049cf6dcfb&operation=register&redirect=https%3A%2F%2Fmedium.com%2Fs-c-a-l-e%2Fhow-baidu-mastered-mandarin-with-deep-learning-and-lots-of-data-1d94032564a5&newsletterV3=7824679e7160&newsletterV3Id=5a049cf6dcfb&user=Derrick+Harris&userId=7824679e7160&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}