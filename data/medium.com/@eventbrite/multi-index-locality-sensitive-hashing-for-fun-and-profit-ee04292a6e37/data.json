{"url": "https://medium.com/@eventbrite/multi-index-locality-sensitive-hashing-for-fun-and-profit-ee04292a6e37", "time": 1682988213.865288, "path": "medium.com/@eventbrite/multi-index-locality-sensitive-hashing-for-fun-and-profit-ee04292a6e37/", "webpage": {"metadata": {"title": "Multi-Index Locality Sensitive Hashing for Fun and Profit | by Eventbrite | Medium", "h1": "Multi-Index Locality Sensitive Hashing for Fun and Profit", "description": "One way that we deal with this volume of data, is to cluster up all the similar messages together to find patterns in behavior of senders. For example, if someone is contacting thousands of different\u2026"}, "outgoing_paragraph_urls": [{"url": "http://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel", "anchor_text": "Bit Twiddling Hacks", "paragraph_index": 13}, {"url": "http://en.wikipedia.org/wiki/Pigeonhole_principle", "anchor_text": "pigeonhole principal", "paragraph_index": 16}, {"url": "http://www.cs.toronto.edu/~norouzi/research/papers/multi_index_hashing.pdf", "anchor_text": "Fast Search in Hamming Space with Multi-Index Hashing]", "paragraph_index": 17}], "all_paragraphs": ["One way that we deal with this volume of data, is to cluster up all the similar messages together to find patterns in behavior of senders. For example, if someone is contacting thousands of different organizers with similar messages, that behavior is suspect and will be examined.", "The big question is, how can we compare every single message we see with every other message efficiently and accurately? In this article, we\u2019ll be exploring a technique known as Multi-Index Locality Sensitive Hashing.", "To perform the the comparison efficiently, we pre-process the data with a series of steps:", "Let\u2019s first define what similar messages are. Here we have and example of two similar messages A and B:", "To our human eyes of course they\u2019re similar, but we want determine this similarity quantitatively. The solution is to break up the message into tokens, and then treat each message as a bag of tokens. The simplest, naive way to do tokenization is to split up a message on spaces/punctuation and convert each character to lowercase. So our result from our tokenization of the above messages would be:", "I\u2019ll leave as an exercise to the reader to come up with more interesting ways to do tokenization for handling contractions, plurals, foreign languages, etc.", "To calculate the similarity between these two bags of tokens, we\u2019ll use an estimation known as the Jaccard Similarity Coefficient. This is defined as \u201cthe ratio of sizes of the intersection and union of A and B\u201d. Therefore, in our example:", "We\u2019ll then set a threshold, above which, we will consider two messages to be similar. So then, when given a set of M messages, we simply compute the similarity of a message to every other message. This works in theory, but in practice there are cases where this metric is unreliable (eg. if one message is significantly longer than the other); not to mention horribly inefficient (O(N\u00b2 M\u00b2), where N is the number of tokens per message). We need do things smarter!", "One problem with doing a simple Jaccard similarity is that the scale of the value changes with the size (number of tokens) of the message. To address this, we can transform our tokens with a method known as minHash. Here\u2019s a psuedo-code snippet:", "The interesting property of the minHash transformation is that it leaves us with a constant N number of hashes, and that \u201cchosen\u201d hashes will be in the same positions in the vector. After the minHash transformation, the Jaccard similarity can be approximated by an element-wise comparison of two hash vectors (implemented as pseudo-code above).", "So, we can stop here, but we\u2019re having so much fun\u2026 and we can do so much better. Notice when we do comparison, we have to to O(N) integer comparisons, and if we have M messages then comparing every message to each other is O(N M\u00b2) integer comparisons. This is still not acceptable.", "To reduce the time complexity of comparing minHashes to each other, we can do better with a technique known as bit sampling. The main idea is that we don\u2019t need to know the exact value of each hash, but only that the hashes are equal at their respective positions in each hash vector. With this insight, let\u2019s only look at the least significant bit (LSB) of each hash value.", "When comparing two messages, if the hashes are equal in the same position in the minHash vector, then the bits in the equivalent position after bit sampling should be also equal. So, we can emulate the Jaccard similarity of two minHashes by counting the equal bits in the two bit vectors (aka. the Hamming Distance) and dividing by the number of bits. Of course, two different hashes will have the same LSB 50% of the time; to increase our efficacy, we would pick a large N initially. Here is some naive and inefficient pseudo-code:", "In practice, more efficient implementations of the bitSimilarity function can calculate in near O(1) time for reasonable sizes of N (Bit Twiddling Hacks). This means that when comparing M messages to each other, we\u2019ve reduced the time complexity to O(M\u00b2). But wait, there\u2019s more!", "Remember how I said we have a lot of data? O(M\u00b2) is still unreasonable when M is a very large number of messages. So we need to try to reduce the number of comparisons to make using a \u201cdivide and conquer\u201d strategy.", "Lets start with an example where we set N=32, and we want to have a bitSimilarity of .9: In the worst case, to do this, we need 28 of the 32 bits to be equal, or 4 bits unequal. We will refer to the number of unequal bits as the radius of the bit vectors; ie. if two bit vectors are within a certain radius of bits, then they are similar. The unequal bits can be found by taking the bit-wise XOR of the two bit vectors. For example:", "If we split up XOR_mask into 4 chunks of 8 bits, then at least one chunk will have exactly zero or exactly one of the bit differences (pigeonhole principal). More generally, if we split XOR_mask of size N into K chunks, with an expected radius R, then at least one chunk is guaranteed to have floor(R / K) or less bits unequal. For the purpose of explanation, we will assume that we have chosen all the parameters such that floor(R / K) = 1.", "Now you\u2019re wondering how this piece of logic help us? We can now design a data structure LshTable to index the bit vectors to reduce the number of bitSimilarity comparisons drastically (but increase memory consumption in O(M)) [Fast Search in Hamming Space with Multi-Index Hashing].", "We will define LshTable with some pseudo-code:", "Basically, in LshTable initialization, we create K hash tables for each K chunks. During add() of a bit vector, we split the bit vector into K chunks. For each of these chunks, we add the original bit vector into the associated hash table under the index chunk.", "Upon the lookup() of a bit vector, we once again split it into chunks and for each chunk look up the associated hash table for a chunk that\u2019s close (zero or one bits off). The returned list is a set of candidate bit vectors to check bitSimilarity. Because of the property explained in the previous section, at least one hash table will contain a set of candidates that contains a similar bit vector.", "To compare every M message to every other message we first insert its bit vector into an LshTable (an O(K) operation, K is constant). Then to find similar messages, we simply do a lookup from the LshTable (another O(K) operation), and then check bitSimilarity for each of the candidates returned. The number of candidates to check is usually on the order of M / 2^(N/K), if at all. Therefore, the time complexity to compare all M messages to each other is O(M * M / 2^(N/K)). In practice, N and K are empirically chosen such that 2^(N/K) >> M, so the final time complexity is O(M) \u2014 remember we started with O(N M\u00b2)!", "Phew, what a ride. So, we\u2019ve detailed how to find similar messages in a very large set of messages efficiently. By using Multi-Index Locality Sensitivity Hashing, we can reduce the time complexity of from quadratic (with a very high constant) to near linear (with a more manageable constant).", "I should also mention that many of the ancillary pseudo-code excerpts used here describe the most naive implementation of each method, and are for instructive purposes only.", "We help bring the world together through live experiences.", "We help bring the world together through live experiences."], "all_outgoing_urls": [{"url": "https://medium.com/?source=---two_column_layout_nav----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eventbrite?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eventbrite?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "Eventbrite"}, {"url": "http://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel", "anchor_text": "Bit Twiddling Hacks"}, {"url": "http://en.wikipedia.org/wiki/Pigeonhole_principle", "anchor_text": "pigeonhole principal"}, {"url": "http://www.cs.toronto.edu/~norouzi/research/papers/multi_index_hashing.pdf", "anchor_text": "Fast Search in Hamming Space with Multi-Index Hashing]"}, {"url": "https://medium.com/tag/performance?source=post_page-----ee04292a6e37---------------performance-----------------", "anchor_text": "Performance"}, {"url": "https://medium.com/tag/algorithm?source=post_page-----ee04292a6e37---------------algorithm-----------------", "anchor_text": "Algorithm"}, {"url": "https://medium.com/tag/clustering?source=post_page-----ee04292a6e37---------------clustering-----------------", "anchor_text": "Clustering"}, {"url": "https://medium.com/tag/machine-learning?source=post_page-----ee04292a6e37---------------machine_learning-----------------", "anchor_text": "Machine Learning"}, {"url": "https://medium.com/tag/prolly?source=post_page-----ee04292a6e37---------------prolly-----------------", "anchor_text": "Prolly"}, {"url": "https://medium.com/@eventbrite?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "More from Eventbrite"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea1595672ff2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40eventbrite%2Fmulti-index-locality-sensitive-hashing-for-fun-and-profit-ee04292a6e37&newsletterV3=ee7fbe242c11&newsletterV3Id=ea1595672ff2&user=Eventbrite&userId=ee7fbe242c11&source=-----ee04292a6e37---------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://medium.com/?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/about?autoplay=1&source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "About"}, {"url": "https://help.medium.com/hc/en-us?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "Help"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "Terms"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ee04292a6e37--------------------------------", "anchor_text": "Privacy"}, {"url": "https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8&ct=post_page&source=post_page-----ee04292a6e37--------------------------------", "anchor_text": ""}, {"url": "https://play.google.com/store/apps/details?id=com.medium.reader&source=post_page-----ee04292a6e37--------------------------------", "anchor_text": ""}, {"url": "https://medium.com/plans?source=upgrade_membership---two_column_layout_sidebar----------------------------------", "anchor_text": "Get unlimited access"}, {"url": "https://medium.com/@eventbrite?source=---two_column_layout_sidebar----------------------------------", "anchor_text": ""}, {"url": "https://medium.com/@eventbrite?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Eventbrite"}, {"url": "https://medium.com/@eventbrite/followers?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "27K Followers"}, {"url": "https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fea1595672ff2&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40eventbrite%2Fmulti-index-locality-sensitive-hashing-for-fun-and-profit-ee04292a6e37&newsletterV3=ee7fbe242c11&newsletterV3Id=ea1595672ff2&user=Eventbrite&userId=ee7fbe242c11&source=---two_column_layout_sidebar-----------------------subscribe_user-----------", "anchor_text": ""}, {"url": "https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Help"}, {"url": "https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Status"}, {"url": "https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Writers"}, {"url": "https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Blog"}, {"url": "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Careers"}, {"url": "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Privacy"}, {"url": "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Terms"}, {"url": "https://medium.com/about?autoplay=1&source=---two_column_layout_sidebar----------------------------------", "anchor_text": "About"}, {"url": "https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------", "anchor_text": "Text to speech"}]}, "scrape_status": {"code": "1"}}